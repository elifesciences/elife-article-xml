<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">57443</article-id><article-id pub-id-type="doi">10.7554/eLife.57443</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A connectome and analysis of the adult <italic>Drosophila</italic> central brain</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-84490"><name><surname>Scheffer</surname><given-names>Louis K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3289-6564</contrib-id><email>schefferl@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-81056"><name><surname>Xu</surname><given-names>C Shan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8564-7836</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-181648"><name><surname>Januszewski</surname><given-names>Michal</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3480-2744</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-75275"><name><surname>Lu</surname><given-names>Zhiyuan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4128-9774</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-77519"><name><surname>Takemura</surname><given-names>Shin-ya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2400-6426</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-81393"><name><surname>Hayworth</surname><given-names>Kenneth J</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-84475"><name><surname>Huang</surname><given-names>Gary B</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9606-3510</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-116948"><name><surname>Shinomiya</surname><given-names>Kazunori</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0262-6421</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181649"><name><surname>Maitlin-Shepard</surname><given-names>Jeremy</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8453-7961</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author" id="author-84474"><name><surname>Berg</surname><given-names>Stuart</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-111423"><name><surname>Clements</surname><given-names>Jody</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181653"><name><surname>Hubbard</surname><given-names>Philip M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6746-5035</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84476"><name><surname>Katz</surname><given-names>William T</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9417-6212</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84479"><name><surname>Umayam</surname><given-names>Lowell</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84472"><name><surname>Zhao</surname><given-names>Ting</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con15"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181650"><name><surname>Ackerman</surname><given-names>David</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0172-6594</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con16"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181651"><name><surname>Blakely</surname><given-names>Tim</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0995-5471</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con17"/><xref ref-type="fn" rid="conf4"/></contrib><contrib contrib-type="author" id="author-116753"><name><surname>Bogovic</surname><given-names>John</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4829-9457</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con18"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181652"><name><surname>Dolafi</surname><given-names>Tom</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con19"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181654"><name><surname>Kainmueller</surname><given-names>Dagmar</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9830-2415</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con20"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa1">‡</xref></contrib><contrib contrib-type="author" id="author-198759"><name><surname>Kawase</surname><given-names>Takashi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con21"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181656"><name><surname>Khairy</surname><given-names>Khaled A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9274-5928</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con22"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa2">§</xref></contrib><contrib contrib-type="author" id="author-181657"><name><surname>Leavitt</surname><given-names>Laramie</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con23"/><xref ref-type="fn" rid="conf5"/></contrib><contrib contrib-type="author" id="author-181658"><name><surname>Li</surname><given-names>Peter H</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6193-4454</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con24"/><xref ref-type="fn" rid="conf6"/></contrib><contrib contrib-type="author" id="author-181659"><name><surname>Lindsey</surname><given-names>Larry</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con25"/><xref ref-type="fn" rid="conf7"/></contrib><contrib contrib-type="author" id="author-181660"><name><surname>Neubarth</surname><given-names>Nicole</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con26"/><xref ref-type="fn" rid="conf1"/><xref ref-type="fn" rid="pa3">#</xref></contrib><contrib contrib-type="author" id="author-84477"><name><surname>Olbris</surname><given-names>Donald J</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con27"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-165616"><name><surname>Otsuna</surname><given-names>Hideo</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con28"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-28200"><name><surname>Trautman</surname><given-names>Eric T</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8588-0569</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con29"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-165615"><name><surname>Ito</surname><given-names>Masayoshi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con30"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-166292"><name><surname>Bates</surname><given-names>Alexander S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1195-0445</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con31"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181661"><name><surname>Goldammer</surname><given-names>Jens</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5623-8339</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con32"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-83906"><name><surname>Wolff</surname><given-names>Tanya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8681-1749</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con33"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181662"><name><surname>Svirskas</surname><given-names>Robert</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8374-6008</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con34"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-117456"><name><surname>Schlegel</surname><given-names>Philipp</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5633-1314</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con35"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-117532"><name><surname>Neace</surname><given-names>Erika</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con36"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181663"><name><surname>Knecht</surname><given-names>Christopher J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5663-5967</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con37"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181664"><name><surname>Alvarado</surname><given-names>Chelsea X</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5973-7512</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con38"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181665"><name><surname>Bailey</surname><given-names>Dennis A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4675-8373</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con39"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181666"><name><surname>Ballinger</surname><given-names>Samantha</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con40"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-75274"><name><surname>Borycz</surname><given-names>Jolanta A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4402-9230</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con41"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181667"><name><surname>Canino</surname><given-names>Brandon S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8454-865X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con42"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181668"><name><surname>Cheatham</surname><given-names>Natasha</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con43"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181669"><name><surname>Cook</surname><given-names>Michael</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7892-6845</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con44"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-201054"><name><surname>Dreher</surname><given-names>Marisa</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0041-9229</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con45"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181671"><name><surname>Duclos</surname><given-names>Octave</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con46"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181672"><name><surname>Eubanks</surname><given-names>Bryon</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9288-2009</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con47"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181673"><name><surname>Fairbanks</surname><given-names>Kelli</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6601-4830</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con48"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181674"><name><surname>Finley</surname><given-names>Samantha</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8086-206X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con49"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181675"><name><surname>Forknall</surname><given-names>Nora</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2139-7599</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con50"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181676"><name><surname>Francis</surname><given-names>Audrey</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1974-7174</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con51"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181677"><name><surname>Hopkins</surname><given-names>Gary Patrick</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con52"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181678"><name><surname>Joyce</surname><given-names>Emily M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5794-6321</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con53"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181679"><name><surname>Kim</surname><given-names>SungJin</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con54"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181680"><name><surname>Kirk</surname><given-names>Nicole A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con55"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181681"><name><surname>Kovalyak</surname><given-names>Julie</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7864-7734</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con56"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84482"><name><surname>Lauchie</surname><given-names>Shirley A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8223-9522</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con57"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181682"><name><surname>Lohff</surname><given-names>Alanna</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1242-1836</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con58"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181683"><name><surname>Maldonado</surname><given-names>Charli</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con59"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181684"><name><surname>Manley</surname><given-names>Emily A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con60"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-111313"><name><surname>McLin</surname><given-names>Sari</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9120-1136</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con61"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181685"><name><surname>Mooney</surname><given-names>Caroline</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con62"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181686"><name><surname>Ndama</surname><given-names>Miatta</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con63"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84483"><name><surname>Ogundeyi</surname><given-names>Omotara</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con64"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181687"><name><surname>Okeoma</surname><given-names>Nneoma</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con65"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84484"><name><surname>Ordish</surname><given-names>Christopher</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con66"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181688"><name><surname>Padilla</surname><given-names>Nicholas</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con67"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181689"><name><surname>Patrick</surname><given-names>Christopher M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8830-1892</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con68"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181690"><name><surname>Paterson</surname><given-names>Tyler</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con69"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181691"><name><surname>Phillips</surname><given-names>Elliott E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4918-2058</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con70"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181692"><name><surname>Phillips</surname><given-names>Emily M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7615-301X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con71"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181693"><name><surname>Rampally</surname><given-names>Neha</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con72"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181694"><name><surname>Ribeiro</surname><given-names>Caitlin</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con73"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181695"><name><surname>Robertson</surname><given-names>Madelaine K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1764-0245</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con74"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181696"><name><surname>Rymer</surname><given-names>Jon Thomson</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4271-6774</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con75"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181697"><name><surname>Ryan</surname><given-names>Sean M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8879-6108</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con76"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181698"><name><surname>Sammons</surname><given-names>Megan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4516-5928</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con77"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181699"><name><surname>Scott</surname><given-names>Anne K</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con78"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181700"><name><surname>Scott</surname><given-names>Ashley L</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con79"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84485"><name><surname>Shinomiya</surname><given-names>Aya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-6358-9567</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con80"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-117534"><name><surname>Smith</surname><given-names>Claire</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con81"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181701"><name><surname>Smith</surname><given-names>Kelsey</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con82"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181702"><name><surname>Smith</surname><given-names>Natalie L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8271-9873</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con83"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181703"><name><surname>Sobeski</surname><given-names>Margaret A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con84"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181704"><name><surname>Suleiman</surname><given-names>Alia</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con85"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181705"><name><surname>Swift</surname><given-names>Jackie</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1321-8183</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con86"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84487"><name><surname>Takemura</surname><given-names>Satoko</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2863-0050</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con87"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-117535"><name><surname>Talebi</surname><given-names>Iris</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0173-8053</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con88"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-92143"><name><surname>Tarnogorska</surname><given-names>Dorota</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7063-6165</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con89"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181706"><name><surname>Tenshaw</surname><given-names>Emily</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con90"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181707"><name><surname>Tokhi</surname><given-names>Temour</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con91"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181708"><name><surname>Walsh</surname><given-names>John J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7176-4708</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con92"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181709"><name><surname>Yang</surname><given-names>Tansy</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1131-0410</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con93"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-111304"><name><surname>Horne</surname><given-names>Jane Anne</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9673-2692</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con94"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-43642"><name><surname>Li</surname><given-names>Feng</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con95"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-199182"><name><surname>Parekh</surname><given-names>Ruchi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8060-2807</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con96"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-84471"><name><surname>Rivlin</surname><given-names>Patricia K</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con97"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-5086"><name><surname>Jayaraman</surname><given-names>Vivek</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3680-7378</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con98"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-124755"><name><surname>Costa</surname><given-names>Marta</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5948-3092</contrib-id><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con99"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-3166"><name><surname>Jefferis</surname><given-names>Gregory SXE</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0587-9355</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con100"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-162098"><name><surname>Ito</surname><given-names>Kei</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7274-5533</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con101"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-19822"><name><surname>Saalfeld</surname><given-names>Stephan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4106-1761</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con102"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181711"><name><surname>George</surname><given-names>Reed</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con103"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-141811"><name><surname>Meinertzhagen</surname><given-names>Ian A</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con104"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-53801"><name><surname>Rubin</surname><given-names>Gerald M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8762-8703</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con105"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-81398"><name><surname>Hess</surname><given-names>Harald F</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3000-1533</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con106"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-181712"><name><surname>Jain</surname><given-names>Viren</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con107"/><xref ref-type="fn" rid="conf8"/></contrib><contrib contrib-type="author" corresp="yes" id="author-84478"><name><surname>Plaza</surname><given-names>Stephen M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7425-8555</contrib-id><email>plazas@janelia.hhmi.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con108"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Janelia Research Campus, Howard Hughes Medical Institute</institution><addr-line><named-content content-type="city">Ashburn</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Google Research</institution><addr-line><named-content content-type="city">Mountain View</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Life Sciences Centre, Dalhousie University</institution><addr-line><named-content content-type="city">Halifax</named-content></addr-line><country>Canada</country></aff><aff id="aff4"><label>4</label><institution>Google Research, Google LLC</institution><addr-line><named-content content-type="city">Zurich</named-content></addr-line><country>Switzerland</country></aff><aff id="aff5"><label>5</label><institution>Institute for Quantitative Biosciences, University of Tokyo</institution><addr-line><named-content content-type="city">Tokyo</named-content></addr-line><country>Japan</country></aff><aff id="aff6"><label>6</label><institution>MRC Laboratory of Molecular Biology</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution>Institute of Zoology, Biocenter Cologne, University of Cologne</institution><addr-line><named-content content-type="city">Cologne</named-content></addr-line><country>Germany</country></aff><aff id="aff8"><label>8</label><institution>Department of Zoology, University of Cambridge</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Reviewing Editor</role><aff><institution>Brandeis University</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Eisen</surname><given-names>Michael B</given-names></name><role>Senior Editor</role><aff><institution>University of California, Berkeley</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>‡</label><p>Max Delbrueck Centre for Developmental Medicine, Berlin, Germany</p></fn><fn fn-type="present-address" id="pa2"><label>§</label><p>Department of Developmental Neurobiology, St. Jude Children’s Research Hospital, Memphis, United States</p></fn><fn fn-type="present-address" id="pa3"><label>#</label><p>Two Six Labs, Arlington, United States</p></fn><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>07</day><month>09</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e57443</elocation-id><history><date date-type="received" iso-8601-date="2020-03-31"><day>31</day><month>03</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-09-01"><day>01</day><month>09</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Scheffer et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Scheffer et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-57443-v3.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="commentary" xlink:href="10.7554/eLife.62451"/><abstract><p>The neural circuits responsible for animal behavior remain largely unknown. We summarize new methods and present the circuitry of a large fraction of the brain of the fruit fly <italic>Drosophila melanogaster</italic>. Improved methods include new procedures to prepare, image, align, segment, find synapses in, and proofread such large data sets. We define cell types, refine computational compartments, and provide an exhaustive atlas of cell examples and types, many of them novel. We provide detailed circuits consisting of neurons and their chemical synapses for most of the central brain. We make the data public and simplify access, reducing the effort needed to answer circuit questions, and provide procedures linking the neurons defined by our analysis with genetic reagents. Biologically, we examine distributions of connection strengths, neural motifs on different scales, electrical consequences of compartmentalization, and evidence that maximizing packing density is an important criterion in the evolution of the fly’s brain.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>Animal brains of all sizes, from the smallest to the largest, work in broadly similar ways. Studying the brain of any one animal in depth can thus reveal the general principles behind the workings of all brains. The fruit fly Drosophila is a popular choice for such research. With about 100,000 neurons – compared to some 86 billion in humans – the fly brain is small enough to study at the level of individual cells. But it nevertheless supports a range of complex behaviors, including navigation, courtship and learning.</p><p>Thanks to decades of research, scientists now have a good understanding of which parts of the fruit fly brain support particular behaviors. But exactly how they do this is often unclear. This is because previous studies showing the connections between cells only covered small areas of the brain. This is like trying to understand a novel when all you can see is a few isolated paragraphs.</p><p>To solve this problem, Scheffer, Xu, Januszewski, Lu, Takemura, Hayworth, Huang, Shinomiya et al. prepared the first complete map of the entire central region of the fruit fly brain. The central brain consists of approximately 25,000 neurons and around 20 million connections. To prepare the map – or connectome – the brain was cut into very thin 8nm slices and photographed with an electron microscope. A three-dimensional map of the neurons and connections in the brain was then reconstructed from these images using machine learning algorithms. Finally, Scheffer et al. used the new connectome to obtain further insights into the circuits that support specific fruit fly behaviors.</p><p>The central brain connectome is freely available online for anyone to access. When used in combination with existing methods, the map will make it easier to understand how the fly brain works, and how and why it can fail to work correctly. Many of these findings will likely apply to larger brains, including our own. In the long run, studying the fly connectome may therefore lead to a better understanding of the human brain and its disorders. Performing a similar analysis on the brain of a small mammal, by scaling up the methods here, will be a likely next step along this path.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>connectome</kwd><kwd>brain regions</kwd><kwd>cell types</kwd><kwd>graph properties</kwd><kwd>connectome reconstuction methods</kwd><kwd>synapse detecton</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><award-id>Internal funding</award-id><principal-award-recipient><name><surname>Scheffer</surname><given-names>Louis K</given-names></name><name><surname>Xu</surname><given-names>C Shan</given-names></name><name><surname>Lu</surname><given-names>Zhiyuan</given-names></name><name><surname>Takemura</surname><given-names>Shin-ya</given-names></name><name><surname>Hayworth</surname><given-names>Kenneth J</given-names></name><name><surname>Huang</surname><given-names>Gary B</given-names></name><name><surname>Shinomiya</surname><given-names>Kazunori</given-names></name><name><surname>Berg</surname><given-names>Stuart</given-names></name><name><surname>Clements</surname><given-names>Jody</given-names></name><name><surname>Hubbard</surname><given-names>Philip M</given-names></name><name><surname>Katz</surname><given-names>William T</given-names></name><name><surname>Umayam</surname><given-names>Lowell</given-names></name><name><surname>Zhao</surname><given-names>Ting</given-names></name><name><surname>Ackerman</surname><given-names>David</given-names></name><name><surname>Bogovic</surname><given-names>John</given-names></name><name><surname>Dolafi</surname><given-names>Tom</given-names></name><name><surname>Kainmueller</surname><given-names>Dagmar</given-names></name><name><surname>Khairy</surname><given-names>Khaled A</given-names></name><name><surname>Neubarth</surname><given-names>Nicole</given-names></name><name><surname>Olbris</surname><given-names>Donald J</given-names></name><name><surname>Otsuna</surname><given-names>Hideo</given-names></name><name><surname>Trautman</surname><given-names>Eric T</given-names></name><name><surname>Ito</surname><given-names>Masayoshi</given-names></name><name><surname>Goldammer</surname><given-names>Jens</given-names></name><name><surname>Wolff</surname><given-names>Tanya</given-names></name><name><surname>Svirskas</surname><given-names>Robert</given-names></name><name><surname>Neace</surname><given-names>Erika</given-names></name><name><surname>Knecht</surname><given-names>Christopher J</given-names></name><name><surname>Alvarado</surname><given-names>Chelsea X</given-names></name><name><surname>Bailey</surname><given-names>Dennis A</given-names></name><name><surname>Ballinger</surname><given-names>Samantha</given-names></name><name><surname>Borycz</surname><given-names>Jolanta A</given-names></name><name><surname>Canino</surname><given-names>Brandon S</given-names></name><name><surname>Cheatham</surname><given-names>Natasha</given-names></name><name><surname>Cook</surname><given-names>Michael</given-names></name><name><surname>Dreher</surname><given-names>Marisa</given-names></name><name><surname>Duclos</surname><given-names>Octave</given-names></name><name><surname>Eubanks</surname><given-names>Bryon</given-names></name><name><surname>Fairbanks</surname><given-names>Kelli</given-names></name><name><surname>Finley</surname><given-names>Samantha</given-names></name><name><surname>Forknall</surname><given-names>Nora</given-names></name><name><surname>Francis</surname><given-names>Audrey</given-names></name><name><surname>Hopkins</surname><given-names>Gary Patrick</given-names></name><name><surname>Joyce</surname><given-names>Emily M</given-names></name><name><surname>Kim</surname><given-names>SungJin</given-names></name><name><surname>Kirk</surname><given-names>Nicole A</given-names></name><name><surname>Kovalyak</surname><given-names>Julie</given-names></name><name><surname>Lauchie</surname><given-names>Shirley A</given-names></name><name><surname>Lohff</surname><given-names>Alanna</given-names></name><name><surname>Maldonado</surname><given-names>Charli</given-names></name><name><surname>Manley</surname><given-names>Emily A</given-names></name><name><surname>McLin</surname><given-names>Sari</given-names></name><name><surname>Mooney</surname><given-names>Caroline</given-names></name><name><surname>Ndama</surname><given-names>Miatta</given-names></name><name><surname>Ogundeyi</surname><given-names>Omotara</given-names></name><name><surname>Okeoma</surname><given-names>Nneoma</given-names></name><name><surname>Ordish</surname><given-names>Christopher</given-names></name><name><surname>Padilla</surname><given-names>Nicholas</given-names></name><name><surname>Patrick</surname><given-names>Christopher M</given-names></name><name><surname>Paterson</surname><given-names>Tyler</given-names></name><name><surname>Phillips</surname><given-names>Elliott E</given-names></name><name><surname>Phillips</surname><given-names>Emily M</given-names></name><name><surname>Rampally</surname><given-names>Neha</given-names></name><name><surname>Ribeiro</surname><given-names>Caitlin</given-names></name><name><surname>Robertson</surname><given-names>Madelaine K</given-names></name><name><surname>Rymer</surname><given-names>Jon Thomson</given-names></name><name><surname>Ryan</surname><given-names>Sean M</given-names></name><name><surname>Sammons</surname><given-names>Megan</given-names></name><name><surname>Scott</surname><given-names>Anne K</given-names></name><name><surname>Scott</surname><given-names>Ashley L</given-names></name><name><surname>Shinomiya</surname><given-names>Aya</given-names></name><name><surname>Smith</surname><given-names>Claire</given-names></name><name><surname>Smith</surname><given-names>Kelsey</given-names></name><name><surname>Smith</surname><given-names>Natalie L</given-names></name><name><surname>Sobeski</surname><given-names>Margaret A</given-names></name><name><surname>Suleiman</surname><given-names>Alia</given-names></name><name><surname>Swift</surname><given-names>Jackie</given-names></name><name><surname>Takemura</surname><given-names>Satoko</given-names></name><name><surname>Talebi</surname><given-names>Iris</given-names></name><name><surname>Tarnogorska</surname><given-names>Dorota</given-names></name><name><surname>Tenshaw</surname><given-names>Emily</given-names></name><name><surname>Tokhi</surname><given-names>Temour</given-names></name><name><surname>Walsh</surname><given-names>John J</given-names></name><name><surname>Yang</surname><given-names>Tansy</given-names></name><name><surname>Horne</surname><given-names>Jane Anne</given-names></name><name><surname>Parekh</surname><given-names>Ruchi</given-names></name><name><surname>Rivlin</surname><given-names>Patricia K</given-names></name><name><surname>Jayaraman</surname><given-names>Vivek</given-names></name><name><surname>Ito</surname><given-names>Kei</given-names></name><name><surname>Saalfeld</surname><given-names>Stephan</given-names></name><name><surname>George</surname><given-names>Reed</given-names></name><name><surname>Meinertzhagen</surname><given-names>Ian A</given-names></name><name><surname>Rubin</surname><given-names>Gerald M</given-names></name><name><surname>Hess</surname><given-names>Harald F</given-names></name><name><surname>Plaza</surname><given-names>Stephen M</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006785</institution-id><institution>Google</institution></institution-wrap></funding-source><award-id>Internal funding</award-id><principal-award-recipient><name><surname>Januszewski</surname><given-names>Michal</given-names></name><name><surname>Maitlin-Shepard</surname><given-names>Jeremy</given-names></name><name><surname>Blakely</surname><given-names>Tim</given-names></name><name><surname>Leavitt</surname><given-names>Laramie</given-names></name><name><surname>Li</surname><given-names>Peter H</given-names></name><name><surname>Lindsey</surname><given-names>Larry</given-names></name><name><surname>Jain</surname><given-names>Viren</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome</institution></institution-wrap></funding-source><award-id>203261/Z/16/Z</award-id><principal-award-recipient><name><surname>Schlegel</surname><given-names>Philipp</given-names></name><name><surname>Li</surname><given-names>Feng</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>New reconstruction methods are used to create a publicly available dense reconstruction of the neurons and chemical synapses of central brain of <italic>Drosophila</italic>, with analysis of its graph properties.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The connectome we present is a dense reconstruction of a portion of the central brain (referred to here as the hemibrain) of the fruit fly, <italic>Drosophila melanogaster</italic>, as shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>. This region was chosen since it contains all the circuits of the central brain (assuming bilateral symmetry), and in particular contains circuits critical to unlocking mysteries involving associative learning in the mushroom body, navigation and sleep in the central complex, and circadian rhythms among clock circuits. The largest dense reconstruction to date, it contains around 25,000 neurons, most of which were rigorously clustered and named, with about 20 million chemical synapses between them, plus portions of many other neurons truncated by the boundary of the data set (details in <xref ref-type="fig" rid="fig1">Figure 1</xref>). Each neuron is documented at many levels - the detailed voxels that constitute it, a skeleton with segment diameters, its synaptic partners and the location of most of their synapses.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The hemibrain and some basic statistics.</title><p>The highlighted area shows the portion of the central brain that was imaged and reconstructed, superimposed on a grayscale representation of the entire <italic>Drosophila</italic> brain. For the table, a neuron is traced if all its main branches within the volume are reconstructed. A neuron is considered uncropped if most arbors (though perhaps not the soma) are contained in the volume. Others are considered cropped. Note: (1) our definition of cropped is somewhat subjective; (2) the usefulness of a cropped neuron depends on the application; and (3) some small fragments are known to be distinct neurons. For simplicity, we will often state that the hemibrain contains ≈25K neurons.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig1-v3.tif"/></fig><p>Producing this data set required advances in sample preparation, imaging, image alignment, machine segmentation of cells, synapse detection, data storage, proofreading software, and protocols to arbitrate each decision. A number of new tests for estimating the completeness and accuracy were required and therefore developed, in order to verify the correctness of the connectome.</p><p>These data describe whole-brain properties and circuits, as well as contain new methods to classify cell types based on connectivity. Computational compartments are now more carefully defined, we conclusively identify synaptic circuits, and each neuron is annotated by name and putative cell type, making this the first complete census of neuropils, tracts, cells, and connections in this portion of the brain. We compare the statistics and structure of different brain regions, and for the brain as a whole, without the confounds introduced by studying different circuitry in different animals.</p><p>All data are publicly available through web interfaces. This includes a browser interface, NeuPrint (<xref ref-type="bibr" rid="bib17">Clements et al., 2020</xref>), designed so that any interested user can query the hemibrain connectome even without specific training. NeuPrint can query the connectivity, partners, connection strengths and morphologies of all specified neurons, thus making identification of upstream and downstream partners both orders of magnitude easier, and significantly more confident, compared to existing genetic methods. In addition, for those who are willing to program, the full data set - the gray scale voxels, the segmentation and proofreading results, skeletons, and graph model of connectivity, are also available through publicly accessible application program interfaces (APIs).</p><p>This effort differs from previous EM reconstructions in its social and collaborative aspects. Previous reconstructions were either dense in much smaller EM volumes (such as <xref ref-type="bibr" rid="bib81">Meinertzhagen and O'Neil, 1991</xref>; <xref ref-type="bibr" rid="bib45">Helmstaedter et al., 2013</xref>; <xref ref-type="bibr" rid="bib114">Takemura et al., 2017</xref>) or sparse in larger volumes (such as <xref ref-type="bibr" rid="bib24">Eichler et al., 2017</xref> or <xref ref-type="bibr" rid="bib136">Zheng et al., 2018</xref>). All have concentrated on the reconstruction of specific circuits to answer specific questions. When the same EM volume is used for many such efforts, as has occurred in the <italic>Drosophila</italic> larva and the full adult fly brain, this leads to an overall reconstruction that is the union of many individual efforts (<xref ref-type="bibr" rid="bib101">Saalfeld et al., 2009</xref>). The result is inconsistent coverage of the brain, with some regions well reconstructed and others missing entirely. In contrast, here we have analyzed the entire volume, not just the subsets of interest to specific groups of researchers with the expertise to tackle EM reconstruction. We are making these data available without restriction, with only the requirement to cite the source. This allows the benefits of known circuits and connectivity to accrue to the field as a whole, a much larger audience than those with expertise in EM reconstruction. This is analogous to progress in genomics, which transitioned from individual groups studying subsets of genes, to publicly available genomes that can be queried for information about genes of choice (<xref ref-type="bibr" rid="bib2">Altschul et al., 1990</xref>).</p><p>One major benefit to this effort is to facilitate research into the circuits of the fly’s brain. A common question among researchers, for example, is the identity of upstream and downstream (respectively input and output) partners of specific neurons. Previously, this could only be addressed by genetic trans-synaptic labeling, such as trans-Tango (<xref ref-type="bibr" rid="bib115">Talay et al., 2017</xref>), or by sparse tracing in previously imaged EM volumes (<xref ref-type="bibr" rid="bib136">Zheng et al., 2018</xref>). However, the genetic methods may give false positives and negatives, and both alternatives require specialized expertise and are time consuming, often taking months of effort. Now, for any circuits contained in our volume, a researcher can obtain the same answers in seconds by querying a publicly available database.</p><p>Another major benefit of dense reconstruction is its exhaustive nature. Genetic methods such as stochastic labeling may miss certain cell types, and counts of cells of a given type are dependent on expression levels, which are always uncertain. Previous dense reconstructions have demonstrated that existing catalogs of cell types are incomplete, even in well-covered regions (<xref ref-type="bibr" rid="bib114">Takemura et al., 2017</xref>). In our hemibrain sample, we have identified all the cells within the reconstructed volume, thus providing a complete and unbiased census of all cell types in the fly’s central brain (at least in this single female), and a precise count of the cells of each type.</p><p>Another scientific benefit lies in an analysis without the uncertainty of pooling data obtained from different animals. The detailed circuitry of the fly’s brain is known to depend on nutritional history, age, and circadian rhythm. Here, these factors are held constant, as are the experimental methods, facilitating comparison between different fly brain regions in this single animal. Evaluating stereotypy across animals will of course eventually require additional connectomes.</p><p>Previous reconstructions of compartmentalized brains have concentrated on particular regions and circuits. The mammalian retina (<xref ref-type="bibr" rid="bib45">Helmstaedter et al., 2013</xref>) and cortex (<xref ref-type="bibr" rid="bib59">Kasthuri et al., 2015</xref>), and insect mushroom bodies (<xref ref-type="bibr" rid="bib24">Eichler et al., 2017</xref>; <xref ref-type="bibr" rid="bib114">Takemura et al., 2017</xref>) and optic lobes (<xref ref-type="bibr" rid="bib113">Takemura et al., 2015</xref>) have all been popular targets. Additional studies have examined circuits that cross regions, such as those for sensory integration (<xref ref-type="bibr" rid="bib85">Ohyama et al., 2015</xref>) or motion vision (<xref ref-type="bibr" rid="bib109">Shinomiya et al., 2019</xref>).</p><p>So far lacking are systematic studies of the statistical properties of computational compartments and their connections. Neural circuit motifs have been studied (<xref ref-type="bibr" rid="bib111">Song et al., 2005</xref>), but only those restricted to small motifs and at most a few cell types, usually in a single portion of the brain. Many of these results are in mammals, leading to questions of whether they also apply to invertebrates, and whether they extend to other regions of the brain. While there have been efforts to build reduced, but still accurate, electrical models of neurons (<xref ref-type="bibr" rid="bib74">Marasco et al., 2012</xref>), none of these to our knowledge have used the compartment structure of the brain.</p><sec id="s1-1"><title>What is included</title><p><xref ref-type="table" rid="table1">Table 1</xref> shows the hierarchy of the named brain regions that are included in the hemibrain. <xref ref-type="table" rid="table2">Table 2</xref> shows the primary regions that are at least 50% included in the hemibrain sample, their approximate size, and their completion percentage. Our names for brain regions follow the conventions of <xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref> with the addition of ‘(L)’ or ‘(R)’ to indicate whether the region (most of which occur on both sides of the fly) has its cell bodies in the left or right, respectively. The mushroom body (<xref ref-type="bibr" rid="bib116">Tanaka et al., 2008</xref>; <xref ref-type="bibr" rid="bib4">Aso et al., 2014</xref>) and central complex (<xref ref-type="bibr" rid="bib122">Wolff et al., 2015</xref>; <xref ref-type="bibr" rid="bib123">Wolff and Rubin, 2018</xref>) are further divided into finer compartments.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Brain regions contained and defined in the hemibrain, following the naming conventions of <xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref> with the addition of (R) and (L) to specify the side of the soma for that region.</title><p><italic>Italics</italic> indicate master regions not explicitly defined in the hemibrain. Region LA is not included in the volume. The regions are hierarchical, with the more indented regions forming subsets of the less indented. The only exceptions are dACA, lACA, and vACA which are considered part of the mushroom body but are not contained in the master region MB.</p></caption><table frame="hsides" rules="groups"><tbody><tr><td>OL(R)</td><td>Optic lobe</td><td>CX</td><td>Central complex</td><td>LH(R)</td><td>Lateral horn</td></tr><tr><td> <italic>LA</italic></td><td>lamina</td><td> FB</td><td>Fan-shaped body</td><td/><td/></tr><tr><td> ME(R)</td><td>Medula</td><td>  FBl1</td><td>Fan-shaped body layer 1</td><td><italic>SNP(R)/(L)</italic></td><td>Superior neuropils</td></tr><tr><td> AME(R)</td><td>Accessory medulla</td><td>  FBl2</td><td>Fan-shaped body layer 2</td><td> SLP(R)</td><td>Superior lateral protocerebrum</td></tr><tr><td> LO(R)</td><td>Lobula</td><td>  FBl3</td><td>Fan-shaped body layer 4</td><td> SIP(R)/(L)</td><td>Superior intermediate protocerebrum</td></tr><tr><td> LOP(R)</td><td>Lobula plate</td><td>  FBl4</td><td>Fan-shaped body layer 4</td><td> SMP(R)(L)</td><td>Superior medial protocerebrum</td></tr><tr><td/><td/><td>  FBl5</td><td>Fan-shaped body layer 5</td><td/><td/></tr><tr><td>MB(R)/(L)</td><td>Mushroom body</td><td>  FBl6</td><td>Fan-shaped body layer 6</td><td><italic>INP</italic></td><td>Inferior neuropils</td></tr><tr><td> CA(R)/(L)</td><td>Calyx</td><td>  FBl7</td><td>Fan-shaped body layer 7</td><td> CRE(R)/(L)</td><td>Crepine</td></tr><tr><td> dACA(R)</td><td>Dorsal accessory calyx</td><td>  FBl8</td><td>Fan-shaped body layer 8</td><td>  RUB(R)/(L)</td><td>Rubu </td></tr><tr><td> lACA(R)</td><td>Lateral accessory calyx</td><td>  FBl9</td><td>Fan-shaped body layer 9</td><td>  ROB(R)</td><td>Round body</td></tr><tr><td> vACA(R)</td><td>Ventral accessory calyx</td><td> EB</td><td>Ellipsoid body</td><td> SCL(R)/(L)</td><td>Superior clamp</td></tr><tr><td> PED(R)</td><td>Pedunculus</td><td>  EBr1</td><td>Ellipsoid body zone r1</td><td> ICL(R)/(L)</td><td>Inferior clamp</td></tr><tr><td> a’L(R)/(L)</td><td>Alpha prime lobe</td><td>  EBr2r4</td><td>Ellipsoid body zone r2r4</td><td> IB</td><td>Inferior bridge</td></tr><tr><td>  a’1(R)</td><td>Alpha prime lobe compartment 1</td><td>  EBr3am</td><td>Ellipsoid body zone r3am</td><td> ATL(R)/(L)</td><td>Antler</td></tr><tr><td>  a’2(R)</td><td>Alpha prime lobe compartment 2</td><td>  EBr3d</td><td>Ellipsoid body zone r3d</td><td/><td/></tr><tr><td>  a’3(R)</td><td>Alpha prime lobe compartment 3</td><td>  EBr3pw</td><td>Ellipsoid body zone r3pw</td><td>AL(R)/(L)</td><td>Antennal lobe</td></tr><tr><td> aL(R)/(L)</td><td>Alpha lobe</td><td>  EBr5</td><td>Ellipsoid body zone r5</td><td/><td/></tr><tr><td>  a1(R)</td><td>Alpha lobe compartment 1</td><td>  EBr6</td><td>Ellipsoid body zone r6</td><td><italic>VMNP</italic></td><td>Ventromedial neuropils</td></tr><tr><td>  a2(R)</td><td>Alpha lobe compartment 2</td><td> AB(R)/(L)</td><td>Asymmetrical body</td><td> VES(R)/(L)</td><td>Vest</td></tr><tr><td>  a3(R)</td><td>Alpha lobe compartment 3</td><td> PB</td><td>Protocerebral bridge</td><td> EPA(R)/(L)</td><td>Epaulette</td></tr><tr><td> gL(R)/(L)</td><td>Gamma lobe</td><td>  PB(R1)</td><td>PB glomerulus R1</td><td> GOR(R)/(L)</td><td>Gorget</td></tr><tr><td>  g1(R)</td><td>Gamma lobe compartment 1</td><td>  PB(R2)</td><td>PB glomerulus R2</td><td> SPS(R)/(L)</td><td>Superior posterior slope</td></tr><tr><td>  g2(R)</td><td>Gamma lobe compartment 2</td><td>  PB(R3)</td><td>PB glomerulus R3</td><td> IPS(R)/(L)</td><td>Inferior posterior slope</td></tr><tr><td>  g3(R)</td><td>Gamma lobe compartment 3</td><td>  PB(R4)</td><td>PB glomerulus R4</td><td/><td/></tr><tr><td>  g4(R)</td><td>Gamma lobe compartment 4</td><td>  PB(R5)</td><td>PB glomerulus R5</td><td><italic>PENP</italic></td><td>Pariesophageal neuropils</td></tr><tr><td>  g5(R)</td><td>Gamma lobe compartment 5</td><td>  PB(R6)</td><td>PB glomerulus R6</td><td> SAD</td><td>Saddle</td></tr><tr><td> b’L(R)/(L)</td><td>Beta prime lobe</td><td>  PB(R7)</td><td>PB glomerulus R7</td><td>  AMMC</td><td>Antennal mechanosensory and motor center</td></tr><tr><td>  b’1(R)</td><td>Beta prime lobe compartment 1</td><td>  PB(R8)</td><td>PB glomerulus R8</td><td> FLA(R)</td><td>Flange</td></tr><tr><td>  b’2(R)</td><td>Beta prime lobe compartment 2</td><td>  PB(R9)</td><td>PB glomerulus R9</td><td> CAN(R)</td><td>Cantle</td></tr><tr><td> bL(R)/(L)</td><td>Beta lobe</td><td>  PB(L1)</td><td>PB glomerulus L1</td><td> PRW</td><td>prow</td></tr><tr><td>  b1(R)</td><td>Beta lobe compartment 1</td><td>  PB(L2)</td><td>PB glomerulus L2</td><td/><td/></tr><tr><td>  b2(R)</td><td>Beta lobe compartment 2</td><td>  PB(L3)</td><td>PB glomerulus L3</td><td>GNG</td><td>Gnathal ganglia</td></tr><tr><td/><td/><td>  PB(L4)</td><td>PB glomerulus L4</td><td/><td/></tr><tr><td><italic>LX(R)/(L)</italic></td><td>Lateral complex</td><td>  PB(L5)</td><td>PB glomerulus L5</td><td colspan="2">Major Fiber bundles</td></tr><tr><td> BU(R)/(L)</td><td>Bulb</td><td>  PB(L6)</td><td>PB glomerulus L6</td><td> AOT(R)</td><td>Anterior optic tract</td></tr><tr><td> LAL(R)/(L)</td><td>Lateral accessory lobe</td><td>  PB(L7)</td><td>PB glomerulus L7</td><td> GC</td><td>Great commissure</td></tr><tr><td>  GA(R)</td><td>Gall</td><td>  PB(L8)</td><td>PB glomerulus L8</td><td> GF(R)</td><td>Giant Fiber (single neuron)</td></tr><tr><td/><td/><td>  PB(L9)</td><td>PB glomerulus L9</td><td> mALT(R)/(L)</td><td>Medial antennal lobe tract</td></tr><tr><td><italic>VLNP(R)</italic></td><td>Ventrolateral neuropils</td><td> NO</td><td>Noduli</td><td> POC</td><td>Posterior optic commissure</td></tr><tr><td> AOTU(R)</td><td>Anterior optic tubercle</td><td>  NO1(R)/(L)</td><td>Nodulus 1</td><td/><td/></tr><tr><td> AVLP(R)</td><td>Anterior ventrolateral protocerebrum</td><td>  NO2(R)/(L)</td><td>Nodulus 2</td><td/><td/></tr><tr><td> PVLP(R)</td><td>Posterior ventrolateral protocerebrum</td><td>  NO3(R)/(L)</td><td>Nodulus 3</td><td/><td/></tr><tr><td> PLP(R)</td><td>Posterior lateral cerebrum</td><td/><td/><td/><td/></tr><tr><td> WED(R)</td><td>Wedge</td><td/><td/><td/><td/></tr></tbody></table></table-wrap><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Regions with ≥50% included in the hemibrain, sorted by completion percentage.</title><p>The approximate percentage of the region included in the hemibrain volume is shown as ‘%inV’. ‘T-bars’ gives a rough estimate of the size of the region. ‘comp%’ is the fraction of the post-synaptic densities (PSDs) contained in the brain region for which both the PSD and the corresponding T-bar are in neurons marked ‘Traced’.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Name</th><th>%inV</th><th>T-bars</th><th>comp%</th><th>Name</th><th>%inV</th><th>T-bars</th><th>comp%</th></tr></thead><tbody><tr><td>PED(R)</td><td>100%</td><td>54805</td><td>85%</td><td>aL(R)</td><td>100%</td><td>95375</td><td>84%</td></tr><tr><td>b’L(R)</td><td>100%</td><td>67695</td><td>83%</td><td>bL(R)</td><td>100%</td><td>71112</td><td>83%</td></tr><tr><td>gL(R)</td><td>100%</td><td>176785</td><td>83%</td><td>a’L(R)</td><td>100%</td><td>39091</td><td>82%</td></tr><tr><td>EB</td><td>100%</td><td>164286</td><td>81%</td><td>bL(L)</td><td>56%</td><td>58799</td><td>81%</td></tr><tr><td>NO</td><td>100%</td><td>36722</td><td>79%</td><td>b’L(L)</td><td>88%</td><td>57802</td><td>78%</td></tr><tr><td>gL(L)</td><td>55%</td><td>133256</td><td>76%</td><td>CA(R)</td><td>100%</td><td>69517</td><td>73%</td></tr><tr><td>AB(R)</td><td>100%</td><td>2734</td><td>65%</td><td>aL(L)</td><td>51%</td><td>44803</td><td>62%</td></tr><tr><td>FB</td><td>100%</td><td>451031</td><td>62%</td><td>AL(R)</td><td>83%</td><td>501004</td><td>59%</td></tr><tr><td>AB(L)</td><td>100%</td><td>572</td><td>57%</td><td>PB</td><td>100%</td><td>46557</td><td>55%</td></tr><tr><td>AME(R)</td><td>100%</td><td>6045</td><td>51%</td><td>BU(R)</td><td>100%</td><td>9385</td><td>46%</td></tr><tr><td>CRE(R)</td><td>100%</td><td>137946</td><td>40%</td><td>AOTU(R)</td><td>100%</td><td>92578</td><td>38%</td></tr><tr><td>LAL(R)</td><td>100%</td><td>234388</td><td>38%</td><td>SMP(R)</td><td>100%</td><td>510937</td><td>34%</td></tr><tr><td>PVLP(R)</td><td>100%</td><td>475219</td><td>30%</td><td>ATL(R)</td><td>100%</td><td>25472</td><td>29%</td></tr><tr><td>SPS(R)</td><td>100%</td><td>253818</td><td>29%</td><td>ATL(L)</td><td>100%</td><td>28153</td><td>29%</td></tr><tr><td>VES(R)</td><td>84%</td><td>157168</td><td>29%</td><td>IB</td><td>100%</td><td>200447</td><td>28%</td></tr><tr><td>CRE(L)</td><td>90%</td><td>132656</td><td>28%</td><td>SIP(R)</td><td>100%</td><td>187493</td><td>26%</td></tr><tr><td>BU(L)</td><td>52%</td><td>7014</td><td>26%</td><td>GOR(R)</td><td>100%</td><td>27140</td><td>26%</td></tr><tr><td>WED(R)</td><td>100%</td><td>232898</td><td>25%</td><td>SMP(L)</td><td>100%</td><td>460784</td><td>26%</td></tr><tr><td>EPA(R)</td><td>100%</td><td>31438</td><td>26%</td><td>PLP(R)</td><td>100%</td><td>429949</td><td>26%</td></tr><tr><td>AVLP(R)</td><td>100%</td><td>630538</td><td>23%</td><td>ICL(R)</td><td>100%</td><td>202549</td><td>23%</td></tr><tr><td>SLP(R)</td><td>100%</td><td>487795</td><td>23%</td><td>LO(R)</td><td>64%</td><td>855251</td><td>22%</td></tr><tr><td>SCL(R)</td><td>100%</td><td>189569</td><td>22%</td><td>GOR(L)</td><td>60%</td><td>19558</td><td>21%</td></tr><tr><td>LH(R)</td><td>100%</td><td>231662</td><td>19%</td><td>CAN(R)</td><td>68%</td><td>6512</td><td>16%</td></tr></tbody></table></table-wrap><p><xref ref-type="table" rid="app1table6">Appendix 1—table 6</xref> provide the list of identified neuron types and their naming schemes. These include newly identified sensory inputs and motor outputs.</p><p>The nature of the proofreading process allows us to improve the data even after their initial publication. Our initial data release was version v1.0 (<xref ref-type="bibr" rid="bib128">Xu et al., 2020b</xref>). Version v1.1 is now available, including improvements such as better accuracy, more consistent cell naming and typing, and inclusion of anatomical names for central complex neurons. The old version(s) remain online and available, to allow reproducibility of older analyses, but we strongly recommend all new analyses use the latest version. The analyses in this article, and in the corresponding articles on the mushroom body and central complex, are based on version v1.1, unless otherwise noted.</p></sec><sec id="s1-2"><title>What is not included</title><p>This research focused on the neurons of the brain and the chemical synapses between them. Every step in our process, from staining and sample preparation through segmentation and proofreading, has been optimized with this goal in mind. While neurons and their chemical synapses are critical to brain operation, they are far from the full story. Other contributors, known to be important, could not be included in our study, largely for technical reasons. Among these are gap junctions, glia, and structures internal to the cell such as mitochondria. Gap junctions, or electrical connections between neurons, are difficult to reliably detect by FIB-SEM under the best of circumstances and not detectable at the low (for EM) resolution needed to complete this study in a reasonable amount of time. Their contribution to the connectome will need to be established through other means - see the section on future research. Glial cells were difficult to segment, due to both staining differences and convoluted morphologies. We identified the volumes where they exist (a glia ’mask’, which allows these regions to be color-coded when viewed in NeuroGlancer) but did not separate them into cells. Structures internal to the neurons, except for synapses, are not considered here even though many are visible in our EM preparation. The most obvious example is mitochondria. Again, we have identified many of them so we could evaluate their effect on segmentation, but they are not included in our connectome. Finally, autapses (synapses from a neuron onto itself) are known to exist in <italic>Drosophila</italic>, but are sufficiently rare that they fall well below the rate of false positives in our automated synapse detection. Therefore most of the putative autapses are false positives, and we do not include them in our connectivity data.</p></sec><sec id="s1-3"><title>Differences from connectomes of vertebrates</title><p>Most accounts of neurobiology define the operation of the mammalian nervous system with, at most, only passing reference to invertebrate brains. Fly (or other insect) nervous systems differ from those of vertebrates in several aspects (<xref ref-type="bibr" rid="bib80">Meinertzhagen, 2016b</xref>). Some main differences include:</p><list list-type="bullet"><list-item><p>Most synapses are polyadic. Each synapse structure comprises a single presynaptic release site and, adjacent to this, several neurites expressing neurotransmitter receptors. An element, T-shaped and typically called a T-bar in flies, marks the site of transmitter release into the cleft between cells. This site typically abuts the neurites of several other cells, where a postsynaptic density (PSD) marks the receptor location.</p></list-item><list-item><p>Most neurites are neither purely axonic nor dendritic, but have both pre- and postsynaptic partners, a feature that may be more prominent in mammalian brains than recognized (<xref ref-type="bibr" rid="bib83">Morgan and Lichtman, 2020</xref>). Within a single brain region, however, neurites are frequently predominantly dendritic (postsynaptic) or axonic (presynaptic).</p></list-item><list-item><p>Unlike some synapses in mammals, EM imagery (at least as we have acquired and analyzed it here) fails to reveal obvious information about whether a synapse is excitatory or inhibitory.</p></list-item><list-item><p>The soma or cell body of each fly neuron resides in a rind (the cell body layer) on the periphery of the brain, mostly disjoint from the main neurites innervating the internal neuropil. As a result, unlike vertebrate neurons, no synapses form directly on the soma. The neuronal process between the soma and the first branch point is called the cell body fiber (CBF), which is likewise not involved in the synaptic transmission of information.</p></list-item><list-item><p>Synapse sizes are much more uniform than those of mammals. Stronger connections are formed by increasing the number of synapses in parallel, not by forming larger synapses, as in vertebrates. In this paper, we will refer to the ‘strength’ of a connection as the synapse count, even though we acknowledge that we lack information on the relative activity and strength of the synapses, and thus a true measure of their coupling strength.</p></list-item><list-item><p>The brain is small, about 250 μm per side, and has roughly the same size as the dendritic arbor of a single pyramidal neuron in the mammalian cortex.</p></list-item><list-item><p>Axons of fly neurons are not myelinated.</p></list-item><list-item><p>Some fly neurons rely on graded transmission (as opposed to spiking), without obvious anatomical distinction. Some neurons even switch between graded and spiking operation (<xref ref-type="bibr" rid="bib95">Pimentel et al., 2016</xref>).</p></list-item></list></sec><sec id="s1-4"><title>Connectome reconstruction</title><p>Producing a connectome comprising reconstructed neurons and the chemical synapses between them required several steps. The first step, preparing a fly brain and imaging half of its center, produced a dataset consisting of 26 teravoxels of data, each with 8 bits of grayscale information. We applied numerous machine-learning algorithms and over 50 person-years of proofreading effort over ≈2 calendar years to extract a variety of more compact and useful representations, such as neuron skeletons, synapse locations, and connectivity graphs. These are both more useful and much smaller than the raw grayscale data. For example, the connectivity could be reasonably summarized by a graph with ≈25,000 nodes and ≈3 million edges. Even when the connections were assigned to different brain regions, such a graph took only 26 MB, still large but roughly a million fold reduction in data size.</p><p>Many of the supporting methods for this reconstruction have been recently published. Here, we briefly survey each major area, with more details reported in the companion papers. Major advances include:</p><list list-type="bullet"><list-item><p>New methods to fix and stain the sample, preparing a whole fly brain with well-preserved subcellular detail particularly suitable for machine analysis.</p></list-item><list-item><p>Methods that have enabled us to collect the largest EM dataset yet using Focused Ion Beam Scanning Electron Microscopy (FIB-SEM), resulting in isotropic data with few artifacts, features that significantly sped up reconstruction.</p></list-item><list-item><p>A coarse-to-fine, automated flood-filling network segmentation pipeline applied to image data normalized with cycle-consistent generative adversarial networks, and an aggressive automated agglomeration regime enabled by advances in proofreading.</p></list-item><list-item><p>A new hybrid synapse prediction method, using two differing underlying techniques, for accurate synapse prediction throughout the volume.</p></list-item><list-item><p>New top-down proofreading methods that utilize visualization and machine learning to achieve orders of magnitude faster reconstruction compared with previous approaches in the fly’s brain.</p></list-item></list><p>Each of these is explained in more detail in the following sections and, where necessary, in the appendix. The companion papers are ‘The connectome of the <italic>Drosophila melanogaster</italic> mushroom body: implications for function’ (<xref ref-type="bibr" rid="bib67">Li et al., 2020</xref>) and ‘A complete synaptic-resolution connectome of the <italic>Drosophila melanogaster</italic> central complex’ by Jayaraman, et al.</p></sec><sec id="s1-5"><title>Image stack collection</title><p>The first steps, fixing and staining the specimen, have been accomplished taking advantage of three new developments. These improved methods allow us to fix and stain a full fly’s brain but nevertheless recover neurons as round profiles with darkly stained synapses, suitable for machine segmentation and automatic synapse detection. We started with a 5-day-old female of wild-type Canton S strain G1 x w<sup>1118</sup>, raised on a 12 hr day/night cycle. 1.5 hr after lights-on, we used a custom-made jig to microdissect the brain, which was then fixed and embedded in Epon, an epoxy resin. We then enhanced the electron contrast by staining with heavy metals, and progressively lowered the temperature during dehydration of the sample. Collectively, these methods optimize morphological preservation, allow full-brain preparation without distortion (unlike fast freezing methods), and provide increased staining intensity that speeds the rate of FIB-SEM imaging (<xref ref-type="bibr" rid="bib71">Lu et al., 2019</xref>).</p><p>The hemibrain sample is roughly 250 × 250 × 250 μm, larger than we can FIB-SEM without introducing milling artifacts. Therefore, we subdivided our epoxy-embedded samples into 20-μm-thick slabs, both to avoid artifacts and allow imaging in parallel (each slab can be imaged in a different FIB machine) for increased throughput. To be effective, the cut surfaces of the slabs must be smooth at the ultrastructural level and have only minimal material loss. Specifically, for connectomic research, all long-distance processes must remain traceable across sequential slabs. We used an improved version of our previously published ‘hot-knife’ ultrathick sectioning procedure (<xref ref-type="bibr" rid="bib41">Hayworth et al., 2015</xref>) which uses a heated, oil-lubricated diamond knife, to section the <italic>Drosophila</italic> brain into 37 sagittal slabs of 20 μm thickness with an estimated material loss between consecutive slabs of only ∼30 nm – sufficiently small to allow tracing of long-distance neurites. Each slab was re-embedded, mounted, and trimmed, then examined in 3D with X-ray tomography to check for sample quality and establish a scale factor for Z-axis cutting by FIB. The resulting slabs were FIB-SEM imaged separately (often in parallel, in different FIB-SEM machines), and the resulting volume datasets were stitched together computationally.</p><p>Connectome studies come with clearly defined resolution requirements – the finest neurites must be traceable by humans and should be reliably segmented by automated algorithms (<xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>). In <italic>Drosophila</italic>, the very finest neural processes are usually 50 nm but can be as little as 15 nm (<xref ref-type="bibr" rid="bib79">Meinertzhagen, 2016a</xref>). This fundamental biological dimension determines the minimum isotropic resolution requirements for tracing neural circuits. To meet the demand for high isotropic resolution and large volume imaging, we chose the FIB-SEM imaging platform, which offers high isotropic resolution (&lt;10 nm in x, y, and z), minimal artifacts, and robust image alignment. The high-resolution and isotropic dataset possible with FIB-SEM has substantially expedited the <italic>Drosophila</italic> connectome pipeline. Compared to serial-section imaging, with its sectioning artifacts and inferior Z-axis resolution, FIB-SEM offers high-quality image alignment, a smaller number of artifacts, and isotropic resolution. This allows higher quality automated segmentation and makes manual proofreading and correction easier and faster.</p><p>At the beginning, deficiencies in imaging speed and system reliability of any commercial FIB-SEM system capped the maximum possible image volume to less than 0.01% of a full fly brain, problems that persist even now. To remedy them, we redesigned the entire control system, improved the imaging speed more than 10x, and created innovative solutions addressing all known failure modes, which thereby expanded the practical imaging volume of conventional FIB-SEM by more than four orders of magnitude from <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mi>m</mml:mi><mml:msup><mml:mrow/><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>3</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:msup><mml:mtext> </mml:mtext><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, while maintaining an isotropic resolution of 8 × 8 × 8 nm voxels (<xref ref-type="bibr" rid="bib125">Xu et al., 2017</xref>; <xref ref-type="bibr" rid="bib126">Xu et al., 2019</xref>). In order to overcome the aberration of a large field of view (up to 300 μm wide), we developed a novel tiling approach without sample stage movement, in which the imaging parameters of each tile are individually optimized through an in-line auto focus routine without overhead (<xref ref-type="bibr" rid="bib127">Xu et al., 2020a</xref>). After numerous improvements, we have transformed the conventional FIB-SEM from a laboratory tool that is unreliable for more than a few days of imaging to a robust volume EM platform with effective long-term reliability, able to perform years of continuous imaging without defects in the final image stack. Imaging time, rather than FIB-SEM reliability, is now the main impediment to obtaining even larger volumes.</p><p>In our study here, the <italic>Drosophila</italic> 'hemibrain', 13 consecutive hot-knifed slabs were imaged using two customized enhanced FIB-SEM systems, in which an FEI Magnum FIB column was mounted at 90° upon a Zeiss Merlin SEM. After data collection, streaking artifacts generated by secondary electrons along the FIB milling direction were computationally removed using a mask in the frequency domain. The image stacks were then aligned using a customized version of the software platform developed for serial section transmission electron microscopy (<xref ref-type="bibr" rid="bib136">Zheng et al., 2018</xref>; <xref ref-type="bibr" rid="bib61">Khairy et al., 2018</xref>), followed by binning along the z-axis to form the final 8 × 8 × 8 nm<sup>3</sup> voxel datasets. Milling thickness variations in the aligned series were compensated using a modified version of the method described by <xref ref-type="bibr" rid="bib37">Hanslovsky et al., 2017</xref>, with the absolute scale calibrated by reference to the MicroCT images.</p><p>The 20 μm slabs generated by the hot-knife sectioning were re-embedded in larger plastic tabs prior to FIB-SEM imaging. To correct for the warping of the slab that can occur in this process, methods adapted from Kainmueller (<xref ref-type="bibr" rid="bib56">Kainmueller et al., 2008</xref>) were used to find the tissue-plastic interface and flatten each slab’s image stack.</p><p>The series of flattened slabs was then stitched using a custom method for large-scale deformable registration to account for deformations introduced during sectioning, imaging, embedding, and alignment (Saalfeld et al. in prep). These volumes were then contrast adjusted using slice-wise contrast limited adaptive histogram equalization (CLAHE) (<xref ref-type="bibr" rid="bib96">Pizer et al., 1987</xref>), and converted into a versioned database (Distributed, Versioned, Image-oriented Database, or DVID) (<xref ref-type="bibr" rid="bib60">Katz and Plaza, 2019</xref>), which formed the raw data for the reconstruction, as illustrated in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The 13 slabs of the hemibrain, each flattened and co-aligned.</title><p>A vertical section at the level of the fan-shaped body is shown. Colors are arbitrary and added to the monochrome data to show brain regions, as defined below. Scale bar 50 μm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig2-v3.tif"/></fig></sec><sec id="s1-6"><title>Automated segmentation</title><p>Computational reconstruction of the image data was performed using flood-filling networks (FFNs) trained on roughly five billion voxels of volumetric ground truth contained in two tabs of the hemibrain dataset (<xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>). Initially, the FFNs generalized poorly to other tabs of the hemibrain, whose image content had different appearances. Therefore, we adjusted the image content to be more uniform using cycle-consistent generative adversarial networks (CycleGANs) (<xref ref-type="bibr" rid="bib138">Zhu et al., 2017</xref>). Specifically, ‘generator’ networks were trained to alter image content such that a second ‘discriminator’ network was unable to distinguish between image patches sampled from, for example, a tab that contained volumetric training data versus a tab that did not. A cycle-consistency constraint was used to ensure that the image transformations preserved ultrastructural detail. The improvement is illustrated in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Overall, this allowed us to use the training data from just two slabs, as opposed to needing training data for each slab.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Examples of results of CycleGAN processing.</title><p>(<bold>a</bold>) Original EM data from tab 34 at a resolution of 16 nm / resolution, (<bold>b</bold>) EM data after CycleGAN processing, (<bold>c–d</bold>) FFN segmentation results with the 16 nm model applied to original and processed data, respectively. Scale bar in (<bold>a</bold>) represents 1 μm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig3-v3.tif"/></fig><p>FFNs were applied to the CycleGAN-normalized data in a coarse-to-fine manner at 32 × 32 × 32 nm<sup>3</sup> and 16 × 16 × 16 nm<sup>3</sup>, and to the CLAHE-normalized data at the native 8 × 8 × 8 nm<sup>3</sup> resolution, in order to generate a base segmentation that was largely over-segmented. We then agglomerated the base segmentation, also using FFNs. We aggressively agglomerated segments despite introducing a substantial number of erroneous mergers. This differs from previous algorithms, which studiously avoided merge errors since they were so difficult to fix. Here, advances in proofreading methodology described later in this report enabled efficient detection and correction of such mergers.</p><p>We evaluated the accuracy of the FFN segmentation of the hemibrain using metrics for expected run length (ERL) and false merge rate (<xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>). The base segmentation (i.e. the automated reconstruction prior to agglomeration) achieved an ERL of 163 μm with a false merge rate of 0.25%. After (automated) agglomeration, run length increased to 585 μm but with a false merge rate of 27.6% (i.e. nearly 30% of the path length was contained in segments with at least one merge error). We also evaluated a subset of neurons in the volume, ∼500 olfactory PNs and mushroom body KCs chosen to roughly match the evaluation performed in <xref ref-type="bibr" rid="bib66">Li et al., 2019</xref> which yielded an ERL of 825 μm at a 15.9% false merge rate.</p></sec><sec id="s1-7"><title>Synapse prediction</title><p>Accurate synapse identification is central to our analysis, given that synapses form both a critical component of a connectome and are required for prioritizing and guiding the proofreading effort. Synapses in <italic>Drosophila</italic> are typically polyadic, with a single presynaptic site (a T-bar) contacted by multiple receiving dendrites (most with PSDs) as shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. Initial synapse prediction revealed that there are over 9 million T-bars and 60 million PSDs in the hemibrain. Manually validating each one, assuming a rate of 1000 connections annotated per trained person, per day, would have taken more than 230 working years. Given this infeasibility, we developed machine learning approaches to predict synapses as detailed below. The results of our prediction are shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, where the predicted synapse sites clearly delineate many of the fly brain regions.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Well-preserved membranes, darkly stained synapses, and smooth round neurite profiles are characteristics of the hemibrain sample.</title><p>Panel (<bold>A</bold>) shows polyadic synapses, with a red arrow indicating the presynaptic T-bar, and white triangles pointing to the PSDs. We identified in total 64 million PSDs and 9.5 million T-bars in the hemibrain volume (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Thus the average number of PSDs per T-bar in our sample is 6.7. Mitochondria (‘M’), synaptic vesicles (‘SV’), and the scale bar (0.5 μm) are shown. Panel (<bold>B</bold>) shows a horizontal cross section through a point cloud of all detected synapses. This EM point cloud defines many of the compartments in the fly’s brain, much like an optical image obtained using antibody nc82 (an antibody against Bruchpilot, a component protein of T-bars) to stain synapses. This point cloud is used to generate the transformation from our sample to the standard <italic>Drosophila</italic> brain.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig4-v3.tif"/></fig><p>Given the size of the hemibrain image volume, a major challenge from a machine learning perspective is the range of varying image statistics across the volume. In particular, model performance can quickly degrade in regions of the data set with statistics that are not well-captured by the training set (<xref ref-type="bibr" rid="bib12">Buhmann et al., 2019</xref>).</p><p>To address this challenge, we took an iterative approach to synapse prediction, interleaving model re-training with manual proofreading, all based on previously reported methods (<xref ref-type="bibr" rid="bib47">Huang et al., 2018</xref>). Initial prediction, followed by proofreading, revealed a number of false positive predictions from structures such as dense core vesicles which were not well-represented in the original training set. A second filtering network was trained on regions causing such false positives, and used to prune back the original set of predictions. We denote this pruned output as the ‘initial’ set of synapse predictions.</p><p>Based on this initial set, we began collecting human-annotated dense ground-truth cubes throughout the various brain regions of the hemibrain, to assess variation in classifier performance by brain region. From these cubes, we determined that although many regions had acceptable precision, there were some regions in which recall was lower than desired. Consequently, a subset of cubes available at that time was used to train a new classifier focused on addressing recall in the problematic regions. This new classifier was used in an incremental (cascaded) fashion, primarily by adding additional predictions to the existing initial set. This gave better performance than complete replacement using only the new classifier, with the resulting predictions able to improve recall while largely maintaining precision.</p><p>As an independent check on synapse quality, we also trained a separate classifier (<xref ref-type="bibr" rid="bib12">Buhmann et al., 2019</xref>), using a modified version of the ‘synful’ software package. Both synapse predictors give a confidence value associated with each synapse, a measure of how firmly the classifier believes the prediction to be a true synapse. We found that we were able to improve recall by taking the union of the two predictor’s most confident synapses, and similarly improve precision by removing synapses that were low confidence in both predictions. <xref ref-type="fig" rid="fig5">Figure 5A and B</xref> show the results, illustrating the precision and recall obtained in each brain region.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Precision and recall for synapse prediction, panel (<bold>A</bold>) for T-bars, and panel (<bold>B</bold>) for synapses as a whole including the identification of PSDs.</title><p>T-bar identification is better than PSD identification since this organelle is both more distinct and typically occurs in larger neurites. Each dot is one brain region. The size of the dot is proportional to the volume of the region. Humans proofreaders typically achieve 0.9 precision/recall on T-bars and 0.8 precision/recall on PSDs, indicated in purple. Data available in <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source datas 1</xref>–<xref ref-type="supplementary-material" rid="fig5sdata2">2</xref>.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig5">Figure 5A</xref>.</title><p>Column A: precision; column B: recall; column C: region size.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-fig5-data1-v3.csv"/></supplementary-material></p><p><supplementary-material id="fig5sdata2"><label>Figure 5—source data 2.</label><caption><title>Data for <xref ref-type="fig" rid="fig5">Figure 5B</xref>.</title><p>Column A: precision; column B: recall; column C: region size.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-fig5-data2-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig5-v3.tif"/></fig></sec><sec id="s1-8"><title>Proofreading</title><p>Since machine segmentation is not perfect, we made a concerted effort to fix the errors remaining at this stage by several passes of human proofreading. Segmentation errors can be roughly grouped into two classes - ‘false merges’, in which two separate neurons are mistakenly merged together, and ‘false splits’, in which a single neuron is mistakenly broken into several segments. Enabled by advances in visualization and semi-automated proofreading using our Neu3 tool (<xref ref-type="bibr" rid="bib48">Hubbard et al., 2020</xref>), we first addressed large false mergers. A human examined each putative neuron and determined if it had an unusual morphology suggesting that a merge might have occurred, a task still much easier for humans than machines. If judged to be a false merger, the operator identified discrete points that should be on separate neurons. The shape was then resegmented in real time allowing users to explore other potential corrections. Neurons with more complex problems were then scheduled to be re-checked, and the process repeated until few false mergers remained.</p><p>In the next phase, the largest remaining pieces were merged into neuron shapes using a combination of machine-suggested edits (<xref ref-type="bibr" rid="bib97">Plaza, 2014</xref>) and manual intuition, until the main shape of each neuron emerged. This requires relatively few proofreading decisions and has the advantage of producing an almost complete neuron catalog early in the process. As discussed below, in the section on validation, emerging shapes were compared against genetic/optical image libraries (where available) and against other neurons of the same putative type, to guard against large missing or superfluous branches. These procedures (which focused on higher-level proofreading) produced a reasonably accurate library of the main branches of each neuron, and a connectome of the stronger neuronal pathways. At this point, there was still considerable variations among the brain regions, with greater completeness achieved in regions where the initial segmentation performed better.</p><p>Finally, to achieve the highest reconstruction completeness possible in the time allotted, and to enable confidence in weaker neuronal pathways, proofreaders connected remaining isolated fragments (segments) to already constructed neurons, using NeuTu (<xref ref-type="bibr" rid="bib134">Zhao et al., 2018</xref>) and Neu3 (<xref ref-type="bibr" rid="bib48">Hubbard et al., 2020</xref>). The fragments that would result in largest connectivity changes were considered first, exploiting automatic guesses through focused proofreading where possible. Since proofreading every small segment is still prohibitive, we tried to ensure a basic level of completeness throughout the brain with special focus in regions of particular biological interest such as the central complex and mushroom body.</p></sec><sec id="s1-9"><title>Defining brain regions</title><p>In a parallel effort to proofreading, the sample was annotated with discrete brain regions. Our progression in mapping the cells and circuits of the fly’s brain bears formal parallels to the history of mapping the earth, with many territories that are named and with known circuits, and others that still lack all or most of these. For the hemibrain dataset, the regions are based on the brain atlas in <xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>. The dataset covers most of the right hemisphere of the brain, except the optic lobe (OL), periesophageal neuropils (PENP) and gnathal ganglia (GNG), as well as part of the left hemisphere (<xref ref-type="table" rid="table2">Table 2</xref>). It covers about 36% of all synaptic neuropils by volume, and 54% of the central brain neuropils. We examined innervation patterns, synapse distribution, and connectivity of reconstructed neurons to define the neuropils as well as their boundaries on the dataset. We also made necessary, but relatively minor, revisions to some boundaries by considering anatomical features that had not been known during the creation of previous brain maps, while following the existing structural definitions (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>). We also used information from synapse point clouds, a predicted glial mask, and a predicted fiber bundle mask to determine boundaries of the neuropils (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). The brain regions of the fruit fly (<xref ref-type="fig" rid="fig6">Figure 6</xref>, B and C) include synaptic neuropils and non-synaptic fiber bundles. The non-synaptic cell body layer on the brain surface, which contains cell bodies of the neurons and some glia, surrounds these structures. The synaptic neuropils can be further categorized into two groups: delineated and diffuse neuropils. The delineated neuropils have distinct boundaries throughout their surfaces, often accompanied by glial processes, and have clear internal structures in many cases. They include the antennal lobe (AL), bulb (BU), as well as the neuropils in the optic lobe (OL), mushroom body (MB), and central complex (CX). Remaining are the diffuse neuropils, sometimes referred to as <italic>terra incognita</italic>, since most have been less investigated than the delineated neuropils.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Division of the sample into brain regions.</title><p>(<bold>A</bold>) A vertical section of the hemibrain dataset with synapse point clouds (white), predicted glial tissue (green), and predicted fiber bundles (magenta). (<bold>B</bold>) Grayscale image overlaid with segmented neuropils at the same level as (<bold>A</bold>). (<bold>C</bold>) A frontal view of the reconstructed neuropils. Scale bar: (<bold>A, B</bold>) 50 μm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig6-v3.tif"/></fig><sec id="s1-9-1"><title>Diffuse (<italic>terra incognita</italic>) neuropils</title><p>In the previous brain atlas of 2014, boundaries of some <italic>terra incognita</italic> neuropils were somewhat arbitrarily determined, due to a lack of precise information of the landmark neuronal structures used for the boundary definition. In the hemibrain data, we adjusted these boundaries to trace more faithfully the contours of the structures that are much better clarified by the EM-reconstructed data. Examples include the lateral horn (LH), ventrolateral neuropils (VLNP), and the boundary between the crepine (CRE) and lateral accessory lobe (LAL). The LH has been defined as the primary projection target of the olfactory projection neurons (PNs) from the antennal lobe (AL) via several antennal lobe tracts (ALTs) (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>; <xref ref-type="bibr" rid="bib93">Pereanu et al., 2010</xref>). The boundary between the LH and its surrounding neuropils is barely visible with synaptic immunolabeling such as nc82 or predicted synapse point clouds, as the synaptic contrast in these regions is minimal. The olfactory PNs can be grouped into several classes, and the projection sites of the uniglomerular PNs that project through the medial ALT (mALT), the thickest fiber bundle between the AL and LH, give the most conservative and concrete boundary of the ‘core’ LH (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). Multiglomerular PNs, on the other hand, project to much broader regions, including the volumes around the core LH (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). These regions include areas which are currently considered parts of the superior lateral protocerebrum (SLP) and posterior lateral protocerebrum (PLP). Since the ‘core’ LH roughly approximates the shape of the traditional LH, and the boundaries given by the multiglomerular PNs are rather diffused, in this study we assumed the core to be the LH itself. Of course, the multiglomerular PNs convey olfactory information as well, and therefore the neighboring parts of the SLP and PLP to some extent also receive inputs from the antennal lobe. These regions might be functionally distinct from the remaining parts of the SLP or PLP, but they are not explicitly separated from those neuropils in this study.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Reconstructed brain regions and substructures.</title><p>(<bold>A, B</bold>) Dorsal views of the olfactory projection neurons (PNs) and the innervated neuropils, AL, CA, and LH. Uniglomerular PNs projecting through the mALT are shown in (<bold>A</bold>), and multiglomerular PNs are shown in (<bold>B</bold>). (<bold>C, D</bold>) Columnar visual projection neurons. Each subtype of cells is color coded. LC cells are shown in (<bold>C</bold>), and LPC, LLPC, and LPLC cells are shown in (<bold>D</bold>). (<bold>E, F</bold>) The nine layers of the fan-shaped body (FB), along with the asymmetrical bodies (AB) and the noduli (NO), displayed as an anterior-ventral view (<bold>E</bold>), and a lateral view (<bold>F</bold>). In (<bold>E</bold>), three FB tangential cells (FB1D (blue), FB3A (green), FB8H (purple)) are shown as markers of the corresponding layers (FBl1, FBl3, and FBl8, respectively). (<bold>G</bold>) Zones in the ellipsoid body (EB) defined by the innervation patterns of different types of ring neurons. In this horizontal section of the EB, the left side shows the original grayscale data, and the seven ring neuron zones (see <xref ref-type="table" rid="table1">Table 1</xref>) are color-coded. The right side displays the seven segmented zones based on the innervation pattern, in a slightly different section. Scale bar: 20 μm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig7-v3.tif"/></fig><p>The VLNP is located in the lateral part of the central brain and receives extensive inputs from the optic lobe through various types of the visual projection neurons (VPNs). Among them, the projection sites of the lobula columnar (LC), lobula plate columnar (LPC), lobula-lobula plate columnar (LLPC), and lobula plate-lobula columnar (LPLC) cells form characteristic glomerular structures, called optic glomeruli (OG), in the AOTU, PVLP, and PLP (<xref ref-type="bibr" rid="bib62">Klapoetke et al., 2017</xref>; <xref ref-type="bibr" rid="bib89">Otsuna and Ito, 2006</xref>; <xref ref-type="bibr" rid="bib90">Panser et al., 2016</xref>; <xref ref-type="bibr" rid="bib124">Wu et al., 2016</xref>). We exhaustively identified columnar VPNs and found 41 types of LC, two types of LPC, six types of LLPC, and three types of LPLC cells (including sub-types of previously identified types). The glomeruli of these pathways were used to determine the medial boundary of the PVLP and PLP, following existing definitions (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>), except for a few LC types which do not form glomerular terminals. The terminals of the reconstructed LC cells and other lobula complex columnar cells (LPC, LLPC, LPLC) are shown in <xref ref-type="fig" rid="fig7">Figure 7C and D</xref>, respectively.</p><p>In the previous paper (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>), the boundary between the CRE and LAL was defined as the line roughly corresponding to the posterior-ventral surface of the MB lobes, since no other prominent anatomical landmarks were found around this region. In this dataset, we found several glomerular structures surrounding the boundary both in the CRE and LAL. These structures include the gall (GA), rubus (RUB), and round body (ROB). Most of them turned out to be projection targets of several classes of central complex neurons, implying the ventral CRE and dorsal LAL are closely related in their function. We re-determined the boundary so that each of the glomerular structures would not be divided into two, while keeping the overall architecture and definition of the CRE and LAL. The updated boundary passes between the dorsal surface of the GA and the ventral edge of the ROB. Other glomerular structures, including the RUB, are included in the CRE.</p></sec><sec id="s1-9-2"><title>Delineated neuropils</title><p>Substructures of the delineated neuropils have also been added to the brain region map in the hemibrain. The asymmetrical bodies (AB) were added as the fifth independent neuropil of the CX (<xref ref-type="bibr" rid="bib123">Wolff and Rubin, 2018</xref>). The AB is a small synaptic volume adjacent to the ventral surface of the fan-shaped body (FB) that has historically been included in the FB (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>). The AB has been described as a Fasciclin II (FasII)-positive structure that exhibits left-right structural asymmetry by <xref ref-type="bibr" rid="bib91">Pascual et al., 2004</xref>, who reported that most flies have their AB only in the right hemisphere, while a small proportion (7.6%) of wild-type flies have their AB on both sides. In the hemibrain dataset, the pair of ABs is situated on both sides of the midline, but the left AB is notably smaller than the right AB (right: 1679 μm<sup>3</sup>, left: 526 μm<sup>3</sup>), still showing an obvious left-right asymmetry. The asymmetry is consistent with light microscopy data (<xref ref-type="bibr" rid="bib123">Wolff and Rubin, 2018</xref>), though the absolute sizes differ, with the light data showing averages (n = 21) of 522 μm<sup>3</sup> for the right and 126 μm<sup>3</sup> on the left. The AB is especially strongly connected to the neighboring neuropil, the FB, by neurons including vDeltaA_a (anatomical name AF in <xref ref-type="bibr" rid="bib123">Wolff and Rubin, 2018</xref>), while it also houses both pre- and postsynaptic terminals of the CX output neurons such as the subset of FS4A and FS4B neurons that project to AB. These anatomical observations imply that the AB is a ventralmost annexed part of the FB, although this possibility is neither developmentally nor phylogenetically proven.</p><p>The round body (ROB) is also a small round synaptic structure situated on the ventral limit of the crepine (CRE), close to the β lobe of the MB (<xref ref-type="bibr" rid="bib68">Lin et al., 2013</xref>; <xref ref-type="bibr" rid="bib123">Wolff and Rubin, 2018</xref>). It is a glomerulus-like structure and one of the foci of the CX output neurons, including the PFR (protocerebral bridge – fan-shaped body – round body) neurons. It is classified as a substructure of the CRE along with other less-defined glomerular regions in the neuropil, many of which also receive signals from the CX. Among these, the most prominent one is the rubus (RUB). The ROB and RUB are two distinct structures; the RUB is embedded completely within the CRE, while the ROB is located on the ventrolateral surface of the CRE. The lateral accessory lobe (LAL), neighboring the CRE, also houses similar glomerular terminals, and the gall (GA) is one of them. While the ROB and GA have relatively clear boundaries separating them from the surrounding regions, they may not qualify as independent neuropils because of their small size and the structural similarities with the glomerulus-like terminals around them. They may be comparable with other glomerular structures such as the AL glomeruli and the optic glomeruli in the lateral protocerebrum, both of which are considered as substructures of the surrounding neuropils.</p><p>Substructures of independent neuropils are also defined using neuronal innervations. The five MB lobes on the right hemisphere are further divided into 15 compartments (α1–3, α’1–3, β1–2, β’1–2, and γ1–5) (<xref ref-type="bibr" rid="bib116">Tanaka et al., 2008</xref>; <xref ref-type="bibr" rid="bib4">Aso et al., 2014</xref>) by the mushroom body output neurons (MBONs) and dopaminergic neurons (DANs). Our compartment boundaries were defined by approximating the innervation of these neurons. Although the innervating regions of the MBONs and DANs do not perfectly tile the entire lobes, the compartments have been defined to tile the lobes, so that every synapse in the lobes belongs to one of the 15 compartments.</p><p>The anatomy of the central complex is discussed in detail in the companion paper ‘A complete synaptic-resolution connectome of the <italic>Drosophila melanogaster</italic> central complex’. Here, we summarize the division of its neuropils into compartments.</p><p>The FB is subdivided into nine horizontal layers (FBl1-9) (<xref ref-type="fig" rid="fig7">Figure 7E and F</xref>) as already illustrated (<xref ref-type="bibr" rid="bib122">Wolff et al., 2015</xref>). The layer boundaries in our dataset were determined by the pattern of innervation of 574 FB tangential cells, which form nine groups depending on the dorsoventral levels they innervate in the FB. Since tangential cells overlap somewhat, and do not entirely respect the layer boundaries, these boundaries were chosen to maximize the containment of the tangential arbors within their respective layers.</p><p>The EB is likewise subdivided into zones by the innervating patterns of the EB ring neurons, the most prominent class of neurons innervating the EB. The ring neurons have six subtypes, ER1-ER6, and each projects to specific zones of the EB. Among them, the regions innervated by ER2 and ER4 are mutually exclusive but highly intermingled, so these regions are grouped together into a single zone (EBr2r4). ER3 has the most neurons among the ring neuron subtypes and is further grouped into five subclasses (ER3a, d, m, p, and w). While each subclass projects to a distinct part of the EB, the innervation patterns of the subclasses ER3a and ER3m, and also ER3p and ER3w, are very similar to each other. The region innervated by ER3 is, therefore, subdivided into three zones, including EBr3am, EBr3pw, and EBr3d. Along with the other three zones, EBr1, EBr5, and EBr6 (innervated by ER1, ER5, and ER6), the entire EB is subdivided into seven non-overlapping zones (<xref ref-type="fig" rid="fig7">Figure 7G</xref>). Unlike other zones, EBr6 is innervated only sparsely by the ER6 cells, with the space filled primarily by synaptic terminals of other neuron types, including the extrinsic ring neurons (ExR). <xref ref-type="bibr" rid="bib86">Omoto et al., 2017</xref> segmented the EB into five domains (EBa, EBoc, EBop, EBic, EBip) by the immunolabeling pattern of DN-cadherin, and each type of the ring neurons may innervate more than one domain in the EB. Our results show that the innervation pattern of each ring neuron subtype is highly compartmentalized at the EM level and the entire neuropil can be sufficiently subdivided into zones based purely on the neuronal morphologies. The neuropil may be subdivided differently if other neuron types, such as the extrinsic ring neurons (ExR) (<xref ref-type="bibr" rid="bib87">Omoto et al., 2018</xref>), are recruited as landmarks.</p></sec></sec><sec id="s1-10"><title>Quality of the brain region boundaries</title><p>Since many of the <italic>terra incognita</italic> neuropils are not clearly partitioned from each other by solid boundaries such as glial walls, it is important to evaluate if the current boundaries reflect anatomical and functional compartments of the brain. To check our definitions, which are mostly based on morphology, we compute metrics for each boundary between any two adjacent neuropil regions. The first is the area of each boundary, in square microns, as shown in <xref ref-type="fig" rid="fig8">Figure 8A</xref>. The map shows results for brain regions that are over 75% in the hemibrain region, restricted to right regions with exception to the asymmetric AB(L). By restricting our analysis to the right part of the hemibrain, we hopefully minimize the effect of smaller, traced-but-truncated neuron fragments on our metric.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Quality checks of the brain compartments.</title><p>(<bold>A</bold>) Areas of the boundaries (in square microns) between adjacent neuropils, indicated on a log scale. (<bold>B</bold>) The number of excess crossings normalized by the area of neuropil boundary. Larger dots indicate a more uncertain boundary. Data available in <xref ref-type="supplementary-material" rid="fig8sdata1">Figure 8—source data 1</xref>.</p><p><supplementary-material id="fig8sdata1"><label>Figure 8—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig8">Figure 8</xref>.</title><p>Column A: index number; column B: first ROI name; column C: second ROI name; column D: boundary area in square microns; column E: number of neurons crossings; column F: number of distinct neurons that cross; column G: (crossings - number of neurons) per area.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-fig8-data1-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig8-v3.tif"/></fig><p>Next, for each boundary, we compute the number of ‘excess’ neuron crossings by traced neurons, where excess crossings are defined as 0 for a neuron that does not cross the boundary, and <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for a neuron crosses the same boundary <italic>n</italic> times. There is no contribution to the metric from neurons that cross a boundary once, since most such crossings are inevitable no matter where the boundary is placed. <xref ref-type="fig" rid="fig8">Figure 8B</xref> shows the number of excess crossings normalized by the area of boundary. A bigger dot indicates a potentially less well-defined boundary.</p><p>We spot checked many of the instances and in general note that the brain regions with high excess crossings per area, such as those in SNP, INP and VLNP, tend to have less well-defined boundaries. In particular, the boundaries at SMP/CRE, CRE/LAL, SMP/SIP, and SIP/SLP have worse scores, indicating these boundaries may not reflect actual anatomical and functional segregation of the neuropils. These brain regions were defined based on the arborization patterns of characteristic neuron types, but because neurons in the <italic>terra incognita</italic> neuropils tend to be rather heterogeneous, there are many other neuron types that do not follow these boundaries. The boundary between the FB and the AB also has a high excess crossing score, suggesting the AB is tightly linked to the neighboring FB.</p><sec id="s1-10-1"><title>Insights for a whole-brain remapping</title><p>The current brain regions based on <xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref> contain a number of arbitrary determinations of brain regions and their boundaries in the <italic>terra incognita</italic> neuropils. In this study, we tried to solidify the ambiguous boundaries as much as possible using the information from the reconstructed neurons. However, large parts of the left hemisphere and the subesophageal zone (SEZ) are missing from the hemibrain dataset, and neurons innervating these regions are not sufficiently reconstructed. This incompleteness of the dataset is the main reason that we did not alter the previous map drastically and kept all the existing brain regions even if their anatomical and functional significance is not obvious. Once a complete EM volume of the whole fly brain is imaged and most of its 100,000 neurons are reconstructed, the entire brain can be re-segmented from scratch with more comprehensive anatomical information. Arbitrary or artificial neuropil boundaries will thereby be minimized, if not avoided, in a new brain map. Anatomy-based neuron segmentation strategies such as NBLAST may be used as neutral methods to revise the neuropils and their boundaries. Any single method, however, is not likely to produce consistent boundaries throughout the brain, especially in the <italic>terra incognita</italic> regions. It may be necessary to use different methods and criteria to segment the entire brain into reasonable brain regions. Such a new map would need discussion in a working group, and approval from the community in advance (as did the previous map [<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>]), insofar as it would replace the current map and therefore require a major revision of the neuron mapping scheme.</p></sec></sec><sec id="s1-11"><title>Cell type classification</title><p>Defining cell types for groups of similar neurons is a time-honored means to help to understand the anatomical and functional properties of a circuit. Presumably, neurons of the same type have similar circuit roles. However, the definition of what is a distinct cell type and the exact delineation between one cell type and another remains inherently subjective and represents a classic taxonomic challenge, pitting ‘lumpers’ against ‘splitters’. Therefore, despite our best efforts, we recognize that our typing of cells may not be identical to that proposed by other experts. We expect future revisions to cell type classification, especially as additional dense connectome data become available.</p><p>One common method of cell type classification, used in flies, exploits the GAL4 system to highlight the morphology of neurons having similar gene expression (<xref ref-type="bibr" rid="bib55">Jenett et al., 2012</xref>). Since these genetic lines are imaged using fluorescence and confocal microscopy, we refer to them as ‘light lines’. Where they exist and are sufficiently sparse, light lines provide a key method for identifying types by grouping morphologically similar neurons together. However, there are no guarantees of coverage, and it is difficult to distinguish between neurons of very similar morphology but different connectivity.</p><p>We enhanced the classic view of morphologically distinct cell types by defining distinct cell types (or sub-types) based on both morphology and connectivity. Connectivity-based clustering often reveals clear cell type distinctions, even when genetic markers have yet to be found, or when the neuronal morphologies of different types are hardly distinguishable in optical images. For example, the two PEN (protocerebral bridge - ellipsoid body - noduli) neurons have very similar forms but quite distinct inputs (<xref ref-type="fig" rid="fig9">Figure 9</xref>; <xref ref-type="bibr" rid="bib119">Turner-Evans et al., 2019</xref>) Confirming their differences, PEN1 and PEN2 neurons, in fact, have been shown to have different functional activity (<xref ref-type="bibr" rid="bib34">Green et al., 2017</xref>).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>An example of two neurons with very similar shapes but differing connectivities.</title><p>PEN1 is on the left, PEN2 on the right.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig9-v3.tif"/></fig><p>Based on our previous definition of cell type, many neurons exhibit a unique morphology or connectivity pattern at least within one hemisphere of the brain (with a matching type in the other hemisphere in most cases). Because our hemibrain volume covers only the right-side examples of ipsilaterally-projecting neurons, and the contralateral arborizations of bilaterally-projecting neurons arising from the left side of the brain were in practice very difficult to match to neurons in the right side, many partial neurons were therefore left uncategorized. As a result, many neuron types consisting of a distinct morphology and connectivity have only a single example in our reconstruction.</p><p>It is possible to provide coarser groupings of neurons. For instance, most cell types are grouped by their cell body fiber representing a distinct clonal unit, which we discuss in more detail below. Furthermore, each neuron can be grouped with neurons that innervate similar brain regions. In this paper, we do not explicitly formalize this higher level grouping, but data on the innervating brain regions can be readily mined from the dataset.</p></sec><sec id="s1-12"><title>Methodology for assigning cell types and nomenclature</title><p>Assigning types and names to the more than 20,000 reconstructed cells was a difficult undertaking. Less than 20% of neuron types found in our data have been described in the literature, and half of our neurons have no previously annotated type. Adding to the complexity, prior work focused on morphological similarities and differences, but here we have, for the first time, connectivity information to assist in cell typing as well.</p><p>Many cell types in well-explored regions have already been described and named in the literature, but existing names can be both inconsistent and ambiguous. The same cell type is often given differing names in different publications, and conversely, the same name, such as PN for projection neuron, is used for many different cell types. Nonetheless, for cell types already named in the literature (which we designate as published cell types, many indexed, with their synonyms, at <ext-link ext-link-type="uri" xlink:href="http://virtualflybrain.org">http://virtualflybrain.org</ext-link>), we have tried to use existing names. In a few cases, using existing names created conflicts, which we have had to resolve. ‘R1’, for example, has long been used both for photoreceptor neurons innervating the lamina and medulla, and ring neurons in the ellipsoid body of the central complex. Similarly, ‘LN’ has been used to refer to lateral neurons in the circadian clock system, ‘local neurons’ in the antenna lobe, and LAL-Nodulus neurons in the central complex. To resolve these conflicts, the ellipsoid body ring neurons are now named ’ER1’ instead of ‘R1’, and the nodulus neurons are now ‘LNO’ and ’GLNO’ instead of ‘LN’ and ‘GLN’. The names of the antennal lobe local neuron are always preceded by lowercase letters for their cell body locations to differentiate them from the clock neuron names, for example, lLN1 versus LNd. Similarly, ‘dorsal neurons’ of the circadian clock system and ‘descending neurons’ in general, both previously abbreviated as ‘DN’, are distinguished by the following characters - numbers for the clock neurons (e.g. DN1) and letters for descending neurons (e.g. DNa01).</p><p>Overall, we defined a ‘type’ of neurons as either a single cell or a group of cells that have a very similar cell body location, morphology, and pattern of synaptic connectivity. We were able to trace from arborizations to the cell bodies for 15,912 neurons in the hemibrain volume, ≈85% of which are located in the right side of the brain while the rest are in the medialmost part of the left-side brain.</p><p>We classified these neurons in several steps. The first step classified all cells by their lineage, grouping neurons according to their bundle of cell body fibers (CBFs). Neuronal cell bodies are located in the cell body layer that surrounds the brain, and each neuron projects a single CBF towards synaptic neuropils. In the central brain, cell bodies of clonally related neurons deriving from a single stem cell (called a neuroblast in the insect brain) tend to form clusters, from each of which arises one or several bundles of CBFs. Comparing the location, trajectory, and the combined arborization patterns of all the neurons that arise from a particular CBF with the light microscopy (LM) image data of the neuronal progeny that derive from single neuroblasts (<xref ref-type="bibr" rid="bib51">Ito et al., 2013</xref>; <xref ref-type="bibr" rid="bib133">Yu et al., 2013</xref>), we confirmed that the neurons of each CBF group belong to a single lineage.</p><p>We carefully examined the trajectory and origins of CBFs of the 15,752 neurons on the right central brain and identified 192 distinct CBF bundles. Neurons arising from four specific CBF bundles arborize primarily in the contralateral brain side, which is not fully covered in the hemibrain volume. We characterized these neurons using the arborization patterns in the right-side brain that are formed by the neurons arising from the left-side CBFs.</p><p>The CBF bundles and associated neuronal cell body clusters were named according to their location (split into eight sectors of the brain surface with the combination of Anterior/Posterior, Ventral/Dorsal, and Medial/Lateral) and a number within the sector given according to the size of cell population. Thus, CBF group ADM01 is the group with the largest number of neurons in the Anterior Dorsal Medial sector of the brain’s surface (see the cellBodyFiber field of the Neuprint database explained later). For the neurons of the four CBF bundles that arborize primarily in the contralateral brain side - AVM15, 18, 19, and PVM10 - we indicated CBF information in the records of the left-side neurons.</p><p>Among the 192 bundles, 155 matched the CBF bundles of 92 known and six newly identified clonal units (<xref ref-type="bibr" rid="bib51">Ito et al., 2013</xref>; <xref ref-type="bibr" rid="bib133">Yu et al., 2013</xref>), a population of neurons and neuronal circuits derived from a single stem cell. The remaining 37 CBF bundles are minor populations and most likely of embryonic origin. In addition, we found 80 segregated cell body fiber bundles (SCB001-080, totalling 112 cells) with only one or two neurons per bundle. Many of them are also likely of embryonic origin.</p><p>We were able to identify another 6682 neurons that were not traced up to their cell bodies. For the neurons that arise from the contralateral side, we gave matching neuron names and associated CBF information, provided their specific arborization patterns gave us convincing identity information by comparison with cells that we identified in the right side of the brain. For the neurons arising from the ventralmost part of the brain outside of the hemibrain volume, we identified and gave them names if we could find convincingly specific arborization patterns, even if the CBF and cell body location data were missing. Sensory neurons that project to the specific primary sensory centers were also identified insofar as possible. In total, we typed and named 22,594 neurons.</p><p>Different stem cells sometimes give rise to neurons with very similar morphologies. We classified these as different types because of their distinct developmental origin and slightly different locations of their cell bodies and CBFs. Thus, the next step in neuron typing was to cluster neurons within each CBF group. This process consisted of three further steps, as shown in <xref ref-type="fig" rid="fig10">Figure 10</xref>. First, we used NBLAST (<xref ref-type="bibr" rid="bib18">Costa et al., 2016</xref>) to subject all the neurons of a particular CBF group to morphology-based clustering. Next, we used CBLAST, a new tool to cluster neurons based on synaptic connectivity (see the next section). This step is an iterative process, using neuron morphology as a template, regrouping neurons after more careful examination of neuron projection patterns and their connections. Neurons with similar connectivity characteristics but with distinguishable shapes were categorized into different morphology types. Those with practically indistinguishable shapes but with different connectivity characteristics were categorized into connectivity types within a morphology type. Finally, we validated the cell typing with extensive manual review and visual inspection. This review allowed us both to confirm cell type identity and help ensure neuron reconstruction accuracy. In total we identified 5229 morphology types and 5609 connectivity types in the hemibrain dataset. (See <xref ref-type="table" rid="table3">Table 3</xref> for the detailed numbers and <xref ref-type="table" rid="app1table6">Appendix 1—table 6</xref> for naming schemes for various neuron categories.)</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Summary of the numbers and types of the neurons in the hemibrain EM dataset.</title><p><italic>m-types</italic> is the number of morphology types; <italic>c-types</italic> the number of connectivity types; and <italic>c/t</italic> the average number of cells per connectivity type. Brain regions with repetitive array architecture tend to have higher average numbers of cells per type (see <xref ref-type="fig" rid="fig12">Figure 12</xref>). The cell number includes ≈4000 neurons on the contralateral side, and the percentage of contralateral cells varies between 0 and ≈50% depending on the category. For example, the central complex includes neurons on both sides of the brain, the mushroom body neurons are identified mostly on the right side, and many left-side antennal lobe sensory neurons are included as they tend to terminate bilaterally. Because of these differences, the figures shown above do not indicate the number of cells (or cell number per type) per brain side.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Brain regions (neuropils) or neuron types</th><th>Cells</th><th>m-types</th><th>c-types</th><th>C/t</th><th>Notes</th></tr></thead><tbody><tr><td>Central complex neuropil neurons</td><td>2826</td><td>224</td><td>262</td><td>10.8</td><td/></tr><tr><td>Mushroom body neuropil neurons</td><td>2315</td><td>72</td><td>80</td><td>28.9</td><td>Including MB-associated DANs</td></tr><tr><td>Mushroom body neuropil neurons</td><td>2003</td><td>51</td><td>51</td><td>39.3</td><td>Excluding MB-associated DANs</td></tr><tr><td>Dopaminergic neurons (DANs)</td><td>335</td><td>35</td><td>43</td><td>7.8</td><td>Including MB-associated DANs</td></tr><tr><td>Dopaminergic neurons (DANs)</td><td>23</td><td>14</td><td>14</td><td>1.7</td><td>Excluding MB-associated DANs</td></tr><tr><td>Octopaminergic neurons</td><td>19</td><td>10</td><td>10</td><td>1.9</td><td/></tr><tr><td>Serotonergic (5HT) neurons</td><td>9</td><td>5</td><td>5</td><td>1.8</td><td/></tr><tr><td>Peptidergic and secretory neurons</td><td>51</td><td>12</td><td>14</td><td>3.6</td><td/></tr><tr><td>Circadian clock neurons</td><td>27</td><td>7</td><td>7</td><td>3.9</td><td/></tr><tr><td>Fruitless gene expressing neurons</td><td>84</td><td>29</td><td>30</td><td>2.8</td><td/></tr><tr><td>Visual projection neurons and lobula intrinsic neurons</td><td>3723</td><td>160</td><td>160</td><td>23.3</td><td/></tr><tr><td>Descending neurons</td><td>103</td><td>51</td><td>51</td><td>2.0</td><td/></tr><tr><td>Sensory associated neurons</td><td>2768</td><td>67</td><td>67</td><td>41.3</td><td/></tr><tr><td>Antennal lobe neuropil neurons</td><td>604</td><td>284</td><td>294</td><td>2.1</td><td/></tr><tr><td>Lateral horn neuropil neurons</td><td>1496</td><td>517</td><td>683</td><td>2.2</td><td/></tr><tr><td>Anterior optic tubercle neuropil neurons</td><td>243</td><td>77</td><td>80</td><td>3.0</td><td/></tr><tr><td>Antler neuropil neurons</td><td>81</td><td>45</td><td>45</td><td>1.8</td><td/></tr><tr><td>Anterior ventrolateral protocerebrum neuropil neurons</td><td>1276</td><td>596</td><td>629</td><td>2.0</td><td/></tr><tr><td>Clamp neuropil neurons</td><td>746</td><td>364</td><td>382</td><td>2.0</td><td/></tr><tr><td>Crepine neuropil neurons</td><td>333</td><td>108</td><td>115</td><td>2.9</td><td/></tr><tr><td>Inferior bridge neuropil neurons</td><td>264</td><td>119</td><td>119</td><td>2.2</td><td/></tr><tr><td>Lateral accessory lobe neuropil neurons</td><td>429</td><td>204</td><td>206</td><td>2.1</td><td/></tr><tr><td>Posterior lateral protocerebrum neuropil neurons</td><td>480</td><td>255</td><td>260</td><td>1.8</td><td/></tr><tr><td>Posterior slope neuropil neurons</td><td>621</td><td>303</td><td>311</td><td>2.0</td><td/></tr><tr><td>Posterior ventrolateral protocerebrum neuropil neurons</td><td>348</td><td>151</td><td>156</td><td>2.2</td><td/></tr><tr><td>Saddle neuropil and antennal mechanosensory and motor center neurons</td><td>219</td><td>96</td><td>99</td><td>2.2</td><td/></tr><tr><td>Superior lateral protocerebrum neuropil neurons</td><td>1096</td><td>468</td><td>494</td><td>2.2</td><td/></tr><tr><td>Superior intermediate protocerebrum neuropil neurons</td><td>220</td><td>90</td><td>92</td><td>2.4</td><td/></tr><tr><td>Superior medial protocerebrum neuropil neurons</td><td>1494</td><td>605</td><td>629</td><td>2.4</td><td/></tr><tr><td>Vest neuropil neurons</td><td>137</td><td>84</td><td>85</td><td>1.6</td><td/></tr><tr><td>Wedge neuropil neurons</td><td>559</td><td>212</td><td>230</td><td>2.4</td><td/></tr><tr><td>Total</td><td>22,594</td><td>5229</td><td>5609</td><td>4.0</td><td/></tr></tbody></table></table-wrap><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Workflow for defining cell types.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig10-v3.tif"/></fig><p>In spite of this general rule, we assigned the same neuron type name for the neurons of different lineages in the following four cases.</p><list list-type="bullet"><list-item><p>Mushroom body intrinsic neurons called Kenyon cells, which are formed by a set of four near-identical neuroblasts (<xref ref-type="bibr" rid="bib50">Ito et al., 1997</xref>) (see also the accompanying MB paper).</p></list-item><list-item><p>Columnar neurons of the central complex, where neurons arising from different stem cells form repetitive column-like arrangement and are near identical in terms of connectivity with tangential neurons (<xref ref-type="bibr" rid="bib36">Hanesch et al., 1989</xref>; <xref ref-type="bibr" rid="bib122">Wolff et al., 2015</xref>; <xref ref-type="bibr" rid="bib123">Wolff and Rubin, 2018</xref>) (and the accompanying CX paper).</p></list-item><list-item><p>The PAM cluster of the dopaminergic neurons, where one of the hemilineages of the two clonal units forms near identical set of neurons (<xref ref-type="bibr" rid="bib65">Lee et al., 2020</xref>) (accompanying MB paper).</p></list-item><list-item><p>Cell body fiber groupings for neurons of the lateral horn, where systematic neuron names have already been given based on the light microscopy analysis (<xref ref-type="bibr" rid="bib31">Frechter et al., 2019</xref>), which did not allow for the precise segregation of very closely situated CBF bundles. Individual cell types exist within the same lineage, however.</p></list-item></list><p>‘Lumping’ versus ‘splitting’ is a difficult problem for classification. Following the experiences of taxonomy, we opted for splitting when we could not obtain convincing identity information, a decision designed to ease the task of future researchers. If we split two similar neuron types into Type 1 and Type 2, then there is a chance future studies might conclude that they are actually subsets of a common cell type. If so, then at that time we can simply merge the two types as Type 1, and leave the other type name unused, and publish a lookup table of the lumping process to keep track of the names that have been merged. The preceding studies can then be re-interpreted as the analyses on the particular subsets of a common neuron type. If, on the contrary, we lump the two similar neurons into a common type, then a later study finds they are actually a mixture of two neuron types, then it would not be possible to determine which of the two neuron types, or a mixture of them, was analyzed in preceding studies.</p><p>In the hemibrain, using the defined brain regions (neuropils) and reference to known expression driver strains, we were able to assign a cell type to many cells. Where possible, we matched previously defined cell types with those labeled in light data using a combination of Neuprint, an interactive analysis tool (described later), Color_MIP_mask search (<xref ref-type="bibr" rid="bib88">Otsuna et al., 2018</xref>), and human recognition to find the matching cell types, especially in well-explored neuropils such as the mushroom body and central complex, where abundant cell type information was already available and where we are more confident in our anatomical expertise (see the accompanying MB and CX papers). Even though most of the cell types in the MB and CX were already known, we still found new cell types in these regions, an important vindication of our methods. In these cases, we tried to name them using the existing schemes for these regions, and further refined these morphological groupings with relevant information on connectivity.</p><p>To give names to neuron types, we categorized neurons that share certain characteristics into groups and distinguished individual types by adding identifiers (IDs) with numbers, uppercase letters, or combinations of these. (See <xref ref-type="table" rid="app1table6">Appendix 1—table 6</xref> for the summary of the naming schemes of all the neuron types). For example, the tangential neurons of the fan-shaped body (FB) of the central complex were grouped as ‘FB’, and an ID of their primary innervating FB layer was added with numbers 1–9. Different types of neurons that arborize in each layer were further distinguished by uppercase letters. Thus, for example the FB7B neurons are the second type of tangential neurons that arborize in the seventh layer of FB. We also used uppercase letters to subdivide the neuron types that have previously been reported as a single type to keep naming consistency. For example, a population of antennal lobe local neurons that has been known as LN2L was divided into five morphology subtypes as lLN2F, 2P, 2R, 2S, and 2T for their full, patchy, regional, star-like and tortuous arborization patterns while still indicating that they are part of the LN2 population. The letter ‘L’ at the end of the previous name, which referred to the cell body location on the lateral side of the AL, was moved in front of LN to keep consistency with the established naming scheme for the olfactory projection neurons (e.g., DA1_lPN).</p><p>Neuron types that are known to exist were sometimes not identified in the particular brain sample used for the hemibrain EM dataset. In such cases, the corresponding ID numbers were kept blank. For example, the MBON08 neurons were not identified in the current sample and the number was therefore skipped.</p><p>Although the morphology type names generally end with either numbers or uppercase letters, in a few cases lower case letters were used for distinguishing morphological subtypes to keep the naming convention of that cell group consistent. For example, subtypes of the neurons in the optic lobes were distinguished as, for example LC28a and LC28b, because such subtypes of the optic lobe neurons have historically been distinguished by lowercase letters.</p><p>If neurons of near-identical morphology could be further subdivided into different connectivity types, they were suffixed with an underscore and a lowercase letter, for example FB2F_a, FB2F_b, and FB2F_c. A neuron type without such a suffix consists of a single connectivity type.</p><p>The cell type names are indicated in the ‘type’ field of the NeuPrint database. In the ‘instance’ field, information about the side of the neuronal cell body, when it is known, is added as _R and _L after the cell type name. The name of the CBF group is indicated in the ‘cellBodyFiber’ field of the right-side neurons except for those that belong to AVM15, 18, 19, and PVM10 groups, and in the same field of the left-side neurons for those four CBF groups. For the rest of the neurons, the CBF information is shown in the ‘instance’ field in parentheses when it is known.</p><p>Across the brain, we looked for neurons that correspond to already known cell types, and as far as possible gave them consistent names. These include: olfactory projection neurons and local neurons associated with the antennal lobe (<xref ref-type="bibr" rid="bib117">Tanaka et al., 2012</xref>; <xref ref-type="bibr" rid="bib6">Bates et al., 2020</xref>; <xref ref-type="bibr" rid="bib75">Marin et al., 2020</xref>), neurons associated with the lateral horn (<xref ref-type="bibr" rid="bib22">Dolan et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Frechter et al., 2019</xref>; <xref ref-type="bibr" rid="bib6">Bates et al., 2020</xref>), aminergic and peptidergic neurons (<xref ref-type="bibr" rid="bib7">Bergland et al., 2012</xref>; <xref ref-type="bibr" rid="bib13">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="bib73">Mao and Davis, 2009</xref>; <xref ref-type="bibr" rid="bib76">Martelli et al., 2017</xref>; <xref ref-type="bibr" rid="bib92">Pech et al., 2013</xref>; <xref ref-type="bibr" rid="bib99">Pooryasin and Fiala, 2015</xref>; <xref ref-type="bibr" rid="bib107">Shao et al., 2017</xref>; <xref ref-type="bibr" rid="bib121">White et al., 2010</xref>), neurons associated with the circadian clock (<xref ref-type="bibr" rid="bib44">Helfrich-Förster et al., 2007</xref>), and neurons that express the fruitless gene (<xref ref-type="bibr" rid="bib14">Cachero et al., 2010</xref>; <xref ref-type="bibr" rid="bib132">Yu et al., 2010</xref>; <xref ref-type="bibr" rid="bib137">Zhou et al., 2014</xref>; <xref ref-type="bibr" rid="bib120">Wang et al., 2020</xref>).</p><p>In some cases, we found candidate neurons that do not precisely match previously identified neurons. For example, in addition to the three cell types that match the octopaminergic (OA) neurons OA-ASM1, 2 and 3 (<xref ref-type="bibr" rid="bib13">Busch et al., 2009</xref>), we found two neuron types in the same location that appear to match some of the tdc2-Gal4 expressing neurons in the FlyCircuit database of single-cell labeling images (<xref ref-type="bibr" rid="bib16">Chiang et al., 2011</xref>). Because of the remaining uncertainty we gave them the canonical names SMP143 and SMP149, but added ‘Tdc2 (OA)-ASM candidates’ in the <italic>Notes</italic> field. We also found that the FB2B neurons share the same cell body location and appear to match another type of tdc2-Gal4 expressing neurons in the FlyCircuit database. Although OA-immunoreactive neurites have been observed in the FB (<xref ref-type="bibr" rid="bib110">Sinakevitch et al., 2005</xref>), it is not known from where they are derived. Considering that the particular neurons may produce only tyramine (TA) but not OA, we added ‘Tdc2 (TA)-ASM candidates’ in the Notes. Due to similar considerations, the number of candidate neurons may not match the actual known numbers for many neuron types.</p><p>For the multiglomerular olfactory projection neurons and local interneurons of the antennal lobe, we devised new naming schemes by expanding the naming scheme of uniglomerular projection neurons, which consists of the contributing antennal lobe glomerulus and the location of the cell body cluster (<xref ref-type="bibr" rid="bib6">Bates et al., 2020</xref>; <xref ref-type="bibr" rid="bib75">Marin et al., 2020</xref>). Because the list of contributing glomeruli is not a useful designator for the multiglomerular projection neurons, we used information about the antennal lobe tract (ALT) projection pathways instead. Unique type ID numbers were then added at the end of the names of the multiglomerular projection neurons (1-92) and local neurons (1-50). For the local neurons LN1-6 the numbers were kept consistent with the published neuron names (<xref ref-type="bibr" rid="bib117">Tanaka et al., 2012</xref>); for the newly identified local neurons and for the multiglomerular projection neurons, ID numbers were sorted according to the cell body location from dorsal to ventral.</p><p>For the neurons associated with the lateral horn, we expanded the existing naming scheme (names such as PV5a1) based on the cell body cluster location (uppercase letters and first number), anatomically associated groups (lower case letter), and individual neuron type (last number), which has previously been applied for ≈30% of the lateral horn neurons (<xref ref-type="bibr" rid="bib31">Frechter et al., 2019</xref>; <xref ref-type="bibr" rid="bib6">Bates et al., 2020</xref>). The neuron types that have been defined in the lateral horn sometimes contain slightly larger morphological varieties of neurons than would be categorized as different types in the hemibrain volume. To reconcile this slight discrepancy while keeping the published neuron type names as consistent as possible, in some cases we used suffices _a, _b, etc., for distinguishing not only the neurons that are different in their connectivity but also those that have minute but distinct morphological differences. Because of this technical issue more neurons are distinguished by suffices in the lateral horn than in other brain regions.</p><p>In cases where we gave new neuron names to the already known ones, or slightly modified the existing names for the sake of naming scheme consistency, we indicated the most commonly used previous names in the <italic>notes</italic> field, from where users can look for further synonyms using the <italic>Virtual Fly Brain</italic> database (<ext-link ext-link-type="uri" xlink:href="http://virtualflybrain.org">http://virtualflybrain.org</ext-link>).</p><p>For the optic lobe neurons, we categorized only the VPNs based primarily on the specific projection patterns of their axon terminals in the central brain. Newly identified neuron types were given higher numbers than those already used (<xref ref-type="bibr" rid="bib26">Fischbach and Dittrich, 1989</xref>; <xref ref-type="bibr" rid="bib90">Panser et al., 2016</xref>; <xref ref-type="bibr" rid="bib89">Otsuna and Ito, 2006</xref>; <xref ref-type="bibr" rid="bib40">Hausen, 1984</xref>). Neurons that arborize only in the optic lobe are not classified, except for several intrinsic neurons in the lobula, because the hemibrain dataset does not provide enough information about their projection patterns in the optic lobe for conclusive cell typing.</p><p>Olfactory-, thermo-, and hygro-receptor (sensory) neurons were named according to their target glomeruli in the antennal lobe (<xref ref-type="bibr" rid="bib27">Fishilevich and Vosshall, 2005</xref>; <xref ref-type="bibr" rid="bib19">Couto et al., 2005</xref>; <xref ref-type="bibr" rid="bib32">Gallio et al., 2011</xref>; <xref ref-type="bibr" rid="bib25">Enjin et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Frank et al., 2017</xref>; <xref ref-type="bibr" rid="bib75">Marin et al., 2020</xref>). Some of the auditory receptor neurons (Johnston’s organ neurons) were also identified, but their precise target zones in the antennal mechanosensory and motor center (<xref ref-type="bibr" rid="bib57">Kamikouchi et al., 2006</xref>) were not determined because of the insufficient information in the hemibrain image volume.</p><p>The neurons associated with the ocellar ganglion (OCG), a detached ganglion just beneath the ocelli, were categorized into eight types based on the morphology of their terminals in the central brain. Precise classification of OCG neurons is not possible without the projection pattern information in the OCG. To remedy this problem the neurons that share the common projection patterns within the brain were classified as OCG1, OCG2, etc., and when the projection pattern information in the OCG is available they will be classified in more detail as OCG1A, OCG1B, etc.</p><p>Outside the heavily studied regions, and the neuron types explained above, the fly’s circuits are largely composed of cells of so-far unknown type. Because such neurons, in what is called the <italic>terra incognita</italic> of the fly brain, account for nearly 70% of the total neuron types, it was necessary to devise a systematic naming scheme to give them names that annotate reasonable morphological characteristics and are easy to pronounce. About 40% of these neurons extend their projections to regions outside of the imaged volume of the hemibrain EM dataset, such as the contralateral brain side, the ventralmost parts of the brain, and the optic lobes. Since whole brain reconstructions of such neurons will soon become available, the naming scheme should provide reasonable names for the neurons that are not fully traceable within the hemibrain image volume.</p><p>To address this problem, we tested various naming schemes using single-cell LM images of about 500 neuron types in these regions. LM images have much lower spatial resolution but visualize entire projection patterns across the brain compared to the EM data. We found the regions (neuropils) of the central brain with the most extensive arborization by counting the voxel numbers of the three-dimensional LM data. We also simulated the numbers of output and input synapses available in the EM data by assessing the number of boutons and spines - characteristic morphology of output and input synaptic sites - in the LM images. Regions with the largest number of output synapses tend to lie on the contralateral side of the brain, out of the hemibrain volume, making it difficult to use EM information as a primary determining factor. Regions with the largest number of input synapses often showed discrepancies between EM and LM images, mainly due to the varying completeness of fine dendritic fragments in the EM data. We found the names based on the neuropils with the largest number of voxels gave the most consistent names, regardless of whether we used the information of the entire brain or only the image area that corresponds to the hemibrain volume. Because the still unmapped fragments of input dendritic arborizations are thin and tiny, with much smaller volumes compared to the already mapped major branches, we found the voxel counts of dendrites are much less affected by potential incompleteness than the counts of input synapses.</p><p>We then applied the above LM-based naming scheme to the EM data of terra incognita neurons, and found that naming based on EM voxel count matched with either the neuropils with the largest or second-largest number of output or input synapses for more than 95% of the neuron types. For the remaining types, we took the neuropil names with the second largest voxel numbers, which resulted in near-perfect match with the neuron type name and either the region of the most major or second major output/input synapses, making the names reasonable for connectivity analysis.</p><p>There is one more factor we had to consider. Certain groups of neuron types tend to share common core projection patterns and differ slightly only in the extent of arbors in each neuropil. For functional interpretation it would be more convenient if such neurons were classified into the same category of neuropils. If we gave names simply to individual neuron types, however, such neurons tend to be scattered into various neuropil categories affected by the slight differences of arborization patterns. To address this problem, we performed NBLAST morphological clustering with a higher threshold than used for individual neuron typing, to group the neurons that share the same CBF bundle and rather similar morphology into a common neuropil category. This additional process, however, sometimes caused mismatches between the resulting neuropil name and the most major or second major output/input synapses if the arborization pattern of that neuron type deviates too much from the rest of the group. In these cases we split such neuron types from the group and assigned them into more appropriate neuropil categories.</p><p>Between 45 and 630 neuron types were assigned into each neuropil category and distinguished with three-digit ID numbers, for example SLP153 and WED048, using the standard nomenclature abbreviations of the neuropils (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>). We gave sequential numbers to the neuron types that share the same CBF bundles and common core projection patterns so that neurons with similar appearance would be assigned similar names, as far as possible. Within each CBF group, neurons are sorted from the ones with broader and more extensive projections to the ones with restricted local arborizations. Because of this numbering scheme, broadly arborizing neurons have scattered numbers within the number range of each neuropil category, depending on the CBF groups they belong to.</p></sec><sec id="s1-13"><title>Results of cell typing</title><p>Using the workflow of <xref ref-type="fig" rid="fig10">Figure 10</xref>, we identified 22,594 neurons with 5229 morphological types and 5609 connectivity types (<xref ref-type="table" rid="table3">Table 3</xref>). Over 2000 of these are types with only a single instance, although presumably, for a whole brain reconstruction, most of these types would have partners on the opposite side of the brain.</p><p><xref ref-type="fig" rid="fig11">Figure 11</xref> shows the number of distinct neuron types found in different brain regions. <xref ref-type="fig" rid="fig12">Figure 12</xref> shows the distribution of the number of neurons in each cell type.</p><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>The number of cell types in each major brain region.</title><p>The total number of cell types shown in this graph is larger than the total number of cell types shown in <xref ref-type="table" rid="table3">Table 3</xref>, because types that arborize in multiple regions are counted in each region in which they occur. Data available in <xref ref-type="supplementary-material" rid="fig11sdata1">Figure 11—source data 1</xref>.</p><p><supplementary-material id="fig11sdata1"><label>Figure 11—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig11">Figure 11</xref>.</title><p>Column A: region name; column B: number of cell types.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-fig11-data1-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig11-v3.tif"/></fig><fig id="fig12" position="float"><label>Figure 12.</label><caption><title>Histogram showing the number of cell types with a given number of constituent cells.</title><p>Data available in <xref ref-type="supplementary-material" rid="fig12sdata1">Figure 12—source data 1</xref>.</p><p><supplementary-material id="fig12sdata1"><label>Figure 12—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig12">Figure 12</xref>.</title><p>Column A: number of instances of a cell; column B: Number of cell types with that number of instances.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-fig12-data1-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig12-v3.tif"/></fig><p>In spite of our extensive efforts, the assignment of type names to neurons is still ongoing. Because we opted for splitting rather than lumping of hard to differentiate cell types, it is possible that some of the neuron types may be merged with others in the future. In such cases, the number that is unused after the merger should not be re-used for other later-discovered neuron types, in order to avoid confusion. There may also be cases where neuron types could be split, or that neuron types that are missing in the current brain sample might be identified in EM or LM images of other brain samples. In such cases the newly identified neurons are expected to be given numbers above the current number range.</p><p>Although cell types and names may change, and indeed have already changed between versions v1.0 and v1.1 of our reconstruction, what will not change are the unique body ID numbers given in the database that refer to a particular (traced) cell in this particular image dataset. We strongly advise that such body IDs be included in any publications based on our data to avoid confusion as cell type names evolve.</p></sec><sec id="s1-14"><title>CBLAST</title><p>As part of our effort to assign cell types, we built a tool for cell type clustering based on neuron connectivity, called CBLAST (by analogy with the existing NBLAST [<xref ref-type="bibr" rid="bib18">Costa et al., 2016</xref>], which forms clusters based on the shapes of neurons). The overall flow of the tool is described in <xref ref-type="fig" rid="fig13">Figure 13</xref>, and the code and instructions on how to install and run it can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/connectome-neuprint/CBLAST">https://github.com/connectome-neuprint/CBLAST</ext-link> (<xref ref-type="bibr" rid="bib98">Plaza and Dreher, 2020</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/CBLAST">https://github.com/elifesciences-publications/CBLAST</ext-link>). </p><fig id="fig13" position="float"><label>Figure 13.</label><caption><title>Overview of the operation of CBLAST.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig13-v3.tif"/></fig><p>Partitioning a network into clusters of nodes that exhibit similar connectivity is known as community detection or graph clustering (<xref ref-type="bibr" rid="bib28">Fortunato and Hric, 2016</xref>). Numerous methods have been proposed for selecting such partitions, the best known being the stochastic block model. To non-theoreticians, the process by which most methods choose a partitioning is not intuitive, and the results are not easily interpretable. Furthermore, most approaches do not readily permit a domain expert to guide the partitioning based on their intuition or on other features of the nodes that are not evident in the network structure itself. In contrast, CBLAST is based on traditional data clustering concepts, leading to more intuitive results. Additionally, users can apply their domain expertise by manually refining the partitioning during successive iterations of the procedure. This is especially useful in the case of a network like ours, in which noise and missing data make it difficult to rely solely on connectivity to find a good partitioning automatically. Additionally, other graph clustering methods do not accommodate the notion of left-right symmetry amongst communities, a feature that is critical for assigning cell types in a connectome.</p><p>CBLAST clusters neurons together using a similarity feature score defined by how the neuron distributes inputs and outputs to different neuron types. However, this is a circular requirement since neuron types must already be defined to use this technique. CBLAST therefore uses an iterative approach, refining cell type definitions successively. Initial cell type groups are putatively defined using an initial set of features based on morphological overlap as in NBLAST and/or based on the distribution of inputs and outputs in defined brain regions. These initial groups are fed into CBLAST in which the user can visualize and analyze the results using plots such as that in <xref ref-type="fig" rid="fig14">Figure 14</xref>. Given the straightforward similarity measure, the user can look at the input and output connections for each neuron to better understand the decision made by the clustering algorithm. As the definitions of cell type definitions are improved, the clustering becomes more reliable. In some cases, this readily exposes incompleteness (e.g., due to the boundary of the hemibrain sample) in some neurons which would complicate clustering even for more computationally intensive strategies such as a stochastic block model. Based on these interactions, the user makes decisions and refines the clusters manually, iterating until further changes are not observed.</p><fig id="fig14" position="float"><label>Figure 14.</label><caption><title>Cells of nine types plotted according to their connectivities.</title><p>Coordinates are in arbitrary units after dimensionality reduction using UMAP (<xref ref-type="bibr" rid="bib77">McInnes et al., 2018</xref>). The results largely agree with those from morphological clustering but in some cases show separation even between closely related types.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig14-v3.tif"/></fig><p>Our large, dense connectome is a key requirement for CBLAST. Unless a significant fraction of a neuron’s inputs and outputs is known, neurons that are in fact similar may not cluster together correctly. This requirement is not absolute, as we note that CBLAST is often able to match left and right symmetric neurons, despite some of these left side neurons being truncated by the boundaries of the dataset. Nonetheless, reconstruction incompleteness and any noise in the reconstruction can contribute to noise in clustering results.</p><p>CBLAST usually generates clusters that are consistent with the morphological groupings of the neurons, with CBLAST often suggesting new sub-groupings as intended. This agreement serves as some validation of the concepts behind CBLAST. In some cases it can be preferable to NBLAST, since the algorithm is less sensitive to exact neuron location, and for many applications the connectivity is more important than the morphology. In <xref ref-type="fig" rid="fig14">Figure 14</xref>, we show the results of using CBLAST on a few neuron types extracted from the ellipsoid body. The clusters are consistent with the morphology, with exception to a new sub-grouping for R3p being suggested as a more distinct group than type ExR7/ExR6.</p></sec><sec id="s1-15"><title>Assessing morphologies and cell types</title><p>Verifying correctness and completeness in these data is a challenging problem because no existing full brain connectome exists against which our data might be compared. We devised a number of tests to check the main features: Are the morphologies correct? Are the regions and cell types correctly defined? Are the synaptic connection counts representative?</p><p>Assessing completeness is much easier than assessing correctness. Since the reconstruction is dense, we believe the census of cells, types, and regions should be essentially complete. The main arbors of every cell within the volume are reconstructed, and almost every cell is assigned a cell type. Similarly, since the identified brain regions nearly tile the entire brain, these are complete as well.</p><p>For checking morphologies, we searched for major missing or erroneous branches using a number of heuristics. Each neuron was reviewed by multiple proofreaders. The morphology of each neuron was compared with light microscopy data whenever it was available. When more than one cell of a given type was available (either left and right hemisphere, or multiple cells of the same type in one hemisphere), a human examined and compared them. This helped us find missing or extra branches, and also served as a double check on the cell type assignment. In addition, since the reconstruction is dense, all sufficiently large ‘orphan’ neurites were examined manually until they were determined to form part of a neuron, or they left the volume. To help validate the assigned cell types, proofreaders did pairwise checks of every neuron with types that had been similarly scored.</p><p>For subregions in which previous dense proofreading was available (such as the alpha lobes of the mushroom body), we compared the two connectomes. We were also helped by research groups using both sparse tracing in the full fly brain TEM dataset (<xref ref-type="bibr" rid="bib136">Zheng et al., 2018</xref>), and our hemibrain connectome. They were happy to inform us of any inconsistencies. There are limits to this comparison, as the two samples being compared were of different ages and raised under different conditions, then prepared and imaged by different techniques, but this comparison would nevertheless have revealed any gross errors. Finally, we generated a ‘probabilistic connectome’ based on a different segmentation, and systematically visited regions where the two versions differed.</p></sec><sec id="s1-16"><title>Assessing synapse accuracy</title><p>As discussed in the section on finding synapses, we evaluated both precision (the fraction of found synapses that are correct) and recall (fraction of true synapses that were correctly predicted) on sample cubes in each brain region. We also double checked by comparing our findings with a different, recently published, synapse detection algorithm (<xref ref-type="bibr" rid="bib12">Buhmann et al., 2019</xref>).</p><p>As a final check, we also evaluated the end-to-end correctness of given connections between neurons for different cell types and across brain regions. Specifically, for each neuron, we sampled 25 upstream connections (T-bar located within the neuron) and 25 downstream connections (PSD located within the neuron), and checked whether the annotations were correct, meaning that the pre/post annotation was valid and assigned to the correct neuron.</p><p>In total, we examined 1735 traced neurons spanning 1518 unique cell types (therefore examining roughly 43,000 upstream connections and 43,000 downstream connections). The histogram of synapse accuracy (end-to-end precision of predicted synapses) is given in <xref ref-type="fig" rid="fig15">Figure 15</xref>. Median precision for upstream connections, as well as for downstream connections, is 88%. Additionally, 90% of cell types have an accuracy of at least 70%. For the few worst cases, we manually refined the synapse predictions afterwards. We note that the worst outlier, having an upstream connection accuracy of 12%, is both a case involving few total connections (17 T-bars), and some ambiguity in the ground-truth decisions (whether the annotated location is an actual T-bar).</p><fig id="fig15" position="float"><label>Figure 15.</label><caption><title>Connection precision of upstream and downstream partners for ≈1000 cell types.</title><p>Data available in <xref ref-type="supplementary-material" rid="fig15sdata1">Figure 15—source data 1</xref>.</p><p><supplementary-material id="fig15sdata1"><label>Figure 15—source data 1.</label><caption><title>Data on 1735 neurons, one per row.</title><p>The histograms shown are computed from the columns 'final upstream perc' and 'final downstream perc'.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-fig15-data1-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig15-v3.tif"/></fig><p>We also evaluated single-connection pathways across each brain region. In the fly, functionally important connections are thought typically to have many synapses, with the possible exception of cases where many neurons of the same type synapse onto the same downstream partner. However, the presence of connections represented by few synapses is also well known, even if the biological importance of these is less clear. Regardless, we wanted to ensure that even single connection pathways were mostly correct. We sampled over 5500 single-connection pathways, distributed across 57 brain regions. Mean synapse precision per brain region was 76.1%, suggesting that single-connection accuracy is consistent with overall synapse prediction accuracy.</p><p>We also undertook a preliminary evaluation of two-connection pathways (two synapses between a single pair of neurons). We sampled 100 such two-connection pathways within the FB. Overall synapse precision (over the 200 synapses) is 79%, consistent with the single-edge accuracy. Moreover, the results also suggest that synapse-level accuracy is largely uncorrelated with pathway/bodies, implying that the probability that both synapses in a two-connection pathway were incorrect is 4.4% (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mn>0.79</mml:mn><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>), close to the observed empirical value of 3%. (Applying a <inline-formula><mml:math id="inf5"><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> goodness of fit test with a null hypothesis of independence gives a <italic>p</italic> value of 0.7.)</p></sec><sec id="s1-17"><title>Assessing connection completeness</title><p>A synapse in the fly’s brain consists of a presynaptic density (with a characteristic T-bar) and typically several postsynaptic partners (PSDs). The T-bars are contained in larger neurites, and most (&gt;90%) of the T-bars in our dataset were contained in identified neurons. The postsynaptic densities are typically in smaller neurites, and it is these that are difficult for both machine and human to connect with certainty.</p><p>With current technology, tracing all fine branches in our EM images is impractical, so we sampled among them (at completeness levels typically ranging from 20% to 85%) and traced as many as practical in the allotted time. The goal is to provide synapse counts that are representative, since completeness is beyond reach and largely superfluous. Assuming the missing PSDs are independent (which we try to verify), then the overall circuit emerges even if a substantial fraction of the connections are missing. If a connection has a synapse count of 10, for example, then it will be found in the final circuit with more than 99.9% probability, provided at least half the individual synapses are traced.</p><p>If unconnected small twigs are the main source of uncertainty in our data (as we believe to be the case), then as the proofreading proceeds the synapse counts of existing connections should only increase. Of course corrections resulting in lower synapse counts, such as correcting a false connection or removing an incorrect synapse, are also possible, but are considerably less likely. To see if our proofreading process worked as expected, we took a region that had been read to a lower percentage completion and then spent the manual effort to reach a higher percentage, and compared the two circuits. (A versioned database such as DVID is enormously helpful here.) If our efforts were successful, ideally what we see is that almost all connections that changed had more synapses, very few connections got fewer synapses, and no new strong (many synapse) connections appeared (since all strong connections should already be present even in low coverage proofreading). If this is the behavior we find, we could be reasonably certain that the circuits found are representative for all many-synapse connections.</p><p><xref ref-type="fig" rid="fig16">Figure 16</xref> shows such an analysis. The results support our view that the circuits we report reflect what would be observed if we extrapolated to assign all pre- and postsynaptic elements.</p><fig id="fig16" position="float"><label>Figure 16.</label><caption><title>Difference between synapse counts in connections of the Ellipsoid Body, with increased completeness in proofreading.</title><p>Roughly 40,000 connection strengths are shown. Almost all points fall above the line Y = X, showing that almost all connections increased in synapse count, with very few decreasing. In particular, no path decreased by more than five synapses. Only two new strong (count &gt;10) paths were found that were not present in the original. As proofreading proceeds, this error becomes less and less common since neuron fragments (orphans) are added in order of decreasing size (see text). Data available in <xref ref-type="supplementary-material" rid="fig16sdata1">Figure 16—source data 1</xref>.</p><p><supplementary-material id="fig16sdata1"><label>Figure 16—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig16">Figure 16</xref>.</title><p>The first column is the synapse count before the additional proofreading, the second after. Each point includes a small random component so the points do not directly overlap.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig16-data1-v3.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig16-v3.tif"/></fig></sec><sec id="s1-18"><title>Interpreting the connection counts</title><p>Given the complexity of the reconstruction process, and the many different errors that could occur, how confident should the user be that the returned synapse counts are valid? This section gives a quick guide in the absence of detailed investigation. The number of synapses we return is the number we found. The true number could range from slightly less, largely due to false synapse predictions, to considerably more, in the regions with low percentage reconstructed. For connections known to be in a specific brain region, the reciprocal of the completion percentage (as shown in <xref ref-type="table" rid="table1">Table 1</xref>) gives a reasonable estimate of the undercount.</p><p>If we return a count of 0 (the neurons are not connected), there are two cases. If the neurons do not share any brain regions, then the lack of connections is real. If they do share a brain region or regions, then a count of 0 is suspect. It is possible that there might be a weak connection (count 1–2) and less likely there is a connection of medium strength (3–9 synapses). Strong connections can be confidently ruled out, minus the small chance of a mis- or un-assigned branch with many synapses.</p><p>If we report a weak connection (1–2 synapses), then the true strength might range from 0 (the connection does not exist) through a weak connection (3–9 synapses). If your model or analysis relies on the strength of these weak connections, it is a good idea to manually check our reconstruction. If your analysis does not depend on knowledge of weak connections, we recommend ignoring connections based on three or fewer synapses.</p><p>If we report a medium strength connection (3–9 synapses) then the connection is real. The true strength could range from weak to the lower end of a strong connection.</p><p>If we report a strong connection (10 or more synapses), the connection not only exists, but is strong. It may well be considerably stronger than we report.</p></sec><sec id="s1-19"><title>Data representation</title><p>The representation of connectomics data is a significant problem for all connectomics efforts. The raw image data on which our connectome is based is larger than 20 TB, and takes 2 full days to download even at a rate of 1 gigabit/second. Looking forward, this problem will only get worse. Recent similar projects are generating petabytes worth of data (<xref ref-type="bibr" rid="bib131">Yin et al., 2019</xref>), and a mouse brain of 500 mm<sup>3</sup>, at a typical FIB-SEM resolution of 8 nm isotropic, would require almost 1000 petabytes.</p><p>In contrast, most users of connectivity information want a far smaller amount of much more specific information. For example, a common query is ‘what neurons are downstream (or upstream) of a given target neuron?’. This question can be expressed in a few tens of characters, and the desired answer, the top few partners, fits on a single page of text.</p><p>Managing this wide range of data, from the raw gray-scale through the connectivity graph, requires a variety of technologies. An overview of the data representations we used to address these needs is shown in <xref ref-type="fig" rid="fig17">Figure 17</xref>.</p><fig id="fig17" position="float"><label>Figure 17.</label><caption><title>Overview of data representations of our reconstruction.</title><p>Circles are stored data representations, rectangles are application programs, ellipses represent users, and arrows indicate the direction of data flow labeled with transformation and/or format. Filled areas represent existing technologies and techniques; open areas were developed for the express purpose of EM reconstruction of large circuits.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig17-v3.tif"/></fig><p>This organization offers several advantages. In most cases, instead of transferring files, the user submits queries for the portion of data desired. If the user needs only a subset of the data (as almost all users do) then they need not cope with the full size of the data set. Different versions of the data can be managed efficiently behind the scenes with a versioned database such as DVID (<xref ref-type="bibr" rid="bib60">Katz and Plaza, 2019</xref>) that keeps track of changes and can deliver data corresponding to any previous version. The use of existing software infrastructure, such as Google buckets or the graph package neo4j, which are already optimized for large data, helps with both performance and ease of development. The advanced user is not limited to these interfaces - for those who may wish to validate or extend our results; we have provided procedures whereby the user can make personal copies of each representation, including the grayscale, the DVID data storage, and our editing and proofreading software. These allow other researchers to establish an entirely independent version of all we have done, completely under their control. Contact the authors for the details of how to copy all the underlying data and software.</p></sec><sec id="s1-20"><title>What are the data types?</title><p>Grayscale data correspond to traditional electron microscope images. This is written only once, after alignment, but often read, because it is required for segmentation, synapse finding, and proofreading. We store the grayscale data, eight bits per voxel, in Google buckets, which facilitates access from geographically distributed sites.</p><p>Segmentation, synapses, and identifying regions annotate and give biological meaning to the grayscale data. For segmentation, we assign a 64 bit neuron ID to each voxel. Despite the larger size per voxel (64 vs 8 bits) compared with the grayscale, the storage required is much smaller (by a factor of more than 20) since segmentation compresses well. Although the voxel level segmentation is not needed for connectivity queries, it may be useful for tasks such as computing areas and cross-sections at the full resolution available, or calculating the distance between a feature and the boundary.</p><p>Synapses are stored as point annotations - one point for a presynaptic T-bar, and one point for each of its postsynaptic densities (or PSDs). The segmentation can then be consulted to find the identity of the neurons containing their connecting synapses.</p><p>The compartment map of the brain is stored as a volume specified at a lower resolution, typically a 32 × 32 × 32 voxel grid. At 8 nm voxels, this gives a 256 nm resolution for brain regions, comparable to the resolution of confocal laser scanning microscopy.</p><p>Unlike the grayscale data, segmentation, synapses, and regions are all modified during proofreading. This requires a representation that must cope with many users modifying the data simultaneously, log all changes, and be versioned. We use DVID (<xref ref-type="bibr" rid="bib60">Katz and Plaza, 2019</xref>), developed internally, to meet these requirements.</p><p>Neuron skeletons are computed from the segmentation (<xref ref-type="bibr" rid="bib135">Zhao and Plaza, 2014</xref>), and not entered or edited directly. A skeleton representation describes each neuron with (branching) centerlines and diameters, typically in the SWC format popularized by the simulator <italic>Neuron</italic> (<xref ref-type="bibr" rid="bib15">Carnevale and Hines, 2006</xref>). These are necessarily approximations, since it is normally not possible (for example) to match both the cross-sectional area and the surface area of each point along a neurite with such a representation. But SWC skeletons are a good representation for human viewing, adequate for automatic morphology classification, and serve as input to neural simulation programs such as ‘Neuron’. SWC files are also well accepted as an interchange format, used by projects such as NeuroMorpho (<xref ref-type="bibr" rid="bib3">Ascoli et al., 2007</xref>) and FlyBrain (<xref ref-type="bibr" rid="bib108">Shinomiya et al., 2011</xref>).</p><p>The connectivity graph is also derived from the data and is yet more abstract, describing only the identity of neurons and a summary of how they connect - for example, Neuron ID1 connects to neuron ID2 through a certain number of synapses. In our case, it also retains the brain region information and the location of each synapse. Such a connectivity graph is both smaller and faster than the geometric data, but sufficient for most queries of interest to biologists, such as finding the upstream or downstream partners of a neuron. A simple connectivity graph is often desired by theorists, particularly within brain regions, or when considering neural circuits in which each neuron can be represented as a single node.</p><p>A final, even more abstract form is the adjacency matrix: This compresses the connectivity between each pair of neurons to a single number. Even this most economical form requires careful treatment in connectomics. As our brain sample contains more than 25K traced neurons as well as many unconnected fragments, the adjacency matrix has more than a billion entries (most of which are zero). Sparse matrix techniques, which report only the non-zero coefficients, are necessary for practical use of such matrices.</p></sec><sec id="s1-21"><title>Accessing the data</title><p>For the hemibrain project, we provide access to the data through a combination of a software interface (<xref ref-type="bibr" rid="bib17">Clements et al., 2020</xref>) and a server (<ext-link ext-link-type="uri" xlink:href="https://neuprint.janelia.org">https://neuprint.janelia.org</ext-link>, also accessible through <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25378/janelia.12818645">https://doi.org/10.25378/janelia.12818645</ext-link>). Login is via any Google account; users who wish to remain anonymous can create a separate account for access purposes only. Data are available in the form of gray-scale, pixel-level segmentation, skeletons, and a graph representation. Two previous connectomics efforts are available as well (a seven-column optic lobe reconstruction [<xref ref-type="bibr" rid="bib113">Takemura et al., 2015</xref>] and the alpha lobe of the mushroom body [<xref ref-type="bibr" rid="bib114">Takemura et al., 2017</xref>]). These can be found at <ext-link ext-link-type="uri" xlink:href="https://neuprint-examples.janelia.org">https://neuprint-examples.janelia.org</ext-link> .</p><p>The most straightforward way to access the hemibrain data is through the Neuprint (<xref ref-type="bibr" rid="bib17">Clements et al., 2020</xref>) interactive browser. This is a web-based application that is intended to be usable by biologists with minimal or no training. It allows the selection of neurons by name, type, or brain region, displays neurons, their partners, and the synapses between these in a variety of forms, and provides many of the graphs and summary statistics that users commonly want.</p><p>Neuprint also supports queries from languages such as Python (<xref ref-type="bibr" rid="bib105">Sanner, 1999</xref>) and R, as used by the neuroanatomy tool NatVerse (<xref ref-type="bibr" rid="bib72">Manton et al., 2019</xref>). Various formats are supported, including SWC format for the skeletons. In particular, the graph data can be queried through an existing graph query language, Cypher (<xref ref-type="bibr" rid="bib29">Francis et al., 2018</xref>), as seen in the example below. The schema for the graph data is shown in <xref ref-type="fig" rid="fig18">Figure 18</xref>.</p><fig id="fig18" position="float"><label>Figure 18.</label><caption><title>Schema for the neo4j graph model of the hemibrain.</title><p>Each neuron contains 0 or more SynapseSets, each of which contains one or more synapses. All the synapses in a SynapseSet connect the same two neurons. If the details of the synapses are not needed, the neuron-to-neuron weight can be obtained as a property on the ‘ConnectsTo’ relation, as can the distribution of this weight across different brain regions (the roiInfo).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig18-v3.tif"/></fig><list list-type="simple"><list-item><p><monospace>MATCH (n:Neuron) - [c:ConnectsTo] -&gt; (t:Neuron) WHERE t.type = `MBON18'</monospace> </p></list-item><list-item><p><monospace>RETURN n.type, n.bodyId, c.weight ORDER BY c.weight DESCENDING</monospace></p></list-item></list><p>This query looks for all neurons that are presynaptic to any neuron of type ‘MBON18’. For each such neuron it returns the types and internal identities of the presynaptic neuron, and the count of synapses between them. The whole list is ordered in order of decreasing synapse count. This is just an illustration for a particular query that is quite common and supported in Neuprint without the need for any programming language.</p><p>Adjacency matrices, if needed, can be derived from the graph representation. We provide a small demonstration program that queries the API and generates such matrices, either with or without the brain regions. The two matrices themselves are available in gzipped Python format.</p><p>The raw greyscale images, with overlays of segmentation and feature masks (such as glia and mitochondria), can be viewed in the publicly available tool NeuroGlancer (<xref ref-type="bibr" rid="bib94">Perlman, 2019</xref>). This viewer can be selected from the Neuprint browser.</p><p>For more information on accessing data and other hemibrain updates, please see <ext-link ext-link-type="uri" xlink:href="https://www.janelia.org/project-teams/flyem/hemibrain">https://www.janelia.org/project-teams/flyem/hemibrain</ext-link> .</p></sec><sec id="s1-22"><title>Matching EM and light microscopy data</title><p>No two flies are identical, and brain samples differ in size and orientation. Furthermore, different preparation methods cause tissues to swell and shrink by varying amounts. Therefore, the first step when comparing the features of different brains is registration to a common reference frame.</p><p>Some of these differences are illustrated in <xref ref-type="fig" rid="fig19">Figure 19</xref>. Compared to the hemibrain EM data (<xref ref-type="fig" rid="fig19">Figure 19(a)</xref>), the confocal laser scanning microscopy images of the previous brain atlas (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>) are about 17% smaller (<xref ref-type="fig" rid="fig19">Figure 19(b)</xref>), and the JRC2018 unisex template brain used for the registration of EM and light microscopy brain images (<xref ref-type="bibr" rid="bib9">Bogovic et al., 2020</xref>) is about 30% smaller (<xref ref-type="fig" rid="fig19">Figure 19(c)</xref>). Since unfixed brains right after dissection in saline are 15–20% larger than the antibody-labeled brains mounted in 80% glycerol – similar to <xref ref-type="fig" rid="fig19">Figure 19(b)</xref> – a raw female brain will be nearly the same size as the hemibrain EM stack.</p><fig id="fig19" position="float"><label>Figure 19.</label><caption><title>Comparison of the size and orientation of brain images.</title><p>Sagittal section images at the plane of the mushroom body pedunculus are shown. Parallel lines indicate the direction of serial sectioning. Purple dotted lines indicate the axes of the pedunculus to show the sample orientation. Numbers indicate the angles of the pedunculus axes relative to the horizontal axis. Scale bar: 50 μm for all images. CA: calyx of the mushroom body. Panel (<bold>a</bold>) Hemibrain EM image stack. Grayscale indicates the density of the points of the presynaptic T-bars (point clouds). (<bold>b</bold>) Confocal light microscopy image stack provided by the Insect Brain Name Working Group (<xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>), of a female brain mounted in 80% glycerol after antibody labeling. Presynaptic sites are labeled by GFP fused with the synaptic vesicle-associated protein neuronal synaptobrevin (nSyb), driven by the pan-neuronal expression driver line elav-GAL4 C155. (<bold>c</bold>) JRC2018 Unisex brain template (<xref ref-type="bibr" rid="bib9">Bogovic et al., 2020</xref>), which is an average of 36 female and 26 male brains mounted in DPX plastic after dehydration with ethanol and clearization with xylene. Presynaptic sites are labeled with the SNAP chemical tag knock-in construct inserted into the genetic locus of the active zone protein bruchpilot (brp). The relative sizes of the brains, measured as the height along the lines that are perpendicular to the pedunculus axes, are 100:83:70 for (<bold>a</bold>), (<bold>b</bold>), and (<bold>c</bold>). These differences in size and orientation must be taken into account when comparing the sections and reconstructed neurons of the hemibrain EM and registered light microscopy images.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig19-v3.tif"/></fig><p>The orientation of the brain samples may also vary. There is about 18.5° of tilt between the hemibrain EM stack and the 2014 brain atlas, and about 14° of tilt between hemibrain EM and the JRC2018 template. To create matching vertical or horizontal sections, therefore, each image stack should be re-sliced after applying the corresponding rotation.</p><p>The raw EM data, segmentation, and skeletons (as displayed in Neuprint) were all computed in a reference frame corresponding to <xref ref-type="fig" rid="fig19">Figure 19(a)</xref>, whereas the light lines and tools such as Color_MIP_mask search (<xref ref-type="bibr" rid="bib88">Otsuna et al., 2018</xref>) use the reference frame of <xref ref-type="fig" rid="fig19">Figure 19(c)</xref>. Therefore, registration is required to map between the EM and light representations.</p><p>We registered the hemibrain EM data to the JRC2018 <italic>Drosophila</italic> template brain using an automatic registration algorithm followed by manual correction. We began by using the automated T-bar predictions (described in section on synapse prediction) to generate a T-bar density volume rendered at a resolution comparable to those from light microscopic images. This hemibrain synapse density volume was automatically registered to the template brain using elastix (<xref ref-type="bibr" rid="bib63">Klein et al., 2010</xref>). The resulting registration was manually fine-tuned using BigWarp (<xref ref-type="bibr" rid="bib8">Bogovic et al., 2016</xref>). The total transform is the composition of the elastix and BigWarp transformations, and can be found at <ext-link ext-link-type="uri" xlink:href="https://www.janelia.org/open-science/jrc-2018-brain-templates">https://www.janelia.org/open-science/jrc-2018-brain-templates</ext-link>. We estimated a corresponding inverse transformation and make that available as well.</p><p>Using these transformations, an implementation that matches EM to light lines, and vice versa, is publicly accessible at <ext-link ext-link-type="uri" xlink:href="https://neuronbridge.janelia.org/">https://neuronbridge.janelia.org/</ext-link>. This matching software is accessible directly from the Neuprint browser, where it can be launched from the tabular display of selected neurons. For those not familiar with NeuronBridge, an explanatory video explains the matching process. The details of the underlying algorithm will be covered in a separate paper by Otsuna et al., but are briefly sketched here.</p><p>If starting from an EM neuron of interest, researchers can use NeuronBridge to identify GAL4 lines labeling that neuron. First, the EM representation of the neuron is spatially transformed into the JRC 2018 unisex template space where GAL4 driver line images are registered. The EM neuron is then used to create a mask (<xref ref-type="bibr" rid="bib88">Otsuna et al., 2018</xref>) that narrows the search space considerably, making it easier to find corresponding neurons even in crowded GAL4 driver line images.</p><p>The opposite direction, finding an EM neuron that corresponds to a light neuron, is also supported. In this case the scoring of a potential match must be modified, since the light image contains the entire neuron, but many EM neurons are trunctated by the limits of our reconstructed volume. Both of these cases are discussed in the upcoming paper, with examples.</p><p>As another option, since hemibrain neurons are skeletonized, users can query GAL4 neuronal skeleton databases using NBLAST (<xref ref-type="bibr" rid="bib18">Costa et al., 2016</xref>).</p></sec><sec id="s1-23"><title>Longer term storage of data, and archival references</title><p>Historically, archival data from biology data have been expressed as files that are included with supplementary data. However, for connectivity data this practice has two main problems. First, the data are large, and hard to store. Journals, for example, typically limit supplemental data to a few 10s of megabytes. The data here are about 6 orders of magnitude larger. Second, connectome data are not static, during proofreading and even after initial publication. As proofreading proceeds, the data improve in their completeness and quality. The question then is how to refer to the data as they existed at some point in time, required for reproducibility of scientific results. If represented as files, this would require many copies, checkpointed at various times - the ‘as submitted’ version, the ‘as published’ version, the ‘current best version’, and so on.</p><p>We resolve this, at least for now, by hosting the data ourselves and making them available through query mechanisms. Underlying our connectome data is a versioned database (DVID) so it is technically possible to access every version of the data as it is revised. However, as it requires effort to host and format this data for the Neuprint browser and API, only selected versions (called named versions) are available by default from the website, starting with the initial versions, which are ‘hemibrain:v1.0’ and the much improved ‘hemibrain:v1.1’. Since multiple versions are available, when reproducibility is required (such as when referencing the data in a paper) it is best to refer explicitly to the version used by name (such as ‘hemibrain:v1.1’) because we expect new milestone versions every few months, at least at first. We will supply a DOI for each of these versions, and each is archived, can be viewed and queried through the web browser and APIs at any time, and will not change.</p><p>The goal of multiple versions is that later versions should be of higher quality. Towards this end we have implemented several systems for reporting errors so we can correct them. Users can add annotations in NeuroGlancer (<xref ref-type="bibr" rid="bib94">Perlman, 2019</xref>), the application used in conjunction with Neuprint to view image data, where they believe there are such errors. To make this process easier, we provide a video explaining it. We will review these annotations and amend those that we agree are problems. Users can also contact us via email about problems they find.</p><p>Archival storage is an issue since, unlike genetic data, there is not yet an institutional repository for connectomics data and the data are too large for journals to archive. We pledge to keep our data available for at least the next 10 years.</p></sec><sec id="s1-24"><title>Analysis</title><p>Of necessity, most previous analyses have concentrated on particular circuits, cell types, or brain regions with relevance to specific functions or behaviors. For example, a classic paper about motifs (<xref ref-type="bibr" rid="bib111">Song et al., 2005</xref>) sampled the connections between one cell type (layer five pyramidal neurons) in one brain region (rat visual cortex), and found a number of non-random features, such as over-represented reciprocal connections and a log-normal strength distribution. However, it has never been clear which of these observations generalize to other cell types, other brain regions, and the brain as a whole. We are now in a position to make much stronger statements, ranging over all brain regions and cell types.</p><p>In addition, many analyses are best performed (or can only be performed) on dense connectomes. Type-wide observations depend on a complete census of that cell type, and depending on the observation, a complete census of upstream and downstream partners as well. Some analyses, such as null observations about motifs (where certain motifs do not occur in all or portions of the fly’s brain) can only be undertaken on dense connectomes.</p></sec><sec id="s1-25"><title>Compartment statistics</title><p>One analysis enabled by a dense whole-brain reconstruction involves the comparison between the circuit architectures of different brain areas within a single individual.</p><p>The compartments vary considerably. <xref ref-type="table" rid="table4">Table 4</xref> shows the connectivity statistics of compartments that are completely contained within the volume, have at least 100 neurons, and have the largest or smallest value of various statistics. Across regions, the number of neurons varies by a factor of 74, the average number of partners of each neuron by a factor of 36, the network diameter (defined as the maximum length of the shortest path between any two neurons) by a factor of 4, the average strength of connection between partner neurons by a factor of 5, and the fraction of reciprocal connections by a factor of 5. The average graph distance between neurons is more conserved, differing by a factor of only 2.</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Regions with minimum or maximum characteristics, picked from those regions lying wholly within the reconstructed volume and containing at least 100 neurons.</title><p>Yellow indicates a minimum value; blue a maximal value. Volume is in cubic microns. N is the number of neurons in the region, L the number of connections between those neurons, <inline-formula><mml:math id="inf6"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula> the average number of partners (in the region), D the network diameter (the maximum length of the shortest path between neurons), <inline-formula><mml:math id="inf7"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mtext>str</mml:mtext><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula> the average connection strength, broken up into non-reciprocal and reciprocal. fracR is the fraction of connections that are reciprocal, and AvgDist the average number of hops (one hop corresponding to a direct synaptic connection) between any two neurons in the compartment.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Name</th><th>Volume</th><th>N</th><th>L</th><th><inline-formula><mml:math id="inf8"><mml:mrow><mml:mo maxsize="70%" minsize="70%">⟨</mml:mo><mml:mi mathsize="70%">k</mml:mi><mml:mo maxsize="70%" minsize="70%">⟩</mml:mo></mml:mrow></mml:math></inline-formula></th><th>D</th><th><inline-formula><mml:math id="inf9"><mml:mrow><mml:mo maxsize="70%" minsize="70%">⟨</mml:mo><mml:mtext mathsize="70%">str</mml:mtext><mml:mo maxsize="70%" minsize="70%">⟩</mml:mo></mml:mrow></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf10"><mml:mrow><mml:mo maxsize="70%" minsize="70%">⟨</mml:mo><mml:mtext mathsize="70%">non-r</mml:mtext><mml:mo maxsize="70%" minsize="70%">⟩</mml:mo></mml:mrow></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf11"><mml:mrow><mml:mo maxsize="70%" minsize="70%">⟨</mml:mo><mml:mtext mathsize="70%">r</mml:mtext><mml:mo maxsize="70%" minsize="70%">⟩</mml:mo></mml:mrow></mml:math></inline-formula></th><th>fracR</th><th>AvgDist</th></tr></thead><tbody><tr><td>MB(R)</td><td>309371</td><td>3514</td><td>574732</td><td style="author-callout-style-b1">163.555</td><td>8</td><td>3.275</td><td>3.081</td><td>3.388</td><td>0.632</td><td>2.215</td></tr><tr><td>bL(R)</td><td>29695</td><td>1171</td><td>108250</td><td>92.442</td><td>8</td><td style="author-callout-style-b4">2.019</td><td>1.856</td><td>2.122</td><td>0.613</td><td>2.090</td></tr><tr><td>EB</td><td>93932</td><td>555</td><td>58789</td><td>105.926</td><td>5</td><td style="author-callout-style-b1">10.087</td><td>4.610</td><td>12.215</td><td style="author-callout-style-b1">0.720</td><td style="author-callout-style-b4">1.798</td></tr><tr><td>AB(L)</td><td>526</td><td style="author-callout-style-b4">100</td><td>1250</td><td>12.500</td><td style="author-callout-style-b4">4</td><td>2.182</td><td>1.765</td><td>2.687</td><td>0.453</td><td>1.938</td></tr><tr><td>PLP(R)</td><td>367711</td><td>6913</td><td>244182</td><td>35.322</td><td style="author-callout-style-b1">15</td><td>2.791</td><td>2.479</td><td>3.866</td><td>0.225</td><td>3.148</td></tr><tr><td>SNP(R)</td><td>1076257</td><td style="author-callout-style-b1">9130</td><td>811279</td><td>88.859</td><td>13</td><td>3.026</td><td>2.552</td><td>4.539</td><td>0.239</td><td>2.724</td></tr><tr><td>RUB(L)</td><td>834</td><td>128</td><td>623</td><td style="author-callout-style-b4">4.867</td><td>6</td><td>7.313</td><td>2.766</td><td>20.253</td><td>0.260</td><td>2.727</td></tr><tr><td>EPA(R)</td><td>29947</td><td>1483</td><td>18848</td><td>12.709</td><td>13</td><td>2.224</td><td>2.152</td><td>2.700</td><td style="author-callout-style-b4">0.131</td><td style="author-callout-style-b1">3.471</td></tr></tbody></table></table-wrap></sec><sec id="s1-26"><title>Paths in the fly brain are short</title><p>Neurons in the fly brain are tightly interconnected, as shown in <xref ref-type="fig" rid="fig20">Figure 20</xref>, which plots what fraction of neuron pairs are connected as a function of the number of interneurons between them. Three quarters of all possible pairs are connected by a path with fewer than three interneurons, even when only connections with ≥5 synapses are included. If weaker connections are allowed, the paths become shorter yet. These short paths and tight coupling are very different from human designed systems, which have much longer path lengths connecting node pairs. As an example, a standard electrical engineering benchmark (S38584 from <xref ref-type="bibr" rid="bib11">Brglez et al., 1989</xref>) is shown alongside the hemibrain data in <xref ref-type="fig" rid="fig20">Figure 20A–B</xref>. The connection graph for this example has roughly the same number of nodes as the graph of the fly brain, but pair-to-pair connections involve paths more than an order of magnitude longer – a typical node pair is separated by 60 intervening nodes. This is because a typical computational element in a human designed circuit (a gate) connects only to a few other elements, whereas a typical neuron receives input from, and sends outputs to, hundreds of other neurons.</p><fig id="fig20" position="float"><label>Figure 20.</label><caption><title>Plots of the percentage of pairs connected (of all possible) versus the number of interneurons required.</title><p>(<bold>a</bold>) It shows the data from the whole hemibrain, for up to eight interneurons. (<bold>b</bold>) It is a much wider view of the same data, shown on a log scale so the curve from a human designed system is visible. Data available in <xref ref-type="supplementary-material" rid="fig20sdata1">Figure 20—source datas 1</xref>–<xref ref-type="supplementary-material" rid="fig20sdata6">6</xref>.</p><p><supplementary-material id="fig20sdata1"><label>Figure 20—source data 1.</label><caption><title>Data for threshold 1 trace.</title><p>The first column is the path length between two nodes, the second the number of pairs for which that is the length of the shortest path between them, and the third the cumulative fraction of all paths of that length or less.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig20-data1-v3.txt"/></supplementary-material></p><p><supplementary-material id="fig20sdata2"><label>Figure 20—source data 2.</label><caption><title>Data for threshold 3.</title><p>The first column is the path length between two nodes, the second the number of pairs for which that is the length of the shortest path between them, and the third the cumulative fraction of all paths of that length or less.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig20-data2-v3.txt"/></supplementary-material></p><p><supplementary-material id="fig20sdata3"><label>Figure 20—source data 3.</label><caption><title>Data for threshold 5 trace.</title><p>The first column is the path length between two nodes, the second the number of pairs for which that is the length of the shortest path between them, and the third the cumulative fraction of all paths of that length or less.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig20-data3-v3.txt"/></supplementary-material></p><p><supplementary-material id="fig20sdata4"><label>Figure 20—source data 4.</label><caption><title>Data for threshold 10 trace.</title><p>The first column is the path length between two nodes, the second the number of pairs for which that is the length of the shortest path between them, and the third the cumulative fraction of all paths of that length or less.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig20-data4-v3.txt"/></supplementary-material></p><p><supplementary-material id="fig20sdata5"><label>Figure 20—source data 5.</label><caption><title>Data for threshold 20 trace.</title><p>The first column is the path length between two nodes, the second the number of pairs for which that is the length of the shortest path between them, and the third the cumulative fraction of all paths of that length or less.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig20-data5-v3.txt"/></supplementary-material></p><p><supplementary-material id="fig20sdata6"><label>Figure 20—source data 6.</label><caption><title>Data for human designed trace.</title><p>The first column is the path length between two nodes, the second the number of pairs for which that is the length of the shortest path between them, and the third the cumulative fraction of all paths of that length or less.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig20-data6-v3.mm.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig20-v3.tif"/></fig></sec><sec id="s1-27"><title>Distribution of connection strength</title><p>The distribution of connection strengths has been studied in mammalian tissue, looking at specific cell types in specific brain areas. These findings, such as the log-normal distribution of connection strengths in rat cortex, do not appear to generalize to flies. Assuming the strength of a connection is proportional to the number of synapses in parallel, we can plot the distribution of connection strengths, summing over the whole central brain, as shown in <xref ref-type="fig" rid="fig21">Figure 21</xref>. We find a nearly pure power law with an exponential cutoff, very different from the log-normal distribution of strengths found by <xref ref-type="bibr" rid="bib111">Song et al., 2005</xref> in pyramidal cells in the rat cortex, or the bimodal distribution found for pyramidal cells in the mouse by <xref ref-type="bibr" rid="bib23">Dorkenwald et al., 2019</xref>. However, we caution that these analyses are not strictly comparable. Even aside from the very different species examined, the three analyses differ. Both Song and Dorkenwald looked at only one cell type, with excitatory connections only, but one looked at electrical strength while the other looked at synapse area as a proxy for strength. In our analysis, we use synapse count as a proxy for connection strength, and look at all cell types, including both excitatory and inhibitory synapses.</p><fig id="fig21" position="float"><label>Figure 21.</label><caption><title>The number of connections with a given strength.</title><p>Up to a strength of 100, this is well described by a power law (exponent −1.67) with exponential cutoff (at N = 42). Data available in <xref ref-type="supplementary-material" rid="fig21sdata1">Figure 21—source data 1</xref>.</p><p><supplementary-material id="fig21sdata1"><label>Figure 21—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig21">Figure 21</xref>.</title><p>The first column is a synapse count of a connection. The second column tells how many connections of that strength exist.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig21-data1-v3.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig21-v3.tif"/></fig></sec><sec id="s1-28"><title>Small motifs</title><p>As mentioned earlier, there have been many studies of small motifs, usually involving limited circuits, cell types, and brain regions. We emphatically confirm some traditional findings, such as the over-representation of reciprocal connections. We observe this in all brain regions and among all cell types, confirming similar findings in the antennal lobe (<xref ref-type="bibr" rid="bib46">Horne et al., 2018</xref>). This can now be assumed to be a general feature of the fly’s brain, and possibly all brains. In the fly, the incidence varies somewhat by compartment, however, as shown in <xref ref-type="table" rid="table4">Table 4</xref>.</p></sec><sec id="s1-29"><title>Large motifs</title><p>We define a large motif as a graph structure that involves every cell of an abundant type (N ≥ 20). The most tightly bound motif is a clique, in which every cell of a given type is connected to every other cell of that type, with synapses in both directions. Such connections, as illustrated in <xref ref-type="fig" rid="fig22">Figure 22(a)</xref>, are extremely unlikely in a random wiring model. Consider, for example, the clique of ER4d cells found in the ellipsoid body, as shown in <xref ref-type="table" rid="table5">Table 5</xref>. In the ellipsoid body, two cells are connected with an average probability of 0.19. Therefore, the odds of finding all 600 possible connections between ER4d cells, assuming a random wiring model, is <inline-formula><mml:math id="inf12"><mml:mrow><mml:msup><mml:mn>0.19</mml:mn><mml:mn>600</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>432</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>.</p><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Cell types that form cliques and near-cliques in the hemibrain data.</title><p>To be included, a cell type must have at least 20 cell instances, 90% or more of which have bidirectional connections to at least 90% of cells of the same type. Coverage is the fraction of all possible edges in the clique that are present with any synapse count &gt;0. Average strength is the average number of synapses in each connection. Synapses is the total number of synapses in the clique.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Type</th><th>Region</th><th>Cells</th><th>Coverage</th><th>Avg. strength</th><th>Synapses</th></tr></thead><tbody><tr><td>KCab-p</td><td>MB</td><td>59/60</td><td>3455/3540</td><td>5.13</td><td>17722</td></tr><tr><td>Delta7</td><td>PB, CX</td><td>42/42</td><td>1719/1722</td><td>14.21</td><td>24433</td></tr><tr><td>ER2_c</td><td>EB, CX</td><td>21/21</td><td>420/420</td><td>33.76</td><td>14180</td></tr><tr><td>ER3w</td><td>EB, CX</td><td>20/20</td><td>380/380</td><td>28.00</td><td>10639</td></tr><tr><td>ER4d</td><td>EB, CX</td><td>25/25</td><td>600/600</td><td>54.94</td><td>32961</td></tr><tr><td>ER5</td><td>EB, CX</td><td>20/20</td><td>380/380</td><td>26.61</td><td>10111</td></tr><tr><td>PFNa</td><td>NO(R)</td><td>29/29</td><td>811/812</td><td>6.74</td><td>5467</td></tr><tr><td>PFNa</td><td>NO(L)</td><td>29/29</td><td>811/812</td><td>7.22</td><td>5858</td></tr><tr><td>PFNd</td><td>NO(R)</td><td>20/20</td><td>377/380</td><td>7.69</td><td>2899</td></tr><tr><td>PFNd</td><td>NO(L)</td><td>20/20</td><td>378/380</td><td>7.60</td><td>2874</td></tr></tbody></table></table-wrap><fig id="fig22" position="float"><label>Figure 22.</label><caption><title>Large motifs searched for.</title><p>Squares represent abundant types with at least 20 instances. Circles represent sparse types with at most two instances. Panel (<bold>a</bold>) shows a clique, where all possible connections are present. (<bold>b</bold>) It shows bidirectional connections between a sparse type and all instances of an abundant type. (<bold>c</bold>) It shows unidirectional connections from all of an abundant type to a sparse type. Panel (<bold>d</bold>) illustrates a cell type that does not form a clique overall, but does within each of two compartments.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig22-v3.tif"/></fig><p>In the fly’s brain, only a few cell types form large cliques, as shown in <xref ref-type="table" rid="table5">Table 5</xref>. All true cliques are among the ring neurons in the central complex, with a near-clique among the KCab-p cells of the mushroom body. The cell types PFNa and PFNd are included although they do not form a clique as shown in <xref ref-type="fig" rid="fig22">Figure 22(a)</xref>. However, these neurons are part of symmetrical structures, the noduli, that occur on both sides of the brain. Within each side, the cells form a clique, as shown in <xref ref-type="fig" rid="fig22">Figure 22(d)</xref>. The cliques within the central complex, and their potential operation, are discussed in detail in the companion paper on the central complex by Jayaraman et al.</p><p>The next most tightly bound motifs are individual cells that connect both to and from all cells of a given type, but are themselves of a different type. This is illustrated in <xref ref-type="fig" rid="fig22">Figure 22(b)</xref>. Such a motif is often speculated to be a gain or sparseness controlling circuit, where the single neuron reads the collective activation of a population and then controls their collective behavior. A well-known example is the APL neuron in the mushroom body, which connects both to and from all the Kenyon cells, and is thought to regulate the sparseness of the Kenyon cell activation (<xref ref-type="bibr" rid="bib69">Lin et al., 2014</xref>).</p><p>We search for this motif by looking at cells with few instances (one or two) connecting bidirectionally to almost all cells (at least 90%) of an abundant type (N ≥ 20). We find this motif in three regions of the brain – it is common in the CX (73 different cells overseeing 22 cell types), the optic lobe circuits (19 cells overseeing 14 types), and somewhat in the MB (12 types overseeing nine types). A spreadsheet containing these cell types, who they connect to, and the numbers and strengths of their connections is described in the appendix and included as supplementary data. We only analyze the optical circuits here, since the mushroom body and central complex are the subjects of companion papers. We observe three variations on this motif - a single cell connected to all of a type (<xref ref-type="fig" rid="fig23">Figure 23(a)</xref>, found five times), a single cell with bidirectional connections to many types (<xref ref-type="fig" rid="fig23">Figure 23(b)</xref>, found once), and multiple cells all connected bidirectionally to a single type (<xref ref-type="fig" rid="fig23">Figure 23(c)</xref>), found three times. We find one circuit that is a combination: There is one cell that connects bidirectionally to all the LC17 neurons, and then a higher order cell that connects bidirectionally to a larger set (LPLC1, LPLC2, LLP1, LPC1, and LC17). In this case, these are all looming-sensitive cells and hence these circuits may regulate the features of the overall looming responses. It is tempting to speculate that the more complex structures of <xref ref-type="fig" rid="fig23">Figure 23 (b) and (c)</xref> arose from the simpler structures of (a) through cell type duplication followed by divergence, but the connectomes of many more related species will be needed before this argument could be made quantitative.</p><fig id="fig23" position="float"><label>Figure 23.</label><caption><title>One to many motifs found in the optic circuits.</title><p>Cell types consisting of a single cell, or a left-right pair, are shown at the top of the diagram. Corresponding cell type, each with many instances, are shown at the bottom of the diagram, with the number of cells per type shown inside. The arrows show the average count of synaptic connections per one cell of the bottom group. (<bold>a</bold>) An example of the most common case is shown. Here one cell, PLP008, has bidirectional connections to all 82 cells of type LC13. (<bold>b</bold>) It shows a single cell with exhaustive connections to several types. (<bold>c</bold>) It shows an alternative motif where several cells form these one-to-many connections.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig23-v3.tif"/></fig><p>The least tightly bound large motif is a cell that connects either to or from (but not both) all cells of a given type, as shown in <xref ref-type="fig" rid="fig22">Figure 22(c)</xref>. Examples include the mushroom body output neurons (<xref ref-type="bibr" rid="bib114">Takemura et al., 2017</xref>). This is a very common motif, found in many regions. We find more than 500 examples of this in the fly’s brain.</p></sec><sec id="s1-30"><title>Brain regions and electrical response</title><p>How does the compartmentalization of the fly brain affect neural computation? In a few cases this has been established. For example, the CT1 neuron performs largely independent computations in each branch (<xref ref-type="bibr" rid="bib78">Meier and Borst, 2019</xref>), whereas estimates show that within the medulla, the delays within each neuron are likely not significant for single column optic lobe neurons, and hence the neurons likely perform only a single computation (<xref ref-type="bibr" rid="bib112">Takemura et al., 2013</xref>). Similarly, compartments of PEN2 neurons in the protocerebral bridge have been shown to respond entirely differently from their compartments in the ellipsoid body (<xref ref-type="bibr" rid="bib34">Green et al., 2017</xref>; <xref ref-type="bibr" rid="bib119">Turner-Evans et al., 2019</xref>).</p><p>Our detailed skeleton models allow us to construct electrical models of neurons. (In what follows, we use the word ‘compartment’ to mean a named physical region of the brain, as shown in <xref ref-type="table" rid="table1">Table 1</xref>, as opposed to the electrical sub-divisions used in simulation.) In particular, to look more generally at the issues of intra– vs inter–compartment delays and amplitudes, we can construct a linear passive model for each neuron. Our method is similar to that elsewhere (<xref ref-type="bibr" rid="bib106">Segev et al., 1985</xref>), except that instead of using right cylinders, we represent each segment of the skeleton as a truncated cone. This is then used to derive the axonic resistance, the membrane resistance, and membrane capacitance for each segment. To analyze the effect of compartment structure on neuron operation, we inject the neuron at a postsynaptic density (input) with a signal corresponding to a typical synaptic input (1 nS conductance, 1 ms width, 0.1 ms rise time constant, 1 ms fall time constant, 60 mV reversal potential). We then compute the response at each of the T-bar sites (outputs). Since the synapses, both input and output, are annotated by the brain region that contains them, this allows us to calculate the amplitudes and delays from each synapse (or a sample of synapses) in each compartment to each output synapse in all other compartments.</p><p>In general, we find the compartment structure of the neuron is clearly reflected in the electrical response. Consider, for example, the EPG neuron (<xref ref-type="fig" rid="fig24">Figure 24(a)</xref>) with arbors in the ellipsoid body, the protocerebral bridge, and the gall (the gall is a sub-compartment of the LAL, the lateral accessory lobe). <xref ref-type="fig" rid="fig25">Figure 25(a)</xref> shows the responses to synaptic input in the gall. Within the gall, the delays are very short, and the amplitude relatively high and variable, depending somewhat on the input and output synapse within the gall. From the gall to other regions, the delays are longer (typically a few milliseconds) and the amplitudes much smaller and nearly constant, largely independent of the exact transmitting and receiving synapse. There is a very clean separation between the within-compartment and across-compartment delays and amplitudes, as shown in <xref ref-type="fig" rid="fig25">Figure 25(a)</xref>. The same overall behavior is true for inputs into the other regions - short delays and strong responses within the compartment, with longer delays and smaller amplitudes to other compartments.</p><fig id="fig24" position="float"><label>Figure 24.</label><caption><title>Neural connection patterns.</title><p>(<bold>a</bold>) An EPG neuron, with arbors in three compartments. (<bold>b</bold>) Two neurons that connect in more than one compartment, in this case the calyx and the lateral horn. They are each pre- and postsynaptic to each other in both compartments.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig24-v3.tif"/></fig><fig id="fig25" position="float"><label>Figure 25.</label><caption><title>Delay versus amplitude plots for a neuron.</title><p>(<bold>a</bold>) The linear response to inputs in the gall (GA) for an EPG neuron, which also has arbors in the ellipsoid body (EB) and the protocerebral bridge (PB). Each point in the modeled plot shows the time each response reached its peak amplitude (the delay), and the amplitude at that time, for an input injected at one of the PSDs in the gall. (<bold>b</bold>) Delays and amplitudes for gall to PB response, for all combinations of three values of cytoplasmic resistance <inline-formula><mml:math id="inf13"><mml:msub><mml:mi>R</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and three values of membrane resistance <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>R</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:math></inline-formula>. Data available in <xref ref-type="supplementary-material" rid="fig25sdata1">Figure 25—source datas 1</xref>–<xref ref-type="supplementary-material" rid="fig25sdata4">4</xref>.</p><p><supplementary-material id="fig25sdata1"><label>Figure 25—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig25">Figure 25A</xref> (ellipsoid body).</title><p>The first column is the delay in milli-seconds, the second the amplitude in mv, the third the connection type.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig25-data1-v3.eb.txt"/></supplementary-material></p><p><supplementary-material id="fig25sdata2"><label>Figure 25—source data 2.</label><caption><title>Data for <xref ref-type="fig" rid="fig25">Figure 25A</xref> (gall).</title><p>The first column is the delay in milli-seconds, the second the amplitude in mv, the third the connection type.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig25-data2-v3.ga.txt"/></supplementary-material></p><p><supplementary-material id="fig25sdata3"><label>Figure 25—source data 3.</label><caption><title>Data for <xref ref-type="fig" rid="fig25">Figure 25A</xref> (protocerebral bridge).</title><p>The first column is the delay in milli-seconds, the second the amplitude in mv, the third the connection type.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig25-data3-v3.pb.txt"/></supplementary-material></p><p><supplementary-material id="fig25sdata4"><label>Figure 25—source data 4.</label><caption><title>Data for <xref ref-type="fig" rid="fig25">Figure 25B</xref>.</title><p>The first column is the delay in milli-seconds, the second the amplitude in mv, the third the connection type.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig25-data4-v3.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig25-v3.tif"/></fig><p>This simple pattern motivates a model that describes delays and amplitudes not as a single number, but as an <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> matrix, where <italic>N</italic> is the number of compartments. Each row contains the estimated amplitude and delay, measured in each compartment, for a synaptic input in the given compartment. This gives a much improved estimate of the linear response. For the example EPG neuron above, with nominal values for <inline-formula><mml:math id="inf16"><mml:msub><mml:mi>R</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf17"><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf18"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, if we represent all delays by a single number then the standard deviation of the error is 0.446 ms. If instead we represent the delays as a 3 × 3 matrix indexed by the compartment, the average error is 0.045 ms, for 10x greater accuracy. Similarly, the average error in amplitude drops from 0.168 mv to 0.021 mv, an eightfold improvement. While the improvement in error will depend on the neuron topology, in all cases it will be more accurate than a point model, for relatively little increase in complexity.</p><p>The absolute values of delay and amplitude are strongly dependent on the electrical parameters of the cell, however. A wide range of electrical properties has been reported in the fly literature (see <xref ref-type="table" rid="table6">Table 6</xref>) and it is plausible that these vary on a cell-to-cell basis. In addition gap junctions, which are not included in our model, could affect the apparent value of <inline-formula><mml:math id="inf19"><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>. In light of these uncertainties, we simulate with minimum, medium, and maximal values of <inline-formula><mml:math id="inf20"><mml:msub><mml:mi>R</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf21"><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, for a total of 9 cases, as shown in <xref ref-type="fig" rid="fig25">Figure 25(b)</xref>. All are needed since the resistance parameters interact non-linearly. We fix the value of <inline-formula><mml:math id="inf22"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula> at 0.01 F/m<sup>2</sup> since this value is determined by the membrane thickness and is not expected to vary from cell to cell (<xref ref-type="bibr" rid="bib58">Kandel et al., 2000</xref>). The results over the parameter range are shown in <xref ref-type="fig" rid="fig25">Figure 25(b)</xref> for the case of the EPG neuron above for delay from the gall to the PB. The intra-compartment and between-compartment values are well separated for any value of the parameters (not shown).</p><table-wrap id="table6" position="float"><label>Table 6.</label><caption><title>Values reported in the literature.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Reference</th><th><inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi><mml:mo>⋅</mml:mo><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mi mathvariant="normal">m</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf25"><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:math></inline-formula>, F/m<sup>2</sup></th></tr></thead><tbody><tr><td>Borst (<xref ref-type="bibr" rid="bib10">Borst and Haag, 1996</xref>), CH cells</td><td>0.60</td><td>0.25</td><td>0.015</td></tr><tr><td>Borst (<xref ref-type="bibr" rid="bib10">Borst and Haag, 1996</xref>), HS cells</td><td>0.40</td><td>0.20</td><td>0.009</td></tr><tr><td>Borst (<xref ref-type="bibr" rid="bib10">Borst and Haag, 1996</xref>), VS cells</td><td>0.40</td><td>0.20</td><td>0.008</td></tr><tr><td>Gouwens (<xref ref-type="bibr" rid="bib33">Gouwens and Wilson, 2009</xref>), DM1 cell 1</td><td>1.62</td><td>0.83</td><td>0.026</td></tr><tr><td>Gouwens (<xref ref-type="bibr" rid="bib33">Gouwens and Wilson, 2009</xref>), DM1 cell 2</td><td>1.02</td><td>2.04</td><td>0.015</td></tr><tr><td>Gouwens (<xref ref-type="bibr" rid="bib33">Gouwens and Wilson, 2009</xref>), DM1 cell 3</td><td>2.66</td><td>2.08</td><td>0.008</td></tr><tr><td>Gouwens (<xref ref-type="bibr" rid="bib33">Gouwens and Wilson, 2009</xref>), dendrite 1</td><td>2.44</td><td>1.92</td><td>0.008</td></tr><tr><td>Gouwens (<xref ref-type="bibr" rid="bib33">Gouwens and Wilson, 2009</xref>), dendrite 2</td><td>2.66</td><td>2.08</td><td>0.008</td></tr><tr><td>Gouwens (<xref ref-type="bibr" rid="bib33">Gouwens and Wilson, 2009</xref>), dendrite 3</td><td>3.11</td><td>2.64</td><td>0.006</td></tr><tr><td>Cuntz (<xref ref-type="bibr" rid="bib20">Cuntz et al., 2013</xref>), HS cells</td><td>4.00</td><td>0.82</td><td>0.006</td></tr><tr><td>Meier (<xref ref-type="bibr" rid="bib78">Meier and Borst, 2019</xref>), CT1 cells</td><td>4.00</td><td>0.80</td><td>0.006</td></tr></tbody></table></table-wrap><p>Programs that deduce synaptic strength and sign by fitting a computed response to a connectome and measured electrical or calcium imaging data (<xref ref-type="bibr" rid="bib118">Tschopp et al., 2018</xref>) may at some point require estimates of the delays within cells. If this is required, the above results suggest this could be accomplished with reasonable accuracy with a compartment-to-compartment delay table and two additional parameters per neuron, <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>R</mml:mi><mml:mi>A</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>R</mml:mi><mml:mi>M</mml:mi></mml:msub></mml:math></inline-formula>. This is relatively few new parameters in addition to the many synaptic strengths already fitted.</p><p>A number of neurons have parallel connections in separate compartments (see <xref ref-type="fig" rid="fig24">Figure 24(b)</xref>). This motif is common in the fly’s brain – about 5% of all connections having a strength ≥6 are spread across two or more non-adjacent compartments. Given the increased delays and lower amplitudes of cross-compartment responses, this type of interaction differs electrically from those in which all connections are contained in a single compartment. A point neuron model cannot generate an accurate response for such connections – a synapse in region A will result in a fast response in A and a slower, smaller response in B, and vice versa, even though both of these events involve communication between the same two neurons. It is not known if this configuration has a significant influence on the neurons’ operation.</p><p>From these models, we conclude (a) the compartment structure of the fly brain shows up directly in the electrical response of the neurons, and (b) the compartment structure, although defined anatomically, matches that of the electrical response. From the clear separation in <xref ref-type="fig" rid="fig25">Figure 25</xref>, it is likely that the same compartment definitions could be found starting with the electrical response, although we have not tried this. (c) These results suggest a low dimensional model for neural operation, at least in the linear region. A small region-to-region matrix can represent the delays and amplitudes well. (d) Absolute delays depend strongly (but in a very predictable manner) on the values of axial and membrane resistance, which can vary both from animal to animal and from cell to cell. (e) Neurons that have parallel connections in separate compartments have a different electrical response than they would have with the same total number of synapses in a single compartment.</p></sec><sec id="s1-31"><title>Rent’s rule analysis</title><p>Rent’s rule (<xref ref-type="bibr" rid="bib64">Lanzerotti et al., 2005</xref>) is an empirical observation that in human designed computing systems, when the system is packed as tightly as possible, at every level of the hierarchy the required communication (the number of pins) scales as a power law of the amount of contained computation, measured in gates. Rent’s rule is an observed relationship, not derived from underlying theory, and the relationship is not exact and still contains scatter. A biological equivalent might be the observation that brain size tends to vary as a power law of body size (<xref ref-type="bibr" rid="bib39">Harvey and Krebs, 1990</xref>), across a wide range of species occupying very different ecological and behavioral niches. Rent’s rule is roughly true over many orders of magnitude in scale, and for almost every system in which it has been measured. Somewhat surprisingly, Rent’s rule applies almost independently of the function performed by the computation being performed, and at every level of a hierarchical system. It also applies whether the compactness criterion is minimization of communication (partitioning) or physical close packing.</p><p>Rent’s rule is expressed as<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>*</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>b</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula>where <italic>a</italic> is a scale factor (typically in the range 1–4), and <italic>b</italic> is the ‘Rent exponent’ describing how the number of connections to the compartment varies as a function of the amount of computation performed in the compartment. The Rent exponent has a theoretical range of 0.0 to 1.0, where 0 represents a constant number of connections, with no dependence on the amount of computation performed, and 1.0 represents a circuit in which every computation is visible on a connection. Human designed computational systems occupy almost the full range, from spreadsheets in which every computation is visible, to largely serial systems in which minimizing communication (pins) is critical. This relationship is shown in <xref ref-type="fig" rid="fig26">Figure 26</xref>. However, when the overriding criterion is that the system must be packed as tightly as possible, Rent observed that the exponent of the power law falls in a close range of roughly 0.5–0.7.</p><fig id="fig26" position="float"><label>Figure 26.</label><caption><title>Rent’s rule for the hemibrain.</title><p>The yellow region encompasses the theoretical bounds for computation. Four varieties of human-designed systems are shown. Those designed for visibility into computation achieve the upper bound, while those designed for minimum communication approach the lower bounds (Microprocessors ST7LU55, LPC1102, and STM32). Human designed systems where efficient packing is the main criterion occupy the shaded area (in 2D and 3D). The characteristics of the primary compartments completely contained in the reconstructed volume are shown with alphanumeric labels. The hemibrain compartments fall very nearly in the same range as human designed systems designed for efficient packing. Data available in <xref ref-type="supplementary-material" rid="fig26sdata1">Figure 26—source data 1</xref>.</p><p><supplementary-material id="fig26sdata1"><label>Figure 26—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="fig26">Figure 26</xref>.</title><p>The first column is the compartment name, the second the number of TBars contained, and the fifth column the number of connections.</p></caption><media mime-subtype="plain" mimetype="text" xlink:href="elife-57443-fig26-data1-v3.txt"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-fig26-v3.tif"/></fig><p>For electrical circuits, the computation is measured in gates, and the connections are measured by pin count. These ranges are shown in <xref ref-type="fig" rid="fig26">Figure 26</xref> for circuits that are roughly the size of the fly’s brain, packed in either two (<xref ref-type="bibr" rid="bib129">Yang et al., 2001</xref>) or three (<xref ref-type="bibr" rid="bib21">Das et al., 2004</xref>) dimensions.</p><p>Also shown in this plot are the values for the fly’s brain computational regions. In this case, the computation is measured as the number of contained T-bars, and the connection count is the number of neurons that have at least one synapse both inside and outside the compartment. (Very similar results are obtained if the computation is measured as the number of PSDs, or the number of unique connection pairs). Almost all the fly brain compartments fall well within the range of exponents expected for packing-dominated systems, while the ellipsoid body (EB) falls just outside the expected area. This is perhaps due to the large number of strongly connected clique-containing circuits in the ellipsoid body (see <xref ref-type="table" rid="table5">Table 5</xref>), since such circuits have relatively few connections for the amount of synapses they contain.</p><p>Both human designed and biological systems have huge incentives to pack their computation as tightly as possible. A tighter packing of the same computation yields faster operation, lower energy consumption, less material cost, and lower mass. A natural speculation, therefore, is that both the human-designed and evolved systems are dominated by packing considerations, and that both have found similar solutions.</p></sec><sec id="s1-32"><title>Conclusions and future work</title><p>In this work, we have achieved a dream of anatomists that is more than a century old. For at least the central brain of at least one animal with a complex brain and sophisticated behavior, we have a complete census of all the neurons and all the cell types that constitute the brain, a definitive atlas of the regions in which they reside, and a graph representing how they are connected.</p><p>To achieve this, we have made improvements to every stage of the reconstruction process. Better means of sample preparation, imaging, alignment, segmentation, synapse finding, and proofreading are all summarized in this work and will form the basis of yet larger and faster reconstructions in the future.</p><p>We have provided the data for all the circuits of the central brain, at least as defined by nerve cells and chemical synapses. This includes not only circuits of regions that are already the subject of extensive study, but also a trove of circuits whose structure and function are yet unknown.</p><p>We have provided a public resource that should be a huge help to all who study fly neural circuits. Finding upstream and downstream partners, a task that until now has typically taken months of challenging experiments, is now replaced by a lookup on a publicly available web site. Detailed circuits, which used to require considerable patience, expertise, and expertise to acquire, are now available for the cost of an internet query.</p><p>More widely, a dense connectome is a valuable resource for all neuroscientists, enabling novel, system-wide analyses, as well as suggesting roles for specific pathways. A surprising revelation is the richness of anatomical synaptic engagements, which far exceeds pathways required to support identified fly behaviors, and suggests that most behaviors have yet to be identified.</p><p>Finally, we have started the process of analyzing the connectome, though much remains to be done. We have quantified the difference between computational compartments, determined that the distribution of strengths is different from that reported in mammals, discovered cliques and other structures and where these occur, examined the effect of compartmentalization on electrical properties, and provided evidence that the wiring of the brain is consistent with optimizing packing.</p><p>Many of the extensions of this work are obvious and already underway. Not all regions of the hemibrain have been read to the highest accuracy possible, insofar as we have concentrated first on the regions overlapping with other projects, such as the central complex and the mushroom body. We will continue to update other sections of the brain, and distributed circuits such as clock and modulatory neurons that are not confined to one region, but spread throughout the brain.</p><p>There is much more to be learned about the graph properties of the brain, and how these relate to its function.</p><p>The two sexes of the <italic>Drosophila</italic> brain are known to differ (<xref ref-type="bibr" rid="bib5">Auer and Benton, 2016</xref>). so that reconstructing a male fly is critical to compare the circuits of the two sexes. A ventral nerve cord (VNC) should be reconstructed, preferably attached to the brain of the same individual, since the circuits in the VNC are known to be crucial for fly motor behavior (<xref ref-type="bibr" rid="bib130">Yellman et al., 1997</xref>). At least one optic lobe should be included to simplify analysis of visual inputs to the central brain. A whole brain connectome is preferable to the hemibrain, since then most cell types would have at least two examples, left and right, which would lend increased confidence to our reconstructions. It would also provide complete reconstruction to the many neurons that span the brain, especially the clock and modulatory neurons, and are incomplete in the hemibrain. These four goals are combined in a project that is currently underway, to image and reconstruct an entire male central nervous system (CNS) including the VNC and optic lobes.</p><p>We continue to improve sample preparation, imaging, and reconstruction both to decrease the efforts expended on reconstruction and to speed reconstruction of more specimens. Improvements include multi-beam imaging, etching methods (<xref ref-type="bibr" rid="bib42">Hayworth et al., 2020</xref>) that can handle larger areas, and yet better reconstruction techniques. These improvements, however, will still rely on FIB-SEM technology, and additional methods will likely be required to fill in other information. Gap junctions will continue to be difficult to see in FIB-SEM, and other methods such as optical labeling, expansion microscopy, and RNA-SEQ (to find which neurons express gap junction proteins) will be required. Methods for estimating the extent of diffusion of the secreted modulatory transmitters and gaseous signal molecules such as NO remain to be established. Different staining methods (and expression driver lines) may be needed to study glia to the same extent we currently study neurons. A wide variety of techniques will be needed to understand the subcellular architecture of the neurons we have reconstructed. Finally, larger animal brains beckon, such as the brain of a mouse and eventually a human. The data we present here is only a start.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank our colleagues at Janelia and the broader connectomics field for many helpful discussions and suggestions during the course of this work. We thank David Peale, Patrick Lee, and the Janelia Experimental Technology group for supporting the modifications of the FIB-SEM systems. Goran Ceric and other members of the Scientific Computing Systems and Scientific Computing Software Teams at Janelia provided critical support throughout this work. The Janelia Facilities group was essential in proving a stable environment for image collection. We thank Julia Buhmann and Jan Funke for help in implementing the synapse prediction algorithm described in <xref ref-type="bibr" rid="bib12">Buhmann et al., 2019</xref>. Many colleagues at Janelia and Cambridge tested the performance of Neuprint performance prior to its release.</p><p>We thank Elizabeth Marin, Tomke Stuerner, Sridhar Jagannathan, Shahar Frechter (Cambridge University/MRC LMB) for additional contributions to the identification/typing and naming of all the neurons associated with the antennal lobe and lateral horn, Rachel Wilson and Asa Barth-Maron (Harvard University) for the typing and naming of antennal lobe local neurons, Nils Otto (Oxford University), Georgia Dempsey and Ildiko Stark (Cambridge University) for typing of some mushroom body dopaminergic neurons, Thomas Riemensperger (University of Cologne) for the identification of known aminergic and peptidergic neurons, Nik Drummond, Markus Pleijzier, Konrad Heinz (Cambridge University) and Joe Hsu (Janelia) for additional tracing of olfactory system neurons, Kaiyu Wang and Barry Dickson (Janelia) for identification of fruitless expressing neurons, and Aljosha Nern, Michael B. Reiser, and Arthur Zhao (Janelia) for the identification of optic lobe neurons.</p><p>Major financial support for this work was provided by the Howard Hughes Medical Institute and Google Research. Feng Li, Marta Costa, Philipp Schlegel, and approximately 10% of the proofreading team were supported by a Wellcome Trust Collaborative Award (203261/Z/16/Z).</p></ack><sec id="s2" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>is an employee of Google.</p></fn><fn fn-type="COI-statement" id="conf3"><p>is an employee of Google.</p></fn><fn fn-type="COI-statement" id="conf4"><p>is an employee of Google.</p></fn><fn fn-type="COI-statement" id="conf5"><p>is an employee of Google.</p></fn><fn fn-type="COI-statement" id="conf6"><p>is an employee of Google.</p></fn><fn fn-type="COI-statement" id="conf7"><p>is an employee of Google.</p></fn><fn fn-type="COI-statement" id="conf8"><p>is an employee of Google.</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing, Image alignment, analysis software, connectivity analysis</p></fn><fn fn-type="con" id="con2"><p>Investigation, Methodology, Writing - original draft, Writing - review and editing, Developed imaging hardware; imaged the sample</p></fn><fn fn-type="con" id="con3"><p>Software, Validation, Investigation, Visualization, Methodology, Developed and applied segmentation and tissue classification</p></fn><fn fn-type="con" id="con4"><p>Validation, Investigation, Methodology, Developed sample preparation methods; fixed and stained the sample</p></fn><fn fn-type="con" id="con5"><p>Formal analysis, Validation, Investigation, Visualization, Methodology, Defined brain regions and cell types; biological interpretation and analysis</p></fn><fn fn-type="con" id="con6"><p>Validation, Investigation, Visualization, Methodology, Writing - original draft, Developed hot-knife method; cut and images sample</p></fn><fn fn-type="con" id="con7"><p>Software, Validation, Investigation, Visualization, Methodology, Writing - original draft, Developed and applied methods to identify synapses</p></fn><fn fn-type="con" id="con8"><p>Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Defined regions and cell types; biological interpretation and analysis</p></fn><fn fn-type="con" id="con9"><p>Software, Formal analysis, Investigation, Visualization, Methodology, Developed and applied segmentation methods, developed analysis and visualization pipeline software</p></fn><fn fn-type="con" id="con10"><p>Software, Formal analysis, Investigation, Visualization, Methodology, Wrote proofreading and analysis software</p></fn><fn fn-type="con" id="con11"><p>Data curation, Software, Visualization, Methodology, Wrote analysis and visualization software</p></fn><fn fn-type="con" id="con12"><p>Software, Investigation, Visualization, Methodology, Wrote analysis and visualization software</p></fn><fn fn-type="con" id="con13"><p>Conceptualization, Data curation, Software, Investigation, Visualization, Methodology, Wrote and managed the versioned data system</p></fn><fn fn-type="con" id="con14"><p>Data curation, Software, Validation, Visualization, Wrote proofreading and analysis software</p></fn><fn fn-type="con" id="con15"><p>Software, Investigation, Visualization, Methodology, Wrote proofreading and data analysis software</p></fn><fn fn-type="con" id="con16"><p>Software, Investigation, Image alignment and flattening</p></fn><fn fn-type="con" id="con17"><p>Software, Investigation, Visualization, Methodology, Developed analysis, visualization, and pipeline software</p></fn><fn fn-type="con" id="con18"><p>Software, Investigation, Visualization, Methodology, Developed EM-Optical mapping</p></fn><fn fn-type="con" id="con19"><p>Software, Investigation, Visualization, Methodology, Developed proofreading and analysis software</p></fn><fn fn-type="con" id="con20"><p>Software, Investigation, Methodology, Image alignment and flattening</p></fn><fn fn-type="con" id="con21"><p>Software, Investigation, Visualization, Methodology, Proofreading and analysis software</p></fn><fn fn-type="con" id="con22"><p>Software, Investigation, Visualization, Methodology, Wrote and applied image alignment software</p></fn><fn fn-type="con" id="con23"><p>Software, Investigation, Visualization, Methodology, Developed and applied tissue classification approaches and analysis, visualization and pipeline software</p></fn><fn fn-type="con" id="con24"><p>Software, Investigation, Visualization, Methodology, Developed and applied segmentation approaches</p></fn><fn fn-type="con" id="con25"><p>Software, Investigation, Visualization, Methodology, Developed analysis, visualization, and pipeline software</p></fn><fn fn-type="con" id="con26"><p>Software, Investigation, Visualization, Wrote proofreading and analysis software</p></fn><fn fn-type="con" id="con27"><p>Software, Investigation, Visualization, Methodology, Wrote proofreading and analysis software</p></fn><fn fn-type="con" id="con28"><p>Software, Investigation, Visualization, Methodology, Developed EM-Optical mapping</p></fn><fn fn-type="con" id="con29"><p>Software, Validation, Investigation, Visualization, Methodology, Wrote image alignment software and aligned data; wrote proofreading and analysis software</p></fn><fn fn-type="con" id="con30"><p>Software, Investigation, Visualization, Methodology, Defined regions and cell types</p></fn><fn fn-type="con" id="con31"><p>Data curation, Validation, Investigation, Visualization, Defined brain regions and cell types</p></fn><fn fn-type="con" id="con32"><p>Software, Investigation, Visualization, Methodology, Biological interpretation and analysis; defined brain regions and cell types</p></fn><fn fn-type="con" id="con33"><p>Validation, Investigation, Visualization, Methodology, Defined brain regions and cell types</p></fn><fn fn-type="con" id="con34"><p>Software, Supervision, Visualization, Methodology, Developed pipeline analysis and software</p></fn><fn fn-type="con" id="con35"><p>Software, Investigation, Visualization, Methodology, Wrote proofreading and analysis software</p></fn><fn fn-type="con" id="con36"><p>Software, Validation, Investigation, Visualization, Methodology, Proofreading analytics</p></fn><fn fn-type="con" id="con37"><p>Software, Supervision, Validation, Investigation, Visualization, Methodology, Proofreading analytics</p></fn><fn fn-type="con" id="con38"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con39"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con40"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con41"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con42"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con43"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con44"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con45"><p>Validation, Investigation, Proofreading and figures</p></fn><fn fn-type="con" id="con46"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con47"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con48"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con49"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con50"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con51"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con52"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con53"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con54"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con55"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con56"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con57"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con58"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con59"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con60"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con61"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con62"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con63"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con64"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con65"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con66"><p>Validation, Investigation, Methodology, Proofreading</p></fn><fn fn-type="con" id="con67"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con68"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con69"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con70"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con71"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con72"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con73"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con74"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con75"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con76"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con77"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con78"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con79"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con80"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con81"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con82"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con83"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con84"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con85"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con86"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con87"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con88"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con89"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con90"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con91"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con92"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con93"><p>Validation, Investigation, Proofreading</p></fn><fn fn-type="con" id="con94"><p>Software, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Project administration, Defined brain regions and cell types</p></fn><fn fn-type="con" id="con95"><p>Software, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Project administration, Defined brain regions and cell types; managed proofreading; biological interpretation</p></fn><fn fn-type="con" id="con96"><p>Resources, Supervision, Validation, Investigation, Visualization, Methodology, Project administration, Biological interpretation and defined brain regions and cell types; managed proofreading</p></fn><fn fn-type="con" id="con97"><p>Resources, Supervision, Validation, Investigation, Visualization, Methodology, Project administration, Biological interpretation; managed proofreading</p></fn><fn fn-type="con" id="con98"><p>Conceptualization, Resources, Writing - review and editing, Biological interpretation and analysis</p></fn><fn fn-type="con" id="con99"><p>Data curation, Supervision, Validation, Investigation, Visualization, Methodology, Writing - review and editing, Defined brain regions and cell typing; biological interpretation and analysis</p></fn><fn fn-type="con" id="con100"><p>Data curation, Supervision, Investigation, Visualization, Methodology, Writing - review and editing, Defined brain regions and cell types; biological interpretation and analysis</p></fn><fn fn-type="con" id="con101"><p>Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Defined brain regions and cell types; managed cell typing</p></fn><fn fn-type="con" id="con102"><p>Software, Validation, Investigation, Visualization, Methodology, Writing - original draft, Image alignment</p></fn><fn fn-type="con" id="con103"><p>Conceptualization, Resources, Project administration, Managed overall effort</p></fn><fn fn-type="con" id="con104"><p>Conceptualization, Formal analysis, Supervision, Validation, Investigation, Methodology, Writing - original draft, Project administration, Writing - review and editing, Biological interpretation and analysis</p></fn><fn fn-type="con" id="con105"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing - original draft, Project administration, Writing - review and editing, Biological interpretation and analysis; managed overall effort</p></fn><fn fn-type="con" id="con106"><p>Conceptualization, Resources, Supervision, Validation, Investigation, Visualization, Methodology, Project administration, Developed imaging hardware and imaged sample</p></fn><fn fn-type="con" id="con107"><p>Resources, Software, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing, Developed and applied tissue classification and segmentation approaches</p></fn><fn fn-type="con" id="con108"><p>Conceptualization, Resources, Software, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing, Wrote proofreading and analysis software; connectivity analysis; managed overall effort</p></fn></fn-group></sec><sec id="s3" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Spreadsheet of instances of sparse-to-many connections.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-supp1-v3.xlxs"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-57443-transrepform-v3.docx"/></supplementary-material></sec><sec id="s4" sec-type="data-availability"><title>Data availability</title><p>There is no institutional resource for hosting connectome data. Therefore we host it ourselves on a publicly accessible web site, <ext-link ext-link-type="uri" xlink:href="https://neuprint.janelia.org">https://neuprint.janelia.org</ext-link>, also accessible via <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25378/janelia.11676099.v2">https://doi.org/10.25378/janelia.11676099.v2</ext-link>. We commit to keeping this available for at least 10 years, and provide procedures where users can copy any or all of it to their own computer. Login is via any Google account; users who wish to remain anonymous can create a separate account for access purposes only.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ache</surname> <given-names>JM</given-names></name><name><surname>Polsky</surname> <given-names>J</given-names></name><name><surname>Alghailani</surname> <given-names>S</given-names></name><name><surname>Parekh</surname> <given-names>R</given-names></name><name><surname>Breads</surname> <given-names>P</given-names></name><name><surname>Peek</surname> <given-names>MY</given-names></name><name><surname>Bock</surname> <given-names>DD</given-names></name><name><surname>von Reyn</surname> <given-names>CR</given-names></name><name><surname>Card</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural basis for looming size and velocity encoding in the <italic>Drosophila</italic> giant fiber escape pathway</article-title><source>Current Biology</source><volume>29</volume><fpage>1073</fpage><lpage>1081</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.01.079</pub-id><pub-id pub-id-type="pmid">30827912</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altschul</surname> <given-names>SF</given-names></name><name><surname>Gish</surname> <given-names>W</given-names></name><name><surname>Miller</surname> <given-names>W</given-names></name><name><surname>Myers</surname> <given-names>EW</given-names></name><name><surname>Lipman</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Basic local alignment search tool</article-title><source>Journal of Molecular Biology</source><volume>215</volume><fpage>403</fpage><lpage>410</lpage><pub-id pub-id-type="doi">10.1016/S0022-2836(05)80360-2</pub-id><pub-id pub-id-type="pmid">2231712</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ascoli</surname> <given-names>GA</given-names></name><name><surname>Donohue</surname> <given-names>DE</given-names></name><name><surname>Halavi</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>NeuroMorpho.Org: a central resource for neuronal morphologies</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>9247</fpage><lpage>9251</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2055-07.2007</pub-id><pub-id pub-id-type="pmid">17728438</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Hattori</surname> <given-names>D</given-names></name><name><surname>Yu</surname> <given-names>Y</given-names></name><name><surname>Johnston</surname> <given-names>RM</given-names></name><name><surname>Iyer</surname> <given-names>NA</given-names></name><name><surname>Ngo</surname> <given-names>TT</given-names></name><name><surname>Dionne</surname> <given-names>H</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Axel</surname> <given-names>R</given-names></name><name><surname>Tanimoto</surname> <given-names>H</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The neuronal architecture of the mushroom body provides a logic for associative learning</article-title><source>eLife</source><volume>3</volume><elocation-id>e04577</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.04577</pub-id><pub-id pub-id-type="pmid">25535793</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auer</surname> <given-names>TO</given-names></name><name><surname>Benton</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Sexual circuitry in <italic>Drosophila</italic></article-title><source>Current Opinion in Neurobiology</source><volume>38</volume><fpage>18</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.004</pub-id><pub-id pub-id-type="pmid">26851712</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Roberts</surname> <given-names>RJV</given-names></name><name><surname>Drummond</surname> <given-names>N</given-names></name><name><surname>Tamimi</surname> <given-names>IFM</given-names></name><name><surname>Turnbull</surname> <given-names>R</given-names></name><name><surname>Zhao</surname> <given-names>X</given-names></name><name><surname>Marin</surname> <given-names>EC</given-names></name><name><surname>Popovici</surname> <given-names>PD</given-names></name><name><surname>Dhawan</surname> <given-names>S</given-names></name><name><surname>Jamasb</surname> <given-names>A</given-names></name><name><surname>Javier</surname> <given-names>A</given-names></name><name><surname>Serratosa Capdevila</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Waddell</surname> <given-names>S</given-names></name><name><surname>Bock</surname> <given-names>DD</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Complete connectomic reconstruction of olfactory projection neurons in the fly brain</article-title><source>Current Biology</source><volume>30</volume><fpage>3183</fpage><lpage>3199</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.06.042</pub-id><pub-id pub-id-type="pmid">32619485</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergland</surname> <given-names>AO</given-names></name><name><surname>Chae</surname> <given-names>HS</given-names></name><name><surname>Kim</surname> <given-names>YJ</given-names></name><name><surname>Tatar</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Fine-scale mapping of natural variation in fly fecundity identifies neuronal domain of expression and function of an aquaporin</article-title><source>PLOS Genetics</source><volume>8</volume><elocation-id>e1002631</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pgen.1002631</pub-id><pub-id pub-id-type="pmid">22509142</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bogovic</surname> <given-names>JA</given-names></name><name><surname>Hanslovsky</surname> <given-names>P</given-names></name><name><surname>Wong</surname> <given-names>A</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Robust registration of calcium images by learned contrast synthesis</article-title><conf-name>IEEE 13th International Symposium on Biomedical Imaging (ISBI)</conf-name><fpage>1123</fpage><lpage>1126</lpage><pub-id pub-id-type="doi">10.1109/ISBI.2016.7493463</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogovic</surname> <given-names>JA</given-names></name><name><surname>Otsuna</surname> <given-names>H</given-names></name><name><surname>Heinrich</surname> <given-names>L</given-names></name><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Jeter</surname> <given-names>J</given-names></name><name><surname>Meissner</surname> <given-names>GW</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Colonell</surname> <given-names>J</given-names></name><name><surname>Malkesman</surname> <given-names>O</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An unbiased template of the <italic>Drosophila</italic> brain and ventral nerve cord</article-title><source>PLOS ONE</source><comment>In press</comment></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borst</surname> <given-names>A</given-names></name><name><surname>Haag</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The intrinsic electrophysiological characteristics of fly lobula plate tangential cells: I. passive membrane properties</article-title><source>Journal of Computational Neuroscience</source><volume>3</volume><fpage>313</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1007/BF00161091</pub-id><pub-id pub-id-type="pmid">9001975</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Brglez</surname> <given-names>F</given-names></name><name><surname>Bryan</surname> <given-names>D</given-names></name><name><surname>Kozminski</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Combinational profiles of sequential benchmark circuits</article-title><conf-name>IEEE International Symposium on Circuits and Systems</conf-name><fpage>1929</fpage><lpage>1934</lpage><pub-id pub-id-type="doi">10.1109/ISCAS.1989.100747</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Buhmann</surname> <given-names>J</given-names></name><name><surname>Sheridan</surname> <given-names>A</given-names></name><name><surname>Gerhard</surname> <given-names>S</given-names></name><name><surname>Krause</surname> <given-names>R</given-names></name><name><surname>Nguyen</surname> <given-names>T</given-names></name><name><surname>Heinrich</surname> <given-names>L</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Lee</surname> <given-names>W-C</given-names></name><name><surname>Wilson</surname> <given-names>R</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name><name><surname>Bock</surname> <given-names>D</given-names></name><name><surname>Turaga</surname> <given-names>S</given-names></name><name><surname>Cook</surname> <given-names>M</given-names></name><name><surname>Funke</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Automatic detection of synaptic partners in a whole-brain <italic>Drosophila</italic> EM dataset</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2019.12.12.874172</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busch</surname> <given-names>S</given-names></name><name><surname>Selcho</surname> <given-names>M</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name><name><surname>Tanimoto</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A map of octopaminergic neurons in the <italic>Drosophila</italic> brain</article-title><source>The Journal of Comparative Neurology</source><volume>513</volume><fpage>643</fpage><lpage>667</lpage><pub-id pub-id-type="doi">10.1002/cne.21966</pub-id><pub-id pub-id-type="pmid">19235225</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cachero</surname> <given-names>S</given-names></name><name><surname>Ostrovsky</surname> <given-names>AD</given-names></name><name><surname>Yu</surname> <given-names>JY</given-names></name><name><surname>Dickson</surname> <given-names>BJ</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sexual dimorphism in the fly brain</article-title><source>Current Biology</source><volume>20</volume><fpage>1589</fpage><lpage>1601</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.07.045</pub-id><pub-id pub-id-type="pmid">20832311</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carnevale</surname> <given-names>NT</given-names></name><name><surname>Hines</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>The NEURON Book</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511541612</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname> <given-names>AS</given-names></name><name><surname>Lin</surname> <given-names>CY</given-names></name><name><surname>Chuang</surname> <given-names>CC</given-names></name><name><surname>Chang</surname> <given-names>HM</given-names></name><name><surname>Hsieh</surname> <given-names>CH</given-names></name><name><surname>Yeh</surname> <given-names>CW</given-names></name><name><surname>Shih</surname> <given-names>CT</given-names></name><name><surname>Wu</surname> <given-names>JJ</given-names></name><name><surname>Wang</surname> <given-names>GT</given-names></name><name><surname>Chen</surname> <given-names>YC</given-names></name><name><surname>Wu</surname> <given-names>CC</given-names></name><name><surname>Chen</surname> <given-names>GY</given-names></name><name><surname>Ching</surname> <given-names>YT</given-names></name><name><surname>Lee</surname> <given-names>PC</given-names></name><name><surname>Lin</surname> <given-names>CY</given-names></name><name><surname>Lin</surname> <given-names>HH</given-names></name><name><surname>Wu</surname> <given-names>CC</given-names></name><name><surname>Hsu</surname> <given-names>HW</given-names></name><name><surname>Huang</surname> <given-names>YA</given-names></name><name><surname>Chen</surname> <given-names>JY</given-names></name><name><surname>Chiang</surname> <given-names>HJ</given-names></name><name><surname>Lu</surname> <given-names>CF</given-names></name><name><surname>Ni</surname> <given-names>RF</given-names></name><name><surname>Yeh</surname> <given-names>CY</given-names></name><name><surname>Hwang</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Three-dimensional reconstruction of brain-wide wiring networks in <italic>Drosophila</italic> at single-cell resolution</article-title><source>Current Biology</source><volume>21</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.11.056</pub-id><pub-id pub-id-type="pmid">21129968</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Clements</surname> <given-names>J</given-names></name><name><surname>Dolafi</surname> <given-names>T</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Neubarth</surname> <given-names>NL</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>NeuPrint: analysis tools for EM connectomics</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.16.909465</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Manton</surname> <given-names>JD</given-names></name><name><surname>Ostrovsky</surname> <given-names>AD</given-names></name><name><surname>Prohaska</surname> <given-names>S</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>NBLAST: rapid, sensitive comparison of neuronal structure and construction of neuron family databases</article-title><source>Neuron</source><volume>91</volume><fpage>293</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.012</pub-id><pub-id pub-id-type="pmid">27373836</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Couto</surname> <given-names>A</given-names></name><name><surname>Alenius</surname> <given-names>M</given-names></name><name><surname>Dickson</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Molecular, anatomical, and functional organization of the <italic>Drosophila</italic> olfactory system</article-title><source>Current Biology</source><volume>15</volume><fpage>1535</fpage><lpage>1547</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2005.07.034</pub-id><pub-id pub-id-type="pmid">16139208</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuntz</surname> <given-names>H</given-names></name><name><surname>Forstner</surname> <given-names>F</given-names></name><name><surname>Schnell</surname> <given-names>B</given-names></name><name><surname>Ammer</surname> <given-names>G</given-names></name><name><surname>Raghu</surname> <given-names>SV</given-names></name><name><surname>Borst</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Preserving neural function under extreme scaling</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e71540</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0071540</pub-id><pub-id pub-id-type="pmid">23977069</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Das</surname> <given-names>S</given-names></name><name><surname>Chandrakasan</surname> <given-names>AP</given-names></name><name><surname>Reif</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Calibration of Rent's rule models for three-dimensional integrated circuits</article-title><source>IEEE Transactions on Very Large Scale Integration (VLSI) Systems</source><volume>12</volume><fpage>359</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1109/TVLSI.2004.825833</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname> <given-names>MJ</given-names></name><name><surname>Frechter</surname> <given-names>S</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Dan</surname> <given-names>C</given-names></name><name><surname>Huoviala</surname> <given-names>P</given-names></name><name><surname>Roberts</surname> <given-names>RJ</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Dhawan</surname> <given-names>S</given-names></name><name><surname>Tabano</surname> <given-names>R</given-names></name><name><surname>Dionne</surname> <given-names>H</given-names></name><name><surname>Christoforou</surname> <given-names>C</given-names></name><name><surname>Close</surname> <given-names>K</given-names></name><name><surname>Sutcliffe</surname> <given-names>B</given-names></name><name><surname>Giuliani</surname> <given-names>B</given-names></name><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Ihrke</surname> <given-names>G</given-names></name><name><surname>Meissner</surname> <given-names>GW</given-names></name><name><surname>Bock</surname> <given-names>DD</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neurogenetic dissection of the <italic>Drosophila</italic> lateral horn reveals major outputs, diverse behavioural functions, and interactions with the mushroom body</article-title><source>eLife</source><volume>8</volume><elocation-id>e43079</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.43079</pub-id><pub-id pub-id-type="pmid">31112130</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dorkenwald</surname> <given-names>S</given-names></name><name><surname>Turner</surname> <given-names>NL</given-names></name><name><surname>Macrina</surname> <given-names>T</given-names></name><name><surname>Lee</surname> <given-names>K</given-names></name><name><surname>Lu</surname> <given-names>R</given-names></name><name><surname>Wu</surname> <given-names>J</given-names></name><name><surname>Bodor</surname> <given-names>AL</given-names></name><name><surname>Bleckert</surname> <given-names>AA</given-names></name><name><surname>Brittain</surname> <given-names>D</given-names></name><name><surname>Kemnitz</surname> <given-names>N</given-names></name><name><surname>Silversmith</surname> <given-names>WM</given-names></name><name><surname>Ih</surname> <given-names>D</given-names></name><name><surname>Zung</surname> <given-names>J</given-names></name><name><surname>Zlateski</surname> <given-names>A</given-names></name><name><surname>Tartavull</surname> <given-names>I</given-names></name><name><surname>Yu</surname> <given-names>S-C</given-names></name><name><surname>Popovych</surname> <given-names>S</given-names></name><name><surname>Wong</surname> <given-names>W</given-names></name><name><surname>Castro</surname> <given-names>M</given-names></name><name><surname>Jordan</surname> <given-names>CS</given-names></name><name><surname>Wilson</surname> <given-names>AM</given-names></name><name><surname>Froudarakis</surname> <given-names>E</given-names></name><name><surname>Buchanan</surname> <given-names>J</given-names></name><name><surname>Takeno</surname> <given-names>M</given-names></name><name><surname>Torres</surname> <given-names>R</given-names></name><name><surname>Mahalingam</surname> <given-names>G</given-names></name><name><surname>Collman</surname> <given-names>F</given-names></name><name><surname>Schneider-Mizell</surname> <given-names>C</given-names></name><name><surname>Bumbarger</surname> <given-names>DJ</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Becker</surname> <given-names>L</given-names></name><name><surname>Suckow</surname> <given-names>S</given-names></name><name><surname>Reimer</surname> <given-names>J</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name><name><surname>Costa</surname> <given-names>NMda</given-names></name><name><surname>Clay Reid</surname> <given-names>R</given-names></name><name><surname>Sebastian Seung</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Binary and analog variation of synapses between cortical pyramidal neurons</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2019.12.29.890319</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichler</surname> <given-names>K</given-names></name><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Litwin-Kumar</surname> <given-names>A</given-names></name><name><surname>Park</surname> <given-names>Y</given-names></name><name><surname>Andrade</surname> <given-names>I</given-names></name><name><surname>Schneider-Mizell</surname> <given-names>CM</given-names></name><name><surname>Saumweber</surname> <given-names>T</given-names></name><name><surname>Huser</surname> <given-names>A</given-names></name><name><surname>Eschbach</surname> <given-names>C</given-names></name><name><surname>Gerber</surname> <given-names>B</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Truman</surname> <given-names>JW</given-names></name><name><surname>Priebe</surname> <given-names>CE</given-names></name><name><surname>Abbott</surname> <given-names>LF</given-names></name><name><surname>Thum</surname> <given-names>AS</given-names></name><name><surname>Zlatic</surname> <given-names>M</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The complete connectome of a learning and memory centre in an insect brain</article-title><source>Nature</source><volume>548</volume><fpage>175</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1038/nature23455</pub-id><pub-id pub-id-type="pmid">28796202</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enjin</surname> <given-names>A</given-names></name><name><surname>Zaharieva</surname> <given-names>EE</given-names></name><name><surname>Frank</surname> <given-names>DD</given-names></name><name><surname>Mansourian</surname> <given-names>S</given-names></name><name><surname>Suh</surname> <given-names>GS</given-names></name><name><surname>Gallio</surname> <given-names>M</given-names></name><name><surname>Stensmyr</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Humidity sensing in <italic>Drosophila</italic></article-title><source>Current Biology</source><volume>26</volume><fpage>1352</fpage><lpage>1358</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.03.049</pub-id><pub-id pub-id-type="pmid">27161501</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischbach</surname> <given-names>K-F</given-names></name><name><surname>Dittrich</surname> <given-names>APM</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The optic lobe of <italic>Drosophila melanogaster</italic>. I. A golgi analysis of wild-type structure</article-title><source>Cell and Tissue Research</source><volume>258</volume><fpage>441</fpage><lpage>475</lpage><pub-id pub-id-type="doi">10.1007/BF00218858</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fishilevich</surname> <given-names>E</given-names></name><name><surname>Vosshall</surname> <given-names>LB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Genetic and functional subdivision of the <italic>Drosophila</italic> antennal lobe</article-title><source>Current Biology</source><volume>15</volume><fpage>1548</fpage><lpage>1553</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2005.07.066</pub-id><pub-id pub-id-type="pmid">16139209</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fortunato</surname> <given-names>S</given-names></name><name><surname>Hric</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Community detection in networks: a user guide</article-title><source>Physics Reports</source><volume>659</volume><fpage>1</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1016/j.physrep.2016.09.002</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Francis</surname> <given-names>N</given-names></name><name><surname>Green</surname> <given-names>A</given-names></name><name><surname>Guagliardo</surname> <given-names>P</given-names></name><name><surname>Libkin</surname> <given-names>L</given-names></name><name><surname>Lindaaker</surname> <given-names>T</given-names></name><name><surname>Marsault</surname> <given-names>V</given-names></name><name><surname>Plantikow</surname> <given-names>S</given-names></name><name><surname>Rydberg</surname> <given-names>M</given-names></name><name><surname>Selmer</surname> <given-names>P</given-names></name><name><surname>Taylor</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cypher: an evolving query language for property graphs ACM</article-title><conf-name>Proceedings of the 2018 International Conference on Management of Data</conf-name><fpage>1433</fpage><lpage>1445</lpage><pub-id pub-id-type="doi">10.1145/3183713.3190657</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>DD</given-names></name><name><surname>Enjin</surname> <given-names>A</given-names></name><name><surname>Jouandet</surname> <given-names>GC</given-names></name><name><surname>Zaharieva</surname> <given-names>EE</given-names></name><name><surname>Para</surname> <given-names>A</given-names></name><name><surname>Stensmyr</surname> <given-names>MC</given-names></name><name><surname>Gallio</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Early integration of temperature and humidity stimuli in the <italic>Drosophila</italic> brain</article-title><source>Current Biology</source><volume>27</volume><fpage>2381</fpage><lpage>2388</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.06.077</pub-id><pub-id pub-id-type="pmid">28736172</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frechter</surname> <given-names>S</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Tootoonian</surname> <given-names>S</given-names></name><name><surname>Dolan</surname> <given-names>MJ</given-names></name><name><surname>Manton</surname> <given-names>J</given-names></name><name><surname>Jamasb</surname> <given-names>AR</given-names></name><name><surname>Kohl</surname> <given-names>J</given-names></name><name><surname>Bock</surname> <given-names>D</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Functional and anatomical specificity in a higher olfactory centre</article-title><source>eLife</source><volume>8</volume><elocation-id>e44590</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.44590</pub-id><pub-id pub-id-type="pmid">31112127</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallio</surname> <given-names>M</given-names></name><name><surname>Ofstad</surname> <given-names>TA</given-names></name><name><surname>Macpherson</surname> <given-names>LJ</given-names></name><name><surname>Wang</surname> <given-names>JW</given-names></name><name><surname>Zuker</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The coding of temperature in the <italic>Drosophila</italic> brain</article-title><source>Cell</source><volume>144</volume><fpage>614</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2011.01.028</pub-id><pub-id pub-id-type="pmid">21335241</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gouwens</surname> <given-names>NW</given-names></name><name><surname>Wilson</surname> <given-names>RI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Signal propagation in <italic>Drosophila</italic> central neurons</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>6239</fpage><lpage>6249</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0764-09.2009</pub-id><pub-id pub-id-type="pmid">19439602</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname> <given-names>J</given-names></name><name><surname>Adachi</surname> <given-names>A</given-names></name><name><surname>Shah</surname> <given-names>KK</given-names></name><name><surname>Hirokawa</surname> <given-names>JD</given-names></name><name><surname>Magani</surname> <given-names>PS</given-names></name><name><surname>Maimon</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A neural circuit architecture for angular integration in <italic>Drosophila</italic></article-title><source>Nature</source><volume>546</volume><fpage>101</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1038/nature22343</pub-id><pub-id pub-id-type="pmid">28538731</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hallem</surname> <given-names>EA</given-names></name><name><surname>Carlson</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Coding of odors by a receptor repertoire</article-title><source>Cell</source><volume>125</volume><fpage>143</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2006.01.050</pub-id><pub-id pub-id-type="pmid">16615896</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanesch</surname> <given-names>U</given-names></name><name><surname>Fischbach</surname> <given-names>K-F</given-names></name><name><surname>Heisenberg</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Neuronal architecture of the central complex in <italic>Drosophila melanogaster</italic></article-title><source>Cell and Tissue Research</source><volume>257</volume><fpage>343</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1007/BF00261838</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslovsky</surname> <given-names>P</given-names></name><name><surname>Bogovic</surname> <given-names>JA</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Image-based correction of continuous and discontinuous non-planar axial distortion in serial section microscopy</article-title><source>Bioinformatics</source><volume>33</volume><fpage>1379</fpage><lpage>1386</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btw794</pub-id><pub-id pub-id-type="pmid">28453669</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartenstein</surname> <given-names>V</given-names></name><name><surname>Omoto</surname> <given-names>JJ</given-names></name><name><surname>Ngo</surname> <given-names>KT</given-names></name><name><surname>Wong</surname> <given-names>D</given-names></name><name><surname>Kuert</surname> <given-names>PA</given-names></name><name><surname>Reichert</surname> <given-names>H</given-names></name><name><surname>Lovick</surname> <given-names>JK</given-names></name><name><surname>Younossi-Hartenstein</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Structure and development of the subesophageal zone of the <italic>Drosophila</italic> brain. I. segmental architecture, compartmentalization, and lineage anatomy</article-title><source>Journal of Comparative Neurology</source><volume>526</volume><fpage>6</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1002/cne.24287</pub-id><pub-id pub-id-type="pmid">28730682</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>PH</given-names></name><name><surname>Krebs</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Comparing brains</article-title><source>Science</source><volume>249</volume><fpage>140</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1126/science.2196673</pub-id><pub-id pub-id-type="pmid">2196673</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hausen</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1984">1984</year><chapter-title>The lobula-complex of the fly: structure, function and significance in visual behaviour</chapter-title><person-group person-group-type="editor"><name><surname>Ali</surname> <given-names>M. A</given-names></name></person-group><source>Photoreception and Vision in Invertebrates</source><publisher-name>Springer</publisher-name><fpage>523</fpage><lpage>559</lpage><pub-id pub-id-type="doi">10.1007/978-1-4613-2743-1_15</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Knott</surname> <given-names>GW</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Tapia</surname> <given-names>JC</given-names></name><name><surname>Lichtman</surname> <given-names>JW</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Ultrastructurally smooth thick partitioning and volume stitching for large-scale connectomics</article-title><source>Nature Methods</source><volume>12</volume><fpage>319</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3292</pub-id><pub-id pub-id-type="pmid">25686390</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Peale</surname> <given-names>D</given-names></name><name><surname>Januszewski</surname> <given-names>M</given-names></name><name><surname>Knott</surname> <given-names>GW</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Gas cluster ion beam SEM for imaging of large tissue samples with 10 nm isotropic resolution</article-title><source>Nature Methods</source><volume>17</volume><fpage>68</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0641-2</pub-id><pub-id pub-id-type="pmid">31740820</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname> <given-names>K</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Ren</surname> <given-names>S</given-names></name><name><surname>Sun</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Deep residual learning for image recognition</article-title><conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name><fpage>770</fpage><lpage>778</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2016.90</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helfrich-Förster</surname> <given-names>C</given-names></name><name><surname>Shafer</surname> <given-names>OT</given-names></name><name><surname>Wülbeck</surname> <given-names>C</given-names></name><name><surname>Grieshaber</surname> <given-names>E</given-names></name><name><surname>Rieger</surname> <given-names>D</given-names></name><name><surname>Taghert</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Development and morphology of the clock-gene-expressing lateral neurons of <italic>Drosophila melanogaster</italic></article-title><source>The Journal of Comparative Neurology</source><volume>500</volume><fpage>47</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1002/cne.21146</pub-id><pub-id pub-id-type="pmid">17099895</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helmstaedter</surname> <given-names>M</given-names></name><name><surname>Briggman</surname> <given-names>KL</given-names></name><name><surname>Turaga</surname> <given-names>SC</given-names></name><name><surname>Jain</surname> <given-names>V</given-names></name><name><surname>Seung</surname> <given-names>HS</given-names></name><name><surname>Denk</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Connectomic reconstruction of the inner plexiform layer in the mouse retina</article-title><source>Nature</source><volume>500</volume><fpage>168</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1038/nature12346</pub-id><pub-id pub-id-type="pmid">23925239</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horne</surname> <given-names>JA</given-names></name><name><surname>Langille</surname> <given-names>C</given-names></name><name><surname>McLin</surname> <given-names>S</given-names></name><name><surname>Wiederman</surname> <given-names>M</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A resource for the <italic>Drosophila</italic> antennal lobe provided by the connectome of glomerulus VA1v</article-title><source>eLife</source><volume>7</volume><elocation-id>e37550</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.37550</pub-id><pub-id pub-id-type="pmid">30382940</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>GB</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Fully-Automatic synapse prediction and validation on a large data set</article-title><source>Frontiers in Neural Circuits</source><volume>12</volume><elocation-id>87</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2018.00087</pub-id><pub-id pub-id-type="pmid">30420797</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hubbard</surname> <given-names>PM</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Maitin-Shepard</surname> <given-names>J</given-names></name><name><surname>Januszewski</surname> <given-names>M</given-names></name><name><surname>Katz</surname> <given-names>WT</given-names></name><name><surname>Neace</surname> <given-names>ER</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Accelerated EM connectome reconstruction using 3D visualization and segmentation graphs</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.17.909572</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ioffe</surname> <given-names>S</given-names></name><name><surname>Szegedy</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Batch normalization: accelerating deep network training by reducing internal covariate shift</article-title><conf-name>Proceedings of the International Conference on Machine Learning</conf-name><fpage>448</fpage><lpage>456</lpage></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>K</given-names></name><name><surname>Awano</surname> <given-names>W</given-names></name><name><surname>Suzuki</surname> <given-names>K</given-names></name><name><surname>Hiromi</surname> <given-names>Y</given-names></name><name><surname>Yamamoto</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The <italic>Drosophila</italic> mushroom body is a quadruple structure of clonal units each of which contains a virtually identical set of neurones and glial cells</article-title><source>Development</source><volume>124</volume><fpage>761</fpage><lpage>771</lpage><pub-id pub-id-type="pmid">9043058</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Masuda</surname> <given-names>N</given-names></name><name><surname>Shinomiya</surname> <given-names>K</given-names></name><name><surname>Endo</surname> <given-names>K</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Systematic analysis of neural projections reveals clonal composition of the <italic>Drosophila</italic> brain</article-title><source>Current Biology</source><volume>23</volume><fpage>644</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.03.015</pub-id><pub-id pub-id-type="pmid">23541729</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>K</given-names></name><name><surname>Shinomiya</surname> <given-names>K</given-names></name><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Armstrong</surname> <given-names>JD</given-names></name><name><surname>Boyan</surname> <given-names>G</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name><name><surname>Harzsch</surname> <given-names>S</given-names></name><name><surname>Heisenberg</surname> <given-names>M</given-names></name><name><surname>Homberg</surname> <given-names>U</given-names></name><name><surname>Jenett</surname> <given-names>A</given-names></name><name><surname>Keshishian</surname> <given-names>H</given-names></name><name><surname>Restifo</surname> <given-names>LL</given-names></name><name><surname>Rössler</surname> <given-names>W</given-names></name><name><surname>Simpson</surname> <given-names>JH</given-names></name><name><surname>Strausfeld</surname> <given-names>NJ</given-names></name><name><surname>Strauss</surname> <given-names>R</given-names></name><name><surname>Vosshall</surname> <given-names>LB</given-names></name><collab>Insect Brain Name Working Group</collab></person-group><year iso-8601-date="2014">2014</year><article-title>A systematic nomenclature for the insect brain</article-title><source>Neuron</source><volume>81</volume><fpage>755</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.12.017</pub-id><pub-id pub-id-type="pmid">24559671</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Januszewski</surname> <given-names>M</given-names></name><name><surname>Kornfeld</surname> <given-names>J</given-names></name><name><surname>Li</surname> <given-names>PH</given-names></name><name><surname>Pope</surname> <given-names>A</given-names></name><name><surname>Blakely</surname> <given-names>T</given-names></name><name><surname>Lindsey</surname> <given-names>L</given-names></name><name><surname>Maitin-Shepard</surname> <given-names>J</given-names></name><name><surname>Tyka</surname> <given-names>M</given-names></name><name><surname>Denk</surname> <given-names>W</given-names></name><name><surname>Jain</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>High-precision automated reconstruction of neurons with flood-filling networks</article-title><source>Nature Methods</source><volume>15</volume><fpage>605</fpage><lpage>610</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0049-4</pub-id><pub-id pub-id-type="pmid">30013046</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Januszewski</surname> <given-names>M</given-names></name><name><surname>Jain</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Segmentation-enhanced CycleGAN</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/548081</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenett</surname> <given-names>A</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Ngo</surname> <given-names>TT</given-names></name><name><surname>Shepherd</surname> <given-names>D</given-names></name><name><surname>Murphy</surname> <given-names>C</given-names></name><name><surname>Dionne</surname> <given-names>H</given-names></name><name><surname>Pfeiffer</surname> <given-names>BD</given-names></name><name><surname>Cavallaro</surname> <given-names>A</given-names></name><name><surname>Hall</surname> <given-names>D</given-names></name><name><surname>Jeter</surname> <given-names>J</given-names></name><name><surname>Iyer</surname> <given-names>N</given-names></name><name><surname>Fetter</surname> <given-names>D</given-names></name><name><surname>Hausenfluck</surname> <given-names>JH</given-names></name><name><surname>Peng</surname> <given-names>H</given-names></name><name><surname>Trautman</surname> <given-names>ET</given-names></name><name><surname>Svirskas</surname> <given-names>RR</given-names></name><name><surname>Myers</surname> <given-names>EW</given-names></name><name><surname>Iwinski</surname> <given-names>ZR</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>DePasquale</surname> <given-names>GM</given-names></name><name><surname>Enos</surname> <given-names>A</given-names></name><name><surname>Hulamm</surname> <given-names>P</given-names></name><name><surname>Lam</surname> <given-names>SC</given-names></name><name><surname>Li</surname> <given-names>HH</given-names></name><name><surname>Laverty</surname> <given-names>TR</given-names></name><name><surname>Long</surname> <given-names>F</given-names></name><name><surname>Qu</surname> <given-names>L</given-names></name><name><surname>Murphy</surname> <given-names>SD</given-names></name><name><surname>Rokicki</surname> <given-names>K</given-names></name><name><surname>Safford</surname> <given-names>T</given-names></name><name><surname>Shaw</surname> <given-names>K</given-names></name><name><surname>Simpson</surname> <given-names>JH</given-names></name><name><surname>Sowell</surname> <given-names>A</given-names></name><name><surname>Tae</surname> <given-names>S</given-names></name><name><surname>Yu</surname> <given-names>Y</given-names></name><name><surname>Zugates</surname> <given-names>CT</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A GAL4-driver line resource for <italic>Drosophila</italic> neurobiology</article-title><source>Cell Reports</source><volume>2</volume><fpage>991</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2012.09.011</pub-id><pub-id pub-id-type="pmid">23063364</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kainmueller</surname> <given-names>D</given-names></name><name><surname>Lamecker</surname> <given-names>H</given-names></name><name><surname>Zachow</surname> <given-names>S</given-names></name><name><surname>Heller</surname> <given-names>M</given-names></name><name><surname>Hege</surname> <given-names>H-C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Multi-object segmentation with coupled deformable models</article-title><conf-name>Proc. of Medical Image Understanding and Analysis</conf-name><fpage>34</fpage><lpage>38</lpage></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamikouchi</surname> <given-names>A</given-names></name><name><surname>Shimada</surname> <given-names>T</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Comprehensive classification of the auditory sensory projections in the brain of the fruit fly <italic>Drosophila melanogaster</italic></article-title><source>The Journal of Comparative Neurology</source><volume>499</volume><fpage>317</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1002/cne.21075</pub-id><pub-id pub-id-type="pmid">16998934</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kandel</surname> <given-names>ER</given-names></name><name><surname>Schwartz</surname> <given-names>JH</given-names></name><name><surname>Jessell</surname> <given-names>TM</given-names></name><name><surname>of Biochemistry</surname> <given-names>D</given-names></name><name><surname>Jessell</surname> <given-names>MBT</given-names></name><name><surname>Siegelbaum</surname> <given-names>S</given-names></name><name><surname>Hudspeth</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Principles of Neural Science</source><publisher-loc>New York</publisher-loc><publisher-name>McGraw-hill</publisher-name></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasthuri</surname> <given-names>N</given-names></name><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Berger</surname> <given-names>DR</given-names></name><name><surname>Schalek</surname> <given-names>RL</given-names></name><name><surname>Conchello</surname> <given-names>JA</given-names></name><name><surname>Knowles-Barley</surname> <given-names>S</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Vázquez-Reina</surname> <given-names>A</given-names></name><name><surname>Kaynig</surname> <given-names>V</given-names></name><name><surname>Jones</surname> <given-names>TR</given-names></name><name><surname>Roberts</surname> <given-names>M</given-names></name><name><surname>Morgan</surname> <given-names>JL</given-names></name><name><surname>Tapia</surname> <given-names>JC</given-names></name><name><surname>Seung</surname> <given-names>HS</given-names></name><name><surname>Roncal</surname> <given-names>WG</given-names></name><name><surname>Vogelstein</surname> <given-names>JT</given-names></name><name><surname>Burns</surname> <given-names>R</given-names></name><name><surname>Sussman</surname> <given-names>DL</given-names></name><name><surname>Priebe</surname> <given-names>CE</given-names></name><name><surname>Pfister</surname> <given-names>H</given-names></name><name><surname>Lichtman</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Saturated reconstruction of a volume of neocortex</article-title><source>Cell</source><volume>162</volume><fpage>648</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.06.054</pub-id><pub-id pub-id-type="pmid">26232230</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katz</surname> <given-names>WT</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>DVID: distributed versioned Image-Oriented dataservice</article-title><source>Frontiers in Neural Circuits</source><volume>13</volume><elocation-id>5</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2019.00005</pub-id><pub-id pub-id-type="pmid">30804760</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Khairy</surname> <given-names>K</given-names></name><name><surname>Denisov</surname> <given-names>G</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Joint deformable registration of large EM image volumes: a matrix solver approach</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1804.10019">https://arxiv.org/abs/1804.10019</ext-link></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klapoetke</surname> <given-names>NC</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Peek</surname> <given-names>MY</given-names></name><name><surname>Rogers</surname> <given-names>EM</given-names></name><name><surname>Breads</surname> <given-names>P</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Reiser</surname> <given-names>MB</given-names></name><name><surname>Card</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ultra-selective looming detection from radial motion opponency</article-title><source>Nature</source><volume>551</volume><fpage>237</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1038/nature24626</pub-id><pub-id pub-id-type="pmid">29120418</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname> <given-names>S</given-names></name><name><surname>Staring</surname> <given-names>M</given-names></name><name><surname>Murphy</surname> <given-names>K</given-names></name><name><surname>Viergever</surname> <given-names>MA</given-names></name><name><surname>Pluim</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Elastix: a toolbox for intensity-based medical image registration</article-title><source>IEEE Transactions on Medical Imaging</source><volume>29</volume><fpage>196</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1109/TMI.2009.2035616</pub-id><pub-id pub-id-type="pmid">19923044</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lanzerotti</surname> <given-names>MY</given-names></name><name><surname>Fiorenza</surname> <given-names>G</given-names></name><name><surname>Rand</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microminiature packaging and integrated circuitry: the work of E. F. Rent, with an application to on-chip interconnection requirements</article-title><source>IBM Journal of Research and Development</source><volume>49</volume><fpage>777</fpage><lpage>803</lpage><pub-id pub-id-type="doi">10.1147/rd.494.0777</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>YJ</given-names></name><name><surname>Yang</surname> <given-names>CP</given-names></name><name><surname>Miyares</surname> <given-names>RL</given-names></name><name><surname>Huang</surname> <given-names>YF</given-names></name><name><surname>He</surname> <given-names>Y</given-names></name><name><surname>Ren</surname> <given-names>Q</given-names></name><name><surname>Chen</surname> <given-names>HM</given-names></name><name><surname>Kawase</surname> <given-names>T</given-names></name><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Otsuna</surname> <given-names>H</given-names></name><name><surname>Sugino</surname> <given-names>K</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Conservation and divergence of related neuronal lineages in the <italic>Drosophila</italic> central brain</article-title><source>eLife</source><volume>9</volume><elocation-id>e53518</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.53518</pub-id><pub-id pub-id-type="pmid">32255422</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>PH</given-names></name><name><surname>Lindsey</surname> <given-names>LF</given-names></name><name><surname>Januszewski</surname> <given-names>M</given-names></name><name><surname>Zheng</surname> <given-names>Z</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Taisz</surname> <given-names>I</given-names></name><name><surname>Tyka</surname> <given-names>M</given-names></name><name><surname>Nichols</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Perlman</surname> <given-names>E</given-names></name><name><surname>Maitin-Shepard</surname> <given-names>J</given-names></name><name><surname>Blakely</surname> <given-names>T</given-names></name><name><surname>Leavitt</surname> <given-names>L</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name><name><surname>Bock</surname> <given-names>D</given-names></name><name><surname>Jain</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Automated reconstruction of a serial-section EM <italic>Drosophila</italic> brain with flood-filling networks and local realignment</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/605634</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Lindsey</surname> <given-names>J</given-names></name><name><surname>Martin</surname> <given-names>EC</given-names></name><name><surname>Otto</surname> <given-names>N</given-names></name><name><surname>Dreher</surname> <given-names>M</given-names></name><name><surname>Dempsey</surname> <given-names>G</given-names></name><name><surname>Stark</surname> <given-names>I</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Pleijzier</surname> <given-names>MW</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Nern</surname> <given-names>AN</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Yang</surname> <given-names>T</given-names></name><name><surname>Francis</surname> <given-names>A</given-names></name><name><surname>Braun</surname> <given-names>A</given-names></name><name><surname>Parekh</surname> <given-names>R</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Scheffer</surname> <given-names>L</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name><name><surname>Abbott</surname> <given-names>L</given-names></name><name><surname>Litwin-Kumar</surname> <given-names>A</given-names></name><name><surname>Waddell</surname> <given-names>S</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The connectome of the <italic>Drosophila melanogaster</italic> mushroom body: implications for function</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.08.29.273276</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>S</given-names></name><name><surname>Marin</surname> <given-names>EC</given-names></name><name><surname>Yang</surname> <given-names>CP</given-names></name><name><surname>Kao</surname> <given-names>CF</given-names></name><name><surname>Apenteng</surname> <given-names>BA</given-names></name><name><surname>Huang</surname> <given-names>Y</given-names></name><name><surname>O'Connor</surname> <given-names>MB</given-names></name><name><surname>Truman</surname> <given-names>JW</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Extremes of lineage plasticity in the <italic>Drosophila</italic> brain</article-title><source>Current Biology</source><volume>23</volume><fpage>1908</fpage><lpage>1913</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.07.074</pub-id><pub-id pub-id-type="pmid">24055154</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>AC</given-names></name><name><surname>Bygrave</surname> <given-names>AM</given-names></name><name><surname>de Calignon</surname> <given-names>A</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name><name><surname>Miesenböck</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Sparse, decorrelated odor coding in the mushroom body enhances learned odor discrimination</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>559</fpage><lpage>568</lpage><pub-id pub-id-type="doi">10.1038/nn.3660</pub-id><pub-id pub-id-type="pmid">24561998</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>T-Y</given-names></name><name><surname>Goyal</surname> <given-names>P</given-names></name><name><surname>Girshick</surname> <given-names>R</given-names></name><name><surname>He</surname> <given-names>K</given-names></name><name><surname>Dollár</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Focal loss for dense object detection</article-title><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><fpage>2980</fpage><lpage>2988</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2017.324</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Rivlin</surname> <given-names>P</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name><name><surname>Scheffer</surname> <given-names>L</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>En bloc preparation of <italic>Drosophila</italic> brains enables high-throughput FIB-SEM connectomics</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/855130</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Manton</surname> <given-names>JD</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Jagannathan</surname> <given-names>SR</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Rohlfing</surname> <given-names>T</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The natverse: a versatile computational toolbox to combine and analyse neuroanatomical data</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/006353</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname> <given-names>Z</given-names></name><name><surname>Davis</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Eight different types of dopaminergic neurons innervate the <italic>Drosophila</italic> mushroom body neuropil: anatomical and physiological heterogeneity</article-title><source>Frontiers in Neural Circuits</source><volume>3</volume><elocation-id>5</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.04.005.2009</pub-id><pub-id pub-id-type="pmid">19597562</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marasco</surname> <given-names>A</given-names></name><name><surname>Limongiello</surname> <given-names>A</given-names></name><name><surname>Migliore</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Fast and accurate low-dimensional reduction of biophysically detailed neuron models</article-title><source>Scientific Reports</source><volume>2</volume><elocation-id>928</elocation-id><pub-id pub-id-type="doi">10.1038/srep00928</pub-id><pub-id pub-id-type="pmid">23226594</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marin</surname> <given-names>EC</given-names></name><name><surname>Büld</surname> <given-names>L</given-names></name><name><surname>Theiss</surname> <given-names>M</given-names></name><name><surname>Sarkissian</surname> <given-names>T</given-names></name><name><surname>Roberts</surname> <given-names>RJV</given-names></name><name><surname>Turnbull</surname> <given-names>R</given-names></name><name><surname>Tamimi</surname> <given-names>IFM</given-names></name><name><surname>Pleijzier</surname> <given-names>MW</given-names></name><name><surname>Laursen</surname> <given-names>WJ</given-names></name><name><surname>Drummond</surname> <given-names>N</given-names></name><name><surname>Schlegel</surname> <given-names>P</given-names></name><name><surname>Bates</surname> <given-names>AS</given-names></name><name><surname>Li</surname> <given-names>F</given-names></name><name><surname>Landgraf</surname> <given-names>M</given-names></name><name><surname>Costa</surname> <given-names>M</given-names></name><name><surname>Bock</surname> <given-names>DD</given-names></name><name><surname>Garrity</surname> <given-names>PA</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Connectomics analysis reveals first-, second-, and third-order thermosensory and hygrosensory neurons in the adult <italic>Drosophila</italic> brain</article-title><source>Current Biology</source><volume>30</volume><fpage>3167</fpage><lpage>3182</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.06.028</pub-id><pub-id pub-id-type="pmid">32619476</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martelli</surname> <given-names>C</given-names></name><name><surname>Pech</surname> <given-names>U</given-names></name><name><surname>Kobbenbring</surname> <given-names>S</given-names></name><name><surname>Pauls</surname> <given-names>D</given-names></name><name><surname>Bahl</surname> <given-names>B</given-names></name><name><surname>Sommer</surname> <given-names>MV</given-names></name><name><surname>Pooryasin</surname> <given-names>A</given-names></name><name><surname>Barth</surname> <given-names>J</given-names></name><name><surname>Arias</surname> <given-names>CWP</given-names></name><name><surname>Vassiliou</surname> <given-names>C</given-names></name><name><surname>Luna</surname> <given-names>AJF</given-names></name><name><surname>Poppinga</surname> <given-names>H</given-names></name><name><surname>Richter</surname> <given-names>FG</given-names></name><name><surname>Wegener</surname> <given-names>C</given-names></name><name><surname>Fiala</surname> <given-names>A</given-names></name><name><surname>Riemensperger</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>SIFamide translates hunger signals into appetitive and feeding behavior in <italic>Drosophila</italic></article-title><source>Cell Reports</source><volume>20</volume><fpage>464</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.06.043</pub-id><pub-id pub-id-type="pmid">28700946</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>McInnes</surname> <given-names>L</given-names></name><name><surname>Healy</surname> <given-names>J</given-names></name><name><surname>Melville</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Umap: uniform manifold approximation and projection for dimension reduction</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1802.03426">https://arxiv.org/abs/1802.03426</ext-link></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meier</surname> <given-names>M</given-names></name><name><surname>Borst</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Extreme compartmentalization in a <italic>Drosophila</italic> amacrine cell</article-title><source>Current Biology</source><volume>29</volume><fpage>1545</fpage><lpage>1550</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.03.070</pub-id><pub-id pub-id-type="pmid">31031119</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Connectome studies on <italic>Drosophila</italic>: a short perspective on a tiny brain</article-title><source>Journal of Neurogenetics</source><volume>30</volume><fpage>62</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.3109/01677063.2016.1166224</pub-id><pub-id pub-id-type="pmid">27328842</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name></person-group><year iso-8601-date="2016">2016b</year><chapter-title>Morphology of invertebrate neurons and synapses</chapter-title><person-group person-group-type="editor"><name><surname>Byrne</surname> <given-names>J. H</given-names></name></person-group><source>Handbook of Invertebrate Neurobiology</source><publisher-name>Oxford University Press</publisher-name><fpage>1</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1093/oxfordhb/9780190456757.001.0001</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name><name><surname>O'Neil</surname> <given-names>SD</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Synaptic organization of columnar elements in the lamina of the wild type in <italic>Drosophila melanogaster</italic></article-title><source>The Journal of Comparative Neurology</source><volume>305</volume><fpage>232</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1002/cne.903050206</pub-id><pub-id pub-id-type="pmid">1902848</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyazaki</surname> <given-names>T</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neural architecture of the primary gustatory center of <italic>Drosophila melanogaster</italic> visualized with GAL4 and LexA enhancer-trap systems</article-title><source>The Journal of Comparative Neurology</source><volume>518</volume><fpage>4147</fpage><lpage>4181</lpage><pub-id pub-id-type="doi">10.1002/cne.22433</pub-id><pub-id pub-id-type="pmid">20878781</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgan</surname> <given-names>JL</given-names></name><name><surname>Lichtman</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An individual interneuron participates in many kinds of inhibition and innervates much of the mouse visual thalamus</article-title><source>Neuron</source><volume>106</volume><fpage>468</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.02.001</pub-id><pub-id pub-id-type="pmid">32142646</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Namiki</surname> <given-names>S</given-names></name><name><surname>Dickinson</surname> <given-names>MH</given-names></name><name><surname>Wong</surname> <given-names>AM</given-names></name><name><surname>Korff</surname> <given-names>W</given-names></name><name><surname>Card</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The functional organization of descending sensory-motor pathways in <italic>Drosophila</italic></article-title><source>eLife</source><volume>7</volume><elocation-id>e34272</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34272</pub-id><pub-id pub-id-type="pmid">29943730</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohyama</surname> <given-names>T</given-names></name><name><surname>Schneider-Mizell</surname> <given-names>CM</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Aleman</surname> <given-names>JV</given-names></name><name><surname>Franconville</surname> <given-names>R</given-names></name><name><surname>Rivera-Alba</surname> <given-names>M</given-names></name><name><surname>Mensh</surname> <given-names>BD</given-names></name><name><surname>Branson</surname> <given-names>KM</given-names></name><name><surname>Simpson</surname> <given-names>JH</given-names></name><name><surname>Truman</surname> <given-names>JW</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name><name><surname>Zlatic</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A multilevel multimodal circuit enhances action selection in <italic>Drosophila</italic></article-title><source>Nature</source><volume>520</volume><fpage>633</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1038/nature14297</pub-id><pub-id pub-id-type="pmid">25896325</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Omoto</surname> <given-names>JJ</given-names></name><name><surname>Keleş</surname> <given-names>MF</given-names></name><name><surname>Nguyen</surname> <given-names>BM</given-names></name><name><surname>Bolanos</surname> <given-names>C</given-names></name><name><surname>Lovick</surname> <given-names>JK</given-names></name><name><surname>Frye</surname> <given-names>MA</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Visual input to the <italic>Drosophila</italic> central complex by developmentally and functionally distinct neuronal populations</article-title><source>Current Biology</source><volume>27</volume><fpage>1098</fpage><lpage>1110</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.02.063</pub-id><pub-id pub-id-type="pmid">28366740</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Omoto</surname> <given-names>JJ</given-names></name><name><surname>Nguyen</surname> <given-names>BM</given-names></name><name><surname>Kandimalla</surname> <given-names>P</given-names></name><name><surname>Lovick</surname> <given-names>JK</given-names></name><name><surname>Donlea</surname> <given-names>JM</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuronal constituents and putative interactions within the <italic>Drosophila</italic> Ellipsoid Body Neuropil</article-title><source>Frontiers in Neural Circuits</source><volume>12</volume><elocation-id>103</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2018.00103</pub-id><pub-id pub-id-type="pmid">30546298</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Otsuna</surname> <given-names>H</given-names></name><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Kawase</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Color depth mip mask search: a new tool to expedite split-GAL4 creation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/318006</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otsuna</surname> <given-names>H</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Systematic analysis of the visual projection neurons of <italic>Drosophila melanogaster</italic>. I. Lobula-specific pathways</article-title><source>The Journal of Comparative Neurology</source><volume>497</volume><fpage>928</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1002/cne.21015</pub-id><pub-id pub-id-type="pmid">16802334</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panser</surname> <given-names>K</given-names></name><name><surname>Tirian</surname> <given-names>L</given-names></name><name><surname>Schulze</surname> <given-names>F</given-names></name><name><surname>Villalba</surname> <given-names>S</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name><name><surname>Bühler</surname> <given-names>K</given-names></name><name><surname>Straw</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Automatic segmentation of <italic>Drosophila</italic> neural compartments using GAL4 expression data reveals novel visual pathways</article-title><source>Current Biology</source><volume>26</volume><fpage>1943</fpage><lpage>1954</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.05.052</pub-id><pub-id pub-id-type="pmid">27426516</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pascual</surname> <given-names>A</given-names></name><name><surname>Huang</surname> <given-names>K-L</given-names></name><name><surname>Neveu</surname> <given-names>J</given-names></name><name><surname>Préat</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Brain asymmetry and long-term memory</article-title><source>Nature</source><volume>427</volume><fpage>605</fpage><lpage>606</lpage><pub-id pub-id-type="doi">10.1038/427605a</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pech</surname> <given-names>U</given-names></name><name><surname>Pooryasin</surname> <given-names>A</given-names></name><name><surname>Birman</surname> <given-names>S</given-names></name><name><surname>Fiala</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Localization of the contacts between Kenyon cells and aminergic neurons in the <italic>Drosophila melanogaster</italic> brain using splitGFP reconstitution</article-title><source>The Journal of Comparative Neurology</source><volume>521</volume><fpage>3992</fpage><lpage>4026</lpage><pub-id pub-id-type="doi">10.1002/cne.23388</pub-id><pub-id pub-id-type="pmid">23784863</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereanu</surname> <given-names>W</given-names></name><name><surname>Kumar</surname> <given-names>A</given-names></name><name><surname>Jennett</surname> <given-names>A</given-names></name><name><surname>Reichert</surname> <given-names>H</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Development-based compartmentalization of the <italic>Drosophila</italic> central brain</article-title><source>The Journal of Comparative Neurology</source><volume>518</volume><fpage>2996</fpage><lpage>3023</lpage><pub-id pub-id-type="doi">10.1002/cne.22376</pub-id><pub-id pub-id-type="pmid">20533357</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perlman</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Visualizing and interacting with large imaging data</article-title><source>Microscopy and Microanalysis</source><volume>25</volume><fpage>1374</fpage><lpage>1375</lpage><pub-id pub-id-type="doi">10.1017/S1431927619007608</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pimentel</surname> <given-names>D</given-names></name><name><surname>Donlea</surname> <given-names>JM</given-names></name><name><surname>Talbot</surname> <given-names>CB</given-names></name><name><surname>Song</surname> <given-names>SM</given-names></name><name><surname>Thurston</surname> <given-names>AJF</given-names></name><name><surname>Miesenböck</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Operation of a homeostatic sleep switch</article-title><source>Nature</source><volume>536</volume><fpage>333</fpage><lpage>337</lpage><pub-id pub-id-type="doi">10.1038/nature19055</pub-id><pub-id pub-id-type="pmid">27487216</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pizer</surname> <given-names>SM</given-names></name><name><surname>Amburn</surname> <given-names>EP</given-names></name><name><surname>Austin</surname> <given-names>JD</given-names></name><name><surname>Cromartie</surname> <given-names>R</given-names></name><name><surname>Geselowitz</surname> <given-names>A</given-names></name><name><surname>Greer</surname> <given-names>T</given-names></name><name><surname>ter Haar Romeny</surname> <given-names>B</given-names></name><name><surname>Zimmerman</surname> <given-names>JB</given-names></name><name><surname>Zuiderveld</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Adaptive histogram equalization and its variations</article-title><source>Computer Vision, Graphics, and Image Processing</source><volume>39</volume><fpage>355</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1016/S0734-189X(87)80186-X</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Focused proofreading: efficiently extracting connectomes from segmented EM images</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1409.1199">https://arxiv.org/abs/1409.1199</ext-link></element-citation></ref><ref id="bib98"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Plaza</surname> <given-names>S</given-names></name><name><surname>Dreher</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>CBLAST</data-title><source>GitHub</source><version designator="d39cf37">d39cf37</version><ext-link ext-link-type="uri" xlink:href="https://github.com/connectome-neuprint/CBLAST">https://github.com/connectome-neuprint/CBLAST</ext-link></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pooryasin</surname> <given-names>A</given-names></name><name><surname>Fiala</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Identified Serotonin-Releasing neurons induce behavioral quiescence and suppress mating in <italic>Drosophila</italic></article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>12792</fpage><lpage>12812</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1638-15.2015</pub-id><pub-id pub-id-type="pmid">26377467</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ronneberger</surname> <given-names>O</given-names></name><name><surname>Fischer</surname> <given-names>P</given-names></name><name><surname>Brox</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>U-net: Convolutional networks for biomedical image segmentation</chapter-title><person-group person-group-type="editor"><name><surname>Navab</surname> <given-names>N</given-names></name><name><surname>Hornegger</surname> <given-names>J</given-names></name><name><surname>Wells</surname> <given-names>W</given-names></name><name><surname>Frangi</surname> <given-names>A</given-names></name></person-group><source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source><publisher-name>Springer</publisher-name><fpage>234</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-24574-4_28</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalfeld</surname> <given-names>S</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name><name><surname>Tomancak</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>CATMAID: collaborative annotation toolkit for massive amounts of image data</article-title><source>Bioinformatics</source><volume>25</volume><fpage>1984</fpage><lpage>1986</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp266</pub-id><pub-id pub-id-type="pmid">19376822</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalfeld</surname> <given-names>S</given-names></name><name><surname>Cardona</surname> <given-names>A</given-names></name><name><surname>Hartenstein</surname> <given-names>V</given-names></name><name><surname>Tomančák</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>As-rigid-as-possible mosaicking and serial section registration of large ssTEM datasets</article-title><source>Bioinformatics</source><volume>26</volume><fpage>i57</fpage><lpage>i63</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btq219</pub-id><pub-id pub-id-type="pmid">20529937</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Saalfeld</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020a</year><data-title>N5</data-title><source>GitHub</source><version designator="dc5e653">dc5e653</version><ext-link ext-link-type="uri" xlink:href="https://github.com/saalfeldlab/n5">https://github.com/saalfeldlab/n5</ext-link></element-citation></ref><ref id="bib104"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Saalfeld</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020b</year><data-title>hot-knife</data-title><source>GitHub</source><version designator="f7971ee">f7971ee</version><ext-link ext-link-type="uri" xlink:href="https://github.com/saalfeldlab/hot-knife">https://github.com/saalfeldlab/hot-knife</ext-link></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanner</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Python: a programming language for software integration and development</article-title><source>Journal of Molecular Graphics &amp; Modelling</source><volume>17</volume><fpage>57</fpage><lpage>61</lpage><pub-id pub-id-type="pmid">10660911</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Segev</surname> <given-names>I</given-names></name><name><surname>Fleshman</surname> <given-names>JW</given-names></name><name><surname>Miller</surname> <given-names>JP</given-names></name><name><surname>Bunow</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Modeling the electrical behavior of anatomically complex neurons using a network analysis program: passive membrane</article-title><source>Biological Cybernetics</source><volume>53</volume><fpage>27</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1007/BF00355688</pub-id><pub-id pub-id-type="pmid">3841013</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shao</surname> <given-names>L</given-names></name><name><surname>Saver</surname> <given-names>M</given-names></name><name><surname>Chung</surname> <given-names>P</given-names></name><name><surname>Ren</surname> <given-names>Q</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name><name><surname>Kent</surname> <given-names>CF</given-names></name><name><surname>Heberlein</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dissection of the <italic>Drosophila</italic> neuropeptide F circuit using a high-throughput two-choice assay</article-title><source>PNAS</source><volume>114</volume><fpage>E8091</fpage><lpage>E8099</lpage><pub-id pub-id-type="doi">10.1073/pnas.1710552114</pub-id><pub-id pub-id-type="pmid">28874527</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinomiya</surname> <given-names>K</given-names></name><name><surname>Matsuda</surname> <given-names>K</given-names></name><name><surname>Oishi</surname> <given-names>T</given-names></name><name><surname>Otsuna</surname> <given-names>H</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Flybrain neuron database: a comprehensive database system of the <italic>Drosophila</italic> brain neurons</article-title><source>The Journal of Comparative Neurology</source><volume>519</volume><fpage>807</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1002/cne.22540</pub-id><pub-id pub-id-type="pmid">21280038</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinomiya</surname> <given-names>K</given-names></name><name><surname>Huang</surname> <given-names>G</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Parag</surname> <given-names>T</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Aniceto</surname> <given-names>R</given-names></name><name><surname>Ansari</surname> <given-names>N</given-names></name><name><surname>Cheatham</surname> <given-names>N</given-names></name><name><surname>Lauchie</surname> <given-names>S</given-names></name><name><surname>Neace</surname> <given-names>E</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Ordish</surname> <given-names>C</given-names></name><name><surname>Peel</surname> <given-names>D</given-names></name><name><surname>Shinomiya</surname> <given-names>A</given-names></name><name><surname>Smith</surname> <given-names>C</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Talebi</surname> <given-names>I</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Comparisons between the ON- and OFF-edge motion pathways in the <italic>Drosophila</italic> brain</article-title><source>eLife</source><volume>8</volume><elocation-id>e40025</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.40025</pub-id><pub-id pub-id-type="pmid">30624205</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sinakevitch</surname> <given-names>I</given-names></name><name><surname>Niwa</surname> <given-names>M</given-names></name><name><surname>Strausfeld</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Octopamine-like immunoreactivity in the honey bee and cockroach: comparable organization in the brain and subesophageal ganglion</article-title><source>The Journal of Comparative Neurology</source><volume>488</volume><fpage>233</fpage><lpage>254</lpage><pub-id pub-id-type="doi">10.1002/cne.20572</pub-id><pub-id pub-id-type="pmid">15952163</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname> <given-names>S</given-names></name><name><surname>Sjöström</surname> <given-names>PJ</given-names></name><name><surname>Reigl</surname> <given-names>M</given-names></name><name><surname>Nelson</surname> <given-names>S</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title><source>PLOS Biology</source><volume>3</volume><elocation-id>e68</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0030068</pub-id><pub-id pub-id-type="pmid">15737062</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Bharioke</surname> <given-names>A</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Vitaladevuni</surname> <given-names>S</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Katz</surname> <given-names>WT</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name><name><surname>Winston</surname> <given-names>P</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Horne</surname> <given-names>JA</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Blazek</surname> <given-names>K</given-names></name><name><surname>Chang</surname> <given-names>LA</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Saunders</surname> <given-names>MA</given-names></name><name><surname>Shapiro</surname> <given-names>V</given-names></name><name><surname>Sigmund</surname> <given-names>C</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A visual motion detection circuit suggested by <italic>Drosophila</italic> connectomics</article-title><source>Nature</source><volume>500</volume><fpage>175</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1038/nature12450</pub-id><pub-id pub-id-type="pmid">23925240</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Parag</surname> <given-names>T</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Plaza</surname> <given-names>S</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Katz</surname> <given-names>WT</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Weaver</surname> <given-names>C</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name><name><surname>Horne</surname> <given-names>JA</given-names></name><name><surname>Nunez-Iglesias</surname> <given-names>J</given-names></name><name><surname>Aniceto</surname> <given-names>R</given-names></name><name><surname>Chang</surname> <given-names>LA</given-names></name><name><surname>Lauchie</surname> <given-names>S</given-names></name><name><surname>Nasca</surname> <given-names>A</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Sigmund</surname> <given-names>C</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Tran</surname> <given-names>J</given-names></name><name><surname>Langille</surname> <given-names>C</given-names></name><name><surname>Le Lacheur</surname> <given-names>K</given-names></name><name><surname>McLin</surname> <given-names>S</given-names></name><name><surname>Shinomiya</surname> <given-names>A</given-names></name><name><surname>Chklovskii</surname> <given-names>DB</given-names></name><name><surname>Meinertzhagen</surname> <given-names>IA</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Synaptic circuits and their variations within different columns in the visual system of <italic>Drosophila</italic></article-title><source>PNAS</source><volume>112</volume><fpage>13711</fpage><lpage>13716</lpage><pub-id pub-id-type="doi">10.1073/pnas.1509820112</pub-id><pub-id pub-id-type="pmid">26483464</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takemura</surname> <given-names>SY</given-names></name><name><surname>Aso</surname> <given-names>Y</given-names></name><name><surname>Hige</surname> <given-names>T</given-names></name><name><surname>Wong</surname> <given-names>A</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Rivlin</surname> <given-names>PK</given-names></name><name><surname>Hess</surname> <given-names>H</given-names></name><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Parag</surname> <given-names>T</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Huang</surname> <given-names>G</given-names></name><name><surname>Katz</surname> <given-names>W</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Plaza</surname> <given-names>S</given-names></name><name><surname>Umayam</surname> <given-names>L</given-names></name><name><surname>Aniceto</surname> <given-names>R</given-names></name><name><surname>Chang</surname> <given-names>LA</given-names></name><name><surname>Lauchie</surname> <given-names>S</given-names></name><name><surname>Ogundeyi</surname> <given-names>O</given-names></name><name><surname>Ordish</surname> <given-names>C</given-names></name><name><surname>Shinomiya</surname> <given-names>A</given-names></name><name><surname>Sigmund</surname> <given-names>C</given-names></name><name><surname>Takemura</surname> <given-names>S</given-names></name><name><surname>Tran</surname> <given-names>J</given-names></name><name><surname>Turner</surname> <given-names>GC</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name><name><surname>Scheffer</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A connectome of a learning and memory center in the adult <italic>Drosophila</italic> brain</article-title><source>eLife</source><volume>6</volume><elocation-id>e26975</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.26975</pub-id><pub-id pub-id-type="pmid">28718765</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talay</surname> <given-names>M</given-names></name><name><surname>Richman</surname> <given-names>EB</given-names></name><name><surname>Snell</surname> <given-names>NJ</given-names></name><name><surname>Hartmann</surname> <given-names>GG</given-names></name><name><surname>Fisher</surname> <given-names>JD</given-names></name><name><surname>Sorkaç</surname> <given-names>A</given-names></name><name><surname>Santoyo</surname> <given-names>JF</given-names></name><name><surname>Chou-Freed</surname> <given-names>C</given-names></name><name><surname>Nair</surname> <given-names>N</given-names></name><name><surname>Johnson</surname> <given-names>M</given-names></name><name><surname>Szymanski</surname> <given-names>JR</given-names></name><name><surname>Barnea</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Transsynaptic mapping of second-order taste neurons in flies by trans-Tango</article-title><source>Neuron</source><volume>96</volume><fpage>783</fpage><lpage>795</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.10.011</pub-id><pub-id pub-id-type="pmid">29107518</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname> <given-names>NK</given-names></name><name><surname>Tanimoto</surname> <given-names>H</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neuronal assemblies of the <italic>Drosophila</italic> mushroom body</article-title><source>The Journal of Comparative Neurology</source><volume>508</volume><fpage>711</fpage><lpage>755</lpage><pub-id pub-id-type="doi">10.1002/cne.21692</pub-id><pub-id pub-id-type="pmid">18395827</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname> <given-names>NK</given-names></name><name><surname>Endo</surname> <given-names>K</given-names></name><name><surname>Ito</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Organization of antennal lobe-associated neurons in adult <italic>Drosophila melanogaster</italic> brain</article-title><source>The Journal of Comparative Neurology</source><volume>520</volume><fpage>4067</fpage><lpage>4130</lpage><pub-id pub-id-type="doi">10.1002/cne.23142</pub-id><pub-id pub-id-type="pmid">22592945</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Tschopp</surname> <given-names>FD</given-names></name><name><surname>Reiser</surname> <given-names>MB</given-names></name><name><surname>Turaga</surname> <given-names>SC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A connectome based hexagonal lattice convolutional network model of the <italic>Drosophila</italic> visual system</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1806.04793">https://arxiv.org/abs/1806.04793</ext-link></element-citation></ref><ref id="bib119"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Turner-Evans</surname> <given-names>DB</given-names></name><name><surname>Jensen</surname> <given-names>K</given-names></name><name><surname>Ali</surname> <given-names>S</given-names></name><name><surname>Paterson</surname> <given-names>T</given-names></name><name><surname>Sheridan</surname> <given-names>A</given-names></name><name><surname>Ray</surname> <given-names>RP</given-names></name><name><surname>Lauritzen</surname> <given-names>S</given-names></name><name><surname>Bock</surname> <given-names>D</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The neuroanatomical ultrastructure and function of a biological ring attractor</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/847152</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>F</given-names></name><name><surname>Wang</surname> <given-names>K</given-names></name><name><surname>Forknall</surname> <given-names>N</given-names></name><name><surname>Patrick</surname> <given-names>C</given-names></name><name><surname>Yang</surname> <given-names>T</given-names></name><name><surname>Parekh</surname> <given-names>R</given-names></name><name><surname>Bock</surname> <given-names>D</given-names></name><name><surname>Dickson</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural circuitry linking mating and egg laying in <italic>Drosophila</italic> females</article-title><source>Nature</source><volume>579</volume><fpage>101</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2055-9</pub-id><pub-id pub-id-type="pmid">32103180</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname> <given-names>KE</given-names></name><name><surname>Humphrey</surname> <given-names>DM</given-names></name><name><surname>Hirth</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The dopaminergic system in the aging brain of <italic>Drosophila</italic></article-title><source>Frontiers in Neuroscience</source><volume>4</volume><elocation-id>205</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2010.00205</pub-id><pub-id pub-id-type="pmid">21165178</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname> <given-names>T</given-names></name><name><surname>Iyer</surname> <given-names>NA</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuroarchitecture and neuroanatomy of the <italic>Drosophila</italic> central complex: a GAL4-based dissection of protocerebral bridge neurons and circuits</article-title><source>Journal of Comparative Neurology</source><volume>523</volume><fpage>997</fpage><lpage>1037</lpage><pub-id pub-id-type="doi">10.1002/cne.23705</pub-id><pub-id pub-id-type="pmid">25380328</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname> <given-names>T</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neuroarchitecture of the <italic>Drosophila</italic> central complex: a catalog of Nodulus and asymmetrical body neurons and a revision of the protocerebral bridge catalog</article-title><source>Journal of Comparative Neurology</source><volume>526</volume><fpage>2585</fpage><lpage>2611</lpage><pub-id pub-id-type="doi">10.1002/cne.24512</pub-id><pub-id pub-id-type="pmid">30084503</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname> <given-names>M</given-names></name><name><surname>Nern</surname> <given-names>A</given-names></name><name><surname>Williamson</surname> <given-names>WR</given-names></name><name><surname>Morimoto</surname> <given-names>MM</given-names></name><name><surname>Reiser</surname> <given-names>MB</given-names></name><name><surname>Card</surname> <given-names>GM</given-names></name><name><surname>Rubin</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Visual projection neurons in the <italic>Drosophila</italic> lobula link feature detection to distinct behavioral programs</article-title><source>eLife</source><volume>5</volume><elocation-id>e21022</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21022</pub-id><pub-id pub-id-type="pmid">28029094</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Grob</surname> <given-names>P</given-names></name><name><surname>Hassan</surname> <given-names>AM</given-names></name><name><surname>García-Cerdán</surname> <given-names>JG</given-names></name><name><surname>Niyogi</surname> <given-names>KK</given-names></name><name><surname>Nogales</surname> <given-names>E</given-names></name><name><surname>Weinberg</surname> <given-names>RJ</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Enhanced FIB-SEM systems for large-volume 3D imaging</article-title><source>eLife</source><volume>6</volume><elocation-id>e25916</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.25916</pub-id><pub-id pub-id-type="pmid">28500755</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Pang</surname> <given-names>S</given-names></name><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Enabling FIB-SEM systems for large volume connectomics and cell biology</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/852863</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="patent"><person-group person-group-type="inventor"><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Hayworth</surname> <given-names>KJ</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Grob</surname> <given-names>P</given-names></name><name><surname>Hassan</surname> <given-names>AM</given-names></name><name><surname>García-Cerdán</surname> <given-names>JG</given-names></name><name><surname>Niyogi</surname> <given-names>KK</given-names></name><name><surname>Nogales</surname> <given-names>E</given-names></name><name><surname>Weinberg</surname> <given-names>RJ</given-names></name><name><surname>Hess</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>Enhanced FIB-SEM systems for large-volume 3D imaging</article-title><source>US Patent</source><patent country="United States">10,600,615</patent><ext-link ext-link-type="uri" xlink:href="http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=10,600,615">http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=10,600,615</ext-link></element-citation></ref><ref id="bib128"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>CS</given-names></name><name><surname>Januszewski</surname> <given-names>M</given-names></name><name><surname>Lu</surname> <given-names>Z</given-names></name><name><surname>Takemura</surname> <given-names>S-y</given-names></name><name><surname>Hayworth</surname> <given-names>K</given-names></name><name><surname>Huang</surname> <given-names>G</given-names></name><name><surname>Shinomiya</surname> <given-names>K</given-names></name><name><surname>Maitin-Shepard</surname> <given-names>J</given-names></name><name><surname>Ackerman</surname> <given-names>D</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>A connectome of the adult <italic>Drosophila</italic> central brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.21.911859</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>X</given-names></name><name><surname>Bozorgzadeh</surname> <given-names>E</given-names></name><name><surname>Sarrafzadeh</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Wirelength estimation based on Rent exponents of partitioning and placement </article-title><conf-name>Proceedings of the 2001 International Workshop on System-Level Interconnect Prediction</conf-name><fpage>25</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1145/368640.368658</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yellman</surname> <given-names>C</given-names></name><name><surname>Tao</surname> <given-names>H</given-names></name><name><surname>He</surname> <given-names>B</given-names></name><name><surname>Hirsh</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Conserved and sexually dimorphic behavioral responses to biogenic amines in decapitated <italic>Drosophila</italic></article-title><source>PNAS</source><volume>94</volume><fpage>4131</fpage><lpage>4136</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.8.4131</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Yin</surname> <given-names>W</given-names></name><name><surname>Brittain</surname> <given-names>D</given-names></name><name><surname>Borseth</surname> <given-names>J</given-names></name><name><surname>Scott</surname> <given-names>ME</given-names></name><name><surname>Williams</surname> <given-names>D</given-names></name><name><surname>Perkins</surname> <given-names>J</given-names></name><name><surname>Own</surname> <given-names>C</given-names></name><name><surname>Murfitt</surname> <given-names>M</given-names></name><name><surname>Torres</surname> <given-names>RM</given-names></name><name><surname>Kapner</surname> <given-names>D</given-names></name><name><surname>Bleckert</surname> <given-names>A</given-names></name><name><surname>Castelli</surname> <given-names>D</given-names></name><name><surname>Reid</surname> <given-names>D</given-names></name><name><surname>Lee</surname> <given-names>W-CA</given-names></name><name><surname>Graham</surname> <given-names>BJ</given-names></name><name><surname>Takeno</surname> <given-names>M</given-names></name><name><surname>Bumbarger</surname> <given-names>DJ</given-names></name><name><surname>Farrell</surname> <given-names>C</given-names></name><name><surname>Clay Reid</surname> <given-names>R</given-names></name><name><surname>Costa</surname> <given-names>NMda</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A petascale automated imaging pipeline for mapping neuronal circuits with high-throughput transmission electron microscopy</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/791889</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>JY</given-names></name><name><surname>Kanai</surname> <given-names>MI</given-names></name><name><surname>Demir</surname> <given-names>E</given-names></name><name><surname>Jefferis</surname> <given-names>GS</given-names></name><name><surname>Dickson</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Cellular organization of the neural circuit that drives <italic>Drosophila</italic> courtship behavior</article-title><source>Current Biology : CB</source><volume>20</volume><fpage>1602</fpage><lpage>1614</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.08.025</pub-id><pub-id pub-id-type="pmid">20832315</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>HH</given-names></name><name><surname>Awasaki</surname> <given-names>T</given-names></name><name><surname>Schroeder</surname> <given-names>MD</given-names></name><name><surname>Long</surname> <given-names>F</given-names></name><name><surname>Yang</surname> <given-names>JS</given-names></name><name><surname>He</surname> <given-names>Y</given-names></name><name><surname>Ding</surname> <given-names>P</given-names></name><name><surname>Kao</surname> <given-names>JC</given-names></name><name><surname>Wu</surname> <given-names>GY</given-names></name><name><surname>Peng</surname> <given-names>H</given-names></name><name><surname>Myers</surname> <given-names>G</given-names></name><name><surname>Lee</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Clonal development and organization of the adult <italic>Drosophila</italic> Central Brain</article-title><source>Current Biology : CB</source><volume>23</volume><fpage>633</fpage><lpage>643</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.02.057</pub-id><pub-id pub-id-type="pmid">23541733</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Olbris</surname> <given-names>DJ</given-names></name><name><surname>Yu</surname> <given-names>Y</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>NeuTu: software for collaborative, Large-Scale, Segmentation-Based connectome reconstruction</article-title><source>Frontiers in Neural Circuits</source><volume>12</volume><elocation-id>101</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2018.00101</pub-id><pub-id pub-id-type="pmid">30483068</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zhao</surname> <given-names>T</given-names></name><name><surname>Plaza</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Automatic neuron type identification by neurite localization in the <italic>Drosophila</italic> medulla</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1409.1892">https://arxiv.org/abs/1409.1892</ext-link></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname> <given-names>Z</given-names></name><name><surname>Lauritzen</surname> <given-names>JS</given-names></name><name><surname>Perlman</surname> <given-names>E</given-names></name><name><surname>Robinson</surname> <given-names>CG</given-names></name><name><surname>Nichols</surname> <given-names>M</given-names></name><name><surname>Milkie</surname> <given-names>D</given-names></name><name><surname>Torrens</surname> <given-names>O</given-names></name><name><surname>Price</surname> <given-names>J</given-names></name><name><surname>Fisher</surname> <given-names>CB</given-names></name><name><surname>Sharifi</surname> <given-names>N</given-names></name><name><surname>Calle-Schuler</surname> <given-names>SA</given-names></name><name><surname>Kmecova</surname> <given-names>L</given-names></name><name><surname>Ali</surname> <given-names>IJ</given-names></name><name><surname>Karsh</surname> <given-names>B</given-names></name><name><surname>Trautman</surname> <given-names>ET</given-names></name><name><surname>Bogovic</surname> <given-names>JA</given-names></name><name><surname>Hanslovsky</surname> <given-names>P</given-names></name><name><surname>Jefferis</surname> <given-names>G</given-names></name><name><surname>Kazhdan</surname> <given-names>M</given-names></name><name><surname>Khairy</surname> <given-names>K</given-names></name><name><surname>Saalfeld</surname> <given-names>S</given-names></name><name><surname>Fetter</surname> <given-names>RD</given-names></name><name><surname>Bock</surname> <given-names>DD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A complete electron microscopy volume of the brain of adult <italic>Drosophila melanogaster</italic></article-title><source>Cell</source><volume>174</volume><fpage>730</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id><pub-id pub-id-type="pmid">30033368</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>C</given-names></name><name><surname>Pan</surname> <given-names>Y</given-names></name><name><surname>Robinett</surname> <given-names>CC</given-names></name><name><surname>Meissner</surname> <given-names>GW</given-names></name><name><surname>Baker</surname> <given-names>BS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Central brain neurons expressing doublesex regulate female receptivity in <italic>Drosophila</italic></article-title><source>Neuron</source><volume>83</volume><fpage>149</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.05.038</pub-id><pub-id pub-id-type="pmid">24991959</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhu</surname> <given-names>J-Y</given-names></name><name><surname>Park</surname> <given-names>T</given-names></name><name><surname>Isola</surname> <given-names>P</given-names></name><name><surname>Efros</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Unpaired image-to-image translation using cycle-consistent adversarial networks</article-title><conf-name>Proceedings of the IEEE International Conference on Computer Vision</conf-name><fpage>2223</fpage><lpage>2232</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2017.244</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><sec id="s5" sec-type="appendix"><title>Sensory inputs and motor outputs</title><p>The dataset covers most of the antennal lobe (AL) glomeruli, which house the presynaptic terminals of the olfactory receptor neurons (ORNs) from the antennae. The ORNs are named after their innervating glomeruli, for example ORN_DA2, and the olfactory receptors they express, as well as their ligands, and have been identified through various physiological studies (<xref ref-type="bibr" rid="bib19">Couto et al., 2005</xref>; <xref ref-type="bibr" rid="bib27">Fishilevich and Vosshall, 2005</xref>; <xref ref-type="bibr" rid="bib35">Hallem and Carlson, 2006</xref>). The olfactory signals are then transmitted by the olfactory projections neurons (PNs) to the calyx (CA) of the mushroom body, the lateral horn (LH) and beyond.</p><p>While a large fraction of the optic lobe (OL) neuropils are missing, more than half of the lobula (LO) and small pieces of the lobula plate (LOP) and medulla (ME) are within the dataset. Many neurons connecting the OL and the central brain, called visual projection neurons (VPNs), are identified and annotated, along with their synaptic terminals in the central brain, and in the optic lobe when possible. Among them, the columnar VPNs, including the lobula columnar (LC), lobula plate columnar (LPC), lobula-lobula plate columnar (LLPC), and lobula plate-lobula columnar (LPLC) neurons (<xref ref-type="bibr" rid="bib1">Ache et al., 2019</xref>; <xref ref-type="bibr" rid="bib26">Fischbach and Dittrich, 1989</xref>; <xref ref-type="bibr" rid="bib62">Klapoetke et al., 2017</xref>; <xref ref-type="bibr" rid="bib89">Otsuna and Ito, 2006</xref>; <xref ref-type="bibr" rid="bib124">Wu et al., 2016</xref>), account for the vast majority of the population and are more or less densely identified. Since the distribution of the columnar neurons in the optic lobe follows the arrangement of the photoreceptor cells in the compound eye, the retinotopy can be traced even in their terminals in the central brain in some cell types, while in others the retinotopy is apparently lost in the central brain. In most cases, these neurons terminate in synapse-rich structures called the optic glomeruli in the ventrolateral neuropils, where they relay visual information to higher-order neurons (<xref ref-type="bibr" rid="bib90">Panser et al., 2016</xref>; <xref ref-type="bibr" rid="bib124">Wu et al., 2016</xref>).</p><p>The antennal mechanosensory and motor center (AMMC) is located lateral and ventral to the esophagus foramen. It houses terminals of the Johnston’s organ neurons (JONs), the mechanosensory neurons from the Johnston’s organ in the second segment of the antennae, as well as their synaptic partners. The AMMC is subdivided into five functionally and anatomically segregated zones, A, B, C, D, and E (<xref ref-type="bibr" rid="bib57">Kamikouchi et al., 2006</xref>). Since the neuropil is partially truncated, especially in the medial and ventral part corresponding to the zones D and E in the hemibrain dataset, only a limited number of the JONs innervating zones A, B, and C have been annotated, as JO-ABC.</p><p>The gustatory receptor neurons (GRNs) from the labellum and maxillary palp terminate in the gustatory sensory centers in the gnathal ganglia (GNG) and the prow (PRW) (<xref ref-type="bibr" rid="bib38">Hartenstein et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>; <xref ref-type="bibr" rid="bib82">Miyazaki and Ito, 2010</xref>). Both of them are mostly out of the imaging range of the dataset and therefore no GRNs have been identified.</p><p>We have identified 51 types of descending neurons (out of a total of 98 types identified by the LM study) that play a key role in behavior. These neurons were annotated based on the nomenclature described in a previous study (<xref ref-type="bibr" rid="bib84">Namiki et al., 2018</xref>), namely the classes of DNa, DNb, DNg, and DNp. Due to the lack of ventral region in the current dataset, we are not able to specify other cell types that run in the neck connective. In addition we identified three types of descending neurons that go out of the brain at the esophogus foramen without going via the neck connective (DNES1, 2, and 3).</p></sec><sec id="s6" sec-type="appendix"><title>Sample preparation</title><p>We employed the Progressive Lowering of Temperature dehydration with Low temperature en bloc Staining (PLT-LTS), a modified conventional chemical fixation and en bloc staining method. This method, mentioned in our previous papers (<xref ref-type="bibr" rid="bib41">Hayworth et al., 2015</xref>; <xref ref-type="bibr" rid="bib125">Xu et al., 2017</xref>; <xref ref-type="bibr" rid="bib71">Lu et al., 2019</xref>), is here abbreviated as ‘C-PLT’. PLT-LTS is an optimization method to give tissue advanced high contrast staining and minimize artifacts such as extraction, and size and shape variation, by treating tissue under 0°C to −25°C in acetone or ethanol based uranyl acetate and osmium tetroxide after routine fixation. PLT-LTS samples show highly visible membranes with fewer deflated and collapsed profiles and conspicuous synaptic densities in FIB-SEM images.</p><p>Five-day-old adult female <italic>Drosophila</italic>, of the genotype Canton S G1 x w<sup>1118</sup>, were used in this experiment. They were raised on a 12-hr day/night cycle, with dissection performed 1.5 hr after lights-on. Isolated whole brains were fixed in 2.5% formaldehyde and 2.5% glutaraldehyde in 0.1 M phosphate buffer at pH 7.4 for 2 hr at 22°C. After washing, the tissues were post-fixed in 0.5% osmium tetroxide in double distilled H<sub>2</sub>O for 30 min at 4°C. After washing and en bloc staining with 0.5% aqueous uranyl acetate for 30 min and then further washing in water, for 20 min in 0.8% osmium tetroxide, a Progressive of Lowering Temperature (PLT) procedure started from 1°C when the tissues were transferred into 10% acetone. The temperature was progressively decreased to −25°C while the acetone concentration was gradually increased to 97%. The tissue was incubated in 1% osmium tetroxide and 0.2% uranyl acetate in acetone for 32 hr at −25°C. After PLT and low temperature incubation, the temperature was increased to 22°C, and tissues were rinsed in pure acetone following by propylene oxide, then infiltrated and embedded in Poly/Bed 812 epoxy (Luft formulation).</p></sec><sec id="s7" sec-type="appendix"><title>Hot knife cutting</title><sec id="s7-1"><title>Ultrathick sectioning</title><p>The hemibrain is too large to image by FIB-SEM without artifacts so we used our ultrathick sectioning ‘hot knife’ procedure (<xref ref-type="bibr" rid="bib41">Hayworth et al., 2015</xref>) to first slice the brain into 20-μm-thick slabs which were better suited to FIB-SEM imaging. The Epon-embedded <italic>Drosophila</italic> brain block’s face was trimmed to present a width of just over 1 mm to the knife during sectioning (with the brain centered in this width). The length of the blockface was trimmed to be &gt;3 mm so that each cut section would have a large enough region of blank plastic surrounding the tissue to allow forceps to grasp it during later processing steps. All sides of the block were trimmed to be perpendicular to the face except the trailing edge which was trimmed to slope away at ≈ 45° (to prevent this trailing edge from deforming during hot knife sectioning). Hot knife sectioning was performed on our custom ultrathick sectioning testbed (<xref ref-type="bibr" rid="bib41">Hayworth et al., 2015</xref>). The block was cut at a speed of 0.1 mm/s into a total of 37 slices, each 20 μm thick, using an oil-lubricated (filtered thread cutting oil, Master Plumber) diamond knife (Cryo 25° from Diatome). The knife temperature was adjusted at the beginning of the run to ensure sections flowed smoothly across the knife surface without curling (too cold) or buckling (too hot). The knife temperature was measured to be 61°C at the end of the run. The knife was forced to oscillate via a piezo at 39 kHz during sectioning. A laser vibrometer (Polytec CLV-2534) was used to measure the amplitude of vibration at 0.5 μm peak-to-peak. Each thick section was collected individually from the knife surface by pressing a vacuum aspirator (extended fine tip plastic transfer pipette, Samco Scientific, attached to lab vacuum) onto the surface of the section. Each section was transferred to an individual well in the top of a 96-well microplate (Costar) into an awaiting oil drop. Once all sections were collected, they were transferred via forceps under a dissection microscope to a glass slide. The slide was placed on a hot plate (200°C) long enough (≈ 10 s) to flatten any residual curl in the sections. Each section was then imaged in a 20x light microscope to evaluate its quality.</p></sec><sec id="s7-2"><title>Flat embedding</title><p>Each of the 20-μm-thick Epon-embedded fly brain sections was re-embedded in Durcupan resin to allow high quality FIB-SEM imaging. Durcupan re-embedding was required because FIB milling of Epon-embedded tissue without a Durcupan front covering resulted in milling streaks which mar the SEM images (<xref ref-type="bibr" rid="bib125">Xu et al., 2017</xref>). Residual oil left over from the cutting process was first removed from each thick sections by dipping the section in Durcupan resin. Four drops of Durcupan resin were spaced out in sequence on a fresh glass slide. Each section was manually grasped with forceps (under a dissecting microscope) and dipped and lightly agitated sequentially in each Durcupan drops. Sections were gently wiped against the glass slide between each dipping to remove excess Durcupan and oil. After the final dipping, each section was placed (blockface side up) onto the heat-sealable side of a strip of 25 μm thick PET film (PP24I, Polymex Clear one side heat sealable/one side untreated polyester film, Polyester Converter Ltd.). Flat embedding tissue sections against this PET backing provided the strength needed for later mounting and handling. The PET film had been previously affixed to a glass slide for support, separated from the slide by a thin Kapton film designed to allow easy stripping of the PET. A gasket made from 50 μm thick adhesive-backed Kapton was positioned so as to surround all of the sections making a well for Durcupan resin to be poured into. This arrangement of sections was placed in a 65°C oven for ≈1 hr to partially cure the Durcupan so as to ‘tack’ the sections into position against the PET film. Then fresh Durcupan was poured to fill the well to its brim, and several large area pieces of 20-μm-thick Durcupan (previously cut from a blank block) were placed above the tissue sections to act as spacers during flat embedding to ensure that at least a 20 μm layer of Durcupan would exist in front of each tissue section during FIB milling. A piece of 25 μm Kapton film was laid on top of the Durcupan along with a glass slide and a weight was placed on top to press excess Durcupan out of the well. This flat embedding stack up was cured at 65°C for 2 days.</p></sec><sec id="s7-3"><title>Tab mounting, laser trimming, X-ray imaging</title><p>Each individual brain slab to be FIB-SEM imaged was cut out of this flat embedding using a scalpel, and the resulting ‘tab’ was affixed with cyanoacrylate (Super Glue) to a metal stud. An ultraviolet laser (LaserMill, New Wave Research) was used to trim away excess blank resin to minimize the FIB-milling time required. An X-ray micro-CT scan (Versa 520, Zeiss) was then performed on each tab prior to FIB-SEM imaging.</p></sec></sec><sec id="s8" sec-type="appendix"><title>Imaging</title><p>For the hemibrain, thirteen such slices were imaged using two customized enhanced FIB-SEM systems, in which an FEI Magnum FIB column was mounted at 90° onto a Zeiss Merlin SEM. Three different imaging conditions were used for different sections with details listed in <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>. In general, SEM images were acquired at 8 nm XY pixel size with a 4-nA beam with 1.2 kV landing energy, but other parameters were tuned for best imaging quality. Slices 24 to 27 were imaged with the specimen biased at + 600 V to prevent secondary electrons from reaching the detector, so that only backscattered electrons were collected. The electron beam energy was lowered to 600 V accordingly to maintain the same 1.2 kV landing energy. The remaining slices were imaged with specimen grounded at 0 V, and both secondary and backscattered electrons were collected to improve signal-to-noise ratio. As a result, SEM scanning rates were set at 2 MHz for slabs with specimen bias and 4 MHz for those without specimen bias. FIB milling was carried out by a 7-nA 30 kV Ga ion beam. Since optic lobes are typically more heavily stained than the central brain, the FIB milling step size in sections 22 to 30 was set to 2 nm, while the step size on sections 31 to 34 was set at 4 nm, to compensate for staining nonuniformity while preserving throughput and signal-to-noise ratio. The total FIB-SEM imaging time for the entire hemibrain was roughly four FIB-SEM-years: two years of on and off operation with two machines.</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>FIB-SEM imaging conditions.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Sample ID</th><th>Electron beam energy (kV)</th><th>Sample bias (kV)</th><th>Landing energy (kV)</th><th>SEM current (nA)</th><th>SEM scan rate (MHz)</th><th>x-y pixel (nm)</th><th>z-step (nm)</th></tr></thead><tbody><tr><td>Z0115-22_Sec22</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec23</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec24</td><td>0.6</td><td>0.6</td><td>1.2</td><td>4</td><td>2</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec25</td><td>0.6</td><td>0.6</td><td>1.2</td><td>4</td><td>2</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec26</td><td>0.6</td><td>0.6</td><td>1.2</td><td>4</td><td>2</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec27</td><td>0.6</td><td>0.6</td><td>1.2</td><td>4</td><td>2</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec28</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec29</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec30</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>2</td></tr><tr><td>Z0115-22_Sec31</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>4</td></tr><tr><td>Z0115-22_Sec32</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>4</td></tr><tr><td>Z0115-22_Sec33</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>4</td></tr><tr><td>Z0115-22_Sec34</td><td>1.2</td><td>0</td><td>1.2</td><td>4</td><td>4</td><td>8</td><td>4</td></tr></tbody></table></table-wrap></sec><sec id="s9" sec-type="appendix"><title>Slab alignment</title><p>From each of the flattened sections, we generated a multi-scale pyramid of the section faces. The highest resolution pyramid level sat exactly at the surface plane, had a thickness of 1 pixel and showed a significant amount of cutting artifacts. Lower levels of the pyramid were increasingly thicker, projecting deeper into the volume and showed larger structures.</p><p>The alignment was initialized with a regularized affine alignment for the complete series of face pairs using the feature based method by <xref ref-type="bibr" rid="bib102">Saalfeld et al., 2010</xref>. The pyramid of section face pairs was then used to robustly calculate pairwise deformations between adjacent sections. The faces are of notable size (&gt;30k<sup>2</sup> pixels) and expose many preparation artifacts such that off the shelf registration packages failed to process them reliably. We therefore developed a custom pipeline that was able to robustly align the complete series without manual corrections. Using the same feature-based method as above, an increasingly fine grid of local affine transformations was calculated and converted into a smooth and increasingly accurate interpolated deformation field. The resulting deformation field was further refined using a custom hierarchical optic flow method down to a resolution of 2 pixels. Optic flow minimizing the normalized cross correlation (NCC) was calculated for a pyramid of square block-sizes. For each pixel, the translation vector with the highest number of votes from all block-sizes was selected, and the resulting flow-field was further smoothed with an adaptive Gaussian filter that was weighted by the corresponding NCC.</p><p>The deformation fields were then applied to each section volume by smoothly interpolating between the deformation field at the top face and the affine transformation at the bottom face.</p><p>The block-based N5 format (<ext-link ext-link-type="uri" xlink:href="https://github.com/saalfeldlab/n5">https://github.com/saalfeldlab/n5</ext-link>; <xref ref-type="bibr" rid="bib103">Saalfeld, 2020a</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/n5">https://github.com/elifesciences-publications/n5</ext-link>) was used to store volumes, multi-scale face pyramids, deformation fields, meta-data, and to generate the final export. Apache Spark was used to parallelize on a compute cluster. The pipeline is open source and available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/saalfeldlab/hot-knife">https://github.com/saalfeldlab/hot-knife</ext-link>; <xref ref-type="bibr" rid="bib104">Saalfeld, 2020b</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/hot-knife">https://github.com/elifesciences-publications/hot-knife)</ext-link>.</p></sec><sec id="s10" sec-type="appendix"><title>Segmentation</title><sec id="s10-1"><title>Image adjustment with CycleGANs</title><p>To reduce photometric variation, we first normalized the contrast of the aligned EM images at full resolution ([8 nm]<sup>3</sup>/voxel) with CLAHE in planes parallel to the hot-knife cuts. In experiments targeted to small subvolumes we observed that segmentation quality decreased in certain areas of the hemibrain volume due to variations in the image content arising from, for example, fluctuations in staining quality as well as reduced contrast near the boundaries of the physically distinct 13 hot-knife ‘tabs’ that partitioned the original tissue volume. To compensate for these irregularities, we trained and applied CycleGAN (<xref ref-type="bibr" rid="bib138">Zhu et al., 2017</xref>) models. This unsupervised machine learning method was originally introduced to adjust the appearance of images from one set A (e.g. photos) to be similar to those from another set B (e.g. paintings), without being given any explicit pairings between elements of both sets. Here, we extended this method to 3D volumes, and used model architectures and training hyperparameters as previously described (<xref ref-type="bibr" rid="bib54">Januszewski and Jain, 2019</xref>), but without utilizing the flood-filling module.</p><p>We trained separate CycleGAN models to make data from every tab visually similar to that of a reference area spanning tabs 26 and 27 at [32 nm]<sup>3</sup> and [16 nm]<sup>3</sup> voxel sizes (i.e. using 4x, and 2x downsampled images, respectively), yielding a total of 20 CycleGAN models (no model was trained for tabs 26 and 27 at 32 nm and for tabs 23, 24, 26, and 27 at 16 nm). The reference area was chosen based on similarity to the region in which training data for segmentation models was located. The images in tabs 26 and 27 were sufficiently similar that no additional adjustment was required. The bounding boxes within the hemibrain volume used for training the CycleGAN models are specified in <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref>.</p><p>During training, a snapshot of network weights ('checkpoint') was saved every 30 min. CycleGAN inference was performed over a tab- and resolution-specific region of interest (ROI; see <xref ref-type="table" rid="app1table3">Appendix 1—table 3</xref>) with every saved checkpoint from the tab- and resolution-matched model. We then segmented the resulting volumetric images with a resolution-matched flood-filling network (FFN) model, and screened the segmentations for merge errors. Merge errors were identified by visually inspecting the largest objects (by the number of voxels) in the segmentations using a 3D mesh viewer (Neuroglancer). For every CycleGAN model, we selected checkpoints resulting in the minimum number of mergers, and then among these, selected the checkpoint corresponding to a segmentation with the maximum number of labeled voxels in objects containing at least 10,000 voxels.</p><p>We then performed CycleGAN inference with the selected checkpoint for every tab-resolution pair over the part of the aligned hemibrain volume corresponding to that tab. The stitched inference results were used as input volumes for tissue classification and neuron segmentation. CycleGAN normalization was not done at the native [8 nm]<sup>3</sup>/voxel resolution because there was insufficient evidence that the 8 nm FFN model could generalize well to different tabs.</p><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>Bounding boxes within the hemibrain volume used for training CycleGAN models.</title><p>Coordinates and sizes are given for [32 nm]<sup>3</sup> voxels. The same physical area of the hemibrain volume was used to train both 32 nm and 16 nm CycleGAN models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Tab</th><th colspan="3">Start</th><th colspan="3">Size</th></tr><tr><th/><th>X</th><th>Y</th><th>Z</th><th>X</th><th>Y</th><th>Z</th></tr></thead><tbody><tr><td>reference</td><td>4633</td><td>3792</td><td>2000</td><td>1374</td><td>2000</td><td>2000</td></tr><tr><td>22</td><td>8089</td><td>4030</td><td>1744</td><td>518</td><td>2000</td><td>2000</td></tr><tr><td>23</td><td>7435</td><td>3925</td><td>2101</td><td>654</td><td>2000</td><td>2000</td></tr><tr><td>24</td><td>6713</td><td>2939</td><td>4094</td><td>722</td><td>2000</td><td>2000</td></tr><tr><td>25</td><td>6017</td><td>2895</td><td>3635</td><td>694</td><td>2000</td><td>2000</td></tr><tr><td>28</td><td>3980</td><td>4944</td><td>3495</td><td>638</td><td>2000</td><td>2000</td></tr><tr><td>29</td><td>3307</td><td>2414</td><td>4094</td><td>666</td><td>2000</td><td>2000</td></tr><tr><td>30</td><td>2649</td><td>2519</td><td>4094</td><td>657</td><td>2000</td><td>2000</td></tr><tr><td>31</td><td>1979</td><td>2750</td><td>4094</td><td>670</td><td>2000</td><td>2000</td></tr><tr><td>32</td><td>1312</td><td>3065</td><td>4094</td><td>667</td><td>2000</td><td>2000</td></tr><tr><td>33</td><td>668</td><td>3101</td><td>3520</td><td>663</td><td>2000</td><td>2000</td></tr><tr><td>34</td><td>1</td><td>3112</td><td>3520</td><td>660</td><td>2000</td><td>2000</td></tr></tbody></table></table-wrap></sec><sec id="s10-2"><title>Tissue classification</title><p>We manually labeled voxels in 4 tabs of the hemibrain volume as belonging to one of 7 classes: ‘broken white tissue’, trachea, cell bodies, glia, large dendrites, neuropil, or ‘out of bounds’. We used these labels to train a 3D convolutional network that receives as input a field of view of 65 × 65 × 65 voxels at (16 nm)<sup>3</sup>/voxel resolution. The network uses 'valid' convolution padding and 'max' pooling operations with a kernel and striding shape of 2 × 2 × 2, with convolution and pooling operations interleaved in the following sequence: convolution with 64 features maps and a 3 × 3 × 3 kernel shape, max-pooling, convolution with 64 feature maps, max-pooling, convolution with 64 feature maps, max-pooling, convolution with 3 × 3 × 3 kernel size and 16 feature maps, convolution with 4 × 4 × 4 kernel shape 512 feature maps (i.e. fully connected layer), and finally a logistic layer output with eight units (the first unit was unused in the labeling scheme). The network was trained with data augmentation in which the order of the three spatial axes was randomly and uniformly permuted for each example during construction of the 16-example minibatch. For each example, the order of voxels along each spatial axis was also inverted at random with 50% probability. Examples from the seven classes were sampled randomly with equal probability. The model was implemented in TensorFlow and training was performed with asynchronous SGD on eight workers using NVIDIA P100 GPUs. The results can be viewed using NeuroGlancer at <ext-link ext-link-type="uri" xlink:href="https://hemibrain-dot-neuroglancer-demo.appspot.com/">https://hemibrain-dot-neuroglancer-demo.appspot.com/</ext-link><ext-link ext-link-type="uri" xlink:href="https://hemibrain-dot-neuroglancer-demo.appspot.com/#!gs://flyem-views/hemibrain/v1.0/mask-view.json">#!gs://flyem-views/hemibrain/v1.0/mask-view.json</ext-link>.</p><p>The resulting classifier output was, on certain slices of the hemibrain, manually proofread using a custom tool (‘‘Armitage’’). The inference and proofreading process was then iterated seven times in order to expand and improve the set of ground truth voxels, resulting in a final ground truth set with the following number of examples in each class (sizes in Mxv, or megavoxels): 9.7 Mvx broken white tissue, 22.9 Mvx trachea, 42.1 Mvx cell bodies, 5.6 Mvx glia, 17.7M Mvx large dendrites, 71.4 Mvx neuropil, and 208.1 Mvx out of bounds.</p></sec><sec id="s10-3"><title>Mitochondria classification</title><p>We detected and classified mitochondria within the hemibrain volume using the same neural network architecture and training setup as that used for tissue classification. Ground truth data was collected through iterative annotation (two rounds) in Armitage, in which voxels within hemibrain were manually annotated as belonging to one of 4 classes: ‘background’ (33.7 Mvx), ‘regular’ (0.7 Mvx), ‘special’ (0.5 Mvx), and ‘intermediate’ (0.5 Mvx).</p><table-wrap id="app1table3" position="float"><label>Appendix 1—table 3.</label><caption><title>ROIs within the hemibrain volume used for CycleGAN checkpoint selection.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Tab</th><th>Voxel Res. [nm]</th><th colspan="3">Start</th><th colspan="3">Size</th></tr><tr><th/><th/><th>X</th><th>Y</th><th>Z</th><th>X</th><th>Y</th><th>Z</th></tr></thead><tbody><tr><td>22</td><td>32</td><td>8092</td><td>4392</td><td>5447</td><td>500</td><td>936</td><td>936</td></tr><tr><td>23</td><td>32</td><td>7435</td><td>2479</td><td>4979</td><td>500</td><td>936</td><td>936</td></tr><tr><td>24</td><td>32</td><td>6717</td><td>5414</td><td>4873</td><td>500</td><td>936</td><td>936</td></tr><tr><td>25</td><td>32</td><td>6010</td><td>3960</td><td>6235</td><td>500</td><td>936</td><td>936</td></tr><tr><td>28</td><td>32</td><td>3971</td><td>2591</td><td>2954</td><td>500</td><td>936</td><td>936</td></tr><tr><td>29</td><td>32</td><td>3471</td><td>4252</td><td>2224</td><td>500</td><td>936</td><td>936</td></tr><tr><td>30</td><td>32</td><td>2650</td><td>2995</td><td>4875</td><td>500</td><td>936</td><td>936</td></tr><tr><td>31</td><td>32</td><td>1982</td><td>3196</td><td>4875</td><td>500</td><td>936</td><td>936</td></tr><tr><td>32</td><td>32</td><td>1311</td><td>3141</td><td>4873</td><td>500</td><td>936</td><td>936</td></tr><tr><td>33</td><td>32</td><td>664</td><td>2850</td><td>4875</td><td>500</td><td>936</td><td>936</td></tr><tr><td>34</td><td>32</td><td>0</td><td>1900</td><td>4500</td><td>500</td><td>5000</td><td>2500</td></tr><tr><td>22</td><td>16</td><td>16080</td><td>8353</td><td>9871</td><td>1034</td><td>936</td><td>936</td></tr><tr><td>25</td><td>16</td><td>11900</td><td>12657</td><td>12636</td><td>1406</td><td>936</td><td>936</td></tr><tr><td>25</td><td>16</td><td>11900</td><td>5266</td><td>10578</td><td>1408</td><td>936</td><td>936</td></tr><tr><td>28</td><td>16</td><td>7900</td><td>9279</td><td>4613</td><td>1297</td><td>936</td><td>936</td></tr><tr><td>29</td><td>16</td><td>6550</td><td>8520</td><td>4613</td><td>1333</td><td>936</td><td>936</td></tr><tr><td>30</td><td>16</td><td>5250</td><td>7997</td><td>7510</td><td>1315</td><td>936</td><td>936</td></tr><tr><td>31</td><td>16</td><td>3860</td><td>7749</td><td>7510</td><td>1340</td><td>936</td><td>936</td></tr><tr><td>32</td><td>16</td><td>2550</td><td>9482</td><td>4225</td><td>1334</td><td>936</td><td>936</td></tr><tr><td>33</td><td>16</td><td>1280</td><td>7176</td><td>12265</td><td>1298</td><td>936</td><td>936</td></tr><tr><td>34</td><td>16</td><td>0</td><td>7587</td><td>12265</td><td>1328</td><td>936</td><td>936</td></tr></tbody></table></table-wrap></sec><sec id="s10-4"><title>Automated neuron segmentation with FFNs</title><p>We trained three FFN models composed of the same architecture as detailed in previous work (<xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>) for FIB-SEM volumes, targeted specifically for 8 nm, 16 nm, and 32 nm voxel resolution data. For the 8 nm model we used manually generated ground truth spread over six subvolumes (520<sup>3</sup> voxels each) located within the ellipsoid body, fan-shaped body and protocerebral bridge. The 16 nm and 32 nm models were trained with a proofread segmentation contained within a 8600 × 3020 × 9500 voxel region spanning tabs 26 and 27. For the 32 nm model, training examples were sampled from objects comprising 5000 or more labeled voxels at 32 nm/voxel resolution. In total, 4.2 Gvx of labeled data were used for the 16 nm model and 423 Mvx for the 32 nm model.</p><p>We split the training examples into ‘probability classes’ similarly to <xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>. Classes 13–17 were not sampled when training the 8 nm model in order to bias it toward small-diameter neurites. For 16 nm and 32 nm models fewer classes were used and the first class comprising all initial training examples with the fraction of voxels set to <inline-formula><mml:math id="inf28"><mml:mrow><mml:mrow><mml:mn>0.95</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>. Other than the changes regarding the probability classes, we followed the same procedures for training example sampling, seed list generation, field-of-view movement, and distributed inference as detailed previously (<xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>).</p><p>FFN checkpoints were selected in a screening process. We generated tab 24 segmentations at 16 and 32 nm voxel resolution for every available checkpoint. We then screened these segmentations for merge errors, annotating every such error with two points, one in each distinct neurite. The segmentation generated with an FFN checkpoint that avoided the most errors was selected. For the 8 nm segmentation, we followed the same procedure but restricted to a 500<sup>3</sup> subvolume within tab 24, located at 23284, 1540, 12080.</p></sec></sec><sec id="s11" sec-type="appendix"><title>Pipeline for segmentation of hemibrain with flood-filling networks</title><sec id="s11-1"><title>Multi-resolution and oversegmentation consensus</title><p>We built the hemibrain segmentation with a coarse-to-fine variant of the FFN pipeline (<xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>) combining partial segmentations generated at different resolutions. First, we used the 16 nm and 32 nm FFN models to segment the dataset at the corresponding resolution, with voxels identified by the tissue classifier as glia and out-of-bounds excluded from FFN FOV movement (‘tissue masking’), and voxels classified as ‘broken white tissue’ excluded from seed generation. Voxels located within 128 nm from every hot knife plane were removed from the image data, and segmentation proceeded as if these regions did not exist. The resulting segmentation was extended back to the original coordinate system by nearest neighbor interpolation to fill the unsegmented spaces.</p><p>We then removed objects smaller than 10,000 voxels from the 32 nm segmentation (we will refer to the resulting segmentation as S32), isotropically upsampled it 2x, and combined it with the 16 nm segmentation using oversegmentation consensus (<xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref>). The resulting segmentation (S16) was used as the initial state for 8 nm FFN inference. In addition to tissue masking which was applied in the same way as in the case of lower resolution segmentations, we also masked areas within 32 voxels (at 8 nm/voxel resolution) from each hot-knife plane.</p><p>FlyEM proofreaders analyzed the roughly 200,000 largest objects in the segmentation, and manually split supervoxels identified as causing merge errors. This was done in three iterations – two targeting neuropil supervoxels, and one targeting cell bodies. The resulting corrected segmentation (S8) was used as the base segmentation for further work.</p></sec><sec id="s11-2"><title>Agglomeration</title><p>For agglomeration, we modified the scheme described in <xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref> for use with resolution-specific FFN models. First, we established a class for every segment by performing a majority vote of the tissue classification model predictions over the voxels covered by the segment. For every S16 segment (A, B), we also identified the maximally overlapping segment in S32 (denoted respectively <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf30"><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> below). For each of the S32, S16, and S8 segmentations, we then computed candidate object pairs and agglomeration scores, restricting object pairs to ones involving both segments classified as either neuropil or ‘large dendrite’. For S8, the object pairs were additionally restricted to those that included at least one object not present in S16.</p><p>For every evaluated segment pair (A, B) and the corresponding segments (A*, B*) generated during agglomeration, we computed the scores originally defined in <xref ref-type="bibr" rid="bib53">Januszewski et al., 2018</xref> that is the recovered voxel fractions (<inline-formula><mml:math id="inf31"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf32"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf33"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the fraction of B found in A*, and so on), the Jaccard index JAB between A* and B*, and the number of voxels contained in A* or B* that had been 'deleted' (i.e., during inference their value in the predicted object mask fell from <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi/><mml:mo>&gt;</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi/><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>) during one of the runs (dA, dB).</p><p>We then used the following criteria to connect segments A and B. In S32, we connected segments that were scored as <inline-formula><mml:math id="inf38"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁣</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁣</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> In S16, we connected segments that either (a) were scored as <inline-formula><mml:math id="inf39"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mo>*</mml:mo></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn></mml:mrow></mml:math></inline-formula> or were both classified as neuropil, and <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mrow><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, or (b) were both classified as neuropil, <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf43"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁣</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁣</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.9</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In S8, we connected segments that were scored as <inline-formula><mml:math id="inf44"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>Given the application of oversegmentation consensus in the process of building S16, objects created in S32 could have a different shape in S8. To compensate for this possibility, when agglomeration scores were being computed for S32 segments A and B, for each we computed up to eight maximally overlapping objects (A’, B’) in a downsampled version of S8 with matching voxel resolution, subject to a minimum overlap size of 1000 voxels and considered the agglomeration decision to apply to all combinations of A’ and B’.</p></sec><sec id="s11-3"><title>Agglomeration constraints</title><p>From the procedure above, we used the agglomeration scores to organize segment connection decisions into priority groups and assign them a single numerical priority score (see <xref ref-type="table" rid="app1table4">Appendix 1—table 4</xref>). The decisions were then sorted in ascending order of the priority score, and sequentially processed, removing any decisions that would cause two cell bodies (as defined by manual annotations), or two segments previously separated manually in S8 proofreading to be connected was removed. Additionally, once all decisions with score &lt;10 were processed, we also disallowed any remaining decisions that connected together any objects larger than 100 Mvx.</p><table-wrap id="app1table4" position="float"><label>Appendix 1—table 4.</label><caption><title>Criteria for agglomerating priority groups.</title><p>If an agglomeration decision fulfills the criteria for multiple priority groups, it is assigned to the one with the lowest resulting score.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Group</th><th>Segmentation</th><th>Criterion</th><th>Score</th></tr></thead><tbody><tr><td>1</td><td>S32</td><td><inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∧</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>∗</mml:mo><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf46"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>2</td><td>S16</td><td><inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∧</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>∗</mml:mo><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∧</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∧</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/>A and B are classified as neuropil</td><td><inline-formula><mml:math id="inf48"><mml:mrow><mml:mn>2</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>3</td><td>S16</td><td><inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∧</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>∗</mml:mo><mml:mo>∗</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>∧</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf50"><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>4</td><td>S16</td><td><inline-formula><mml:math id="inf51"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo></mml:mrow></mml:math></inline-formula> <break/>A and B are classified as neuropil</td><td><inline-formula><mml:math id="inf52"><mml:mrow><mml:mn>4</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>5</td><td>S16</td><td><inline-formula><mml:math id="inf53"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mn>0.02</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf54"><mml:mrow><mml:mn>5</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>6</td><td>S32</td><td><inline-formula><mml:math id="inf55"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo></mml:mrow></mml:math></inline-formula> A and B are classified as neuropil</td><td><inline-formula><mml:math id="inf56"><mml:mrow><mml:mn>6</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>7</td><td>S16</td><td><inline-formula><mml:math id="inf57"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>∨</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf58"><mml:mrow><mml:mn>7</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>8</td><td>S16</td><td><inline-formula><mml:math id="inf59"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>∧</mml:mo></mml:mrow></mml:math></inline-formula> <break/>A and B are classified as neuropil</td><td><inline-formula><mml:math id="inf60"><mml:mrow><mml:mn>8</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>9</td><td>S16</td><td><inline-formula><mml:math id="inf61"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi/><mml:mo>*</mml:mo><mml:mo>*</mml:mo></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mrow><mml:mn>0.6</mml:mn><mml:mo>∧</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0.4</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></td><td><inline-formula><mml:math id="inf62"><mml:mrow><mml:mn>9</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>10</td><td>S8</td><td>None</td><td><inline-formula><mml:math id="inf63"><mml:mrow><mml:mn>11</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></td></tr><tr><td>11</td><td>S32</td><td>None</td><td><inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mn>12</mml:mn><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td>12</td><td>S16</td><td>None</td><td><inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mn>13</mml:mn><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s11-4"><title>Speculative agglomeration</title><p>Any body (or set of segments connected by the agglomeration graph) larger than 10 Mvx was considered to be an ‘anchor’ body. We connected smaller bodies to these anchor bodies in a greedy procedure to further reduce the total number of bodies in the agglomerated segmentation. We formed body pair scores using segment pair agglomeration scores as <inline-formula><mml:math id="inf66"><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mo>⁢</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We then merged every body with its highest scoring candidate partner, as long as this would not connect two anchor bodies, and the body pair score was &gt;0.1. This procedure was repeated seven times.</p></sec></sec><sec id="s12" sec-type="appendix"><title>Synapse prediction</title><sec id="s12-1"><title>Ground truth</title><p>For training and validation, we collected dense synapse annotations within small cubes, spread through different brain regions. In total, we collected 122 such cubes, using 25 for classifier training, and the remaining 97 for validation. At each cube location, proofreaders manually annotated all T-bars within a 400<sup>3</sup> window, and further annotated all PSDs attached to T-bars within a smaller 256<sup>3</sup> sub-window. In total, 7.6k T-bars were annotated, split between 1.8k for training and 5.8k for validation, and 11.7k PSDs were annotated, split between 3k for training and 8.7k for validation.</p></sec><sec id="s12-2"><title>Method</title><p>Details of the T-bar and PSD detection algorithms we used can be found in <xref ref-type="bibr" rid="bib47">Huang et al., 2018</xref>. For reference, the T-bar classifier is a 3D CNN using a U-Net architecture (<xref ref-type="bibr" rid="bib100">Ronneberger et al., 2015</xref>), with a receptive field size of 40<sup>3</sup> voxels and 770 k parameters.</p><p>At inference, we leverage the tissue classification results mentioned above by discarding any predictions that fell outside of tissue categories of large dendrites or neuropil.</p><p>As mentioned in the main text, after collecting ground-truth throughout additional brain regions, we found that our initial T-bar classifier was giving lower than desired recall in certain areas. Therefore, we trained a new classifier, and combined the results in a cascade fashion, which we found gave better results than simply replacing the initial predictions. Specifically, we added any predictions above a given confidence threshold made by the new classifier for synapses that were not near an existing prediction, and removed any existing predictions that were far from predictions made by the new classifier at a second lower/conservative threshold.</p><p>One difficulty in placing a single T-bar annotation at each presynaptic location is a certain ambiguity with respect to ‘multi T-bars’, cases in which two distinct T-bar pedestals lay in close proximity, within the same neuron. Such a case can be difficult to distinguish from a single large synapse, both for manual annotators as well as the automated prediction algorithm. To make such a distinction reliably would require obtaining many training examples for both cases (multi T-bar versus single large synapse), and would only have a slight effect on the final weights of the connectome (but not the unweighted connectivity). Therefore, we make no attempt to predict multi T-bars, and instead as a final post-processing step, collapse to a single annotation any T-bar annotations that are in close proximity and in the same segmented body.</p><p>Finally, we observed that in certain brain regions, there are instances of T-bars in separate bodies but in close proximity to one another. These often form a ‘convergent T-bars’ motif, in which multiple T-bars closely situated in distinct bodies form a synapse onto the same PSD body. The proximity of such T-bars is often less than the distance threshold used in the non-maxima suppression (NMS) that is applied to generate the T-bar annotations from the pixel-wise U-Net predictions. Given the NMS, a number of these types of T-bars would be missed by our predictor.</p><p>To address this issue, we modified the post-processing of pixel-wise predictions so as to use a ‘segmentation-aware NMS’. Specifically, we constrain the NMS applied to each pixel-wise local maxima to largely be limited to the specific segment in which the maxima occurs. Each segment is dilated slightly to avoid additional predictions that only fall a very small number of voxels outside the segment containing the maxima. (Note that unlike standard NMS, this procedure does require that the automated segmentation be available prior to inference.) We apply the segmentation-aware NMS only in brain regions where convergent T-bars were observed, as occurs in the mushroom body and fan-shaped body.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Precision-recall plot of T-bar prediction.</title><p>The purple intercept indicates estimated manual agreement rate of 0.9. Data available in <xref ref-type="supplementary-material" rid="app1fig1sdata1">Appendix 1—figure 1—source data 1</xref>.</p><p><supplementary-material id="app1fig1sdata1"><label>Appendix 1—figure 1—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>.</title><p>Column A: initial recall; column B: initial precision; column C: cascade recall; column D: cascade precision.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-app1-fig1-data1-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-app1-fig1-v3.tif"/></fig></sec><sec id="s12-3"><title>Evaluation</title><p><xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> gives the precision-recall plot for T-bar prediction, averaged over all the available ground-truth validation cubes. As mentioned above, we do not attempt to predict multi T-bars; therefore, for the purposes of evaluation, we also collapse any ground-truth T-bars within close proximity in the same body to a single annotation. As can be seen from the figure, the cascade predictions are able to increase recall while maintaining precision. One of the primary error modes that leads to a difference between automated accuracy and manual agreement rate is the case of convergent T-bars, noted above. For instance, in <xref ref-type="fig" rid="fig5">Figure 5</xref> of the main text, the brain region with lowest recall is b’L in the mushroom body; closer analysis revealed many convergent T-bars in the annotated ground-truth cubes for b’L.</p><p><xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref> below in the next subsection gives the corresponding precision-recall plot for end-to-end synapse prediction, averaged over all the available ground-truth validation cubes. As with both (<xref ref-type="bibr" rid="bib47">Huang et al., 2018</xref>) and (<xref ref-type="bibr" rid="bib12">Buhmann et al., 2019</xref>), we do not attempt to predict autapses, and remove any predicted connections that lie within the same neuron. For evaluation, any occasional ground-truth autapses are filtered out.</p></sec><sec id="s12-4"><title>Additional classifier</title><p>As an independent check on synapse quality, we also trained a separate classifier proposed by Buhmann (<xref ref-type="bibr" rid="bib12">Buhmann et al., 2019</xref>), using the ‘synful’ software package provided. We additionally made several modifications to the code, including: adding an ‘ignore’ region around synapse blobs where predictions were not penalized, using focal loss (<xref ref-type="bibr" rid="bib70">Lin et al., 2017</xref>) to help with class imbalance, using batch normalization (<xref ref-type="bibr" rid="bib49">Ioffe and Szegedy, 2015</xref>) and residual layers (<xref ref-type="bibr" rid="bib43">He et al., 2016</xref>), and adding explicit T-bar prediction as an additional network output. We found this multi-task learning (adding explicit T-bar prediction to PSD prediction and partner direction prediction) to be beneficial, similar to the use of cleft prediction in <xref ref-type="bibr" rid="bib12">Buhmann et al., 2019</xref>, most likely due to the T-bar pedestals being a more reliable and prominent signal in our hemibrain preparation/staining than the PSDs. We refer to this network and its resulting synapse predictions as ‘synful+’.</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Precision-recall plot of end-to-end synapse prediction.</title><p>The purple intercept indicates estimated manual agreement rate of 0.8. Data available in <xref ref-type="supplementary-material" rid="app1fig2sdata1">Appendix 1—figure 2—source data 1</xref>.</p><p><supplementary-material id="app1fig2sdata1"><label>Appendix 1—figure 2—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</title><p>Column A: initial recall; column B: initial precision; column C: cascade recall; column D: cascade precision; column E: hybrid recall; column F: hybrid precision; column G: synfulp recall; column H: synfulp precision.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-app1-fig2-data1-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-app1-fig2-v3.tif"/></fig><p><xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref> shows the overall end-to-end precision-recall plots for each of the classifiers. As mentioned in the main text, we combined the predictions from the cascade and synful+ classifiers to yield a ‘hybrid’ classifier that achieved both better recall and precision than the two individual classifiers. Specifically, we modified the cascade predictions by (1) adding any PSDs that were predicted with strong confidence by synful+ and attached to existing T-bars, and (2) removing any PSDs that were predicted with weak confidence by the cascade classifier and not predicted by synful+ even at a very low confidence threshold.</p></sec><sec id="s12-5"><title>Pathway analysis</title><p>Given two independent sets of synapse predictions (cascade and synful+), we further conduct an analysis of their respective connectivity graphs. We construct connectomes from each set of synapse predictions, limited to the 21,000+ traced bodies. At the level of individual synapses, the two sets of predictions have an agreement rate of about 80%.</p><p>However, we can look at connections of a given strength in one set of predictions, and see whether the other set of predictions gives a corresponding connection of any strength. For instance, among bodies that are connected with at least five synapses in the cascade predictions, less than 1% have no connection in the synful+ predictions, and similarly, among bodies that are connected with at least five synapses in the synful+ predictions, less than 2% have no connection in the cascade predictions. This suggests some level of stability in edges with a stronger connection, so that using a different classifier would be still likely to maintain that edge.</p><p>We also further manually assessed the small percentage of outlier edges. We sampled 100 synapses from the strongest of the edges in the cascade predictions that are not present in the synful+ predictions, and similarly 100 synapses from the synful+ predictions. For the cascade predictions, we find an overall accuracy of 64%, lower than the general accuracy of the cascade predictor, but we did not observe a pathway in which all sampled synapses were false positives. For the synful+ predictions, we found that all sampled synapses were false positives, resulting from improper placement of the T-bar annotation, thereby assigning the T-bar to an incorrect body. This suggests another use for such pathway analysis, in potentially discovering particular error modes of a classifier and allowing for re-training/refining to address such errors.</p><p>As a related measure of connectome stability, we also looked at how often the magnitude of the pathway connections were comparable. For instance, we can examine connections consisting of at least 10 synapses in one prediction set, and see how often those connections are within a factor of 2 in the other prediction set. We find that this holds for 93% of the connections of strength greater than 10. <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref> shows a plot comparing pathway connection strength between the two sets of predictions.</p><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Comparison of synful+ connection strength versus cascade connection strength (truncated at a connection strength of 500 for clarity, omitting 40 edges from each prediction set).</title><p>Data available in <xref ref-type="supplementary-material" rid="app1fig3sdata1">Appendix 1—figure 3—source data 1</xref>.</p><p><supplementary-material id="app1fig3sdata1"><label>Appendix 1—figure 3—source data 1.</label><caption><title>Data for <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>.</title><p>Column A: cascade synapse count; column B: synfulp synapse count; column C: frequency of this pair in our data.</p></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-57443-app1-fig3-data1-v3.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57443-app1-fig3-v3.tif"/></fig></sec></sec><sec id="s13" sec-type="appendix"><title>Logistics and management</title><p>The hemibrain reconstruction required a large-scale effort involving several research labs, Janelia shared services, about ten staff scientists, and about 60 proofreaders. The overall initiative planning, including the choice of biological regions to image and reconstruct, timeline, and budget, was orchestrated by the FlyEM project team at the Janelia Research Campus with a guiding steering committee composed of several experts within the institute. The Connectomics Group at Google Research collaborated extensively with FlyEM developing key technology to segment the hemibrain volume.</p><p>Extensive orchestration by project staff and Janelia shared services was required to manage the team of proofreaders and the reconstruction effort. Our proofreading team consisted of full-time technicians hired specifically for proofreading. To satisfy the ambitious reconstruction goals of the hemibrain effort, we hired close to 30 people in a few months to augment the existing proofreading resources, requiring a streamlined system of recruitment and training. We found that the average proofreader required around 2 months of training to become reasonably proficient in EM tracing, which entailed working on carefully designed training modules and iterative feedback with more experienced proofreaders or managers. Ongoing training was necessary for both new and experienced proofreaders to meet the needs of different reconstruction tasks. The team of proofreaders had frequent meetings, and a Slack channel, with the software staff to improve proofreading software. We found that for a project of this size, several additional software personnel were required for data management, monitoring, orchestrating, and streamlining proofreading assignments.</p><p>The hemibrain reconstruction involved several different reconstruction steps or workflows, many discussed in the paper. The primary workflows were cleaving, false split review, focused proofreading, and orphan linking. Cleaving is the task of splitting a falsely merged segment. False split review entails examining a neuron, using 3D morphology, for potential false splits. Focused proofreading is a ‘merge’ or ‘don’t merge’ protocol based on automated suggestions from the segmentation algorithm. Orphan linking is fixing small detached segments that should either be annotated as exiting the hemibrain dataset, or be merged to a larger, already proofread body. Overall, we estimate that we undertook ≈ 50–100 proofreading years of reconstruction effort.</p></sec><sec id="s14" sec-type="appendix"><title>Anatomical names in the central complex</title><p><xref ref-type="table" rid="app1table5">Appendix 1—table 5</xref> provides two names for CX neurons: a short name useful for searching databases and an anatomical name that reveals morphological insight indicated by the input and output neuropils in the name. Previously published neurons (e.g. PB, NO, AB, EB ring neurons) now have short names, but their anatomical names are largely unchanged. Slight modifications were made to two neuron names to eliminate duplications with names in other brain regions or species: LN was changed to LNO1 and LGN to LGNO. In addition, the hyphens used in the abbreviated neuron names in <xref ref-type="bibr" rid="bib123">Wolff and Rubin, 2018</xref> have been eliminated. The new anatomical names are limited to three neuropils: two input followed by an output brain region. Neurons that arborize in only two structures are named by the input followed by output neuropil. Two-letter abbreviations are used for the CX brain regions: PB, FB, EB, NO, and AB. All remaining neuropils follow the three-letter abbreviations established in <xref ref-type="bibr" rid="bib52">Ito et al., 2014</xref>.</p><p>For fan-shaped body columnar and tangential cell anatomical names, numbers that follow ‘FB’ indicate layers, and layer numbers followed by a lower case ‘d’ or ‘v’ indicate the arbor is restricted to the dorsal or ventral half of the indicated layer (e.g. FB6d). Many FB arbors extend vertically to span more than one layer, a form that is indicated by sequential numbers separated by commas (e.g. FB2,3,4 indicates a single, vertical arbor that extends across layers 2, 3, and 4 of the FB). Some FB neurons have two distinct arbors in different layers; these are indicated by a gap in the layer numbers (e.g. FB2,6 has one arbor in layer 2 and a second in layer 6).</p><p>Inevitably, the large number of cell types and three-neuropil limit for anatomical names results in redundancy in neuron names. To give a unique identity to each name, ‘_#’ is appended to otherwise indistinguishable names (e.g. LALCREFB2_1 and LALCREFB2_2).</p><p>The nomenclature system for the anatomical names was designed to enable visualization of a neuron’s morphology. High synaptic density generally correlates with more prominent arbors in light level images and therefore provides a visual depiction of the neuron’s overall shape. In most cases, synaptic density was therefore used as the primary metric in naming neurons. Synapse counts were retrieved from the neuPrint database. Only fully traced neurons from the right hemisphere were used in this analysis.</p><p>Different criteria were applied to FB tangential and columnar neurons when selecting neuropils to include in neuron names. The FB tangential neurons exhibit the greatest number of both presynaptic and postsynaptic terminals within a single FB layer, so naming these neurons based on neuropils with highest synaptic density would limit morphological insight. For example, FB layer 2 tangential neurons would be named FB2-neuropil X-FB2, FB2-neuropil Y-FB2, etc. Furthermore, since only a small number of neuropils are frequently arborized by the FB tangential neurons (e.g., SLP, SIP, SMP, CRE), names would be highly redundant. Instead, a more complete visual representation of a cell’s morphology is achieved by using the brain regions with the second and third greatest number of input synapses (the first and second neuropils in the name). FB layer information is included in the third, or output, neuropil since presynaptic arbors are greatest in the FB in tangential neurons.</p><p>Occasional exceptions were made to include neuropils that would provide deeper insight into morphology. For example, according to the rules above, CRENO2FB4_2 (FB4M) should be named CRELALFB4 or CRESMPFB4 since 10–12% of input synapses are in the LAL and in the CRE, whereas only 6% are in NO2. An exception was made in this cell’s name since arbors in the noduli distinguish this cell from other CRELALFB4 and CRESMPFB4 cells. Similarly, for neurons with equivalent synaptic density in several neuropils, those neuropils that best portrayed the neuron’s unique morphology were chosen (e.g. SIPSCLFB2, or FB2H_a and FB2H_b).</p><table-wrap id="app1table5" position="float"><label>Appendix 1—table 5.</label><caption><title>Corresponding short and anatomical names for cell types in the central complex.</title><p>These types were determined by different methods and different researchers, using different criteria.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Short</th><th>Long</th><th/><th>Short</th><th>Long</th><th/><th>Short</th><th>Long</th><th/><th>Short</th><th>Long</th></tr></thead><tbody><tr><td>vDeltaA_a</td><td>AF</td><td/><td>FB3B</td><td>EBCREFB3</td><td/><td>FB6C_a</td><td>SIPSMPFB6_1</td><td/><td>FC2B</td><td>FB1d,3,5,6CRE</td></tr><tr><td>vDeltaA_b</td><td>FB1D0FB8</td><td/><td>FB3C</td><td>LALSMPFB3</td><td/><td>FB6C_b</td><td>SIPSMPFB6_1</td><td/><td>FC2C</td><td>FB1d,3,6,7CRE</td></tr><tr><td>vDeltaB</td><td>FB1D0FB7_1</td><td/><td>FB3D</td><td>LALCREFB3</td><td/><td>FB6D</td><td>SMPFB6</td><td/><td>FC3</td><td>FB2,3,5,6CRE</td></tr><tr><td>vDeltaC</td><td>FB1D0FB7_2</td><td/><td>FB3E</td><td>SMPLALFB3</td><td/><td>FB6E</td><td>SIPSMPFB6_2</td><td/><td>FR1</td><td>FB2-5RUB</td></tr><tr><td>vDeltaD</td><td>FB1D0FB6</td><td/><td>FB4A</td><td>CRESMPFB4_1</td><td/><td>FB6F</td><td>SMPSIPFB6_3</td><td/><td>FR2</td><td>FB2-4RUB</td></tr><tr><td>vDeltaE</td><td>FB1,2,3D0FB6v</td><td/><td>FB4B</td><td>NO2LALFB4</td><td/><td>FB6G</td><td>SIPSMPFB6_3</td><td/><td>FS1A</td><td>FB2-6SMPSMP</td></tr><tr><td>vDeltaF</td><td>FB1,2,3D0FB5d</td><td/><td>FB4C</td><td>CRENO2FB4_1</td><td/><td>FB6H</td><td>SMPSIPFB6_4</td><td/><td>FS1B</td><td>FB2,5,SMPSMP</td></tr><tr><td>vDeltaG</td><td>FB1,2D0FB5d</td><td/><td>FB4D</td><td>CRESMPFB4_2</td><td/><td>FB6I</td><td>SMPSIPFB6_5</td><td/><td>FS2</td><td>FB3,6SMP</td></tr><tr><td>vDeltaH</td><td>FB1,2D0FB5</td><td/><td>FB4E</td><td>CRELALFB4_1</td><td/><td>FB6J</td><td>FB6_1</td><td/><td>FS3</td><td>FB1d,3,6,7SMP</td></tr><tr><td>vDeltaI</td><td>FB1D0FB5</td><td/><td>FB4F_a</td><td>CRELALFB4_2</td><td/><td>FB6K</td><td>SMPSIPFB6_6</td><td/><td>FS4A</td><td>FB3,8ABSMP</td></tr><tr><td>vDeltaJ</td><td>FB1D0FB5v</td><td/><td>FB4F_b</td><td>CRELALFB4_2</td><td/><td>FB6L</td><td>FB6_2</td><td/><td/><td>FB1,3,8SMP</td></tr><tr><td>vDeltaK</td><td>FB1vD0FB4d5v</td><td/><td>FB4G</td><td>CRELALFB4_3</td><td/><td>FB6M</td><td>WEDLALFB6</td><td/><td>FS4B</td><td>FB2,8ABSMP</td></tr><tr><td>vDeltaL</td><td>FB1vD0FB4</td><td/><td>FB4H</td><td>CRELALFB4_4</td><td/><td>FB6N</td><td>CRESMPFB6_1</td><td/><td/><td>FB1,2,8SMP</td></tr><tr><td>vDeltaM</td><td>FB1vD0FB4</td><td/><td>FB4I</td><td>LALCREFB4</td><td/><td>FB6O</td><td>SIPSMPFB6_4</td><td/><td>FS4C</td><td>FB2,6,7SMP</td></tr><tr><td>hDeltaA</td><td>FB4D5FB4</td><td/><td>FB4J</td><td>CRELALFB4_5</td><td/><td>FB6P</td><td>SMPCREFB6_1</td><td/><td>GLNO</td><td>LGNO</td></tr><tr><td>hDeltaB</td><td>FB3,4vD5FB3,4v</td><td/><td>FB4K</td><td>CRESMPFB4_3</td><td/><td>FB6Q</td><td>SIPSMPFB6_5</td><td/><td>IbSpsP</td><td>IbSpsP</td></tr><tr><td>hDeltaC</td><td>FB2,6D7FB6</td><td/><td>FB4L</td><td>LALSIPFB4</td><td/><td>FB6R</td><td>SMPSIPFB6_7</td><td/><td>LCNOp</td><td>LCNp</td></tr><tr><td>hDeltaD</td><td>FB1,8D3FB8</td><td/><td>FB4M</td><td>CRENO2FB4_2</td><td/><td>FB6S</td><td>SIPSMPFB6_6</td><td/><td>LCNOpm</td><td>LCNpm</td></tr><tr><td>hDeltaE</td><td>FB1,7D3FB7</td><td/><td>FB4N</td><td>SMPCREFB4</td><td/><td>FB6T</td><td>SIPSMPFB6_7</td><td/><td>LNO1</td><td>LNO1</td></tr><tr><td>hDeltaF</td><td>FB1,6d,7D2FB6,7</td><td/><td>FB4O</td><td>CRESMPFB4d</td><td/><td>FB6U</td><td>SMPCREFB6_2</td><td/><td>LNO2</td><td>LNO2</td></tr><tr><td>hDeltaG</td><td>FB2,3,5d6vD3FB6v</td><td/><td>FB4P_a</td><td>CRESMPFB4_ 4</td><td/><td>FB6V</td><td>SMPCREFB6_3</td><td/><td>LNO3</td><td>LNO3</td></tr><tr><td>hDeltaH</td><td>FB2d,4D3FB5</td><td/><td>FB4P_b</td><td>CRESMPFB4_ 4</td><td/><td>FB6W</td><td>CRESMPFB6_2</td><td/><td>LNOa</td><td>LNa</td></tr><tr><td>hDeltaI</td><td>FB2,3,4,5D5FB4,5v</td><td/><td>FB4Q_a</td><td>CRESMPFB4_5</td><td/><td>FB6X</td><td>SMPCREFB6_4</td><td/><td>LPsP</td><td>LPsP</td></tr><tr><td>hDeltaJ</td><td>FB1,2,3,4D5FB4,5</td><td/><td>FB4Q_b</td><td>CRESMPFB4_5</td><td/><td>FB6Y</td><td>SMPSIPFB6_8</td><td/><td>Delta7</td><td>Delta7</td></tr><tr><td>hDeltaK</td><td>EBFB3,4D5FB6</td><td/><td>FB4R</td><td>CREFB4</td><td/><td>FB6Z</td><td>SMPSIPFB6_9</td><td/><td>EL</td><td>EBGAs</td></tr><tr><td>hDeltaL</td><td>FB2,6D5FB6d</td><td/><td>FB4X</td><td>CRESIPFB4,5</td><td/><td>FB7A</td><td>SIPSLPFB7</td><td/><td>EPG</td><td>EPG</td></tr><tr><td>hDeltaM</td><td>FB2,4D3FB5</td><td/><td>FB4Y</td><td>EBCREFB4,5</td><td/><td>FB7B</td><td>SMPSLPFB7</td><td/><td>EPGt</td><td>EPGt</td></tr><tr><td>FB1A</td><td>SMPSIPFB1,3</td><td/><td>FB4Z</td><td>FB4d5v</td><td/><td>FB7C</td><td>SMPSIPFB7_1</td><td/><td>P1-9</td><td>PBPB</td></tr><tr><td>FB1B</td><td>SMPSLPFB1d</td><td/><td>FB5A</td><td>LALCREFB5</td><td/><td>FB7D</td><td>FB7,6</td><td/><td>P6-8P9</td><td>P6-8P9</td></tr><tr><td>FB1C</td><td>LALNOmFB1</td><td/><td>FB5AA</td><td>SMPCREFB5_10</td><td/><td>FB7E</td><td>SMPSIPFB7_2</td><td/><td>PEG</td><td>PEG</td></tr><tr><td>FB1D</td><td>SLPFB1d</td><td/><td>FB5AB</td><td>SIPCREFB5d</td><td/><td>FB7F</td><td>SMPSIPFB7_3</td><td/><td>PEN_a(PEN1)</td><td>PEN1</td></tr><tr><td>FB1E_a</td><td>SIPSMPFB1d</td><td/><td>FB5B</td><td>SMPSIPFB5d_1</td><td/><td>FB7G</td><td>SMPFB7,8</td><td/><td>PEN_b(PEN2)</td><td>PEN2</td></tr><tr><td>FB1E_b</td><td>SLPSIPFB1d</td><td/><td>FB5C</td><td>SMPCREFB5_1</td><td/><td>FB7H</td><td>SMPFB7</td><td/><td>PFGs</td><td>PFGs</td></tr><tr><td>FB1F</td><td>SMPSIPFB1d</td><td/><td>FB5D</td><td>CRESMPFB5_1</td><td/><td>FB7I</td><td>SMPSIPFB7,6</td><td/><td>PFL1</td><td>PFLC</td></tr><tr><td>FB1G</td><td>SMPSIPFB1d,3</td><td/><td>FB5E</td><td>CRESMPFB5_2</td><td/><td>FB7J</td><td>FB7,8</td><td/><td>PFL2</td><td>PB1-4FB1,2,4,5LAL</td></tr><tr><td>FB1H</td><td>CRENO2,3FB1-4</td><td/><td>FB5F</td><td>SMPCREFB5_2</td><td/><td>FB7K</td><td>SLPSIPFB7</td><td/><td>PFL3</td><td>PB1-7FB1,2,4,5LAL</td></tr><tr><td>FB1I</td><td>SMPSIPFB1d,7</td><td/><td>FB5G</td><td>SMPSIPFB5,6</td><td/><td>FB7L</td><td>SMPSIPFB7_4</td><td/><td>PFNa</td><td>PFNa</td></tr><tr><td>FB1J</td><td>SLPSIPFB1,7,8</td><td/><td>FB5H</td><td>CRESMPFB5_3</td><td/><td>FB7M</td><td>SMPSIPFB7_5</td><td/><td>PFNd</td><td>PFNd</td></tr><tr><td>FB2A</td><td>NOaLALFB2</td><td/><td>FB5I</td><td>SMPCREFB5_3</td><td/><td>FB8A</td><td>SLPSMPFB8_1</td><td/><td>PFNm_a</td><td>PFNm_a</td></tr><tr><td>FB2B_a</td><td>LALCREFB2_1</td><td/><td>FB5J</td><td>SMPFB5</td><td/><td>FB8B</td><td>PLPSLPFB8</td><td/><td>PFNm_b</td><td>PFNm_b</td></tr><tr><td>FB2B_b</td><td>LALCREFB2_1</td><td/><td>FB5K</td><td>CREFB5</td><td/><td>FB8C</td><td>SMPFB8</td><td/><td>PFNp_a</td><td>PFNp_a</td></tr><tr><td>FB2C</td><td>SMPCREFB2_1</td><td/><td>FB5L</td><td>CRESMPFB5_4</td><td/><td>FB8D</td><td>SLPSMPFB8_2</td><td/><td>PFNp_b</td><td>PFNp_b</td></tr><tr><td>FB2D</td><td>LALCREFB2_2</td><td/><td>FB5M</td><td>CRESMPFB5_5</td><td/><td>FB8E</td><td>SMPSIPFB8_1</td><td/><td>PFNp_c</td><td>PFNp_c</td></tr><tr><td>FB2E</td><td>SCLSMPFB2</td><td/><td>FB5N</td><td>SMPCREFB5_4</td><td/><td>FB8F_a</td><td>SIPSLPFB8</td><td/><td>PFNp_d</td><td>PFNp_d</td></tr><tr><td>FB2F_a</td><td>SIPSMPFB2</td><td/><td>FB5O</td><td>SMPCREFB5_5</td><td/><td>FB8F_b</td><td>SIPSLPFB8</td><td/><td>PFNp_e</td><td>PFNp_e</td></tr><tr><td>FB2F_b</td><td>SIPSMPFB2</td><td/><td>FB5P</td><td>SMPCREFB5_6</td><td/><td>FB8G</td><td>SMPSIPFB8_2</td><td/><td>PFNv</td><td>PFNv</td></tr><tr><td>FB2F_c</td><td>SIPSMPFB2</td><td/><td>FB5Q</td><td>SMPCREFB5d</td><td/><td>FB8H</td><td>SMPSLPFB8</td><td/><td>PFR_a</td><td>PFR_a</td></tr><tr><td>FB2G_a</td><td>SMPSIPFB2</td><td/><td>FB5R</td><td>FB5</td><td/><td>FB8I</td><td>SMPSIPFB8_3</td><td/><td>PFR_b</td><td>PFR_b</td></tr><tr><td>FB2G_b</td><td>SIPLALFB2</td><td/><td>FB5S</td><td>FB5d,6v</td><td/><td>FB9A</td><td>SLPFB9_1</td><td/><td>SA1_a</td><td>SlpA</td></tr><tr><td>FB2H_a</td><td>SIPSCLFB2</td><td/><td>FB5T</td><td>CRESMPFB5_6</td><td/><td>FB9B_a</td><td>SLPFB9_2</td><td/><td>SA1_b</td><td>SlpA</td></tr><tr><td>FB2H_b</td><td>SIPSCLFB2</td><td/><td>FB5U</td><td>FB5d</td><td/><td>FB9B_b</td><td>SLPFB9_2</td><td/><td>SA1_c</td><td>SlpA</td></tr><tr><td>FB2I_a</td><td>SMPATLFB2</td><td/><td>FB5V</td><td>CRELALFB5</td><td/><td>FB9B_c</td><td>SLPFB9_2</td><td/><td>SA2_a</td><td>SlpA</td></tr><tr><td>FB2I_b</td><td>SMPATLFB2</td><td/><td>FB5W</td><td>SMPCREFB5_7</td><td/><td>FB9B_d</td><td>SLPFB9_2</td><td/><td>SA2_b</td><td>SlpA</td></tr><tr><td>FB2J</td><td>SMPPLPFB2</td><td/><td>FB5X</td><td>SMPCREFB5_8</td><td/><td>FB9B_e</td><td>SLPFB9_2</td><td/><td>SA3</td><td>SlpA</td></tr><tr><td>FB2K</td><td>LALSMPFB2</td><td/><td>FB5Y</td><td>SMPSIPFB5d_2</td><td/><td>FB9C_a</td><td>SLPFB9_2</td><td/><td>SAF</td><td>SlpAF</td></tr><tr><td>FB2L</td><td>SMPCREFB2_2</td><td/><td>FB5Z</td><td>SMPCREFB5_9</td><td/><td>FB9C_b</td><td>SLPFB9_2</td><td/><td>SpsP</td><td>SpsP</td></tr><tr><td>FB2M</td><td>SIPCREFB2</td><td/><td>FB6A</td><td>SMPSIPFB6_1</td><td/><td>FC1</td><td>FB2CRE</td><td/><td/><td/></tr><tr><td>FB3A</td><td>LALNO2FB3</td><td/><td>FB6B</td><td>SMPSIPFB6_2</td><td/><td>FC2A</td><td>FB1-5CRE</td><td/><td/><td/></tr></tbody></table></table-wrap><p>In contrast to the FB tangential neurons, the FB columnar neurons project terminals to generally more than one layer of the FB. In addition, unlike the nine glomeruli in the PB, there is not a fixed number of vertical columns in the FB. Rather, column number is a function of cell type, so column number is an important feature of each cell type. Finally, a subset of the columnar neurons is intrinsic to the FB, whereas the remaining columnar neurons project terminals to additional neuropils. Nomenclature rules differ for these classes of neurons.</p><p>Intrinsic columnar FB neurons have multiple arbors in the FB. While most arbors comprise a mixture of dendrites and axons, one arbor type usually predominates. The predominantly input or output arbors are either vertically arranged within a single column of the FB, in which case they include the prefix ‘v’ in the short name and D0 in the anatomical name (see below), or horizontally distributed across different columns, in which case they include the prefix ‘h’ in the short name and D# in the anatomical name (see below for details). The horizontal class of neurons includes one or more input arbors vertically arranged within a single column that are separated by a given number of columns from an output arbor on the contralateral side of the FB. The distance between the input and output arbors, measured as the difference of column numbers, is unique to each cell type but is always half the width of the FB. The number of columns between the input and output arbors is referred to as ‘delta’ and is indicated in these neuron’s names by a capital ‘D’ followed by the number of skipped columns between horizontally distributed input and output arbors. Two, three, five or seven columns have been documented to separate input from output arbors. As with the FB tangential neurons, input neuropils are indicated first in the neuron’s name, followed by output neuropils. The total number of columns per brain for a given cell type equals (Delta + 1) x 2. For example, FB2,3,5d,6vD3FB6v (hDeltaG) has input arbors in FB layers 2, 3 and 1 that spans the dorsal layer 5 and ventral layer 6. A gap of 3 columns (D3) separates the input arbors from the output arbor, which is located in the ventral portion of layer 6. For this cell type, there are (3+1) x 2 or eight columns per brain. In some instances, output arbors were easier to count than input (dendritic) arbors, so column counts were based on output arbors. While columns for some cell types are unambiguous, in other cases, best guesses were made based on anatomy and connectivity. For cells with arbors that overlap, column number was defined by the minimal number of arbors (in other words, non-overlapping) that achieved full coverage of the cell’s layer.</p><p>Neurons with input and output arbors that are vertically arranged within the same column have a displacement of zero columns, or a Delta0 (D0). This vertical alignment is reflected in the neuron’s anatomical name by D0 and in the short name with the prefix ‘v’. Column numbers were not calculated for these cell types.</p><p>The remaining columnar neurons exhibit both dendritic and axonal arbors within the FB as well as axonal arbors in additional neuropils. Although the vast majority of synapses are in the FB, it is the axonal synapses outside the FB that provide the best insight into gross morphology and are therefore indicated as the output neuropil. For example, while only 1% of the output for the FB2,5,6CRE (FC3) neuron is in the CRE, the neurite that projects to the CRE is distinctive and informs morphology. Column numbers were also not calculated for these cell types.</p></sec><sec id="s15" sec-type="appendix"><title>Sparse to many motifs</title><p>The attached spreadsheet ‘SparseToMany.xlsx’ describes the sparse-to-many motifs illustrated in <xref ref-type="fig" rid="fig22">Figure 22(B)</xref>. Shown are all instances where sparse type (N ≤ 2) connects bidirectionally to at least 90% of all instances of an abundant type (N ≥ 20). The two sheets have identical data, but one is sorted by the name of the sparse type, and one the abundant type. The data contained is:</p><list list-type="bullet"><list-item><p>Column A: The brain region and threshold used. All entries here are for the full brain and threshold 1.</p></list-item><list-item><p>Column B: The name of the sparse type.</p></list-item><list-item><p>Column C: The number of instances of the sparse type. This is most commonly 2, as most neurons are bilaterally symmetric. However there are cases where only a single instance was reconstructed in our volume.</p></list-item><list-item><p>Column D: The bodyID of the sparse type.</p></list-item><list-item><p>Column E: The instance name of the sparse type. This normally distinguishes the left and right examples.</p></list-item><list-item><p>Column F: The name of the abundant type.</p></list-item><list-item><p>Column G: The count of the abundant type.</p></list-item><list-item><p>Column H: The number of connections from the sparse to the abundant type.</p></list-item><list-item><p>Column I: The average strength of such connections.</p></list-item><list-item><p>Column J: The number of connections from the abundant type to the sparse type.</p></list-item><list-item><p>Column K: The average strength of such connections.</p></list-item></list></sec><sec id="s16" sec-type="appendix"><title>Supplementary neuron type naming tables</title><table-wrap id="app1table6" position="float"><label>Appendix 1—table 6.</label><caption><title>Naming scheme for neurons.</title><p>The neuron types that are known to exist but are not yet identified conclusively in the hemibrain data are not shown in the list.</p></caption><table frame="hsides" rules="groups"><tbody><tr><th>Connectivity types</th></tr><tr><td> _a, _b, _c, _d, etc. at the end of the morphology type names shown below</td></tr><tr><th>Morphology types</th></tr><tr><th>Central complex neuropil neurons</th></tr><tr><td> Delta7 (protocerebral bridge Delta seven between glomeruli)</td></tr><tr><td> vDeltaA-M (fan-shaped body vertical Delta within a single column [type ID])</td></tr><tr><td> hDeltaA-M (fan-shaped body horizontal Delta across columns [type ID])</td></tr><tr><td> EL (Ellipsoid body - Lateral accessory lobe)</td></tr><tr><td> EPG (Ellipsoid body - Protocerebral bridge - Gall)</td></tr><tr><td> EPGt (Ellipsoid body - Protocerebral bridge - Gall tip)</td></tr><tr><td> ER1-6 (Ellipsoid body Ring neuron [type ID])</td></tr><tr><td> ExR1-8 (Extrinsic Ring neuron [type ID])</td></tr><tr><td> FB1A-9C (Fan-shaped Body [layer ID][type ID])</td></tr><tr><td> FC1A-3 (Fan-shaped body - Crepine [type ID])</td></tr><tr><td> FR1, 2 (Fan-shaped body - Rubus [type ID])</td></tr><tr><td> FS1A-4C (Fan-shaped body - Superior medial protocerebrum [type ID])</td></tr><tr><td> IbSpsP (Inferior bridge - Superior posterior slope - Protocerebral bridge)</td></tr><tr><td> LCNOp, pm (Lateral accessory lobe - Crepine - NOduli [compartment ID])</td></tr><tr><td> LNOa (Lateral accessory lobe - NOduli [compartment ID])</td></tr><tr><td> LNO1-3 (Lateral accessory lobe - NOduli [type ID])</td></tr><tr><td> GLNO (Gall - Lateral accessory lobe - Noduli)</td></tr><tr><td> LPsP (Lateral accessory lobe - Posterior slope - Protocerebral bridge)</td></tr><tr><td> P1-9 (Protocerebral bridge [glomerulus ID])</td></tr><tr><td> P6-8P9 (Protocerebral bridge [glomerulus ID1] Protocerebral bridge [glomerulus ID2])</td></tr><tr><td> PEG (Protocerebral bridge - Ellipsoid body - Gall)</td></tr><tr><td> PEN_a(PEN1), _b(PEN2) (Protocerebral bridge - Ellipsoid body - Noduli [subtype ID])</td></tr><tr><td> PFGs (Protocerebral bridge - Fan-shaped body - Gall surrounding region)</td></tr><tr><td> PFL1-3 (Protocerebral bridge - Fan-shaped body - Lateral accessory lobe [type ID])</td></tr><tr><td> PFNa, d, m, p, v (Protocerebral bridge - Fan-shaped body - Noduli [compartment ID])</td></tr><tr><td> PFR (Protocerebral bridge - Fan-shaped body - Round body)</td></tr><tr><td> SA1-3 (Superior medial protocerebrum - Asymmetrical body [type ID])</td></tr><tr><td> SAF (Superior medial protocerebrum - Asymmetrical body - Fan-shaped body)</td></tr><tr><td> SpsP (Superior posterior slope - Protocerebral bridge)</td></tr><tr><th>Mushroom body neuropil neurons</th></tr><tr><td> KCab-c, m, p, s (Kenyon Cell alpha-beta lobe - [layer ID])</td></tr><tr><td> KCa’b’-ap1, ap2, m (Kenyon Cell alpha’-beta’ lobe - [layer ID])</td></tr><tr><td> KCg-d, m, s, t (Kenyon Cell gamma lobe - [layer ID])</td></tr><tr><td> MBON01-35 (Mushroom Body Output Neuron [type ID])</td></tr><tr><td> APL (Anterior Paired Lateral)</td></tr><tr><td> DPM (Dorsal Paired Medial)</td></tr><tr><td> MB-C1 (Mushroom Body - Calyx [type ID])</td></tr><tr><td> PAM01-15 (MB-associated DAN, Protocerebral Anterior Medial cluster [type ID])</td></tr><tr><td> PPL101-106 (MB-associated DAN, Protocerebral Posterior Lateral 1 cluster [type ID])</td></tr><tr><th>Dopaminergic neurons (DANs)</th></tr><tr><td> PPL107, 08 (Protocerebral Posterior Lateral 1 cluster [type ID])</td></tr><tr><td> PPL201-04 (Protocerebral Posterior Lateral 2 cluster [type ID])</td></tr><tr><td> PPM1201-05 (Protocerebral Posterior Medial 1/2 clusters [type ID])</td></tr><tr><td> PAL01-03 (Protocerebral/paired Anterior Lateral cluster [type ID])</td></tr><tr><th>Octopaminergic neurons</th></tr><tr><td> OA-ASM1-3 (OctopAmine - Anterior Superior Medial [type ID])</td></tr><tr><td> OA-VPM3, 4 (OctopAmine - ventral paired median [type ID])</td></tr><tr><td> OA-VUMa1-7 (OctopAmine - ventral unpaired median anterior [type ID])</td></tr><tr><th>Serotonergic (5HT) neurons</th></tr><tr><td> 5-HTPLP01 (5-HT Posterior lateral protocerebrum [type ID])</td></tr><tr><td> 5-HTPMPD01 (Posterior medial protocerebrum, dorsal [type ID])</td></tr><tr><td> 5-HTPMPV01, 03 (Posterior medial protocerebrum, ventral [type ID])</td></tr><tr><td> CSD (Serotonin-immunoreactive Deutocerebral neuron)</td></tr><tr><th>Peptidergic and secretory neurons</th></tr><tr><td> AstA1 (Allatostatin A)</td></tr><tr><td> CRZ01, 02 (Corazonin [type ID])</td></tr><tr><td> DSKMP1A, 1B, 3 (Drosulfakinin medial protocerebrum [type ID])</td></tr><tr><td> NPFL1-I (Neuropeptide F lateral large)</td></tr><tr><td> NPFP1 (Neuropeptide F dorso median)</td></tr><tr><td> PI1-3 (Pars Intercerebralis [type ID] Insulin Producing Cell candidates)</td></tr><tr><td> SIFa (SIFamide)</td></tr><tr><th>Circadian clock neurons</th></tr><tr><td> DN1a (Dorsal Neuron 1 anterior)</td></tr><tr><td> DN1pA, B (Dorsal Neuron 1 posterior [type ID])</td></tr><tr><td> l-LNv (large Lateral Neuron ventral)</td></tr><tr><td> LNd (Lateral Neuron dorsal)</td></tr><tr><td> LPN (Lateral Posterior Neuron)</td></tr><tr><td> s-LNv (small Lateral Neuron ventral)</td></tr><tr><th>Fruitless gene expressing neurons</th></tr><tr><td> aDT4 (anterior DeuTocerebrum [type ID])</td></tr><tr><td> aIPg1-4 (anterior Inferior Protocerebrum [type ID])</td></tr><tr><td> aSP-f1-4, g1-3B (anterior Superior Protocerebrum [type ID])</td></tr><tr><td> aSP8, 10A-10C (anterior Superior Protocerebrum [type ID])</td></tr><tr><td> pC1a-e (doublesex-expressing posterior Cells [type ID])</td></tr><tr><td> oviDNa, b (Oviposition Descending Neuron [type ID])</td></tr><tr><td> oviIN (Oviposition Inhibitory Neuron)</td></tr><tr><td> SAG (Sex peptide Abdominal Ganglion)</td></tr><tr><td> vpoDN (vaginal plate opening descending neuron)</td></tr><tr><td> vpoEN (vaginal plate opening excitatory neuron)</td></tr><tr><th>Visual projection neurons and intrinsic neurons of the optic lobe</th></tr><tr><td> aMe1-26 (accessory Medulla [type ID])</td></tr><tr><td> CT1 (Complex neuropils Tangential [type ID])</td></tr><tr><td> LC4, 6, 9–46 (Lobula Columnar [type ID])</td></tr><tr><td> LLPC1-3 (Lobula - Lobula Plate Columnar [type ID])</td></tr><tr><td> LPC1, 2 (Lobula Plate Columnar [type ID])</td></tr><tr><td> LPLC1-4 (Lobula Plate - Lobula Columnar [type ID])</td></tr><tr><td> LT1, 11, 33–47, 51–87 (Lobula Tangential [type ID])</td></tr><tr><td> MC61-66 (Medulla Columnar [type ID])</td></tr><tr><td> DCH (Dorsal Centrifugal Horizontal)</td></tr><tr><td> H1, 2 (Horizontal [type ID])</td></tr><tr><td> HSN, E, S (Horizontal System North, Equatorial, South)</td></tr><tr><td> VS (Vertical System)</td></tr><tr><td> VCH (Ventral Centrifugal Horizontal)</td></tr><tr><td> Li11-20 (Lobula intrinsic [type ID])</td></tr><tr><td> HBeyelet (Hofbauer-Buchner eyelet)</td></tr><tr><th>Descending neurons</th></tr><tr><td> DNa01-10 (Descending Neuron cell body anterior dorsal [type ID])</td></tr><tr><td> DNb01-06 (Descending Neuron cell body anterior ventral [type ID])</td></tr><tr><td> DNd01 (Descending Neuron outside cell cluster on the anterior surface [type ID])</td></tr><tr><td> DNg30 (Descending Neuron cell body in the gnathal ganglion [type ID])</td></tr><tr><td> DNp02-49 (Descending Neuron cell body on the posterior surface of the brain [type ID])</td></tr><tr><td> DNES1-3 (Descending Neuron going out to ESophagus [type ID])</td></tr><tr><td> Giant_Fiber descending neuron</td></tr><tr><td> MDN (Moonwalker Descending Neuron)</td></tr><tr><th>Sensory associated neurons</th></tr><tr><td> ORN_D, DA1-4, DC1-4, DL1-5, DM1-6, DP1l, m, V, VA1-7m, VC1-5, VL1-2p, VM1-7v (Olfactory Receptor Neuron_ [glomerulus ID])</td></tr><tr><td> TRN_VP1m, 2, 3 (Thermo-Receptor Neuron_ [glomerulus ID])</td></tr><tr><td> HRN_VP1d, 1 l, 4, 5 (Hygro-Receptor Neuron_ [glomerulus ID])</td></tr><tr><td> JO-ABC (Johnston’s Organ auditory receptor neuron- [AMMC zone ID])</td></tr><tr><td> OCG01-08 (OCellar Ganglion neuron [type ID])</td></tr><tr><th>Antennal lobe neuropil neurons</th></tr><tr><td> D_adPN, DA1_lPN, DC2_adPN, DL3_lPN, DM4_vPN, DP1l_adPN, VA1d_adPN, VC2_lPN, VL2p_vPN, VM7d_adPN, VP2_l2PN, etc. (uniglomerular [glomerulus ID] _ [cell cluster ID] Projection Neuron)</td></tr><tr><td> VP1l+_lvPN, VP3+_vPN, etc. (uni+glomerular [glomerulus ID]+ _ [cell cluster ID] Projection Neuron, arborizing in a glomerulus and a few neighboring areas)</td></tr><tr><td> VP1m+VP2_lvPN1, 2, VP4+VL1_l2PN, etc. (biglomerular [glomerulus ID1]+[glomerulus ID2] _ [cell cluster ID] Projec tion Neuron, arborizing in two glomeruli)</td></tr><tr><td> M_smPNm1, 6t2, adPNm3-8, spPN4t9, 5t10, lPNm11A-13, l2PNm14-16, 3t17, 10t18, l19-22, m23, lvPNm24-48, lv2PN9t49, vPNml50-89, ilPNm90, 8t91, imPNl92 (Multiglomerular_ [cell cluster ID] Projection Neuron [antennal lobe tract ID][type ID])</td></tr><tr><td> MZ_lvPN, lv2PN (Multiglomerular and subesophageal Zone _ [cell cluster ID] Projection Neuron)</td></tr><tr><td> Z_lvPNm1, Z_vPNml1 (subesophageal Zone only _ [cell cluster ID] Projection Neuron [antennal lobe tract ID][type ID])</td></tr><tr><td> lLN1, 2, 7–17, v2LN2-5, 30–50, il3LN6, l2LN18-23, vLN24-29 ([cell cluster ID] Local Neuron [type ID])</td></tr><tr><td> mAL1-6, B1-5, C1-6, D1-4 (mediodorsal Antennal Lobe neuron [type ID])</td></tr><tr><td> AL-AST1 (Antennal Lobe - Antenno-Subesophageal Tract [type ID])</td></tr><tr><td> AL-MBDL1 (Antennal Lobe - Median BunDLe [type ID])</td></tr><tr><td> ALBN1 (Antennal Lobe Bilateral Neuron [type ID])</td></tr><tr><td> ALIN1-3 (Antennal Lobe INput neuron [type ID])</td></tr><tr><th>Lateral horn neuropil neurons</th></tr><tr><td> LHAD1a1-4a1 (Lateral Horn Anterior Dorsal cell cluster [cell cluster ID][anatomy group ID][type ID])</td></tr><tr><td> LHAV1a1-9a1 (Lateral Horn Anterior Ventral cell cluster [cell cluster ID][anatomy group ID][type ID])</td></tr><tr><td> LHPD1a1-5f1 (Lateral Horn Posterior Dorsal cell cluster [cell cluster ID][anatomy group ID][type ID])</td></tr><tr><td> LHPV1c1-12a1 (Lateral Horn Posterior Ventral cell cluster [cell cluster ID][anatomy group ID][type ID])</td></tr><tr><td> LHCENT1-14 (Lateral Horn CENTrifugal [type ID])</td></tr><tr><td> LHMB1 (Lateral Horn - Mushroom Body [type ID])</td></tr><tr><th>Anterior optic tubercle neuropil neurons</th></tr><tr><td> AOTU001-065 (Anterior Optic TUbercle [type ID])</td></tr><tr><td> TuBu01-10, A, B (anterior optic Tubercle - Bulb [type ID])</td></tr><tr><th>Antler neuropil neurons</th></tr><tr><td> ATL001-045 (Antler [type ID])</td></tr><tr><th>Anterior ventrolateral protocerebrum neuropil neurons</th></tr><tr><td> AVLP001-596 (Anterior VentroLateral Protocerebrum [type ID])</td></tr><tr><th>Clamp neuropil neurons</th></tr><tr><td> CL001-364 (CLamp [type ID])</td></tr><tr><th>Crepine neuropil neurons</th></tr><tr><td> CRE001-108 (CREpine [type ID])</td></tr><tr><th>Inferior bridge neuropil neurons</th></tr><tr><td> IB001-119 (Inferior Bridge [type ID])</td></tr><tr><th>Lateral accessory lobe neuropil neurons</th></tr><tr><td> LAL001-204 (Lateral Accessory Lobe [type ID])</td></tr><tr><th>Posterior lateral protocerebrum neurons</th></tr><tr><td> PLP001-255 (Posterior Lateral Protocerebrum [type ID])</td></tr><tr><th>Posterior slope neuropil neurons</th></tr><tr><td> PS001-303 (Posterior Slope [type ID])</td></tr><tr><th>Posterior ventrolateral protocerebrum neuropil neurons</th></tr><tr><td> PVLP001-151 (Posterior VentroLateral Protocerebrum [type ID])</td></tr><tr><th>Saddle neuropil and antennal mechanosensory and motor center neurons</th></tr><tr><td> SAD001-095 (SADdle [type ID])</td></tr><tr><td> AMMC-A1 (Antennal Mechanosensory and Motor Center- [type ID])</td></tr><tr><th>Superior lateral protocerebrum neuropil neurons</th></tr><tr><td> SLP001-468 (Superior Lateral Protocerebrum [type ID])</td></tr><tr><th>Superior intermediate protocerebrum neuropil neurons</th></tr><tr><td> SIP001-90 (Superior Intermediate Protocerebrum [type ID])</td></tr><tr><th>Superior medial protocerebrum neuropil neurons</th></tr><tr><td> SMP001-604 (Superior Medial Protocerebrum [type ID])</td></tr><tr><td> DGI (Dorsal Giant Interneuron)</td></tr><tr><th>Vest neuropil neurons</th></tr><tr><td> VES001-84 (VESt [type ID])</td></tr><tr><th>Wedge neuropil neurons</th></tr><tr><td> WED001-183 (WEDge [type ID])</td></tr><tr><td> WEDPN1-19 (WEDge Projection Neuron [type ID])</td></tr></tbody></table></table-wrap></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.57443.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Marder</surname><given-names>Eve</given-names></name><role>Reviewing Editor</role><aff><institution>Brandeis University</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Pipkin</surname><given-names>Jason</given-names> </name><role>Reviewer</role><aff><institution>Brandeis University</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Doe</surname><given-names>Chris Q</given-names></name><role>Reviewer</role><aff><institution>Howard Hughes Medical Institute, University of Oregon</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>We consider this work to be a tour de force achievement on several fronts. Technologically, it ties together nearly a decade of advances in sample preparation, imaging, data management, and image analysis. It also is a very complete automated reconstruction of an EM volume that allows the authors to carefully begin the process of labeling subregions of the neuropil, derive cell types on the basis of both structure and connectivity, and identify circuit motifs, and is a demonstration of what connectomics has always promised to deliver: a reference atlas for biologists and a springboard for theoreticians and modelers working anywhere between the single-cell and whole network levels. We anticipate that this paper and its tools will facilitate the work from numerous laboratories around the world.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;A Connectome and Analysis of the Adult <italic>Drosophila</italic> Central Brain&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Michael Eisen as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Jason Pipkin (Reviewer #1) and Chris Q Doe (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, we are asking editors to accept without delay manuscripts, like yours, that they judge can stand as <italic>eLife</italic> papers without additional data, even if they feel that they would make the manuscript stronger. Thus the revisions requested below only address clarity and presentation.</p><p>Summary:</p><p>This paper is viewed as a landmark contribution to the methodologies of EM connectomics and its use to characterize the <italic>Drosophila</italic> brain. The manuscript is extensive and well-illustrated, and the reviewers and editors are pleased to help to make this work available to the public. I am taking the unusual (for <italic>eLife</italic>) action to include the two reviewers in their entirety, as they include constructive comments that were intended by these two careful readers to make the paper more accessible and more useful for the community. I hope that you will take into consideration these comments, and make those editorial changes that will strengthen the paper. In particular, reviewer 2's major request for additional information seems critical for the paper to be maximally useful to the community,</p><p>Title: Reviewer 2 suggests a change in the title for your consideration.</p><p><italic>Reviewer #1:</italic></p><p>The work presented by Scheffer et al. here is a tour de force achievement on several fronts. Technologically, it ties together nearly a decade of advances in sample preparation, imaging, data management, and image analysis. Most impressively, this represents – to my knowledge – the densest and most complete automated reconstruction of an EM volume of this size. While at least one larger volume has been generated from the adult fly brain (Davi Bock's TEMCA work), it has not been segmented (yet) to the level of completion presented here. (Though I am curious to hear the authors' thoughts on to what extent the overall automated segmentation strategy used herein is truly dependent on the isotropic voxels or if a similar set of networks could be retrained on anisotropic data from other existing volumes. One can imagine the value in validating connectivity in another sample that's already been imaged.)</p><p>The completeness of the hemibrain connectome enables the authors to carefully begin the process of labeling subregions of the neuropil, derive cell types on the basis of both structure and connectivity, and identify circuit motifs. They also show that the segmented skeletons enable a first pass at building detailed neuronal models at the single-cell level. Therefore this work is not just the presentation of a volume of data (itself impressive) but also a demonstration of what connectomics has always promised to deliver: a reference atlas for biologists and a springboard for theoreticians and modelers working anywhere between the single-cell and whole network levels.</p><p>I have no major critiques of this manuscript. Some of the figures could be more striking – or at least not set to Matlab defaults in terms of colors and box ticks (Figures 17, 20, 21 and 25). Others are beautiful (Figures 8 and 10, e.g.).</p><p>Finally, I commend the authors for building out the online portal for others to interact with their data. This is an achievement on its own, and probably the most important one for yielding the greatest scientific returns from their efforts.</p><p><italic>Reviewer #2:</italic></p><p>This massive work describes new methods for generating EM data on large chunks of nervous system – 250 x 250 μm adult central brain – which includes all of one side of the bilateral brain plus all of the central brain midline structures such as the central complex. Thus, it has an n = 1 for most brain neurons. It excludes most of the optic lobe, and all of the ascending/descending neurons, SEZ and VNC. The paper contains comprehensive analyses of the data set, including motif structure, classifying cell types, and adjusting brain neuropil boundaries. The Neuprint software is elegant and intuitive.</p><p>Importantly, this data set and associated software provide a method to transition from a light level neuron morphology (e.g. from a FlyLight neuron to a Neuprint neuron). While this needs further development (see comment below), it has the potential to save years of experimental analysis to reach the same point.</p><p>This data set will be the gold standard until the full CNS reconstruction is finished in the future. The quality of the EM data are extremely high based on images shown and data in Neuroglancer. As mentioned above, this is a massive work in many regards.</p><p>My only required major comment is to expand the section &quot;Matching EM and light microscopy data&quot; as this is an extremely important advance, and perhaps one of the most useful aspects of the entire manuscript. I think the most useful improvement would be to give an example from beginning (FlyLight neuron) to end (matching neuron in Neuprint). This can be another figure, or perhaps better as a numbered text instructions with full URLs for each required step. Or a third option, provide an example workflow on a Janelia page and link to it here. As it stands, I was unable to perform this function with the available information in the paper.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.57443.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>The work presented by Scheffer et al. here is a tour de force achievement on several fronts. Technologically, it ties together nearly a decade of advances in sample preparation, imaging, data management, and image analysis. Most impressively, this represents – to my knowledge – the densest and most complete automated reconstruction of an EM volume of this size. While at least one larger volume has been generated from the adult fly brain (Davi Bock's TEMCA work), it has not been segmented (yet) to the level of completion presented here. (Though I am curious to hear the authors' thoughts on to what extent the overall automated segmentation strategy used herein is truly dependent on the isotropic voxels or if a similar set of networks could be retrained on anisotropic data from other existing volumes. One can imagine the value in validating connectivity in another sample that's already been imaged.)</p><p>The completeness of the hemibrain connectome enables the authors to carefully begin the process of labeling subregions of the neuropil, derive cell types on the basis of both structure and connectivity, and identify circuit motifs. They also show that the segmented skeletons enable a first pass at building detailed neuronal models at the single-cell level. Therefore this work is not just the presentation of a volume of data (itself impressive) but also a demonstration of what connectomics has always promised to deliver: a reference atlas for biologists and a springboard for theoreticians and modelers working anywhere between the single-cell and whole network levels.</p><p>I have no major critiques of this manuscript. Some of the figures could be more striking – or at least not set to Matlab defaults in terms of colors and box ticks (Figures 17, 20, 21 and 25). Others are beautiful (Figures 8 and 10, e.g.).</p></disp-quote><p>We had someone with stronger graphic artist skills work on these figures, and a few others. She unified the fonts and the colors, changed the backgrounds to be clearer, and substituted color-blind friendly colors for the originals. We hope these are more striking.</p><disp-quote content-type="editor-comment"><p>Finally, I commend the authors for building out the online portal for others to interact with their data. This is an achievement on its own, and probably the most important one for yielding the greatest scientific returns from their efforts.</p><p>Reviewer #2:</p><p>This massive work describes new methods for generating EM data on large chunks of nervous system – 250 x 250 μm adult central brain – which includes all of one side of the bilateral brain plus all of the central brain midline structures such as the central complex. Thus, it has an n = 1 for most brain neurons. It excludes most of the optic lobe, and all of the ascending/descending neurons, SEZ and VNC. The paper contains comprehensive analyses of the data set, including motif structure, classifying cell types, and adjusting brain neuropil boundaries. The Neuprint software is elegant and intuitive.</p><p>Importantly, this data set and associated software provide a method to transition from a light level neuron morphology (e.g. from a FlyLight neuron to a Neuprint neuron). While this needs further development (see comment below), it has the potential to save years of experimental analysis to reach the same point.</p><p>This data set will be the gold standard until the full CNS reconstruction is finished in the future. The quality of the EM data are extremely high based on images shown and data in Neuroglancer. As mentioned above, this is a massive work in many regards.</p><p>My only required major comment is to expand the section &quot;Matching EM and light microscopy data&quot; as this is an extremely important advance, and perhaps one of the most useful aspects of the entire manuscript. I think the most useful improvement would be to give an example from beginning (FlyLight neuron) to end (matching neuron in Neuprint). This can be another figure, or perhaps better as a numbered text instructions with full URLs for each required step. Or a third option, provide an example workflow on a Janelia page and link to it here. As it stands, I was unable to perform this function with the available information in the paper.</p></disp-quote><p>We completely agree with this comment – this is one of the most useful things to do with the data, and it was not easy upon our initial data release. We have now addressed this – there is a new web application, <ext-link ext-link-type="uri" xlink:href="https://neuronbridge.janelia.org">https://neuronbridge.janelia.org</ext-link>, devoted explicitly to EM to light matching and vice versa. Furthermore there is now a button, shown as NB, on the tabular format for neurons in Neuprint. This neuron brings up NeuronBridge with the particular neuron pre-selected. There is also a demonstration video showing how to use this software, with examples.</p><p>There will be a separate paper on this process, with more examples and description of the algorithms. For example, when going from EM to light, it’s helpful if the software can create a search mask to help pull the specific neuron out of a not-so-sparse GAL4 line. When going from light to EM, the similarity function needs to know that only a portion of a brain-spanning neuron can be expected to match, and so on. Unfortunately, this paper is not out yet, even in bioRxiv form, so we cannot cite it. We are encouraging the authors to get this out as quickly as possible. Meanwhile we describe the process, and at least point out there is an upcoming paper.</p></body></sub-article></article>