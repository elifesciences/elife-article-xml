<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">76218</article-id><article-id pub-id-type="doi">10.7554/eLife.76218</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Selfee, self-supervised features extraction of animal behaviors</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-264682"><name><surname>Jia</surname><given-names>Yinjun</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-161386"><name><surname>Li</surname><given-names>Shuaishuai</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-264683"><name><surname>Guo</surname><given-names>Xuan</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-282048"><name><surname>Lei</surname><given-names>Bo</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-264684"><name><surname>Hu</surname><given-names>Junqiang</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-161390"><name><surname>Xu</surname><given-names>Xiao-Hong</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-263377"><name><surname>Zhang</surname><given-names>Wei</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0512-3096</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">IDG/McGovern Institute for Brain Research</institution>, <institution>Tsinghua University</institution>, <addr-line><named-content content-type="city">Beijing</named-content></addr-line>, <country>China</country></aff><aff id="aff2"><institution content-type="dept">Institute of Neuroscience</institution>, <institution>Chinese Academy of Sciences</institution>, <addr-line><named-content content-type="city">Beijing</named-content></addr-line>, <country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-208808"><name><surname>Zlatic</surname><given-names>Marta</given-names></name><role>Reviewing editor</role><aff><institution>MRC Laboratory of Molecular Biology</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>jyj20@mails.tsinghua.edu.cn</email> (YJ);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>wei_zhang@mail.tsinghua.edu.cn</email> (WZ);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>16</day><month>06</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e76218</elocation-id><history><date date-type="received"><day>08</day><month>12</month><year>2021</year></date><date date-type="accepted"><day>15</day><month>06</month><year>2022</year></date></history><permissions><copyright-statement>Â© 2022, Jia et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Jia et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-76218-v1.pdf"/><abstract><p>Fast and accurately characterizing animal behaviors is crucial for neuroscience research. Deep learning models are efficiently used in laboratories for behavior analysis. However, it has not been achieved to use an end-to-end unsupervised neural network to extract comprehensive and discriminative features directly from social behavior video frames for annotation and analysis purposes. Here, we report a self-supervised feature extraction (Selfee) convolutional neural network with multiple downstream applications to process video frames of animal behavior in an end-to-end way. Visualization and classification of the extracted features (Meta-representations) validate that Selfee processes animal behaviors in a way similar to human perception. We demonstrate that Meta-representations can be efficiently used to detect anomalous behaviors that are indiscernible to human observation and hint in-depth analysis. Furthermore, time-series analyses of Meta-representations reveal the temporal dynamics of animal behaviors. In conclusion, we present a self-supervised learning approach to extract comprehensive and discriminative features directly from raw video recordings of animal behaviors and demonstrate its potential usage for various downstream applications.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32022029</award-id><principal-award-recipient><name><surname>Zhang</surname><given-names>Wei</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All mating experiments were approved by the Animal Care and Use Committee of the Institute of Neuroscience, CAS Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China (IACUC No. NA-016-2016)All studies and experimental protocols of CIS and OFT were approved by Institutional Animal Care and Use Committee (IACUC) at Tsinghua University (No. 19-ZY1). Experiments were performed using the principles outlined in the Guide for the Care and Use of Laboratory Animals of Tsinghua University.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>Major data used in this study were uploaded to Dryad, including pretrained weights. Data could be accessed via:https://doi.org/10.5061/dryad.brv15dvb8.With the uploaded dataset and pretrained weights, our experiments could be replicated. However, due to its huge size and the limited internet service resources, we are currently not able to share our full training dataset. The full dataset is as large as 400GB, which is hard to upload to a public server and will be difficult for others users to download.For training dataset, it would be available from the corresponding author upon reasonable request (wei_zhang@mail.tsinghua.edu.cn), and then we can discuss how to transfer the dataset. No project proposal is needed as long as the dataset is not used for any commercial purpose.Our Python scripts could be accessed on GitHub: https://github.com/EBGU/SelfeeOther software used in our project include ImageJ(https://imagej.net/software/fiji/) and GraphPad Prism(https://www.graphpad.com/).All data used to plot graphs and charts in the manuscript can be fully accessed on Dryad (DOI 10.5061/dryad.brv15dvb8).</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Jia Y</collab><collab>Li S</collab><collab>Guo X</collab><collab>Lei B</collab><collab>Hu J</collab><collab>Xu X</collab><collab>Zhang W</collab></person-group><year iso-8601-date="2022">2022</year><source>Data from: Selfee: Self-supervised features extraction of animal behaviors</source><ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.5061/dryad.brv15dvb8">https://dx.doi.org/10.5061/dryad.brv15dvb8</ext-link><comment>Dryad Digital Repository, doi:10.5061/dryad.brv15dvb8</comment></element-citation></p><p>The following previously published datasets were used:</p><p><element-citation id="dataset2" publication-type="data" specific-use="references"><person-group person-group-type="author"><collab>Eyrun Eyjolfsdottir</collab><collab>Branson</collab><collab>S.</collab><collab>P.Burgos-Artizzu</collab><collab>X.</collab><collab>Hoopfer</collab><collab>E. D.</collab><collab>Schor</collab><collab>J.</collab><collab>Anderson</collab><collab>D. J.</collab><collab>&amp; Perona</collab><collab>P.</collab></person-group><year iso-8601-date="2021">2021</year><source>Fly-vs-Fly</source><ext-link ext-link-type="uri" xlink:href="https://data.caltech.edu/records/1893">https://data.caltech.edu/records/1893</ext-link><comment>CaltechDATA</comment></element-citation><element-citation id="dataset3" publication-type="data" specific-use="references"><person-group person-group-type="author"><collab>Leng Xubo</collab><collab>Wohl Margot</collab><collab>Ishii Kenichi</collab><collab>Nayak Pavan</collab><collab>Asahina Kenta</collab></person-group><year iso-8601-date="2020">2020</year><source>Data from: Quantifying influence of human choice on the automated detection of Drosophila behavior by a supervised machine learning algorithm</source><ext-link ext-link-type="uri" xlink:href="https://library.ucsd.edu/dc/object/bb20197654">https://library.ucsd.edu/dc/object/bb20197654</ext-link><comment>LIBRARY DIGITAL COLLECTIONS, UCSD</comment></element-citation><element-citation id="dataset4" publication-type="data" specific-use="references"><person-group person-group-type="author"><collab>M Lorbach</collab><collab>EI Kyriakou</collab><collab>R Poppe</collab><collab>EA van Dam</collab><collab>LPJJ Noldus</collab><collab>RC Veltkamp</collab></person-group><year iso-8601-date="2017">2017</year><source>RatSI</source><ext-link ext-link-type="uri" xlink:href="https://www.noldus.com/form/ratsi-dataset">https://www.noldus.com/form/ratsi-dataset</ext-link><comment>Noldus Information Technology</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-76218-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>