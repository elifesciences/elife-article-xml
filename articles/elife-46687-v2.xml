<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">46687</article-id><article-id pub-id-type="doi">10.7554/eLife.46687</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>A geometric attractor mechanism for self-organization of entorhinal grid modules</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-132728"><name><surname>Kang</surname><given-names>Louis</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5702-2740</contrib-id><email>louis.kang@berkeley.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-15603"><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6497-3819</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution content-type="dept">David Rittenhouse Laboratories</institution><institution>University of Pennsylvania</institution><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution content-type="dept">Redwood Center for Theoretical Neuroscience</institution><institution>University of California, Berkeley</institution><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution>University of Texas at Austin</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>02</day><month>08</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>8</volume><elocation-id>e46687</elocation-id><history><date date-type="received" iso-8601-date="2019-03-08"><day>08</day><month>03</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2019-08-01"><day>01</day><month>08</month><year>2019</year></date></history><permissions><copyright-statement>Â© 2019, Kang and Balasubramanian</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Kang and Balasubramanian</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-46687-v2.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.46687.001</object-id><p>Grid cells in the medial entorhinal cortex (MEC) respond when an animal occupies a periodic lattice of â€˜grid fieldsâ€™ in the environment. The grids are organized in modules with spatial periods, or scales, clustered around discrete values separated on average by ratios in the range 1.4â€“1.7. We propose a mechanism that produces this modular structure through dynamical self-organization in the MEC. In attractor network models of grid formation, the grid scale of a single module is set by the distance of recurrent inhibition between neurons. We show that the MEC forms a hierarchy of discrete modules if a smooth increase in inhibition distance along its dorso-ventral axis is accompanied by excitatory interactions along this axis. Moreover, constant scale ratios between successive modules arise through geometric relationships between triangular grids and have values that fall within the observed range. We discuss how interactions required by our model might be tested experimentally.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.46687.002</object-id><title>eLife digest</title><p>In a room, we have a sense of our location relative to the doors and to objects within the room. This is because the brain constructs a mental map of our current environment. As we move around the room, neurons called grid cells fire whenever we are in specific locations. But these locations are not random. They correspond to the corners of a grid of tessellating triangles on the floor, a little like the dots in a regular polka-dot pattern. Grid cells fire whenever we stand on one of the dots. This enables the brain to keep track of where we are and where we are heading.</p><p>But the brain does not use just a single grid cell map to represent a room. Instead, it uses multiple maps with different spatial scales. These maps differ in the distance between the points at which each grid cell fires, that is, the distance between the polka dots. Some maps have many small triangles, providing high resolution spatial information. Others have fewer, larger triangles. This is similar to how we use maps with different spatial scales when driving between cities versus walking around a single neighborhood. A set of grid cell maps with the same spatial scaleâ€”and the same orientationâ€”is known as a grid cell module.</p><p>Animal experiments suggest that different individuals use a similar combination of grid cell modules that can efficiently map rooms. But how can the brain reliably produce this particular combination? Using a computer model to simulate networks of grid cells, Kang and Balasubramanian identify a mechanism that enables the brain to spontaneously organize into the previously observed combination. The interactions between networksâ€”in particular the balance of inhibitory and excitatory activityâ€”determine the arrangement of grid cell modules. This process still works even with random fluctuations in network activity.</p><p>Grid cells occupy a brain region that degenerates early in the course of Alzheimer's disease. This may explain why some patients experience difficulty finding their way around as one of their first symptoms. To develop effective treatments, scientists need to understand how neural circuits within this brain region work, and how the disease process disrupts them. The computer model of Kang and Balasubramanian brings the research community a step closer to achieving this. It also provides insights into how neuronal networks self-organize, which is relevant to other brain functions too.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>grid cell</kwd><kwd>entorhinal cortex</kwd><kwd>grid module</kwd><kwd>continuous attractor</kwd><kwd>geometry</kwd><kwd>self-organization</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Honda Research Institute</institution></institution-wrap></funding-source><award-id>Embodied, efficient, geometry-driven curiosity</award-id><principal-award-recipient><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>PHY-1734030</award-id><principal-award-recipient><name><surname>Balasubramanian</surname><given-names>Vijay</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007247</institution-id><institution>Adolph C. and Mary Sprague Miller Institute for Basic Research in Science, University of California Berkeley</institution></institution-wrap></funding-source><award-id>Postdoctoral fellowship</award-id><principal-award-recipient><name><surname>Kang</surname><given-names>Louis</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>Medical Scientist Training Program</award-id><principal-award-recipient><name><surname>Kang</surname><given-names>Louis</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The hierarchy of entorhinal grid cell modules with constant scale ratios can self-organize through a new geometrically organized attractor mechanism.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>A grid cell has a spatially modulated firing rate that peaks when an animal reaches certain locations in its environment (<xref ref-type="bibr" rid="bib26">Hafting et al., 2005</xref>). These locations of high activity form a regular triangular grid with a particular length scale and orientation in space. Every animal has many grid cells that collectively span a wide range of scales, with smaller scales enriched dorsally and larger scales ventrally along the longitudinal axis of the MEC (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). Instead of being smoothly distributed, grid scales cluster around particular values and thus grid cells are partitioned into modules (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). Consecutive pairs of modules have scale ratios in the range 1.2â€“2.0 (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Barry et al., 2007</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>). The scale ratio averaged across animals is constant from one pair of modules to the next and lies in the interval 1.4Â (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>) to 1.7Â (<xref ref-type="bibr" rid="bib3">Barry et al., 2007</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>), suggesting that the grid system favors a universal scale ratio in this range.</p><p>Encoding spatial information through grid cells with constant scale ratios is thought to provide animals with an efficient way of representing their position within an environment (<xref ref-type="bibr" rid="bib41">Moser et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Fiete et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Mathis et al., 2012</xref>; <xref ref-type="bibr" rid="bib63">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Stemmler et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Sanzeni et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Mosheiff et al., 2017</xref>). Moreover, periodic representations of space permit a novel mechanism for precise error correction against neural noise (<xref ref-type="bibr" rid="bib52">Sreenivasan and Fiete, 2011</xref>) and are learned by machines seeking to navigate open environments (<xref ref-type="bibr" rid="bib12">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref>). These findings provide motivation for forming a modular grid system with a constant scale ratio, but a mechanism for doing so is unknown. Continuous attractor networks (<xref ref-type="bibr" rid="bib21">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>), a leading model for producing grid cells, would currently require discrete changes in scales to be directly imposed as sharp changes in parameters, as would the oscillatory interference model (<xref ref-type="bibr" rid="bib7">Burgess et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Hasselmo et al., 2007</xref>) or hybrid models (<xref ref-type="bibr" rid="bib8">Bush and Burgess, 2014</xref>). In contrast, many sensory and behavioral systems have smooth tuning distributions, such as preferred orientation in visual cortex (<xref ref-type="bibr" rid="bib32">Issa et al., 2008</xref>) and preferred head direction in the MEC (<xref ref-type="bibr" rid="bib58">Taube et al., 1990</xref>). A self-organizing map model with stripe cell inputs (<xref ref-type="bibr" rid="bib23">Grossberg and Pilly, 2012</xref>) and a firing rate adaptation model with place cell inputs (<xref ref-type="bibr" rid="bib60">Urdapilleta et al., 2017</xref>) can generate discrete grid scales, but their ratios are not constant or constant-on-average unless explicitly tuned.</p><p>Here, we present a simple extension of the continuous attractor model that adds excitatory connections between a series of attractor networks along the dorso-ventral axis of the MEC, accompanied by an increase in the distance of inhibition. The inhibition gradient drives an increase in grid scale along the MEC axis. Meanwhile, the excitatory coupling discourages changes in grid scale and orientation unless they occur through geometric relationships with defined scale ratios and orientation differences. Competition between the effects of longitudinal excitation and lateral inhibition self-organizes the complete network into a discrete hierarchy of modules. Certain grid relationships are geometrically stable, which makes them, and their associated scale ratios, insensitive to perturbations. The precise ratios that appear depend on the balance between excitation and inhibition and how it varies along the MEC axis. We show that sampling across a range of these parameters leads to a distribution of scale ratios that matches experiment and is, on average, constant from the smallest to the largest pair of modules.</p><p>Continuous attractors are a powerful general method for self-organizing neural dynamics. To our knowledge, our results are the first demonstration of a mechanism for producing a discrete hierarchy of modules in a continuous attractor system.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Standard grid cell attractors are not modular</title><p>We assemble a series of networks along the longitudinal MEC axis, numbering themÂ <italic>z</italic>Â = 1, 2, ..., 12 from dorsal to ventral (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Each network contains the standard 2D continuous attractor architecture of the Burak-Fiete model (<xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>). Namely, neurons are arranged in a 2D sheet with positions (<italic>x</italic>,<italic>y</italic>), receive broad excitatory drive (<xref ref-type="bibr" rid="bib5">Bonnevie et al., 2013</xref> and <xref ref-type="fig" rid="fig1">Figure 1B</xref>), and inhibit one another at a characteristic separation on the neural sheet (<xref ref-type="fig" rid="fig1">Figure 1C</xref>; see MaterialsÂ andÂ methods for a complete description). In our model, this inhibition distance <italic>l</italic> is constant within each network but increases from one network to the next along the longitudinal axis of the MEC. With these features alone, the population activity in each network self-organizes into a triangular grid whose lattice points correspond to peaks in neural activity (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Importantly, the scale of each networkâ€™s grid, which we callÂ Î»(<italic>z</italic>), is proportional to that networkâ€™s inhibition distance <italic>l</italic>(z) (â€˜uncoupledâ€™ simulations in <xref ref-type="fig" rid="fig3">Figure 3A</xref>). Also, network grid orientations Î¸ show no consistent pattern across scales and among replicate simulations with different random initial firing rates.</p><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.003</object-id><label>Figure 1.</label><caption><title>The entorhinal grid system as coupled 2D continuous attractor networks (MaterialsÂ andÂ methods).</title><p>(<bold>A</bold>) Each network <italic>z</italic> corresponds to a region along the dorso-ventral MEC axis and contains a 2D sheet of neurons with positions (<italic>x</italic>,<italic>y</italic>). (<bold>B</bold>) Neurons receive excitatory drive <italic>a</italic>(<italic>x</italic>,<italic>y</italic>) that is greatest at the network center and decays toward the edges. (<bold>C</bold>) Neurons inhibit neighbors within the same network with a weight w(<italic>x</italic>,<italic>y</italic>;<italic>z</italic>) that peaks at a distance of <italic>l</italic>(<italic>z</italic>) neurons, which increases as a function of <italic>z</italic>. Each neuron has its inhibitory outputs shifted slightly in one of four preferred network directions and receives slightly more drive when the animal moves along its preferred spatial direction. (<bold>D</bold>) Each neuron at position (<italic>x</italic>,<italic>y</italic>) in network <italic>z</italic> excites neurons located within a spread <italic>d</italic> of (<italic>x</italic>,<italic>y</italic>) in network <italic>z</italic>Â â€“Â 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig1-v2.tif"/></fig><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.004</object-id><label>Figure 2.</label><caption><title>Uncoupled and coupled systems produce grid cells with a range of scales.</title><p>(<bold>Aâ€“D</bold>) A representative simulation without coupling. (<bold>A</bold>) Network activities at the end of the simulation. (<bold>B</bold>) Activity overlays between adjacent networks depicted in <bold>A</bold>. In each panel, the network with smaller (larger) <italic>z</italic> is depicted in magenta (green), soÂ white indicates activity in both networks. (<bold>C</bold>) Spatial rate map of a single neuron for each <italic>z</italic> superimposed on the animalâ€™s trajectory. (<bold>D</bold>) Spatial autocorrelations of the rate maps depicted in <bold>C</bold>. (<bold>Eâ€“H</bold>) Same as <bold>Aâ€“D</bold> but for a representative simulation with coupling. Standard parameter values provided in <xref ref-type="table" rid="table1">Table 1</xref>. White scale bars, 50 neurons. Black scale bars, 50Â cm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig2-v2.tif"/></fig><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.005</object-id><label>Figure 3.</label><caption><title>Coupling can induce modularity with fixed scale ratios and orientation differences.</title><p>(<bold>Aâ€“C</bold>) Data from 10 replicate uncoupled and coupled simulations. (<bold>A</bold>) Left: network grid scalesÂ Î»(<italic>z</italic>). For each network, there are 10 closely spaced red circles and 10 closely spaced blue squares corresponding to replicate simulations. Inset: Î»(<italic>z</italic>) divided by the inhibition distance <italic>l</italic>(z). Middle: histogram for Î» collected across all networks. Right: network grid orientations Î¸ relative to the network in the same simulation with largest scale. (<bold>B</bold>) Left: spatial grid scales Î›(<italic>z</italic>). For each <italic>z</italic>, there are up to 30 red circles and 30 blue squares corresponding to three neurons recorded during each simulation. Inset: Î›(<italic>z</italic>) divided by the inhibition distance <italic>l</italic>(<italic>z</italic>). Middle: histogram for Î› collected across all networks. In the coupled model, grid cells are clustered into three modules. Right: spatial grid orientations Î˜ relative to the grid cell in the same simulation with largest scale. (<bold>C</bold>) Spatial scale ratios and orientation differences between adjacent modules for the coupled model. (<bold>D</bold>) Activity overlays enlarged from <xref ref-type="fig" rid="fig2">Figure 2F</xref> to emphasize lattice relationships. In each panel, the network with smaller (larger) <italic>z</italic> is depicted in magenta (green), so white indicates activity in both networks. Standard parameter values provided in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig3-v2.tif"/></fig><table-wrap id="table1" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.006</object-id><label>Table 1.</label><caption><title>Main model parameters and their values unless otherwise noted.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Parameter</th><th>Variable</th><th>Value</th></tr></thead><tbody><tr><td>Number of networks</td><td><inline-formula><mml:math id="inf1"><mml:mi>h</mml:mi></mml:math></inline-formula></td><td>12</td></tr><tr><td>Number of neurons per network</td><td><inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>n</mml:mi><mml:mo>Ã—</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula></td><td>160Â Ã—Â 160</td></tr><tr><td>Neurons recorded per network</td><td/><td>3</td></tr><tr><td>Animal speed</td><td><inline-formula><mml:math id="inf3"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="bold">ğ•</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula></td><td>0â€“1Â m/s</td></tr><tr><td>Diameter of enclosure</td><td/><td>180Â cm</td></tr><tr><td>Simulation time</td><td/><td>500Â s</td></tr><tr><td>Simulation timestep</td><td><inline-formula><mml:math id="inf4"><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula></td><td>1Â ms</td></tr><tr><td>Neural relaxation time</td><td><inline-formula><mml:math id="inf5"><mml:mi>Ï„</mml:mi></mml:math></inline-formula></td><td>10Â ms</td></tr><tr><td>Broad input strength</td><td><inline-formula><mml:math id="inf6"><mml:msub><mml:mi>a</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula></td><td>1</td></tr><tr><td>Broad input falloff</td><td><inline-formula><mml:math id="inf7"><mml:msub><mml:mi>a</mml:mi><mml:mtext>fall</mml:mtext></mml:msub></mml:math></inline-formula></td><td>4</td></tr><tr><td>Inhibition distance minimum</td><td><inline-formula><mml:math id="inf8"><mml:msub><mml:mi>l</mml:mi><mml:mtext>min</mml:mtext></mml:msub></mml:math></inline-formula></td><td>4</td></tr><tr><td>Inhibition distance maximum</td><td><inline-formula><mml:math id="inf9"><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub></mml:math></inline-formula></td><td>15</td></tr><tr><td>Inhibition distance exponent</td><td><inline-formula><mml:math id="inf10"><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula></td><td>â€“1</td></tr><tr><td>Inhibition strength</td><td><inline-formula><mml:math id="inf11"><mml:msub><mml:mi>w</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula></td><td>2.4</td></tr><tr><td>Subpopulation shift</td><td><inline-formula><mml:math id="inf12"><mml:mi>Î¾</mml:mi></mml:math></inline-formula></td><td>1</td></tr><tr><td>Coupling spread</td><td><inline-formula><mml:math id="inf13"><mml:mi>d</mml:mi></mml:math></inline-formula></td><td>8</td></tr><tr><td>Coupling strength</td><td><inline-formula><mml:math id="inf14"><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula></td><td>2.6</td></tr><tr><td>Velocity gain</td><td><inline-formula><mml:math id="inf15"><mml:mi>Î±</mml:mi></mml:math></inline-formula></td><td>0.3Â s/m</td></tr></tbody></table></table-wrap><p>Following the standard attractor model (<xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>), the inhibitory connections in each network are slightly modulated by the animalâ€™s velocity such that the population activity pattern of each network translates proportionally to animal motion at all times (MaterialsÂ andÂ methods). This modulation allows each network to encode the animalâ€™s displacement through a process known as path-integration, and projects the network grid pattern onto spatial rate maps of single neurons. That is, a recording of a single neuron over the course of an animal trajectory would show high activity in spatial locations that form a triangular grid with scale Î› (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Moreover, Î›(<italic>z</italic>) for a neuron from network <italic>z</italic> is proportional to that networkâ€™s population grid scale Î»(<italic>z</italic>), and thus also proportional to its inhibition distance <italic>l</italic>(z) (uncoupled simulations in <xref ref-type="fig" rid="fig3">Figure 3B</xref>). To be clear, we call Î› the â€˜spatial scaleâ€™; it corresponds to a single neuronâ€™s activity over the course of a simulation and has units of physical distance in space. By contrast, Î», the â€˜network scaleâ€™ described above, corresponds to the population activity at a single time and has units of separation on the neural sheet. Similarly, Î˜(<italic>z</italic>) describes the orientation of the spatial grid of a single neuron in the network z; we call Î˜ the â€˜spatial orientation.â€™ Like the network orientations Î¸ discussed above, spatial orientations of grids show no clustering (uncoupled simulations in <xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>With an inhibition distance <italic>l</italic>(z) that increases gradually from one network to the next (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), proportional changes in network and spatial scales Î»(<italic>z</italic>) and Î›(<italic>z</italic>) lead to a smooth distribution of grid scales (uncoupled simulations in <xref ref-type="fig" rid="fig3">Figure 3A,B</xref>). To reproduce the experimentally observed jumps in grid scale between modules, the inhibition distance would also have to undergo discrete, sharp jumps between certain adjacent networks. In summary, a grid system created by disjoint attractor networks will not self-organize into modules.</p></sec><sec id="s2-2"><title>Coupled attractor networks produce modules</title><p>Module self-organization can be achieved with one addition to the established features listed above: we introduce excitatory connections from each neuron to those in the preceding network with approximately corresponding neural sheet positions (<xref ref-type="fig" rid="fig1">Figure 1D</xref>; see MaterialsÂ andÂ methods for a complete description). That is, a neuron in network <italic>z</italic> (more ventral) with position (<italic>x</italic>,<italic>y</italic>) will excite neurons in network <italic>z</italic>Â â€“Â 1 (more dorsal) with positions that are within a distance <italic>d</italic> of position (<italic>x</italic>,<italic>y</italic>). In other words, the distance <italic>d</italic> is the â€˜spreadâ€™ of excitatory connections, and we choose a constant value across all networks comparable to the inhibition distance <italic>l</italic>(<italic>z</italic>).</p><p>The self-organization of triangular grids in the neural sheet and the faithful path-integration that projects these grids onto single neuron spatial rate maps persist after introduction of inter-network coupling (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). Network and spatial scales Î»(<italic>z</italic>) and Î›(<italic>z</italic>) still increase from network <italic>z</italic>Â =Â 1 (dorsal) to network <italic>z</italic>Â =Â 12 (ventral). Yet, <xref ref-type="fig" rid="fig3">Figure 3A,B</xref> shows that for the coupled model, these scales exhibit plateaus that are interrupted by large jumps, disrupting their proportionality to inhibition distance <italic>l</italic>(<italic>z</italic>), which is kept identical to that of the uncoupled system (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Collecting scales across all networks illustrates that they cluster around certain values in the coupled system while they are smoothly distributed in the uncoupled system. We identify these clusters with modules M1, M2, and M3 of increasing scale. Note that multiple networks at various depths <italic>z</italic> can belong to the same module. Moreover, coupling causes grid cells that cluster around a certain scale to also cluster around a certain orientation (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref>), as seen in experiment (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). The uncoupled system does not demonstrate co-modularity of orientation with scale, thatÂ is two networks with similar grid scales need not have similar orientations unless this is imposed by an external constraint.</p><p>In summary, excitatory coupling between grid attractor networks dynamically induces discreteness in grid scales that is co-modular with grid orientation, as observed experimentally (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>), and as needed for even coverage of space by the grid map (<xref ref-type="bibr" rid="bib50">Sanzeni et al., 2016</xref>).</p></sec><sec id="s2-3"><title>Modular geometry is determined by lattice geometry</title><p>Not only does excitatory coupling produce modules, it can do so with consistent scale ratios and orientation differences. For the coupled system depicted in <xref ref-type="fig" rid="fig2">Figure 2</xref>, scale ratios and orientation differences between pairs of adjacent modules consistently take values 1.74Â Â±Â 0.02 and 29.5Â Â±Â 0.4Â°, respectively (mean Â± s.d.; <xref ref-type="fig" rid="fig3">Figure 3C</xref>). These values are robust to a variety of parameter perturbations, coupling architectures, and sources of noise. We can make the inhibition distance profile <italic>l</italic>(<italic>z</italic>) less or more concave (<xref ref-type="fig" rid="fig4">Figure 4A,B</xref>), or we can implement excitatory connections with different properties by reversing their direction (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), including connections in both directions (<xref ref-type="fig" rid="fig4">Figure 4D</xref>), or allowing the coupling spread to vary with network depth (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). In each case, the same scale ratio ofÂ â‰ˆ1.7 and orientation difference of â‰ˆ30Â°Â persist. We can also reduce the number of neurons by a factor of 9 without affecting the scale ratio and orientation difference (<xref ref-type="fig" rid="fig4">Figure 4F</xref>). Similar results are obtained with neural inputs corrupted by independent Gaussian noise (<xref ref-type="fig" rid="fig4">Figure 4G</xref>) and with randomly shifted excitatory connections, which adds another form of coupling imprecision in addition to spread (<xref ref-type="fig" rid="fig4">Figure 4H</xref>). Finally, simulations with spiking dynamics following <xref ref-type="bibr" rid="bib6">Burak and Fiete (2009)</xref> also demonstrate a preference for scale ratios of â‰ˆ1.7 and orientation differences of â‰ˆ30Â°, albeit with greater variability (<xref ref-type="fig" rid="fig4">Figure 4I</xref>).</p><fig-group><fig id="fig4" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.007</object-id><label>Figure 4.</label><caption><title>Modules produced by commensurate lattices maintain the same scale ratios and orientation differences across various perturbations, architectures, and sources of noise.</title><p>Data from 10 replicate simulations in each subfigure, which shows spatial grid scales Î›(<italic>z</italic>) and scale ratios and orientation differences between modules. (<bold>A</bold>) Left: less concave inhibition distance profile <italic>l</italic>(<italic>z</italic>) (dark) compared to <xref ref-type="fig" rid="fig1">Figure 1C</xref> (light). (<bold>B</bold>) Same as <bold>A</bold>, but for a more concave <italic>l</italic>(<italic>z</italic>). (<bold>C</bold>) Dorsal-to-ventral coupling from each network <italic>z</italic> to network <italic>z</italic>Â +Â 1. (<bold>D</bold>) Bidirectional coupling from each network <italic>z</italic> to networks <italic>z</italic>Â â€“Â 1 and <italic>z</italic>Â +Â 1. (<bold>E</bold>) Left: coupling spread <italic>d</italic>(<italic>z</italic>) set to <italic>l</italic>(<italic>z</italic>) (dark) instead of a constant <italic>d</italic> (light). (<bold>F</bold>) Grid system with fewer networks <italic>h</italic>Â =Â 6 of smaller size <italic>n</italic>Â Ã—Â <italic>n</italic>Â =Â 76Â Ã—Â 76. (<bold>G</bold>) Independent noise added to each neuronâ€™s firing rate at each timestep. (<bold>H</bold>) Coupling outputs randomly shifted for each neuron by one neuron in both <italic>x</italic>- and <italic>y</italic>-directions. (<bold>I</bold>) Spiking simulations with spikes generated by an independent Poisson process. Detailed methods for each system provided in Appendix 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.008</object-id><label>Figure 4â€”figure supplement 1.</label><caption><title>Representative network activities and single neuron rate maps corresponding to <xref ref-type="fig" rid="fig4">Figure 4Aâ€“C</xref>.</title><p>Top row of each subfigure: network activities at the end of the simulation. Second row: activity overlays between adjacent networks depicted in the top row. In each panel, the network at smaller (larger) <italic>z</italic> is depicted in magenta (green), so white indicates regions of activity in both networks. Third row: spatial rate map of a single neuron for each <italic>z</italic> superimposed on the animalâ€™s trajectory. Bottom row: spatial autocorrelations of the rate maps depicted in the third row. (<bold>A</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4A</xref>. (<bold>B</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4B</xref>. (<bold>C</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4C</xref>. White scale bars, 50 neurons. Black scale bars, 50Â cm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.009</object-id><label>Figure 4â€”figure supplement 2.</label><caption><title>Representative network activities and single neuron rate maps corresponding to <xref ref-type="fig" rid="fig4">Figure 4Dâ€“F</xref>.</title><p>Panels same as in <xref ref-type="fig" rid="fig4s1">Figure 4â€“Figure supplement 1</xref>. (<bold>A</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4D</xref>. (<bold>B</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4E</xref>. (<bold>C</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4F</xref>. White scale bars, 50 neurons. Black scale bars, 50Â cm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.010</object-id><label>Figure 4â€”figure supplement 3.</label><caption><title>Representative network activities and single neuron rate maps corresponding to <xref ref-type="fig" rid="fig4">Figure 4Gâ€“I</xref>.</title><p>Panels same as in <xref ref-type="fig" rid="fig4s1">Figure 4â€“Figure supplement 1</xref>. (<bold>A</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4G</xref>. (<bold>B</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4H</xref>. (<bold>C</bold>) Corresponding to <xref ref-type="fig" rid="fig4">Figure 4I</xref>. White scale bars, 50 neurons. Black scale bars, 50Â cm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig4-figsupp3-v2.tif"/></fig></fig-group><p>We can intuitively understand this robust modularity through the competition between lateral inhibition within networks and longitudinal excitation across networks. In the uncoupled system, grid scales decrease proportionally as the inhibition distance <italic>l</italic>(<italic>z</italic>) decreases from <italic>z</italic>Â =Â 12 to <italic>z</italic>Â =Â 1. However, coupling causes areas of high activity in network <italic>z</italic> to preferentially excite corresponding areas in network <italic>z</italic>Â â€“Â 1, which encourages adjacent networks to share the same grid pattern (<italic>z</italic>Â =Â 10Â &amp;Â 11 in <xref ref-type="fig" rid="fig3">Figure 3D</xref>). Thus, coupling adds rigidity to the system and provides an opposing â€˜forceâ€™ against the changing inhibition distance that attempts to drive changes in grid scale. This rigidity produces the plateaus in network and spatial scales Î»(<italic>z</italic>) and Î›(<italic>z</italic>) that delineate modules across multiple networks.</p><p>At interfaces between modules, coupling can no longer fully oppose the changing inhibition distance, and the grid pattern changes. However, the rigidity fixes a geometric relationship between the grid patterns of the two networks spanning the interface. In the coupled system of <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref>, module interfaces occur between networks <italic>z</italic>Â =Â 4Â and 5 and between <italic>zÂ </italic>=Â 9Â and 10. The network population activity overlays of <xref ref-type="fig" rid="fig3">Figure 3D</xref> reveal overlap of many activity peaks at these interfaces. However, the more dorsal network (with smaller <italic>z</italic>) at each interface contains additional small peaks between the shared peaks. In this way, adjacent networks still share many corresponding areas of high activity, as favored by coupling, but the grid scale changes, as favored by a changing inhibition distance. Pairs of grids whose lattice points demonstrate regular registry are called <italic>commensurate</italic> lattices (<xref ref-type="bibr" rid="bib10">Chaikin and Lubensky, 1995</xref>) and have precise scale ratios and orientation differences, here respectively <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula>Â â‰ˆÂ 1.7Â and 30Â°, which match the results in <xref ref-type="fig" rid="fig3">Figure 3C</xref> and <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p><p>In summary, excitatory coupling can compete against a changing inhibition distance to produce a rigid grid system whose â€˜fracturesâ€™ exhibit stereotyped commensurate lattice relationships. These robust geometric relationships lead to discrete modules with fixed scale ratios and orientation differences.</p><p>In our model, commensurate lattice relationships naturally lead to field-to-field firing rate variability in single neuron spatial rate maps (<italic>z</italic>Â =Â 8 in <xref ref-type="fig" rid="fig2">Figure 2G</xref>, for example), another experimentally observed feature of the grid system (<xref ref-type="bibr" rid="bib31">Ismakov et al., 2017</xref>; <xref ref-type="bibr" rid="bib15">Dunn et al., 2017</xref>; <xref ref-type="bibr" rid="bib13">Diehl et al., 2017</xref>). At interfaces between two commensurate lattices, only a subset of population activity peaks in the grid of smaller scale overlap with, and thus receive excitation from, those in the grid of larger scale. The network with smaller grid scale will contain activity peaks of different magnitudes; this heterogeneity is then projected onto the spatial rate maps of its neurons.</p></sec><sec id="s2-4"><title>Excitation-inhibition balance sets lattice geometry</title><p>Adjusting the balance between excitatory coupling and a changing inhibition distance produces other commensurate lattice relationships, each of which enforces a certain scale ratio and orientation difference. To explore this competition systematically, we use a smaller coupled model with just two networks, <italic>z</italic>Â =Â 1Â andÂ 2, and vary three parameters: the coupling spread <italic>d</italic>, the coupling strength <italic>u</italic><sub>mag</sub>, and the ratio of inhibition distances between the two networks <italic>l</italic>(2)/<italic>l</italic>(1) (Appendix 1). For each set of parameters, we measure network scale ratios and orientation differences produced by multiple replicate simulations (<xref ref-type="fig" rid="fig5s1">Figure 5â€”figure supplement 1</xref> and <xref ref-type="fig" rid="fig5s2">Figure 5â€”figure supplement 2</xref>). We find that as the excitation-inhibition balance is varied by changing <italic>u</italic><sub>mag</sub> and <italic>l</italic>(2)/<italic>l</italic>(1), a number of discretely different relationships appear, which can be summarized in â€˜phase diagramsâ€™ (<xref ref-type="fig" rid="fig5">Figure 5A,B</xref>).</p><fig-group><fig id="fig5" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.011</object-id><label>Figure 5.</label><caption><title>Diverse lattice relationships emerge over wide ranges in simulation parameters.</title><p>In models with only two networks <italic>z</italic> = 1 and 2, we vary the coupling strength <italic>u</italic><sub>mag</sub> and the ratio of inhibition distances <italic>l</italic>(2)/<italic>l</italic>(1) for two different coupling spreads <italic>d</italic>. (<bold>A, B</bold>) Approximate phase diagrams based on 10 replicate simulations for each set of parameters, with the mean of <italic>l</italic>(1) and <italic>l</italic>(2) fixed to be 9. The most frequently occurring scale ratio and orientation difference are indicated for each region; coexistence between multiple lattice relationships may exist at drawn boundaries. (<bold>A</bold>) Phase diagram for small coupling spread <italic>d</italic> = 6. Solid lines separate four regions with different commensurate lattice relationships labeled by scale ratio and orientation difference, and dotted lines mark one region of discommensurate lattice relationships. (<bold>B</bold>) Phase diagram for large coupling spread <italic>d</italic> = 12. There are five different commensurate regions, a discommensurate region, as well as a region containing incommensurate lattices (gray). (<bold>C</bold>) Network activity overlays for representative observed (left) and idealized (right) commensurate relationships. Numbers at the top right of each image indicate network scale ratios Î»(2)/Î»(1) and orientation differences Î¸(2) âˆ’ Î¸(1). Networks <italic>z</italic> = 1 and 2 in magenta and green, respectively, so white indicates activity in both networks. (<bold>D</bold>) Expanded region of <bold>B</bold> displaying discommensurate lattice statistics. For each set of parameters, a representative overlay for the most prevalent discommensurate lattice relationship is shown. The number in the lower right indicates the proportion of replicate simulations with scale ratio within 0.02 and orientation difference within 3Â° of the values shown at top right. In one overlay, discommensurations are outlined by white lines. (<bold>E</bold>) The discommensurate relationships described in <bold>D</bold> demonstrate positive correlation between scale ratio and the logarithm of orientation difference (Pearsonâ€™s Ï = 0.91, <italic>p</italic>Â âˆ¼ 10<sup>â€“26</sup> ; Spearmanâ€™s Ï = 0.92, p âˆ¼ 10<sup>â€“27</sup> ). Simulation details provided in Appendix 1.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.012</object-id><label>Figure 5â€”figure supplement 1.</label><caption><title>Raw scale ratio and orientation difference data used to produce <xref ref-type="fig" rid="fig5">Figure 5A</xref>.</title><p>Two-network model with coupling spreadÂ <italic>d</italic>Â = 6.Â (<bold>A</bold>) Network scale ratios Î»(2)/Î»(1). (<bold>B</bold>) Network orientation differences Î¸(2) âˆ’ Î¸(1). For each <italic>l</italic>(2)<italic>/l</italic>(1) and <italic>u</italic><sub>mag</sub>, 10 replicate simulations subject are represented by circles with colors corresponding across the two subfigures. Small horizontal offsets are introduced for clarity, and each set of replicate simulations is ordered by Î¸(2) âˆ’ Î¸(1). Gray lines track mean values as a function of <italic>l</italic>(2)<italic>/l</italic>(1).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.013</object-id><label>Figure 5â€”figure supplement 2.</label><caption><title>Raw scale ratio and orientation difference data used to produce <xref ref-type="fig" rid="fig5">Figure 5B</xref>.</title><p>Panels same as in <xref ref-type="fig" rid="fig5s1">Figure 5â€”figure supplement 1</xref>, but for coupling spread <italic>d</italic> = 12.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.014</object-id><label>Figure 5â€”figure supplement 3.</label><caption><title>Commensurate and discommensurate relationships are robust against activity noise and coupling noise.</title><p>Two-network model with no noise, activity noise as inÂ <xref ref-type="fig" rid="fig4">Figure 4G</xref>, and coupling noise as inÂ <xref ref-type="fig" rid="fig4">Figure 4H</xref>.Â (<bold>A, B</bold>) Network parameters that, in accordance with <xref ref-type="fig" rid="fig5">Figure 5</xref>, produce a predominance of the <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mo>,</mml:mo><mml:msup><mml:mn>30</mml:mn><mml:mrow><mml:mo>âˆ˜</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> commensurate relationship. (<bold>A</bold>) Representative activity overlays. Networks <italic>z</italic> = 1 and 2 in magenta and green, respectively, so white indicates activity in both networks. Prevalence is the proportion of replicate simulations with scale ratio within 0.02 and orientation difference within 3Â° of the values shown at top right. (<bold>B</bold>) Network scale ratios and orientation differences for 10 replicate simulations per noise condition. (<bold>C, D</bold>) Same as <bold>A,Â B</bold>,Â but for parameters that produce a predominance of the <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msqrt><mml:mn>7</mml:mn></mml:msqrt><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mn>19</mml:mn><mml:mrow><mml:mo>âˆ˜</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> commensurate relationship. (<bold>E, F</bold>) Same as <bold>A, B</bold>, but for parameters that produce a predominance of discommensurate relationships with scale ratioÂ â‰ˆ1.24 and orientation difference â‰ˆ0Â°. Note that for each set of parameters, the predominant lattice relationship is maintained in the presence of noise. Data for the no noise condition taken from <xref ref-type="fig" rid="fig5s1">Figure 5â€”figure supplement 1</xref> and <xref ref-type="fig" rid="fig5s2">Figure 5â€”figure supplement 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig5-figsupp3-v2.tif"/></fig></fig-group><p>In many regions of the phase diagrams, these lattice relationships are commensurate, each with a characteristic scale ratio and orientation difference (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). When parameters are chosen near a boundary between two regions, replicate simulations may adopt either lattice relationship or occasionally be trapped in other metastable relationships due to variations in random initial conditions (<xref ref-type="fig" rid="fig5s2">Figure 5â€”figure supplement 2</xref>). At larger <italic>u</italic><sub>mag</sub> in both phase diagrams, there are fewer regions as <italic>l</italic>(2)/<italic>l</italic>(1) varies because a higher excitatory coupling strength provides more rigidity against gradients in inhibition distance (<xref ref-type="fig" rid="fig5">Figure 5A,B</xref>). However, a larger coupling spread <italic>d</italic> would cause network <italic>z</italic>Â =Â 2 to excite a broader set of neurons in network <italic>z</italic>Â =Â 1, softening the rigidityÂ imposed by coupling and producing a wider variety of lattices in <xref ref-type="fig" rid="fig5">Figure 5B</xref> than <xref ref-type="fig" rid="fig5">Figure 5A</xref>. Also in <xref ref-type="fig" rid="fig5">Figure 5B</xref>, when excitation is weak and approaching the uncoupled limit, there is a noticeable region dominated by <italic>incommensurate</italic> lattices, in which the two grids lack consistent registry or relative orientation, and grid scale is largely determined by inhibition distance (<xref ref-type="fig" rid="fig5s2">Figure 5â€”figure supplement 2</xref>).</p><p><xref ref-type="fig" rid="fig5">Figure 5B</xref> also contains a larger region of <italic>discommensurate</italic> lattices (although strictly speaking, in condensed matter physics, they would be termed commensurate lattices with discommensurations; <xref ref-type="bibr" rid="bib10">Chaikin and Lubensky, 1995</xref>). Discommensurate networks have closely overlapping activities in certain areas that are separated by a mesh of regions lacking overlap called discommensurations (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). They exhibit ranges of scale ratios 1.1â€“1.4 and orientation differences 0Â°â€“10Â° that ultimately arise from a single source: the density of discommensurations, whose properties can also be explained through excitation-inhibition competition. Stronger coupling drives more activity overlap, which favors sparser discommensurations and lowers the scale ratio and orientation difference. However, a larger inhibition distance ratio drives the two networks to differ more in grid scale, which favors denser discommensurations. To better accommodate the discommensurations, grids rotate slightly as observed previously in a crystal system (<xref ref-type="bibr" rid="bib65">Wilson, 1990</xref>). <xref ref-type="fig" rid="fig5">Figure 5E</xref> confirms that scale ratios and orientation differences vary together as the discommensuration density changes.</p><p>Thus, by changing the balance between excitation and inhibition, a two-network model yields geometric lattice relationships with various scale ratios and corresponding orientation differences. All the commensurate relationships (<xref ref-type="fig" rid="fig5">Figure 5C</xref>) and almost the entire range of discommensurate relationships (<xref ref-type="fig" rid="fig5">Figure 5D</xref>) have scale ratios that fall in the range of experimental measurements, which is roughly 1.2â€“2.0 (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Barry et al., 2007</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>). The scale ratios and orientation differences in both the commensurate and discommensurate cases are robust against activity noise and coupling noise (<xref ref-type="fig" rid="fig5s3">Figure 5â€”figure supplement 3</xref>).</p></sec><sec id="s2-5"><title>Discommensurate lattices produce distinct modular geometries but with more variation</title><p>As mentioned above, discommensurate lattices have a range of allowed geometries (<xref ref-type="fig" rid="fig5">Figure 5D,E</xref>), but they can still produce modules in a full 12-network grid system with a preferred scale ratio and orientation difference. However, these values do not cluster as strongly as they do for a commensurate relationship, which is geometrically precise.</p><p>The phase diagrams of <xref ref-type="fig" rid="fig5">Figure 5</xref> provide guidance for modifying a 12-network system that exhibits a <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mo>,</mml:mo><mml:msup><mml:mn>30</mml:mn><mml:mo>âˆ˜</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>Â relationship to produce discommensurate relationships instead. We make the inhibition distance profile <italic>l</italic>(<italic>z</italic>) shallower (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) and increase the coupling spread <italic>d</italic> by 50%. Network activity overlays of these new simulations reveal grids obeying discommensurate relationships (<xref ref-type="fig" rid="fig6">Figure 6B,C</xref>), which are projected onto single neuron spatial rate maps through faithful path-integration (<xref ref-type="fig" rid="fig6s1">Figure 6â€”figure supplement 1A</xref>). Across replicate simulations with identical parameter values but different random initial firing rates, the discommensurate system demonstrates greater variation in scale and orientation (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) than the commensurate system of <xref ref-type="fig" rid="fig3">Figure 3</xref> does. Nevertheless, analysis of each replicate simulation reveals clustering with well-defined modules (<xref ref-type="fig" rid="fig6">Figure 6E</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6â€”figure supplement 1B</xref>). These modules have scale ratio 1.39Â Â±Â 0.10 and orientation difference 6.7Â Â±Â 3.5Â° (mean Â± s.d.; <xref ref-type="fig" rid="fig6">Figure 6F</xref>). The preferred scale ratio agrees well with the mean value observed experimentally in <xref ref-type="bibr" rid="bib56">Stensola et al. (2012)</xref>.</p><fig-group><fig id="fig6" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.015</object-id><label>Figure 6.</label><caption><title>Discommensurate lattice relationships can produce realistic modules.</title><p>(<bold>A</bold>) We use a shallower inhibition distance profile <italic>l</italic>(<italic>z</italic>) (dark) compared to <xref ref-type="fig" rid="fig1">Figure 1C</xref> (light). (<bold>B</bold>) Large activity overlays from a representative simulation that emphasize discommensurate lattice relationships. (<bold>C</bold>) All activity overlays from the representative simulation in <bold>B</bold> between adjacent networks <italic>z</italic> in magenta and green, so white indicates activity in both networks. Scale bar, 50 neurons. (<bold>Dâ€“F</bold>) Data from 10 replicate simulations. (<bold>D</bold>) Left: spatial grid scales Î›(<italic>z</italic>). For each network, there are up to 30 red circles corresponding to three neurons recorded during each simulation. Middle: histogram for Î› collected across all networks. Right: spatial orientations Î˜ relative to the grid cell in the same simulation with largest scale. (<bold>E</bold>) Clustering of spatial scales and orientations for three representative simulations. Due to sixfold lattice symmetry, orientation is a periodic variable modulo 60Â°. Different colors indicate separate modules. (<bold>F</bold>) Spatial scale ratios and orientation differences between adjacent modules. (<bold>G</bold>) Representative activity overlay demonstrating defect with low activity overlap. Maximum inhibition distance <italic>l</italic><sub>max</sub> = 10, coupling spread <italic>d</italic> = 12. We use larger network size <italic>n</italic> Ã— <italic>n</italic> = 230 Ã— 230 to allow for discommensurate relationships whose periodicities span longer distances on the neural sheets. Other parameter values are in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.016</object-id><label>Figure 6â€”figure supplement 1.</label><caption><title>Representative network activities and single neuron rate maps; module clustering for all replicate simulations.</title><p>(<bold>A</bold>) Representative network activities and single neuron rate maps for the discommensurate system. Top row: network activities at the end of the simulation. Second row: activity overlays between adjacent networks depicted in the top row. In each panel, the network at smaller (larger) <italic>z</italic> is depicted in magenta (green), so white indicates regions of activity in both networks. Third row: spatial rate map of a single neuron for each <italic>z</italic> superimposed on the animalâ€™s trajectory. Bottom row: spatial autocorrelations of the rate maps depicted in the third row. White scale bars, 50 neurons. Black scale bars, 50 cm. (<bold>B</bold>) Clustering of spatial scales and orientations for all replicate simulations. Due to sixfold lattice symmetry, orientation is a periodic variable modulo 60Â°. Different colors indicate separate modules.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.017</object-id><label>Figure 6â€”figure supplement 2.</label><caption><title>Sample comparison of field-to-field firing rate variability between an experimental recording and our model.</title><p>(<bold>A</bold>) Sample experimentally recorded single neuron rate map adapted from Figure 1a of <xref ref-type="bibr" rid="bib15">Dunn et al. (2017)</xref>. (<bold>B</bold>) Sample single neuron rate map from a simulation with the same parameters as in <xref ref-type="fig" rid="fig6">Figure 6</xref> that exhibits discommensurate lattice relationships. Note that firing rate decreases across fields from the bottom left to the top right of bothÂ <bold>A</bold>Â andÂ <bold>B</bold>; the presence of firing rate modulation over long distances has been considered by <xref ref-type="bibr" rid="bib55">Stemmler and Herz (2017)</xref>. In <bold>B</bold>, the fields at the top right correspond to a discommensuration on the neural sheet and the fields at the bottom left correspond to a region in between discommensurations that exhibits activity overlap. A comprehensive test requires analysis with experiments using circular enclosures to eliminate confounding boundary effects (see Discussion).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig6-figsupp2-v2.tif"/></fig></fig-group><p>Conceptually, we can interpret the greater spread of scales and orientations in terms of coupling rigidity. Excitatory coupling, especially when the spread is larger, provides enough rigidity in the discommensurate system to cluster scale ratios and orientation differences but not enough to prevent variations in these values. The degree of variability observed in <xref ref-type="fig" rid="fig6">Figure 6D,E</xref> appears consistent with experimental measurements, which also demonstrate spread (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Barry et al., 2007</xref>).</p><p>A few module pairs in <xref ref-type="fig" rid="fig6">Figure 6F</xref> exhibit a large orientation difference &gt;10Â°. This is not expected from a discommensurate relationship, and indeed, inspecting the network activities reveals adjacent networks trapped in a relationship with low activity overlap and large orientation difference (<xref ref-type="fig" rid="fig6">Figure 6G</xref>). In the context of a grid system that otherwise obeys commensurate or discommensurate geometries containing more overlap, we call this less common relationship a â€˜defect.â€™ We distinguish between these relationshipsÂ and the incommensurate lattices discussed above, which also have low activity overlap. Defects arise when the excitatory coupling is strong, and incommensurate lattices arise when this coupling is weak. Also, defects have smaller scale ratios &lt;1.1 and larger orientation differences &gt;10Â°, whereas incommensurate lattices have larger scale ratios &gt;1.3 and any orientation difference (<xref ref-type="fig" rid="fig5">Figure 5B</xref> and <xref ref-type="fig" rid="fig5s2">Figure 5â€”figure supplement 2</xref>).</p><p>Thus, networks governed by discommensurate relationships also cluster into modules with a preferred scale ratio and orientation difference within the experimental range (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>). Due to lower coupling rigidity compared to commensurate grid systems, they exhibit increased variability and occasional defects across replicate simulations.</p><p>As in the commensurate case, discommensurate lattice relationships also create field-to-field firing rate variability in single neuron spatial rate maps. At interfaces between two discommensurate lattices, population activity peaks lack overlap at discommensurations and exhibit overlap in between them. Thus, only a subset of peaks in the grid of smaller scale receive excitation from the grid of larger scale; those located at discommensurations do not. As activity patterns translate on the neural sheets during path-integration, a grid cell in the network with smaller scale will have lower firing rate when a discommensuration moves through it, leading to firing rate variability (see <xref ref-type="fig" rid="fig6s2">Figure 6â€”figure supplement 2</xref> for an example).</p></sec><sec id="s2-6"><title>A diversity of lattice geometries maintains constant-on-average scale ratios</title><p>So far, each set of 12-network simulations contained replicates with identical parameter values and exhibited a single dominant lattice relationship. We now present results with different parameter values to imitate biological network variability across animals. This procedure leads to modules with different commensurate and discommensurate relationships (<xref ref-type="fig" rid="fig7">Figure 7A</xref> and <xref ref-type="fig" rid="fig7s1">Figure 7â€”figure supplement 1</xref>). There is no longer a single preferred scale ratio or orientation difference (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), but patterns emerge due to the predominance of discommensurate and commensurate relationships. Recall from <xref ref-type="fig" rid="fig6">Figure 6F</xref> that discommensurate module pairs exhibit scale ratios â‰ˆ1.4Â and orientation differences â‰ˆ7ï»¿Â°. Combined withÂ <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mo>â‰ˆ</mml:mo><mml:mn>1.7</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mn>30</mml:mn><mml:mo>âˆ˜</mml:mo></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> module pairs, we find a bimodal distribution of orientation differences around 7Â° and 30Â°, consistent with experimental data (<xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>), and positive correlation between scale ratio and orientation difference. Modules with low scale ratio but high orientation difference decrease this correlation; they arise from defects (<xref ref-type="fig" rid="fig6">Figure 6G</xref>). <xref ref-type="fig" rid="fig7s2">Figure 7â€”figure supplement 2</xref> illustratesÂ how modules observed experimentally may be governed by a variety of lattice relationships.</p><fig-group><fig id="fig7" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.018</object-id><label>Figure 7.</label><caption><title>Simulations spanning different parameters contain diversity in lattice relationships, but average scale ratios are still constant between module pairs.</title><p>Data from five replicate simulations for each set of parameters, encompassing 51 total module pairs. (<bold>A</bold>) Clustering of spatial scales and orientations for one representative simulation (left) and lattice relationship distribution across all pairs of adjacent modules (right) for each set of parameters. (<bold>B</bold>) Spatial scale ratios and orientation differences between adjacent modules with respective histograms to the right and above. Scale ratios and orientation differences exhibit positive rank correlation (Spearmanâ€™s Ï = 0.44, <italic>p</italic> = 0.001). (<bold>C</bold>) Spatial scale ratios. Means indicated by lines. Medians compared through the Mann-Whitney <italic>U</italic> test with reported <italic>p</italic>-value. (<bold>D</bold>) Spatial scale differences normalized by the scale of the first module (M1) in each simulation. Same interpretation of lines and <italic>p</italic>-value as in <bold>C</bold>. The <italic>u</italic><sub>mag</sub> = 2.6 and <italic>l</italic><sub>max</sub> = 10 data are taken from simulations in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Some simulations produced only two modules M1 and M2; one simulation produced four modules, and M4 was excluded from further analysis. Coupling spread <italic>d</italic> = 12 and network size <italic>n</italic> Ã— <italic>n</italic> = 230 Ã— 230. Other parameter values are in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.020</object-id><label>Figure 7â€”figure supplement 1.</label><caption><title>Module clustering for all simulations.</title><p>Clustering of scales and orientations for all replicate simulations spanning a range of parameters.Â Due to 6-fold lattice symmetry, orientation is a periodic variable modulo 60Â°. Different colors indicate separate modules. Simulations use network size <italic>n</italic>Â Ã—Â <italic>n</italic>Â =Â 230 Ã— 230 and coupling spread <italic>d</italic> = 12.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig7-figsupp1-v2.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.019</object-id><label>Figure 7â€”figure supplement 2.</label><caption><title>Lattice relationships that may underlie scale ratios and orientation differences for sample experimental recordings.</title><p>(<bold>A</bold>) Sample single neuron autocorrelation maps of grid cells belonging to four modules from Figure 1c of <xref ref-type="bibr" rid="bib56">Stensola et al. (2012)</xref>. (<bold>B</bold>) Overlays between sheared triangular lattices extracted from the maps in <bold>A</bold> (see Appendix 1 for details). In each panel, the lattice with smaller (larger) scale is depicted in magenta (green), so white indicates activity in both lattices. (<bold>C</bold>) Measured scale ratios and orientation differences, which involves averaging over lattice vectors because the triangular lattices are sheared, and comparable lattice relationships by our model with predicted values. For the left panel, a discommensurate relationship is assigned by visual identification of discommensurations in the left panel of <bold>B</bold>. Because discommensurate lattices allow for a range of scale ratios with corresponding orientation differences, we performed linear regression on <xref ref-type="fig" rid="fig5">Figure 5E</xref> to obtain the predicted orientation difference that corresponds to the measured scale ratio. For the middle and right panels, commensurate lattice relationships are assigned by identifying the lattice points in the middle and right panels of <bold>B</bold> closest to, but not including, the center that exhibit significant overlap and comparing with the idealized relationships in <xref ref-type="fig" rid="fig5">Figure 5C</xref>. Note that our predicted values do not account for the shearing observed in the experimental grids, which will change scale ratios and orientation differences from their unsheared values even for idealized lattice relationships. Shearing may result from tethering of grids to environmental boundaries, perhaps through interactions with border cells (<xref ref-type="bibr" rid="bib33">Keinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>; <xref ref-type="bibr" rid="bib57">Stensola et al., 2015</xref>). (<bold>Dâ€“F</bold>) Same as <bold>Aâ€“C</bold>, but for two modules from Figure 2d of <xref ref-type="bibr" rid="bib36">Krupic et al. (2015)</xref>. A comprehensive test requires analysis of experiments using circular enclosures to eliminate confounding boundary effects (see Discussion).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig7-figsupp2-v2.tif"/></fig></fig-group><p>Scale ratios across the assortedÂ simulations span a range of values, but their averages are constant across module pairs. That is, the median scale ratio does not change between the pair of modules with smaller scales and the larger pair (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). Similarly, mean values are respectively 1.52Â Â±Â 0.05 and 1.53Â Â±Â 0.05 (mean Â± s.e.m.) for module pairs M2 and M1 and M3 and M2. Combining data from both module pairs gives scale ratio 1.52Â Â±Â 0.03 (mean Â± s.e.m.), which agrees well with the mean value of 1.56 from <xref ref-type="bibr" rid="bib36">Krupic et al. (2015)</xref>. <xref ref-type="bibr" rid="bib56">Stensola et al. (2012)</xref> reports a slightly smaller mean value of 1.42Â Â±Â 0.17 (mean Â± s.d.; re-analyzed by <xref ref-type="bibr" rid="bib63">Wei et al., 2015</xref>), but its broad distribution of scale ratios overlaps considerably with ours. Moreover, we find that the normalized scale <italic>difference</italic> does change its median across module pairs (<xref ref-type="fig" rid="fig7">Figure 7D</xref>). This result that scale ratios are constant on average but scale differences are not matches experiment (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>).</p><p>Thus, although our model can produce modules with fixed scale ratios, allowing for a range of network parameters also produces modules with a range of scale ratios. Nevertheless, the scale ratio averaged over these parameters is still constant across module pairs, a key feature of the grid system that holds even if scales are not governed by a universal ratio (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>).</p></sec><sec id="s2-7"><title>Testing for coupling: a mock lesion experiment</title><p>Excitatory coupling locks networks into scales and orientations imposed by more ventral networks. Disrupting the coupling frees networks from this rigidity, which can change scales and orientations far from the disruption. We demonstrate this effect by inactivating one network <italic>z</italic>Â =Â 7 midway through the simulation (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). This corresponds experimentally to disrupting excitatory connections at one location along the dorsoventral MEC axis.</p><fig-group><fig id="fig8" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.021</object-id><label>Figure 8.</label><caption><title>Lesioning a network changes grid scales and orientations of more dorsal networks.</title><p>(<bold>A</bold>) Lesion protocol. The lesion inactivates network <italic>z</italic> = 7. (<bold>B</bold>) A representative simulation before the lesion. Top row: network activities at the end of the pre-lesion simulation. Second row: activity overlays between adjacent networks depicted in the top row. In each panel, the network with smaller (larger) <italic>z</italic> is depicted in magenta (green), so white indicates activity in both networks. Third row: spatial rate map of a single neuron for each <italic>z</italic> superimposed on the animalâ€™s trajectory. White scale bars, 50 neurons. Black scale bars, 50 cm. (<bold>C</bold>) Same as <bold>B</bold> but after the lesion. Spatial rate maps are recorded from the same neurons as in <bold>B</bold>. (<bold>D, E</bold>) Data from 10 replicate simulations. (<bold>D</bold>) Left: spatial grid scales Î›(<italic>z</italic>) before and after the lesion. Middle: histogram for Î› collected across all networks. Right: spatial orientations Î˜ relative to the grid cell in the same simulation with largest scale. (<bold>E</bold>) Spatial scale ratios and orientation differences between adjacent modules. Standard parameter values provided in <xref ref-type="table" rid="table1">Table 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig8-v2.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.46687.022</object-id><label>Figure 8â€”figure supplement 1.</label><caption><title>The effects of incomplete lesions on grid cells in more dorsal networks.</title><p>(<bold>Aâ€“C</bold>) A regional lesion of network <italic>z</italic> = 7 that spares the lower left quadrant. (<bold>A</bold>) A representative post-lesion simulation. Top row: network activities at the end of the post-lesion simulation. Second row: activity overlays between adjacent networks depicted in the top row. In each panel, the network with smaller (larger) <italic>z</italic> is depicted in magenta (green), so white indicates activity in both networks. Third row: spatial rate map of a single neuron for each <italic>z</italic> superimposed on the animalâ€™s trajectory. Bottom row: spatial autocorrelations of the rate maps depicted in the third row. White scale bars, 50 neurons. Black scale bars, 50 cm. (<bold>B</bold>) Left: spatial grid scales Î›(<italic>z</italic>) before and after the lesion. Middle: histogram for Î› collected across all networks. Right: spatial orientations Î˜ relative to the grid cell in the same simulation with largest scale. For each <italic>z</italic>, two neurons are selected from the lower left quadrant and two neurons are selected from elsewhere. (<bold>C</bold>) Spatial scale ratios and orientation differences between adjacent modules. (<bold>D</bold>) A representative post-lesion simulation of a decimation of network <italic>n</italic> = 7 that spares the top left neuron in every 3 Ã— 3 block. Rows same as the top three rows of <bold>A</bold>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-fig8-figsupp1-v2.tif"/></fig><media id="fig8video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-46687-fig8-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.46687.023</object-id><label>Figure 8â€”video 1.</label><caption><title>Last 100Â s of the simulation displayed in <xref ref-type="fig" rid="fig8s1">Figure 8â€”figure supplement 1A</xref>.</title><p>Top left: accumulated rat trajectory (gray curve) with current rat position (blue dot). Top right, bottom left, and bottom right: activity overlays between adjacent networks with the network at smaller (larger) <italic>z</italic> depicted in magenta (green), so white indicates regions of activity in both networks. White scale bar, 50 neurons. Black scale bar, 50Â cm.</p></caption></media><media id="fig8video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-46687-fig8-video2.mp4"><object-id pub-id-type="doi">10.7554/eLife.46687.024</object-id><label>Figure 8â€”video 2.</label><caption><title>Last 100Â s of the simulation displayed in <xref ref-type="fig" rid="fig8s1">Figure 8â€”figure supplement 1D</xref>.</title><p>Panels same as in <xref ref-type="video" rid="fig8video1">Figure 8â€”video 1</xref>.</p></caption></media></fig-group><p>After the lesion, grid cells ventral to the lesion location (<italic>z</italic>Â â‰¥Â 8) are unaffected, but those dorsal to the lesion location (<italic>z</italic>Â â‰¤Â 6) change scale and orientation and form a single module (<xref ref-type="fig" rid="fig8">Figure 8Bâ€“D</xref>). Network <italic>z</italic>Â =Â 6 is no longer constrained by larger grids of more ventral networks, so its scale decreases. The coupling that remains from <italic>z</italic>Â =Â 6Â to 1 then rigidly propagates the new grid down to network <italic>z</italic>Â =Â 1. This post-lesion module M1 has larger scale and 30Âº orientation difference compared to the pre-lesion M1; these changes also appear as corresponding changes in the scale ratio and orientation difference between modules M2 and M1 (<xref ref-type="fig" rid="fig8">Figure 8E</xref>).</p><p>Immediate changes in grid scale and/or orientation observed at one location along the longitudinal MEC axis due to a lesion at another location would strongly support the presence of the excitatory coupling predicted by our model. Moreover, the anatomical distribution of the changes would indicate the directionality of coupling; those in grid cells dorsal to the lesion would indicate ventral-to-dorsal coupling and those ventral to the lesion would indicate dorsal-to-ventral coupling.</p><p>We have also considered the consequences of certain incomplete lesions. A regional lesion, in which a corner of the lesioned network <italic>z</italic>Â =Â 7Â is preserved, causes each more dorsal network to contain regions with different scales (<xref ref-type="fig" rid="fig8s1">Figure 8â€”figure supplement 1</xref> and <xref ref-type="video" rid="fig8video1">Figure 8â€”video 1</xref>). These differences are not large enough to create a new module close to the lesioned network (<italic>z</italic>Â =Â 5Â andÂ 6), so scale ratios and orientations are not strongly affected. However, different regions of each network will independently transition to the smallest module farther away from the lesioned network (<italic>z</italic>Â =Â 1Â to 4). Thus, one network corresponding to a single location along the dorso-ventral MEC axis can contain grid cells belonging to two modules. Experimentally, grid modules do overlap in their anatomic extent along the MEC axis (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>); our model predicts that this overlap may be enhanced by a regional lesion. Note that some neurons also appear to show band-like spatial rate maps (<italic>z</italic>Â =Â 4Â and 6 in <xref ref-type="fig" rid="fig8s1">Figure 8â€”figure supplement 1A</xref>), whose experimental observation has been reported (<xref ref-type="bibr" rid="bib35">Krupic et al., 2012</xref>) but disputed (<xref ref-type="bibr" rid="bib44">Navratilova et al., 2016</xref>). We also performed a decimation-type lesion, in which one neuron of every 3 Ã— 3 block is preserved in the lesioned network. This impedes the motion of the grid pattern on the neural sheet in more dorsal networks (<xref ref-type="video" rid="fig8video2">Figure 8â€”video 2</xref>) and thus destroys single neuron grid responses in those networks (<xref ref-type="fig" rid="fig8s1">Figure 8â€”figure supplement 1D</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We propose that the hierarchy of grid modules in the MEC is self-organized by competition in attractor networks between excitation along the longitudinal MEC axis and lateral inhibition. We showed that such an architecture, with an inhibition distance that increases smoothly along the MEC axis, reproduces a central experimental finding: grid cells form modules with scales clustered around discrete values (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Barry et al., 2007</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>).</p><p>The distribution of scales across modules in our model quantitatively matches experiments. Different groups have reported mean scale ratios of 1.64 (6 module pairs), 1.42 (24 module pairs), and 1.56 (11 module pairs) (<xref ref-type="bibr" rid="bib3">Barry et al., 2007</xref>; <xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>). These data could be interpreted as an indication that the grid system has a preferred scale ratio roughly in range of 1.4â€“1.7. As we showed, our model naturally produces a hierarchy of modules with scale ratios in this range; its network parameters lead to both commensurate and discommensurate grids (<xref ref-type="fig" rid="fig5">Figure 5</xref>). On the other hand, the data on scale ratios between individual pairs of modules actually span a range of values in the different experiments: 1.6â€“1.9, 1.1â€“1.8, and 1.2â€“2.0 (<xref ref-type="bibr" rid="bib3">Barry et al., 2007</xref>; <xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>). This suggests that the underlying mechanism that produces grid modules must be capable of producing different scale ratios as its parameters vary. This is indeed the case for our model, in which variation of network parameters produces a realistic range of scale ratios (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Despite variability across individual scale ratios, experiments strikingly reveal that the average scale ratioÂ is the same from the smallest pair of modules to the largest pair, whereas the average scale <italic>difference</italic> changes across the hierarchy (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). Our model robustly reproduces this observation (<xref ref-type="fig" rid="fig7">Figure 7C,D</xref>) because its fundamental mechanism of geometric coordination between grids enforces constant-on-average scale ratios even with variation in parameters among individual networks.</p><p>Our model requires that grid orientation be co-modular with scale, as observed in experiment (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). Studies characterizing the statistics of orientation differences between modules are limited, but values seem to span the entire range 0Â°â€“30Â°, with some preference for values at the low and high ends of this range (<xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>). Our model can capture the entire range of orientation differences with discommensurate relationships favoring small differences and commensurate relationships favoring large differences (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Overall, our model predicts a positive correlation between scale ratio and orientation difference (<xref ref-type="fig" rid="fig5">Figure 5E</xref> and <xref ref-type="fig" rid="fig7">Figure 7B</xref>), which can be tested experimentally. Existing datasets (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>) have a confoundâ€”animals are tested in square and rectangular enclosures which have distinguishable orientations marked by the corners. Grid orientations can anchor to such features (<xref ref-type="bibr" rid="bib57">Stensola et al., 2015</xref>), either through the integration of visual and external cues (<xref ref-type="bibr" rid="bib48">Raudies and Hasselmo, 2015</xref>; <xref ref-type="bibr" rid="bib51">Savelli et al., 2017</xref>), or through interaction with boundaries (<xref ref-type="bibr" rid="bib8">Bush and Burgess, 2014</xref>; <xref ref-type="bibr" rid="bib37">Krupic et al., 2016</xref>; <xref ref-type="bibr" rid="bib22">Giocomo, 2016</xref>; <xref ref-type="bibr" rid="bib16">Evans et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Hardcastle et al., 2017</xref>; <xref ref-type="bibr" rid="bib33">Keinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ocko et al., 2018</xref>). Experiments in circular or other non-rectangular environments may help disambiguate the effects of such anchoring. Our model also predicts that orientation differences between modules will be preserved between environments with different geometries since the differences are internally generated by the dynamics of the network. This effect has been observed (<xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>).</p><p>Our model produces consistent differences in firing rate from one grid field to another for some grid cells. This variability is structured because it arises at module interfaces from the selective excitation of some network activity peaks in the smaller-scale grid by the overlapping activity peaks of the larger-scale grid. Such an explanation for firing rate variability has been suggested by <xref ref-type="bibr" rid="bib31">Ismakov et al. (2017)</xref>. Signatures of structured variability can be sought in experimental grid cell recordings (see <xref ref-type="fig" rid="fig6s2">Figure 6â€”figure supplement 2</xref> for an example). However, these signatures may be obscured by other sources of grid variability, such as proposed inputs from place cells (<xref ref-type="bibr" rid="bib15">Dunn et al., 2017</xref>) and the observed modulation of grid fields by reward (<xref ref-type="bibr" rid="bib9">Butler et al., 2019</xref>; <xref ref-type="bibr" rid="bib4">Boccara et al., 2019</xref>), which may in turn be also related to hippocampal input.</p><p>Our model requires excitatory coupling between grid cells at different locations along the longitudinal MEC axis, either through direct excitation or disinhibition (<xref ref-type="bibr" rid="bib20">Fuchs et al., 2016</xref>). Short-range excitatory connections between principal neurons in superficial MEC layers have been discovered recently through patch clamp experiments (<xref ref-type="bibr" rid="bib20">Fuchs et al., 2016</xref>; <xref ref-type="bibr" rid="bib66">Winterer et al., 2017</xref>). These neurons also make long-range projections to superficial layers of the contralateral MEC (<xref ref-type="bibr" rid="bib61">Varga et al., 2010</xref>; <xref ref-type="bibr" rid="bib20">Fuchs et al., 2016</xref>), where they connect to other principal cells (<xref ref-type="bibr" rid="bib68">Zutshi et al., 2018</xref>). The validity of our model would be bolstered if similar connections were found between locations along the MEC that correspond to different grid modules.</p><p>The presence of excitatory coupling can also be tested indirectly. We predict that the destruction of grid cells, or inactivation of excitatory coupling (<xref ref-type="bibr" rid="bib68">Zutshi et al., 2018</xref>), at a given location along the axis will change grid scales and/or orientations at other locations (<xref ref-type="fig" rid="fig8">Figure 8</xref>). The presence of noise correlations across modules, as previously investigated but not fully characterized (<xref ref-type="bibr" rid="bib40">Mathis et al., 2013</xref>; <xref ref-type="bibr" rid="bib59">Tocker et al., 2015</xref>), would suggest connections between modules. Such correlations, and perhaps even lattice relationships, could be observed via calcium imaging of the MEC (<xref ref-type="bibr" rid="bib30">Heys et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Gu et al., 2018</xref>). The effect of environmental manipulations on grid relationships has been suggested to demonstrate both independence (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>) and dependence (<xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>) across modules. However, (<xref ref-type="bibr" rid="bib33">Keinath et al., 2018</xref>) showed that apparent deformations of grids after changes in environmental shape may result in part from learned interactions with boundaries, perhaps mediated by border cells. Thus, environmental deformation paradigms may not be ideal tests of our model due to confounding boundary effects (<xref ref-type="bibr" rid="bib33">Keinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ocko et al., 2018</xref>).</p><p>Our predictions may be altered by synaptic plasticity, which we do not implement in our model. Spike-timing-dependent plasticity rules are capable of creating the recurrent inhibitory architecture required by continuous attractor models of a single grid module (<xref ref-type="bibr" rid="bib64">Widloski and Fiete, 2014</xref>). As for our model with multiple modules, synaptic plasticity within the inhibitory connections may resolve the competition between excitation and inhibition by adjusting the inhibition distance in each network to the value favored by the rigidity of excitatory coupling. In that case, lesioning one network would not affect the grid scales of other networks, although changes in orientation differences may be observed over time due to attractor drift. Nevertheless, our proposed geometric mechanism could still govern the initial formation of modules with certain scale ratios before plasticity fully takes effect.</p><p>Since spatial grid scales are both proportional to inhibition distance <italic>l</italic> and inversely proportional to velocity gain <inline-formula><mml:math id="inf21"><mml:mi>Î±</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref> and MaterialsÂ andÂ methods), we also simulated excitatorily coupled networks with a depth-dependent velocity gain Î±(<italic>z</italic>) and a fixed inhibition distance <italic>l</italic> (Appendix 2). In contrast to simulations in one dimension (J Widloski and I Fiete, personal communication, October 2017), while we observed module self-organization, the system gave inconsistent results among replicate simulations and lacked fixed scale ratios. Moreover, recent calcium imaging experiments suggest that activity on the MEC is arranged a deformed triangular lattice (<xref ref-type="bibr" rid="bib25">Gu et al., 2018</xref>), as predicted by the continuous attractor model (<xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>), and that regions with activity separated by larger anatomic distances contain grid cells of larger spatial scale. These observations support a changing inhibition distance over a changing velocity gain as a mechanism for producing different grid scales, under the assumption that anatomic and network distances correspond to each other.</p><p>Our results differ from previous work on mechanisms for forming grid modules. Grossberg and Pilly hypothesize that grid cells arise from stripe cells in parasubiculum, and that discreteness in the spatial period of stripe cells leads to modularity of grid cells (<xref ref-type="bibr" rid="bib23">Grossberg and Pilly, 2012</xref>). However, stripe cells have only been observed once (<xref ref-type="bibr" rid="bib35">Krupic et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">Navratilova et al., 2016</xref>), and the origin of discrete periods with constant-on-average ratios in stripe cells would then need to be addressed. Urdapilleta, Si, and Treves propose a model in which discrete modules self-organize from smooth gradients in parameters in a model where grid formation is driven by firing rate adaptation in single cells (<xref ref-type="bibr" rid="bib60">Urdapilleta et al., 2017</xref>). They also utilize excitatory coupling among grid cells along the longitudinal MEC axis. However, this model does not have a mechanism to dynamically enforce the average constancy of grid scale ratios, which is a feature of the grid system (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). Furthermore, it produces modules with orientation differences near zero and does not demonstrate values near 30Â°Â (<xref ref-type="bibr" rid="bib36">Krupic et al., 2015</xref>). Our model naturally produces constant-on-average scale ratios and allows for a wide range of orientation differences. Moreover, over the past few years, multiple reports have provided independent experimental support for the importance of recurrent connections among grid cells (<xref ref-type="bibr" rid="bib11">Couey et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Dunn et al., 2015</xref>; <xref ref-type="bibr" rid="bib20">Fuchs et al., 2016</xref>; <xref ref-type="bibr" rid="bib68">Zutshi et al., 2018</xref>) and for the continuous attractor model in particular (<xref ref-type="bibr" rid="bib67">Yoon et al., 2013</xref>; <xref ref-type="bibr" rid="bib30">Heys et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Gu et al., 2018</xref>). Our work establishes that continuous attractor networks can produce a discrete hierarchy of modules with a constant-on-average scale ratio.</p><p>The competition generated between excitatory and inhibitory connections bears a strong resemblance to the Frenkel-Kontorova model of condensed matter physics, in which a periodic potential of one scale acts on particles that prefer to form a lattice of a different, competing scale (<xref ref-type="bibr" rid="bib34">Kontorova and Frenkel, 1938</xref>). This model has a rich literature with many deep theoretical results, including the calculation of complicated phase diagrams involving â€˜devilâ€™s staircasesâ€™ (<xref ref-type="bibr" rid="bib1">Bak, 1982</xref>; <xref ref-type="bibr" rid="bib10">Chaikin and Lubensky, 1995</xref>) which mirror those of our model (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Under certain conditions, our model produces networks with quasicrystalline approximant grids that are driven by networks with standard triangular grids at other scales (Appendix 3). Quasicrystalline order lacks periodicity, but contains more nuanced positional order (<xref ref-type="bibr" rid="bib38">Levine and Steinhardt, 1986</xref>). This phenomenon wherein quasicrystalline structure is driven by crystalline order in a coupled system was recently observed for the first time in thin-film materials that contain Frenkel-Kontorova-like interactions (<xref ref-type="bibr" rid="bib18">FÃ¶rster et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">FÃ¶rster et al., 2016</xref>; <xref ref-type="bibr" rid="bib46">PaÃŸens et al., 2017</xref>).</p><p>Commensurate and discommensurate lattice relationships are a robust and versatile mechanism for self-organizing a grid system whose scale ratios are constant or constant on average across a hierarchy of modules. We demonstrated this mechanism in a basic extension of the continuous attractor model with excitatory connections between networks. This model is amenable to extensions that capture other features of the grid system, such as fully spiking dynamics, learning of synaptic weights (<xref ref-type="bibr" rid="bib64">Widloski and Fiete, 2014</xref>), the union of our separate networks into a single network spanning the entire MEC, and the addition of border cell inputs or recurrent coupling between modules to correct path-integration errors or react to environmental deformations (<xref ref-type="bibr" rid="bib27">Hardcastle et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Keinath et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Ocko et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">Pollock et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Mosheiff and Burak, 2019</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Model setup and dynamics</title><p>We implemented the Burak-Fiete model (<xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>) as follows (<xref ref-type="supplementary-material" rid="scode1">Source code 1</xref>). Networks <inline-formula><mml:math id="inf22"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">â€¦</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> each contain a 2D sheet of neurons with indices <inline-formula><mml:math id="inf23"><mml:mrow><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf24"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">â€¦</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf25"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">â€¦</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Neurons receive broad excitatory input <inline-formula><mml:math id="inf26"><mml:mrow><mml:mi>a</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from the hippocampus, and, to prevent edge effects, those toward the center of the networks receive more excitation than those toward the edges. Each neuron also inhibits others that lie around a length scale of <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> neurons away in the same network <inline-formula><mml:math id="inf28"><mml:mi>z</mml:mi></mml:math></inline-formula>. Moreover, every neuron belongs to one of four subpopulations that evenly tile the neural sheet. Each subpopulation is associated with both a preferred direction <inline-formula><mml:math id="inf29"><mml:mover accent="true"><mml:mi mathvariant="bold">ğ</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> along one of the network axes <inline-formula><mml:math id="inf30"><mml:mrow><mml:mo>Â±</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ±</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf31"><mml:mrow><mml:mo>Â±</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ²</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> and a corresponding preferred direction <inline-formula><mml:math id="inf32"><mml:mover accent="true"><mml:mi mathvariant="bold">ğ„</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> along an axis <inline-formula><mml:math id="inf33"><mml:mrow><mml:mo>Â±</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ—</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf34"><mml:mrow><mml:mo>Â±</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ˜</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> in its spatial environment. A neuron at position <inline-formula><mml:math id="inf35"><mml:mi mathvariant="bold">ğ«</mml:mi></mml:math></inline-formula> in network <inline-formula><mml:math id="inf36"><mml:mi>z</mml:mi></mml:math></inline-formula> has its inhibitory outputs <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>w</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>;</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> shifted slightly by <inline-formula><mml:math id="inf38"><mml:mi>Î¾</mml:mi></mml:math></inline-formula> neurons in the <inline-formula><mml:math id="inf39"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> direction and its broad excitation modulated by a small amount proportional to <inline-formula><mml:math id="inf40"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ„</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>â‹…</mml:mo><mml:mi mathvariant="bold">ğ•</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf41"><mml:mi mathvariant="bold">ğ•</mml:mi></mml:math></inline-formula> is the spatial velocity of the animal. Note that lowercase letters refer to attractor networks at each depth <inline-formula><mml:math id="inf42"><mml:mi>z</mml:mi></mml:math></inline-formula> in which distances have units of neurons, and uppercase letters refer to the animalâ€™s spatial environment in which distances have physical units, such as centimeters.</p><p>In addition to these established features (<xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>), we introduce excitatory connections <inline-formula><mml:math id="inf43"><mml:mrow><mml:mi>u</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from every neuron <inline-formula><mml:math id="inf44"><mml:mi mathvariant="bold">ğ«</mml:mi></mml:math></inline-formula>Â in network <inline-formula><mml:math id="inf45"><mml:mi>z</mml:mi></mml:math></inline-formula> to neurons located within a spread <inline-formula><mml:math id="inf46"><mml:mi>d</mml:mi></mml:math></inline-formula> of the same <inline-formula><mml:math id="inf47"><mml:mi mathvariant="bold">ğ«</mml:mi></mml:math></inline-formula> but in the preceding network with depth <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>z</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>u</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>Â is constant for all networks. These components lead to the following dynamical equation for the dimensionless neural firing rates <inline-formula><mml:math id="inf50"><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Ï„</mml:mi><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Î”</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>âˆ’</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mspace width="1em"/><mml:mrow/><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">{</mml:mo></mml:mrow><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>âˆ’</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>Î¾</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold">e</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>;</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>âˆ’</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold">E</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">}</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Inputs to each neuron are rectified by <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>c</mml:mi><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> for <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>c</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf53"><mml:mi>c</mml:mi></mml:math></inline-formula> for <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>â‰¥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.Â <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is the simulation time increment, <inline-formula><mml:math id="inf56"><mml:mi>Ï„</mml:mi></mml:math></inline-formula> is the neural relaxation time, and <inline-formula><mml:math id="inf57"><mml:mi>Î±</mml:mi></mml:math></inline-formula> is the velocity gain that describes how much the animalâ€™s velocity <inline-formula><mml:math id="inf58"><mml:mi mathvariant="bold">ğ•</mml:mi></mml:math></inline-formula> modulates the broad inputs <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi>a</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that <inline-formula><mml:math id="inf60"><mml:mi>s</mml:mi></mml:math></inline-formula> can be treated as a dimensionless variable because <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> is invariant to scaling of <inline-formula><mml:math id="inf61"><mml:mi>s</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf62"><mml:mi>a</mml:mi></mml:math></inline-formula> by the same factor.</p><p>We use velocities <inline-formula><mml:math id="inf63"><mml:mrow><mml:mi mathvariant="bold">ğ•</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> corresponding to a real rat trajectory (<xref ref-type="bibr" rid="bib26">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>). Details are provided in Appendix 1.</p></sec><sec id="s4-2"><title>Inhibitory and excitatory connections</title><p>The broad excitatory input is<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mo>âˆ’</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>â‰¥</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mrow><mml:mtext>scaled</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mrow><mml:msqrt><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>âˆ’</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>âˆ’</mml:mo><mml:mfrac><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mrow/><mml:mo stretchy="true">/</mml:mo><mml:mrow/><mml:mfrac><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is a scaled radial distance for the neuron at <inline-formula><mml:math id="inf65"><mml:mrow><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf66"><mml:msub><mml:mi>a</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula> is the magnitude of the input, and <inline-formula><mml:math id="inf67"><mml:msub><mml:mi>a</mml:mi><mml:mtext>fall</mml:mtext></mml:msub></mml:math></inline-formula> is a falloff parameter. The inhibition distance for network <inline-formula><mml:math id="inf68"><mml:mi>z</mml:mi></mml:math></inline-formula> is<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>l</mml:mi><mml:mtext>min</mml:mtext><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>l</mml:mi><mml:mtext>min</mml:mtext><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>â¢</mml:mo><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which ranges from <inline-formula><mml:math id="inf69"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf70"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> with concavity tuned by <inline-formula><mml:math id="inf71"><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula>. More negative values of <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula> lead to greater concavity; for <inline-formula><mml:math id="inf73"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, we use the limiting expression <inline-formula><mml:math id="inf74"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>l</mml:mi><mml:mtext>min</mml:mtext><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>-</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>â¢</mml:mo><mml:msubsup><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. The recurrent inhibition profile for network <inline-formula><mml:math id="inf75"><mml:mi>z</mml:mi></mml:math></inline-formula> is<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>;</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" displaystyle="false" rowspacing=".2em"><mml:mtr><mml:mtd><mml:mo>âˆ’</mml:mo><mml:mfrac><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mtext>mag</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>âˆ’</mml:mo><mml:mi>cos</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>Ï€</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mtd><mml:mtd><mml:mi>r</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>2</mml:mn><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>r</mml:mi><mml:mo>â‰¥</mml:mo><mml:mn>2</mml:mn><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf76"><mml:msub><mml:mi>w</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula> is the magnitude of inhibition. We scale this magnitude by <inline-formula><mml:math id="inf77"><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to make the integrated inhibition constant across <inline-formula><mml:math id="inf78"><mml:mi>z</mml:mi></mml:math></inline-formula>. The excitatory coupling is<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" displaystyle="false" rowspacing=".2em"><mml:mtr><mml:mtd><mml:mfrac><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mrow><mml:mtext>mag</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>cos</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>Ï€</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mtd><mml:mtd><mml:mi>r</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>d</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi>r</mml:mi><mml:mo>â‰¥</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf79"><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf80"><mml:mi>d</mml:mi></mml:math></inline-formula> are the magnitude and spread of coupling, respectively. In analogy to <inline-formula><mml:math id="inf81"><mml:msub><mml:mi>w</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula>, we scale <inline-formula><mml:math id="inf82"><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub></mml:math></inline-formula> by <inline-formula><mml:math id="inf83"><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>.</p></sec><sec id="s4-3"><title>Overview of data analysis techniques</title><p>To determine spatial grid scales, orientations, and gridness, we consider an annular region of the spatial autocorrelation map that contains the six peaks closest to the origin. Grid scale is the radius with highest value, averaging over angles. Grid orientation and gridness are determined by first averaging over radial distance and analyzing the sixth component of the Fourier series with respect to angle (<xref ref-type="bibr" rid="bib62">Weber and Sprekeler, 2019</xref>). The power of this component divided by the total Fourier power measures â€˜gridnessâ€™ and its complex phase measures the orientation. Grid cells are subject to a gridness cutoff of 0.6. For each replicate simulation, we cluster its grid cells with respect to scale and orientation using a <inline-formula><mml:math id="inf84"><mml:mi>k</mml:mi></mml:math></inline-formula>-means procedure with <inline-formula><mml:math id="inf85"><mml:mi>k</mml:mi></mml:math></inline-formula> determined by kernel smoothed densities (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). See Appendix 1 for full details.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We are grateful to Xue-Xin Wei, Tom Lubensky, Ila Fiete, John Widloski, and Zengyi Li for their thoughtful ideas and suggestions.Â We thank Hanne Stensola and Julija Krupic for sharing raw experimental data. We are also grateful to the Kavli Institute for the Physics and Mathematics of the Universe for hospitality provided to VB.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Investigation, Visualization, Methodology, Writingâ€”original draft, Writingâ€”review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Visualization, Methodology, Writingâ€”original draft, Writingâ€”review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><object-id pub-id-type="doi">10.7554/eLife.46687.025</object-id><label>Source code 1.</label><caption><title>Source code for the main simulations written in C.</title></caption><media mime-subtype="x-c" mimetype="text" xlink:href="elife-46687-code1-v2.c"/></supplementary-material><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.46687.026</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-46687-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>We have included the source code for our main simulation as a supporting file.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bak</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Commensurate phases, incommensurate phases and the Devil's staircase</article-title><source>Reports on Progress in Physics</source><volume>45</volume><fpage>587</fpage><lpage>629</lpage><pub-id pub-id-type="doi">10.1088/0034-4885/45/6/001</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname> <given-names>A</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Uria</surname> <given-names>B</given-names></name><name><surname>Blundell</surname> <given-names>C</given-names></name><name><surname>Lillicrap</surname> <given-names>T</given-names></name><name><surname>Mirowski</surname> <given-names>P</given-names></name><name><surname>Pritzel</surname> <given-names>A</given-names></name><name><surname>Chadwick</surname> <given-names>MJ</given-names></name><name><surname>Degris</surname> <given-names>T</given-names></name><name><surname>Modayil</surname> <given-names>J</given-names></name><name><surname>Wayne</surname> <given-names>G</given-names></name><name><surname>Soyer</surname> <given-names>H</given-names></name><name><surname>Viola</surname> <given-names>F</given-names></name><name><surname>Zhang</surname> <given-names>B</given-names></name><name><surname>Goroshin</surname> <given-names>R</given-names></name><name><surname>Rabinowitz</surname> <given-names>N</given-names></name><name><surname>Pascanu</surname> <given-names>R</given-names></name><name><surname>Beattie</surname> <given-names>C</given-names></name><name><surname>Petersen</surname> <given-names>S</given-names></name><name><surname>Sadik</surname> <given-names>A</given-names></name><name><surname>Gaffney</surname> <given-names>S</given-names></name><name><surname>King</surname> <given-names>H</given-names></name><name><surname>Kavukcuoglu</surname> <given-names>K</given-names></name><name><surname>Hassabis</surname> <given-names>D</given-names></name><name><surname>Hadsell</surname> <given-names>R</given-names></name><name><surname>Kumaran</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><volume>557</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Hayman</surname> <given-names>R</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Jeffery</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Experience-dependent rescaling of entorhinal grids</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>682</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.1038/nn1905</pub-id><pub-id pub-id-type="pmid">17486102</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boccara</surname> <given-names>CN</given-names></name><name><surname>Nardin</surname> <given-names>M</given-names></name><name><surname>Stella</surname> <given-names>F</given-names></name><name><surname>O'Neill</surname> <given-names>J</given-names></name><name><surname>Csicsvari</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The entorhinal cognitive map is attracted to goals</article-title><source>Science</source><volume>363</volume><fpage>1443</fpage><lpage>1447</lpage><pub-id pub-id-type="doi">10.1126/science.aav4837</pub-id><pub-id pub-id-type="pmid">30923221</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnevie</surname> <given-names>T</given-names></name><name><surname>Dunn</surname> <given-names>B</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Derdikman</surname> <given-names>D</given-names></name><name><surname>Kubie</surname> <given-names>JL</given-names></name><name><surname>Roudi</surname> <given-names>Y</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Grid cells require excitatory drive from the hippocampus</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>309</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1038/nn.3311</pub-id><pub-id pub-id-type="pmid">23334581</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname> <given-names>Y</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate path integration in continuous attractor network models of grid cells</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000291</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id><pub-id pub-id-type="pmid">19229307</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>An oscillatory interference model of grid cell firing</article-title><source>Hippocampus</source><volume>17</volume><fpage>801</fpage><lpage>812</lpage><pub-id pub-id-type="doi">10.1002/hipo.20327</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A hybrid oscillatory interference/continuous attractor network model of grid cell firing</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>5065</fpage><lpage>5079</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4017-13.2014</pub-id><pub-id pub-id-type="pmid">24695724</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname> <given-names>WN</given-names></name><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Remembered reward locations restructure entorhinal spatial maps</article-title><source>Science</source><volume>363</volume><fpage>1447</fpage><lpage>1452</lpage><pub-id pub-id-type="doi">10.1126/science.aav5297</pub-id><pub-id pub-id-type="pmid">30923222</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chaikin</surname> <given-names>PM</given-names></name><name><surname>Lubensky</surname> <given-names>TC</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Principles of Condensed Matter Physics</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511813467</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Couey</surname> <given-names>JJ</given-names></name><name><surname>Witoelar</surname> <given-names>A</given-names></name><name><surname>Zhang</surname> <given-names>SJ</given-names></name><name><surname>Zheng</surname> <given-names>K</given-names></name><name><surname>Ye</surname> <given-names>J</given-names></name><name><surname>Dunn</surname> <given-names>B</given-names></name><name><surname>Czajkowski</surname> <given-names>R</given-names></name><name><surname>Moser</surname> <given-names>MB</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Roudi</surname> <given-names>Y</given-names></name><name><surname>Witter</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Recurrent inhibitory circuitry as a mechanism for grid formation</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>318</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.1038/nn.3310</pub-id><pub-id pub-id-type="pmid">23334580</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cueva</surname> <given-names>CJ</given-names></name><name><surname>Wei</surname> <given-names>X-X</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergence of grid-like representations by training recurrent neural networks to perform spatial localization</article-title><source>International Conference on Learning Representations</source></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diehl</surname> <given-names>GW</given-names></name><name><surname>Hon</surname> <given-names>OJ</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name><name><surname>Leutgeb</surname> <given-names>JK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid and nongrid cells in medial entorhinal cortex represent spatial location and environmental features with complementary coding schemes</article-title><source>Neuron</source><volume>94</volume><fpage>83</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.004</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunn</surname> <given-names>B</given-names></name><name><surname>MÃ¸rreaunet</surname> <given-names>M</given-names></name><name><surname>Roudi</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Correlations and functional connections in a population of grid cells</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004052</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004052</pub-id><pub-id pub-id-type="pmid">25714908</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dunn</surname> <given-names>B</given-names></name><name><surname>Wennberg</surname> <given-names>D</given-names></name><name><surname>Huang</surname> <given-names>Z</given-names></name><name><surname>Roudi</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid cells show field-to-field variability and this explains the aperiodic response of inhibitory interneurons</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/101899</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname> <given-names>T</given-names></name><name><surname>Bicanski</surname> <given-names>A</given-names></name><name><surname>Bush</surname> <given-names>D</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How environment and self-motion combine in neural representations of space</article-title><source>The Journal of Physiology</source><volume>594</volume><fpage>6535</fpage><lpage>6546</lpage><pub-id pub-id-type="doi">10.1113/JP270666</pub-id><pub-id pub-id-type="pmid">26607203</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname> <given-names>IR</given-names></name><name><surname>Burak</surname> <given-names>Y</given-names></name><name><surname>Brookings</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>What grid cells convey about rat location</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>6858</fpage><lpage>6871</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5684-07.2008</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>FÃ¶rster</surname> <given-names>S</given-names></name><name><surname>Meinel</surname> <given-names>K</given-names></name><name><surname>Hammer</surname> <given-names>R</given-names></name><name><surname>Trautmann</surname> <given-names>M</given-names></name><name><surname>Widdra</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Quasicrystalline structure formation in a classical crystalline thin-film system</article-title><source>Nature</source><volume>502</volume><fpage>215</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1038/nature12514</pub-id><pub-id pub-id-type="pmid">24108053</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>FÃ¶rster</surname> <given-names>S</given-names></name><name><surname>Trautmann</surname> <given-names>M</given-names></name><name><surname>Roy</surname> <given-names>S</given-names></name><name><surname>Adeagbo</surname> <given-names>WA</given-names></name><name><surname>Zollner</surname> <given-names>EM</given-names></name><name><surname>Hammer</surname> <given-names>R</given-names></name><name><surname>Schumann</surname> <given-names>FO</given-names></name><name><surname>Meinel</surname> <given-names>K</given-names></name><name><surname>Nayak</surname> <given-names>SK</given-names></name><name><surname>Mohseni</surname> <given-names>K</given-names></name><name><surname>Hergert</surname> <given-names>W</given-names></name><name><surname>Meyerheim</surname> <given-names>HL</given-names></name><name><surname>Widdra</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Observation and Structure Determination of an Oxide Quasicrystal Approximant</article-title><source>Physical Review Letters</source><volume>117</volume><elocation-id>1260</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.117.095501</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuchs</surname> <given-names>EC</given-names></name><name><surname>Neitz</surname> <given-names>A</given-names></name><name><surname>Pinna</surname> <given-names>R</given-names></name><name><surname>Melzer</surname> <given-names>S</given-names></name><name><surname>Caputi</surname> <given-names>A</given-names></name><name><surname>Monyer</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Local and distant input controlling excitation in layer II of the medial entorhinal cortex</article-title><source>Neuron</source><volume>89</volume><fpage>194</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.029</pub-id><pub-id pub-id-type="pmid">26711115</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuhs</surname> <given-names>MC</given-names></name><name><surname>Touretzky</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A spin glass model of path integration in rat medial entorhinal cortex</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>4266</fpage><lpage>4276</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4353-05.2006</pub-id><pub-id pub-id-type="pmid">16624947</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Environmental boundaries as a mechanism for correcting and anchoring spatial maps</article-title><source>The Journal of Physiology</source><volume>594</volume><fpage>6501</fpage><lpage>6511</lpage><pub-id pub-id-type="doi">10.1113/JP270624</pub-id><pub-id pub-id-type="pmid">26563618</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname> <given-names>S</given-names></name><name><surname>Pilly</surname> <given-names>PK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How entorhinal grid cells may learn multiple spatial scales from a dorsoventral gradient of cell response rates in a self-organizing map</article-title><source>PLOS Computational Biology</source><volume>8</volume><elocation-id>e1002648</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002648</pub-id><pub-id pub-id-type="pmid">23055909</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>GrÃ¼nbaum</surname> <given-names>B</given-names></name><name><surname>Shephard</surname> <given-names>GC</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Tilings by regular polygons</article-title><source>Mathematics Magazine</source><volume>50</volume><fpage>227</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1080/0025570X.1977.11976655</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname> <given-names>Y</given-names></name><name><surname>Lewallen</surname> <given-names>S</given-names></name><name><surname>Kinkhabwala</surname> <given-names>AA</given-names></name><name><surname>Domnisoru</surname> <given-names>C</given-names></name><name><surname>Yoon</surname> <given-names>K</given-names></name><name><surname>Gauthier</surname> <given-names>JL</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A map-like micro-organization of grid cells in the medial entorhinal cortex</article-title><source>Cell</source><volume>175</volume><fpage>736</fpage><lpage>750</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.08.066</pub-id><pub-id pub-id-type="pmid">30270041</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname> <given-names>T</given-names></name><name><surname>Fyhn</surname> <given-names>M</given-names></name><name><surname>Molden</surname> <given-names>S</given-names></name><name><surname>Moser</surname> <given-names>M-B</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Environmental boundaries as an error correction mechanism for grid cells</article-title><source>Neuron</source><volume>86</volume><fpage>827</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.039</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Maheswaranathan</surname> <given-names>N</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A multiplexed, heterogeneous, and adaptive code for navigation in medial entorhinal cortex</article-title><source>Neuron</source><volume>94</volume><fpage>375</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.025</pub-id><pub-id pub-id-type="pmid">28392071</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname> <given-names>ME</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name><name><surname>Zilli</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Grid cell firing may arise from interference of theta frequency membrane potential oscillations in single neurons</article-title><source>Hippocampus</source><volume>17</volume><fpage>1252</fpage><lpage>1271</lpage><pub-id pub-id-type="doi">10.1002/hipo.20374</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heys</surname> <given-names>JG</given-names></name><name><surname>Rangarajan</surname> <given-names>KV</given-names></name><name><surname>Dombeck</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The functional micro-organization of grid cells revealed by cellular-resolution imaging</article-title><source>Neuron</source><volume>84</volume><fpage>1079</fpage><lpage>1090</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.048</pub-id><pub-id pub-id-type="pmid">25467986</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ismakov</surname> <given-names>R</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Jeffery</surname> <given-names>K</given-names></name><name><surname>Derdikman</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid cells encode local positional information</article-title><source>Current Biology</source><volume>27</volume><fpage>2337</fpage><lpage>2343</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.06.034</pub-id><pub-id pub-id-type="pmid">28756950</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Issa</surname> <given-names>NP</given-names></name><name><surname>Rosenberg</surname> <given-names>A</given-names></name><name><surname>Husson</surname> <given-names>TR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Models and measurements of functional maps in V1</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>2745</fpage><lpage>2754</lpage><pub-id pub-id-type="doi">10.1152/jn.90211.2008</pub-id><pub-id pub-id-type="pmid">18400962</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keinath</surname> <given-names>AT</given-names></name><name><surname>Epstein</surname> <given-names>RA</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Environmental deformations dynamically shift the grid cell spatial metric</article-title><source>eLife</source><volume>7</volume><elocation-id>e38169</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.38169</pub-id><pub-id pub-id-type="pmid">30346272</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kontorova</surname> <given-names>T</given-names></name><name><surname>Frenkel</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1938">1938</year><article-title>On the theory of plastic deformation and twinning: II</article-title><source>Zhurnal Ã‰ksperimental'noÄ­ i TeoreticheskoÄ­ Fiziki</source><volume>8</volume><fpage>1340</fpage><lpage>1348</lpage></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural representations of location composed of spatially periodic bands</article-title><source>Science</source><volume>337</volume><fpage>853</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1126/science.1222403</pub-id><pub-id pub-id-type="pmid">22904012</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Burton</surname> <given-names>S</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cell symmetry is shaped by environmental geometry</article-title><source>Nature</source><volume>518</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature14153</pub-id><pub-id pub-id-type="pmid">25673417</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Burton</surname> <given-names>S</given-names></name><name><surname>O'Keefe</surname> <given-names>J</given-names></name><name><surname>Oâ€™Keefe</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Framing the grid: effect of boundaries on grid cells and navigation</article-title><source>The Journal of Physiology</source><volume>594</volume><fpage>6489</fpage><lpage>6499</lpage><pub-id pub-id-type="doi">10.1113/JP270607</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levine</surname> <given-names>D</given-names></name><name><surname>Steinhardt</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Quasicrystals. I. definition and structure</article-title><source>Physical Review B</source><volume>34</volume><fpage>596</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1103/PhysRevB.34.596</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Herz</surname> <given-names>AVM</given-names></name><name><surname>Stemmler</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Optimal population codes for space: grid cells outperform place cells</article-title><source>Neural Computation</source><volume>24</volume><fpage>2280</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00319</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Herz</surname> <given-names>AVM</given-names></name><name><surname>Stemmler</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multiscale codes in the nervous system: The problem of noise correlations and the ambiguity of periodic scales</article-title><source>Physical Review E</source><volume>88</volume><fpage>022713</fpage><pub-id pub-id-type="doi">10.1103/PhysRevE.88.022713</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname> <given-names>EI</given-names></name><name><surname>Kropff</surname> <given-names>E</given-names></name><name><surname>Moser</surname> <given-names>M-B</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Place cells, grid cells, and the brainâ€™s spatial representation system</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>69</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.061307.090723</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mosheiff</surname> <given-names>N</given-names></name><name><surname>Agmon</surname> <given-names>H</given-names></name><name><surname>Moriel</surname> <given-names>A</given-names></name><name><surname>Burak</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An efficient coding theory for a dynamic trajectory predicts non-uniform allocation of entorhinal grid cells to modules</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005597</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005597</pub-id><pub-id pub-id-type="pmid">28628647</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mosheiff</surname> <given-names>N</given-names></name><name><surname>Burak</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Velocity coupling of grid cell modules: stable embedding of a low dimensional variable in a high dimensional neural attractor</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/651513</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navratilova</surname> <given-names>Z</given-names></name><name><surname>Godfrey</surname> <given-names>KB</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Grids from bands, or bands from grids? An examination of the effects of single unit contamination on grid cell firing fields</article-title><source>Journal of Neurophysiology</source><volume>115</volume><fpage>992</fpage><lpage>1002</lpage><pub-id pub-id-type="doi">10.1152/jn.00699.2015</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ocko</surname> <given-names>SA</given-names></name><name><surname>Hardcastle</surname> <given-names>K</given-names></name><name><surname>Giocomo</surname> <given-names>LM</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergent elasticity in the neural code for space</article-title><source>PNAS</source><volume>115</volume><fpage>E11798</fpage><lpage>E11806</lpage><pub-id pub-id-type="doi">10.1073/pnas.1805959115</pub-id><pub-id pub-id-type="pmid">30482856</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>PaÃŸens</surname> <given-names>M</given-names></name><name><surname>Caciuc</surname> <given-names>V</given-names></name><name><surname>Atodiresei</surname> <given-names>N</given-names></name><name><surname>Feuerbacher</surname> <given-names>M</given-names></name><name><surname>Moors</surname> <given-names>M</given-names></name><name><surname>Dunin-Borkowski</surname> <given-names>RE</given-names></name><name><surname>BlÃ¼gel</surname> <given-names>S</given-names></name><name><surname>Waser</surname> <given-names>R</given-names></name><name><surname>KarthÃ¤user</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Interface-driven formation of a two-dimensional dodecagonal fullerene quasicrystal</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>15367</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms15367</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollock</surname> <given-names>E</given-names></name><name><surname>Desai</surname> <given-names>N</given-names></name><name><surname>Wei</surname> <given-names>X</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A mechanism for self-organized error-correction of grid cells by border cells</article-title><source>Cosyne Abstracts 2017, Salt Lake City, UT, USA</source><pub-id pub-id-type="doi">10.1101/385229</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raudies</surname> <given-names>F</given-names></name><name><surname>Hasselmo</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Differences in visual-spatial input may underlie different compression properties of firing fields for grid cell modules in medial entorhinal cortex</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004596</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004596</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rousseeuw</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</article-title><source>Journal of Computational and Applied Mathematics</source><volume>20</volume><fpage>53</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/0377-0427(87)90125-7</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanzeni</surname> <given-names>A</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name><name><surname>Tiana</surname> <given-names>G</given-names></name><name><surname>Vergassola</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Complete coverage of space favors modularity of the grid system in the brain</article-title><source>Physical Review E</source><volume>94</volume><fpage>599</fpage><pub-id pub-id-type="doi">10.1103/PhysRevE.94.062409</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savelli</surname> <given-names>F</given-names></name><name><surname>Luck</surname> <given-names>JD</given-names></name><name><surname>Knierim</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Framing of grid cells within and beyond navigation boundaries</article-title><source>eLife</source><volume>6</volume><elocation-id>e21354</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.21354</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname> <given-names>S</given-names></name><name><surname>Fiete</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1330</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1038/nn.2901</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stampfli</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>A dodecagonal quasiperiodic lattice in two dimensions</article-title><source>Helvetica Physica Acta</source><volume>59</volume><fpage>1260</fpage><lpage>1263</lpage></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stemmler</surname> <given-names>M</given-names></name><name><surname>Mathis</surname> <given-names>A</given-names></name><name><surname>Herz</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Connecting multiple spatial scales to decode the population activity of grid cells</article-title><source>Science Advances</source><volume>1</volume><elocation-id>e1500816</elocation-id><pub-id pub-id-type="doi">10.1126/science.1500816</pub-id><pub-id pub-id-type="pmid">26824061</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stemmler</surname> <given-names>M</given-names></name><name><surname>Herz</surname> <given-names>AVM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatial cognition: grid cells harbour three complementary positional codes</article-title><source>Current Biology</source><volume>27</volume><fpage>R755</fpage><lpage>R758</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.06.067</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname> <given-names>H</given-names></name><name><surname>Stensola</surname> <given-names>T</given-names></name><name><surname>Solstad</surname> <given-names>T</given-names></name><name><surname>FrÃ¸land</surname> <given-names>K</given-names></name><name><surname>Moser</surname> <given-names>M-B</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The entorhinal grid map is discretized</article-title><source>Nature</source><volume>492</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1038/nature11649</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname> <given-names>T</given-names></name><name><surname>Stensola</surname> <given-names>H</given-names></name><name><surname>Moser</surname> <given-names>M-B</given-names></name><name><surname>Moser</surname> <given-names>EI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Shearing-induced asymmetry in entorhinal grid cells</article-title><source>Nature</source><volume>518</volume><fpage>207</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1038/nature14151</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taube</surname> <given-names>JS</given-names></name><name><surname>Muller</surname> <given-names>RU</given-names></name><name><surname>Ranck</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Head-direction cells recorded from the postsubiculum in freely moving rats. I. description and quantitative analysis</article-title><source>The Journal of Neuroscience</source><volume>10</volume><fpage>420</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-02-00420.1990</pub-id><pub-id pub-id-type="pmid">2303851</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tocker</surname> <given-names>G</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name><name><surname>Derdikman</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cells correlation structure suggests organized feedforward projections into superficial layers of the medial entorhinal cortex</article-title><source>Hippocampus</source><volume>25</volume><fpage>1599</fpage><lpage>1613</lpage><pub-id pub-id-type="doi">10.1002/hipo.22481</pub-id><pub-id pub-id-type="pmid">26105192</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urdapilleta</surname> <given-names>E</given-names></name><name><surname>Si</surname> <given-names>B</given-names></name><name><surname>Treves</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Selforganization of modular activity of grid cells</article-title><source>Hippocampus</source><volume>27</volume><fpage>1204</fpage><lpage>1213</lpage><pub-id pub-id-type="doi">10.1002/hipo.22765</pub-id><pub-id pub-id-type="pmid">28768062</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varga</surname> <given-names>C</given-names></name><name><surname>Lee</surname> <given-names>SY</given-names></name><name><surname>Soltesz</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Target-selective GABAergic control of entorhinal cortex output</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>822</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1038/nn.2570</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weber</surname> <given-names>SN</given-names></name><name><surname>Sprekeler</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A local measure of symmetry and orientation for individual spikes of grid cells</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006804</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006804</pub-id><pub-id pub-id-type="pmid">30730888</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname> <given-names>XX</given-names></name><name><surname>Prentice</surname> <given-names>J</given-names></name><name><surname>Balasubramanian</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A principle of economy predicts the functional architecture of grid cells</article-title><source>eLife</source><volume>4</volume><elocation-id>e08362</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08362</pub-id><pub-id pub-id-type="pmid">26335200</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Widloski</surname> <given-names>J</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A model of grid cell development through spatial exploration and spike time-dependent plasticity</article-title><source>Neuron</source><volume>83</volume><fpage>481</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.06.018</pub-id><pub-id pub-id-type="pmid">25033187</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Solution of the 1t2 discommensurate state of 1T-TaS2. an example of rotated hexagonal discommensuration</article-title><source>Journal of Physics: Condensed Matter</source><volume>2</volume><fpage>1683</fpage><lpage>1704</lpage><pub-id pub-id-type="doi">10.1088/0953-8984/2/7/002</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winterer</surname> <given-names>J</given-names></name><name><surname>Maier</surname> <given-names>N</given-names></name><name><surname>Wozny</surname> <given-names>C</given-names></name><name><surname>Beed</surname> <given-names>P</given-names></name><name><surname>Breustedt</surname> <given-names>J</given-names></name><name><surname>Evangelista</surname> <given-names>R</given-names></name><name><surname>Peng</surname> <given-names>Y</given-names></name><name><surname>D'Albis</surname> <given-names>T</given-names></name><name><surname>Kempter</surname> <given-names>R</given-names></name><name><surname>Schmitz</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Excitatory microcircuits within superficial layers of the medial entorhinal cortex</article-title><source>Cell Reports</source><volume>19</volume><fpage>1110</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.04.041</pub-id><pub-id pub-id-type="pmid">28494861</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoon</surname> <given-names>K</given-names></name><name><surname>Buice</surname> <given-names>MA</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name><name><surname>Hayman</surname> <given-names>R</given-names></name><name><surname>Burgess</surname> <given-names>N</given-names></name><name><surname>Fiete</surname> <given-names>IR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Specific evidence of low-dimensional continuous attractor dynamics in grid cells</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1077</fpage><lpage>1084</lpage><pub-id pub-id-type="doi">10.1038/nn.3450</pub-id><pub-id pub-id-type="pmid">23852111</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zutshi</surname> <given-names>I</given-names></name><name><surname>Fu</surname> <given-names>ML</given-names></name><name><surname>Lilascharoen</surname> <given-names>V</given-names></name><name><surname>Leutgeb</surname> <given-names>JK</given-names></name><name><surname>Lim</surname> <given-names>BK</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Recurrent circuits within medial entorhinal cortex superficial layers support grid cell firing</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3701</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06104-5</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.46687.027</object-id><sec id="s8" sec-type="appendix"><title>Additional methods</title><sec id="s8-1"><title>Simulation setup</title><sec id="s8-1-1"><title>Standard model</title><p>To distribute neural subpopulations evenly, we assign each position in a <inline-formula><mml:math id="inf86"><mml:mrow><mml:mn>2</mml:mn><mml:mo>Ã—</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> block of neurons to a different subpopulation and tile each network with these blocks. In other words, for a network of size <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>n</mml:mi><mml:mo>Ã—</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>, the preferred network directions are <inline-formula><mml:math id="inf88"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ±</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf89"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ²</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf90"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ²</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf91"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ±</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> for block indices <inline-formula><mml:math id="inf92"><mml:mrow><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">â€¦</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The preferred spatial directions take corresponding values <inline-formula><mml:math id="inf93"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ„</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ—</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf94"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ„</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ˜</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf95"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ„</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ˜</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf96"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">ğ„</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">ğ—</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>.</p><p>We initialize each neuron with a uniformly-distributed random firing rate between 0 and 0.001 (arbitrary units). We evolve 500 timesteps without velocity input to generate grid-like activity. Next, we anneal grid defects. For each velocity angle <inline-formula><mml:math id="inf97"><mml:mrow><mml:mrow><mml:mi>Ï€</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>Ï€</mml:mi><mml:mo>/</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf98"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>Ï€</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf99"><mml:mrow><mml:mi>Ï€</mml:mi><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, we evolve 5000â€“10000 timesteps with constant speed <inline-formula><mml:math id="inf100"><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>0.5</mml:mn></mml:mpadded><mml:mo>â¢</mml:mo><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:math></inline-formula>. We then evolve 50000Â timesteps with velocity data from a real rat trajectory within a circular enclosure (<xref ref-type="bibr" rid="bib26">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>). The main simulation phase ensues with continuation of velocity input from the trajectory. For each network <inline-formula><mml:math id="inf101"><mml:mi>z</mml:mi></mml:math></inline-formula>, we randomly choose three neurons within a distance of <inline-formula><mml:math id="inf102"><mml:mrow><mml:mn>0.15</mml:mn><mml:mo>â¢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> from the network center. Throughout the main phase, we tabulate their mean firing rates as a function of rat spatial position.</p></sec><sec id="s8-1-2"><title>Modified models in <xref ref-type="fig" rid="fig4">Figure 4Aâ€“H</xref></title><p>The various models depicted in <xref ref-type="fig" rid="fig4">Figure 4</xref> differ from the standard model with standard parameters in <xref ref-type="table" rid="table1">Table 1</xref> in the following ways.</p><p><xref ref-type="fig" rid="fig4">Figure 4A</xref> <inline-formula><mml:math id="inf103"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.Â </p><p><xref ref-type="fig" rid="fig4">Figure 4B</xref> <inline-formula><mml:math id="inf104"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p><xref ref-type="fig" rid="fig4">Figure 4C</xref> Dorsal-to-ventral coupling from each network <inline-formula><mml:math id="inf105"><mml:mi>z</mml:mi></mml:math></inline-formula> to network <inline-formula><mml:math id="inf106"><mml:mrow><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf107"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf108"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>.Â </p><p><xref ref-type="fig" rid="fig4">Figure 4D</xref> Bidirectional coupling from each network <inline-formula><mml:math id="inf109"><mml:mi>z</mml:mi></mml:math></inline-formula> to networks <inline-formula><mml:math id="inf110"><mml:mrow><mml:mi>z</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf111"><mml:mrow><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf112"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>.Â </p><p><xref ref-type="fig" rid="fig4">Figure 4E</xref> Coupling spread <inline-formula><mml:math id="inf114"><mml:mrow><mml:mi>d</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> set to <inline-formula><mml:math id="inf115"><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.Â </p><p><xref ref-type="fig" rid="fig4">Figure 4F</xref> Fewer networks <inline-formula><mml:math id="inf116"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> of size <inline-formula><mml:math id="inf117"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>Ã—</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>76</mml:mn><mml:mo>Ã—</mml:mo><mml:mn>76</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. <inline-formula><mml:math id="inf118"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>2.4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf119"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf120"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf122"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>Î±</mml:mi><mml:mo>=</mml:mo><mml:mn>1.8</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf124"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mtext>fall</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>. Main simulation run forÂ 300000 timesteps.Â </p><p><xref ref-type="fig" rid="fig4">Figure 4G</xref> Independent Gaussian noise with mean 0 and standard deviation 0.3 added to neural inputs; that is, this noise term is introduced inside the braces of <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> in MaterialsÂ andÂ methods. <inline-formula><mml:math id="inf125"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1.8</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf127"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula>. Main simulation run forÂ 300000 timesteps.</p><p><xref ref-type="fig" rid="fig4">Figure 4H</xref> The excitatory outputs for neuron <inline-formula><mml:math id="inf128"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in network <inline-formula><mml:math id="inf129"><mml:mi>z</mml:mi></mml:math></inline-formula> are centered at <inline-formula><mml:math id="inf130"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>Â±</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>Â±</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> in network <inline-formula><mml:math id="inf131"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, with signs randomly chosen for each neuron. <inline-formula><mml:math id="inf132"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf133"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1.6</mml:mn></mml:mrow></mml:math></inline-formula>. Main simulation run forÂ 300000 timesteps.Â </p></sec><sec id="s8-1-3"><title>Spiking model in <xref ref-type="fig" rid="fig4">Figure 4I</xref></title><p>We follow <xref ref-type="bibr" rid="bib6">Burak and Fiete (2009)</xref> and simulate stochastic spiking with sub-Poisson statistics. Firing rates (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref> in MaterialsÂ andÂ methods) are replaced by synaptic activations <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that evolve as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>Ï„</mml:mi><mml:mo>â¢</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf135"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> if neuron <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in network <inline-formula><mml:math id="inf137"><mml:mi>z</mml:mi></mml:math></inline-formula> spikes at time <inline-formula><mml:math id="inf138"><mml:mi>t</mml:mi></mml:math></inline-formula> or <inline-formula><mml:math id="inf139"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> if it does not. One can recover a firing rate interpretation in a deterministic limit by choosing <inline-formula><mml:math id="inf140"><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> to be the fixed time between regular spikes. In that case, <inline-formula><mml:math id="inf141"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>Â andÂ <inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, so <inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, which is the firing rate.</p><p>The rate parameter of the spiking process is governed by the total neural input<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">{</mml:mo></mml:mrow><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>âˆ’</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>Î¾</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold">e</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>;</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>u</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo>âˆ’</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold">E</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>â‹…</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">}</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>(c.f. <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> in MaterialsÂ andÂ methods). To generate a sub-Poisson process whose interspike intervals exhibit coefficient of variation <inline-formula><mml:math id="inf144"><mml:mrow><mml:mtext>CV</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:mi>m</mml:mi></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>, for each neuron, we sample <inline-formula><mml:math id="inf145"><mml:mi>m</mml:mi></mml:math></inline-formula> times from a Bernoulli distribution with probability <inline-formula><mml:math id="inf146"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mtext>in</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>â¢</mml:mo><mml:mi mathvariant="normal">Î”</mml:mi><mml:mo>â¢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>. We take every <inline-formula><mml:math id="inf147"><mml:mi>m</mml:mi></mml:math></inline-formula>thÂ 1Â to be a spike and discard all other results. Note that unlike the rate model, <inline-formula><mml:math id="inf148"><mml:mi>s</mml:mi></mml:math></inline-formula> can no longer be treated as a dimensionless variable.</p><p>We use <inline-formula><mml:math id="inf149"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>2.0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf150"><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf151"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf152"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mtext>mag</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf153"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mtext>fall</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>. We use a 10-fold finer simulation timestep <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Î”</mml:mi><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and run each phase of the simulation setup for 10 times more timesteps. We run the main simulation for 2000000 timesteps.</p></sec><sec id="s8-1-4"><title>Two-network model for phase diagrams in <xref ref-type="fig" rid="fig5">Figure 5</xref></title><p>To generate data for the phase diagrams in <xref ref-type="fig" rid="fig5">Figure 5</xref>, we set up our simulations in a similar way, with the following differences. We use only two network depths. We use slightly larger velocity gain <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Î±</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> to produce grids of smaller spatial scale since a greater number of activity peaks allows for better measurement of grid scale. After initializing the system and performing initial time evolution in the same manner as in the standard model, we take the activity patterns of the two networks. There is no main phase with extended rat trajectories and single neuron recordings.</p></sec></sec><sec id="s8-2"><title>Simulation data analysis</title><sec id="s8-2-1"><title>Spatial rate maps and autocorrelation functions</title><p>We discretize the animalâ€™s environment into <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mo>Ã—</mml:mo><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> position bins indexed by <inline-formula><mml:math id="inf157"><mml:mrow><mml:mi mathvariant="bold">ğ‘</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. By tabulating a single neuronâ€™s average firing rate when the animal occupies each position, we produce the spatial rate map <inline-formula><mml:math id="inf158"><mml:mrow><mml:mi>S</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ‘</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We define its normalized spatial autocorrelation function as<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo>âˆ’</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">â€²</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf159"><mml:mrow><mml:mi>N</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ‘</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of pairs of positions separated by <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> can be efficiently calculated via discrete Fourier transforms.</p><p>We can define similar network autocorrelation functions <inline-formula><mml:math id="inf161"><mml:mrow><mml:mi>c</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for the population activity within the neural sheet of each networks indexed <inline-formula><mml:math id="inf162"><mml:mi>z</mml:mi></mml:math></inline-formula>.</p></sec><sec id="s8-2-2"><title>Grid scale, orientation, and gridness</title><p>We use autocorrelation functions to extract the scale, orientation, and gridness of spatial and network grids. We first convert each position <inline-formula><mml:math id="inf163"><mml:mi mathvariant="bold">ğ‘</mml:mi></mml:math></inline-formula> to polar coordinates and calculate the autocorrelation as a function of radial distance <inline-formula><mml:math id="inf164"><mml:mi>R</mml:mi></mml:math></inline-formula> by averaging over polar angle <inline-formula><mml:math id="inf165"><mml:mi mathvariant="normal">Î¦</mml:mi></mml:math></inline-formula>:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mrow><mml:mtext>rad</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:mi mathvariant="normal">Î¦</mml:mi></mml:mrow></mml:munder><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf166"><mml:mrow><mml:mi>N</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of positions corresponding to each discretized <inline-formula><mml:math id="inf167"><mml:mi>R</mml:mi></mml:math></inline-formula>. This function is analogous to the radial distribution function of condensed matter physics. To filter out small fluctuations at the centimeter scale while permitting estimation of the location of extrema at the subcentimeter scale, we use coarse 1Â cm bins for <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mrow><mml:mtext>rad</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, linearly interpolate its value at every 0.1Â cm, and apply a Gaussian filter with respect to <inline-formula><mml:math id="inf169"><mml:mi>R</mml:mi></mml:math></inline-formula> with standard deviation 8Â cm. We define the spatial grid scale <inline-formula><mml:math id="inf170"><mml:mi mathvariant="normal">Î›</mml:mi></mml:math></inline-formula> as the <inline-formula><mml:math id="inf171"><mml:mi>R</mml:mi></mml:math></inline-formula> corresponding to the first maximum of the smoothed <inline-formula><mml:math id="inf172"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>rad</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, not including the maximum at <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>Grid orientation and gridness are computed from the angular structure of <inline-formula><mml:math id="inf174"><mml:mrow><mml:mi>C</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the region around <inline-formula><mml:math id="inf175"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Î›</mml:mi></mml:mrow></mml:math></inline-formula>. This region is an annulus bounded by <inline-formula><mml:math id="inf176"><mml:mi>R</mml:mi></mml:math></inline-formula>â€™s corresponding to the first and second minima of the smoothed <inline-formula><mml:math id="inf177"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>rad</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which we call <inline-formula><mml:math id="inf178"><mml:msubsup><mml:mi>R</mml:mi><mml:mn>1</mml:mn><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf179"><mml:msubsup><mml:mi>R</mml:mi><mml:mn>2</mml:mn><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula>. This annulus is analogous to the first coordination shell of condensed matter physics. We average over <inline-formula><mml:math id="inf180"><mml:mi>R</mml:mi></mml:math></inline-formula> within the annulus to calculate the autocorrelation as a function of <inline-formula><mml:math id="inf181"><mml:mi mathvariant="normal">Î¦</mml:mi></mml:math></inline-formula>:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>pol</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>â¢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mml:mo><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mn>1</mml:mn><mml:mo>*</mml:mo></mml:msubsup><mml:mo>â‰¤</mml:mo><mml:mi>R</mml:mi><mml:mo>â‰¤</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mn>2</mml:mn><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:munder><mml:mrow><mml:mi>C</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf182"><mml:mrow><mml:mi>N</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of positions within the annulus corresponding to each discretized <inline-formula><mml:math id="inf183"><mml:mi mathvariant="normal">Î¦</mml:mi></mml:math></inline-formula>. To assess the degree of sixfold symmetry, we calculate the sixth component of the discrete Fourier transform of <inline-formula><mml:math id="inf184"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>pol</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using 5Â° bins for <inline-formula><mml:math id="inf185"><mml:mi mathvariant="normal">Î¦</mml:mi></mml:math></inline-formula>:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Î¨</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>pol</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>â¢</mml:mo><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>â¢</mml:mo><mml:mi mathvariant="normal">i</mml:mi><mml:mo>â¢</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Orientation angle <inline-formula><mml:math id="inf186"><mml:mi mathvariant="normal">Î˜</mml:mi></mml:math></inline-formula> is defined as the complex argument of <inline-formula><mml:math id="inf187"><mml:msub><mml:mi mathvariant="normal">Î¨</mml:mi><mml:mn>6</mml:mn></mml:msub></mml:math></inline-formula> divided by 6. Gridness is the fraction of <inline-formula><mml:math id="inf188"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>pol</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>â€™s total Fourier power, after removing the zeroth component that describes its constant amplitude, belonging to the sixth component. It is thus<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext>gridness</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Î¨</mml:mi><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:mi mathvariant="normal">Î¦</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mrow><mml:mtext>pol</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>âˆ’</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mtext>pol</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mo>âˆ‘</mml:mo><mml:mrow><mml:mi mathvariant="normal">Î¦</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mrow><mml:mtext>pol</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mtext>pol</mml:mtext></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>72</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> is the number <inline-formula><mml:math id="inf190"><mml:mi mathvariant="normal">Î¦</mml:mi></mml:math></inline-formula> bins. We need the factor ofÂ 2 to account for negative Fourier components which have power equal to that of positive components. By properties of Fourier transforms, <inline-formula><mml:math id="inf191"><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">âˆ‘</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>pol</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is the total Fourier power, and <inline-formula><mml:math id="inf192"><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">âˆ‘</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>pol</mml:mtext></mml:msub><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Î¦</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mtext>pol</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula> is the power of the zeroth component. A similar definition for gridness has been proposed to assign a local grid score to each spike (<xref ref-type="bibr" rid="bib62">Weber and Sprekeler, 2019</xref>). We use this definition instead of others used in the literature (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>) because it has an intuitive meaning as the fraction of angular power contributed by sixfold symmetry to the autocorrelation function.</p><p>Network grid scales <inline-formula><mml:math id="inf193"><mml:mi>Î»</mml:mi></mml:math></inline-formula>, orientations <inline-formula><mml:math id="inf194"><mml:mi>Î¸</mml:mi></mml:math></inline-formula>, and gridness can be similarly extracted via the network activity autocorrelation functions <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>c</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s8-2-3"><title>Module clustering</title><p>Following (<xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>), we categorize grid cells into modules by clustering their grid scales and orientations using a <inline-formula><mml:math id="inf196"><mml:mi>k</mml:mi></mml:math></inline-formula>-means algorithm. The number of clusters <inline-formula><mml:math id="inf197"><mml:mi>k</mml:mi></mml:math></inline-formula> is determined through kernel smoothed densities (KSDs).</p><p>We define linearly rescaled grid scales <inline-formula><mml:math id="inf198"><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> such that the largest and smallest scales for each simulation correspond to 0 and 1. We similarly define linearly rescaled grid orientations <inline-formula><mml:math id="inf199"><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> such that 0Â° and 60Â° correspond to 0 and 1. We divide <inline-formula><mml:math id="inf200"><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula>-<inline-formula><mml:math id="inf201"><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> space into <inline-formula><mml:math id="inf202"><mml:mrow><mml:mn>0.02</mml:mn><mml:mo>Ã—</mml:mo><mml:mn>0.02</mml:mn></mml:mrow></mml:math></inline-formula> bins and define the KSD for each bin as<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:mtext>KSD</mml:mtext><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mo>â¢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:msubsup><mml:mi>Ïƒ</mml:mi><mml:mi mathvariant="normal">Î›</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>â¢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:msubsup><mml:mi>Ïƒ</mml:mi><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf203"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of grid cells, each of which has scale <inline-formula><mml:math id="inf204"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf205"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>. For the periodic variable <inline-formula><mml:math id="inf206"><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula>, we define the distance <inline-formula><mml:math id="inf207"><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>c</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf208"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>â‰¤</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf209"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf210"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>. We take both standard deviations <inline-formula><mml:math id="inf211"><mml:msub><mml:mi>Ïƒ</mml:mi><mml:mi mathvariant="normal">Î›</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf212"><mml:msub><mml:mi>Ïƒ</mml:mi><mml:mi mathvariant="normal">Î˜</mml:mi></mml:msub></mml:math></inline-formula> to be 0.1. We use the number of peaks of this KSD as the initial number of clusters <inline-formula><mml:math id="inf213"><mml:mi>k</mml:mi></mml:math></inline-formula> for <inline-formula><mml:math id="inf214"><mml:mi>k</mml:mi></mml:math></inline-formula>-means clustering in <inline-formula><mml:math id="inf215"><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula>-<inline-formula><mml:math id="inf216"><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> space.</p><p>We perform <inline-formula><mml:math id="inf217"><mml:mi>k</mml:mi></mml:math></inline-formula>-means clustering with random initial points in <inline-formula><mml:math id="inf218"><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula>-<inline-formula><mml:math id="inf219"><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> space 200 times per simulation. For each clustering attempt, we calculate the silhouette, a metric describing degree of separation among clusters (<xref ref-type="bibr" rid="bib49">Rousseeuw, 1987</xref>; <xref ref-type="bibr" rid="bib56">Stensola et al., 2012</xref>). For each grid cell <inline-formula><mml:math id="inf220"><mml:mi>i</mml:mi></mml:math></inline-formula> in cluster <inline-formula><mml:math id="inf221"><mml:mi>b</mml:mi></mml:math></inline-formula>, we calculate its average distance in <inline-formula><mml:math id="inf222"><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula>-<inline-formula><mml:math id="inf223"><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:math></inline-formula> space to all grid cells <inline-formula><mml:math id="inf224"><mml:mi>j</mml:mi></mml:math></inline-formula> in cluster <inline-formula><mml:math id="inf225"><mml:mi>c</mml:mi></mml:math></inline-formula>:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfrac><mml:mo>â¢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î›</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mo>â¢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Î˜</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf226"><mml:msub><mml:mi>N</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math></inline-formula> is the number of scales in cluster <inline-formula><mml:math id="inf227"><mml:mi>c</mml:mi></mml:math></inline-formula>. The silhouette of grid cell <inline-formula><mml:math id="inf228"><mml:mi>i</mml:mi></mml:math></inline-formula> in cluster <inline-formula><mml:math id="inf229"><mml:mi>b</mml:mi></mml:math></inline-formula> compares its average distance to other grid cells within its own cluster against its average distance to its closest cluster:<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mrow><mml:msub><mml:mtext>silhouette</mml:mtext><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>â‰ </mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:munder><mml:mo>â¡</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>b</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:mi>max</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mo>â‰ </mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:munder><mml:mo>â¡</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>â¢</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mi>b</mml:mi></mml:msubsup><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The denominator is a normalization factor that rescales the silhouette betweenÂ â€“1 and 1. More positive values indicate better clustering. Out of the 200 clustering attempts, we select the one with largest average silhouette across all grid cells. Finally, we reject all clusters with three or fewer grid cells from further analysis. The remaining clusters are grid cell modules.</p></sec></sec><sec id="s8-3"><title>Extracting sheared triangular lattices for <xref ref-type="fig" rid="fig7s1">Figure 7â€”figure supplement 1</xref></title><p>From vector graphics coordinates in <xref ref-type="bibr" rid="bib56">Stensola et al. (2012)</xref> and <xref ref-type="bibr" rid="bib36">Krupic et al. (2015)</xref>, we extract locations of the six autocorrelation peaks closest to the origin. These give us three lattice vectors. Distance is in arbitrary units.</p><p>We define the scale of each lattice to be the average length of the three lattice vectors. To obtain the orientation of each lattice, we calculate a circular mean of the angles of the lattice vectors. In contrast to the standard circular mean, this version has periodicity 60Â°:<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>Î¸</mml:mi><mml:mo stretchy="false">Â¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>6</mml:mn></mml:mfrac><mml:mo>â¢</mml:mo><mml:mrow><mml:mi>arctan</mml:mi><mml:mo>â¡</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">âˆ‘</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mi>sin</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>â¢</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">âˆ‘</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mi>cos</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mo>â¢</mml:mo><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf230"><mml:msub><mml:mi>Î¸</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is angle of each lattice vector and the arctangent accounts for the sign of the numerator and denominator of its argument.</p><p>These three lattice vectors <inline-formula><mml:math id="inf231"><mml:msub><mml:mi mathvariant="bold">ğš</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> may not correspond to a perfect sheared grid, which is spanned by two independent lattice vectors. To evenly distribute the error introduced by the third lattice vector, we first choose the sign for each vector such that they are mutually separated by approximately 120Â°. We calculate reciprocal lattice vectors <inline-formula><mml:math id="inf232"><mml:msub><mml:mi mathvariant="bold">ğ›</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">ğ›</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>â¢</mml:mo><mml:mi>Ï€</mml:mi><mml:mo>â¢</mml:mo><mml:msubsup><mml:mi mathvariant="bold">ğš</mml:mi><mml:mi>i</mml:mi><mml:mo>âŸ‚</mml:mo></mml:msubsup></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi mathvariant="bold">ğš</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf233"><mml:msubsup><mml:mi mathvariant="bold">ğš</mml:mi><mml:mi>i</mml:mi><mml:mo>âŸ‚</mml:mo></mml:msubsup></mml:math></inline-formula> is the lattice vector <inline-formula><mml:math id="inf234"><mml:msub><mml:mi mathvariant="bold">ğš</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> rotated by 90Â°. We then calculate the vector sum of these reciprocal lattice vectors, which should be the zero vector for a perfect grid in 2D. We subtract each original reciprocal lattice vector by a third of this sum to produce our corrected reciprocal lattice vectors <inline-formula><mml:math id="inf235"><mml:msubsup><mml:mi mathvariant="bold">ğ›</mml:mi><mml:mi>i</mml:mi><mml:mo>â€²</mml:mo></mml:msubsup></mml:math></inline-formula>. Finally, we produce the lattice patterns <inline-formula><mml:math id="inf236"><mml:mrow><mml:mi>Ï</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for the overlays in <xref ref-type="fig" rid="fig7s1">Figure 7â€”figure supplement 1</xref> by<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:mrow><mml:mrow><mml:mi>Ï</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">âˆ</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mfrac><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">ğ›</mml:mi><mml:mi>i</mml:mi><mml:mo>â€²</mml:mo></mml:msubsup><mml:mo>â‹…</mml:mo><mml:mi mathvariant="bold">ğ«</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec></sec></boxed-text></app><app id="appendix-2"><title>Appendix 2</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.46687.028</object-id><sec id="s9" sec-type="appendix"><title>Varying velocity gain model</title><fig id="app2fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.029</object-id><label>Appendix 2â€”figure 1.</label><caption><title>Simulations with a varying velocity gain Î±(<italic>z</italic>) and constant inhibition distance <italic>l</italic> produce modules that do not exhibit preferred relationships.</title><p>(<bold>A</bold>) Representative simulation. Top rows: activity overlays between adjacent networks with the network at smaller (larger) <italic>z</italic> depicted in magenta (green). Bottom rows: spatial autocorrelations of spatial rate maps. (<bold>B</bold>) Velocity gain profile Î±(<italic>z</italic>). (<bold>Câ€“E</bold>) Data from 10 replicate simulations. (<bold>C</bold>) Left: spatial grid scales Î›(<italic>z</italic>). For each network, there are up to 30 red circles corresponding to three neurons recorded during each simulation. Inset: Î›(<italic>z</italic>)Â multiplied by the velocity gain Î±(<italic>z</italic>). Middle: histogram for Î›(<italic>z</italic>) collected across all networks. Right: spatial grid orientations Î˜ relative to the grid cell in the same simulation with largest scale. (<bold>D</bold>) Distributions of spatial grid scales and orientations for each replicate simulation. Due to hexagonal symmetry, orientation is a periodic variable modulo 60Â°. Different colors indicate separate modules. The ninth panel corresponds to the overlays in <bold>A</bold>. (<bold>E</bold>) Spatial grid scale ratios and orientation differences between adjacent modules. Maximum velocity gain Î±<sub>max</sub>Â =Â 0.40Â s/m, minimum velocity gain Î±<sub>min</sub>Â =Â 0.12Â s/m, and scaling exponent Î±<sub>exp</sub>Â =Â 0. Network size <italic>n</italic>Â Ã—Â <italic>n</italic>Â =Â 174Â Ã—Â 174, coupling spread <italic>d</italic>Â =Â 12, coupling strength <italic>u</italic><sub>mag</sub>Â =Â 0.6, and inhibition distance <italic>l</italic>Â =Â 6. Other parameter values are in <xref ref-type="table" rid="table1">Table 1</xref>. White scale bars, 50 neurons. Black scale bars, 50Â cm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-app2-fig1-v2.tif"/></fig><media id="app2video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-46687-app2-video1.mp4"><object-id pub-id-type="doi">10.7554/eLife.46687.030</object-id><label>Appendix 2â€”video 1.</label><caption><title>Last 100Â s of the simulation displayed in <xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1A</xref>.</title><p>Top left: accumulated rat trajectory (gray curve) with current rat position (blue dot). Top right, bottom left, and bottom right: activity overlays between adjacent networks with the network at smaller (larger) <italic>z</italic> depicted in magenta (green), so white indicates regions of activity in both networks. White scale bar, 50 neurons. Black scale bar, 50Â cm.</p></caption></media><sec id="s9-1"><title>Simulation setup with a velocity gain gradient</title><p>These simulations use constant inhibition distance <inline-formula><mml:math id="inf237"><mml:mi>l</mml:mi></mml:math></inline-formula> and a varying velocity gain <inline-formula><mml:math id="inf238"><mml:mrow><mml:mi>Î±</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1B</xref>). The functional form for <inline-formula><mml:math id="inf239"><mml:mrow><mml:mi>Î±</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is similar to that for <inline-formula><mml:math id="inf240"><mml:mrow><mml:mi>l</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the inhibition gradient model (see MaterialsÂ andÂ methods), except it decreases with <inline-formula><mml:math id="inf241"><mml:mi>z</mml:mi></mml:math></inline-formula> instead of increasing:<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Î±</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>âˆ’</mml:mo><mml:msubsup><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>âˆ’</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>Î±</mml:mi><mml:mrow><mml:mrow><mml:mtext>exp</mml:mtext></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>which ranges from <inline-formula><mml:math id="inf242"><mml:mrow><mml:msub><mml:mi>Î±</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>Î±</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf243"><mml:mrow><mml:msub><mml:mi>Î±</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>Î±</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> with concavity tuned by <inline-formula><mml:math id="inf244"><mml:msub><mml:mi>Î±</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula>. More negative values of <inline-formula><mml:math id="inf245"><mml:msub><mml:mi>Î±</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula> lead to greater concavity; for <inline-formula><mml:math id="inf246"><mml:mrow><mml:msub><mml:mi>Î±</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, we use the limiting expression <inline-formula><mml:math id="inf247"><mml:mrow><mml:mrow><mml:mi>Î±</mml:mi><mml:mo>â¢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>Î±</mml:mi><mml:mtext>max</mml:mtext><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>-</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>â¢</mml:mo><mml:msubsup><mml:mi>Î±</mml:mi><mml:mtext>min</mml:mtext><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Simulation initialization and time evolution proceed similarly to the inhibition gradient model, except we evolveÂ 250000Â timesteps with a real rat trajectory before starting the main simulation phase, instead ofÂ 50000Â timesteps. Simulations with a velocity gain gradient tend to have transient configurations that persist longer before changing to a stable configuration, so a longer initialization period helps the main simulation start in a stable configuration.</p></sec><sec id="s9-2"><title>Results with a velocity gain gradient</title><p>Simulations with a velocity gain gradient and excitatory coupling exhibit modularity, but grid scale and orientation relationships vary greatly among replicate simulations that use different random initial firing rates. Single neuron autocorrelation maps in <xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1A</xref> show that this model can produce a grid system with range of grid scales. Note that the population activity contains grids of the same scale for all networks because the inhibition distance is constant. Spatial scales are smaller at lower <italic>z</italic> because they have higher velocity gain Î± (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1B</xref>) and translate their activity patterns in proportion to rat motion more rapidly (see also <xref ref-type="fig" rid="app2fig2">Appendix 2â€”figure 2</xref>). Plotting the spatial scales and orientations of all replicate simulations does not reveal strong clustering (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1C</xref>), but separate analysis of each replicate simulation allows us to identify mostly well-defined modules (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1D</xref>). However, scale ratios and orientation differences between adjacent modules do not cluster around preferred values (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1E</xref>).</p><fig id="app2fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.031</object-id><label>Appendix 2â€”figure 2.</label><caption><title>Activities of additional replicate simulations with a varying velocity gain contributing to <xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1</xref>.</title><p>Top rows: activity overlays between adjacent networks with the network at smaller (larger) <italic>z</italic> depicted in magenta (green). Bottom rows: autocorrelations of spatial rate maps. White scale bars, 50 neurons. Black scale bars, 50Â cm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-app2-fig2-v2.tif"/></fig><p>To further investigate the dynamics of this model, we follow three pairs of adjacent networks in <xref ref-type="video" rid="app2video1">Appendix 2â€”Video 1</xref> which corresponds to the replicate simulation shown in <xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1A</xref>. The movie depicts the activity overlays of these networks as the simulated rat explores its enclosure. We first consider the overlay between networks 1 and 2. Due to the â€˜rigidityâ€™ provided by excitatory coupling as described in the main text, the population activities of these two networks remain in registry throughout the movie; thus, grid cells from these two networks have the same spatial scale and orientation and belong to the same module. Now consider the overlay between networks 3 and 4. For mostÂ of the movie, their population activities are in registry. However, the gradient in velocity gain prefers the more dorsal network (smaller <italic>z</italic>) to have an activity pattern that translates more rapidly. This effect can disrupt the rigidity imposed by coupling and, at <italic>t</italic>Â â‰ˆÂ 470Â s, one pattern jumps along a lattice vector relative to the other. Such an anomaly implies that at least one of the two networks cannot have an activity pattern that translates proportionally to the entire rat trajectory, a requirement for faithful path-integration. Indeed, the spatial autocorrelation map for <italic>z</italic>Â =Â 3 in <xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1A</xref> shows a lack of grid-like symmetry. This example illustrates how a velocity gain gradient can disrupt grid cells in a way that an inhibition distance gradient does notâ€”the latter does not resist the rigidity of excitatory coupling through different translation speeds of activity patterns.</p><p>Finally, consider the overlay between networks 7 and 8 in <xref ref-type="video" rid="app2video1">Appendix 2â€”Video 1</xref>. Here, the two activity patterns remain rotated relative to each other, with little registry. Coupling causes the activity peaks of network 8 to preferentially excite the corresponding areas of network 7, but since there are few peaks in those areas, the effect of coupling is weak between these two networks. Therefore, the activity patterns can freely glide relative to each other, each translating proportionally with animal motion but with different speeds preferred by different velocity gains. Indeed, single neuron spatial rate maps for <italic>z</italic>Â =Â 7 and 8 show different scales (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1A</xref>), which identifies this lack of registry as a mechanism for producing interfaces between grid modules. However, this mechanism does not enforce how quickly one pattern glides relative to the other and thus does not lead to preferred scale ratios (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1E</xref>). It does require that activity patterns stay rotated relative to each other, which may explain the abundance of large orientation differences &gt;15Â°Â between modules (<xref ref-type="fig" rid="app2fig1">Appendix 2â€”figure 1E</xref>).</p><p>Thus, excitatory coupling with a velocity gain gradient can produce grid modules, but, in contrast to the model with varying inhibition distance, the velocity gain gradient model does not favor certain scale ratios and orientation differences. Coupling between attractor networks with different velocity gains may perform a different role: it can make path-integration more robust against input noise (<xref ref-type="bibr" rid="bib43">Mosheiff and Burak, 2019</xref>).</p></sec></sec></boxed-text></app><app id="appendix-3"><title>Appendix 3</title><boxed-text><object-id pub-id-type="doi">10.7554/eLife.46687.032</object-id><sec id="s10" sec-type="appendix"><title>Quasicrystal approximant grids</title><p>Within certain parameter ranges, the coupled system can give rise to quasicrystal approximant grids. One example simulation with dorsal-to-ventral coupling is shown in <xref ref-type="fig" rid="app3fig1">Appendix 3â€“Figure 1</xref>. From <italic>z</italic>Â =Â 6 to 9, network activity peaks form the vertices of a square-triangle tiling that is a dodecagonal quasicrystal approximant (<xref ref-type="bibr" rid="bib53">Stampfli, 1986</xref>; <xref ref-type="bibr" rid="bib38">Levine and Steinhardt, 1986</xref>). This tiling is labeled <inline-formula><mml:math id="inf248"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mn>3</mml:mn><mml:mn>6</mml:mn></mml:msup><mml:mo>;</mml:mo><mml:mrow><mml:msup><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:msup><mml:mo>â¢</mml:mo><mml:mn>.4.3.4</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> based on the type and order of regular polygons that meet at its vertices (<xref ref-type="bibr" rid="bib24">GrÃ¼nbaum and Shephard, 1977</xref>). The <italic>z</italic>Â =Â 8 and 9Â Fourier power spectra approach 12-fold symmetry, as expected from a dodecahedral quasicrystal approximant. From <italic>z</italic>Â =Â 10Â to 12, the network activity patterns demonstrate twofold dihedral symmetry.</p><fig id="app3fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.46687.033</object-id><label>Appendix 3â€”figure 1.</label><caption><title>Quasicrystal approximant grids in a simulation with dorsal-to-ventral coupling.</title><p>Networks <italic>z</italic>Â =Â 4 to 11 shown out of 12 total. (<bold>A</bold>) Network activities at the end of the simulation. (<bold>B</bold>) Activity overlays between adjacent networks depicted in the top row. In each panel, the network at smaller (larger) <italic>z</italic> is depicted in magenta (green), so white indicates regions of activity in both networks. (<bold>C</bold>) Fourier power spectra for network activities with the origin at the center of each image and the edges cropped. (<bold>D</bold>) Spatial rate map of a single neuron for each <italic>z</italic> superimposed on the animalâ€™s trajectory. (<bold>E</bold>) Spatial autocorrelations of the rate maps depicted in <bold>D</bold>. Network size <italic>n</italic>Â Ã—Â <italic>n</italic>Â = 230Â Ã—Â 230, coupling spread <italic>d</italic>Â =Â 2, coupling strength <italic>u</italic><sub>mag</sub>Â =Â 0.6, maximum inhibition distance Î±<sub>exp</sub>Â =Â 0, and velocity gain Î±Â =Â 0.12Â s/m. Other parameter values are in <xref ref-type="table" rid="table1">Table 1</xref>. White scale bars, 50 neurons. Black scale bars, 50Â cm.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-46687-app3-fig1-v2.tif"/></fig></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.46687.035</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution>Tata Institute of Fundamental Research</institution><country>India</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Gu</surname><given-names>Yi</given-names> </name><role>Reviewer</role><aff><institution>Princeton University</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;A geometric attractor mechanism for self-organization of entorhinal grid modules&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Laura Colgin as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Yi Gu (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This study presents a model for MEC grid module formation emerging from a series of attractor networks (based on the Burak-Fiete model) coupled by excitatory interactions. The coupling causes the length-scales of each network to cluster into discrete bands, reminiscent of experimental modules of increasing scale. The orientation of the networks also cluster, again consistent with experiment. Thus a rather simple addition to the network model architecture brings it into agreement with a large body of experiments.</p><p>Essential revisions:</p><p>1) The authors must provide more links from model predictions to experiments. The reviewers have made some suggestions both to link the model to existing data, and for new predictions, and the authors could of course come up with further such links.</p><p>2) The authors must examine the assumption of precise positional projections between networks. We would prefer to see some test simulations that explore imprecision in this quantity.</p><p>3) The authors should address some of the other key parameters of the simulations, particularly the network size, noise, spiking dynamics, and plasticity. The reviewers would prefer to see simulations for at least some of these, though we understand that others may be a substantial effort and the authors can address those in the Discussion.</p><p><italic>Reviewer #1:</italic> </p><p>This study presents a model for MEC grid module formation emerging from a series of attractor networks (based on the Burak-Fiete model) coupled by excitatory interactions. The coupling causes the length-scales of each network to cluster into discrete bands, reminiscent of experimental modules of increasing scale. The orientation of the networks also cluster, again consistent with experiment. Thus a rather simple addition to the network model architecture brings it into agreement with a large body of experiments. Some aspects of these findings have been seen in models proposed by Treves and co-workers, but the authors point out that there are features such as orientation, that only the current model predicts.</p><p>1) The model makes several predictions, including the modules, their orientation, firing rate variability. These all emerge from this rather parsimonious elaboration to the attractor network model. This is a strong point of this study.</p><p>2) A key requirement for these outcomes is the coupling between networks, which requires a certain precision of connectivity between successive networks. The authors have made predictions for the outcome of lesion experiments, but I would like to ask if there are any more direct projection or connectivity studies that support this proposed circuitry. They mention some studies involving recurrent connectivity among grid cells, but it isn't clear to me that these studies demonstrate the spatial structure that the current model requires.</p><p>3) Another possible and testable manipulation would be to make a small focal lesion rather than a sub-network wide one. It would be interesting to see how this affects the z&lt;lesion networks, and this might provide a more stringent and nuanced prediction for experiments.</p><p>4) In an ideal world one would like to compare predictions for specific manipulations between the current model and others in the field. I would specifically be interested in seeing if there are manipulations which would strongly contrast the properties of the current model and that of Treves and co-workers.</p><p>5) The authors explore a range of simulation parameters, notably coupling strengths and the ratio of inhibition distances. However, they barely touch on spiking dynamics and plasticity in a line in the Discussion. I therefore get a sense that the model has been sensitivity tested only along a very few dimensions. It would be reassuring to see somewhat more exploration of these properties, especially those that relate to more biological realism.</p><p><italic>Reviewer #2:</italic> </p><p>This paper proposed a mechanism for generating discrete grid modules (Stensola et al., 2012) in attractor networks of medial entorhinal cortex (MEC) by combining lateral inhibition within individual &quot;networks&quot; and excitatory interactions between networks. Modulating the balance between the inhibition and excitation led to constant scale ratios and orientation differences between adjacent modules, which were consistent with experimental data. This paper is very well written and this first demonstration of a potential mechanism for generating grid modules in attractor networks of the MEC would be of high interest to neuroscience readers. However, providing additional connections between the proposed theory and experimental observations would make this work more significant.</p><p>1) Numbers of neurons in each module: the current theory was developed based on 12 &quot;attractor networks&quot; the MEC. Each network contained 160Ã—160 neurons and these 307,200 grid cells mostly gave three modules. In reality, an animal could have four or five modules (Stensola et al., 2012), so there might be even a larger number of grid cells per animal based on the theory. Given the fact that grid cell population is only ~20% (or even less, ~5% in Miao C et al., Cell, 2017) of the MEC cells, and the relatively low number of grid cells per module recorded by tetrodes and imaging (Stensola et al., 2012; Gu et al., 2018), this theoretical number of grid cell seems unrealistically large. Although it would be hard to know exactly how many grid cells are in real animals, the question is how the conclusions are sensitive to the size of the network. For a network contains half or even a quarter of neurons used here (less number of neurons per network or less number of networks), are these conclusions (the coupled excitation and lateral inhibition generate constant scale ratio and orientation differences between adjacent modules) still true?</p><p>2) Neurons coupled by excitation: the theory is developed under the assumption that a neuron at a given position of a ventral network excited the neuron at the same position of a dorsal network (Figure 1D, bidirectionally if in Figure 3C). Thinking about the noise of real network connectivity, how tolerant is this theory to the disruption of this position correspondence of the excitatory connection across networks?</p><p>3) Variation of grid field amplitudes: the authors claimed that the excitation from the ventral to dorsal modules could lead to the variation in grid field amplitudes for cells in dorsal modules, as observed experimentally (Ismakov, 2017; Dunn, 2017). However, this statement is rather weak. Based on the theory, for a dorsal grid cell, its fields, which aligned with the fields of a ventral grid cell that excited this dorsal cell, should have higher amplitudes. The amplitude variation of grid fields should have a particular pattern (Figures 2B and 4D). It would be helpful to see more specific explanations for real examples of grid cell activity based on the current theory, i.e. what commensurate or discommensurate lattices could be responsible for generating a given pattern of grid field amplitudes and under what kind of excitation and inhibition.</p><p>4) Discommensurate lattices for real grid modules: the author claimed that discommensurate lattice relationships could produce realistic modules (Figure 5). Similar to (3), this statement would be more convincing if the author could give several examples of adjacent modules recorded from the same animal and explain the discommensurate lattices and the detailed parameters of excitation and inhibitions (strength and spread of excitation, and ratio of inhibition distances between modules) that used to form these modules.</p><p>5) Independent rescaling of grid modules in different environments: previous work showed that grid scales of different modules could change independently when an environment was deformed (Stensola et al., 2012, Figure 7). However, based the current theory, the scale ratio of adjacent modules seemed to be constant, unless the balance between the excitation and inhibition is changed. How could the current theory explain the independent rescaling of different modules? This question could also be in line with the last sentence in the &quot;Discussion&quot; about border cells and environmental deformation. In general, can the author expand this discussion by speculating the mechanism for the change of grid scales (maybe orientations too) in different modules in different (or deformed) environments and how border cells play roles in this process (i.e. how do border cells interfere with the balance of excitation and inhibition)?</p><p><italic>Reviewer #3:</italic> </p><p>This paper is quite well written and comprehensive. It addresses an important question, namely, what are the mechanisms responsible for the modular organization of grid cells? In doing so it arrives at some general principles of network organization in the MEC. Overall, I think it needs no major changes.</p><p>An earlier paper by one of the authors showed that grid cell modules are arranged in a manner that minimizes the number of neurons required to encode location with a given resolution. In this paper, they look at how such a peculiar modular organization emerges in a model attractor network. To construct individual modules the authors used a well-known continuous attractor network by Burak and Fiete. The grid scale is determined by the spatial extent of inhibition in this network. The authors connected a set of 12 such attractor networks with a gradually varying grid scale using excitatory connections across neighboring networks. The observed spatial scale of grid cell receptive fields in each attractor network did not follow the gradual increase that would be the case if they were uncoupled, but clustered into groups, with the scale ratios across groups matching experimental observations.</p><p>This paper addresses an important question and does so using an innovative and simple extension of an existing model. The manuscript is clearly written, potential caveats have been addressed, and the figures are detailed (albeit tiny). The authors arrive at an intuitive explanation for the location of fractures where the grid cell receptive fields transition from one scale to the next. Given the complex dynamics of stellate cells and pyramidal cells in layer II, it is quite surprising that the patterns that emerge from this phenomenological model can be quantitatively compared to the results of experiments. What is particularly interesting is that the model is difficult to break, in that different excitatory connectivities (bi-directional and uni-directional in either direction), all seem to generate the same modularity ratios. It seems like the model hints at general principles at work in the MEC that the authors allude to in the Discussion.</p><p>The authors mention that at the boundaries an attractor network can be part of one module or the other depending on the initial conditions. Here it would be useful to understand whether a grid-like receptive field persists when temporal noise is added to the system.</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.46687.036</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The authors must provide more links from model predictions to experiments. The reviewers have made some suggestions both to link the model to existing data, and for new predictions, and the authors could of course come up with further such links.</p></disp-quote><p>We have added further connections between model predictions and experiments in three ways. In Figure 8â€”figure supplement 1, we provide predictions for additional lesion protocols, as suggested by reviewer 1. In Figure 7â€”figure supplement 2, we provide examples for how module relationships in experimental recordings may arise from lattice relationships predicted by our model, as suggested by reviewer 2. In Figure 6â€”figure supplement 2, we provide an example for how structured field-to-field firing rate variability in an experimental recording may arise from a discommensurate lattice relationship predicted by our model, as suggested by reviewer 2. These additions will strengthen the interpretability and the predictive power of our model.</p><disp-quote content-type="editor-comment"><p>2) The authors must examine the assumption of precise positional projectionsbetween networks. We would prefer to see some test simulations that exploreimprecision in this quantity.</p></disp-quote><p>Figure 4 and Figure 5â€”figure supplement 3 now provide results that demonstrate robustness of our results to variations in directionality, positional spread, and positional noise in the excitatory coupling between networks.</p><disp-quote content-type="editor-comment"><p>3) The authors should address some of the other key parameters of the simulations, particularly the network size, noise, spiking dynamics, and plasticity. The reviewers would prefer to see simulations for at least some of these, though we understand that others may be a substantial effort and the authors can address those in the Discussion.</p></disp-quote><p>Figure 4 and Figure 5â€”figure supplement 3 now provide results for systems with smaller network size, temporal and coupling noise, and spiking dynamics. Implementing plasticity in our model would be a substantial effort, and so, as the Editor suggests, and we address its possible effects in the Discussion.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>1) The model makes several predictions, including the modules, theirorientation, firing rate variability. These all emerge from this ratherparsimonious elaboration to the attractor network model. This is a strongpoint of this study.</p></disp-quote><p>Thank you for this assessment. We were very pleased to find that such a simple extension to the attractor network model seems to account for a number of experimental findings.</p><disp-quote content-type="editor-comment"><p>2) A key requirement for these outcomes is the coupling between networks, which requires a certain precision of connectivity between successive networks.</p><p>The authors have made predictions for the outcome of lesion experiments, but</p><p>I would like to ask if there are any more direct projection or connectivity studies that support this proposed circuitry. They mention somestudies involving recurrent connectivity among grid cells, but it isn't clearto me that these studies demonstrate the spatial structure that the currentmodel requires.</p></disp-quote><p>In the Discussion, we have elaborated upon the connectivity studies reported in the literature that find excitatory connections among superficial layers of the MEC. In short, thus far these studies have found short-range connections and very long-range connections across hemispheres. Our model predicts excitatory connections between locations along the MEC corresponding to different modules. An observation of such connections would support our model.</p><disp-quote content-type="editor-comment"><p>3) Another possible and testable manipulation would be to make a small focallesion rather than a sub-network wide one. It would be interesting to see howthis affects the z&lt;lesion networks, and this might provide a more stringentand nuanced prediction for experiments.</p></disp-quote><p>We thank the reviewer for this excellent suggestion. We now provide predictions for such a regional lesion in Figure 8â€”figure supplement 1 and in the Results section â€œTesting for coupling with a mock lesion experimentâ€. The figure supplement also contains predictions for a global lesion that spares one neuron in every 3 x 3 block of the lesioned network.</p><disp-quote content-type="editor-comment"><p>4) In an ideal world one would like to compare predictions for specificmanipulations between the current model and others in the field. I wouldspecifically be interested in seeing if there are manipulations which wouldstrongly contrast the properties of the current model and that of</p><p>Treves and co-workers.</p></disp-quote><p>We agree with the reviewer that our model and that of Treves and co-workers (Urdapilleta et al., 2017) should be distinguishable by experimental tests. In the first place, we are studying an attractor model in which grids form through a collective effect of the interactions in a network. The Urdapilleta et al. paper uses a firing rate adaptation model which generates grids through a fundamentally different mechanism: cells with different time constants produce grids of different scales. Thus, fundamentally, we need experiments testing whether grids are formed by a collective spatial attractor mechanism or through a temporal single-cell firing rate adaption mechanism.</p><p>Urdapilleta et al. extend the firing rate adaptation model for grid cells by adding excitatory coupling among these cells of different scales. This causes clustering in scales and orientations but, unlike our model, does not have a mechanism to dynamically enforce the average constancy of grid scale ratios, which appears to be a feature of the grid system (Barry et al., 2007; Stensola et al., 2012; Krupic et al., 2015). We state this in the Discussion.</p><p>We believe that the two models can be most effectively differentiated by careful measurements of the orientation differences between modules in intact animals. We have now emphasized in the Discussion that our model allows for orientation differences that are significantly different from zero as sometimes seen in, e.g., Krupic et al., 2015. In contrast, Treves and co-workers report orientation differences that are all within one standard deviation away from zero (Table 1 of Urdapilleta, et al., 2017).</p><disp-quote content-type="editor-comment"><p>5) The authors explore a range of simulation parameters, notably couplingstrengths and the ratio of inhibition distances. However, they barely touchon spiking dynamics and plasticity in a line in the Discussion. I thereforeget a sense that the model has been sensitivity tested only along a very fewdimensions. It would be reassuring to see somewhat more exploration of theseproperties, especially those that relate to more biological realism.</p></disp-quote><p>We have now tested robustness of our results to variations in directionality, positional spread, and positional noise in the excitatory coupling between networks We also tested robustness for systems with smaller network size, temporal and coupling noise, and spiking dynamics. These new tests appear in Figure 4 and Figure 5â€”figure supplement 3. Implementing plasticity in our model would be a substantial additional effort and is out of the scope of this manuscript; so we addressed its possible effects in the Discussion.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>1) Numbers of neurons in each module: the current theory was developed based on 12 &quot;attractor networks&quot; the MEC. Each network contained 160Ã—160 neurons and these 307,200 grid cells mostly gave three modules. In reality, an animal could have four or five modules (Stensola et al., 2012), so there might be even a larger number of grid cells per animal based on the theory. Given the fact that grid cell population is only ~20% (or even less, ~5% in Miao C et al., Cell, 2017) of the MEC cells, and the relatively low number of grid cells per module recorded by tetrodes and imaging (Stensola et al., 2012; Gu et al., 2018), this theoretical number of grid cell seems unrealistically large. Although it would be hard to know exactly how many grid cells are in real animals, the question is how the conclusions are sensitive to the size of the network. For a network contains half or even a quarter of neurons used here (less number of neurons per network or less number of networks), are these conclusions (the coupled excitation and lateral inhibition generate constant scale ratio and orientation differences between adjacent modules) still true?</p></disp-quote><p>The reviewer suggests a good opportunity to exhibit the robustness of our model. Our main simulation uses a large number of neurons in each network to clearly illustrate the geometric relationships between attractor bumps. It uses a large number of networks to demonstrate that our model can produce modules with grid scales that jump sharply, even when the incremental changes in inhibition distances are small from one network to the next. We now show results for systems with 11% of the original number of neurons in Figure 4F. It contains approximately 35,000 neurons and forms 3 modules.</p><disp-quote content-type="editor-comment"><p>2) Neurons coupled by excitation: the theory is developed under the assumption that a neuron at a given position of a ventral network excited the neuron at the same position of a dorsal network (Figure 1D, bidirectionally if in Figure 3C). Thinking about the noise of real network connectivity, how tolerant is this theory to the disruption of this position correspondence of the excitatory connection across networks?</p></disp-quote><p>The suggestion of coupling noise is another good opportunity to exhibit the robustness of our model. In Figure 4 and Figure 5â€”figure supplement 3 we show that our model is robust to such positional noise in the excitatory coupling.</p><disp-quote content-type="editor-comment"><p>3) Variation of grid field amplitudes: the authors claimed that the excitation from the ventral to dorsal modules could lead to the variation in grid field amplitudes for cells in dorsal modules, as observed experimentally (Ismakov, 2017; Dunn, 2017). However, this statement is rather weak. Based on the theory, for a dorsal grid cell, its fields, which aligned with the fields of a ventral grid cell that excited this dorsal cell, should have higher amplitudes. The amplitude variation of grid fields should have a particular pattern (Figures 2B and 4D). It would be helpful to see more specific explanations for real examples of grid cell activity based on the current theory, i.e. what commensurate or discommensurate lattices could be responsible for generating a given pattern of grid field amplitudes and under what kind of excitation and inhibition.</p></disp-quote><p>We are grateful to the reviewer for this suggestion to illustrate a sample connection between our model and experimental data. In Figure 6â€”figure supplement 2, we provide an example comparison between a pattern of firing rates in a recorded neuron (Dunn et al., 2017) and a simulated neuron that participates in a discommensurate relationship. We caution that proper testing of our predictions requires a comprehensive analysis with much more data, preferably with grid cells recorded from a circular environment to prevent confounding effects from environmental boundaries.</p><disp-quote content-type="editor-comment"><p>4) Discommensurate lattices for real grid modules: the author claimed that discommensurate lattice relationships could produce realistic modules (Figure 5). Similar to (3), this statement would be more convincing if the author could give several examples of adjacent modules recorded from the same animal and explain the discommensurate lattices and the detailed parameters of excitation and inhibitions (strength and spread of excitation, and ratio of inhibition distances between modules) that used to form these modules.</p></disp-quote><p>We are similarly grateful for this suggestion. In Figure 7â€”figure supplement 2, we provide an example for how a series of experimentally recorded grid cells from different modules can arise from various lattice relationships. Again, we caution that a detailed test requires a comprehensive analysis with more data, preferably with grid cells recorded from a circular environment to prevent confounding effects from environmental boundaries, or with an extension of the theory include effects on grid orientation of anchoring to boundaries (see, e.g., Keinath et al., 2018).</p><disp-quote content-type="editor-comment"><p>5) Independent rescaling of grid modules in different environments: previous work showed that grid scales of different modules could change independently when an environment was deformed (Stensola et al., 2012, Figure 7). However, based the current theory, the scale ratio of adjacent modules seemed to be constant, unless the balance between the excitation and inhibition is changed. How could the current theory explain the independent rescaling of different modules? This question could also be in line with the last sentence in the &quot;Discussion&quot; about border cells and environmental deformation. In general, can the author expand this discussion by speculating the mechanism for the change of grid scales (maybe orientations too) in different modules in different (or deformed) environments and how border cells play roles in this process (i.e. how do border cells interfere with the balance of excitation and inhibition)?</p></disp-quote><p>The interpretation of the experimental rescaling data is complicated, with the original explanation of rescaling contested by data analysis that shows direction-dependent field shifts instead (Keinath et al., 2018). In the latter interpretation, phase relationships with border cells that are learned during familiarization with an environment produce trajectory dependent grid phase shifts when the environment is deformed. According to this interpretation, and the evidence shown in Keinath et al., averaging the data over time produces the appearance of rescaling, but in fact the grids are simply shifting left, right, up or down depending on the last contacted wall in the deformed environment. The appearance of rescaling in the time-averaged fields is simply more prominent in the large grids, and less so in the small ones. Meanwhile, conditioning the data on the last encounter with a boundary leads to grids that do not rescale and maintain their scale ratios. Thus, following Keinath et al. and results from the Giocomo lab, we are not convinced that there is independent rescaling of grid modules. Including the effects of environmental boundaries is beyond the scope of the current work and thus we leave investigation of the effects of boundary deformations to future authors. We have expanded on this in the Discussion.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>[â€¦] The authors mention that at the boundaries an attractor network can be part of one module or the other depending on the initial conditions. Here it would be useful to understand whether a grid-like receptive field persists when temporal noise is added to the system.</p></disp-quote><p>We are grateful for this opportunity to demonstrate the robustness of our model, and Figure 4G and Figure 5â€”figure supplement 3 now include simulations with temporal noise and demonstrate the persistence of precise modules.</p></body></sub-article></article>