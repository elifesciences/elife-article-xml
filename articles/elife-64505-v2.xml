<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">64505</article-id><article-id pub-id-type="doi">10.7554/eLife.64505</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Hippocampal replay of experience at real-world speeds</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-213325"><name><surname>Denovellis</surname><given-names>Eric L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4606-087X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-213822"><name><surname>Gillespie</surname><given-names>Anna K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0980-2408</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-213823"><name><surname>Coulter</surname><given-names>Michael E</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-213824"><name><surname>Sosa</surname><given-names>Marielena</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0762-1128</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-86296"><name><surname>Chung</surname><given-names>Jason E</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-128888"><name><surname>Eden</surname><given-names>Uri T</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-2662"><name><surname>Frank</surname><given-names>Loren M</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1752-5677</contrib-id><email>loren@phy.ucsf.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Howard Hughes Medical Institute, University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Departments of Physiology and Psychiatry, University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Kavli Institute for Fundamental Neuroscience, University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution>Department of Neurobiology, Stanford University School of Medicine</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>Department of Neurological Surgery, University of California, San Francisco</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution>Department of Mathematics and Statistics, Boston University</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing Editor</role><aff><institution>McGill University</institution><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>27</day><month>09</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e64505</elocation-id><history><date date-type="received" iso-8601-date="2020-10-30"><day>30</day><month>10</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-09-08"><day>08</day><month>09</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-10-21"><day>21</day><month>10</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.10.20.347708"/></event></pub-history><permissions><copyright-statement>© 2021, Denovellis et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Denovellis et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-64505-v2.pdf"/><abstract><p>Representations related to past experiences play a critical role in memory and decision-making processes. The rat hippocampus expresses these types of representations during sharp-wave ripple (SWR) events, and previous work identified a minority of SWRs that contain ‘replay’ of spatial trajectories at ∼20x the movement speed of the animal. Efforts to understand replay typically make multiple assumptions about which events to examine and what sorts of representations constitute replay. We therefore lack a clear understanding of both the prevalence and the range of representational dynamics associated with replay. Here, we develop a state space model that uses a combination of movement dynamics of different speeds to capture the spatial content and time evolution of replay during SWRs. Using this model, we find that the large majority of replay events contain spatially coherent, interpretable content. Furthermore, many events progress at real-world, rather than accelerated, movement speeds, consistent with actual experiences.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>hippocampus</kwd><kwd>replay</kwd><kwd>state space</kwd><kwd>dynamics</kwd><kwd>sharp-wave ripple</kwd><kwd>memory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>542971</award-id><principal-award-recipient><name><surname>Eden</surname><given-names>Uri T</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>542981</award-id><principal-award-recipient><name><surname>Denovellis</surname><given-names>Eric L</given-names></name><name><surname>Gillespie</surname><given-names>Anna K</given-names></name><name><surname>Coulter</surname><given-names>Michael E</given-names></name><name><surname>Sosa</surname><given-names>Marielena</given-names></name><name><surname>Chung</surname><given-names>Jason E</given-names></name><name><surname>Frank</surname><given-names>Loren M</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Denovellis</surname><given-names>Eric L</given-names></name><name><surname>Frank</surname><given-names>Loren M</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A new state space decoder revealed that most hippocampal sharp-wave ripples contain coherent spatial content, and that this 'replay' typically progresses at speeds similar to those seen during actual experiences.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The brain has the remarkable ability to store and retrieve representations of past events, enabling memories of the past to influence future behavior. These memory processes depend critically on the hippocampus, where rapid plasticity during an experience is thought to drive the initial encoding of representations of events (<xref ref-type="bibr" rid="bib23">Eichenbaum and Cohen, 2004</xref>). Subsequently, hippocampal 'replay' of stored representations during both slow-wave sleep and periods of immobility during waking is thought to contribute to the longer term storage and updating of event memories in distributed hippocampal-neocortical circuits (<xref ref-type="bibr" rid="bib29">Frankland and Bontempi, 2005</xref>; <xref ref-type="bibr" rid="bib4">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib40">Joo and Frank, 2018</xref>).</p><p>The canonical example of 'replay' is seen in the rodent, where hippocampal cells preferentially fire at specific locations in an environment, and thus ensembles of cells fire in sequence as the animal moves through a series of locations. When the animal is asleep or immobile, hippocampal cells can be reactivated during a 'sharp-wave ripple' (SWR) event. A subset of SWRs contain sequential firing similar to that seen during a previous experience, and thus are thought to 'replay' these previous experiences. Importantly, previous work has reported that these sequential firing events proceed at an average speed of ∼10 meters per second, about 20x faster than the animal’s usual movement speed (<xref ref-type="bibr" rid="bib56">Nádasdy et al., 1999</xref>; <xref ref-type="bibr" rid="bib47">Lee and Wilson, 2002</xref>; <xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>).</p><p>While the existence of these sequential events is well established, the current consensus is that only a minority (∼5–45%) of hippocampal SWRs contain statistically identifiable, sequential replay (<xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib54">Michon et al., 2019</xref>; <xref ref-type="bibr" rid="bib64">Shin et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Kaefer et al., 2020</xref>; <xref ref-type="bibr" rid="bib68">Tingley and Peyrache, 2020b</xref>). One might therefore conclude that all memories that are stored or updated by SWRs correspond to sequences of locations. Our subjective experience, however, suggests that we can retrieve memories of individual locations without having to mentally traverse a long distance. Such memories would seem to be useful, in that they could encode the stimuli and values associated with a given place irrespective of the path used to get there. If the rodent hippocampus is capable of storing those sorts of memories then one might expect to see SWRs where the neural activity corresponds not to a rapid trajectory through space, but instead to either a stable pattern associated with a single location or perhaps a brief pattern more similar to one that occurs during a real experience.</p><p>Interestingly, there is evidence for SWRs where the spiking corresponds to a single location. Specifically, some SWRs contain spiking of neurons associated with single locations where animals are immobile (<xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>), although two reports suggested that events that represent a single location are only seen in young animals (<xref ref-type="bibr" rid="bib24">Farooq and Dragoi, 2019</xref>; <xref ref-type="bibr" rid="bib55">Muessig et al., 2019</xref>). Other studies have reported activity that, when combined across an entire event, seems to correspond roughly to a single location, although the dynamics of these events is typically not investigated (<xref ref-type="bibr" rid="bib22">Dupret et al., 2010</xref>). Thus, while it would seem useful to replay memories associated with single locations or a small region of the environment, the prevalence of that type of replay in awake animals remains unclear.</p><p>Our uncertainty stems in part from the dominant approaches used to identify the content of replay events. These approaches typically involve multiple steps and assumptions about the nature of replay, which are most commonly characterized using the standard 'Bayesian' decoder. First, an encoding model is constructed based on spiking activity during movement, most often using only spikes that have been clustered as single units (putative single neurons). Then, a subset of SWRs or events with high activity levels are selected based on a threshold for event size chosen by the experimenter (<xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib17">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib65">Stella et al., 2019</xref>). A decoding algorithm is then applied to the spikes within these events, yielding a set of position probability distributions for each time bin. Current approaches use either overlapping or non-overlapping time bins whose size is also chosen by the experimenter. Finally, the most commonly used approaches for detecting sequential replay involve fitting a line to the resulting set of probability distributions, which relies on the assumption that the representations progress at a constant speed (<xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib17">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib5">Carr et al., 2012</xref>; <xref ref-type="bibr" rid="bib58">Ólafsdóttir et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Tang et al., 2017</xref>; <xref ref-type="bibr" rid="bib21">Drieu et al., 2018</xref>; <xref ref-type="bibr" rid="bib64">Shin et al., 2019</xref>; <xref ref-type="bibr" rid="bib67">Tingley and Buzsáki, 2020a</xref>; <xref ref-type="bibr" rid="bib1">Bhattarai et al., 2020</xref>). A statistical test is then used to determine whether the line fit to the data is better than a line fit to shuffled versions of the data, where the shuffled version of the data represent an implicit definition of a 'random' sequence.</p><p>While the standard approach identifies constant speed events, it does not consider events that are rejected by the statistical test. This is problematic because it has the potential to mischaracterize real events that do not move at constant speeds, such as those that change direction or are discontinuous (<xref ref-type="bibr" rid="bib50">Liu et al., 2018</xref>). Furthermore, the use of large, fixed-size temporal bins acts as a boxcar smoother that limits the potential movement speeds of the representation. For example, with 20 ms time bins and 3 cm position bins, an event can only move in 1.5 m/s increments (one or more bins in 20 ms) between time steps. The linear fit is also highly dependent on the estimation of event boundaries, such as the start and end times of the SWR, because the fit depends on all the data over the course of the event. Approaches that focus on the order of cell activity within each event (<xref ref-type="bibr" rid="bib47">Lee and Wilson, 2002</xref>; <xref ref-type="bibr" rid="bib31">Gupta et al., 2010</xref>) allow for a relaxation of that linear assumption, but replace it with a loss of statistical power due to either ignoring all but the first spike from each cell or using an arbitrarily smoothed version of the spike train. These approaches also do not provide information about the dynamics of the underlying spatial representation. Moreover, these approaches often exclude events that have stationary representations of a single location (<xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>; <xref ref-type="bibr" rid="bib24">Farooq and Dragoi, 2019</xref>).</p><p>Recognizing the problems with the linear fit, several studies have moved away from the constant velocity assumption, using the most probable location at each time bin (<xref ref-type="bibr" rid="bib60">Pfeiffer and Foster, 2013</xref>; <xref ref-type="bibr" rid="bib76">Wu and Foster, 2014</xref>; <xref ref-type="bibr" rid="bib30">Grosmark and Buzsáki, 2016</xref>; <xref ref-type="bibr" rid="bib3">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Kaefer et al., 2020</xref>). For example, using this approach, <xref ref-type="bibr" rid="bib61">Pfeiffer and Foster, 2015</xref> found awake replay events containing alternation between representations of a single location and sequential spatial trajectories. On the other hand, <xref ref-type="bibr" rid="bib65">Stella et al., 2019</xref> reported that replays during sleep are spatially continuous and follow Brownian diffusion dynamics. However, both methods still used large time bins and neither took into account the uncertainty of the decoded estimates, making it hard to identify the source of the different conclusions.</p><p>An ideal approach to identifying and quantifying the dynamics of replay would circumvent these problems. It would use all the available spiking data to yield the most accurate decoded positions. It would provide a moment-by-moment estimate of position and dynamics that would not be dependent on the estimation of SWR start and end times and could rapidly adjust to changes in dynamics. It would use very small temporal bins (1 or 2 ms) to allow for very rapid representational movement and would provide information about the certainty of the decoded estimates. It would be able to capture a range of movement dynamics including stationary or unchanging representations, trajectories that progress through space at constant or variable speeds, and disorganized, spatially incoherent events. It would provide a robust statistical assessment of confidence for each dynamic. Finally, where assumptions are made, it would provide well-defined parameters whose values could be explored systematically to understand their influence on the results.</p><p>We developed a state space model that achieves all those goals. State space models are a well-understood, well-known statistical solution to the problems described above. By mathematically modeling the relationship between the data and latent dynamics, state space models make the assumptions of the model explicit and interpretable. Our model goes beyond previous approaches (<xref ref-type="bibr" rid="bib13">Deng et al., 2016</xref>; <xref ref-type="bibr" rid="bib52">Maboudi et al., 2018</xref>) by characterizing the spatial representations during SWRs as a mixture of three underlying patterns of movement dynamics: stationary trajectories, continuous trajectories that can progress at many times the typical speed of the animal, and spatially fragmented trajectories. We show how this model can take advantage of clusterless decoding—which relates multiunit spike waveform features to position without spike sorting—giving us more information about the population spiking activity. We apply this model to spiking data during SWR events from 10 rats, enabling a direct comparison to previous work.</p><p>We find that the large majority of SWRs contain spatially coherent content; that is, trajectories that are spatially concentrated at each moment in time and have no large discontinuities in position. Surprisingly, while the expected high-speed, sequential replay events were identified, the most common category of events expressed representations that moved at slower speeds, more consistent with real-world experiences. These findings illustrate the power of state space models and provide a new understanding of the nature of hippocampal replay.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Overview of the model</title><p>We begin with an application of the state space model to simulated data, both to validate the model and to provide intuition (<xref ref-type="fig" rid="fig1">Figure 1</xref>). We simulate 19 Poisson spiking cells with Gaussian place fields on a 180 cm virtual linear track. Each place field has a 36 cm variance and a 15 Hz peak firing rate, and fields are spaced every 10 cm along the virtual track. We then construct a 280 ms spiking sequence (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) and apply our model to the sequence. For the first 60 ms of this sequence, a single place cell fires repeatedly, resulting in the extended representation of a single location. For the second 190 ms of the sequence, the cells fire in sequential spatial order, representing a fast moving trajectory across the virtual linear track. For the last 30 ms of the sequence, the cells fire in an incoherent spatial order. These three firing patterns represent three different types of movement dynamics that could be expressed during SWRs, which we call stationary, continuous, and fragmented, respectively. The goal of our model is to characterize SWRs in terms of a mixture of these three dynamics at every time point.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The model can capture different sequence dynamics on simulated data.</title><p>(<bold>A</bold>) We construct a firing sequence of 19 simulated place cells that exhibits three different movement dynamics. For the first 60 ms, one cell fires repeatedly, representing one stationary location. For next 190 ms, the cells fire in sequence, representing a rapid continuous trajectory along the virtual track. For the last 30 ms, cells fire randomly, out of spatial order, representing an fragmented spatial sequence. (<bold>B</bold>) Like the standard decoder, the state space model uses estimates of cells’ place fields from when the animal is moving and combines them with the observed spikes in (<bold>A</bold>) to compute the likelihood of position for each time step. (<bold>C</bold>) The prediction from the neural data is then combined with an explicit model of each movement dynamic, which determines how latent position can change based on the position in the previous time step. We show the probability of the next position bin for each movement dynamic model (color scale). Zero here represents the previous position. (<bold>D</bold>) The probability of remaining in a particular movement dynamic versus switching to another dynamic is modeled as having a high probability of remaining in a particular dynamic with a small probability of switching to one of the other dynamics at each time step. (<bold>E</bold>) The model uses the components in A-D over all time to decode the joint posterior probability of latent position and dynamic. This can be summarized by marginalizing over latent position (left panel) to get the probability of each dynamic over time. The shaded colors indicate the category of the speed of the trajectory at that time (Stat. = Stationary, S-C-M = Stationary-Continuous-Mixture, Cont. = Continuous, F-C-M = Fragmented-Continuous-Mixture, Frag. = Fragmented), which is determined from the probability. Marginalizing the posterior across dynamics also provides an estimate of latent position over time (right panel). Red dotted line in the right panel is the best fit line from the standard decoder using the Radon transform. (<bold>F</bold>) The probability of each dynamic depends heavily on the speed of the trajectory, as we show using a range of simulated spiking sequences each moving at a constant speed. Each dot corresponds to the average probability of that dynamic for a given constant speed sequence. We use a 0.80 threshold (dotted line) to classify each sequence based on the dynamic or dynamics which contribute maximally to the posterior (shaded colors).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>The model is robust to change of the probability of persisting in the same dynamic for a wide range of plausible expected durations (25–150 ms).</title><p>(<bold>A</bold>) Each panel shows the probability of each dynamic on simulated data example from <xref ref-type="fig" rid="fig1">Figure 1</xref> with a different diagonal value—which governs the probability of remaining in that dynamic. The corresponding expected duration of staying in the dynamic is listed as duration. The off-diagonal values—the probability of switching to one of the other dynamics—are set to be equally likely with the remainder of the probability, as in <xref ref-type="fig" rid="fig1">Figure 1D</xref>. The diagonal increases from left to right, top to bottom, until the case where the diagonal is one and the off-diagonal is zero—that is the case where there is no probability of switching to another dynamic. Shaded regions correspond to the classification as in <xref ref-type="fig" rid="fig1">Figure 1F</xref>. (<bold>B</bold>) The probability of position over time for each diagonal value. Conventions the same as in (<bold>A</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig1-figsupp1-v2.tif"/></fig></fig-group><p>Decoding the spiking sequence requires specifying two elements: the data model—how the spikes relate to position—and the movement dynamic models—how the position can change over time in each movement dynamic. For the data model, our decoder is the same as the standard ('Bayesian') decoder (<xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Pfeiffer and Foster, 2015</xref>; <xref ref-type="bibr" rid="bib65">Stella et al., 2019</xref>). We compute an estimate of how each cell’s firing rate varies over position during movement (i.e. the place field, <xref ref-type="fig" rid="fig1">Figure 1B</xref>). This is used during decoding to compute the Poisson likelihood of position over time given the spiking sequence of interest. In contrast to the standard decoding approaches, we can use small time bins (in our case 2 ms vs. 20 ms or more) because we are able to take advantage of the prior placed on the dynamics by the state space model. This allows us to detect changes on smaller time scales than would be possible with the standard decoder and incorporate information about times when there is no spiking (<xref ref-type="bibr" rid="bib12">Deng et al., 2015</xref>). Further, because place estimates from spikes within a single bin are combined, our small time bins allow us to measure the spatial information conveyed by single spikes, rather than assuming that a downstream neuron would integrate spikes from multiple neurons on the timescale of 20 ms or more.</p><p>Next, we specify movement dynamic models that describe a variety of ways that the latent position—the 'mental' position of the animal represented by the cells— could evolve over time. (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We do this by defining a state transition matrix that defines how the latent position can move from the previous time step (in our case, 2 ms). Previous findings suggest that replay may exhibit at least three distinct types of movement dynamics: stationary (<xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>; <xref ref-type="bibr" rid="bib24">Farooq and Dragoi, 2019</xref>; <xref ref-type="bibr" rid="bib55">Muessig et al., 2019</xref>), continuous (<xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>), and fragmented, which could correspond to both extended spatially incoherent representations and representations that jump from one position to another in a short time period (<xref ref-type="bibr" rid="bib61">Pfeiffer and Foster, 2015</xref>). We therefore define movement dynamic models to capture each of these possibilities.</p><p>In the stationary movement dynamic, the latent position does not change between time steps. The state transition matrix can thus be defined as an identity matrix, which predicts that the next position will be the same as the last position (at the resolution of the position bin). In the continuous movement dynamic, the latent position is most likely to be 'spatially close' to the position in the previous time step, so we use a Gaussian random walk state transition matrix. This means that, for a given latent position, the probability of moving to another position is modeled by a Gaussian centered at that position and 'spatially close' is defined by the variance of the Gaussian. In our case, since replay has been shown to move at speeds much faster than the animal’s speed (<xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib61">Pfeiffer and Foster, 2015</xref>), we set the variance of the Gaussian to 6.0 cm. This ensures that with a 2 ms time step, the latent position is 95% likely to be within 4.90 cm of the previous latent position (or equivalently, this means that latent speeds from 0 to ∼25 m/s are most likely). Last, in the fragmented movement dynamic, the latent position can move to any available position instantaneously. We model this using a uniform state transition matrix, which makes transitions to each position equally likely. Importantly, the fragmented dynamic provides a well-specified definition of what we mean by random, or unstructured activity.</p><p>Finally, we specify how likely each movement dynamic is to persist in time versus change to another dynamic via another state transition matrix between the movement dynamics (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). In order to be conservative with respect to switching between dynamics, we assume that each movement dynamic is likely to dominate for ∼100 ms on average, which is approximately the duration of a SWR event. There is, however, a small probability of switching to one of the other movement dynamics. Accordingly, we set the probability of staying in a dynamic to 0.98 for each 2 ms time step, which corresponds to an expected duration of 100 ms for staying in a particular dynamic (the Markov assumption of the model means that the probability of staying in a dynamic follows a geometric distribution). Importantly, the data drives the estimated dynamic, so even if the probability of staying in a particular movement dynamic is high, data providing clear evidence for a change in dynamic can, within a time frame of ∼10 ms, drive a change to a different estimated dynamic, as in our simulated example. In line with this, we show below that our results are relatively insensitive to the value of this parameter.</p><p>Once we have specified the data and the movement dynamic models, we have fully specified the state space model. We use acausal decoding, meaning that we use all information from both past and future spikes, to estimate the joint posterior probability of position and dynamic (see Materials and methods). With this, we can summarize the resulting posterior probability with two quantities: the probability of each movement dynamic over time (by integrating out position; <xref ref-type="fig" rid="fig1">Figure 1E</xref>, left panel) and the probability of latent position over time, irrespective of movement dynamic (by summing over the movement dynamics; <xref ref-type="fig" rid="fig1">Figure 1E</xref>, right panel).</p><p>An examination of the two summaries shown in <xref ref-type="fig" rid="fig1">Figure 1E</xref> reveals that that the model successfully captures the dynamics of the population spiking activity in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. The stable firing of the one active neuron indicates a stationary representation, and accordingly, the probability of the stationary movement dynamic is high at the beginning of the simulated replay. A change in the data then drives a rapid transition to the continuous movement dynamic, reflecting the trajectory-like spatially sequential spiking from the population of cells. Subsequently, as the population activity becomes spatially incoherent, the fragmented movement dynamic dominates for the last 30 ms of the simulated event.</p><p>This illustrates two key features of the model. First, as mentioned above, the fragmented dynamic gives us a way to directly identify times when the position representation is spatially incoherent, a higher resolution and less assumption-dependent alternative to the more commonly used non-parametric shuffle. Second, this approach allows the model to to capture a wide range of movement speeds for the latent position in contrast to the standard decoder line fit (red dashed line in <xref ref-type="fig" rid="fig1">Figure 1E</xref>, using the Radon transform). The model is defined in terms of a mixture of movement dynamics, as summarized by the probability of each movement dynamic, and which dynamic or dynamics are dominant at a given moment is related to the temporal evolution of the underlying position representation. To demonstrate this, we applied the model to 10,000 simulated trajectories, each trajectory proceeding at a constant speed (<xref ref-type="fig" rid="fig1">Figure 1F</xref>) from 1 cm/s to 10,000 cm/s. From this, we can see that not only are there regions of speed that correspond to each of our three movement dynamics being highly probable (where we define highly probable to be greater than or equal to 0.80 probability), but there are also intermediate speeds where two of the dynamics exhibit relatively high probability; and where the sum of two of the dynamics’ probabilities exceeds 0.80. In this manuscript, we will refer to these intermediate speeds as mixture dynamics. For example, when the stationary dynamic has a probability of 0.6 and the continuous has a probability of 0.4, we call this a stationary-continuous mixture (light blue, <xref ref-type="fig" rid="fig1">Figure 1F</xref>) and this indicates that the trajectory is moving slowly. Correspondingly, if the continuous dynamic has a probability of 0.5 and the fragmented dynamic has a probability of 0.4, then we would call this a fragmented-continuous-mixture and this indicates the trajectory is moving very quickly, but not as quickly as the fragmented dynamic dictates. In summary, we can characterize the speed or set of speeds that occur within an SWR based on the probability of each of the three movement dynamics over time. We further classify the probability of each movement dynamic as being part of one of five speed categories: stationary, stationary-continuous-mixtures, continuous, fragmented-continuous mixtures, and fragmented.</p><p>We note here that the choice of any particular threshold for classifying the movement dynamic of a SWR is arbitrary, and that the power of our approach lies in part on the ability to assign a probability for each dynamic or combinations of dynamics to each moment in time. Our goal in choosing 0.80 was to use a threshold that corresponds to highly probable events that roughly partition the latent position trajectory into interpretable categories of speed. Nonetheless, we also verify that our central results hold with a higher threshold of 0.95. We do not know if downstream neurons can explicitly responds to these dynamics based on either threshold, and there is probably no hard boundary between these dynamics, but our approach makes it possible to ask that question in a systematic way.</p><p>Finally, as mentioned above, we wanted to test the robustness of the model to the choice of probability of staying in a dynamic, because our choice of 0.98 or an expected duration of 100 ms is only based on the expected duration of an SWR. To investigate this we decoded the spiking sequence in <xref ref-type="fig" rid="fig1">Figure 1A</xref> with different probabilities of staying in the same dynamic versus switching to another dynamic (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). We found that for a large range of plausible probabilities of staying in one of the dynamics (between 0.96 and 0.993, corresponding to an expected duration between 25 and 150 ms), the model identified the movement dynamics consistently, with high probability (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>), demonstrating that data itself is the most influential element in the model. Furthermore, the most probable latent positions remained relatively consistent across the range of these probabilities as well (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>).</p></sec><sec id="s2-2"><title>Identification of continuous dynamics in a SWR with sorted or clusterless spikes</title><p>We next sought to validate the model on real hippocampal data recorded from awake, behaving rats. To ensure that we could capture rapid trajectories many times the speed of the animal—as described by most studies of hippocampal replay—we first decoded a single SWR with sequential population activity (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, top panel). Here the rat was performing a spatial alternation task on a W-shaped track (see Materials and methods for details). As expected, we observed that the probability of the continuous dynamic is high throughout this event, but the probability of the stationary dynamic was also noticeable at the beginning and end of the SWR (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, middle panel). Using our speed classification scheme, this indicates that the speed of the replay is initially slower— a mixture of continuous and stationary dynamics—and then speeds up and slows down again. This is also evident in the posterior probability of latent linear position over time, which shows that the replay most likely travels down the center arm and up the right arm (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, bottom panel). We can also see this when we project the maximum of the posterior of this trajectory (the most probable 'mental' position) to 2D to better see the spatial trajectory on the maze (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Importantly, when we apply the same model using the 2D position of the animal we get a similar result (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The model can decode hippocampal replay trajectories using either sorted and clusterless spikes from the same SWR event.</title><p>(<bold>A</bold>) Decoding using sorted spikes. The top panel shows 31 cells on a W-track ordered according to linearized position by their place field peaks. The middle panel shows the probability of each dynamic over time as in <xref ref-type="fig" rid="fig1">Figure 1E</xref>, left panel. Shaded regions correspond to the speed classifications as in <xref ref-type="fig" rid="fig1">Figure 1F</xref>. The bottom panel shows the estimated probability of latent position over the course of the SWR as it travels down the center arm toward the right arm. L, R, C correspond to the position of the left, right and center reward wells, respectively. The animal’s actual position is indicated by the the magenta dashed line. Underneath is the maximum of the 1D decoded position (the most probable position) projected back onto the 2D track for the sorted decoding. Color indicates time. The animal’s actual position is denoted by the pink dot. Light gray lines show the animal’s 2D position over the entire recording session. (<bold>B</bold>) Decoding using clusterless spikes. The top panel shows multiunit spiking activity from each tetrode. Other panels have the same convention as (<bold>A</bold>). Underneath is the maximum of the 1D decoded position (the most probable position) projected back into 2D using the clusterless decoding.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Decoding the same SWR in <xref ref-type="fig" rid="fig2">Figure 2</xref> with 2D position using sorted spikes and clusterless decoding.</title><p>(<bold>A</bold>) The left panel shows the spikes from cells arranged by the linear position of the peak of place field as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. The middle panel shows the probability of each dynamic over time from the 2D decode. Shaded regions indicate classification category as in <xref ref-type="fig" rid="fig1">Figure 1F</xref> and <xref ref-type="fig" rid="fig2">Figure 2</xref>. The rightmost panel shows the most probable estimate of the latent position (MAP estimate) with color indicating time. The latent position posterior summed over time is shown in the purple shading. The light gray lines represent the position of the animal over the entire recording session and the magenta dot represents the animal’s position. (<bold>B</bold>) Same as in (<bold>A</bold>), but with clusterless decoding.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>More examples of SWRs that have continuous trajectories.</title><p>(<bold>A-F</bold>) More examples of SWRs that have continuous trajectories. Left panel uses the same conventions as <xref ref-type="fig" rid="fig2">Figure 2A</xref> and <xref ref-type="fig" rid="fig2">Figure 2B</xref>. Right panel shows the 1D MAP estimate projected back to 2D as in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. Color indicates time. Light gray lines indicate the animal’s position over the entire recording session. Magenta dashed line represents the animal’s position during the SWR.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Population firing rate on the track is spatially uniform and consistent for each animal.</title><p>Multiunit rate of encoding spikes over track positions for each animal. Each gray line represents a recording session for that animal.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig2-figsupp3-v2.tif"/></fig><media id="fig2video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-64505-fig2-video1.mp4"><label>Figure 2—video 1.</label><caption><title>Example of an SWR with continuous content.</title><p>Magenta dot represents the animal’s position. Green dot represents the most likely decoded position projected from 1D back to the linearized 2D position. Green line represents the decoded positions in the last 10 ms. Gray lines represent the position of the animal over the course of the recording session.</p></caption></media></fig-group><p>One of our criteria for a more optimal method is for it to use all of the available spiking data. Using only clustered spikes discards any spike events that cannot be uniquely assigned to a putative single neuron, substantially reducing the amount of information that the resultant decoding can use. Additionally, spike sorting is not necessary to recover the underlying neural population dynamics (<xref ref-type="bibr" rid="bib69">Trautmann et al., 2019</xref>) and often requires inclusion decisions that can vary widely across experimenters. We therefore adopted a 'clusterless' approach which directly uses multiunit spikes and their spike waveform features to decode position without spike sorting (see Materials and methods). Clusterless decoding has previously been used to successfully identify theta sequences and replay sequences in the hippocampus (<xref ref-type="bibr" rid="bib8">Chen et al., 2012b</xref>; <xref ref-type="bibr" rid="bib45">Kloosterman et al., 2014</xref>; <xref ref-type="bibr" rid="bib13">Deng et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Kay et al., 2020</xref>). Applying a clusterless decoder to the same SWR event, we get similar classification of the sequence (<xref ref-type="fig" rid="fig2">Figure 2B,D</xref>), both with 1D linearized position and 2D position (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>). As predicted, the spatial extent of the event is longer and the estimate of the posterior probability of latent position is narrower for the clusterless model. This reflects the clusterless model’s access to a larger pool of data that provides more information about the extent of the event and more certainty in the latent position and the dynamic (<xref ref-type="fig" rid="fig2">Figure 2D</xref> vs C).</p></sec><sec id="s2-3"><title>Most replays contain coherent spatial content</title><p>After testing our model on a single SWR event, we applied our clusterless decoding algorithm to hippocampal recordings from 10 rats performing the W-track spatial alternation task (# tetrodes range: [10, 24], brain areas = [CA1, CA2, CA3]; some data previously used in <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib5">Carr et al., 2012</xref>; <xref ref-type="bibr" rid="bib44">Kay et al., 2020</xref>; position linearized to 1D). We first confirmed that our cell population for each animal could closely track the position of the animal during behavior by comparing the most probable decoded position to the position of the animal. We found that the average median difference between actual and decoded location is small (7 cm median difference, 5–9 cm 95% CI, for all times where the animal was moving greater than 4 cm/s, five-fold cross validation). This level of accuracy is comparable to that of other studies (<xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib64">Shin et al., 2019</xref>; <xref ref-type="bibr" rid="bib24">Farooq and Dragoi, 2019</xref>), and reflects in part the presence of 'theta sequences' (<xref ref-type="bibr" rid="bib19">Dragoi and Buzsáki, 2006</xref>; <xref ref-type="bibr" rid="bib26">Foster and Wilson, 2007</xref>) where position deviates behind and ahead of the animal across individual theta cycles. Importantly, we achieved this using small time bins (2 ms) compared to the commonly used 250 ms time bin that most studies use for decoding during movement, demonstrating the power of our algorithm. For each animal, we also verified that the population spiking rate was relatively consistent over all positions on the track, suggesting that we have comparable sampling of all locations in the environment (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>).</p><p>Having established the validity of our decoder in tracking the animal’s position, we next assessed the prevalence of spatial content across SWRs. We detected SWRs using a permissive threshold (see Materials and methods) to ensure that we include both the rare large-amplitude events as well as the much more common small-amplitude events. As expected, and providing further support for the validity of the model, we observed replays that are classified as continuous throughout the entirety of the SWR, similar to those seen using standard approaches (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A–F</xref>). However, we also observed many events with spatially coherent content that do not have this structure. For example, there are trajectories that start in one direction and reverse back to the original position (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>), representations that remain fixed in one position (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1G</xref>), and trajectories that jump between arms and between dynamics (<xref ref-type="fig" rid="fig3">Figure 3C,D,F</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1F,H,I</xref>). We also observed SWRs where the content is spatially incoherent throughout (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A,D</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Most SWRs are spatially coherent, but not continuous.</title><p>(<bold>A-F</bold>) Examples of SWRs with non-constant speed trajectories. Figure conventions are the same as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. Filtered SWR ripple (150–250 Hz) trace from the tetrode with the maximum amplitude displayed above each example. (<bold>A</bold>) An SWR where the decoded position starts moving down the center arm away from the animal’s position at the center well, slows down, and returns back. (<bold>B</bold>) An SWR where the decoded position persistently stays at the choice point (open circle) while the animal remains at the left well. (<bold>C</bold>) An SWR where the decoded position begins with stationary representation of the left well, then jumps to the middle of the right arm and proceeds up the right arm to the right well. (<bold>D</bold>) An SWR where the decoded position begins with stationary representation of the left well, jumps to the center arm, proceeds away from the center well, jumps to the right arm, proceeds back toward the center well, and then becomes fragmented. (<bold>E</bold>) An SWR where the decoded position begins in the left arm and persists at the end of the center arm. (<bold>F</bold>) An SWR where the decoded position starts in the left arm toward the choice point, jumps to the right arm and proceeds back toward the choice point. (<bold>G</bold>) Classification of SWRs from multiple animals and datasets. Each dot represents the percentage of SWRs for each day for that animal. An SWR is included in the numerator of the percentage if at any time it includes the classifications listed below the column. The denominator is listed in the x-axis label.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Table of replay statistics for each SWR for <xref ref-type="fig" rid="fig3">Figure 3G</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-64505-fig3-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>More examples of SWRs with non-constant speed trajectories.</title><p>(<bold>A-I</bold>) More examples of SWRs with non-constant speed trajectories. Conventions are the same as in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Shuffling the position data with replacement decreases the percent of SWRs classified.</title><p>Comparison of percentage of SWRs classified (that is, an SWR containing at least one of the five classifications) on real vs. position shuffled data for two recording sessions from different animals. Red line represents the percent of SWR events classified in that recording session for real data. The histogram represents the distribution after 50 shuffles of the position data. Position data was shuffled by resampling with replacement from the set of all observed positions in that recording session, destroying position information but preserving spiking timing and position occupancy.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Shuffling the data by swapping the runs and circularly permuting the position increases the percentage of spatially incoherent SWRs and decreases the spatially coherent SWRs.</title><p>The red line represents the percent of spatially coherent or incoherent SWRs in that recording session for actual data. The histogram represents the distribution after 50 shuffles of the run from well to well as well as the circularly shuffled position (for each tetrode). This preserves local spatial correlations in the data but breaks the global spatial relationships between the spikes and the data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig3-figsupp3-v2.tif"/></fig><media id="fig3video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-64505-fig3-video1.mp4"><label>Figure 3—video 1.</label><caption><title>Example of an SWR with that is not purely continuous.</title><p>Conventions the same as <xref ref-type="video" rid="fig2video1">Figure 2—video1</xref>.</p></caption></media></fig-group><p>Using a 0.80 threshold, 89% (23,071 of 25,844) of SWRs contain at least one of the three dynamics or dynamic mixtures. To ensure that this reflects the spatially tuned firing of the neurons, we trained the encoding model with positions resampled with replacement, a shuffling procedure which disrupts the relationship between spiking and position, for two recording sessions. We then decoded the same SWR events, containing the original spikes. Only 9% of the SWRs are classified in the shuffled datasets, a value that is significantly less than that seen for the real data (p=0.02 for recording session 1, p=0.02 for recording session 2, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). This shows that our model does not impose movement dynamics in the absence of spatial information in the data.</p><p>Previous work focusing on spatially sequential replay reported that only a minority of events contain sequential spatial content (<xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>). We therefore asked what fraction of classified events contain spatially coherent content, which we define as any times with stationary, stationary-continuous mixture, or continuous dynamics (see Materials and methods and <xref ref-type="fig" rid="fig1">Figure 1F</xref>). We find that 96% (22,170 of 23,071) of classified SWRs and 86% (22,170 of 25,844) of all SWRs include spatially coherent structure, and that this prevalence of spatially coherent structure is consistent across animals (<xref ref-type="fig" rid="fig3">Figure 3G</xref>). We then asked what fraction of events contained spatially incoherent content, defined as an SWR containing any times with fragmented or fragmented-continuous mixture dynamics. We find that only 14% (3295 of 23,071) of classified SWRs include any times with spatially incoherent structure (<xref ref-type="fig" rid="fig3">Figure 3G</xref>). To further validate this result, we performed a shuffling procedure that, in contrast to our previous shuffle, preserves the local correlations between spikes but reduces global spatial structure. This controls for dynamics that may have been induced by bursts or other local features of the spike train while randomizing the position to spike relationship. To do this, we randomized the order of runs (from one reward well to another) and then circularly permuted the resulting segments of data across all tetrodes uniformly. Using this shuffle, we found that there was still less spatially coherent and more spatially incoherent content compared to the real data (recording session #1, spatially coherent: 99% vs. 71%, p=0.02, real vs. shuffled; spatially incoherent: 22% vs. 61%, p=0.02, real vs. shuffled; recording session #2, spatially coherent: 95% vs. 63%, p=0.02, real vs. shuffled; spatially incoherent: 16% vs. 79%, p=0.02, real vs. shuffled; <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p><p>To more directly compare our findings to previous work, we quantified the percentage of classified SWRs that contained continuous content, as would typically be analyzed when using the standard decoder. Here, our findings were consistent with previous reports: in our datasets, 4449 of 23,071 or 19% of classified SWRs included time periods where the decoded position was classified as continuous (<xref ref-type="fig" rid="fig3">Figure 3G</xref>, 17% of all SWRs). Thus, focusing on only high-speed, linear-fit trajectories excludes a large fraction of events where there is evidence for spatially coherent, but not continuously changing, content. We emphasize here that we did not limit our analysis to only those SWRs that had continuous dynamics for the entire SWR, as is assumed by line-fitting approach of the standard decoder. The consideration of this broader class of SWRs allows us to take advantage of the ability of our decoder to capture a range different speeds within each SWR event.</p><p>We repeated our classification analysis with a higher classification threshold of 0.95 to ensure that our result was not dependent on the threshold of 0.80. We find that, while this change slightly reduced the total fraction of classified SWRs (19,478 of 26,159 or 74% of all SWRs), an even higher fraction of the classified SWRs (19,317 of 19,478 or 99% classified SWRs) included spatially coherent content. Similarly, SWRs containing spatially incoherent content comprised a small fraction of the classified SWRs (490 of 19,478 or 3% classified SWRs).</p><p>Because our model is specified in the context of a latent position associated with different movement dynamics, it allows us to not only classify events in terms of their dynamics, but also to quantify the model’s certainty in each position estimate at each moment in time given the model parameters. To do so, we can compute the cumulative spatial size of the 95% highest posterior density (HPD) region of the latent position estimate. The 95% HPD region corresponds to the set of most probable latent positions as estimated by the model. Larger values of the HPD region size indicate the model is less certain about position, because the most probable decoded positions are distributed over more of the track at a given time point. In contrast, smaller values of the HPD region size indicate that the model is more certain about the estimate of position because the extent of the HPD is more concentrated and covers less of the track. Thus, the HPD region size provides a complementary measure of spatial information, and evaluating it allows us to verify that the events we defined as spatially coherent also correspond to events where there is high certainty around the position estimates.</p><p>We find that spatially coherent events indeed have smaller HPD regions than events with fragmented dynamics. <xref ref-type="fig" rid="fig4">Figure 4A</xref> and <xref ref-type="fig" rid="fig4">Figure 4B</xref> show two example SWRs that are classified as having continuous and stationary dynamics, respectively. The most probable positions (as estimated by the model) at each time step in these SWRs is concentrated in a small portion of the track and correspondingly, the HPD region is small throughout the SWRs. In contrast, <xref ref-type="fig" rid="fig4">Figure 4C</xref> shows a SWR where the dynamics are fragmented and correspondingly, the most probable positions are more spatially diffuse and the HPD region is much larger. The HPD region size also provides insights into the moment-by-moment structure of each event, which can change over the time course of a SWR. An example of this change is shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref>, where the HPD region is small for most of the SWR until the end, at which point the uncertainty of position becomes much higher, reflecting a transition from a spatially coherent to a spatially incoherent representation. Overall, when we examine the average HPD region size for each SWR, grouped by dynamic, we find a clear bimodal split between spatially coherent dynamics and spatially incoherent dynamics (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). For the spatially coherent dynamics, the average HPD region for each SWR was much smaller than the spatially incoherent dynamics (median 24 cm, spatially coherent vs. median 238 cm, spatially incoherent, p=2.2e-16, one-sided Mann-Whitney-U). The HPD region for the unclassified SWRs was similarly large.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Validation of classification using the 95% Highest Posterior Density.</title><p>(<bold>A–D</bold>) Examples of the 95% Highest Posterior Density. In each column: top panel: Probability of dynamic over time. Shading and labels indicate dynamic categories. Middle panel: Posterior distribution of estimated linear position over time. Magenta dashed line indicates animal’s position. Bottom panel: HPD region size—the integral of the position bins with the top 95% probable values. (<bold>E</bold>) Average 95% HPD region size for each dynamic category. Median 24 cm for spatially coherent vs. median 238 cm for spatially incoherent, p=2.2e-16, one-sided Mann-Whitney-U.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Table of replay statistics for each SWR for <xref ref-type="fig" rid="fig4">Figure 4E</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-64505-fig4-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Shuffling the position with replacement increases the average 95% HPD region size.</title><p>Red line represents the average 95% HPD region size for all ripples. The histogram represents the distribution after 50 shuffles of the position data. Position data was shuffled by resampling with replacement from the set of all observed positions in that recording session, destroying position information but preserving spiking timing and position occupancy.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Shuffling the position data by swapping the runs and circularly permuting the data increases the average 95% HPD region size for spatially coherent and incoherent classified times.</title><p>Data from two recording sessions from different animals. Red line represents the average spatial position spanned by the highest posterior density on real data for all ripples. The histogram represents the distribution after 50 shuffles of the position data. The histogram represents the distribution after 50 shuffles of the run from well to well as well as the circularly shuffled position (for each tetrode). This preserves local correlations between spikes but reduces global spatial structure.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig4-figsupp2-v2.tif"/></fig></fig-group><p>We note here that while the size of the HPD region will be influenced by the dynamic estimated from the data, it remains possible for continuous or stationary dynamics to correspond to a large HPD region (see outliers in <xref ref-type="fig" rid="fig4">Figure 4E</xref>), indicating less spatial certainty for those specific events. In general, if the data does not exhibit strong place specific firing, the HPD region will be large, regardless of dynamic classification. To show this, we used the same shuffle as above, resampling position with replacement for two recording sessions and shuffling the relationship between spiking and spatial information when fitting the encoding model. The shuffled decodes have much larger HPD regions than the real data (recording session #1: 55 cm vs. 229 cm, p=0.02, real vs. shuffled; recording session #2: 72 cm vs. 231 cm, p=0.02, real vs. shuffled, one-sided; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We also compared the HPD regions between the real data and a shuffle that swapped the runs and circularly shuffled position, as above. This also resulted in larger HPD regions than the real data for spatially coherent and incoherent SWRs (recording session #1, spatially coherent: 29 cm vs. 52 cm, p=0.02, real vs. shuffled; spatially incoherent: 181 cm vs. 243 cm, p=0.02, real vs. shuffled; recording session #2, spatially coherent: 26 cm vs. 53 cm, p=0.02, real vs. shuffled; spatially incoherent: 210 cm vs. 263 cm, p=0.02, real vs. shuffled; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>).</p></sec><sec id="s2-4"><title>Many replay events are slow or stationary</title><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Prevalence of classifications.</title><p>(<bold>A</bold>) UpSet plot (<xref ref-type="bibr" rid="bib48">Lex et al., 2014</xref>)—which is similar to a Venn diagram with more than three sets—of the most common sets of classifications within each SWR. Each row represents a classification and each column represents a set of classifications, where filled-in black dots with an edge between the dots indicates that multiple classifications are present in the SWR (at different times). The sets are ordered by how often they occur as indicated by the bar plot above each category. The total percentage of each classification is indicated by the rotated bar plot on the left. (<bold>B</bold>) Duration of each dynamic category within a SWR. The box shows the interquartile range (25–75%) of the data and the whiskers are 1.5 times the interquartile range. Outlier points outside of this are labeled as diamonds. (<bold>C</bold>) Average distance between the latent position and the animal’s actual position for each classification within the SWR. (<bold>D</bold>) Average speed of the classification within the SWR (excluding classifications with durations less than 20 ms). Note that these speeds are calculated using the most probable position (MAP estimate) which can be noisy when the probability of position is flat or multimodal.(<bold>E</bold>) Kernel density estimate of the position of stationary trajectories on the W-track at least 30 cm away from the animal’s position. The shaded region represents the density estimate while the black ticks represent the observed non-local stationary positions. (<bold>F</bold>) Average tetrode multiunit spike rates for each dynamic category within each SWR (excluding classifications 20 ms). (<bold>G</bold>) Probability density of animal movement speeds, illustrating prevalence of slower speed real-world movement consistent with stationary and stationary-continuous mixture replay events.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Table of replay statistics for each SWR for <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-64505-fig5-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>More examples of stationary-continuous-mixtures.</title><p>Conventions are the same as in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Control analyses for distribution of dynamics.</title><p>Conventions are the same as in <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Further quantification of spiking and ripple properties by dynamic.</title><p>(<bold>A</bold>) Further quantification of the dynamics with respect to the spiking and ripple properties. (<bold>B</bold>) Speed and number of tetrodes with spikes for entire SWR.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig5-figsupp3-v2.tif"/></fig><media id="fig5video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-64505-fig5-video1.mp4"><label>Figure 5—video 1.</label><caption><title>Example of a stationary-continuous-mixture.</title><p>Conventions the same as <xref ref-type="video" rid="fig2video1">Figure 2—video1</xref>.</p></caption></media></fig-group><p>Surprisingly, our results indicate that most events with coherent spatial content are not dominated by the continuous movement dynamic, but instead correspond to trajectories that are stationary or that move relatively slowly compared to their purely continuous counterparts. We therefore examined these events in more detail. We first note that most of the SWRs (14,989 of 21,433 or 70% of classified SWRs) were classified as having only a single dynamic or dynamic mixture (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, for specific example SWR see <xref ref-type="fig" rid="fig3">Figure 3B</xref>), whereas SWRs with multiple dynamics or dynamic mixtures (such as those in <xref ref-type="fig" rid="fig3">Figure 3A,C,D,E and F</xref>) were less common. Interestingly, the most common category of classified SWRs were those with only stationary-continuous mixtures (8944 of 21,433 or 42% of classified SWRs, <xref ref-type="fig" rid="fig5">Figure 5A</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, note that this percentage ignores the unclassified category). These events contain representations that move at slower speeds (<xref ref-type="fig" rid="fig5">Figure 5D</xref>)—similar to those speeds experienced by the animal in the environment (<xref ref-type="fig" rid="fig5">Figure 5G</xref>, median 17 cm/s for run periods and 4 cm/s for all times)—and are sustained, but slightly shorter, on average, than events with continuous dynamics (median duration: stationary-continuous-mixture 73 ms vs. continuous 94 ms, <xref ref-type="fig" rid="fig5">Figure 5B</xref>). Nonetheless, both the slow-moving events and continuous events frequently represent locations that were some distance away from the animal (mean trajectory distance from animal’s position: stationary-continuous-mixture 52 cm vs. continuous 43 cm, <xref ref-type="fig" rid="fig5">Figure 5C</xref>). This indicates that the content of these SWRs, like those that are classified as continuous, do not represent the animal’s actual position. We note that roughly a third of these events persisted for the entire duration of the SWR, but the other two thirds included some time where the model was uncertain about the dynamic. This shows the power of our state space decoder because it allows us identify periods of time when the model has high confidence with each SWR, and use these periods to characterize the SWR overall or to focus on specifically for further analysis.</p><p>The second most prevalent classification was exclusively stationary events (4858 of 21,433 or 23% classified SWRs; 47% of SWRs with stationary dynamics were entirely stationary for the entire duration of the SWR). Unlike the stationary-continuous mixtures, most of these events represented a location close to the animal’s actual position (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). There were, however, a number of stationary events that represented positions far from the animal. We set a threshold of 30 cm distance from the animal to identify non-local stationary events and found such content in ∼7% of classified SWRs (1437 of 21,433 classified SWRs). Of these, 46% (664 of 1437 stationary SWRs) were stationary throughout the duration of the SWR. These non-local stationary events most commonly represented reward wells or choice points (<xref ref-type="fig" rid="fig5">Figure 5E</xref>), consistent with <xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>, but a small portion of them occurred at other locations of the track. This suggests that these representations can be flexibly deployed to represent discrete locations.</p></sec><sec id="s2-5"><title>Control analyses</title><p>We then carried out a series of control analyses to determine whether our results could be due to differences in spiking statistics across dynamics or interneuron-specific activity patterns. We first calculated the multiunit spiking rates and found that these were similar across the different dynamics (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). This indicates that all dynamics, including stationary and stationary-continuous mixtures, were driven by comparable levels of sustained spiking information and could not be explained by the absence of spiking. Further corroborating this, we found that when we re-ran our analysis using periods of high multiunit activity instead of SWRs to identify events, we still found a larger proportion of stationary and stationary-continuous dynamics relative to the continuous dynamics (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3F</xref>).</p><p>We also verified that our classifications were very unlikely to be driven by the firing of interneurons, which are less likely to project to other brain areas and exhibit less spatial specificity than principal neurons in the hippocampus (<xref ref-type="bibr" rid="bib75">Wilent and Nitz, 2007</xref>; <xref ref-type="bibr" rid="bib38">Jinno et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Hangya et al., 2010</xref>). First, we increased our tetrode participation threshold from two up to five tetrodes active during the SWR, to eliminate the possibility that events with a single tetrode with a high rate interneuron might drive the classification of stationary or stationary-continuous mixture dynamics during SWRs. We found that our results were robust to this increase in threshold (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A</xref>). Indeed, most of our events and most periods of dynamics within each event included spikes from upwards of 10 tetrodes (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). Next, we removed spikes that had spike widths of less than 0.3 ms to reduce the potential contribution of narrow-waveform inhibitory interneurons (<xref ref-type="bibr" rid="bib27">Fox and Ranck, 1975</xref>). Similarly, this had little effect: we still observed a high proportion of SWRs with stationary and stationary-continuous mixture dynamics (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2B</xref>). Using clustered data, we can more robustly categorize units as putative interneurons; thus, we then repeated this analysis on clustered data for 9 of the 10 animals, excluding putative interneurons based on spike width and firing rate and requiring that at least three putative pyramidal cells be active during the SWR. Although there were many fewer events to examine, we still observed many stationary and stationary-continuous mixtures in SWRs (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2D</xref>). Finally, if interneurons with less spatial specificity were driving the classification of slower dynamics, we would expect to see the posterior be less spatially concentrated during these events. Instead, we found that stationary and stationary-continuous mixtures tended to have narrow posteriors (as characterized by 95% HPD region size in <xref ref-type="fig" rid="fig4">Figure 4E</xref>). This provides further evidence that our large fraction of slow-speed events were not the solely the result of the firing of interneurons.</p><p>We then asked whether the slow spatially coherent events (stationary-continuous mixtures) potentially reflect a slow theta sweep rather than a replay event. We noted that this seems very unlikely given that the stationary-continuous mixtures tended to represent locations far from the animal that would require rapid, long-distance theta sequences (median 50 cm <xref ref-type="fig" rid="fig5">Figure 5C</xref>). In addition, the majority of our events occur when the animal is moving at speeds less than 2 cm/s, as expected for SWRs (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3B</xref>). Further, when we restrict the analyses to SWRs where the animal was moving at speeds less than 1 cm/s, we find similar proportion of SWRs with stationary and stationary-continuous mixture dynamics (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2C</xref>).</p><p>A third possible concern is that burst firing from a single cell is driving the stationary dynamics. There are several lines of evidence against this. First, as mentioned above, most of our SWRs contained spikes from multiple tetrodes, including those with stationary dynamics (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3A</xref>), so it is unlikely that a single cell could drive these dynamics. Second, the stationary dynamics have a longer duration than one would expect from a burst alone (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, 54 ms median duration, 38–74 ms quartiles vs. bursts which have a typical duration of 6–24 ms; <xref ref-type="bibr" rid="bib62">Ranck Jr, 1973</xref>; <xref ref-type="bibr" rid="bib34">Harris et al., 2001</xref>; <xref ref-type="bibr" rid="bib70">Tropp Sneider et al., 2006</xref>). Third, only ∼50% of the spikes had interspike intervals (ISIs) of less than 6 ms during the stationary, stationary-continuous, and continuous dynamics (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3A</xref>), indicating that rapid bursts made up at most half of the observed spikes, and likely fewer given that these ISIs are computed for each tetrode, rather than for single units.</p><p>Finally, we wished to assess whether the spiking information from different hippocampal subfields (CA1, CA2, and CA3), could influence the types of dynamics we observed. This seemed unlikely, given that CA1 and CA3 spiking is tightly coordinated within and across hemispheres during SWR replay (<xref ref-type="bibr" rid="bib5">Carr et al., 2012</xref>) and multiple previous papers have combined recordings across subfields and obtained results similar to those that restricted their analyses to CA1 (<xref ref-type="bibr" rid="bib17">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>). However, we verified that when we used only CA1 tetrodes to decode (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2E</xref>), we get similar proportions of dynamics as when using all the tetrodes.</p></sec><sec id="s2-6"><title>Comparison to standard approaches</title><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>The standard decoder MAP estimate speeds are the most similar to the state space decoder.</title><p>Event speeds calculated using three common 'Bayesian' decoder approaches (<bold>A–C</bold>) compared to using the state space model (<bold>D</bold>). For each panel, the top five rows show the probability density of the estimated speed for SWRs that contain that dynamic or combination of dynamics. Note that these categories are not mutually exclusive since a SWR can include more than one dynamic or combination of dynamics. The sixth row shows all SWRs containing unclassified dynamics. The final row is the estimated speed for all SWRs. (<bold>A</bold>) Radon transform (<bold>B</bold>) MAP estimate (<bold>C</bold>) Linear regression (<bold>D</bold>) State space decoder presented in this manuscript.</p><p><supplementary-material id="fig6sdata1"><label>Figure 6—source data 1.</label><caption><title>Table of replay statistics for each SWR for <xref ref-type="fig" rid="fig6">Figure 6</xref>.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-64505-fig6-data1-v2.csv"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Examples of fits from the standard 'Bayesian' decoder with 20 ms bins and state space model.</title><p>(<bold>A–F</bold>) For each panel, the top row is a raster plot of the sorted cells, the second row is the decoded posterior probability of position in 20 ms time bins for the sorted spikes and the corresponding Radon line fit (blue line) and the MAP fit (green line) on this posterior probability, the third row is a raster plot of the multiunit spike times used for clusterless decoding, the fourth row is the posterior probability in 20 ms time bins using clusterless data as well as the accompanying Radon fit and MAP fit, the fifth row is the posterior probability from the clusterless state space model, and the sixth row is the probability of each dynamic (lines) and the color shading indicates the category of dynamic as before.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Examples of fits from the standard 'Bayesian' decoder with 2 ms bins and state space model.</title><p>(<bold>A–F</bold>) For each panel, the top row is a raster plot of the sorted cells, the second row is the decoded posterior probability of position in 2 ms time bins for the sorted spikes and the corresponding Radon line fit (blue line) and the MAP fit (green line) on this posterior probability, the third row is a raster plot of the multiunit spike times used for clusterless decoding, the fourth row is the posterior probability in 2 ms time bins using clusterless data as well as the accompanying Radon fit and MAP fit, the fifth row is the posterior probability from the clusterless state space model, and the sixth row is the probability of each dynamic (lines) and the color shading indicates the category of dynamic as before.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-fig6-figsupp2-v2.tif"/></fig></fig-group><p>Finally, we asked how our method compares to the standard approaches to identifying significant replay events that use a non-parametric shuffle test to characterize their content. This comparison is complicated due to the variety of parameters and inference methods used previously, so here we chose three commonly used approaches and a reasonable parameter set for the comparison. We began with an examination of events based on statistical significance of a line fit to a circularly permuted spatial distribution, which has been the standard in the field. We applied the clusterless algorithm in 20 ms bins to produce probability densities of represented locations, as this binning is comparable to previous methods. We then used the Radon transform method, which finds the line with the highest summed posterior probability of position along the line (<xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib24">Farooq and Dragoi, 2019</xref>), to calculate, for each SWR, a measure of significance based on the assumption that the probability density moves at a constant speed throughout the event (see examples in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A–F</xref>, fourth row, blue line). We found that ∼12% of the classified events (as defined by our state-space decoder) were identified as significant by this Radon method. Not surprisingly, the fraction of significant events was strongly related to which dynamic they contained. Of the SWRs that contained a period of continuous dynamics, 31% (1386 of 4511 SWRs) were significant. Of all SWRs that contained a period of stationary dynamics, 8% (542 of 7176 SWRs) were significant, and when we restricted the analysis to long stationary events (&gt;100 ms duration), we found that 28% were significant. This increase is not surprising, since the shuffle used for the Radon method penalizes shorter events. An alternative approach, the linear regression method, which samples from the posterior probability and uses linear regression to fit a line to the samples (<xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib4">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib64">Shin et al., 2019</xref>), detects only non-zero slopes as significant, and thus by definition cannot identify stationary events as significant.</p><p>Conclusions about the representational content of events were similarly variable across methods. In addition to the Radon and linear regression methods, we also computed the MAP estimate, the maximum probability position of each 20 ms time bin (see examples in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A–F</xref>, fourth row, green line, <xref ref-type="bibr" rid="bib61">Pfeiffer and Foster, 2015</xref>; <xref ref-type="bibr" rid="bib65">Stella et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Kaefer et al., 2020</xref>). We then compared the speed of the replay for each dynamic and for the entire SWR (<xref ref-type="fig" rid="fig6">Figure 6</xref>). We found that the methods that rely on fitting a line for the entire SWR (the Radon transform and the linear regression), tend to estimate that the replays proceed at faster speeds (<xref ref-type="fig" rid="fig6">Figure 6A,C</xref>), whereas the MAP method (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), which only relies on picking the most probable position for a given time bin and allows for more variable speeds, meaning it can capture both fast and slow speeds. In addition, the speeds from the MAP method (<xref ref-type="fig" rid="fig6">Figure 6B</xref>) are quite similar to the speeds estimated by the state space decoder (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). This is to be expected because the MAP method imposes less smoothing (although some is added by using 20 ms time bins, see <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2A–F</xref> for the same examples with 2 ms bins), whereas the linear methods impose a larger amount of smoothing and cannot change directions (see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A</xref> for an example where this is beneficial because the trajectory is linear and the smoothing ignores a lack of spiking and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref> for an example where this is not beneficial because the linear fit cannot change direction). Our state space decoder with 2 ms bins imposes much less smoothing than the linear methods and therefore is closer to the MAP estimates with 20 ms bins (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref>), but also takes into account the uncertainty of each time bin (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C</xref>) and is able to change direction more quickly than the 20 ms time bins (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1E</xref>). Using 2 ms bins with the MAP method would allow for faster change in the direction of the latent position but also results in much more variable estimates (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). These results indicate that the methods that made more assumptions about the structure of replay (Radon and linear regression approaches) yield different conclusions about which events are potentially meaningful and how those events progress over time from methods that make fewer assumptions (the MAP and state-space approaches). The substantial variability in both the proportions of 'significant' events and the speed of the events demonstrates that key conclusions about the events could be very different depending on the which of the previous methods and parameter were used.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We developed a state space model that identifies and quantifies replay in terms of a mixture of three movement dynamics: stationary, continuous, and fragmented. This model is robust: it is relatively insensitive to a range of plausible transition parameters between dynamics and instead strongly reflects the hippocampal place representation structure. We show that this model is interpretable: it has well-defined parameters that capture intuitive movement models and allows us to explain a large fraction of SWRs in terms of these dynamics—far more than have been previously associated with identifiable activity patterns. This model is also flexible: it can be used with sorted or clusterless spikes, it can be used with 1D or 2D positions, and—because it uses a mixture of dynamics—it allows us to confidently discover not only SWRs with spatial representations that move at a constant speed, but also representations that vary in speed, have slower speeds, or that are stationary. In fact, these slower moving representations constitute the majority of representations seen during SWRs, but would not be found with the typical approaches that assume that events progress at constant speed. The prevalence of these events indicates that hippocampal replay can recapitulate experience at both accelerated and closer to real-world speeds.</p><p>Previous work reported that less than half of SWRs or high-population-activity events contained replay events (<xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>). This could lead one to the assumption that most events are not spatially coherent or meaningful. Our results indicate that this is not the case: in our dataset, the large majority of SWRs (86%) contained spatially coherent content, as defined by some combination of stationary and continuous dynamics. These events were mostly decoded representations where the most probable positions were highly spatially concentrated (i.e. had small HPD region size), indicating that they were driven by spatially specific firing. This was in contrast to unclassified events or events that included fragmented dynamics, which were associated with highly distributed decoded spatial representations.</p><p>Importantly, the spatially coherent events most often expressed a dynamic that was consistent with slower speeds of less than 1 m/s (100 cm/s), a speed range that includes the speeds at which rats traverse their environment. The next most common category were stationary events (<xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>; <xref ref-type="bibr" rid="bib24">Farooq and Dragoi, 2019</xref>; <xref ref-type="bibr" rid="bib55">Muessig et al., 2019</xref>) that activated a persistent representation of a single location, while the 'classical' replay events—continuous, extended trajectories through space—made up only about 19% of classified events. Events with slower dynamics tended to persist for approximately the same length of time as events with faster continuous dynamics (∼50–100 ms), consistent with a brief activation of a representation of a location or a short trajectory through space. Events with slower dynamics most often represented the animal’s current location, similar to continuous events identified in previous work (<xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>); however, slower events were also capable of representing locations far from the animal. Interestingly, <xref ref-type="bibr" rid="bib51">Louie and Wilson, 2001</xref> found that during REM sleep, the longer time scale population activity (on the order of seconds) is highly correlated with firing during times when the animal is running, resembling the animal’s experience. Our results are similar but were observed during pauses in active behavior and on the timescale of SWRs, which last 10s to 100s of milliseconds.</p><p>These results challenge the long-held notion that hippocampal replay trajectories necessarily proceed at many times the speed of the animal (<xref ref-type="bibr" rid="bib56">Nádasdy et al., 1999</xref>; <xref ref-type="bibr" rid="bib47">Lee and Wilson, 2002</xref>; <xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>). Instead, replay events encompass a much richer variety of event speeds that could promote storage and updating of memories on different spatial and temporal scales, including slower moving representations that activate a spatially compact set of nearby locations and stationary representations of single locations. This is consistent with observations of events that, when decoded in a single time bin, represent a small neighborhood in the environment (<xref ref-type="bibr" rid="bib22">Dupret et al., 2010</xref>). Interestingly, a previous paper (<xref ref-type="bibr" rid="bib24">Farooq and Dragoi, 2019</xref>) reported that these stationary representations were most prevalent in juvenile rats and decreased to 'chance' levels when the rats reached adulthood. Our results strongly suggest that they do not disappear, but are a very common occurrence with adult rats. We believe that the difference in these findings is a result of defining 'chance' levels of occurrence of these events and using a restrictive decoding model which requires the decoded position to be stationary for the entire event. We also note that we chose to include a stationary dynamic to explicitly evaluate the prevalence of stationary events in adult animals, but in principle, a model with just continuous and fragmented dynamics could capture these events as well, as the continuous dynamic includes movement speeds close to 0 m/s.</p><p>The differences between our findings and those reported in some previous papers also highlight the importance of identifying the specific question that an analysis seeks to answer. Initial studies of replay (<xref ref-type="bibr" rid="bib47">Lee and Wilson, 2002</xref>; <xref ref-type="bibr" rid="bib25">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>; <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>) focused on the question of whether the observed patterns of spiking seen during replay reflected structured content or 'random' spiking as defined by a comparison to one or more shuffles. These and subsequent studies answered the question 'are replay events the result of random spiking?' with a clear 'no'. These studies did not, however, establish that the significance criteria used to show non-random structure has anything to do with the presence of spatial structure or events that are potentially useful for memory processes.</p><p>Our method aims to identify structure within events and to capture their complex dynamics to determine what sort of information replay events could provide in service of memory functions. We precisely define patterns of spatial representation that are, and are not, interpretable in terms of the structure of a given environment and the spatial activity seen during movement. In so doing, we find that most, but not all, events contain spiking that corresponds to a location or a trajectory through the animal’s environment.</p><p>The different questions addressed by our method compared to previous methods can also explain the apparent differences in findings. Our results showed that 19% of SWRs contained continuous trajectories—meaning that portions of the SWR had spatially coherent trajectories that moved at high velocities—but only 4% were continuous throughout the entire SWR. This, <italic>prima facie</italic>, may seem at odds with previous results, which found between 5% and 45% of SWRs were 'significant', meaning that they were well fit by a line compared to various shuffled versions of the dataset. Furthermore, these studies found trajectories on average move at much higher speeds (20x normal rat movement speed) than we report here. These previous findings were based largely on a single linear fits to the data for each event, while our model allows the trajectory to change speed during the SWR, which can lead to very different estimates of the speed of the event. Many of the events that had continuous dynamics, and would be classified as having high speed trajectories, also exhibited stationary-continuous mixture dynamics for some portion of the event(see for example <xref ref-type="fig" rid="fig2">Figure 2</xref>). Further, because the linear fit includes the whole SWR event, it is highly sensitive to the definition of the start and end of the SWR event, an often arbitrary definition which varies across research groups. In contrast, our model makes an estimate for each time point and only depends on the previous and future time step, which minimizes the dependence of the event on those boundaries and any possible 'noise' activity within the SWR. This, along with our more permissive threshold for SWRs, allows us to characterize more SWRs than previous studies, rather than exclude them from analysis.</p><p>Our results may also explain the seeming conflict between (<xref ref-type="bibr" rid="bib65">Stella et al., 2019</xref>), who reported that hippocampal replay trajectories followed Brownian-like diffusion dynamics, and (<xref ref-type="bibr" rid="bib61">Pfeiffer and Foster, 2015</xref>), who reported that a subset of replay trajectories contained systematic jumps in position. We found that while replay speeds are, on average, distributed log normally, a small subset of the replays include definitive 'jumps' from one position to another. Because our model makes it possible to identify different dynamics within the same SWR, we are able to identify both types of sequences.</p><p>We hypothesize that this large set of events supports the ability to store and update representations of individual places and snippets of experience. Previous findings demonstrated that SWRs with movement- or immobility-related activity engage specific patterns of spiking activity outside the hippocampus (<xref ref-type="bibr" rid="bib37">Jadhav et al., 2016</xref>; <xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>). Thus, we would expect that the large set of events with slow dynamics would also engage specific patterns of activity outside the hippocampus, perhaps allowing animals to store or update the value of specific locations or short movement trajectories without having to generate full trajectories representing one of multiple ways to arrive at a location (<xref ref-type="bibr" rid="bib79">Yu and Frank, 2015</xref>). Events that contain multiple dynamics (e.g. two continuous representations separated by a brief fragmented representation) might also help bind together experiences that occur in the same environment but at different places, whereas sustained spatially incoherent representations might represent coherent representations in other spatial environments (<xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>) or non-spatial experiences. Alternatively, downstream structures may be are attuned to the shifts in dynamics, and that each period of coherent hippocampal dynamics drives its own set of responses elsewhere in the brain. We further note that recent results from a study of activity patterns during movement indicates that individual theta cycles can have different dynamics as well (<xref ref-type="bibr" rid="bib73">Wang et al., 2020</xref>), suggesting that the underlying sequences seen during replay and theta may overlap in their dynamics as well as their content.</p><p>Similarly, it is possible that slow and fast dynamics are supported by different subcircuits within the hippocampal formation. <xref ref-type="bibr" rid="bib77">Yamamoto and Tonegawa, 2017</xref> found that blocking medial entorhinal cortex (MEC) output to CA1 resulted in shorter (and therefore slower) replay trajectories and (<xref ref-type="bibr" rid="bib59">Oliva et al., 2018</xref>) showed that layer 2/3 MEC neurons increased their firing 50 ms before the start of longer duration SWRs (&gt;100 ms). This raises the possibility that these slower replays are driven by CA3-CA1 interaction while the faster trajectories are more externally driven by MEC-CA1, and that these different events could also engage different circuits outside of the hippocampus and entorhinal cortex.</p><p>One key aspect to understanding how the hippocampus engages with other brain structures is identifying the times when the neural dynamics have changed. The times of SWRs or increases in multiunit activity has provided an important, but coarse, landmark to this change in neural dynamics. Because our method allows for moment-by-moment characterization of the neural dynamic, we suggest that evaluating the start and end of each dynamic may prove a powerful way identify periods of interest. Examination of such periods may advance our understanding of when and why the hippocampus may be representing current position, past experience, or possible future locations, how inputs to the hippocampus influence these events, and how these events may in turn influence downstream structures.</p><p>Our identification of the rich and varied dynamics in SWRs depended on several factors. First, we sought to describe as many SWRs as possible, instead of setting a high threshold for event detection. This more permissive approach was also critical for the identification of events that activate specific, immobility-associated locations in previous work (<xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>). More broadly, there is no evidence that SWR and high population activity events constitute clearly distinct classes of events that can be identified with a single fixed threshold. Instead, the sizes of these events are well described by a unimodal, long-tailed distribution (<xref ref-type="bibr" rid="bib78">Yu et al., 2017</xref>). High thresholds can therefore exclude large numbers of real events and potentially lead to erroneous conclusions.</p><p>Second, we used clusterless decoding, which enabled us to take advantage of information from neurons farther away from the tetrodes and not just those that could be cleanly and somewhat subjectively separated (<xref ref-type="bibr" rid="bib8">Chen et al., 2012b</xref>; <xref ref-type="bibr" rid="bib45">Kloosterman et al., 2014</xref>; <xref ref-type="bibr" rid="bib13">Deng et al., 2016</xref>). We note that more fully automated modern spike sorting algorithms (such as MountainSort; <xref ref-type="bibr" rid="bib10">Chung et al., 2017</xref>) in combination with better recording technology could reduce the differences in results when using sorted spikes or clusterless decoding, as these sorting methods help reduce experimenter subjectivity involved in spike sorting and identify larger numbers of putative single neurons.</p><p>Third, we built an explicit and flexible model that allowed us to identify not just one dynamic, but multiple dynamics consistent with different speeds of motion. We used these dynamics to describe the SWR events, rather than declaring the events as significant or not.</p><p>Fourth, our model avoided using large temporal bins and does not make assumptions about the linear progression of events. Instead, the model allows for movement in any direction allowed by geometry of the environment, and further, still accounts for the uncertainty of the data. Because the model gives a moment-by-moment estimate of the position and dynamic, this also minimizes the effect of misidentifying the SWR start and end times. Combined with an acausal estimation of latent position, this approach allows us to identify the specific timing of transitions in dynamics at a fine timescale. In addition to our SWR-based analyses, this approach could also be used to decode activity during movement, where we might expect that place-specific activity would express combinations of stationary and continuous dynamics reflecting different speeds of representational movement during each cycle of the theta rhythm. Similarly, because our approach uses the same encoder-decoder approach as the standard decoder, it can be used to investigate sequence dynamics before experience (<xref ref-type="bibr" rid="bib20">Dragoi and Tonegawa, 2013</xref>).</p><p>Our model can be viewed as an extension to the multiple temporal models approach of <xref ref-type="bibr" rid="bib39">Johnson et al., 2008</xref>, which used model selection to determine the model with the most appropriate trajectory speed. Our model goes beyond the Johnson model in that it explicitly permits a mixture between the movement speeds, can work for arbitrary track geometries, and uses clusterless decoding. Our model also represents a middle ground between Hidden Markov-style models (<xref ref-type="bibr" rid="bib7">Chen et al., 2012a</xref>; <xref ref-type="bibr" rid="bib9">Chen et al., 2016</xref>; <xref ref-type="bibr" rid="bib49">Linderman et al., 2016</xref>; <xref ref-type="bibr" rid="bib52">Maboudi et al., 2018</xref>), which seek to be environment-agnostic detectors of sequential patterns, and the standard decoder, which typically use arbitrarily chosen bin sizes and restrictive assumptions about the nature of the trajectories. In particular, our approach allows for a variety of dynamics while still yielding spatially interpretable results and makes it possible to use bin sizes of any size (here 2 ms).</p><p>Code and algorithms for decoding hippocampal replay have not typically been made accessible or easy to use. This is problematic because it can lead to severe variation or errors in code and parameters, limits reproducibility of results, and slows down scientific progress. Accordingly, we have made code for this model publicly available as a python package at the following URL <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/replay_trajectory_classification">https://github.com/Eden-Kramer-Lab/replay_trajectory_classification</ext-link> (<xref ref-type="bibr" rid="bib15">Denovellis, 2021a</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ebb1c86ba8f4326b48209b5023d1fbec9ed4c7b3;origin=https://github.com/Eden-Kramer-Lab/replay_trajectory_classification;visit=swh:1:snp:1e5ca13211f6110f3ede8de3f4fc92299f25fd54;anchor=swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986">swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986</ext-link>). It is easily installable using the pip or conda package installer and contains tutorial Jupyter notebooks in order to facilitate reuse.</p><p>State-space models like the one we use here can enable a richer set of analyses of events that take advantage of all of the available data. These approaches can be applied not just to SWRs but to all times, providing a moment-by-moment estimate of the nature of the spatial representation in the hippocampus, including important information about the spatial coherence of that representation. The model can be extended to incorporate other previously experienced environments by training place field models on those environments and including the appropriate movement transition matrices for those environments. It can also be extended to account for task conditions (such as the inbound and outbound conditions in our spatial alternation task) and forward/reverse sequences as in <xref ref-type="bibr" rid="bib13">Deng et al., 2016</xref>. Finally, models can be built to estimate any covariate, including movement direction (<xref ref-type="bibr" rid="bib44">Kay et al., 2020</xref>). We therefore suggest that this approach has the potential to provide a much richer understanding of neural representations throughout the brain.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Simulated data</title><p>Encoding data for <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> were generated by simulating 15 traversals of a 180 cm linear track. The spiking of 19 neurons was simulated using an inhomogeneous Poisson process where the instantaneous firing rate of each neuron changes according to a Gaussian place field. The Gaussian place fields had a variance of 36 cm and were spaced at 10 cm intervals over the 180 cm track. The decoding data for <xref ref-type="fig" rid="fig1">Figure 1F</xref> was generated by simulating 20,000 linear traversals of the 180 cm track, each with a unique constant speed, starting at 0.5 cm/s and increasing by 0.5 cm/s up to 10,000 cm/s. Each simulated neuron 'spiked' when the traversal passed through the peak location of its place field.</p></sec><sec id="s4-2"><title>Recording locations and techniques</title><p>Ten male Long Evans rats (500–700 g, 4–9 months old) were trained on a W-track spatial alternation task. nine rats contributed to previous studies (<xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib5">Carr et al., 2012</xref>; <xref ref-type="bibr" rid="bib43">Kay et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Kay et al., 2020</xref>). Neural activity was recorded in CA1, CA2, CA3, MEC, Subiculum, and DG depending on the rat. We only used tetrodes located in the CA1, CA2, and CA3 subregions in this study.</p></sec><sec id="s4-3"><title>Behavioral task</title><p>All animals performed a W-track spatial alternation task, which is described in detail in <xref ref-type="bibr" rid="bib42">Karlsson and Frank, 2009</xref>. In brief, each day, animals alternate between 20 min rest sessions in a rest box and 15 min run sessions on the W-shaped track equipped with a reward well at each arm end. On the W-track, animals are rewarded at the ends of an arm when that arm is the next correct arm in the sequence. Two rules determine the next correct arm. If the animal is in an outer arm, it must next visit the center arm. If the animal is in the center arm, it has to next visit the less recently visited outer arm. Correct performance of these rules result in the visit sequence: center, left, center, right, center, left, etc. Animals were free to choose any arm at any time. Only run recording sessions with at least nine putative hippocampal pyramidal cells that fired at least 100 spikes were included in the analysis.</p></sec><sec id="s4-4"><title>Position of the animal and linearization</title><p>The animal’s 2D position was estimated from digital video (30 Hz) of two infrared diodes placed on the headstage preamplifiers using a semi-automated analysis. In order to decrease the time it takes to run the model, the 2D position of the animal was converted into a 1D position. This is done by first defining a 2D graph representation of the track (herein referred to as the track graph), where edges correspond to segments of the W-track and nodes represent intersection points between those segments. Then, based on the algorithm in <xref ref-type="bibr" rid="bib57">Newson and Krumm, 2009</xref>, we use a Hidden Markov Model (HMM) to assign the position detected in each video frame to the most likely track segment. Using the HMM takes into account the time dependent nature of the data and helps prevents sudden jumps from one track segment to another, which is particularly important near intersections. The observation model of the HMM is Gaussian and it models the likelihood of being on a track segment as the Gaussian distance to that segment with a 5 cm standard deviation. The state transition model is empirically estimated, and changes with each time point to ensure that the Euclidean distance between successive position estimates is similar to the shortest path distance along the graph between successive position estimates. A slight bias of 0.1 is given to the diagonal of the state transition model to encourage staying on the same track segment. The most likely track segment the animal is on is computed using the Viterbi algorithm <xref ref-type="bibr" rid="bib72">Viterbi, 1967</xref>. After finding the track segment that corresponds to each 2D position, the 2D position is projected onto the nearest point of the track segment. This allows us to define a distance from the center well in terms of shortest path length on the track, where 0 cm represents the center well position. The linear distance can then be converted into a linear position by assigning each track segment a position in 1D space. 15 cm gaps were placed between the center arm, left arm, and right arms in 1D space to prevent any smoothing done in the model from influencing neighboring segments inappropriately. The code used for linearization can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/loren_frank_data_processing">https://github.com/Eden-Kramer-Lab/loren_frank_data_processing</ext-link> (<xref ref-type="bibr" rid="bib16">Denovellis, 2021b</xref>).</p></sec><sec id="s4-5"><title>Sorted spikes, multiunit spikes, and waveform features</title><p>To obtain the neural spiking data used for decoding, electrical potentials from rat hippocampus were recorded at 30 kHz, referenced to a tetrode located in the corpus callosum, and then digitally filtered between 600 Hz and 6 kHz. Spiking events were detected as any potential exceeding a 60 <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula> threshold on any one of the four tetrode wires of a tetrode. The electrical potential value on each wire of the tetrode at the time of maximum potential of any of the four wires was used as the waveform feature in the clusterless decoding.</p><p>For decoding using sorted spikes, the multiunit events were processed further to assign events to putative single cells. Putative single cells were manually identified based on the clustering of three waveform features within a day: peak amplitude, principal components, and spike width. Only putative hippocampal pyramidal cells—identified based on spike width and average firing rate—were included in the analysis.</p></sec><sec id="s4-6"><title>SWR detection</title><p>Sharp wave ripples were detected using the same method as in <xref ref-type="bibr" rid="bib43">Kay et al., 2016</xref>. Each CA1 LFP was obtained by downsampling the original 30 kHz electrical potential to 1.5 kHz and bandpass filtering between 0.5 Hz and 400 Hz. This was further bandpass filtered for the ripple band (150–250 Hz), squared, and then summed across tetrodes—forming a single population trace over time. This trace was smoothed with a Gaussian with a 4 ms standard deviation and the square root of this trace was taken to get an estimate of the population ripple band power. Candidate SWR times were found by z-scoring the population power trace of an entire recording session and finding times when the z-score exceeded two standard deviations for a minimum of 15 ms and the speed of the animal was less than 4 cm/s. The SWR times were then extended before and after the threshold crossings to include the time until the population trace returned to the mean value. The code used for ripple detection can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/ripple_detection">https://github.com/Eden-Kramer-Lab/ripple_detection</ext-link> (<xref ref-type="bibr" rid="bib16">Denovellis, 2021b</xref>). We only analyzed SWRs with spikes from at least two tetrodes.</p></sec><sec id="s4-7"><title>The model</title><p>Let <italic>x</italic><sub><italic>k</italic></sub> be a continuous latent variable that corresponds to the position represented by the population of cells at time <italic>t</italic><sub><italic>k</italic></sub> and let <inline-formula><mml:math id="inf2"><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> be a discrete latent variable that is an indicator for the movement dynamics we wish to characterize: stationary, continuous, and fragmented. The goal of the model is to estimate simultaneously the posterior probability of position and dynamics <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf4"><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> corresponds to the observed spiking data from time one to time <inline-formula><mml:math id="inf5"><mml:mi>T</mml:mi></mml:math></inline-formula>. The observed data can be either spike trains <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> from <inline-formula><mml:math id="inf7"><mml:mi>C</mml:mi></mml:math></inline-formula> putative cells when decoding with sorted spikes or multiunit spikes <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and their associated wave form features <inline-formula><mml:math id="inf9"><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> from each tetrode <inline-formula><mml:math id="inf10"><mml:mi>E</mml:mi></mml:math></inline-formula> when decoding with clusterless spikes, where <inline-formula><mml:math id="inf11"><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf12"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf13"><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>N</mml:mi><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>We have previously shown (<xref ref-type="bibr" rid="bib14">Denovellis et al., 2019</xref>) that the posterior probability <inline-formula><mml:math id="inf14"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be estimated by applying the following recursive causal filter equation, starting with initial conditions <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and iterating to time <inline-formula><mml:math id="inf16"><mml:mi>T</mml:mi></mml:math></inline-formula>:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>and then applying the acausal smoother equation, starting from the last estimate of the casual filter <inline-formula><mml:math id="inf17"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and recursively iterating backwards to time 1:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mo>∫</mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>where:<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mo>∫</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Therefore, to specify the model, we have to define or estimate the following quantities:</p><list list-type="order"><list-item><p><inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> - the initial conditions</p></list-item><list-item><p><inline-formula><mml:math id="inf19"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> - the dynamics transition matrix</p></list-item><list-item><p><inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> - the dynamics movement model</p></list-item><list-item><p><inline-formula><mml:math id="inf21"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> - the likelihood of the observations</p></list-item></list><p>For the initial conditions <inline-formula><mml:math id="inf22"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we set each dynamic <italic>I</italic><sub>0</sub> to have uniform <inline-formula><mml:math id="inf23"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> probability and each initial latent position to have uniform probability density over all possible positions <inline-formula><mml:math id="inf24"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒰</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, reflecting the fact that we do not have any prior knowledge about which dynamic or position is more likely:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi class="ltx_font_mathcaligraphic">𝒰</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>For the dynamics transition matrix <inline-formula><mml:math id="inf25"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which defines how likely the dynamic is to change to another dynamic versus persist in the same dynamic, we set it to be:<disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.98</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.01</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.01</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.01</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.98</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.01</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0.01</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.01</mml:mn></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mn>0.98</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>to encode the prior expectation that each of the dynamics will last the average duration of 100 ms, with a small probability of changing to one of the other dynamics.</p><p>For the dynamics movement model <inline-formula><mml:math id="inf26"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which defines how likely the position <italic>x</italic><sub><italic>k</italic></sub> is to change given the previous position <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and current <inline-formula><mml:math id="inf28"><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> and past dynamics <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, we set it to be:<disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>6.0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒰</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>6.0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒰</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒰</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒰</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="script">𝒰</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf30"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is an identity transition matrix where position cannot change from the previous time step, <inline-formula><mml:math id="inf31"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>6.0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a random walk from the previous position with variance 6.0, and <inline-formula><mml:math id="inf32"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒰</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>min</mml:mi><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>max</mml:mi><mml:mo>⁡</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a uniform transition that allows transitions to any possible position. As discussed in the Results, this means that when persisting in the same dynamic, the stationary, continuous, and fragmented dynamics are defined by the identity transition, the random walk, and the uniform transition, respectively. When transitioning to or from the fragmented dynamic, we assume we do not have any information about the position, so the transition is uniform. Finally, when the transition is from the stationary to continuous, we assume the position is spatially close where it was previously, so we use a random walk. When the transition is from continuous to stationary, we assume that the position is no longer changing, so we use the identity transition.</p><p>Lastly, we evaluate the likelihood of the observations <inline-formula><mml:math id="inf33"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> based on an encoding model fit during the encoding period. We assume the likelihood is the same for each dynamic <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>, so we only need to evaluate <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. It has been shown (<xref ref-type="bibr" rid="bib80">Zhang et al., 1998</xref>; <xref ref-type="bibr" rid="bib2">Brown et al., 1998</xref>) that the Poisson likelihood with sorted spikes can be computed as:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf36"><mml:msubsup><mml:mi>N</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>i</mml:mi></mml:msubsup></mml:math></inline-formula> represents a spike at time <italic>t</italic><sub><italic>k</italic></sub> from cell <inline-formula><mml:math id="inf37"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf38"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> is the time bin size, and <inline-formula><mml:math id="inf39"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the instantaneous firing rate of cell <inline-formula><mml:math id="inf40"><mml:mi>i</mml:mi></mml:math></inline-formula> given position <italic>x</italic><sub><italic>k</italic></sub>. <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the 'place field’ of the cell, which can be estimated by fitting a generalized linear model to each cell’s spiking during the encoding period.</p><p>Likewise, it has been shown (<xref ref-type="bibr" rid="bib8">Chen et al., 2012b</xref>; <xref ref-type="bibr" rid="bib45">Kloosterman et al., 2014</xref>; <xref ref-type="bibr" rid="bib13">Deng et al., 2016</xref>) that the clusterless likelihood can be computed as:<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mspace linebreak="newline"/><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="normal">Λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is now a generalized firing rate that depends on an associated wave form features <inline-formula><mml:math id="inf43"><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf44"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a marginal firing rate that is equivalent to a place field estimated on multiunit spikes. Both of these rates can be defined as:<disp-formula id="equ9"><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>and<disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf45"><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the mean firing rate for tetrode <inline-formula><mml:math id="inf46"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the smoothed spatial occupancy of the animal on the track, <inline-formula><mml:math id="inf48"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the smoothed spatial occupancy only at times when spikes occur in tetrode <inline-formula><mml:math id="inf49"><mml:mi>i</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf50"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the smoothed occupancy in the space of both space and waveform features. <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf52"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf53"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can all be estimated by training a kernel density estimator on each tetrode’s spike waveform features and corresponding position during the encoding period.</p></sec><sec id="s4-8"><title>Encoding - sorted spikes</title><p>In order to encode how each cell’s spiking activity relates to position (the place field), we fit a generalized linear model (GLM) with a Poisson response distribution to each cell’s spiking activity during the encoding period, which we define as all movement times (time periods when the running speed is greater than 4 cm/s). We estimate the parameters <inline-formula><mml:math id="inf54"><mml:mi>β</mml:mi></mml:math></inline-formula>, which consist of <inline-formula><mml:math id="inf55"><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, the baseline firing rate over time, and <inline-formula><mml:math id="inf56"><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, weights for third degree B-spline basis functions <italic>f</italic><sub><italic>i</italic></sub> over position (or tensor products of the B-splines when position is two dimensional). B-spline basis functions are used because place field firing activity is assumed to vary smoothly over position and this prior knowledge can be exploited to reduce the total number of model parameters needed. Each basis function is spaced every 5 cm over the range of the position and zero constrained so that the change encoded by the parameters is relative to the baseline firing rate. We use a log link function to convert the linear combination of parameters to an instantaneous firing rate over time <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to ensure the rate is always positive.<disp-formula id="equ11"><mml:math id="m11"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>A small L2 penalization term <inline-formula><mml:math id="inf58"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is used to prevent model fitting instability when spiking activity is very low. We set this to 0.5 for all cells. Fitting is done by maximizing the penalized likelihood using a Newton-Raphson algorithm. The code used to fit the GLMs is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/regularized_glm">https://github.com/Eden-Kramer-Lab/regularized_glm</ext-link>; <xref ref-type="bibr" rid="bib16">Denovellis, 2021b</xref>.</p></sec><sec id="s4-9"><title>Encoding - clusterless</title><p>In order to relate each tetrode’s unsorted spiking activity and waveform features to position during the encoding period, which we define as all movement times (time periods when the running speed is greater than 4 cm/s), we used kernel density estimation (KDE) to estimate the following distributions: <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf60"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf61"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We used KDEs of the form:<disp-formula id="equ12"><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mo>⋅</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf62"><mml:mi>y</mml:mi></mml:math></inline-formula> is the data with <inline-formula><mml:math id="inf63"><mml:mi>D</mml:mi></mml:math></inline-formula> dimensions, <inline-formula><mml:math id="inf64"><mml:mi>K</mml:mi></mml:math></inline-formula> is a one dimensional Gaussian kernel with bandwidth <italic>h</italic><sub><italic>d</italic></sub>, <inline-formula><mml:math id="inf65"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the data observed during movement, <inline-formula><mml:math id="inf66"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of observations during the movement period. For <inline-formula><mml:math id="inf67"><mml:mrow><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf68"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is all positions observed during movement. For <inline-formula><mml:math id="inf69"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf70"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is all positions at the time of multiunit spikes during movement. For <inline-formula><mml:math id="inf71"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is all positions at the time of multiunit spikes and their associated waveform features during movement. We choose the bandwidth <italic>h</italic><sub><italic>d</italic></sub> to be 6.0 cm for any position dimension and 24.0 <inline-formula><mml:math id="inf73"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math></inline-formula> for any spike amplitude dimension, because these parameters were found to minimize decoding error in <xref ref-type="bibr" rid="bib45">Kloosterman et al., 2014</xref>. The mean firing rate <inline-formula><mml:math id="inf74"><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula> was also estimated during movement.</p></sec><sec id="s4-10"><title>Decoding</title><p>In order to decode <inline-formula><mml:math id="inf75"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we used a grid-based approximation of the latent position <italic>x</italic><sub><italic>k</italic></sub> that respected the geometry of the track. For 1D linearized positions, we discretized the position space based on the same track graph we used for linearization by finding bins less than or equal to the chosen position bin size for each edge of the graph. For 2D positions, we discretized the position space by binning 2D positions occupied by the animal with equal sized bins of the chosen position bin size, followed by morphological opening to get rid of any holes smaller than the bin size. This was done using Scipy image processing tools (<xref ref-type="bibr" rid="bib63">SciPy 1.0 Contributors et al., 2020</xref>). This grid based approximation allows us to use Riemann sums to approximate the integrals in the causal filter and acausal smoother equations. We chose a position grid with bins of 3 cm in width (and height if the model was computed with 2D positions) in order to get good resolution for the random walk transition matrices (which had 6 cm variance) as well as for the clusterless and sorted spikes decoding (which have 6 cm bandwidth for the KDE position dimensions and 5 cm spline knots for the GLM). For sorted spikes decoding, we evaluated the place field <inline-formula><mml:math id="inf76"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on the midpoint of these bins. Likewise, for clusterless decoding, we evaluated the spike amplitudes observed during the decoding period by evaluating the KDE for <inline-formula><mml:math id="inf77"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for the midpoint of these bins.</p><p>We also used these grid bins in combination with the track graph in order to construct the appropriate 1D random walk transition matrices that respected the track geometry. To do this, we inserted the bin centers as nodes in the track graph, and then computed the shortest path distance between all pairs of position bin centers. We then evaluated a zero mean Gaussian with a variance of 6 cm on these distances to get the appropriate transition probability of moving from bin to bin.</p><p>Finally, for our SWR analysis of <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, we decoded each immobility time period (times when the animal’s speed was less than 4 cm / s) in 2 ms time bins and extracted the SWR times.</p></sec><sec id="s4-11"><title>Probability of the dynamics</title><p>The probability of the dynamics is a quantity that indicates how much that dynamic is contributing to the posterior at a given time. We estimate the probability of the dynamics by integrating out position from the joint posterior:<disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">𝑑</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>As in other calculations, the integral is approximated with a Riemann sum.</p></sec><sec id="s4-12"><title>Posterior probability of position</title><p>The posterior probability of position is a quantity that indicates the most probable 'mental' positions of the animal based on the data. We estimate it by marginalizing the joint probability over the dynamics.<disp-formula id="equ14"><mml:math id="m14"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-13"><title>Classification of dynamics</title><p>We used a threshold of 0.80 to classify the probability of each state <inline-formula><mml:math id="inf79"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> into five categories. Time periods during sharp wave ripples are labeled as stationary, continuous, or fragmented when the probability of each individual state is above 0.80, regardless of duration. Time periods are labeled as stationary-continuous-mixture or fragmented-continuous-mixture when the sum of stationary and continuous or fragmented and continuous are above 0.80, respectively. Time periods where none of these criterion are met are considered unclassified.</p></sec><sec id="s4-14"><title>Highest posterior density</title><p>The 95% highest posterior density (HPD) is a measurement of the spread of the posterior probability and is defined as the region of the posterior that contains the top 95% of values of the posterior probability (<xref ref-type="bibr" rid="bib6">Casella and Berger, 2001</xref>). By using only the top values, this measurement of spread is not influenced by multimodal distributions (whereas an alternative measure like the quantiles of the distribution would be). In this manuscript, we use the HPD region size—the total area of the track covered by the 95% HPD region—to evaluate the uncertainty of the posterior probability of position.</p><p>In order to calculate the HPD region size, we first calculate the 95% HPD region by determining the maximum threshold value <inline-formula><mml:math id="inf80"><mml:mi>h</mml:mi></mml:math></inline-formula> that fulfills the follow equality:<disp-formula id="equ15"><mml:math id="m15"><mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>x</mml:mi><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="0pt">𝑑</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></disp-formula></p><p>The 95% HPD region is the set of position bins with posterior values greater than the threshold <inline-formula><mml:math id="inf81"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>x</mml:mi><mml:mo>:</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>. The HPD region size is calculated by taking the integral of the members of this set:<disp-formula id="equ16"><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>x</mml:mi><mml:mo>:</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mi>h</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mn mathvariant="double-struck">𝟙</mml:mn></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula>which we approximate with a Riemann sum.</p></sec><sec id="s4-15"><title>Shuffle analysis of the effect of place encoding on classification of dynamics and HPD region size</title><p>In order to confirm that the model classification of dynamics depended on hippocampal place specific encoding, we resampled the position during movement with replacement, but preserved the spike times and spike waveform amplitudes. We fit the clusterless encoding model on the resampled data and then decoded the immobility periods. Like with the non-resampled data, we then extracted the SWR times and determined their classification based on our classification scheme. We repeated this shuffle analysis 50 times and compared this distribution to the real data for two recording sessions on two different animals (animal Bond, day 3, epoch two and animal Remy, day 35, epoch 2).</p><p>We also performed another shuffle that preserved more of the local correlation structure of spiking by shuffling the order of the well-to-well runs and then circularly shuffling the position within the runs. A well-to-well run starts when the animal moves more than 5 cm from a well and ends when the animal moves back within 5 cm of a well. This largely reflects runs from one well to another (e.g. from the center well to the left well), but for a small number of well-to-well runs, the animal did turn back to the same well (e.g. went back to the center well after leaving the center well). As above, after permuting the order of the well-to-well runs and circularly shuffling the position, we fit the clusterless encoding model and decoded SWRs. We repeated this shuffle analysis 50 times and compared this distribution to the real data for two recording sessions on two different animals (animal Bond, day 3, epoch two and animal Remy, day 35, epoch 2).</p></sec><sec id="s4-16"><title>Distance from animal</title><p>The distance of the decoded position from the animal’s is defined as the shortest path distance along the track graph between the animal’s 2D position projected on to the track graph (see Linearization) and the MAP estimate of the posterior probability of position, <inline-formula><mml:math id="inf82"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>arg</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the center of the position bin with the greatest posterior value. The shortest path is found using Dijkstra’s algorithm <xref ref-type="bibr" rid="bib18">Dijkstra, 1959</xref> as implemented in NetworkX (<xref ref-type="bibr" rid="bib32">Hagberg et al., 2008</xref>).</p></sec><sec id="s4-17"><title>Estimation of speed</title><p>In order to estimate the speed over time, we first found the MAP estimate of the posterior probability of position, <inline-formula><mml:math id="inf83"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>arg</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt">∣</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the center of the position bin with the greatest posterior value. We then computed the first derivative using the Python library Numpy’s gradient function, which computes the difference in the forward and backward time direction and then averages them for all points except the boundaries. We then smoothed this quantity with a small Gaussian (2.5 ms standard deviation) and then averaged this for the classified time points. Because our position bin size of 3 cm makes it hard to distinguish between slower speeds in a 2 ms time step, we only analyzed classifications longer than 20 ms.</p></sec><sec id="s4-18"><title>Non-local stationary position</title><p>The non-local stationary position is defined as replay distances at least 30 cm from the animal’s position during a time period classified as stationary.</p></sec><sec id="s4-19"><title>Identifying events of high multiunit activity</title><p>We identified times of high multiunit activity when the animal was immobile as a control analysis. Our approach was similar to <xref ref-type="bibr" rid="bib11">Davidson et al., 2009</xref>. High multiunit periods were identified as times when the z-scored multiunit population spiking activity was greater than two standard deviations for at least 15 ms and the animal was moving at speeds less than 4 cm/s. The code used for detection of high multiunit time periods can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/ripple_detection">https://github.com/Eden-Kramer-Lab/ripple_detection</ext-link>.</p></sec><sec id="s4-20"><title>Standard 'Bayesian’ decoding and significance estimation</title><p>For the standard decoder analysis, we first fit a clusterless encoding model in the same manner as described in the subsection Encoding - Clusterless. We then decoded the posterior probability of each position, using 20 ms time bins, using the clusterless likelihood equation as described in the subsection The Model and assuming a uniform prior probability. Finally, to get an estimate of speed of the replay, we used either the Radon transform method, the linear regression method, or the MAP estimate method.</p><p>For the Radon transform method, we densely sampled potential line trajectories and picked the line that maximized the probability along that line. The sum of the probability along the line is called the Radon score. We picked the maximum Radon score on lines fit on the combination of center arm and left arm posterior versus center arm and right arm posteriors. p-Values were computed by circularly shuffling the posterior probabilities 1000 times and comparing the real data vs. the shuffled distribution.</p><p>For the linear regression method, we drew 1000 position samples from each time bin according to the probability of position in that time bin. A linear regression was then fit to the sampled positions using time as a covariate. Fits were made separately for the posterior probabilities corresponding to the center arm with the left arm and the center arm with the right arm. Quality of the fit was assessed using the R-squared and the best fit between the arms was selected based on this metric.</p><p>For the MAP estimate, we pick the position bin with the maximum value for each time bin, which corresponds to the most probable position.</p></sec><sec id="s4-21"><title>Software and code availability</title><p>Python code used for analysis and generating figures in the paper is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/replay_trajectory_paper">https://github.com/Eden-Kramer-Lab/replay_trajectory_paper</ext-link> (<xref ref-type="bibr" rid="bib28">Frank, 2021</xref> copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ee06069fffec82100150398b357bb4f332d09376;origin=https://github.com/Eden-Kramer-Lab/replay_trajectory_paper;visit=swh:1:snp:46f6d1bb45c3612bf3206208647700c940699a40;anchor=swh:1:rev:630d4e32f343e86a4921d0773f1f5c5adf90553f">swh:1:rev:630d4e32f343e86a4921d0773f1f5c5adf90553f</ext-link>). Code for the decoder is available in a separate software repository to facilitate code reuse at: <ext-link ext-link-type="uri" xlink:href="https://github.com/Eden-Kramer-Lab/replay_trajectory_classification">https://github.com/Eden-Kramer-Lab/replay_trajectory_classification</ext-link> (<xref ref-type="bibr" rid="bib15">Denovellis, 2021a</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ebb1c86ba8f4326b48209b5023d1fbec9ed4c7b3;origin=https://github.com/Eden-Kramer-Lab/replay_trajectory_classification;visit=swh:1:snp:1e5ca13211f6110f3ede8de3f4fc92299f25fd54;anchor=swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986">swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986</ext-link>) (doi: <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5281/zenodo.3713412">10.5281/zenodo.3713412</ext-link>). Both code bases rely on the following python packages: Numpy (<xref ref-type="bibr" rid="bib71">van der Walt et al., 2011</xref>), Numba (<xref ref-type="bibr" rid="bib46">Lam et al., 2015</xref>), Matplotlib (<xref ref-type="bibr" rid="bib36">Hunter, 2007</xref>), xarray (<xref ref-type="bibr" rid="bib35">Hoyer and Hamman, 2017</xref>), NetworkX (<xref ref-type="bibr" rid="bib32">Hagberg et al., 2008</xref>), Pandas (<xref ref-type="bibr" rid="bib53">McKinney, 2010</xref>), and Seaborn (<xref ref-type="bibr" rid="bib74">Waskom, 2021</xref>). All code is open-source and licensed under the MIT Software License. Decoder code can be easily installed as a python package with all requisite dependencies using pip or conda. See software repositories for specific details.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Margaret Carr Larkin and Mattias P Karlsson for use of their openly available datasets. We also thank Abhilasha Joshi for feedback on the manuscript. This work was supported by the Simons Foundation for the Global Brain Grants 542971 (UTE) and 542981 (LMF) and the Howard Hughes Medical Institute (LMF).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Data curation, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Resources, Formal analysis, Supervision, Funding acquisition, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing - original draft, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: All experiments were conducted in accordance with University of California San Francisco Institutional Animal Care and Use Committee and US National Institutes of Health guidelines. The protocol was approved by the Institutional Animal Care and Use Committee, approval number AN174991-03G. All surgical procedures were performed under anesthesia and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-64505-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data from this paper has been deposited in a dryad repository. Some of this data was previously deposited at the CRCNS data sharing website as dataset hc-6, but for reproducibility purposes we have included it here.</p><p>The following dataset was generated:</p><p><element-citation id="dataset2" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Denovellis</surname><given-names>EL</given-names></name><name><surname>Gillespie</surname><given-names>AK</given-names></name><name><surname>Coulter</surname><given-names>ME</given-names></name><name><surname>Sosa</surname><given-names>M</given-names></name><name><surname>Chung</surname><given-names>JE</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Data from: Hippocampal replay of experience at real-world speeds</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.7272/Q61N7ZC3</pub-id></element-citation></p><p>The following previously published dataset was used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Karlsson</surname><given-names>MP</given-names></name><name><surname>Carr</surname><given-names>M</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2015">2015</year><data-title>Simultaneous extracellular recordings from hippocampal areas CA1 and CA3 (or MEC and CA1) from rats performing an alternation task in two W-shapped tracks that are geometrically identically but visually distinct</data-title><source>Collaborative Research in Computational Neuroscience</source><pub-id assigning-authority="other" pub-id-type="doi">10.6080/K0NK3BZJ</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhattarai</surname> <given-names>B</given-names></name><name><surname>Lee</surname> <given-names>JW</given-names></name><name><surname>Jung</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Distinct effects of reward and navigation history on hippocampal forward and reverse replays</article-title><source>PNAS</source><volume>117</volume><fpage>689</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1073/pnas.1912533117</pub-id><pub-id pub-id-type="pmid">31871185</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname> <given-names>EN</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Tang</surname> <given-names>D</given-names></name><name><surname>Quirk</surname> <given-names>MC</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A statistical paradigm for neural spike train decoding applied to position prediction from ensemble firing patterns of rat hippocampal place cells</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>7411</fpage><lpage>7425</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-18-07411.1998</pub-id><pub-id pub-id-type="pmid">9736661</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carey</surname> <given-names>AA</given-names></name><name><surname>Tanaka</surname> <given-names>Y</given-names></name><name><surname>van der Meer</surname> <given-names>MAA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reward revaluation biases hippocampal replay content away from the preferred outcome</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1450</fpage><lpage>1459</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0464-6</pub-id><pub-id pub-id-type="pmid">31427771</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname> <given-names>MF</given-names></name><name><surname>Jadhav</surname> <given-names>SP</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>147</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1038/nn.2732</pub-id><pub-id pub-id-type="pmid">21270783</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname> <given-names>MF</given-names></name><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Transient slow gamma synchrony underlies hippocampal memory replay</article-title><source>Neuron</source><volume>75</volume><fpage>700</fpage><lpage>713</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.06.014</pub-id><pub-id pub-id-type="pmid">22920260</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Casella</surname> <given-names>G</given-names></name><name><surname>Berger</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2001">2001</year><chapter-title>Duxbury Advanced Series in Statistics and Decision Sciences</chapter-title><person-group person-group-type="editor"><name><surname>Berger</surname> <given-names>R. L</given-names></name></person-group><source>Statistical Inference</source><publisher-loc>United States</publisher-loc><publisher-name>Cengage</publisher-name><fpage>10</fpage><lpage>21</lpage></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Kloosterman</surname> <given-names>F</given-names></name><name><surname>Brown</surname> <given-names>EN</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Uncovering spatial topology represented by rat hippocampal population neuronal codes</article-title><source>Journal of Computational Neuroscience</source><volume>33</volume><fpage>227</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1007/s10827-012-0384-x</pub-id><pub-id pub-id-type="pmid">22307459</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Kloosterman</surname> <given-names>F</given-names></name><name><surname>Layton</surname> <given-names>S</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Transductive neural decoding for unsorted neuronal spikes of rat Hippocampus</article-title><conf-name>Engineering in Medicine and Biology Society (EMBC), 2012 Annual International Conference of the IEEE</conf-name><fpage>1310</fpage><lpage>1313</lpage><pub-id pub-id-type="doi">10.1109/EMBC.2012.6346178</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Linderman</surname> <given-names>SW</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Bayesian nonparametric methods for discovering latent structures of rat hippocampal ensemble spikes</article-title><conf-name>2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP) Vietri Sul Mare Salerno Italy: IEEE</conf-name><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1109/MLSP.2016.7738867</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname> <given-names>JE</given-names></name><name><surname>Magland</surname> <given-names>JF</given-names></name><name><surname>Barnett</surname> <given-names>AH</given-names></name><name><surname>Tolosa</surname> <given-names>VM</given-names></name><name><surname>Tooker</surname> <given-names>AC</given-names></name><name><surname>Lee</surname> <given-names>KY</given-names></name><name><surname>Shah</surname> <given-names>KG</given-names></name><name><surname>Felix</surname> <given-names>SH</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Greengard</surname> <given-names>LF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A fully automated approach to spike sorting</article-title><source>Neuron</source><volume>95</volume><fpage>1381</fpage><lpage>1394</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.08.030</pub-id><pub-id pub-id-type="pmid">28910621</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Kloosterman</surname> <given-names>F</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hippocampal replay of extended experience</article-title><source>Neuron</source><volume>63</volume><fpage>497</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id><pub-id pub-id-type="pmid">19709631</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname> <given-names>X</given-names></name><name><surname>Liu</surname> <given-names>DF</given-names></name><name><surname>Kay</surname> <given-names>K</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Eden</surname> <given-names>UT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Clusterless decoding of position from multiunit activity using a marked point process filter</article-title><source>Neural Computation</source><volume>27</volume><fpage>1438</fpage><lpage>1460</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00744</pub-id><pub-id pub-id-type="pmid">25973549</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname> <given-names>X</given-names></name><name><surname>Liu</surname> <given-names>DF</given-names></name><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Eden</surname> <given-names>UT</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Rapid classification of hippocampal replay content for real-time applications</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>2221</fpage><lpage>2235</lpage><pub-id pub-id-type="doi">10.1152/jn.00151.2016</pub-id><pub-id pub-id-type="pmid">27535369</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Denovellis</surname> <given-names>EL</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Eden</surname> <given-names>UT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Characterizing hippocampal replay using hybrid point process state space models</article-title><conf-name>53rd Asilomar Conference on Signals, Systems, and Computers</conf-name><fpage> 245</fpage><lpage> 249</lpage><pub-id pub-id-type="doi">10.1109/IEEECONF44664.2019.9048688</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Denovellis</surname> <given-names>EL</given-names></name></person-group><year iso-8601-date="2021">2021a</year><data-title>replay_trajectory_classification</data-title><source>Software Heritage</source><version designator="swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986">swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986</version><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ebb1c86ba8f4326b48209b5023d1fbec9ed4c7b3;origin=https://github.com/Eden-Kramer-Lab/replay_trajectory_classification;visit=swh:1:snp:1e5ca13211f6110f3ede8de3f4fc92299f25fd54;anchor=swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986">https://archive.softwareheritage.org/swh:1:dir:ebb1c86ba8f4326b48209b5023d1fbec9ed4c7b3;origin=https://github.com/Eden-Kramer-Lab/replay_trajectory_classification;visit=swh:1:snp:1e5ca13211f6110f3ede8de3f4fc92299f25fd54;anchor=swh:1:rev:83d84170ae0bdeef65cd123fa83448fcca9cb986</ext-link></element-citation></ref><ref id="bib16"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Denovellis</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021b</year><data-title>Eden-Kramer-Lab/loren_frank_data_processing</data-title><source>Zenodo</source><version designator="0.9.13.">v0.9.13.dev0</version><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5523666">https://doi.org/10.5281/zenodo.5523666</ext-link></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diba</surname> <given-names>K</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1241</fpage><lpage>1242</lpage><pub-id pub-id-type="doi">10.1038/nn1961</pub-id><pub-id pub-id-type="pmid">17828259</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dijkstra</surname> <given-names>EW</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>A note on two problems in connexion with graphs</article-title><source>Numerische Mathematik</source><volume>1</volume><fpage>269</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1007/BF01386390</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dragoi</surname> <given-names>G</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Temporal encoding of place sequences by hippocampal cell assemblies</article-title><source>Neuron</source><volume>50</volume><fpage>145</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.02.023</pub-id><pub-id pub-id-type="pmid">16600862</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dragoi</surname> <given-names>G</given-names></name><name><surname>Tonegawa</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Distinct preplay of multiple novel spatial experiences in the rat</article-title><source>PNAS</source><volume>110</volume><fpage>9100</fpage><lpage>9105</lpage><pub-id pub-id-type="doi">10.1073/pnas.1306031110</pub-id><pub-id pub-id-type="pmid">23671088</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drieu</surname> <given-names>C</given-names></name><name><surname>Todorova</surname> <given-names>R</given-names></name><name><surname>Zugaro</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Nested sequences of hippocampal assemblies during behavior support subsequent sleep replay</article-title><source>Science</source><volume>362</volume><elocation-id>675</elocation-id><pub-id pub-id-type="doi">10.1126/science.aat2952</pub-id><pub-id pub-id-type="pmid">30409880</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dupret</surname> <given-names>D</given-names></name><name><surname>O'Neill</surname> <given-names>J</given-names></name><name><surname>Pleydell-Bouverie</surname> <given-names>B</given-names></name><name><surname>Csicsvari</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The reorganization and reactivation of hippocampal maps predict spatial memory performance</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>995</fpage><lpage>1002</lpage><pub-id pub-id-type="doi">10.1038/nn.2599</pub-id><pub-id pub-id-type="pmid">20639874</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eichenbaum</surname> <given-names>H</given-names></name><name><surname>Cohen</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><chapter-title>From conditioning to conscious recollection: memory systems of the brain</chapter-title><person-group person-group-type="editor"><name><surname>Cohen</surname> <given-names>N. J</given-names></name></person-group><source>No. 35 in Oxford Psychology Series</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name><fpage>1</fpage><lpage>52</lpage></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farooq</surname> <given-names>U</given-names></name><name><surname>Dragoi</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Emergence of preconfigured and plastic time-compressed sequences in early postnatal development</article-title><source>Science</source><volume>363</volume><fpage>168</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1126/science.aav0502</pub-id><pub-id pub-id-type="pmid">30630930</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname> <given-names>DJ</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title><source>Nature</source><volume>440</volume><fpage>680</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/nature04587</pub-id><pub-id pub-id-type="pmid">16474382</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname> <given-names>DJ</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal theta sequences</article-title><source>Hippocampus</source><volume>17</volume><fpage>1093</fpage><lpage>1099</lpage><pub-id pub-id-type="doi">10.1002/hipo.20345</pub-id><pub-id pub-id-type="pmid">17663452</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname> <given-names>SE</given-names></name><name><surname>Ranck</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Localization and anatomical identification of theta and complex spike cells in dorsal hippocampal formation of rats</article-title><source>Experimental Neurology</source><volume>49</volume><fpage>299</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/0014-4886(75)90213-7</pub-id><pub-id pub-id-type="pmid">1183529</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>replay_trajectory_paper</data-title><source>Software Heritage</source><version designator="swh:1:rev:630d4e32f343e86a4921d0773f1f5c5adf90553f">swh:1:rev:630d4e32f343e86a4921d0773f1f5c5adf90553f</version><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ee06069fffec82100150398b357bb4f332d09376;origin=https://github.com/Eden-Kramer-Lab/replay_trajectory_paper;visit=swh:1:snp:46f6d1bb45c3612bf3206208647700c940699a40;anchor=swh:1:rev:630d4e32f343e86a4921d0773f1f5c5adf90553f">https://archive.softwareheritage.org/swh:1:dir:ee06069fffec82100150398b357bb4f332d09376;origin=https://github.com/Eden-Kramer-Lab/replay_trajectory_paper;visit=swh:1:snp:46f6d1bb45c3612bf3206208647700c940699a40;anchor=swh:1:rev:630d4e32f343e86a4921d0773f1f5c5adf90553f</ext-link></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frankland</surname> <given-names>PW</given-names></name><name><surname>Bontempi</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The organization of recent and remote memories</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>119</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1038/nrn1607</pub-id><pub-id pub-id-type="pmid">15685217</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grosmark</surname> <given-names>AD</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences</article-title><source>Science</source><volume>351</volume><fpage>1440</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1126/science.aad1935</pub-id><pub-id pub-id-type="pmid">27013730</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname> <given-names>AS</given-names></name><name><surname>van der Meer</surname> <given-names>MA</given-names></name><name><surname>Touretzky</surname> <given-names>DS</given-names></name><name><surname>Redish</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Hippocampal replay is not a simple function of experience</article-title><source>Neuron</source><volume>65</volume><fpage>695</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.034</pub-id><pub-id pub-id-type="pmid">20223204</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hagberg</surname> <given-names>AA</given-names></name><name><surname>Schult</surname> <given-names>DA</given-names></name><name><surname>Swart</surname> <given-names>PJ</given-names></name><name><surname>Structure</surname> <given-names>EN</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Dynamics, and function using NetworkX</article-title><conf-name>Proceedings of the 7th Python In Science Conference Pasadena</conf-name><fpage>11</fpage><lpage>15</lpage></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hangya</surname> <given-names>B</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Muller</surname> <given-names>RU</given-names></name><name><surname>Czurkó</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Complementary spatial firing in place cell-interneuron pairs</article-title><source>The Journal of Physiology</source><volume>588</volume><fpage>4165</fpage><lpage>4175</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2010.194274</pub-id><pub-id pub-id-type="pmid">20819942</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Hirase</surname> <given-names>H</given-names></name><name><surname>Leinekugel</surname> <given-names>X</given-names></name><name><surname>Henze</surname> <given-names>DA</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporal interaction between single spikes and complex spike bursts in hippocampal pyramidal cells</article-title><source>Neuron</source><volume>32</volume><fpage>141</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(01)00447-0</pub-id><pub-id pub-id-type="pmid">11604145</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoyer</surname> <given-names>S</given-names></name><name><surname>Hamman</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Xarray: n-d labeled arrays and datasets in Python</article-title><source>Journal of Open Research Software</source><volume>5</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.5334/jors.148</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Matplotlib: a 2D graphics environment</article-title><source>Computing in Science &amp; Engineering</source><volume>9</volume><fpage>90</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jadhav</surname> <given-names>SP</given-names></name><name><surname>Rothschild</surname> <given-names>G</given-names></name><name><surname>Roumis</surname> <given-names>DK</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Coordinated excitation and inhibition of prefrontal ensembles during awake hippocampal Sharp-Wave ripple events</article-title><source>Neuron</source><volume>90</volume><fpage>113</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.02.010</pub-id><pub-id pub-id-type="pmid">26971950</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jinno</surname> <given-names>S</given-names></name><name><surname>Klausberger</surname> <given-names>T</given-names></name><name><surname>Marton</surname> <given-names>LF</given-names></name><name><surname>Dalezios</surname> <given-names>Y</given-names></name><name><surname>Roberts</surname> <given-names>JD</given-names></name><name><surname>Fuentealba</surname> <given-names>P</given-names></name><name><surname>Bushong</surname> <given-names>EA</given-names></name><name><surname>Henze</surname> <given-names>D</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name><name><surname>Somogyi</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neuronal diversity in GABAergic long-range projections from the Hippocampus</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>8790</fpage><lpage>8804</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1847-07.2007</pub-id><pub-id pub-id-type="pmid">17699661</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Johnson</surname> <given-names>A</given-names></name><name><surname>Jackson</surname> <given-names>JC</given-names></name><name><surname>Redish</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2008">2008</year><chapter-title>Measuring Distributed Properties of Neural Representations beyond the Decoding of Local Variables: Implications for Cognition</chapter-title><person-group person-group-type="editor"><name><surname>Holscher</surname> <given-names>C</given-names></name><name><surname>Munk</surname> <given-names>M</given-names></name></person-group><source>Information Processing by Neuronal Populations</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><fpage>95</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1017/CBO9780511541650.005</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joo</surname> <given-names>HR</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampal sharp wave-ripple in memory retrieval for immediate use and consolidation</article-title><source>Nature Reviews. Neuroscience</source><volume>19</volume><fpage>744</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.1038/s41583-018-0077-1</pub-id><pub-id pub-id-type="pmid">30356103</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaefer</surname> <given-names>K</given-names></name><name><surname>Nardin</surname> <given-names>M</given-names></name><name><surname>Blahna</surname> <given-names>K</given-names></name><name><surname>Csicsvari</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Replay of behavioral sequences in the medial prefrontal cortex during rule switching</article-title><source>Neuron</source><volume>106</volume><fpage>154</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.01.015</pub-id><pub-id pub-id-type="pmid">32032512</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Awake replay of remote experiences in the Hippocampus</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>913</fpage><lpage>918</lpage><pub-id pub-id-type="doi">10.1038/nn.2344</pub-id><pub-id pub-id-type="pmid">19525943</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname> <given-names>K</given-names></name><name><surname>Sosa</surname> <given-names>M</given-names></name><name><surname>Chung</surname> <given-names>JE</given-names></name><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Larkin</surname> <given-names>MC</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A hippocampal network for spatial coding during immobility and sleep</article-title><source>Nature</source><volume>531</volume><fpage>185</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1038/nature17144</pub-id><pub-id pub-id-type="pmid">26934224</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname> <given-names>K</given-names></name><name><surname>Chung</surname> <given-names>JE</given-names></name><name><surname>Sosa</surname> <given-names>M</given-names></name><name><surname>Schor</surname> <given-names>JS</given-names></name><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Larkin</surname> <given-names>MC</given-names></name><name><surname>Liu</surname> <given-names>DF</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Constant Sub-second cycling between representations of possible futures in the Hippocampus</article-title><source>Cell</source><volume>180</volume><fpage>552</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.01.014</pub-id><pub-id pub-id-type="pmid">32004462</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kloosterman</surname> <given-names>F</given-names></name><name><surname>Layton</surname> <given-names>SP</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Bayesian decoding using unsorted spikes in the rat Hippocampus</article-title><source>Journal of Neurophysiology</source><volume>111</volume><fpage>217</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1152/jn.01046.2012</pub-id><pub-id pub-id-type="pmid">24089403</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lam</surname> <given-names>SK</given-names></name><name><surname>Pitrou</surname> <given-names>A</given-names></name><name><surname>Seibert</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Numba: a LLVM-Based Python JIT compiler</article-title><conf-name>Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC -LLVM ’15 Austin</conf-name><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>AK</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Memory of sequential experience in the Hippocampus during slow wave sleep</article-title><source>Neuron</source><volume>36</volume><fpage>1183</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01096-6</pub-id><pub-id pub-id-type="pmid">12495631</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lex</surname> <given-names>A</given-names></name><name><surname>Gehlenborg</surname> <given-names>N</given-names></name><name><surname>Strobelt</surname> <given-names>H</given-names></name><name><surname>Vuillemot</surname> <given-names>R</given-names></name><name><surname>Pfister</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>UpSet: visualization of intersecting sets</article-title><source>IEEE Transactions on Visualization and Computer Graphics</source><volume>20</volume><fpage>1983</fpage><lpage>1992</lpage><pub-id pub-id-type="doi">10.1109/TVCG.2014.2346248</pub-id><pub-id pub-id-type="pmid">26356912</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linderman</surname> <given-names>SW</given-names></name><name><surname>Johnson</surname> <given-names>MJ</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A bayesian nonparametric approach for uncovering rat hippocampal population codes during spatial navigation</article-title><source>Journal of Neuroscience Methods</source><volume>263</volume><fpage>36</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2016.01.022</pub-id><pub-id pub-id-type="pmid">26854398</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>S</given-names></name><name><surname>Grosmark</surname> <given-names>AD</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Methods for assessment of memory reactivation</article-title><source>Neural Computation</source><volume>30</volume><fpage>2175</fpage><lpage>2209</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01090</pub-id><pub-id pub-id-type="pmid">29652580</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Louie</surname> <given-names>K</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Temporally structured replay of awake hippocampal ensemble activity during rapid eye movement sleep</article-title><source>Neuron</source><volume>29</volume><fpage>145</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(01)00186-6</pub-id><pub-id pub-id-type="pmid">11182087</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maboudi</surname> <given-names>K</given-names></name><name><surname>Ackermann</surname> <given-names>E</given-names></name><name><surname>de Jong</surname> <given-names>LW</given-names></name><name><surname>Pfeiffer</surname> <given-names>BE</given-names></name><name><surname>Foster</surname> <given-names>D</given-names></name><name><surname>Diba</surname> <given-names>K</given-names></name><name><surname>Kemere</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Uncovering temporal structure in hippocampal output patterns</article-title><source>eLife</source><volume>7</volume><elocation-id>e34467</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34467</pub-id><pub-id pub-id-type="pmid">29869611</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>McKinney</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Data structures for statistical computing in Python</article-title><conf-name>Python in Science Conference </conf-name><fpage>56</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michon</surname> <given-names>F</given-names></name><name><surname>Sun</surname> <given-names>JJ</given-names></name><name><surname>Kim</surname> <given-names>CY</given-names></name><name><surname>Ciliberti</surname> <given-names>D</given-names></name><name><surname>Kloosterman</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Post-learning hippocampal replay selectively reinforces spatial memory for highly rewarded locations</article-title><source>Current Biology</source><volume>29</volume><fpage>1436</fpage><lpage>1444</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.03.048</pub-id><pub-id pub-id-type="pmid">31031113</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muessig</surname> <given-names>L</given-names></name><name><surname>Lasek</surname> <given-names>M</given-names></name><name><surname>Varsavsky</surname> <given-names>I</given-names></name><name><surname>Cacucci</surname> <given-names>F</given-names></name><name><surname>Wills</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Coordinated emergence of hippocampal replay and theta sequences during Post-natal development</article-title><source>Current Biology : CB</source><volume>29</volume><fpage>834</fpage><lpage>840</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.01.005</pub-id><pub-id pub-id-type="pmid">30773370</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nádasdy</surname> <given-names>Z</given-names></name><name><surname>Hirase</surname> <given-names>H</given-names></name><name><surname>Czurkó</surname> <given-names>A</given-names></name><name><surname>Csicsvari</surname> <given-names>J</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Replay and time compression of recurring spike sequences in the Hippocampus</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>9497</fpage><lpage>9507</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-21-09497.1999</pub-id><pub-id pub-id-type="pmid">10531452</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Newson</surname> <given-names>P</given-names></name><name><surname>Krumm</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hidden markov map matching through noise and sparseness</article-title><conf-name>17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS 2009)</conf-name><fpage>336</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1145/1653771.1653818</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname> <given-names>HF</given-names></name><name><surname>Carpenter</surname> <given-names>F</given-names></name><name><surname>Barry</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Task demands predict a dynamic switch in the content of awake hippocampal replay</article-title><source>Neuron</source><volume>96</volume><fpage>925</fpage><lpage>935</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.035</pub-id><pub-id pub-id-type="pmid">29056296</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliva</surname> <given-names>A</given-names></name><name><surname>Fernández-Ruiz</surname> <given-names>A</given-names></name><name><surname>Fermino de Oliveira</surname> <given-names>E</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Origin of gamma frequency power during hippocampal Sharp-Wave ripples</article-title><source>Cell Reports</source><volume>25</volume><fpage>1693</fpage><lpage>1700</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.10.066</pub-id><pub-id pub-id-type="pmid">30428340</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname> <given-names>BE</given-names></name><name><surname>Foster</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal place-cell sequences depict future paths to remembered goals</article-title><source>Nature</source><volume>497</volume><fpage>74</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1038/nature12112</pub-id><pub-id pub-id-type="pmid">23594744</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname> <given-names>BE</given-names></name><name><surname>Foster</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Place cells autoassociative dynamics in the generation of sequences of hippocampal place cells</article-title><source>Science</source><volume>349</volume><fpage>180</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1126/science.aaa9633</pub-id><pub-id pub-id-type="pmid">26160946</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranck Jr</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Studies on single neurons in dorsal hippocampal formation and septum in unrestrained rats. I. behavioral correlates and firing repertoires</article-title><source>Experimental Neurology</source><volume>41</volume><fpage>462</fpage><lpage>531</lpage><pub-id pub-id-type="doi">10.1016/0014-4886(73)90290-2</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><collab>SciPy 1.0 Contributors</collab><name><surname>Virtanen</surname> <given-names>P</given-names></name><name><surname>Gommers</surname> <given-names>R</given-names></name><name><surname>Oliphant</surname> <given-names>TE</given-names></name><name><surname>Haberland</surname> <given-names>M</given-names></name><name><surname>Reddy</surname> <given-names>T</given-names></name><name><surname>Cournapeau</surname> <given-names>D</given-names></name><name><surname>Burovski</surname> <given-names>E</given-names></name><name><surname>Peterson</surname> <given-names>P</given-names></name><name><surname>Weckesser</surname> <given-names>W</given-names></name><name><surname>Bright</surname> <given-names>J</given-names></name><name><surname>van der Walt</surname> <given-names>SJ</given-names></name><name><surname>Brett</surname> <given-names>M</given-names></name><name><surname>Wilson</surname> <given-names>J</given-names></name><name><surname>Millman</surname> <given-names>KJ</given-names></name><name><surname>Mayorov</surname> <given-names>N</given-names></name><name><surname>Nelson</surname> <given-names>ARJ</given-names></name><name><surname>Jones</surname> <given-names>E</given-names></name><name><surname>Kern</surname> <given-names>R</given-names></name><name><surname>Larson</surname> <given-names>E</given-names></name><name><surname>Carey</surname> <given-names>CJ</given-names></name><name><surname>Polat</surname> <given-names>İ</given-names></name><name><surname>Feng</surname> <given-names>Y</given-names></name><name><surname>Moore</surname> <given-names>EW</given-names></name><name><surname>VanderPlas</surname> <given-names>J</given-names></name><name><surname>Laxalde</surname> <given-names>D</given-names></name><name><surname>Perktold</surname> <given-names>J</given-names></name><name><surname>Cimrman</surname> <given-names>R</given-names></name><name><surname>Henriksen</surname> <given-names>I</given-names></name><name><surname>Quintero</surname> <given-names>EA</given-names></name><name><surname>Harris</surname> <given-names>CR</given-names></name><name><surname>Archibald</surname> <given-names>AM</given-names></name><name><surname>Ribeiro</surname> <given-names>AH</given-names></name><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>van Mulbregt</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname> <given-names>JD</given-names></name><name><surname>Tang</surname> <given-names>W</given-names></name><name><surname>Jadhav</surname> <given-names>SP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dynamics of awake Hippocampal-Prefrontal replay for spatial learning and Memory-Guided decision making</article-title><source>Neuron</source><volume>104</volume><fpage>1110</fpage><lpage>1125</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.012</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stella</surname> <given-names>F</given-names></name><name><surname>Baracskay</surname> <given-names>P</given-names></name><name><surname>O'Neill</surname> <given-names>J</given-names></name><name><surname>Csicsvari</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hippocampal reactivation of random trajectories resembling brownian diffusion</article-title><source>Neuron</source><volume>102</volume><fpage>450</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.052</pub-id><pub-id pub-id-type="pmid">30819547</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname> <given-names>W</given-names></name><name><surname>Shin</surname> <given-names>JD</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name><name><surname>Jadhav</surname> <given-names>SP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Hippocampal-Prefrontal reactivation during learning is stronger in awake compared with sleep states</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>11789</fpage><lpage>11805</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2291-17.2017</pub-id><pub-id pub-id-type="pmid">29089440</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tingley</surname> <given-names>D</given-names></name><name><surname>Buzsáki</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>Routing of hippocampal ripples to subcortical structures via the lateral septum</article-title><source>Neuron</source><volume>105</volume><fpage>138</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.10.012</pub-id><pub-id pub-id-type="pmid">31784288</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tingley</surname> <given-names>D</given-names></name><name><surname>Peyrache</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>On the methods for reactivation and replay analysis</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>375</volume><elocation-id>20190231</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2019.0231</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trautmann</surname> <given-names>EM</given-names></name><name><surname>Stavisky</surname> <given-names>SD</given-names></name><name><surname>Lahiri</surname> <given-names>S</given-names></name><name><surname>Ames</surname> <given-names>KC</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>O'Shea</surname> <given-names>DJ</given-names></name><name><surname>Vyas</surname> <given-names>S</given-names></name><name><surname>Sun</surname> <given-names>X</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Accurate estimation of neural population dynamics without spike sorting</article-title><source>Neuron</source><volume>103</volume><fpage>292</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.05.003</pub-id><pub-id pub-id-type="pmid">31171448</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tropp Sneider</surname> <given-names>J</given-names></name><name><surname>Chrobak</surname> <given-names>JJ</given-names></name><name><surname>Quirk</surname> <given-names>MC</given-names></name><name><surname>Oler</surname> <given-names>JA</given-names></name><name><surname>Markus</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Differential behavioral state-dependence in the burst properties of CA3 and CA1 neurons</article-title><source>Neuroscience</source><volume>141</volume><fpage>1665</fpage><lpage>1677</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2006.05.052</pub-id><pub-id pub-id-type="pmid">16843607</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Walt</surname> <given-names>S</given-names></name><name><surname>Colbert</surname> <given-names>SC</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The NumPy array: a structure for efficient numerical computation</article-title><source>Computing in Science &amp; Engineering</source><volume>13</volume><fpage>22</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viterbi</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Error bounds for convolutional codes and an asymptotically optimum decoding algorithm</article-title><source>IEEE Transactions on Information Theory</source><volume>13</volume><fpage>260</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1109/TIT.1967.1054010</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>M</given-names></name><name><surname>Foster</surname> <given-names>DJ</given-names></name><name><surname>Pfeiffer</surname> <given-names>BE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Alternating sequences of future and past behavior encoded within hippocampal theta oscillations</article-title><source>Science</source><volume>370</volume><elocation-id>247</elocation-id><pub-id pub-id-type="doi">10.1126/science.abb4151</pub-id><pub-id pub-id-type="pmid">33033222</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waskom</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Seaborn: statistical data visualization</article-title><source>Journal of Open Source Software</source><volume>6</volume><elocation-id>3021</elocation-id><pub-id pub-id-type="doi">10.21105/joss.03021</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilent</surname> <given-names>WB</given-names></name><name><surname>Nitz</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Discrete place fields of hippocampal formation interneurons</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>4152</fpage><lpage>4161</lpage><pub-id pub-id-type="doi">10.1152/jn.01200.2006</pub-id><pub-id pub-id-type="pmid">17392415</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname> <given-names>X</given-names></name><name><surname>Foster</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Hippocampal replay captures the unique topological structure of a novel environment</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>6459</fpage><lpage>6469</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3414-13.2014</pub-id><pub-id pub-id-type="pmid">24806672</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamamoto</surname> <given-names>J</given-names></name><name><surname>Tonegawa</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Direct medial entorhinal cortex input to hippocampal CA1 is crucial for extended quiet awake replay</article-title><source>Neuron</source><volume>96</volume><fpage>217</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.017</pub-id><pub-id pub-id-type="pmid">28957670</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>JY</given-names></name><name><surname>Kay</surname> <given-names>K</given-names></name><name><surname>Liu</surname> <given-names>DF</given-names></name><name><surname>Grossrubatscher</surname> <given-names>I</given-names></name><name><surname>Loback</surname> <given-names>A</given-names></name><name><surname>Sosa</surname> <given-names>M</given-names></name><name><surname>Chung</surname> <given-names>JE</given-names></name><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Larkin</surname> <given-names>MC</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct hippocampal-cortical memory representations for experiences associated with movement versus immobility</article-title><source>eLife</source><volume>6</volume><elocation-id>e27621</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27621</pub-id><pub-id pub-id-type="pmid">28826483</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>JY</given-names></name><name><surname>Frank</surname> <given-names>LM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal-cortical interaction in decision making</article-title><source>Neurobiology of Learning and Memory</source><volume>117</volume><fpage>34</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2014.02.002</pub-id><pub-id pub-id-type="pmid">24530374</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>K</given-names></name><name><surname>Ginzburg</surname> <given-names>I</given-names></name><name><surname>McNaughton</surname> <given-names>BL</given-names></name><name><surname>Sejnowski</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>1017</fpage><lpage>1044</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.2.1017</pub-id><pub-id pub-id-type="pmid">9463459</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.64505.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing Editor</role><aff><institution>McGill University</institution><country>Canada</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Liu</surname><given-names>Yunzhe</given-names> </name><role>Reviewer</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Ólafsdóttir</surname><given-names>H Freyja</given-names> </name><role>Reviewer</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper presents a new framework to decode neuronal activity in the hippocampus during ripple events. This method reveals that most ripple events contain spatially interpretable content that often progresses at timescales slower than previously reported and that appears to better match previous wake activity at real time. These findings challenge the classical view of replay as primarily time-compressed representation of previous wake activity and provide a fuller picture of the repertoire of possible content for ripple events during rest.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Hippocampal replay of experience at real-world speeds&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Timothy Behrens as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Yunzhe Liu (Reviewer #1); H Freyja Ólafsdóttir (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>In the present study, the authors report that the proportion of candidate replay events in the hippocampus showing spatially interpretable content is much higher than previously described. In addition, these events often progress at slow (&quot;real-world&quot;) timescales while it is generally assumed that hippocampal replay is compressed in time. Specifically, the authors have used a state space model that captures the spatial content and temporal evolution of replay. This model is based on few assumptions and is aimed to be unbiased – as it is based on &quot;clusterless&quot; extracellular spikes. While the three reviewers are generally enthusiastic about the work and agree that this study is potentially suitable for <italic>eLife</italic>, they have raised several concerns that should be addressed to warrant publication. The main concerns are summarized below, please refer to the detailed reviewer's comments for more information.</p><p>Essential revisions:</p><p>1. The authors should further test their method on exploration data to validate the approach, especially since non place cells may potentially bias the decoding of animal's speed in clusterless data (see reviewer #3 point #1). This analysis of hippocampal activity during run can be used to identify the encoded speed in within theta sequences (reviewer #1, point #2).</p><p>2. The authors have to improve controls, especially their shuffling procedures. Shuffling the spike-location relationship is too permissive. See reviewer #2, point #1 and reviewer #3, point #9.</p><p>3. The authors should use more stringent thresholds on speed and theta power to rule out the possibility that some of the events are not replays but represent current position. See reviewer #2, points #2-3.</p><p>4. The classification of candidate replay events should be improved (especially events that may be partially &quot;unclassified&quot;) and the authors should provide a more detailed comparison of the replay events detected with their method and with previously described methods (reviewer #3, points #2-3)</p><p>5. The authors should provide descriptive statistics demonstrating that spiking properties during candidate replay events (e.g. average rate per tetrode) are similar between sorted and clusterless data (reviewer #3 point #6-7). Only events in which spikes are detected on multiple tetrodes should be included, to prevent decoding from the firing of a single cell. Finally, spikes of putative inhibitory neurons should be discarded (reviewer #3, point #7).</p><p>6. The authors have used neuronal data collected from the different subcircuits of the hippocampus (CA1-3). It should be demonstrated that the main results hold if the analysis is restricted to CA1, on which most of previously published studies are based, especially since it can affect the nature of replay events. Is there a relationship between the category (e.g. continuous or stationary) of a given replay event and the proportion of neurons from the different substructures that fired during that event? Also, discussing the seemingly low proportion of continuous events (if the same proportion is observed when only including CA1 neurons). See reviewer #2, point #4 and reviewer #3, points #4-5.</p><p>7. The title of the manuscript is a bit misleading as the reported replayed speeds are often even slower than &quot;real-world speed&quot; and should therefore be changed. See reviewer #1, point #1 and reviewer #3, point #8.</p><p>8. The authors should further discuss the implication of their findings. See reviewer #1, point #3 and reviewer #2, point #4.</p><p>9. Please note that reviewer #3 has also raised a couple of minor concerns that should be addressed.</p><p><italic>Reviewer #1:</italic></p><p>Denovellis et al. have developed a state space model approach for unbiased replay detection. As a result, they are able to demonstrate that most of the candidate replay events (i.e., sharp wave ripple events) contains spatial coherent (stationary or continuous) content, and they progress at a relative lower speed (&lt; 1m/s) than previously believed.</p><p>I like this paper a lot. The writing is very clear, and the analysis is thorough. The proposed method is likely to be very impactful and widely adopted in the replay community.</p><p><italic>Reviewer #2:</italic></p><p>Denovel and colleagues develop and apply a state space model to decode position representation during hippocampal SWR events. The main advantage of this model is that is makes fewer assumptions of the dynamics of SWR events allowing it capturing varying and mixed movement dynamics. Through the application of this model the authors are able to decode coherent spatial content from the vast majority (~90%) of SWR events – a much, much higher proportion than previous papers on the topic have reported – and they show that, contrary to previous work, the most common type of movement dynamic during SWR events is one that's characterised by a stationary/slow movement speeds.</p><p>I believe the work by Denove and colleagues represents a significant advance in our understanding of SWR events. Moreover, the state space method Denove et al. described also represents useful analytical tool which could potentially be useful to many neuroscientists in the field. I would also like to commend the authors for their clear and detailed explanation of the model.</p><p>I do however have some concerns about the robustness of their SWR event method and some of their control analyses. Below I explain these in more details and suggest ways to address these concerns. All suggestions are implementable and would, I believe, significantly strengthen the authors' conclusions.</p><p>1. To control for spurious SWR events (containing spatially coherent content), the authors shuffle the position-spike relationship. Although this type of control analysis is commonly used, it can be overly permissive, particularly if researchers are working with small-to-medium samples sizes. This is because for smaller samples sizes it is unlikely that all positions are represented equally by the cell population (which is an assumption of the control analysis). However, given the authors are using clusterless decoding, a cell ID shuffle is not possible. Thus to address this potential caveat, it would be useful if the authors show position representation in their cell population on the W-maze? Moreover, if the position representation is not equal throughout the environment the authors need to account for this in their position resampling with replacement control analysis.</p><p>2. The authors use a speed threshold of 4cm/s to exclude SWR events that may occur during movement periods. Could the authors use a more stringent threshold – e.g. 1cm/sec or 0cm/sec? Although 4cm/sec is low I believe it is important to rule out the possibility that some of their detected spatially coherent SWR events don't merely reflect the movement of the animal during the event. This is particularly important given their finding that the most common type of replay event is one that is characterised by slow movement speeds – akin to those seen during actual behaviour.</p><p>3. Related to this, the authors could also use low theta power as an additional quality criteria to weed out events that may reflect (slow) movement periods.</p><p>4. One of the main findings of the paper is that SWR events can consist of different types of movement dynamics (stationary, continuous, fragmented) or a mixture of dynamics. This is indeed an interesting and novel finding, but it would be useful if the authors could elaborate on the theoretical implications of different type of replay events. For example, do the authors think SWR events belonging to different movement dynamic categories are supported by different sub-circuits within the hippocampus? For example, some work has shown SWR events preceded by EC activity are longer in duration Oliva et al. (2016).</p><p><italic>Reviewer #3:</italic></p><p>The authors of this study investigated the prevalence and range of representational dynamics associated with replay activity in the rat hippocampus during periods of rest following a spatial alternation task in a W-shape maze. Using a state space model that captures the spatial content and temporal evolution of replay during sharp-wave ripple activity, the authors report that most ripple events contain spatially interpretable content that often progresses at timescales slower than previously reported and that appears to better match previous wake activity at real time. The reported findings challenge the classical view of replay as primarily time-compressed representation of previous wake activity and build on previous work on stationary events and reduced proportion of significant trajectory replay events to provide a fuller picture of the repertoire of possible content for ripple events during rest. While the results are intriguing, a number of conceptual and technical shortcomings prevent a more enthusiastic appreciation of this work in its current state, as detailed below.</p><p>1. The main Bayesian model needs to be tested first during run on track, where the prior is being built. The authors need to compute the error of the model during run in terms of the difference between the decoded position during run and the actual animal trajectory. If, for any reason, the model appears stationary during run at any trial/lap, then the authors will need to take that into account when claiming stationarity during rest. In particular, clusterless decoding may make use of spikes that are not spatially well modulated and that would appear to support the stationary events during rest.</p><p>2. Please use more stringent classification of the events. As the current relaxed criterion for classifying events only requires a portion of the event to exhibit that behavior, what proportion of events classified as 'stationary' or 'continuous' significantly pass traditional, rigorous event-matched shuffles? What proportion of extended stationary events, &gt;100 ms for instance, have a line-fit replay score above the 95th percentile of event-matched shuffles (circular shifting of posterior decoded probabilities) and a trajectory length shorter than a certain value, e.g. 6 cm? Similarly, what proportion of continuous trajectories pass their respective event-matched shuffles? What proportion of stationary events are entirely stationary? The authors need to quantify all of the above and present them in the Results.</p><p>3. One significant conclusion of this paper is that most population events during awake rest are stationary-continuous mixtures or stationary as opposed to continuous (replay) events. However, given that an event is classified as stationary if part of the event is stationary (probability &gt;0.8), there is a possibility that the rest of the event is unclassified (no clear structure). In plots 3G, 5A-F it is important to include details about the unclassified ripples and the unclassified parts of the ripple which is otherwise classified. For instance, in 5A, the proportion of ripples with parts that are unclassified needs to be mentioned. This is important because parts of the event might be stationary, and parts might be noise/unclassified. Previous studies have characterized events as stationary only if they were stationary throughout the event and had excess stationarity than the 95th percentile of an event-based shuffle. How many of the events classified as stationary pass this significance criterion? This relaxed classification might otherwise lead to over-classification of certain event types.</p><p>4. The reported results are based on combined recordings from 3 hippocampal areas: CA1, CA2, and CA3 (conform Methods). These areas have different cell types, some of which respond to animal stationarity rather than movement. This makes classification and comparison of all event types between this study and the previous studies reporting on CA1 place cells only which were active on simpler tasks on linear tracks difficult. The authors should restrict their analysis to tetrodes located exclusively in CA1 when computing proportions of event types and only then compare their results to previous studies reporting on significant replay and stationary events. To make this comparison even more interpretable, similar significance tests against shuffles and use of clustered data (available for 9 out of the 10 animals that were previously published) should be performed. If the presented proportions of events persist under these conditions, the impact of the findings will be significantly increased.</p><p>5. There is discrepancy in proportion of replay events reported here compared to previous studies. Continuous events are most similar to traditionally detected replay sequences, however, those sequences are unidirectional (move from one side of the track to the other to be significant), while these events can move in both directions (model of movement dynamic is symmetric for continuous). The authors should investigate and explain why the proportions of continuous events are less than those of traditionally detected replay sequence events with event-matched shuffles (10-50% in other studies as stated by the authors versus ~5% only continuous).</p><p>6. The properties of each event type need to be compared to rule out other reasons for their distinct spatial and temporal dynamics. These properties to be compared between classes of event types (e.g. stationary, continuous, etc.) include: number of tetrodes active in the event, ripple power, total number of spikes in the event, spikes per bin, event duration, proportion of spikes under 6 ms ISI for each tetrode in each event type, proportion of the event duration it lies in that classification. Could you also confirm that population events included for clusterless decoding are similar in properties to those obtained from clustered data by comparing their properties (duration and z-scored population firing rates across the event)?</p><p>7. There is a possibility that one neuron dominates a population event and, therefore, stationary events are simply single units firing continuously. For instance, Figure 1A for the simulation shows just that, one simulated neuron fires and a stationary event is predicted by the algorithm. As clusterless decoding is used for the main analyses, can only events consisting of multiunit activity from at least 5 tetrodes be included in the analysis? Will the main classes of events be replicated under these conditions? Related to this, interneurons (putative inhibitory neurons) should be removed from the clusterless decoding based on waveform shape as there is a possibility that inclusion of interneurons in the clustering decoding analysis biases results towards detection of stationary events (there might be a hint of this from examples presented in Figure S4 where good stationary events seem to have higher spiking per tetrode compared to continuous events). The event classes should be recomputed and compared with the original classes.</p><p>8. The current title is misleading. There does not appear to be clear evidence of replay at real-world speeds. First, during each run lap, the animal trajectory changes unidirectionally at an estimated speed of 25-35 cm/s. For replay to occur at real time speed, the trajectory decoded during rest should fully unfold at the same speed over 3-4 s for a 1m-long track. This is never reported here, partly because the events are shorter. The stationary events decode individual locations, but there is no indication that they evolve in succession (successive locations at successive times) to represent trajectories at real time speeds. Second, neurons fire in time-compressed theta sequences during run, so neuronal activity is naturally compressed even before replay. Compressed replay essentially already represents space at roughly the same speed as during run (theta sequences).</p><p>9. Bursting of neurons or other individual neuronal properties might lead to classification of successive bins as spatially coherent and/or stationary. In order to control for that possibility, in clustered decoding researchers typically generate shuffled datasets with conserved place map properties by circularly shifting individual place maps. The shuffles generated in this paper randomize the position to spike relationship destroying all single-cell properties. Can shuffles with conserved tetrode multiunit activity properties be generated instead to test this hypothesis? E.g. circularly shift by the same value all spikes from the same tetrode.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Hippocampal replay of experience at real-world speeds&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Timothy Behrens (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>The most critical aspect is about the decoding. During wake, theta sequences should strongly impact the accuracy of the decoding with 2m time bins, but it is unclear why this is not the case. The study should also provide some comparison of decoding accuracy with 2ms and 20ms and provide further details regarding how exactly events are eventually classified (see reviewer #2, points 9-11).</p><p>The study should also include examples showing the differences and similarities in decoding with the clusterless and more classical approaches (see reviewer #2, point #1).</p><p>Some other concerns were raised, mostly requesting clarification in the methods and the discussion of the results. Please see detailed review below (reviewer #2, points #2-8).</p><p><italic>Reviewer #2:</italic></p><p>I am satisfied with the changes the authors have made in their manuscript and the updated manuscript addresses all of my concerns.</p><p>I think the findings are exciting and will contribute to theoretical development in the field. I particularly like that the authors have made the code for their state space model available – this may prove useful for promoting methodological consistency and transparency in the replay field.</p><p><italic>Reviewer #3:</italic></p><p>In the revised manuscript, the authors have partially addressed the previous concerns. The manuscript has improved, and the findings remain potentially interesting. Below, please find additional comments aimed at improving the accuracy and readability of the manuscript:</p><p>1. Due to the various differences from earlier methods (clusterless decoding, state space encoding model, bin size, event detection criteria and quantification of dynamic type: radon transform vs current method), it is difficult to pinpoint which of these differences is leading to the authors' main conclusions. For the general readership, it will be extremely useful to show actual examples of the same decoded spike trains using standard Bayesian decoding (with clustered units) and using state space models. This could reveal any significant differences in the decoded locations which the authors claim are revealed by this method (pages 3 and 4). Since the authors claim there is a substantial difference between the two methods, differences in the inferred dynamics from the two methods should be visible by eye and many such examples should be available.</p><p>2. Is the higher preponderance of stationary/slow events caused by the authors setting of the beginning and ends of events as the start and ends of ripples, rather than using the multiunit population activity (which can span multiple ripples). Can the authors rerun the analysis with multiunit population activity to ensure that the results are not different from previous studies mostly due to how events are detected? Even if the results are due to that, it will be useful to report that to the reader as it will not diminish the impact of these findings (the authors already allude to the fact that the cut off is arbitrary) but will help them understand the reason for the differences between the studies.</p><p>3. Can the authors include a histogram of event duration versus proportion of such events for each of the dynamic so that the reader can better judge what is the likelihood of each event type by duration?</p><p>4. Although the fragmented dynamic would indeed identify discontinuities in decoded locations, how exactly is it better than a non-parametric shuffle? What if the fragmented dynamic has more false-positives or false-negatives?</p><p>5. Are the discovered dynamics restricted to the replay of the animal experience or can they be present before the experience? The authors should discuss this possibility.</p><p>6. How is stationarity a real-world 'speed'? Isn't it a lack of movement? Were only the spikes emitted while the animal was moving used for the encoding model and not those while it was resting? How are then the stationary events replays of that movement? What was the average velocity of the animal during movement? And of the stationary dynamic?</p><p>7. References cited and conclusions drawn from papers are not accurate in some instances, please verify and correct. Several cases are listed below, but the list is larger. Louie and Wilson, Neuron 2001 showed that replay of experience can occur at real-time speed during REM sleep, which should be cited. On lines 67-68 the authors say: &quot;events that represent a single location are only seen in young animals (Stella et al., 2019)&quot;. That study did not investigate young animals, the authors probably meant to refer to (Farooq and Dragoi, 2019), which should be cited. There is a difference between what previous studies have claimed, and what the authors attribute to those studies. For instance, previous studies observed low proportions of sequential trajectories, but they did not observe low proportions of spatially coherent time-bins/cofiring, which are otherwise well-reported and have been observed many times.</p><p>8. How do the authors know that a probability of 0.8 or above can be inferred from downstream neurons as opposed to 0.95? Unless recordings are performed from downstream neurons that cannot really be determined. Both 0.8 and 0.95 face the problem of ambiguity of whether it is interpretable by a downstream neuron, however, a probability of 0.95 will enable readers to judge what happens when events are statistically significant. Can the authors discuss this in the main text?</p><p>9. Very low decoding errors (3-6 cm) during the run at the small timescale employed here (2 ms) may indicate that this method is incapable of capturing theta sequences (which should give a higher decoding error). Instead, they capture stationary dynamics like they do during rest. Larger bins for decoding during run are typically used to study position representation at larger timescales (at bigger timescales than theta sequences) which are likely to have low error. This could be problematic since the current method might be biased toward over-representing the stationary dynamic. The authors should address this in the manuscript.</p><p>10. What happens when a 20 ms time bin is used for state space modelling? Does it reduce the proportion of spatially-coherent events?</p><p>11. Figure 5. When whole ripples are classified as stationary, stationary-continuous mixture and so on, how is this classification done for the whole ripple? The classification of dynamics is done for each 2 ms bin, but what criteria are used to classify the whole ripple? Please provide more details on the intermediate steps. For instance, if an event is stationary, but only has one 2 ms bin which deviates, is it considered stationary-continuous?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.64505.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. The authors should further test their method on exploration data to validate the approach, especially since non place cells may potentially bias the decoding of animal's speed in clusterless data (see reviewer #3 point #1). This analysis of hippocampal activity during run can be used to identify the encoded speed in within theta sequences (reviewer #1, point #2).</p></disp-quote><p>We have added a comparison between the decoded position and the animal’s position to validate our decoding of speed (page 7) as well as added a discussion about the ability of our model to identify speed during theta sequences. We have provided a more detailed response to reviewers #3 and #1 below.</p><disp-quote content-type="editor-comment"><p>2. The authors have to improve controls, especially their shuffling procedures. Shuffling the spike-location relationship is too permissive. See reviewer #2, point #1 and reviewer #3, point #9.</p></disp-quote><p>We have added an additional shuffle where we randomized the order of runs (from one reward well to another) and then circularly permuted the resulting segments of data across all tetrodes uniformly (page 9). This shuffle preserves local spiking correlations (and thus spiking statistics), but the relationship to position is disrupted. We find that our results are very different when our model is applied to these shuffled data as we describe in detail in our response to reviewers #2 and #3 below.</p><disp-quote content-type="editor-comment"><p>3. The authors should use more stringent thresholds on speed and theta power to rule out the possibility that some of the events are not replays but represent current position. See reviewer #2, points #2-3.</p></disp-quote><p>We have performed a control analysis where we required animal speeds to be less than 1 cm/s and achieved similar results (Figure5—figure supplement 2C). We also show in Figure 5 that most of the dynamics do not represent the animal’s current position (although the stationary dynamics often represent the animal’s position). We have provided a more detailed response to reviewer #2 below.</p><disp-quote content-type="editor-comment"><p>4. The classification of candidate replay events should be improved (especially events that may be partially &quot;unclassified&quot;) and the authors should provide a more detailed comparison of the replay events detected with their method and with previously described methods (reviewer #3, points #2-3)</p></disp-quote><p>We included more information about which SWR included times that were unclassified (Figure 5). We also performed a comparison between our method and three previously described methods (Figure 6). We have provided a more detailed response to reviewer #2 below.</p><disp-quote content-type="editor-comment"><p>5. The authors should provide descriptive statistics demonstrating that spiking properties during candidate replay events (e.g. average rate per tetrode) are similar between sorted and clusterless data (reviewer #3 point #6-7). Only events in which spikes are detected on multiple tetrodes should be included, to prevent decoding from the firing of a single cell. Finally, spikes of putative inhibitory neurons should be discarded (reviewer #3, point #7).</p></disp-quote><p>We have included descriptive statistics about the spiking statistics during each of the dynamics (Figure 5—figure supplement 3) as well as performed a control analysis using clustered units (Figure 5—figure supplement 2D). We have clarified in the Methods (page 22) that all the SWR events that we have analyzed included more than 2 tetrodes with spikes and we have included a further control where we required more than 5 tetrodes with spikes (Figure 5—figure supplement 2A). We have also performed a control analysis where we removed spikes with narrow waveforms to exclude spikes from putative interneurons (Figure 5—figure supplement 2B) and another analysis where we included only sorted putative pyramidal cells (Figure 5—figure supplement 2D). We have provided a more detailed response to reviewer #3 below.</p><disp-quote content-type="editor-comment"><p>6. The authors have used neuronal data collected from the different subcircuits of the hippocampus (CA1-3). It should be demonstrated that the main results hold if the analysis is restricted to CA1, on which most of previously published studies are based, especially since it can affect the nature of replay events. Is there a relationship between the category (e.g. continuous or stationary) of a given replay event and the proportion of neurons from the different substructures that fired during that event? Also, discussing the seemingly low proportion of continuous events (if the same proportion is observed when only including CA1 neurons). See reviewer #2, point #4 and reviewer #3, points #4-5.</p></disp-quote><p>We have performed a control analysis where we include only CA1 tetrodes (Figure5—figure supplement 2E). Our dataset does not allow comparison of hippocampal subregions because of the varying number of tetrodes in each region. We have also included a discussion (page 18) of why our proportion of continuous events seem lower than those observed in the literature, but are actually in line with the proportion observed in the literature because of the capability of our model to characterize more than one dynamic per SWR. We have provided a more detailed response to reviewers #2 and #3 below.</p><disp-quote content-type="editor-comment"><p>7. The title of the manuscript is a bit misleading as the reported replayed speeds are often even slower than &quot;real-world speed&quot; and should therefore be changed. See reviewer #1, point #1 and reviewer #3, point #8.</p></disp-quote><p>Here we respectfully disagree. We now provide a plot showing the actual speeds at which the animal moves through the environment, which cover a similar range to those seen during the slower replay events (Figure 5G). We have provided a more detailed response to reviewers #1 and #3 below.</p><disp-quote content-type="editor-comment"><p>8. The authors should further discuss the implication of their findings. See reviewer #1, point #3 and reviewer #2, point #4.</p></disp-quote><p>We have further expanded our discussion to discuss the functional implications of the slower replays and the possible subcircuits that could underlie the different replay speeds within the hippocampal structure (page 19). We have provided a more detailed response to reviewers #1 and #2 below.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>Denovellis and colleagues develop and apply a state space model to decode position representation during hippocampal SWR events. The main advantage of this model is that is makes fewer assumptions of the dynamics of SWR events allowing it capturing varying and mixed movement dynamics. Through the application of this model the authors are able to decode coherent spatial content from the vast majority (~90%) of SWR events – a much, much higher proportion than previous papers on the topic have reported – and they show that, contrary to previous work, the most common type of movement dynamic during SWR events is one that's characterised by a stationary/slow movement speeds.</p><p>I believe the work by Denovellis and colleagues represents a significant advance in our understanding of SWR events. Moreover, the state space method Denove et al. described also represents useful analytical tool which could potentially be useful to many neuroscientists in the field. I would also like to commend the authors for their clear and detailed explanation of the model.</p><p>I do however have some concerns about the robustness of their SWR event method and some of their control analyses. Below I explain these in more details and suggest ways to address these concerns. All suggestions are implementable and would, I believe, significantly strengthen the authors' conclusions.</p><p>1. To control for spurious SWR events (containing spatially coherent content), the authors shuffle the position-spike relationship. Although this type of control analysis is commonly used, it can be overly permissive, particularly if researchers are working with small-to-medium samples sizes. This is because for smaller samples sizes it is unlikely that all positions are represented equally by the cell population (which is an assumption of the control analysis). However, given the authors are using clusterless decoding, a cell ID shuffle is not possible. Thus to address this potential caveat, it would be useful if the authors show position representation in their cell population on the W-maze? Moreover, if the position representation is not equal throughout the environment the authors need to account for this in their position resampling with replacement control analysis.</p></disp-quote><p>We thank the reviewer for this comment. As the reviewer noted, it is important to know how well the spatial environment is represented by cells because this could affect the decode of SWRs. To address this, we have added Figure 2—figure supplement 3 to show that the firing over all our tetrodes is roughly equal for most of our epochs. We believe this is one of the advantages of clusterless decoding in that we have more spikes and therefore are potentially less constrained by worries about under sampling positions in the environment. Furthermore, we also measured the median difference between the most probable decoded position and the animal’s actual position and found a 4 cm median difference (3-6 cm 95% CI), for all time in sessions. This gives us confidence that the cell population has spatial information about all positions in the environment.</p><p>We would also like to note that we directly test for non-spatially coherent content by including the fragmented dynamic in our model, which is what the shuffle tests are aimed at capturing in most analyses. We have added to the Results to clarify this point (page 6).</p><p>In addition, to better illustrate this point, we have added an additional shuffle where we have randomized the order of the runs between wells and circularly permuted the spatial position within the runs to preserve more of the structure of the task (Figure 3—figure supplement 3, page 9). This shuffle increased the prevalence of spatially incoherent dynamics and decreased the prevalence of spatially coherent dynamics as expected, showing that our addition of the fragmented state works well to capture these types of dynamics. The shuffle also substantially increased the spatial extent of the 95% HPD region, indicating that the model was much less certain of the decoded locations even in cases where it identified a dynamic. These results indicate that our results reflect structure in the data, not just structure in the model.</p><disp-quote content-type="editor-comment"><p>2. The authors use a speed threshold of 4cm/s to exclude SWR events that may occur during movement periods. Could the authors use a more stringent threshold – e.g. 1cm/sec or 0cm/sec? Although 4cm/sec is low I believe it is important to rule out the possibility that some of their detected spatially coherent SWR events don't merely reflect the movement of the animal during the event. This is particularly important given their finding that the most common type of replay event is one that is characterised by slow movement speeds – akin to those seen during actual behaviour.</p></disp-quote><p>As per the reviewer’s suggestion, we reran our analysis using a speed threshold of less than 1 cm/s and found a similar distribution of movement dynamics (Figure 5—figure supplement 2C). Also note that the majority of our SWRs occur at speeds less than 1 cm/s (Figure 5—figure supplement 3B). We have also quantified the distance of the decoded trajectory from the animal for stationary-continuous-mixtures (Figure 5C) and found that these represented locations that were some distance away from the animal (median 52 cm). Because of this we are confident that our results are not simply encoding the animal’s position or the result of theta sequences as the animal begins to move.</p><disp-quote content-type="editor-comment"><p>3. Related to this, the authors could also use low theta power as an additional quality criteria to weed out events that may reflect (slow) movement periods.</p></disp-quote><p>We agree that this is a very reasonable suggestion, and in fact we have tried this in the past. Unfortunately, low theta power is difficult to use as a criteria because the sharp wave that occurs during the SWR is also in this same frequency band. In our experience, there is no consistent threshold of theta power (or even theta/δ ratio) that consistently separates immobility from movement times. Because of these challenges, and because of our analysis above, we feel confident that our results are not due to movement of the animal and slow theta sequences.</p><disp-quote content-type="editor-comment"><p>4. One of the main findings of the paper is that SWR events can consist of different types of movement dynamics (stationary, continuous, fragmented) or a mixture of dynamics. This is indeed an interesting and novel finding, but it would be useful if the authors could elaborate on the theoretical implications of different type of replay events. For example, do the authors think SWR events belonging to different movement dynamic categories are supported by different sub-circuits within the hippocampus? For example, some work has shown SWR events preceded by EC activity are longer in duration Oliva et al. (2016).</p></disp-quote><p>As per the reviewer’s suggestion, we have broadened our Discussion to talk about the theoretical implications of the different types of replay events (page 19). In particular, for the slower dynamics: stationary dynamics could be important for recalling specific locations in the environment and stationary-continuous-dynamics could be useful for recalling or evaluating small snippets of the environment. Continuous dynamics could be useful when needing to recall or consolidate an entire trajectory. Finally, fragmented dynamics could correspond to non-spatial memories or memories of other spatial environments. When there are jumps between positions, perhaps these represent instances when several snippets are consolidated in succession.</p><disp-quote content-type="editor-comment"><p>For example, do the authors think SWR events belonging to different movement dynamic categories are supported by different sub-circuits within the hippocampus? For example, some work has shown SWR events preceded by EC activity are longer in duration Oliva et al. (2016).</p></disp-quote><p>It is certainly possible that the different dynamics are driven by different subcircuits within the hippocampus because awake SWRs are influenced by input from outside of the hippocampus, as the reviewer noted. However, due to the varying number of tetrodes in each hippocampal subfield, we are unable to attribute particular dynamics to specific subregions. We have added this to the Discussion (page 19).</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The authors of this study investigated the prevalence and range of representational dynamics associated with replay activity in the rat hippocampus during periods of rest following a spatial alternation task in a W-shape maze. Using a state space model that captures the spatial content and temporal evolution of replay during sharp-wave ripple activity, the authors report that most ripple events contain spatially interpretable content that often progresses at timescales slower than previously reported and that appears to better match previous wake activity at real time. The reported findings challenge the classical view of replay as primarily time-compressed representation of previous wake activity and build on previous work on stationary events and reduced proportion of significant trajectory replay events to provide a fuller picture of the repertoire of possible content for ripple events during rest. While the results are intriguing, a number of conceptual and technical shortcomings prevent a more enthusiastic appreciation of this work in its current state, as detailed below.</p><p>1. The main Bayesian model needs to be tested first during run on track, where the prior is being built. The authors need to compute the error of the model during run in terms of the difference between the decoded position during run and the actual animal trajectory. If, for any reason, the model appears stationary during run at any trial/lap, then the authors will need to take that into account when claiming stationarity during rest. In particular, clusterless decoding may make use of spikes that are not spatially well modulated and that would appear to support the stationary events during rest.</p></disp-quote><p>As per the reviewers suggestion, we computed the median absolute difference between the animal’s most probable decoded position during run and the animal’s actual location, using a five fold cross validation. We found that the median difference between these two quantities was comparable to other studies (4 cm median difference, 3-6 cm 95% CI, for all time in sessions), even though we used 2 ms time bins, rather than the more commonly used 250 ms time bins. We have added this to the Results (page 7). We also note that the slower spatially coherent trajectories had posteriors that were highly spatially concentrated (as characterized by the size of the 95% highest posterior density in Figure 4E). This can only happen if the spikes themselves were from cells that were strongly spatially modulated, ruling out the possibility that the stationary events are driven by cells lacking spatial selectivity.</p><disp-quote content-type="editor-comment"><p>2. Please use more stringent classification of the events.</p></disp-quote><p>As suggested by the reviewer, we have added more comparison between our method and previous methods in the Results (Figure 6). However, we believe that it is a strength of our decoder that the classification of dynamics is not dependent on the entire SWR. The determination of the start and end times of the SWR are somewhat ad hoc and vary greatly from paper to paper. Because of this, other studies have used a procedure where the stop and start is determined by the decode and not the multiunit or SWR event boundary (Xu and Csicsvari 2019, Pfeiffer and Foster 2015). Using the whole SWR for determination of the trajectory means any noise or spatially incoherent period during the SWR could cause the whole event to be thrown out and not analyzed. Our method allows us to characterize the content of all SWRs, rather than exclude certain SWRs because the SWR does not fit our assumptions about constant velocity trajectories. Furthermore, we have shown that the spatially coherent dynamics that we characterize are sustained in duration (Figure 5, stationary-continuous-mixtures have a median duration of 73 ms for example). Finally, we and others have shown examples where there are multiple dynamics in a single SWR (Figure 3, Figure 3—figure supplement 1, Pfeiffer and Foster 2015), so we think it would be inappropriate to classify these types of events as a single dynamic. We have clarified this in the manuscript (pages 11, 18).</p><disp-quote content-type="editor-comment"><p>As the current relaxed criterion for classifying events only requires a portion of the event to exhibit that behavior, what proportion of events classified as 'stationary' or 'continuous' significantly pass traditional, rigorous event-matched shuffles?</p></disp-quote><p>As requested by the reviewer, we have performed the comparison of our dynamics to the standard Bayesian decoder that passed event-matched shuffles (page 15). These were all based on a Radon line fit with 20 ms bins, have a replay score with p &lt; 0.05 using a circular shuffle of the posterior values for each time bin, and use clusterless decoding. We chose this method as the “traditional” method, but please note, as we mentioned in our Introduction, that there are many other methods that have been used in the replay field. We would like to emphasize that the dynamics captured by our decoder are not required to be present for the entire SWR while the line is fit over the entire SWR, so the comparison is, in our opinion, hard to interpret. However, we agree with the reviewer that, despite these limitations, it is useful to have this comparison for others in the field to understand the differences between the methods, so we have included them here and in the manuscript (Figure 6):</p><p>– 8% (542 of 7176) of SWRs containing stationary dynamics with p &lt; 0.05.</p><p>– 14% (2253 of 16106) of SWRs containing stationary-continuous-mixtures dynamics with p &lt; 0.05.</p><p>– 31% (1368 of 4511) of SWRs containing continuous dynamics with p &lt; 0.05.</p><p>– 31% (799 of 2562) of SWRs containing fragmented-continuous dynamics with p &lt; 0.05.</p><p>– 15% (244 of 1598) of SWRs containing fragmented dynamics with p &lt; 0.05.</p><disp-quote content-type="editor-comment"><p>What proportion of extended stationary events, &gt;100 ms for instance, have a line-fit replay score above the 95th percentile of event-matched shuffles (circular shifting of posterior decoded probabilities) and a trajectory length shorter than a certain value, e.g. 6 cm?</p></disp-quote><p>28% of extended stationary events have a line-fit replay score with p &lt; 0.05.</p><disp-quote content-type="editor-comment"><p>Similarly, what proportion of continuous trajectories pass their respective event-matched shuffles?</p></disp-quote><p>30% of SWRs with continuous dynamics have a line-fit replay score with p &lt; 0.05.</p><disp-quote content-type="editor-comment"><p>What proportion of stationary events are entirely stationary? The authors need to quantify all of the above and present them in the Results.</p></disp-quote><p>47% of SWRs containing the stationary dynamics are entirely stationary. We have added all of these quantifications to the results.</p><disp-quote content-type="editor-comment"><p>3. One significant conclusion of this paper is that most population events during awake rest are stationary-continuous mixtures or stationary as opposed to continuous (replay) events. However, given that an event is classified as stationary if part of the event is stationary (probability &gt;0.8), there is a possibility that the rest of the event is unclassified (no clear structure). In plots 3G, 5A-F it is important to include details about the unclassified ripples and the unclassified parts of the ripple which is otherwise classified. For instance, in 5A, the proportion of ripples with parts that are unclassified needs to be mentioned. This is important because parts of the event might be stationary, and parts might be noise/unclassified.</p></disp-quote><p>We agree with the reviewer that including information about the unclassified times is important in order to fully characterize the SWRs. As suggested, we included the unclassified categorization in Figure 5 to give the readers a sense for how often the unclassified category occurs, the duration of these time periods, and the multiunit firing during these time periods. We have also included the unclassified category in Figure 5—figure supplement 3 to add information about the ripple power, spikes per bin, and number of spikes per tetrode.</p><disp-quote content-type="editor-comment"><p>Previous studies have characterized events as stationary only if they were stationary throughout the event and had excess stationarity than the 95th percentile of an event-based shuffle. How many of the events classified as stationary pass this significance criterion?</p></disp-quote><p>5% of events classified as stationary were significant at the 0.05 level using the standard Bayesian decoder with Radon transform line fit. We feel that our findings argue strongly against trusting this 5% number as an indication that there are no meaningful stationary events.</p><disp-quote content-type="editor-comment"><p>This relaxed classification might otherwise lead to over-classification of certain event types.</p></disp-quote><p>We hope that we have addressed this issue in the answers above and in the text (page 15), and we want to emphasize that given that many events contain multiple dynamics, the standard line-fitting approaches are problematic in terms of accurately capturing the way that representations move during these events. The goal of our approach is to provide information about the sorts of representational dynamics that are present and that could provide information to downstream structures, and for that goal, we felt that a threshold of 0.80 was reasonable. That said, future work that examines how these events influence activity and plasticity should help us refine these classifications further.</p><disp-quote content-type="editor-comment"><p>4. The reported results are based on combined recordings from 3 hippocampal areas: CA1, CA2, and CA3 (conform Methods). These areas have different cell types, some of which respond to animal stationarity rather than movement. This makes classification and comparison of all event types between this study and the previous studies reporting on CA1 place cells only which were active on simpler tasks on linear tracks difficult. The authors should restrict their analysis to tetrodes located exclusively in CA1 when computing proportions of event types and only then compare their results to previous studies reporting on significant replay and stationary events.</p></disp-quote><p>As requested by the reviewer, we performed a control analysis where we only used CA1 tetrodes for clusterless decoding. We found similar dynamics as reported in the main result of the paper (Figure 5—figure supplement 2E).</p><p>However, we would like to point out that several studies (e.g. Diba and Buszaki 2007, Karlsson and Frank 2009) investigating replay have used cells from multiple subregions within the hippocampus. Second, we have also found cells show place specific activity during immobility across CA1, CA2 and CA3 (Yu et al. 2017, Kay et al. 2016). Finally, we have also found that CA1 and CA3 spiking are largely coordinated within and across hemispheres during awake SWR replay (Carr et al. 2012). For these reasons, we feel our main analysis should not exclude CA2 and CA3 tetrodes.</p><disp-quote content-type="editor-comment"><p>To make this comparison even more interpretable, similar significance tests against shuffles and use of clustered data (available for 9 out of the 10 animals that were previously published) should be performed. If the presented proportions of events persist under these conditions, the impact of the findings will be significantly increased.</p></disp-quote><p>We appreciate this point, and carried out an analysis of replays events based on clustered data. The results were very similar (Figure 5—figure supplement 2D).</p><disp-quote content-type="editor-comment"><p>5. There is discrepancy in proportion of replay events reported here compared to previous studies. Continuous events are most similar to traditionally detected replay sequences, however, those sequences are unidirectional (move from one side of the track to the other to be significant), while these events can move in both directions (model of movement dynamic is symmetric for continuous). The authors should investigate and explain why the proportions of continuous events are less than those of traditionally detected replay sequence events with event-matched shuffles (10-50% in other studies as stated by the authors versus ~5% only continuous).</p></disp-quote><p>The reviewer brings up an important point that we failed to clarify in the text. We believe that there is not a discrepancy in the proportion of replay events in our study compared to previous studies. Our decoder is much more flexible in terms of allowing different speeds during the SWR event, so an event that might have been characterized as having constant high speed for the entire event might actually have some time periods that have slower trajectories, even if the majority the time the trajectory proceeds at a higher speed (see Figure 2 for example). Accordingly, we still find 19% of classified SWR events contain continuous trajectories, which is consistent with those previous studies, and these continuous trajectories persist for a considerable duration (median 94 ms, Figure 5B). As the reviewer noted, only 5% of SWRs have continuous dynamics throughout the entire duration of the SWR, but we feel that restricting our analyses to dynamics which last the entire SWR is a limited characterization of the SWR, particularly given that we observed SWRs with multiple dynamics. Finally, we have also used a less strict threshold for including SWRs and interpreted a much larger fraction of these SWRs, so the percentage may be hard to compare between studies. We have added this clarification to the text (page 18).</p><disp-quote content-type="editor-comment"><p>6. The properties of each event type need to be compared to rule out other reasons for their distinct spatial and temporal dynamics. These properties to be compared between classes of event types (e.g. stationary, continuous, etc.) include; number of tetrodes active in the event, ripple power, total number of spikes in the event, spikes per bin, event duration, proportion of spikes under 6 ms ISI for each tetrode in each event type, proportion of the event duration it lies in that classification.</p></disp-quote><p>We thank the reviewer for this suggestion. We have added these statistics as a supplementary figure (Figure 5—figure supplement 3). These statistics confirm that slower dynamics are not driven by a single neuron as there are many tetrodes active for each dynamic and there are multiple spikes from different tetrodes in each time bin. There is also little evidence for more bursting in the slower dynamics compared to the continuous dynamics because we observed a similar proportion of spikes under 6 ms ISI for the slow dynamics. Only ~50% of the spikes had ISIs of less than 6 ms in the stationary, stationary-continuous, and continuous dynamics (Figure 5—figure supplement 3). It should be noted that this metric should be interpreted with extreme caution because with clusterless decoding, the ISI of the multiunit spikes is not the same as if we had an individual unit. The spikes could be from multiple neurons firing, which would not tell us if there was bursting or not. Finally, these statistics show similar ripple power for all our dynamics as well as a tendency for the unclassified time periods during the SWR to have lower average ripple power.</p><disp-quote content-type="editor-comment"><p>Could you also confirm that population events included for clusterless decoding are similar in properties to those obtained from clustered data by comparing their properties (duration and z-scored population firing rates across the event)?</p></disp-quote><p>We apologize for the confusion regarding our event detection method. In this manuscript, we analyzed SWR events which are detected based on the combined instantaneous ripple-band power of CA1 LFPs and not based on high multiunit firing rate, as many studies have done (Xu et al. 2019, Farooq and Dragoi 2019, Drieu et al. 2018, Ólafsdóttir et al. 2017, Grossmark and Buzsáki 2016, Pfeiffer and Foster 2013, Davidson et al. 2009). Therefore, we are not able to compare the multiunit and clustered events because they are not selected on this basis.</p><disp-quote content-type="editor-comment"><p>7. There is a possibility that one neuron dominates a population event and, therefore, stationary events are simply single units firing continuously. For instance, Figure 1A for the simulation shows just that, one simulated neuron fires and a stationary event is predicted by the algorithm. As clusterless decoding is used for the main analyses, can only events consisting of multiunit activity from at least 5 tetrodes be included in the analysis? Will the main classes of events be replicated under these conditions?</p></disp-quote><p>As suggested by the reviewer, to exclude the possibility that a single neuron firing is the cause of stationary events, we performed a control analysis where we required spiking from at least 5 tetrodes for a SWR to be analyzed and found a similar distribution of movement dynamics (Figure 5—figure supplement 2A). It also should be noted that our original analysis required at least 2 tetrodes to be active for a SWR to be analyzed and we have clarified this in the Methods (page 22). We have also included a histogram of the number of active tetrodes per SWR event (Figure 5—figure supplement 3B) as well as a boxplot of the number of active tetrodes by dynamic (Figure 5—figure supplement 3B). These show that well over 5 tetrodes are active in each dynamic and during the SWR events.</p><disp-quote content-type="editor-comment"><p>Related to this, interneurons (putative inhibitory neurons) should be removed from the clusterless decoding based on waveform shape as there is a possibility that inclusion of interneurons in the clustering decoding analysis biases results towards detection of stationary events (there might be a hint of this from examples presented in Figure S4 where good stationary events seem to have higher spiking per tetrode compared to continuous events). The event classes should be recomputed and compared with the original classes.</p></disp-quote><p>As requested by the reviewer, we performed a control analysis where we excluded spikes with narrow waveform spike widths (&lt;0.3 ms), which would preferentially exclude spikes from putative interneurons. We again found a similar distribution as in our main results (Figure 5—figure supplement 2B). However, we should note several caveats to this approach. First, interneurons are typically identified by both their high firing rate and the average narrow spike width waveforms. Our approach only considered the spike width for each individual spike (not average) and therefore may be much less discriminating and remove many spikes that may contain spatial information. Second, it is not clear that interneurons should be excluded. Interneurons can have spatially specific firing and may contain information about the position represented by the hippocampus (Hangya et al. 2010, Wilent and Nitz 2007). Third, if interneurons were not spatially specific and driving the slower dynamics, we would expect to see the posterior be less spatially concentrated. Instead, we found that these dynamics tended to have narrow posteriors (as characterized by spatial coverage of the 95% highest posterior density values in Figure 4E).</p><p>Finally, we performed a third control analysis where we also looked at the 9 of 10 animals in our dataset that already had clustered cells, excluding putative interneurons based on spike width and firing rate and requiring that at least three putative pyramidal cells be active during the SWR. Although there were many fewer events to examine, we still observed many stationary and stationary-continuous-mixtures in SWRs compared to continuous sequences (Figure 5—figure supplement 2D).</p><disp-quote content-type="editor-comment"><p>8. The current title is misleading. There does not appear to be clear evidence of replay at real-world speeds. First, during each run lap, the animal trajectory changes unidirectionally at an estimated speed of 25-35 cm/s. For replay to occur at real time speed, the trajectory decoded during rest should fully unfold at the same speed over 3-4 s for a 1m-long track. This is never reported here, partly because the events are shorter. The stationary events decode individual locations, but there is no indication that they evolve in succession (successive locations at successive times) to represent trajectories at real time speeds.</p></disp-quote><p>We thank the reviewer for this comment. As the reviewer stated, the slower trajectories cannot span the same amount of distance as when the animal is moving at slow speeds because of the duration of the SWR. Our claim in the title and in the rest of the manuscript is that the speed of the decoded trajectory over the duration of the SWR is often similar to the speeds at which the animal experiences the environment, which includes times when the animal is immobile and times when the animal is running. This does indeed imply that the replay trajectory does not move very far. We have clarified this in the text (pages 12) and added a figure showing the distribution of speeds of the animal (Figure 5G). As this figure shows, there is substantial overlap between the movement speeds seen during replay and real movement speeds.</p><disp-quote content-type="editor-comment"><p>Second, neurons fire in time-compressed theta sequences during run, so neuronal activity is naturally compressed even before replay. Compressed replay essentially already represents space at roughly the same speed as during run (theta sequences).</p></disp-quote><p>The reviewer brings up an interesting and important point. Individual theta cycles can contain extended sequences spanning locations behind and in front of the animal, but other theta cycles can show much less prominent sequences, resulting in a range of potential representational movement speeds. In addition, a recent result reported quite different dynamics for the first and second halves of theta cycles (Wang et al. 2020).</p><p>Whether replay sequences are essentially the same as theta sequences remains to be determined, but we have noted that our methods could be used to study these sequences as well.</p><p>We emphasize, though, that the goal of this paper is to establish that replay sequences can proceed at a variety of speeds. We hope in future manuscripts to directly address the similarities and differences between replay and theta sequences using our approach.</p><disp-quote content-type="editor-comment"><p>9. Bursting of neurons or other individual neuronal properties might lead to classification of successive bins as spatially coherent and/or stationary. In order to control for that possibility, in clustered decoding researchers typically generate shuffled datasets with conserved place map properties by circularly shifting individual place maps. The shuffles generated in this paper randomize the position to spike relationship destroying all single-cell properties. Can shuffles with conserved tetrode multiunit activity properties be generated instead to test this hypothesis? E.g. circularly shift by the same value all spikes from the same tetrode.</p></disp-quote><p>The reviewer brings up an important point, which highlights our use of small time bins. Our time bins are 2 ms, which implies spike bursts (3-8 ms ISI, 2-3 spikes per burst, Tropp Sneider et al. (2006)) could fall in separate, potentially successive time bins as the reviewer noted (although the average ISI is ~6 ms so it’s likely not the case, Tropp Sneider et al. (2006)). Note that our use of 2 ms time bins is an advantage over the standard 20 ms time bins because with 20 ms time bins, either most of these spikes fall into one time bin, making the estimate stationary over the 20 ms time bin or the spikes could fall into two 20 ms time bins, making the estimate stationary over 40 ms; with our approach, the stationary period could only last for approximately as long as the burst modulo 1 or 2 ms.</p><p>As the reviewer stated, spike bursts from a single neuron could lead to successive time bins being classified as stationary. There are two lines of evidence that make us think that this is not the case. First, the stationary dynamics have a longer duration than one would expect from a burst alone (54 ms median duration, 38-74 ms quartiles vs. bursts which have a duration of 6-24 ms). Second, thanks to a previous suggestion of this reviewer, we know that multiple tetrodes are active during each SWR (Figure 5—figure supplement 3B), there are often multiple spikes from different tetrodes in a given time bin (Figure 5—figure supplement 3A), and the proportion of spikes under 6 ms for stationary dynamics is similar to those as stationary-continuous-mixtures and continuous dynamics (Figure 5—figure supplement 3A). Moreover, our main claim in the manuscript is that the stationary-continuous-mixtures constitute the bulk of dynamics in SWRs, which can only happen with more than one tetrode active.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>The most critical aspect is about the decoding. During wake, theta sequences should strongly impact the accuracy of the decoding with 2m time bins, but it is unclear why this is not the case.</p></disp-quote><p>The number we reported included both times when the animal was immobile and times when the animal was running. Because of this, the decoding accuracy was not strictly computed on times when theta was most prevalent. To prevent confusion for the readers, we have changed the decoding accuracy to be measured only on the times when the animal was moving. This resulted in a change of decoding accuracy from a median error of 4 cm <italic>(3-6 cm) to</italic> 7 cm (5-9 cm), which is in line with most previous results. We also note that we show an example of decoding during movement in a separate manuscript that uses a version of this algorithm (Gillespie et al. Biorxiv 2021, Figure 2B) which illustrates its capacity to detect theta sequences.</p><disp-quote content-type="editor-comment"><p>The study should also provide some comparison of decoding accuracy with 2ms and 20ms and provide further details regarding how exactly events are eventually classified (see reviewer #2, points 9-11).</p></disp-quote><p>We clarified this issue regarding decoding accuracy with Dr. Peyrache and have therefore not included this first analysis.</p><p>For the second analysis we now provide further details on the classification of events on page 26 and in our response to the reviewer. We also clarified this issue with Dr. Peyrache.</p><disp-quote content-type="editor-comment"><p>The study should also include examples showing the differences and similarities in decoding with the clusterless and more classical approaches (see reviewer #2, point #1).</p></disp-quote><p>We have added six examples comparing the differences in decoding with clusterless and more classical approaches in a new supplemental figure: Figure 6—figure supplement 1.</p><disp-quote content-type="editor-comment"><p>Some other concerns were raised, mostly requesting clarification in the methods and the discussion of the results. Please see detailed review below (reviewer #3, points #2-8).</p><p>Reviewer #3:</p><p>In the revised manuscript, the authors have partially addressed the previous concerns. The manuscript has improved, and the findings remain potentially interesting. Below, please find additional comments aimed at improving the accuracy and readability of the manuscript:</p><p>1. Due to the various differences from earlier methods (clusterless decoding, state space encoding model, bin size, event detection criteria and quantification of dynamic type: radon transform vs current method), it is difficult to pinpoint which of these differences is leading to the authors' main conclusions. For the general readership, it will be extremely useful to show actual examples of the same decoded spike trains using standard Bayesian decoding (with clustered units) and using state space models. This could reveal any significant differences in the decoded locations which the authors claim are revealed by this method (pages 3 and 4). Since the authors claim there is a substantial difference between the two methods, differences in the inferred dynamics from the two methods should be visible by eye and many such examples should be available.</p></disp-quote><p>We thank the reviewer for this great suggestion. We have added six examples of the fits from three different methods in a new supplemental figure: Figure 6-supplemental1. These examples illustrate the variety of event types seen and the challenges inherent in using 20 ms bins and standard “Bayesian” decoding approaches.</p><disp-quote content-type="editor-comment"><p>2. Is the higher preponderance of stationary/slow events caused by the authors setting of the beginning and ends of events as the start and ends of ripples, rather than using the multiunit population activity (which can span multiple ripples). Can the authors rerun the analysis with multiunit population activity to ensure that the results are not different from previous studies mostly due to how events are detected? Even if the results are due to that, it will be useful to report that to the reader as it will not diminish the impact of these findings (the authors already allude to the fact that the cut off is arbitrary) but will help them understand the reason for the differences between the studies.</p></disp-quote><p>As requested by the reviewer, we reran the analysis using times of high multiunit activity during immobility and found that the distribution of slow dynamics is qualitatively similar. Thus, the preponderance of slow events does not seem to be a result of using sharp wave ripple rather than events with high multiunit activity. We have included this as Figure5—figure supplement 2F in the manuscript. This also corroborates our finding that these slow dynamics have similar multiunit firing rates to the higher speed, continuous dynamics (Figure 5F).</p><disp-quote content-type="editor-comment"><p>3. Can the authors include a histogram of event duration versus proportion of such events for each of the dynamic so that the reader can better judge what is the likelihood of each event type by duration?</p></disp-quote><p>We are unclear on whether proportion in this case refers to proportion relative to the length of the sharp wave ripple or whether proportion refers to over a recording session. We have included both here as <xref ref-type="fig" rid="respfig1">Author response image 1</xref> and <xref ref-type="fig" rid="respfig2">Author response image 2</xref>. Given that we already show the distributions of dynamics per SWR and the distributions of the durations of the dynamics in main figures, it is not clear to us that these Author response images will substantially augment a reader’s understanding of our results, so we have not included them in the manuscript, but if the reviewer feel strongly that they need to be included we can do so.</p><fig id="respfig1"><label>Author response image 1.</label><caption><title>Proportion of SWRs for each day vs duration of the dynamic within the SWR.</title><p>Each dot represents one day for one animal.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-resp-fig1-v2.tif"/></fig><fig id="respfig2"><label>Author response image 2.</label><caption><title>For each dynamic, the duration of the dynamic vs the proportion of time of the total SWR duration.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64505-resp-fig2-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>4. Although the fragmented dynamic would indeed identify discontinuities in decoded locations, how exactly is it better than a non-parametric shuffle? What if the fragmented dynamic has more false-positives or false-negatives?</p></disp-quote><p>All statistical methods have trade-offs. However, we believe that our fragmented state directly tests for “random” on a moment-by-moment basis. This is an advantage because non-parametric methods cannot do this on a moment-by-moment basis thereby potentially excluding content of interest. Shuffles also can require much time for computation often leading to small numbers of shuffles, which can make the tests underpowered. Finally, shuffles can lead to pathological null distributions which cannot occur in real data and therefore do not test against the null hypothesis of interest (e.g Foster 2017, van der Meer et al. 2020). Thus, including the fragmented dynamic preserves the existing data while still testing for the different dynamics. More broadly, testing for false-positives and false-negatives requires a model of what a true positive and a true negative is. The state space approach provides a relatively simple, interpretable version of such a model, while the model associated with a shuffle is often harder to define and understand. We have added this point to the Discussion.</p><disp-quote content-type="editor-comment"><p>5. Are the discovered dynamics restricted to the replay of the animal experience or can they be present before the experience? The authors should discuss this possibility.</p></disp-quote><p>Our study was not focused on these types of events but indeed our model could be used to discover dynamics present for the experience. We added this point to the Discussion that we could use this model to detect dynamics before the event (page 20).</p><disp-quote content-type="editor-comment"><p>6. How is stationarity a real-world 'speed'? Isn't it a lack of movement? Were only the spikes emitted while the animal was moving used for the encoding model and not those while it was resting? How are then the stationary events replays of that movement? What was the average velocity of the animal during movement? And of the stationary dynamic?</p></disp-quote><p>To answer the first question, the animal’s experience is not limited to running. The animals can stop at any position on the track, and thus a real world experience can include movement and immobility at any given position.</p><p>We only used spikes that occurred in association with speeds of &gt; 4 cm / second in the encoding model. We had mentioned that in the Methods for the single spike analysis, but we had neglected to do so for the clusterless analysis, so we have added that information. We note, however, that place specific spiking in a location can continue even when animals are still (Kay et al. 2016; Yu et al. 2017), so using this encoding model still allows for the identification of periods of immobility or slow movement in a decoded representation. More importantly, stationary events are those that have slow velocity, but nowhere do we claim that this velocity is &lt; 4 cm/second. Indeed, given our bin size of 3 cm, a 100 ms event could be moving at (for example) 10 cm /second and still remain within a single bin. Thus, we only claim that these events represent very slow speed movements consistent with (slower) real-world speeds, not that they are perfectly stationary at a point in space.</p><p>Finally, the median speed of our animals is 4 cm/s for all times (including immobility times) and 17 cm/s for run periods (speeds &gt; 4 cm/s). We have added this to the manuscript in the Results (page 14).</p><disp-quote content-type="editor-comment"><p>7. References cited and conclusions drawn from papers are not accurate in some instances, please verify and correct. Several cases are listed below, but the list is larger. Louie and Wilson, Neuron 2001 showed that replay of experience can occur at real-time speed during REM sleep, which should be cited.</p></disp-quote><p>We thank the reviewer for the reference. We have added the reference to Louie and Wilson 2001 on page 18 in the Discussion.</p><disp-quote content-type="editor-comment"><p>On lines 67-68 the authors say: &quot;events that represent a single location are only seen in young animals (Stella et al., 2019)&quot;. That study did not investigate young animals, the authors probably meant to refer to (Farooq and Dragoi, 2019), which should be cited.</p></disp-quote><p>We thank the reviewer for catching this mistake. We have changed the reference to Farooq and Dragoi (2019) as we originally intended, which was erroneously referenced as Stella et al. 2019. We have correctly referenced Farooq and Dragoi (2019) in other parts of the paper and apologize for our carelessness in this instance.</p><disp-quote content-type="editor-comment"><p>There is a difference between what previous studies have claimed, and what the authors attribute to those studies. For instance, previous studies observed low proportions of sequential trajectories, but they did not observe low proportions of spatially coherent time-bins/cofiring, which are otherwise well-reported and have been observed many times.</p></disp-quote><p>We agree that previous studies that examined co-firing across entire events found substantial structure, but those studies did not determine whether individual events were expressing spatially coherent structure across a set of time bins. We have modified the introduction and discussion to reflect this clarification.</p><disp-quote content-type="editor-comment"><p>8. How do the authors know that a probability of 0.8 or above can be inferred from downstream neurons as opposed to 0.95? Unless recordings are performed from downstream neurons that cannot really be determined. Both 0.8 and 0.95 face the problem of ambiguity of whether it is interpretable by a downstream neuron, however, a probability of 0.95 will enable readers to judge what happens when events are statistically significant. Can the authors discuss this in the main text?</p></disp-quote><p>Our threshold of 0.8 is used to categorize the dynamics to determine the speed and as a measure of our confidence in that dynamic. We are not claiming downstream neurons are explicitly making use of our dynamics categories, but rather our categories can be used to understand and summarize the dynamics of replay. Thus, our algorithm enables the possibility of a systematic investigation of how different thresholds and thus different category boundaries might be related to activity in downstream regions.</p><p>We have also shown that these categories broadly correspond to speeds of interest in Figure 1F. Additionally, we have also shown that our results still hold with a higher 0.95 threshold. We have added a discussion of this on page 6.</p><disp-quote content-type="editor-comment"><p>9. Very low decoding errors (3-6 cm) during the run at the small timescale employed here (2 ms) may indicate that this method is incapable of capturing theta sequences (which should give a higher decoding error). Instead, they capture stationary dynamics like they do during rest. Larger bins for decoding during run are typically used to study position representation at larger timescales (at bigger timescales than theta sequences) which are likely to have low error. This could be problematic since the current method might be biased toward over-representing the stationary dynamic. The authors should address this in the manuscript.</p></disp-quote><p>We reported decoding error for both immobility and running time periods to show that our model could capture stationary representation of the animal’s position at the well as well as theta sequences when the animal was running. We realize, however, this is confusing to the reader given what is typically reported. We have changed this to be the error only during running times. During running, we observed a median error of 7 cm (5-9 cm), showing that we indeed can capture theta sequences. This is similar to most other studies (Davidson et al. 2009: 7 cm, 9 cm, 8 cm, 8 cm for each rat; Shin et al. 2019: 3.81 cm; Farooq and Dragoi 2019: ~5 cm (inferred from Figure 1J); Stella et al. 2019: ~9 cm (Figure S2); Farooq et al. 2019: 7.6 cm; Grossmark and Buzsaki 2016: 5.14 cm; Ólafsdóttir et al. 2017: 17.5 cm). We also note that we illustrate the application of the state space algorithm to data from running in Figure 2B of Gillespie et al. <italic>Biorxiv</italic> (2021), which clearly illustrates that it can capture the dynamics of theta sequences.</p><p>We also do not think that our model is biased to over-representing stationary dynamics because we observed similar distributions of speeds when using the MAP estimate (which picks the most likely position without the state space modeling component) with 20 ms time bins (Figure 6B).</p><disp-quote content-type="editor-comment"><p>10. What happens when a 20 ms time bin is used for state space modelling? Does it reduce the proportion of spatially-coherent events?</p></disp-quote><p>We do not have reason to believe that larger time bins would reduce the proportion of spatially coherent events because our analysis using the MAP estimate and 20 ms bins (Figure 6B) rather than the state space model (Figure 6D) also showed many slow events. In any case, we emphasize that there are serious issues with using longer bins for understanding the structure of the data because it introduces arbitrary boundaries between sets of spikes. Some papers try to overcome this with a sliding window, which partially smooths over those boundaries, but even there, the data are chunked into bins that are larger than necessary (e.g. 10 ms for a 20 ms sliding window that is offset by 10 ms each step) and we argue that there is no reason to introduce these arbitrary boundaries.</p><disp-quote content-type="editor-comment"><p>11. Figure 5. When whole ripples are classified as stationary, stationary-continuous mixture and so on, how is this classification done for the whole ripple? The classification of dynamics is done for each 2 ms bin, but what criteria are used to classify the whole ripple? Please provide more details on the intermediate steps. For instance, if an event is stationary, but only has one 2 ms bin which deviates, is it considered stationary-continuous?</p></disp-quote><p>Any time bin that meets the criteria is included. However, the majority of our dynamics have a duration much longer than a single time bin (Figure 5B). We have further clarified this in the methods (page 26).</p></body></sub-article></article>