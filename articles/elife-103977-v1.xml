<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">103977</article-id><article-id pub-id-type="doi">10.7554/eLife.103977</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.103977.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Exploring neurodevelopment via spatiotemporal collation of anatomical networks with NeuroSC</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Koonce</surname><given-names>Noelle L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0597-3499</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Emerson</surname><given-names>Sarah E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9587-3784</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Bhaskar</surname><given-names>Dhananjay</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8068-3101</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Kuchroo</surname><given-names>Manik</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7512-9739</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Moyle</surname><given-names>Mark W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0007-8609-0164</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Arroyo-Morales</surname><given-names>Pura</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5369-6097</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Vázquez-Martínez</surname><given-names>Nabor</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3602-2802</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Emerson</surname><given-names>Jamie I</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-9333-7484</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Krishnaswamy</surname><given-names>Smita</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Mohler</surname><given-names>William A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3586-547X</contrib-id><email>wmohler@uchc.edu</email><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Colón-Ramos</surname><given-names>Daniel A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0223-7717</contrib-id><email>daniel.colon-ramos@yale.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="aff" rid="aff11">11</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Neuroscience and Department of Cell Biology, Wu Tsai Institute, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Genetics, Yale School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05j7qk258</institution-id><institution>Department of Biology, Brigham Young University-Idaho</institution></institution-wrap><addr-line><named-content content-type="city">Rexburg</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution>Bilte Co.</institution><addr-line><named-content content-type="city">Ventura</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Program for Applied Mathematics, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Computer Science, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Program for Computational Biology and Bioinformatics, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02kzs4y22</institution-id><institution>Department of Genetics and Genome Sciences and Center for Cell Analysis and Modeling, University of Connecticut Health Center</institution></institution-wrap><addr-line><named-content content-type="city">Farmington</named-content></addr-line><country>United States</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046dg4z72</institution-id><institution>MBL Fellow, Marine Biological Laboratory</institution></institution-wrap><addr-line><named-content content-type="city">Woods Hole</named-content></addr-line><country>United States</country></aff><aff id="aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Wu Tsai Institute, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff11"><label>11</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02yg0nm07</institution-id><institution>Instituto de Neurobiología, Recinto de Ciencias Médicas, Universidad de Puerto Rico</institution></institution-wrap><addr-line><named-content content-type="city">San Juan</named-content></addr-line><country>Puerto Rico</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kratsios</surname><given-names>Paschalis</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>University of Chicago</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Cardona</surname><given-names>Albert</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>21</day><month>10</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP103977</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-10-23"><day>23</day><month>10</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-10-24"><day>24</day><month>10</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.27.609993"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-12-18"><day>18</day><month>12</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.103977.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-08-21"><day>21</day><month>08</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.103977.2"/></event></pub-history><permissions><copyright-statement>© 2024, Koonce, Emerson et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Koonce, Emerson et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-103977-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-103977-figures-v1.pdf"/><abstract><p>Volume electron microscopy (vEM) datasets such as those generated for connectome studies allow nanoscale quantifications and comparisons of the cell biological features underpinning circuit architectures. Quantifying cell biological relationships in the connectome yields rich, multidimensional datasets that benefit from data science approaches, including dimensionality reduction and integrated graphical representations of neuronal relationships. We developed NeuroSC (<italic>also known as NeuroSCAN,</italic> <ext-link ext-link-type="uri" xlink:href="https://neurosc.net/">https://neurosc.net/</ext-link>) an open source online platform that bridges sophisticated graph analytics from data science approaches with the underlying cell biological features in the connectome. We analyze a series of published <italic>C. elegans</italic> brain neuropils and demonstrate how these integrated representations of neuronal relationships facilitate comparisons across connectomes, catalyzing new insights into the structure-function relationships of the circuits and their changes during development. NeuroSC is designed for intuitive examination and comparisons across connectomes, enabling synthesis of knowledge from high-level abstractions of neuronal relationships derived from data science techniques to the detailed identification of the cell biological features underpinning these abstractions.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>connectomics</kwd><kwd>neurodevelopment</kwd><kwd>neuronal architecture</kwd><kwd>contactome</kwd><kwd>neuronal strata</kwd><kwd>C-PHATE</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>C. elegans</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R24-OD016474</award-id><principal-award-recipient><name><surname>Colón-Ramos</surname><given-names>Daniel A</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R35 NS132156-01</award-id><principal-award-recipient><name><surname>Colón-Ramos</surname><given-names>Daniel A</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>DP1 NS111778</award-id><principal-award-recipient><name><surname>Colón-Ramos</surname><given-names>Daniel A</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 NS076558-2</award-id><principal-award-recipient><name><surname>Colón-Ramos</surname><given-names>Daniel A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>NeuroSC provides an open-source framework for comparative connectomics, integrating neuronal morphologies, contacts, and synapses across developmental stages and datasets.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Neural circuit structure supports function. The underlying image data that yields anatomical connectomes (or wiring diagrams) are typically obtained using volume electron microscopy (vEM) techniques (<xref ref-type="bibr" rid="bib10">Collinson et al., 2023</xref>). Since the first complete connectome was published for <italic>C. elegans</italic> (<xref ref-type="bibr" rid="bib47">White et al., 1986</xref>), these last decades have seen an increase in the generation of vEM datasets, as reviewed in <xref ref-type="bibr" rid="bib24">Kaiser, 2023</xref> and others. The expansion in available anatomical connectomes has resulted from recent advancements in: (1) data generation via automation of EM data acquisition (<xref ref-type="bibr" rid="bib49">Xu et al., 2017</xref>; <xref ref-type="bibr" rid="bib17">Eberle and Zeidler, 2018</xref>; <xref ref-type="bibr" rid="bib52">Zheng et al., 2018</xref>; <xref ref-type="bibr" rid="bib33">Phelps et al., 2021</xref>); and (2) alignment, segmentation, and reconstruction (including recent implementation of AI-driven methods) as reviewed in <xref ref-type="bibr" rid="bib22">Galili et al., 2022</xref>; <xref ref-type="bibr" rid="bib8">Choi et al., 2024</xref> and others. As these developing methodologies continue to improve, they will continue to facilitate the generation of additional connectomes of whole brains and organisms.</p><p>The increasing availability of vEM datasets, including the first series of developmental connectomes published for <italic>C. elegans</italic> (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib51">Yim et al., 2024</xref>), has highlighted the need for new tools to enable intuitive examination and comparisons across connectomes to promote novel discoveries (<xref ref-type="bibr" rid="bib25">Kasthuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Lichtman et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Barabási et al., 2023</xref>; <xref ref-type="bibr" rid="bib50">Xu et al., 2021</xref>). It has also underscored the fact that vEM datasets contain a wealth of untapped information that has yet to be fully examined, represented, and integrated for more comprehensive analyses (<xref ref-type="bibr" rid="bib32">Perez et al., 2014</xref>; <xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>). For example, vEM datasets enable nanoscale explorations of the underlying cell biological features that govern the properties of neural circuit architectures (<xref ref-type="bibr" rid="bib37">Rivlin et al., 2024</xref>; <xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>; <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>; <xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib51">Yim et al., 2024</xref>; <xref ref-type="bibr" rid="bib14">Cuentas-Condori et al., 2019</xref>). Yet most of these cell biological features (cell morphologies, contact profiles, organelle positions, and shapes, etc) are not currently represented in most anatomical connectomes. Quantification of cell biological data results in high-dimensional datasets that require new approaches for their analyses and representations. The advances in vEM data generation and the resulting need for new methodologies in data science and integrated representations of neuronal relationships (e.g. from neuronal positions to neuropil structures) are akin to how advances in genetic sequencing required new methodologies in bioinformatics and new, integrated representations of genomic data (e.g. from gene sequence to gene structure; <xref ref-type="bibr" rid="bib43">Swanson and Lichtman, 2016</xref>). Addressing this gap holds the promise of integrating new knowledge from the fields of cell biology, neurodevelopment, physiology, and systems neuroscience towards explaining how nervous system structure underpins its function.</p><p>Most representations of anatomical connectomes have focused on defining neuronal relationships at the level of the chemical synapse (NemaNode; WormWiring; EleganSign; FlyWire; <xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Fenyves et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Dorkenwald et al., 2023</xref>; <xref ref-type="bibr" rid="bib51">Yim et al., 2024</xref>). While the existence of chemical synapses between neuron pairs is an important feature of neuronal communication, these representations do not capture other neuroanatomical features that also underlie neuron structure and function, including contact sites from adjacent (or nearby) neurons. Recent work in <italic>C. elegans</italic> examined neuronal relationships by quantifying neuron-neuron contact sites to build contact profiles, or contactomes (<xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>). Examination of the contactome with data science approaches uncovered structural principles that were not evident from interrogating the synaptic connectome alone (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>; <xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>). These included the existence of higher-order structural motifs and the stratification of neurons (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>), whose hierarchical assembly during development is guided by centrally located pioneer neurons (<xref ref-type="bibr" rid="bib36">Rapti et al., 2017</xref>). Moreover, integrating neuronal adjacencies (contactome) with synaptic profiles (connectome) allowed for a deeper understanding of the functional segregation of neurons within the stratified neuropil structures (<xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>; <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). Key to achieving this were data science approaches such as Diffusion Condensation (DC) and C-PHATE (<xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">Moon et al., 2019</xref>), which resulted in reduced dimensionality of the neuronal relationships, revealing architectural motifs across various scales of granularity, from individual neurons within circuits, to individual circuits within the neuropil. These techniques produced graphs that enabled exploration of these computationally identified groups (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). DC/C-PHATE graphs are powerful tools, but they have yet to be integrated to connectomics datasets to enable explorations of the underlying cell biological features. This limits their effectiveness for hypothesis generation and comparative analyses across connectomes.</p><p>To address this, we generated NeuroSC (<ext-link ext-link-type="uri" xlink:href="https://neurosc.net/">https://neurosc.net/</ext-link>) a tool for exploring neuroarchitectures across vEM datasets via novel representations of the connectome, contactome, and anatomical networks. NeuroSC is an online, open-source platform that facilitates comparisons of neuronal features and relationships across vEM data to catalyze new insights of the relationships that underpin architectural and functional motifs of the nerve ring neuropil. NeuroSC builds on recent publications in whole-brain EM datasets, integrating the latest set of developmental connectomes (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>) and employing data science tools (<xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">Moon et al., 2019</xref>) to examine neuronal relationships based on contact profiles. NeuroSC was purposefully developed with a different and complementary goal to existing tools that offer web-based visualization and access to large-scale EM datasets, such as Neuroglancer and Webknossos <xref ref-type="bibr" rid="bib27">Maitin-Shepard et al., 2021</xref>; <xref ref-type="bibr" rid="bib3">Boergens et al., 2017</xref>. The explicit goal of NeuroSC is to provide a platform optimized for examining <italic>neuronal relationships</italic> across connectomic datasets. To achieve this, NeuroSC builds on the segmentations emerging from programs like NeuroGlancer and Webknossos, but with tools tailored to explore relationships such as contact profiles in the context of neuronal morphologies and synaptic positions, and across datasets that represent different animals or different developmental stages. Designed as an open-source and modular platform, NeuroSC is intended to integrate with these existing tools and datasets, supporting a synergistic approach to navigating, analyzing, and deriving meaning from complex connectomic resources.</p><p>We demonstrate how these integrated representations of neuronal relationships facilitate comparisons across these connectomes, catalyzing new insights on their structure-function and changes during development. NeuroSC achieves this by addressing three challenges in current neuronal representations: (1) accessibility of specific neuronal cell biological features (i.e. synapses and contacts), (2) integration of features for examining neuronal relationships across anatomical scales, and (3) spatiotemporal comparisons of these features across developmental datasets. These challenges were addressed by (1) creating representations of contact sites and establishing the ability to visualize subsets of synaptic sites; (2) enabling synchronous visualization of neuron morphologies, contacts, and synapses and integrating these cell biological features with algorithmically-generated graphical representations of neuronal relationships; and (3) enabling simultaneous exploration of these relational representations across developmental connectomes. NeuroSC was designed as a suite of tools that facilitates future incorporation of additional datasets and representations with the goal of enabling integrated data exploration beyond the available <italic>C. elegans</italic> connectomes. The NeuroSC-based approaches used here for <italic>C. elegans</italic> could be applicable to other systems as new EM-based datasets and reconstructions become available.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Comparing contactome-based relationships using C-PHATE</title><p>The adult hermaphrodite <italic>C. elegans</italic> nerve ring is a neuropil of 181 neurons of known identities, morphologies, contact profiles, and synaptic partners (<xref ref-type="bibr" rid="bib47">White et al., 1986</xref>). Even for this relatively small neuropil, representations of a single feature type, such as neuronal contact profiles, constitute over 100,000 data points of multidimensional information: cell identity, region of contact, presence of synapses, etc. Analysis of this multidimensional information requires approaches that can both capture higher order patterns of organization while enabling researchers to access the underlying cell biological features resulting in these relationships. We implemented DC, a clustering algorithm that iteratively groups neurons based on the quantitative similarities of their ‘contact’ or ‘adjacency’ profiles (<xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). Briefly, DC makes use of pair-wise quantifications of adjacent neuron contacts to, in a graph, move neurons with similar adjacency profiles closer together by applying a diffusion filter in a multidimensional manifold. At each iteration, the diffusion filter smooths the data across the manifold, such that local variability (or noise) in the adjacency profiles is reduced, highlighting broader, higher-order pattern similarities across neurons. As iterations proceed, individual neurons (and eventually groups of neurons) are clustered together based on how close their contact profiles are to one another in the manifold (<xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>). In this way, DC uncovers hierarchical neuronal relationships in the contactome (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>).</p><p>To ensure accurate comparisons of DC across available EM datasets (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib47">White et al., 1986</xref>), we empirically determined minimum-distance adjacency thresholds (measured in pixels; <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>) to construct adjacency profiles. Each neuron’s adjacency profile is a quantitative measure that captures the extent of contact with neighboring neurons within its spatial vicinity. By individually setting distance thresholds for each dataset, we ensured that the degree of adjacency—defined by both the presence and extent of contact—could be accurately compared across datasets generated at different times and using diverse methodologies (see also Methods and Materials), schematized in <xref ref-type="fig" rid="fig1">Figure 1A–C</xref>). We applied an established adjacency algorithm to quantify the extent of contact between neuron pairs by measuring the number of shared pixels within the defined distance threshold for adjacency (<xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>). Pixel counts were summed for each neuron across EM slices within the defined nerve ring region (see Materials and methods), resulting in an adjacency matrix representing pairwise shared pixel counts for each of the seven selected <italic>C. elegans</italic> contactome datasets (L1, 0 hours post hatch (hph); L1, 5hph; L2, 16hph; L3, 27hph; L4, 36hph; Adult 48hph (<xref ref-type="fig" rid="fig1">Figure 1C</xref>; See also Materials and methods). These adjacency matrices were fed into DC to reveal iterative clusters of neurons with similar adjacency profiles. To visualize and compare the results from DC, we used a graphical representation of the algorithm output called C-PHATE (<xref ref-type="bibr" rid="bib28">Moon et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>), a 3-D visualization tool that builds a hierarchical, visual representation of the DC agglomeration procedure (<xref ref-type="fig" rid="fig1">Figure 1D–E</xref>). In C-PHATE visualizations, the DC output is mapped in 3-D space with spheres. Initially, all individual neurons in the neuropil dataset are at the periphery of the C-PHATE graph (left-hand side in schematic in <xref ref-type="fig" rid="fig1">Figure 1D</xref>, edges of graph in <xref ref-type="fig" rid="fig1">Figure 1E</xref>). Neurons are iteratively condensed together based on the similarity of their adjacency profiles (schematized in <xref ref-type="fig" rid="fig1">Figure 1D</xref>). In the last iteration of DC, there is a single point at the center of the C-PHATE graph which represents the entire neuropil (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, red dot). C-PHATE representations enable visualization and comparisons of contactomes across datasets, and explorations of neuronal relationship trajectories, from individual neuron interactions to circuit-circuit bundling (<xref ref-type="fig" rid="fig1">Figures 1F</xref> and <xref ref-type="fig" rid="fig2">2</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>DC/C-PHATE representations of contactome-based relationships.</title><p>DC/C PHATE graphs enable representations of neuronal contact relationships. To build DC/C-PHATE graphs, we (<bold>A</bold>) analyzed serial section EM datasets of the <italic>C. elegans</italic> nerve ring neuropil (located in the head of the animal). (<bold>B</bold>) Single cross-section of the nerve ring (surrounding the pharynx), with segmented neurites pseudo-colored. The dark box corresponds to the zoomed-in image in (<bold>C</bold>). The cross-section is from the JSH dataset digitally segmented (<xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>). (<bold>C</bold>) Zoom-in cross section with three arbitrary neurons (called <bold>A</bold>, <bold>B, C</bold>) highlighted by overlaying opaque cartoon (2-D, left image) and 3-D shapes (middle image) to represent the segmentation process in the z-axis (arrow) and the neuronal contact sites (highlighted Yellow, orange, and Red). Contacts are quantified for all neuron pairs across the contactome (see Materials and methods), to generate a Contact Matrix (represented here as a table, schematized for the three arbitrary neurons selected and in which specific contact quantities are represented by a color scale and not numerical values). Yellow represents little contact, and red represents a large degree of contact. Here, as an example, you can see that neuron B and C have the largest degree of contact. In an actual contact matrix, this would be a large number of shared pixels. (<bold>D</bold>) Schematic of how the Diffusion Condensation algorithm (visualized with C-PHATE) works. DC/C-PHATE makes use of the contact matrix to group neurons based on similar adjacency profiles (<xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>; <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>), schematized here for the three neurons in (<bold>C</bold>). (<bold>E</bold>) Screenshot of the 3-D C-PHATE graph from a Larval stage 1 (L1; 0 hours post hatching;) contactome, with individual neurons represented as spheres at the periphery. Neurons were iteratively clustered towards the center, with the final iteration containing the nerve ring represented as a sphere in the center of the graph (Highlighted in maroon). (<bold>F</bold>) Integration in NeuroSC of the DC/C-PHATE and EM-derived 3-D neuron morphology representations allows users to point to each sphere in the graph and determine cellular or cluster identities for each iteration. Shown here and circled in red, an arbitrarily selected cluster (in E), with the identities of the neurons belonging to that cluster (four letter codes in the column to the left of F) and the corresponding neuronal morphologies (right) of this group of neurons in the EM-reconstructed nerve ring (with individual neurons pseudo-colored according to their names to the left). Compass: Anterior (A), Posterior (P), Dorsal (D), Ventral (V), Left (L), Right (R).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig1-v1.tif"/></fig><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Implementation of DC/C-PHATE to developmental contactomes reveals a conserved layered organization maintained during post-embryonic growth.</title><p>(<bold>A</bold>) Cartoon of the <italic>C. elegans</italic> head and nerve ring (outlined with black box). Below, nerve ring reconstruction from EM data of an L1 animal (5 hours post-hatching), with all neurons in gray. Scale bar 2 μm. (<bold>B–F</bold>) DC/C-PHATE plots generated for available contactomes across <italic>C. elegans</italic> larval development, colored by stratum identity as described (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). Individual neurons are located at the edges of the graph and condense centrally. The four superclusters identified and all iterations before are colored accordingly. The identity of the individual neurons belonging to each stratum, and at each larval stage, was largely preserved and is provided in <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>; <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref>; <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>; <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>. Some datasets contain 5 or 6 super-clusters (colored hues of the stratum that they most closely identify with). These clusters are classified as groups of neurons that are differentially categorized across the developmental connectomes. Note in B the blue cluster extends far to the left due to rotation of the 3D image. (<bold>G–K</bold>) Volumetric reconstruction of the <italic>C. elegans</italic> neuropil from EM serial sections for the indicated larval stages (columns) with the neurons colored based on their strata identity. Scale bar 2 μm; Anterior (<bold>A</bold>) left, Dorsal (<bold>D</bold>) up.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig2-v1.tif"/></fig><p>By Larval stage 1 (L1), 90% of neurons in the neuropil (161 neurons out of the 181 neurons) have grown into the nerve ring and adopted characteristic morphologies and positions. Although the organism grows approximately fivefold from L1 to the adult, contacts in the nerve ring are also largely established by L1 and preserved during postembryonic growth (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>). In agreement with this, when we used DC and C-PHATE to examine contactomes from these datasets, we consistently identified four main superclusters: Stratum 1, Stratum 2, Stratum 3, and Stratum 4, using the clusters found at the highest modularity score (the iteration at which the algorithm has the highest clustering confidence) (<xref ref-type="bibr" rid="bib30">Newman, 2006</xref>; <xref ref-type="fig" rid="fig2">Figure 2B–F</xref>). DC outputs for each strata across animals can also be inspected using Sankey diagrams (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>; <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref>; <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>; <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>). These diagrams detail the neuron members at each iteration of DC, allowing the user to derive quantitative comparisons of clustering events. The alignment of the neuronal morphologies of strata members reveals a persistent layered organization to the nerve ring neuropil (<xref ref-type="fig" rid="fig2">Figure 2G–K</xref>), and the functional identities of the neurons in each stratum suggest that there is spatial segregation of sensory information and motor outputs (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>, <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>; <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref>; <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>; <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>). Our findings are consistent with previous studies on the Larval Stage 4 (L4) and adult contactomes (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>), and support that neurons establish core relationships during embryogenesis and maintain them during postembryonic growth, consistent with previous studies (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>). Our findings also demonstrate the utility of DC and C-PHATE analyses in extracting, visualizing, and comparing the structure of the neuropil architecture across contactomes.</p><p>Because DC and C-PHATE allow for the examination of relationships at varying levels of granularity, these diagrams also facilitate the interrogation of the architectural motifs that underlie distinct neural strata. A more detailed examination of clusters reveals that while the overall strata are preserved, the underlying neuronal configurations undergo changes during postembryonic growth (<xref ref-type="fig" rid="fig2">Figures 2B–F</xref>–<xref ref-type="fig" rid="fig3">3</xref>, see:<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>; <xref ref-type="supplementary-material" rid="supp4">Supplementary file 4</xref>; <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>; <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>). Three general features were extracted from these analyses: (1) individual neurons renegotiate their positions in the context of the identified C-PHATE clusters in different developmental contactomes, suggesting developmental changes; (2) the degree of these changes varied across the distinct strata; and (3) the degree of these changes mapped onto strata containing neurons with functions known to require either more or less neuronal plasticity, such as integrative behaviors versus more fixed reflexive behaviors, respectively. For example, Stratum 1, which contains most neurons contributing to shallow reflex circuits, controlling aversive head movements in response to noxious stimuli, displayed the fewest changes among the developmental connectomes (<xref ref-type="fig" rid="fig3">Figure 3B–F</xref>; <xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). On the other hand, <italic>C. elegans</italic> exhibit tractable behaviors which can adapt due to changing environmental conditions <xref ref-type="bibr" rid="bib21">Flavell et al., 2020</xref>. Strata 3 and 4 contain most neurons belonging to circuits associated with such learned behaviors, including chemo, mechano, and thermo sensation. This is reflected by strata 3 and 4 being the regions of the most change in neuronal relationships across postembryonic development (<xref ref-type="fig" rid="fig3">Figure 3G–L</xref>; <xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>; <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Examination of the architectural motifs underlying the distinct strata across development.</title><p>Visualization of (<bold>A–F</bold>) Stratum 1 (Red) and (<bold>G–L</bold>) Strata 3 and 4 (Blue and Green) reveal motifs that are preserved (Stratum 1) and change (Strata 3 and 4) across developmental contactomes (L1 to Adult, left to right, as indicated by labels on top). (<bold>B–F</bold>) Cropped view of Stratum 1 at each developmental stage showing a similar shape of two ‘horn-like’ clusters in the C-PHATE graphs (as seen by orange and blue shaded areas). These two clusters have similar neuronal memberships, which are largely invariant across developmental contactomes (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>). (<bold>H–L</bold>) Cropped view of Strata 3 and 4 at each developmental stage highlighting differences in the organization and number of neurons contained in each of the Blue and Green strata, which is particularly distinct when comparing (<bold>H</bold>) L1 and (<bold>K</bold>) L4 (<xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>; <xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig3-v1.tif"/></fig><p>To examine the changes in DC/C-PHATE during postembryonic development, we made the C-PHATE plots fully interactive. This enables users to hover over and identify members of each intermediate cluster, to highlight specific cell trajectories via pseudo-coloring, and compare specific neuronal relationship dynamics across development within a multi-view window of distinct C-PHATE plots (<xref ref-type="fig" rid="fig1">Figure 1E-F</xref>, <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>; <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>). Because C-PHATE graphs ultimately represent cells of known identities, we reasoned that interactive mapping of the C-PHATE cluster objects to their component cellular identities and anatomies could yield greater insights on neurodevelopmental changes by linking the algorithmic abstractions of the relationships with the cell biological features and their changes across development (<xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Case study: AIML and PVQL neurons change clustering patterns across the developmental contactomes.</title><p>(<bold>A–E</bold>) C-PHATE plots across development, with the trajectories of AIM neurons (in purple) and the rest of the spheres colored by stratum identity (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). (<bold>F–G</bold>) Zoom in of the AIML and PVQL trajectories corresponding to larval Stage 1 (pre-AVF ingrowth) (A, dotted box) and in (<bold>G</bold>), Larval Stage 3 with AVFL/R present (<bold>C</bold>, dashed box). Note how the relationship between AIM and PVQ neurons in the C-PHATE graph varies for each of the examined contactomes across development. (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="supplementary-material" rid="supp7">Supplementary file 7</xref>). (<bold>H,I</bold>) simplified schematics of F and G based on neuron class.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>DC/C-PHATE clustering of AIM, PVQ, and AVF across postembryonic development.</title><p>(<bold>A–E</bold>) A cropped view of the DC/C-PHATE plot colored to identify individual neurons and clustering events in (<bold>A</bold>) Larval stage 1 (5 hours post hatching); (<bold>B</bold>) Larval stage 2 (23 hours post hatching); (<bold>C</bold>) Larval Stage 3 (27 hours post hatching); (<bold>D</bold>) Larval stage 4 (36 hours post hatching); and (<bold>E</bold>) Adult (48 hours post hatching). See also <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref> and <xref ref-type="supplementary-material" rid="supp7">Supplementary file 7</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig4-figsupp1-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-103977-fig4-video1.mp4" id="fig4video1"><label>Figure 4—video 1.</label><caption><title>Visualization of hierarchical relationships using C-PHATE plots in NeuroSC.</title><p>The process for rendering a C-PHATE plot at the L4 stage (36 hours post hatching) with the real-time loading speed. In the viewer, 3-D visualization of a C-PHATE plot (shades of cyan), which is rotated to show the dome- shape of the plots and to orient the plot to correspond to <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig4">4</xref>. The highlight functionality is used to show the spheres containing AIM (teal), then PVQ (teal). The spheres of the first iterations, containing AIM and PVQ, are identified, selected, and colored magenta. The AVF neurons are highlighted in teal, and the first AIM and AVF containing clusters are identified, selected, and colored yellow. The first clusters containing AIML, AVF, and PVQL are identified and colored green. Neurons in the left yellow and magenta clusters are reconstructed with a right click on the sphere and ‘“Add to new viewer’” selection.</p></caption></media></fig-group><p>To evaluate our hypothesis and assess the utility of C-PHATE for discovery, we examined specific regions where the distribution or ‘shape’ of super clusters changed across developmental contactomes. This approach accounts for differences in contact profiles, which directly impacts the overall clustering structure. Based on these criteria, we focused on a region displaying changes in Strata 3 and 4, and using the interactive C-PHATE graphs (<xref ref-type="fig" rid="fig4">Figure 4A–E</xref>), we determined the identities of neurons that changed clustering patterns across the developmental contactomes. Specifically, we focused on two interneurons, named AIML and PVQL, which we observed undergo a change in their cluster assignment from Stratum 4 (at L1) to Stratum 3 (at Larval stage 4, L4; <xref ref-type="fig" rid="fig4">Figure 4A and D</xref>). We pseudo-colored the trajectories of the AIML and PVQL neurons in C-PHATE to explore the changes in their C-PHATE trajectories throughout the developmental stages (<xref ref-type="fig" rid="fig4">Figure 4F-I</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="supplementary-material" rid="supp7">Supplementary file 7</xref>). Comparison of the identities of the neurons that co-cluster with AIML and PVQL suggests that the contact relationships varied across developmental stages (<xref ref-type="fig" rid="fig4">Figure 4F-G</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), co-cluster members can also be evaluated via Sankey diagrams, showing a switch in membership of AIM and PVQ from clusters of stratum 4 at L1-L2, pre-AVF ingrowth, to include a transitionary stratum at L3, finally to stratum 3 at L4-adult after AVF ingrowth (see <xref ref-type="supplementary-material" rid="supp7">Supplementary file 7</xref>).</p></sec><sec id="s2-2"><title>Visualizing contact profiles in individual cells</title><p>DC/C-PHATE changes should result from changes in contact profiles. To link the observed changes in the C-PHATE graphs with the cell-biological changes in contact profiles, we generated a tool that would simultaneously enable: (1) 3D visualization of the cell-cell contact sites onto individual neuronal morphologies; (2) examination and comparisons of these contact profiles throughout development for the available contactomes; and (3) integration with DC/C-PHATE to link C-PHATE cluster objects to the 3-D morphologies of the algorithmically clustered cells. With these capabilities integrated, we could simultaneously view the contactome from two complementary perspectives – at an abstract systems level via DC/C-PHATE and at a cell biological level via 3D contact modeling – to perceive the architectural themes that underlie similar network patterns.</p><p>To create this tool, we generated 3D models of the area of physical contact between adjacent neuron pairs (<xref ref-type="supplementary-material" rid="supp1 supp2">Supplementary files 1 and 2</xref>; Materials and methods; <xref ref-type="fig" rid="fig5">Figure 5</xref>); <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>. Visualizing contacts from all adjacent neurons builds a multi-colored skeleton of the neuron morphology mapped onto the boundaries of this neuron (<xref ref-type="fig" rid="fig5">Figure 5A and C</xref>). Because the identities of the neurons are known and linked to the 3D contact models, we built text pop-ups that define the contact partners for each site (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Furthermore, since neuron names are consistent across the EM datasets, we can link and compare contact sites throughout development (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). Additionally, we can analyze the representations of contact sites in the context of DC/C-PHATE clustering profiles (<xref ref-type="fig" rid="fig4">Figure 4F–I</xref>), 3D models of neuronal morphologies (<xref ref-type="fig" rid="fig1">Figure 1F</xref>), and 3D models of synaptic sites for any neuron(s) across development (Figure 7).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Case Study: Visualization of contact profiles in individual neurons.</title><p>(<bold>A</bold>) Cartoon schematic of the head of the animal with the AIM neurons (purple) and pharynx (gray), and (dotted box) a 3-D reconstruction of the AIM neuron morphology from the L1 (0 hours post-hatching) dataset. (<bold>B</bold>) AIML and AIMR neurites rendered in 3D from L1. Note that we did not implement any surface smoothing methods to objects, so there might be gaps in the renderings. This was done intentionally, with the goal of producing the most accurate representation of the available data segmentation and avoiding any rendering interpretations. (<bold>C</bold>) 3-D representation of all contacts onto the AIM neuron morphology in an L1 animal, colored based on contacting partner identity, as labeled (right) in the detailed inset (black box) region. (<bold>D</bold>) AIM-PVQ contacts (in orange) and AIM-AVF contacts (in green), projected onto the AIM neurons (light purple) across developmental stages and augmented for clarity in the figure (see non-augmented contacts in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>). Scale bar 2 μm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Projecting contact profiles onto the segmented neuronal shapes.</title><p>(<bold>A–C</bold>) Graphical representations of the strategy utilized for creating the contact profiles for each of the adjacent neurons (purple, red, cyan) onto a cross section of the neuron of interest (Neuron A, yellow). (<bold>D–F</bold>) Electron micrograph from the L4 dataset with two adjacent neurons colored yellow and cyan. To build 3-D reconstructions of contact sites from adjacent neurons, we analyzed segmented neurons from the electron microscopy datasets in each slice (<bold>A, D</bold>). Each adjacent neuron is expanded in all directions to the pixel threshold distance (specified for each dataset; <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>; Methods; <ext-link ext-link-type="uri" xlink:href="https://www.cytoshow.org/">CytoSHOW.org</ext-link>) (<bold>B, E</bold>). A new ROI (region of interest; purple, red, cyan in C; green in F) is created from the overlapping areas between the neuron of interest (yellow) and the adjacent neurons (<bold>C,F</bold>). (<bold>G–I</bold>) 3-D reconstruction of neuron (yellow) (<bold>G</bold>) with adjacent neuron (cyan), (<bold>H</bold>) with contact sites captured (green) across all slices, and (<bold>I</bold>) with contact areas from the adjacent neuron augmented (green) as seen in <xref ref-type="fig" rid="fig5">Figure 5D</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>AIM contact sites.</title><p>Contact sites from PVQ (Orange and highlighted with orange arrowheads) and from AVF (Green and highlighted with green arrowheads) across developmental stages (as indicated) and projected onto the segmented AIM neurons (transparent purple). This figure is the unmodified NeuroSC outputs of contact profiles that correspond to <xref ref-type="fig" rid="fig5">Figure 5D</xref>. In <xref ref-type="fig" rid="fig5">Figure 5D</xref> these contact profiles were augmented. Scale bar = 2 um. See also <xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig5-figsupp2-v1.tif"/></fig></fig-group><p>We used the integrated tools of DC/C-PHATE and 3D representations of the contact profiles to examine the potential cell biological changes leading to the DC/C-PHATE clustering changes observed for the AIML neuron during development. With these tools, we observed changes in the identities of the contacts made in the dorsal region of the AIML neurite (<xref ref-type="fig" rid="fig5">Figure 5D</xref>; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). Specifically, in the L2 stage (as compared to L1), we observed a decrease in the contacts from PVQL and an increase in contacts from the AVF neurons. This change persists to the adult stage (<xref ref-type="fig" rid="fig5">Figure 5D</xref>; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>).</p><p>To then determine the possible source of these developmental changes in contacts, we visualized 3D models of the segmented morphologies for these neurons across L1 to adulthood (<xref ref-type="fig" rid="fig6">Figure 6</xref>). We find that AIM and PVQ neurons maintain similar morphologies throughout development (<xref ref-type="fig" rid="fig6">Figure 6C</xref>), while AVF neurons undergo substantial neurite outgrowth onto new regions of contact between AIM and PVQ (<xref ref-type="fig" rid="fig6">Figure 6B–D</xref>). These observations are consistent with lineaging studies which demonstrated that AVF neurons are generated from neuronal precursors (P0 and P1) at the end of the L1 stage (<xref ref-type="bibr" rid="bib41">Sulston et al., 1983</xref>; <xref ref-type="bibr" rid="bib42">Sun and Hobert, 2023</xref>; <xref ref-type="bibr" rid="bib34">Poole et al., 2024</xref>; <xref ref-type="bibr" rid="bib23">Hall and Altun, 2008</xref>; <xref ref-type="bibr" rid="bib40">Sulston and Horvitz, 1977</xref>). By comparing the EM datasets across development, we observe that the AVF neurons grow into the nerve ring during the L2 stage and continue to grow until the Adult stage (<xref ref-type="fig" rid="fig6">Figure 6B–D</xref>). We also consistently observe throughout the individual datasets that the AVF neurons grow in between the AIM and PVQ neurons (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), altering their contact profiles, which likely contributes to the observed changes in the C-PHATE graphs. While the DC/C-PHATE representations systematically cluster neurons based on relative similarities across contact profiles, and not solely by scoring changes in specific contacts within any given pair, our findings demonstrate the use of DC/C-PHATE as a discovery tool to identify cell-biological contact changes during development. (<xref ref-type="fig" rid="fig4">Figure 4F and G</xref>; <xref ref-type="fig" rid="fig5">Figure 5D</xref>; <xref ref-type="video" rid="fig6video1">Figure 6—video 1</xref>). Consistent with this, we also observe that both AVFL and AVFR grow into the nerve ring alongside AIML, later continuing to grow around to reach AIMR, and that these relationships were reflected in the C-PHATE graphs in terms of the clustering profiles throughout development (<xref ref-type="fig" rid="fig4">Figure 4G</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Case study: Segmented morphologies of AIM, PVQ, and AVF across larval development.</title><p>(<bold>A</bold>) Cartoon schematic of the <italic>C. elegans</italic> head, pharynx (gray), and examined neurons with dashed black box representing the nerve ring region. (<bold>B</bold>) Schematic representation of the outgrowth path of the AVF neurons as observed by EM (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>). The distal end of the AVFL neurite is highlighted with a green arrowhead in the schematic. (<bold>C</bold>) Neuronal morphologies of AIM (purple), PVQ (orange), AVFL (green) across postembryonic development, as indicated, with green arrowhead pointing to AVF outgrowth tip. Scale bar = 2 μm. Regions for insets (L1, dotted box; L2, dashed box) correspond to (<bold>D</bold>). Note that the AVF neuron class is comprised of a left and right counterpart. In C and D, we only show AVFL for simplicity. During development, AVFL and AVFR, as shown in A and B, both grow ipsilaterally along AIML in parallel and extend around the nerve ring together. This is unusual among classes of nerve ring neurons. (<bold>D</bold>) Morphologies of these neurons (rotated to the posterior view) display the AVFL neuron positions between the AIM and PVQ neurons at the L1 and L2 stage. Indicated outgrowth between neurons continues to the adult stage (<xref ref-type="video" rid="fig6video1">Figure 6—video 1</xref>). Note how AVF outgrowth alters contact between PVQ and AIM (<xref ref-type="fig" rid="fig5">Figure 5D</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig6-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-103977-fig6-video1.mp4" id="fig6video1"><label>Figure 6—video 1.</label><caption><title>Analysis of AIM, PVQ, and AVF neuronal morphologies in developmental datasets.</title><p>3-D visualizations of AIM (Purple), PVQ (Orange), and AVF (Green) at (Left viewer) L1 (5 hours post hatching) and (Right viewer) L3 (27 hours post hatching) in NeuroSC. Note that at L1, AVF has not grown into the nerve ring, therefore, only AIM and PVQ are present, but by L3, the AVF neurons have grown between the AIM and PVQ neurons.</p></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-103977-fig6-video2.mp4" id="fig6video2"><label>Figure 6—video 2.</label><caption><title>Navigating NeuroSC features that enable integration of Neurons, Contacts, and Synapses across developmental datasets.</title><p>Upon first opening NeuroSC, a tutorial will launch (<xref ref-type="fig" rid="fig8s4">Figure 8—figure supplement 4</xref>). In the NeuroSC menu, one can read about NeuroSC, access the tutorial, and navigate to the embryonic promoter database (<xref ref-type="fig" rid="fig8s4">Figure 8—figure supplement 4</xref>). The video shows the user searching neurons (AIM and PVQ) and adding neurons to the viewers (<xref ref-type="fig" rid="fig8s6">Figure 8—figure supplement 6</xref>). Side-by-side viewers with AIML, AIMR, and PVQL enable comparisons across developmental stages (L1, 0 hours post hatching and L4, 36 hours post hatching). Also shown in the video are the use of the in-viewer toolbar (<xref ref-type="fig" rid="fig8s7">Figure 8—figure supplement 7</xref>) and navigation menu (<xref ref-type="fig" rid="fig8s8">Figure 8—figure supplement 8</xref>) for object exploration.</p></caption></media></fig-group><p>We then examined if the developmental changes in contact profiles result in changes in circuitry. We examined this by layering on synaptic information. Despite dwindling AIM-PVQ contacts, AIM and PVQ neurons maintained their synaptic relationship throughout development, with synaptic sites observed primarily at the base of AIM neurons, a region of persistent contact with PVQ (<xref ref-type="fig" rid="fig7">Figure 7A-B</xref>). We observed that increases in contacts between AIM and AVF neurons resulted in additional en passant synapses at the new points of contact, beginning at the L2 stage and continuing to adulthood (<xref ref-type="fig" rid="fig7">Figure 7A–B</xref>). We also observed that AVF forms synapses with the adjacent PVQ neurons (<xref ref-type="fig" rid="fig7">Figure 7</xref>; <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Case study: AIM-PVQ and AIM-AVF synaptic positions across development.</title><p>(<bold>A</bold>) AIM-PVQ synaptic sites (dark orange arrowheads) and AIM-AVF synaptic sites (dark green arrowheads) in the segmented AIM neurons and reconstructed across postembryonic development from original connectomics data. Scale bar = 2 μm. (<bold>B</bold>) Schematic of the AIM, PVQ, and AVF circuitry across development based on synaptic connectivity and focusing on the stage before AVF outgrowth (L1), during AVF outgrowth (L2), and Adult; arrow direction indicates pre to post synaptic connection, and arrow thickness indicates relative number of synaptic sites (finest, &lt;5 synapses; medium, 5–10 synapses; thickest, 11–30 synapses). (<bold>C</bold>) Zoom in of synaptic sites (green) in the Adult connectome and embedded into the AIM neuron morphology (light purple). In NeuroSC, presynaptic sites are displayed as blocks and postsynaptic sites as spheres, and a scaling factor is applied to the 3-D models (Materials and methods).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>AVF synaptic sites.</title><p>Synaptic sites displayed onto transparent (green) AVF neurons across developmental stages. Presynaptic sites (spheres) and postsynaptic sites (blocks) are visualized between the AVF neurons and the AIM (purple) neurons, PVQ (orange) neurons and other AVF (either AVFL or AVFR; opaque green) neuron; Scale bar = 2 um.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig7-figsupp1-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-103977-fig7-video1.mp4" id="fig7video1"><label>Figure 7—video 1.</label><caption><title>Exploring contacts and synapses using NeuroSCAN.</title><p>Video of user navigating the tools of NeuroSC to examine synapses and contact profiles to yield results as in <xref ref-type="fig" rid="fig8s3">Figure 8—figure supplements 3</xref> and <xref ref-type="fig" rid="fig8s5">5</xref>. AIM neurons (Transparent Purple), AIM (Purple)-PVQ synaptic sites (Orange), and AIM-PVQ contact sites (Orange) at L1 (5 hours post hatching) are added into Viewer 1. AIM neurons (Transparent Purple), AIM(Purple)-PVQ synaptic sites (Orange), and AIM-PVQ contact sites (Orange), AVF (Green)-AIM synaptic sites, and AVF-AIM contact sites (Green) at L3 (27 hours post hatching) are added into Viewer 2. Contact sites and synaptic sites are compared across developmental stages by hiding AIM neurons. All contact sites for AIM are added for L1 (5 hours post hatching) into Viewer 3.</p></caption></media></fig-group><p>In summary, by integrating, representing, and comparing datasets using the new C-PHATE tools and contact profiles in NeuroSC, we identified developmental changes in the relationships of AIM, AVF, and PVQ. This case study highlights the utility of combining cell biological representations (such as morphologies, contacts, and synapses) with coarse-grained systems-level representations (like DC/C-PHATE) of vEM datasets to uncover developmental changes that could be further explored experimentally. Therefore, NeuroSC serves as a powerful platform for generating hypotheses for empirical testing, which can lead to insights into the dynamics of circuit development.</p></sec><sec id="s2-3"><title>NeuroSC: facilitating multi-layered interrogation of neuronal relationships in the <italic>C. elegans</italic> nerve ring throughout larval development</title><p>NeuroSC is built as a web-based client-server system designed to enable the sharing of anatomical connectomics data with an emphasis on facilitating the analyses of neuropil relationships across hierarchies and scales. To achieve this, we integrated tools of neuroanatomical investigation from the available <italic>C. elegans</italic> nerve ring connectomes and contactomes with a collection of 3-D modeled elements (morphologies, contacts and synapses and C-PHATE) representing different aspects of neuronal architecture and relationships (<xref ref-type="fig" rid="fig8">Figure 8</xref>). NeuroSC differs from other available web-based tools in this area with the integration of C-PHATE graphs that enable exploration of hierarchical organizations of stratified fascicles, the availability of new tools to examine the contactome, and the integration of these data with existing connectome and morphological datasets across developmental stages.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>NeuroSC is a tool that enables integrated comparisons of neuronal relationships across development.</title><p>With NeuroSC, users have integrated access to: C-PHATE plots, 3-D morphological renderings, neuronal contact sites, and synaptic representations. Through stage-specific C-PHATE renderings, users can explore neuronal relationships from high dimensional contactome data. (Top) On C-PHATE plots, schematized here, each sphere represents an individual neuron, or a group of neurons clustered together during algorithm iterations. (Right) 3D renderings of select neurons can be visualized in the context of the entire nerve ring or other circuits (gray). (Left) AIM contact sites at L1 and the same region showing synapses. The inset shows a zoomed-in view of contacts and synapses - presynaptic sites (blocks) and postsynaptic sites (spheres). Data depicted here are from the L1 stage (0 hours post hatching).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-v1.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Visualization of contact sites in NeuroSC.</title><p>(<bold>A</bold>) Search for a specific neuron (here, AIM) to filter (<bold>B</bold>) the list of contacts corresponding to the developmental slider. Neuron A (AIML, here) is the neuron onto which the contacts will be mapped. The Contacts drop-down menu sorts neurons alphabetically (here, colored according to the contact patch color in <bold>C</bold>). (<bold>C</bold>) 3-D reconstruction of all AIM contacts at L3 stage. See also <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>; <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>. In <xref ref-type="fig" rid="fig5">Figure 5D</xref>, contacts are augmented. Inset: Click on a contact rendering to show ’contact stats’. This pop-up displays quantifications of the selected contact relationship. Rank compares the summed surface area of contacts (‘patches’) between these two neurons relative to all other contact relationships for the primary neuron. A rank of 1 means this neuron pair shares the largest contact area. Total surface area is the total surface area in nm2 that covers the primary neuron in the contact relationship. Here the primary neuron is AIM. Contact area percentages are also shown for the cell and the whole nerve ring.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp1-v1.tif"/></fig><fig id="fig8s2" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 2.</label><caption><title>C-PHATE tutorial in NeuroSC.</title><p>(<bold>A</bold>) Add the C-PHATE plot corresponding to the position of the purple circle on the developmental slider (yellow box) by clicking (<bold>B</bold>) the + sign. (<bold>C</bold>) Screenshot of C-PHATE plot at L4 (36 hours post hatching), spheres represent individual neurons at the outer edge of the plot and DC iterations increase towards the center where spheres represent clusters of neurons and eventually the entire nerve ring. (<bold>D</bold>) Screenshot of C-PHATE plot at L4 (36 hours post hatching) with the spheres/clusters containing the AIM neurons highlighted (Blue) by selecting the AIM neurons within the light bulb menu (red box). See also <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>. NeuroSC features in this figure are not shown to scale.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp2-v1.tif"/></fig><fig id="fig8s3" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 3.</label><caption><title>Visualization of synaptic sites with NeuroSC.</title><p>(<bold>A</bold>) Search for synaptic sites for specific neuron(s) (e.g. AIM, PVQ) and choose a developmental time point with the slider. (<bold>B</bold>) Synapses dropdown menu contains a list of objects representing pre- and postsynaptic sites corresponding to all neuron names in the search bar and sorted alphabetically. Searched neurons can be used with the synaptic filter (<bold>C</bold>) to select for synapse type (electrical or chemical; Note: only use this feature for L4_36 hours post hatching and Adult_48 hours post hatching) and to filter objects by synaptic specialization (pre or post; gray dotted box), (<bold>D</bold>) which will follow the filter logic (example shown for AIM and PVQ). (<bold>E</bold>) To enable visualization of subsets of synapses and differentiate between pre- and postsynaptic sites, each synapse contains object(s) representing the postsynaptic site(s) as spheres (Blue and Purple) and the presynaptic site as a block (Orange). These are ordered ‘by synapse’, with all postsynaptic objects, then the presynaptic object. This specific example corresponds to a 3-D representation of the PVQL (Orange, Pre) AIAL (Blue, Post), AIML (Purple, Post) synapse. (<bold>F</bold>) All synaptic sites contain the name of the presynaptic neuron (Orange), neuron type (chemical, electrical, or undefined), list of postsynaptic neuron(s) (Blue), and Unique identifier (Black; Section, letter) for cases with multiple synapses between the same neurons. The ‘section’ is unique to each synapse between specified neurons and at that specific developmental stage. It is listed in order of its anteroposterior position in the neuron. Synapse names are not linked through developmental datasets. If the synapse is polyadic, there will be multiple postsynaptic neuron names and objects associated with a single presynaptic site. See also <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>. (<bold>G</bold>) Right-click on a rendered synapse to open synapse stats. Expand (click arrow in green box) to show the numbers of synapses, broken down by polyadic variations if applicable, per the primary neuron (in this case the primary neuron is PVQL).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp3-v1.tif"/></fig><fig id="fig8s4" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 4.</label><caption><title>Opening page view and menu.</title><p>(<bold>A</bold>) View of opening page. (<bold>B</bold>) Menu for access to the ‘About’ window for referencing source information, the Tutorial, and the developmental Promoter database. See also <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp4-v1.tif"/></fig><fig id="fig8s5" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 5.</label><caption><title>The NeuroSC interface enables interrogation of neuronal relationships across development.</title><p>(<bold>A</bold>) The left-facing arrow to minimize the left panel and optimize space for the viewer windows. The interface contains four main parts: (<bold>B–E</bold>) Filters, (<bold>F–J</bold>) Results, (<bold>K–M</bold>) Viewer Navigation, and (<bold>N–Q</bold>) viewer windows. Filter Results by (<bold>C</bold>) searching for neuron names, (<bold>D</bold>) selecting a dataset with the developmental slider (in hours post- hatching), (<bold>E</bold>) and filtering synapses based on the pre- or post-synaptic partner on the neurons that are on the search bar. (<bold>F</bold>) Results drop down menus (filtered by B) for (<bold>G</bold>) Neuronal morphologies (shown in the viewer as purple in (<bold>O</bold>)), (<bold>H</bold>) Contacts (shown in green (<bold>O</bold>)); (<bold>I</bold>) Synapses (shown in Orange in (<bold>O</bold>)); and (<bold>J</bold>) C-PHATE (shown in (<bold>Q</bold>)), which gets filtered by the developmental slider in (<bold>D</bold>). (<bold>K</bold>) Viewer Navigation to rotate the 3-D projections in all viewers simultaneously (Play All) and which contains a drop-down menu for each viewer (<bold>L,M</bold>). The viewers are named as Viewer 1 (<bold>L, N</bold>) or CPHATE viewer (<bold>M, P</bold>) and followed by information of the developmental stage and the hours post hatching for the objects in the viewer. (<bold>O</bold>) Reconstruction of the AIM neurons with AVF contacts and synapses at L3 27 hours post hatching; scale bar = 2 µm. (<bold>Q</bold>) C-PHATE plot at L1 (0 hours post hatching). See also <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp5-v1.tif"/></fig><fig id="fig8s6" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 6.</label><caption><title>Select and Add objects to viewers.</title><p>(<bold>A</bold>) Click ‘select (number) items’ to select all items in the drop down list (green box), or (<bold>A’</bold>) click the hexagon next to each item (green box). (<bold>B</bold>) Click ‘Add Selected’ (purple box) to add all selected items or (<bold>B’</bold>) click ‘Add to’ (purple box) to add each item individually. (<bold>C</bold>) To add the selected item(s) to an existing viewer of the same developmental stage or to a new viewer, choose a viewer as indicated. (<bold>D</bold>) Click ‘Deselect (number) items’ (orange box) to deselect items. See also <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp6-v1.tif"/></fig><fig id="fig8s7" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 7.</label><caption><title>In-viewer toolbar features.</title><p>(<bold>A</bold>) In-viewer toolbar for Neurons, Contacts, and Synapses and C-PHATE (shown here, only Neurons). (<bold>B, K</bold>) Change the background color of viewer from dark (white box, moon) to white (white box, sun). (<bold>C, L</bold>) Change the color of any objects by selecting a desired color, transparency, or color code and selecting the object (or instance) name (here, AIML and AIMR). (<bold>D, M</bold>) Copy and paste your neuron and contact profile scenes through time into a comparative side by side window changing the developmental stage for items in the viewer by using the in-viewer developmental slider. Note a new window will be generated, which can be dragged next to the original window.(<bold>N</bold>) Add 3-D representations of the Nerve Ring for that developmental stage, note: must be added to the scene last. (<bold>E, O</bold>) Record and download movies for the viewer. (<bold>F,P</bold>) Download.gltf files and viewer screenshot (png). (<bold>G</bold>) Rotate objects around the y-axis. (<bold>H</bold>) Zoom in and (<bold>I</bold>) zoom out, and (<bold>J</bold>) reset objects to original positions in the viewer. See also <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp7-v1.tif"/></fig><fig id="fig8s8" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 8.</label><caption><title>Viewer navigation menu.</title><p>(<bold>A</bold>) Navigation bar contains a drop-down menu for each viewer (shown here, six viewers at varied developmental stages) and a ‘Play all’ button for simultaneously rotating all objects in each viewer around the y-axis (<xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>). Each viewer drop-down menu contains a drop-down menu for Neurons (green box), Contacts, and Synapses. (<bold>B</bold>) Viewer 6 with reconstructions of three neurons (AIML and AIMR, purple; PVQL, orange) at Larval Stage 4 (<bold>L4</bold>), 36 hours post hatching. (<bold>C</bold>) Browse and Select objects in the viewer by navigating the nested drop-down menus. (<bold>D</bold>) Manage objects in viewers with options to select, group, hide, and delete objects in each viewer. Objects can be deleted with ‘select’ and keyboard ‘delete’. See also <xref ref-type="video" rid="fig6video1">Figure 6—video 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp8-v1.tif"/></fig><fig id="fig8s9" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 9.</label><caption><title>NeuroSC architecture.</title><p>(<bold>A</bold>) Source data are defined in a file tree structure that contains various assets such as .gltf files representing various entities, as well as CSVs storing entity metadata. The directory structure outlines a vertical hierarchy starting at the developmental stages, then branching downwards through neuron, C-PHATE, contact, and synapse data.(<bold>B</bold>) A Golang script can be invoked to traverse the directory tree and ingest the files. This parses the hierarchical file path and file contents, verifying the data and associating it with underlying entities, writing it to the database.(<bold>C</bold>) The backend consists of a Postgres Database to store underlying data, a Block Storage Volume that houses static assets (.gltf files, javascript bundle, css styles, etc), and a Golang application. The Golang application surfaces a JSON REST API, leveraging caching strategies to reduce DB load. It also serves the static assets to the client from the block storage. A variable number of Virtual Machines run the backend application code, scaling as needed to accommodate traffic. (<bold>D</bold>) The client-side is a React application that uses Geppetto for entity rendering (<xref ref-type="bibr" rid="bib7">Cantarelli et al., 2018</xref>). User interactions on the frontend result in queries to the backend to filter, sort, and search via the REST API, resulting in the entities and metadata to be rendered to an interactive canvas.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp9-v1.tif"/></fig><fig id="fig8s10" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 10.</label><caption><title>NeuroSC data model.</title><p>(<bold>A</bold>) Reference scheme for B-F; Instance refers to the category (e.g., B, Neuron; C, Developmental Stage), which contains a name or identifier (id) for each object, lists of files associated with the instance (C, Developmental Stage does not have files), and metadata to further describe each instance, which is usually a string (str) or an integer (int). (<bold>B</bold>) The neuron name is the foundation for the Contacts, Synapses, and C-PHATE, which enables integration across each of these representations and across developmental stages (time points) with metadata from WormAtlas (<ext-link ext-link-type="uri" xlink:href="https://wormatlas.org/MoW_built0.92/MoW.html">wormatlas.org/MoW_built0.92/MoW.html</ext-link>). (<bold>C</bold>) The Developmental Stages are named by the larval stages (L1, L2, L3, L4, Adult), and the metadata captures the list of time points within those developmental stages (i.e. L1, 0 hours post hatching, and L1, 5 hours post hatching). (<bold>D</bold>) C-PHATE objects are named with a list of Neurons. (<bold>E</bold>) Contacts link to the Neuron names (Neuron A and Neuron B nomenclature in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>), and metadata annotates the surface area in nm<sup>2</sup> of contact quantified in the source Electron Microscopy micrographs. (<bold>F</bold>) Synapses link to the Neuron names (Pre, type (chemical, electrical or undefined), Post, and section described in <xref ref-type="fig" rid="fig8s3">Figure 8—figure supplement 3</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103977-fig8-figsupp10-v1.tif"/></fig></fig-group><p>NeuroSC has eight key user-driven features: (1) C-PHATE, with the ability to highlight clusters containing neurons of interest (<xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>; <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>), (2) interactive reconstructions of neuronal morphologies (<xref ref-type="fig" rid="fig8s6">Figure 8—figure supplement 6</xref>; <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>), with click-based display of cell statistics, including total volume and surface area within the defined neuropil region (see Materials and methods), (3) reconstructions of neuronal morphologies of C-PHATE cluster members with a right-click on C-PHATE clusters (<xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>), (4) 3-D renderings of neuronal contacts to visualize the spatial distribution of contact profiles, with click-based displays of quantitative statistics, including total contact area, rank among all contacts of the primary neuron, and surface area percentages relative to both the neuron and the nerve ring (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>; <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>), (5) 3-D representations of synaptic sites with the option to visualize subsets of those sites, and a click-based display showing the number of synapses of the selected identity within the primary neuron, including any polyadic synapse combinations involving the primary neurons (<xref ref-type="fig" rid="fig8s3">Figure 8—figure supplement 3</xref>; <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>) (6) the ability to perform side-by-side comparisons across development by cloning a rendered scene across time into a new window at the click of a button using the in viewer developmental stage slider (<xref ref-type="fig" rid="fig8s7">Figure 8—figure supplement 7</xref>; <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>). The cloning feature uses the original search query from the first viewer. ‘Contacts’ may appear or disappear when the user examines different developmental stages if the original query contacts are lost (or gained) at the specific developmental stage in the underlying data. (7) The option to pseudo color each object to highlight points of interest (<xref ref-type="fig" rid="fig8s7">Figure 8—figure supplement 7</xref>; <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>) and (8) each item is an individual object with the ability to be further customized by the user (<xref ref-type="fig" rid="fig8s7">Figure 8—figure supplement 7</xref>, <xref ref-type="fig" rid="fig8s8">Figure 8—figure supplement 8</xref>).</p></sec><sec id="s2-4"><title>NeuroSC: practical considerations</title><p>We offer seven practical considerations for users. First, NeuroSC is available on mobile platforms as a quick and convenient way to look up neuron morphologies and relationships. Second, since contact sites offer the ability to explore the surrounding neurons and the position(s) of contact between adjacent neurons, NeuroSC is designed to enable studies of adjacent neurons (e.g. phenotypes that result in site-specific ectopic synapses; neuron morphology changes that may affect specific surrounding neurons; developmental events requiring communication between neurons, etc.). Third, C-PHATE can be used to identify neurons with similar contact profiles. Because contact profiles are associated with circuit identities (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>), exploration of neuronal relationships via C-PHATE can be used to identify new relationships between specific neurons and circuits. Fourth, visualization of subsets of synaptic and contact sites allows direct comparisons to light microscopy approaches such as cell-specific labeling of synapses or GFP-Reconstitution across synaptic partners (<xref ref-type="bibr" rid="bib19">Feinberg et al., 2008</xref>). Fifth, because the color and transparency of each 3-D model can be customized, users can further integrate NeuroSC outputs of additional atlases for gene expression, neurotransmitter and receptor expression, functional connectivity, etc. (<xref ref-type="bibr" rid="bib31">Packer et al., 2019</xref>; <xref ref-type="bibr" rid="bib44">Taylor et al., 2021</xref>; <xref ref-type="bibr" rid="bib46">Wang et al., 2023</xref>; <xref ref-type="bibr" rid="bib20">Fenyves et al., 2020</xref>; <xref ref-type="bibr" rid="bib35">Randi et al., 2023</xref>; <xref ref-type="bibr" rid="bib27">Maitin-Shepard et al., 2021</xref>) and directly use the NeuroSC outputs to create figures and comparisons (as done for this paper). Sixth, although synaptic sites with BWM (body wall muscles) are included in NeuroSC, the current data model limits the ability to search for these non-neuronal cells. Users can search for neurons with synapses to BWM to find this datatype. Seventh, to enable direct comparisons between our data representations and the primary EM data, the original annotations have been preserved and can be accessed by users via the sister app, CytoSHOW (<ext-link ext-link-type="uri" xlink:href="https://www.cytoshow.org/">CytoSHOW.org</ext-link>). As the data continues to be curated, the modular design of NeuroSC and its companionship with CytoSHOW enables integration of future annotations.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>NeuroSC is an integrative tool for analyzing detailed, web-based representations of neuronal connectomes and contactomes throughout post-embryonic development in <italic>C. elegans</italic>. Connectomes and contactomes are derived from volume electron microscopy (vEM) micrographs of neuropil regions (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib47">White et al., 1986</xref>; <xref ref-type="bibr" rid="bib51">Yim et al., 2024</xref>). These EM micrographs are information-rich and have the potential to reveal architectural motifs across scales, from the nanoarchitecture of the neuron to the neuroanatomy of each circuit in the brain. Cell biological features, such as contact profiles and synaptic positions, can be rigorously quantified and systematically represented as graphs capturing multidimensional relationships. These representations require methodologies from data science that enable dimensionality reduction and comparisons of the architecture across scales. Yet to derive new intuitions about the spatiotemporal events leading to the architecture that shapes its function, it is necessary to integrate and compare these various representations, bridging knowledge from the cell biological events to the systems-level network relationships. NeuroSC is designed to achieve this integration, enabling synthesis of knowledge ranging from the abstractions of neuronal relationships in C-PHATE to the cell biological features underpinning these abstractions. We provide a case study to illustrate how integration of analyses performed in NeuroSC can result in new insights. First, we demonstrated the discovery process with C-PHATE representations to identify neurons that undergo changes in their contactome during development. Second, we developed 3-D representations of contact sites to analyze the local neuronal regions that were identified via DC/C-PHATE analysis. Third, we visualized and compared these representations across development to identify cell biological changes in neuronal morphologies and synaptic positions across neuron classes. Our case study demonstrates the utility NeuroSC to facilitate exploration of neuronal relationships, leading to new insights on structural features of the connectome and hypotheses for empirical testing.</p><sec id="s3-1"><title>Comparisons of NeuroSC to other connectomics atlases</title><p>NeuroSC is one of several efforts centered around interpreting the <italic>C. elegans</italic> EM datasets. Other open-source tools for data exploration in <italic>C. elegans</italic> include efforts to capture neuron morphologies and synaptic information (including integration of new connectomes across larval development), to map neurotransmitter and receptor expression, and to record whole brain functional connectivity across genotypes (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib1">Altun et al., 2002</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Fenyves et al., 2020</xref>; <xref ref-type="bibr" rid="bib35">Randi et al., 2023</xref>; <xref ref-type="bibr" rid="bib27">Maitin-Shepard et al., 2021</xref>; <xref ref-type="bibr" rid="bib3">Boergens et al., 2017</xref>). NeuroSC was designed to interface and enhance these existing resources. NeuroSC focuses on comparative, biologically grounded analysis of segmented neuronal features across datasets. This includes new tools for rendering contact profiles, synchronizing 3D views, and navigating C-PHATE diagrams, all of which support multi-scale comparisons of neuronal organization. NeuroSC was designed as a series of modular, open-source tools that can be integrated onto other programs or existing resources, enhancing the existing landscape of connectomic tools. NeuroSC was inspired by tools like NemaNode and WormWiring (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>), which enable 3-D visualizations of neuronal morphologies and synaptic sites with synaptic subsets restricted to pre or postsynaptic sites. In NeuroSC, we sought to generate and integrate information beyond the synaptic connectome to include local neuronal regions (contactome) and neuronal morphologies across available developmental vEM datasets. Contactomes represent features that have been largely overlooked in connectomic datasets, and which capture circuit structures not evident by inspecting solely synaptic relationships (<xref ref-type="bibr" rid="bib4">Brittin et al., 2018</xref>; <xref ref-type="bibr" rid="bib51">Yim et al., 2024</xref>; <xref ref-type="bibr" rid="bib13">Cook et al., 2023</xref>). NeuroSC extends existing representations to also offer user-driven experience with choice over the visualization of specific synaptic sites, the option to search for synaptic partners, and the ability to customize the color of each synaptic representation (<xref ref-type="fig" rid="fig7">Figure 7</xref>). NeuroSC representations complement resource databases like WormAtlas, which hosts digitized electron micrographs and schematics of neuron morphologies with aggregated information on each neuron (<xref ref-type="bibr" rid="bib1">Altun et al., 2002</xref>). Neuroglancer (<xref ref-type="bibr" rid="bib27">Maitin-Shepard et al., 2021</xref>), developed by Google, is a powerful interactive tool for visualizing large-scale 3D electron microscopy (EM) and other neuroimaging datasets beyond the <italic>C. elegans</italic> community. Similar in functionality to Webknossos (<xref ref-type="bibr" rid="bib3">Boergens et al., 2017</xref>), it provides detailed views of high-resolution EM data and enables users to explore individual datasets effectively, with a strong emphasis on synaptic connectivity. NeuroSC builds upon these capabilities by offering a complementary approach focused on comparative connectomics and broader neuronal relationships. NeuroSC enables the visualization of EM datasets alongside neuron reconstructions while allowing users to compare neuron relationships across multiple carefully curated datasets. These datasets have been standardized across time points and methodologies, making it possible to track developmental changes in neural circuits with confidence. In addition to synaptic connections, NeuroSC highlights the contactome with rendered contact patches, providing a more complete picture of spatial relationships. Users can dynamically adjust colors of rendered objects, generate scale bars for precise comparisons, and clearly visualize synapses with large geometric representations of pre- and post-synaptic structures. Importantly, neuron names and object relationships appear directly when hovering over a rendering, eliminating the need for external lookup tables. NeuroSC also supports downloading models and creating publication-ready figures, making it a valuable tool for both research and presentation. While NeuroSC does not prioritize the display of raw EM data, this information is accessible through <ext-link ext-link-type="uri" xlink:href="https://NeuroSC.cytoshow.org/">https://NeuroSC.cytoshow.org/</ext-link> (link also available on <ext-link ext-link-type="uri" xlink:href="https://neurosc.net/">https://neurosc.net/</ext-link> in the &quot;About&quot; section) for those who want direct EM inspection. By emphasizing comparability and standardized dataset integration, NeuroSC enables researchers to uncover insights into neural development and connectivity that might not be as easily accessible with single-dataset visualization tools. Together, existing tools and NeuroSC provide complementary ways to explore and analyze complex neural datasets, each offering unique strengths to the neuroscience community.</p></sec><sec id="s3-2"><title>NeuroSC design and future directions</title><p>NeuroSC code and development was intentional in its design as an open-source resource that is modular and allows integration of additional features and data structures (<xref ref-type="bibr" rid="bib7">Cantarelli et al., 2018</xref>). It is a hypothesis-generating tool that can be equally used by educators seeking to teach neuroanatomical principles and researchers seeking to identify changes across connectome datasets. NeuroSC could be integrated into emerging datasets, including developmental time courses of cell-specific transcriptomic data that would enable further insights on the molecular events underpinning neuronal development and function—from synaptogenic processes to the logic of neurotransmitter use (<xref ref-type="bibr" rid="bib31">Packer et al., 2019</xref>; <xref ref-type="bibr" rid="bib44">Taylor et al., 2021</xref>; <xref ref-type="bibr" rid="bib20">Fenyves et al., 2020</xref>) and how it sustains functional connectivity (<xref ref-type="bibr" rid="bib35">Randi et al., 2023</xref>). Future iterations of NeuroSC could also include positions and relationships of neurons to non-neuronal cell types, as well as the relative networks of segmented and quantified organelles within cells. NeuroSC could be used to compare new datasets from genetic variants, from animals trained under specific conditions, or from additional developmental datasets across embryogenesis. As such, the pipeline and design of NeuroSC can serve as a sandbox to examine the value of the integration of datasets in exploring representations of neuronal relationships across connectomes. Currently, the addition of new datasets must be performed in-house. In the future, standardized practices for EM generation and annotation data could facilitate the implementation of a standard importer.</p><p>NeuroSC forms part of a longer tradition that has leveraged the pioneering datasets generated for <italic>C. elegans</italic> connectomes towards exploring structure-function relationships in the nervous system. While the smaller scale of the <italic>C. elegans</italic> neuropil allowed us to rigorously vet the utility of these approaches, we suggest that these same methods would be beneficial in comparative studies in neuropils of other species, including those with less stereotypically formed connectomes. We recognize that more complex organisms possess orders of magnitude more neurons, with significantly larger neuron populations per cell class. However, our previous work has demonstrated that DC/CPHATE clustering of <italic>C. elegans</italic> neurons consistently pulls out clusters of shared neuron classes and shared functional roles (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). Building on this foundation, we envision applying similar clustering approaches to larger connectomes, aiming to identify classes and functionally related neuronal groups in more complex nervous systems. We suggest that contact profiles, along with neuron morphologies and synaptic partners, can act as ‘fingerprints’ for individual neurons and neuron classes. These ‘fingerprints’ can be aligned across animals of the same species to create identities for neurons. Frameworks for systematic connectomics analysis in tractable model systems such as <italic>C. elegans</italic> are critical in laying a foundation for future analyses in other organisms with up to a billion-fold increase in neurons (<xref ref-type="bibr" rid="bib45">Toga et al., 2012</xref>). We think of these collective efforts as akin to the foundational work from <italic>C. elegans</italic> in pioneering genomic analysis and annotations ahead of the Human Genome Project (<xref ref-type="bibr" rid="bib39">Stein et al., 2001</xref>; <xref ref-type="bibr" rid="bib9">Collins and Fink, 1995</xref>). We believe that further integration of datasets in platforms like NeuroSC would be key in determining the representations and features necessary for the interpretation and analyses of other connectomes.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Lead Contact</title><p>Further information and requests can be directed to Daniel.colon-ramos@yale.edu.</p></sec><sec id="s4-2"><title>Data code and availability</title><p>Figures in this article have been generated with NeuroSC (<xref ref-type="fig" rid="fig5">Figure 5D</xref>; <xref ref-type="fig" rid="fig6">Figures 6</xref> and <xref ref-type="fig" rid="fig7">7</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1G–I</xref>, <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>, <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1A–B</xref>, <xref ref-type="fig" rid="fig8">Figure 8</xref>, <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplements 2</xref>–<xref ref-type="fig" rid="fig8s8">8</xref>; <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>, <xref ref-type="video" rid="fig6video1 fig6video2">Figure 6—videos 1; 2</xref>, <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>) and CytoSHOW (<xref ref-type="fig" rid="fig1">Figures 1</xref>—<xref ref-type="fig" rid="fig5">5A and C</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1C</xref>). Data can be visualized via the viewer at <ext-link ext-link-type="uri" xlink:href="https://neurosc.net/">https://neurosc.net/</ext-link> or by downloading glTF files from NeuroSC and using a glTF viewer to visualize them. Additionally, the data generated for NeuroSC is available in .OBJ file format at (and can be visualized from a local hard drive with CytoSHOW <ext-link ext-link-type="uri" xlink:href="https://NeuroSC.cytoshow.org/">https://NeuroSC.cytoshow.org/</ext-link>). All Excel files for DC iterations and adjacency quantifications can be found in <xref ref-type="supplementary-material" rid="supp3 supp4 supp5 supp6 supp7 supp8 supp9 supp10 supp11 supp12 supp13">Supplementary files 3–13</xref>. Tutorials for NeuroSC are available on <ext-link ext-link-type="uri" xlink:href="https://neurosc.net/">https://neurosc.net/</ext-link> upon opening the website, within the main menu of the website (<xref ref-type="fig" rid="fig8s4">Figure 8—figure supplement 4</xref>), and in the supplementary materials (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplements 1</xref>–<xref ref-type="fig" rid="fig8s8">8</xref>; <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>, <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>, <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>). These tutorials generally cover the process of engaging in analysis at and across specific developmental stages by filtering the data items and adding items to viewers (<xref ref-type="fig" rid="fig8s6">Figure 8—figure supplement 6</xref>). General understanding for how to use C-PHATE to analyze neuronal relationships can be found in <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig4">4</xref>, <xref ref-type="fig" rid="fig8s2">Figure 8—figure supplement 2</xref>; <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>, and in our previous publication (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). For additional information on filters and in-viewer changes to the data (colors, developmental stages, downloading data), see <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>, <xref ref-type="fig" rid="fig8s3">Figure 8—figure supplement 3</xref>, <xref ref-type="fig" rid="fig8s7">Figure 8—figure supplement 7</xref>, <xref ref-type="fig" rid="fig8s8">Figure 8—figure supplement 8</xref>, and <xref ref-type="video" rid="fig6video2">Figure 6—video 2</xref>, <xref ref-type="video" rid="fig7video1">Figure 7—video 1</xref>. All code for website development is available at GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/colonramoslab/NeuroSCAN">https://github.com/colonramoslab/NeuroSCAN</ext-link>, <xref ref-type="bibr" rid="bib18">Emerson, 2025</xref>). and for information on website architecture and data model see <xref ref-type="fig" rid="fig8s9">Figure 8—figure supplements 9</xref>–<xref ref-type="fig" rid="fig8s10">10</xref>.</p></sec><sec id="s4-3"><title>Experimental model and subject details</title><p>Volume electron microscopy (vEM) data and segmentation of neurons and synapses were analyzed from <xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib47">White et al., 1986</xref>; <xref ref-type="bibr" rid="bib4">Brittin et al., 2018</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>. We analyzed available EM datasets that were transversely sectioned and segmented (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>; <xref ref-type="bibr" rid="bib47">White et al., 1986</xref>). We deleted the CAN neurons in the L1-L3 datasets to keep these datasets consistent with the legacy datasets L4 and Adult (N2U), which do not contain CAN neurons (as in <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>).</p></sec><sec id="s4-4"><title>Method details</title><p>All 3-D object isosurfaces (Morphologies (Neurons), Contacts, Synapses, C-PHATE plots) were generated from segmented EM datasets using a modified version of the ImageJ 3D viewer plug-in (<xref ref-type="bibr" rid="bib38">Schmid et al., 2010</xref>) implemented in CytoSHOW (<ext-link ext-link-type="uri" xlink:href="https://www.cytoshow.org/">cytoshow.org</ext-link>). This tool employs the marching cubes algorithm for polygon generation. All 3-D objects are first exported as wavefront (.OBJ) files, then converted to GL Transmission Format (.glTF) file format, which does not distort the resolution but compacts the file information to enable faster loading times in the web-based 3-D viewer. We intentionally avoided surface smoothing to renderings to preserve the details of the raw EM data.</p><sec id="s4-4-1"><title>Pixel threshold distance for adjacency profiles and contacts</title><p>We identified two challenges in compiling Electron Microscopy (EM) datasets for comparisons: (1) how to uniformly capture neuronal relationships based on areas of physical adjacency (contact) across datasets that have differences in volume depth and in x-y-z resolutions and (2) how to standardize across datasets in which membrane boundaries had been called using a variety of methods, including contrast methods and segmentation methods (hand-drawn vs predicted via centroid node expansion by a shallow convolutional neural network) (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib4">Brittin et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">White et al., 1986</xref>). To address this, we first standardized the region of the neuropil across all developmental stages as in <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>. Briefly, all cell bodies were deleted, and we used the entry of the nerve ring neurons into the ventral cord as the posterior boundary landmark for the entire volume, focusing on the AIY Zone 2 (<xref ref-type="bibr" rid="bib11">Colón-Ramos et al., 2007</xref>; slice range <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Previously reported adjacency profiles used 10 pixels (or 45 nm) as the pixel threshold distance for the L4 (JSH) and Adult (N2U) datasets (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). To account for differences in resolution (x-y axis) and in calling membrane boundaries between the L4 and Adult datasets and L1-L3 datasets, we designed a protocol to define the pixel threshold for each dataset. In short, for two cells that are in direct contact <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1D</xref> in the manually segmented datasets (L4 and Adult), we calculated the length of overlap needed to reach from the segmented edge of one cell, across the membrane, and into the adjacent cell, when the segmented area of one cell is expanded by 45 nm (10 pixels). This results in an average overlap of 30 nm for directly contacting cells in the L4 dataset. Then, in each computationally segmented dataset (L1-L3), we empirically tested the distance (e.g. 55 nm, 60 nm, 62 nm) required to achieve a similar overlap of 30 nm in direct contact cells. That empirical number (in nm) was used for adjacency calculations and rendering of contacts. The numbers were converted from nanometers into pixels to create a pixel threshold distance for each dataset, and these are shown in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>. Once these corrections had been applied, we calculated the cell-to-cell adjacency scores for all cell pairs in each dataset by using the measure_adjacency algorithm from <ext-link ext-link-type="uri" xlink:href="https://github.com/cabrittin/volumetric_analysis">https://github.com/cabrittin/volumetric_analysis</ext-link> (<xref ref-type="bibr" rid="bib4">Brittin et al., 2018</xref>; <xref ref-type="supplementary-material" rid="supp8 supp9 supp10 supp11 supp12 supp13">Supplementary files 8-13</xref>). Adjacency matrices were used for DC (<xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>). The contact surface areas, shown in the contact stats boxes, each represent the sum of the lengths of each all contact outlines for a given cell pair throughout the EM volume, multiplied by the reported z-axis spacing between the slices, giving units of nm<sup>2</sup>.</p></sec><sec id="s4-4-2"><title>Diffusion condensation</title><p>DC is a dynamic, time-inhomogeneous process designed to create a sequence of multiscale data representations by condensing information over time (<xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>). The primary objective of this technique is to capture and encode meaningful abstractions from high-dimensional data, facilitating tasks such as manifold learning, denoising, clustering, and visualization. The underlying principle of DC is to iteratively apply diffusion operators that adapt to the evolving data representation, effectively summarizing the data at multiple scales. The DC process begins with the initialization of an initial data representation, typically the raw high-dimensional data or a preprocessed version. This initial representation is used to construct a diffusion operator, a matrix derived from a similarity matrix that reflects the local geometry of the data. The similarity metric, such as Euclidean distance or cosine similarity, plays a crucial role in defining these local relationships. For contactome datasets, distances between neurons are determined by the pixel overlap between their segmented shapes in the EM dataset. We use these distances to build a graph with weighted edges, in which the weight of the edge represents the pixel overlap (the adjacency in the actual EM segmentation). Affinities between neurons, which are a proxy for their distance in the graph, are then computed as now revised in <xref ref-type="box" rid="box1">Box 1</xref>, Algorithm 1. This process is done iteratively as neurons cluster. Once the initial diffusion operator is established, the algorithm proceeds to the diffusion step. In this step, the diffusion operator is applied to the data, smoothing it by spreading information along the edges of the similarity graph. This operation captures the intrinsic geometry of the data while reducing noise. The specific form of the diffusion operator, such as the heat kernel or graph Laplacian, significantly impacts how information is propagated during this step. Following the diffusion step, the condensation step updates the data representation by aggregating diffused data points if the distance between them falls below a ‘merge threshold’. This step creates a more compact and abstract representation of the data. These diffusion and condensation steps are iteratively repeated. At each iteration, the diffusion operator is recomputed based on the updated diffuse data representation, ensuring that the process adapts to the evolving structure of the data. The iterations continue until a stopping criterion is met, such as convergence of the data representation to a single point. The output of the DC process is a sequence of multiscale data representations. Each representation in this sequence captures the data at a different level of abstraction, with earlier representations preserving more detailed information and later representations providing more condensed summaries. This sequence of representations can be utilized for various tasks, including manifold learning, denoising, clustering, and visualization. By iteratively smoothing and condensing the data, DC reveals the underlying structure of high-dimensional datasets. The threshold (epsilon) used to merge data points in each iteration is set as a small fraction of the spatial extent of the data: for each coordinate dimension (x, y, z), we compute the range (maximum minus minimum), take the maximum of these three values, and divide it by 10,000. This process is performed iteratively for each round of clustering until all data points cluster into a single point. During DC, we track the modularity of the resulting clusters at each iteration and select the iteration with the highest modularity to define the clusters that represent the strata (<xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>; <xref ref-type="bibr" rid="bib6">Brugnone et al., 2019</xref>). Mathematically, modularity is calculated by comparing the actual number of edges within clusters to the expected number of such edges in a randomized network with the same degree distribution (<xref ref-type="bibr" rid="bib30">Newman, 2006</xref>). A higher modularity value implies that nodes within the same cluster are more densely connected to each other than to nodes in other clusters. A detailed algorithm description is provided in <xref ref-type="box" rid="box1">Box 1</xref> and Algorithm 1.</p><boxed-text id="box1"><label>Box 1.</label><caption><title>Mathematical description of diffusion condensation.</title></caption><p>Diffusion condensation</p><p>Initialization:</p><p>Let <inline-formula><alternatives><mml:math id="inf1"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$\mathbf{X}=\{x_{1},x_{2},\ldots,x_{n}\}$\end{document}</tex-math></alternatives></inline-formula> be the set of <inline-formula><alternatives><mml:math id="inf2"><mml:mstyle><mml:mi>n</mml:mi></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}$  n$\end{document}</tex-math></alternatives></inline-formula> data points in a high-dimensional space. Construct the affinity matrix <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$\mathbf{A}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf4"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}$A_{ij}$\end{document}</tex-math></alternatives></inline-formula> measures the similarity between <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$x_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf6"><mml:mstyle><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft6">\begin{document}$  x_{j}$\end{document}</tex-math></alternatives></inline-formula>. Typically,<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="t1">\begin{document}$$\displaystyle A_{ij}=\exp\left(-\frac{d(x_{i},x_{j})^{2}}{2\sigma^{2}}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>for a chosen scale parameter σ and distance metric <inline-formula><alternatives><mml:math id="inf7"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>d</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}$d$\end{document}</tex-math></alternatives></inline-formula>. In the case of the contactome dataset, the data points represent segmented neurons, and affinities are computed using the number of shared pixels shared by pairs of neurons at their boundary.</p><p>Diffusion Operator:</p><p>Define the degree matrix <inline-formula><alternatives><mml:math id="inf8"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft8">\begin{document}$\mathbf{D}$\end{document}</tex-math></alternatives></inline-formula> as a diagonal matrix where <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}$D_{ii}=\sum_{j}A_{ij}$\end{document}</tex-math></alternatives></inline-formula> . Construct the diffusion operator<disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mrow><mml:mi>𝐏</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>𝐃</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐀</mml:mi></mml:mrow></mml:mrow></mml:math><tex-math id="t2">\begin{document}$$\displaystyle \mathbf{P}=\mathbf{D}^{-1}\mathbf{A}$$\end{document}</tex-math></alternatives></disp-formula></p><p>which normalizes the affinity matrix.</p><p>Diffusion Step:</p><p>Apply the diffusion operator to the data:<disp-formula id="equ3"><alternatives><mml:math id="m3"><mml:mrow><mml:mi>𝐘</mml:mi><mml:mo>=</mml:mo><mml:mi>𝐏𝐗</mml:mi></mml:mrow></mml:math><tex-math id="t3">\begin{document}$$\displaystyle \mathbf{Y}=\mathbf{P}\mathbf{X}$$\end{document}</tex-math></alternatives></disp-formula></p><p>This step smooths the data, capturing the intrinsic geometry.</p><p>Condensation Step:</p><p>After each diffusion step, merge data points that are within a small distance, <inline-formula><alternatives><mml:math id="inf10"><mml:mstyle><mml:mi>ϵ</mml:mi></mml:mstyle></mml:math><tex-math id="inft10">\begin{document}$  \epsilon$\end{document}</tex-math></alternatives></inline-formula> , from each other to form a condensed representation. Specifically, data points <inline-formula><alternatives><mml:math id="inf11"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft11">\begin{document}$y_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf12"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft12">\begin{document}$y_{j}$\end{document}</tex-math></alternatives></inline-formula> are merged if<disp-formula id="equ4"><alternatives><mml:math id="m4"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math><tex-math id="t4">\begin{document}$$\displaystyle \|y_{i}-y_{j}\| \lt \epsilon.$$\end{document}</tex-math></alternatives></disp-formula></p><p>The threshold <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}$\epsilon$\end{document}</tex-math></alternatives></inline-formula> is computed as a small fraction of the coordinate-wise (element-wise) maximum pairwise distance among all pairs of points after the first diffusion step:<disp-formula id="equ5"><alternatives><mml:math id="m5"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:mrow></mml:mfrac><mml:mo>⋅</mml:mo><mml:mrow><mml:munder><mml:mi>max</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="t5">\begin{document}$$\displaystyle \epsilon=\frac{1}{10,000}\cdot\max_{i,j}\|y_{i}-y_{j}\|_{\infty}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf14"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft14">\begin{document}$\|\cdot\|_{\infty}$\end{document}</tex-math></alternatives></inline-formula> denotes the element-wise (coordinate-wise) maximum norm.</p><p>Let <inline-formula><alternatives><mml:math id="inf15"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>π</mml:mi><mml:mo>:</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo stretchy="false">→</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft15">\begin{document}$\pi:\{1,2,\ldots,n\}\to\{1,2,\ldots,k\}$\end{document}</tex-math></alternatives></inline-formula> be a mapping that assigns each data point index <italic>i</italic> to a cluster index <inline-formula><alternatives><mml:math id="inf16"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft16">\begin{document}$\pi(i)$\end{document}</tex-math></alternatives></inline-formula> after condensation. The condensed cluster centers are then given by<disp-formula id="equ6"><alternatives><mml:math id="m6"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝐂</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mtext>where</mml:mtext></mml:mrow></mml:mrow><mml:mo mathvariant="italic" separator="true"> </mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:msup><mml:mi>π</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  \mathbf{C}=\{c_{1},c_{2},\ldots,c_{k}\},\quad\text{where}\quad c_{j}=\frac{1}{|\pi^{-1}(j)|}\sum_{i\in\pi^{-1}(j)}y_{i}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>Modularity:</p><p>To evaluate the community structure after condensation, compute the modularity score <inline-formula><alternatives><mml:math id="inf17"><mml:mstyle><mml:mi>M</mml:mi></mml:mstyle></mml:math><tex-math id="inft17">\begin{document}$  M$\end{document}</tex-math></alternatives></inline-formula><disp-formula id="equ7"><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>e</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>m</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  e_M = \frac{1}{2m} \sum_{i,j} \left( A_{ij} - \frac{d_i d_j}{2m} \right) \delta(\pi(i), \pi(j)) $$\end{document}</tex-math></alternatives></disp-formula></p><p>where:</p><list list-type="bullet" id="list1"><list-item><p><inline-formula><alternatives><mml:math id="inf18"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft18">\begin{document}$d_{i}=\sum_{j}A_{ij}$\end{document}</tex-math></alternatives></inline-formula> is the degree of node <italic>i</italic>,</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf19"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}$m=\frac{1}{2}\sum_{i,j}A_{ij}$\end{document}</tex-math></alternatives></inline-formula> is the total edge weight in the graph, and</p></list-item><list-item><p><inline-formula><alternatives><mml:math id="inf20"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}$\delta(\pi(i),\pi(j))=1$\end{document}</tex-math></alternatives></inline-formula> if <inline-formula><alternatives><mml:math id="inf21"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft21">\begin{document}$\pi(i)=\pi(j)$\end{document}</tex-math></alternatives></inline-formula> (i.e., <inline-formula><alternatives><mml:math id="inf22"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft22">\begin{document}$x_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf23"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft23">\begin{document}$x_{j}$\end{document}</tex-math></alternatives></inline-formula> belong to the same cluster), and 0 otherwise.</p></list-item></list><p>Iteration:</p><p>Repeat the diffusion and condensation steps, adjusting the parameter σ adaptively and keeping track of the modularity score, until all points are merged. Output iteration with highest modularity score.</p></boxed-text><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups" id="AL1"><thead><tr><th align="left" valign="bottom">Algorithm 1. Diffusion condensation</th></tr></thead><tbody><tr><td align="left" valign="bottom">1: <bold>Input:</bold> Data matrix <inline-formula><alternatives><mml:math id="inf24"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft24">\begin{document}$\mathbf{X}={x_1,x_2,\dots,x_n}\in \mathbb{R}^{n\times d}$\end{document}</tex-math></alternatives></inline-formula>, number of iterations <inline-formula><alternatives><mml:math id="inf25"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>T</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft25">\begin{document}$T$\end{document}</tex-math></alternatives></inline-formula>, scale parameter σ, condensation threshold <inline-formula><alternatives><mml:math id="inf26"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>ϵ</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft26">\begin{document}$\epsilon $\end{document}</tex-math></alternatives></inline-formula><break/>2: <bold>Output:</bold> Condensed data matrix <inline-formula><alternatives><mml:math id="inf27"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft27">\begin{document}$\mathbf{X}_{\rm condensed}$\end{document}</tex-math></alternatives></inline-formula><break/>3: <bold>Initialize:</bold> Construct affinity matrix <inline-formula><alternatives><mml:math id="inf28"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft28">\begin{document}$\mathbf{A}$\end{document}</tex-math></alternatives></inline-formula>, degree matrix <inline-formula><alternatives><mml:math id="inf29"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft29">\begin{document}$\mathbf{D}$\end{document}</tex-math></alternatives></inline-formula>, and diffusion operator <inline-formula><alternatives><mml:math id="inf30"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft30">\begin{document}$\mathbf{P}$\end{document}</tex-math></alternatives></inline-formula><break/>4:  <inline-formula><alternatives><mml:math id="inf31"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft31">\begin{document}$\mathbf{A}_{ij} \leftarrow \exp\left(-\frac{d(x_i, x_j)^2}{2\sigma^2}\right)$\end{document}</tex-math></alternatives></inline-formula> for all <italic>i</italic>, <italic>j</italic><break/>5:  <inline-formula><alternatives><mml:math id="inf32"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft32">\begin{document}$\mathbf{D}\leftarrow \text{diag}(\sum\limits_{j}{\mathbf{A}_{ij}})$\end{document}</tex-math></alternatives></inline-formula><break/>6:  <inline-formula><alternatives><mml:math id="inf33"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mo stretchy="false">⟵</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft33">\begin{document}$\mathbf{P}\longleftarrow \mathbf{D}^{-1}\mathbf{A}$\end{document}</tex-math></alternatives></inline-formula><break/>7: <bold>for</bold> iteration = 1 to <inline-formula><alternatives><mml:math id="inf34"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>T</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft34">\begin{document}$T$\end{document}</tex-math></alternatives></inline-formula> <bold>do</bold><break/>8:  <bold>Diffusion Step</bold>:<break/>    <inline-formula><alternatives><mml:math id="inf35"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi mathvariant="bold">P</mml:mi><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft35">\begin{document}$\mathbf{Y}\leftarrow \mathbf{PX}$\end{document}</tex-math></alternatives></inline-formula><break/><break/>9: <bold>Condensation Step:</bold><break/>    Merge data points <inline-formula><alternatives><mml:math id="inf36"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft36">\begin{document}$x_i$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf37"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft37">\begin{document}$x_j$\end{document}</tex-math></alternatives></inline-formula> if <inline-formula><alternatives><mml:math id="inf38"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>ϵ</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft38">\begin{document}$d(x_i,x_j)\lt\epsilon$\end{document}</tex-math></alternatives></inline-formula> to form<break/>    condensed cluster centers <inline-formula><alternatives><mml:math id="inf39"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft39">\begin{document}$\mathbf{c}={c_1,c_2,\dots,c_k}$\end{document}</tex-math></alternatives></inline-formula><break/>10:  <inline-formula><alternatives><mml:math id="inf40"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft40">\begin{document}$\mathbf{X}\leftarrow \mathbf{C}$\end{document}</tex-math></alternatives></inline-formula><break/>11:  <bold>Update:</bold><break/><break/>12: <inline-formula><alternatives><mml:math id="inf41"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft41">\begin{document}$\mathbf{A}_{ij} \leftarrow \exp\left(-\frac{d(x_i, x_j)^2}{2\sigma^2}\right)$\end{document}</tex-math></alternatives></inline-formula> for all <italic>i</italic>, <italic>j</italic><break/>13:  <inline-formula><alternatives><mml:math id="inf42"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>D</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft42">\begin{document}$ D\leftarrow {\rm diag}(\sum\limits_{j}{\mathbf{A}_{ij}} ) $\end{document}</tex-math></alternatives></inline-formula><break/>14:   <inline-formula><alternatives><mml:math id="inf43"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mo stretchy="false">←</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft43">\begin{document}$\mathbf{P}\leftarrow \mathbf{D}^{-1}\mathbf{A}$\end{document}</tex-math></alternatives></inline-formula><break/>15:  <bold>end for</bold><break/>16:  <bold>Return: </bold><inline-formula><alternatives><mml:math id="inf44"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft44">\begin{document}$\mathbf{X}_{\rm condensed}\leftarrow \mathbf{X}$\end{document}</tex-math></alternatives></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s4-4-3"><title>C-PHATE</title><p>C-PHATE is an extension of the PHATE technique (<xref ref-type="bibr" rid="bib28">Moon et al., 2019</xref>) which is specifically aimed at handling and visualizing high-dimensional biological data. C-PHATE is specifically designed to handle compositional data, which are datasets where the components represent parts of a whole and are inherently constrained. It learns the intrinsic manifold of the data, effectively capturing non-linear relationships and structures that are not apparent with traditional methods like PCA or t-SNE. The C-PHATE algorithm starts by loading affinity matrices associated with specific clustering obtained from DC. These matrices are normalized to generate kernel matrices that emphasize the strength of connections within each cluster. The algorithm then builds a connectivity matrix by integrating these kernel matrices based on cluster assignments over multiple time points. This is achieved by first initializing the matrix with kernel matrices along its diagonal and then filling in off-diagonal blocks with transition probabilities that reflect how clusters transition from one time point to the next. Next, we apply the PHATE dimensionality reduction technique to the connectivity matrix to generate 3D embeddings of the data. These embeddings are derived from multiple iterations of DC, capturing the geometry of the data at various levels of granularity. The resulting coordinates are saved for subsequent analysis. The final step involves visualizing the PHATE results in a 3D graphics tool, CytoSHOW (Java-based; <ext-link ext-link-type="uri" xlink:href="https://www.cytoshow.org/">CytoSHOW.org</ext-link>; <ext-link ext-link-type="uri" xlink:href="https://github.com/mohler/CytoSHOW">https://github.com/mohler/CytoSHOW</ext-link>; <xref ref-type="bibr" rid="bib29">Moyle et al., 2021</xref>). The results are plotted in a 3D environment, with functionality enabling rollover labels to display information about clustered cells. This requires cross-referencing output tables from the original data collection. CytoSHOW is an interactive tool that allows for assigning colors and annotations to individual neurons and clusters of interest. A detailed algorithm description is provided in <xref ref-type="box" rid="box2">Box 2</xref> and Algorithm 2. The Python code for C-PHATE allows for user specification of four numerical parameters within the command line, and we used the same set of values for all C-PHATE plots shown in this report (100, 30, 50, 1). The first two integers define the weighting of connectivity between the current condensation step t and previous steps t-1 (weighting = 100) or t-2 (30), respectively, during construction of the connectivity matrix. Values 100 and 30 consistently resulted in a series of plotted clustering trajectories that form a dome-like convergence of paths, enhancing our visual perception of relative relationships and showcasing the super clusters that constitute anatomical strata in the nerve ring neuropil (<xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>). The reproducibility of the dome shape depends on assigning two specific PHATE parameters (<ext-link ext-link-type="uri" xlink:href="https://phate.readthedocs.io/en/stable/api.html">https://phate.readthedocs.io/en/stable/api.html</ext-link>) to non-default values when calling PHATE, the ‘t’ value is set to 50; the ‘randomstate’ value is set to 1.</p><boxed-text id="box2"><label>Box 2.</label><caption><title>Mathematical description of C-PHATE</title></caption><p>Given <inline-formula><alternatives><mml:math id="inf45"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>n</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft45">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula> data points, <inline-formula><alternatives><mml:math id="inf46"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft46">\begin{document}$\mathbf{X}=\{x_{1},x_{2},\ldots,x_{n}\}$\end{document}</tex-math></alternatives></inline-formula>, and the diffusion condensation output, consisting of  <inline-formula><alternatives><mml:math id="inf47"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft47">\begin{document}$\mathbf{C}_{t}=\{c_{1},c_{2},\ldots,c_{k}\}$\end{document}</tex-math></alternatives></inline-formula> denoting the merged data points and <inline-formula><alternatives><mml:math id="inf48"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft48">\begin{document}$\mathbf{A}_{t}$\end{document}</tex-math></alternatives></inline-formula> denoting the affinity matrix at iteration <inline-formula><alternatives><mml:math id="inf49"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft49">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>.</p><p><bold>Kernel Matrix:</bold> For each iteration, <inline-formula><alternatives><mml:math id="inf50"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft50">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, compute the degree matrix <inline-formula><alternatives><mml:math id="inf51"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft51">\begin{document}$ \mathbf{D}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf52"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft52">\begin{document}$D_{ii}=\sum_{j}A_{ij}$\end{document}</tex-math></alternatives></inline-formula>. Then, normalize the affinity matrix to construct the kernel matrix <inline-formula><alternatives><mml:math id="inf53"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft53">\begin{document}$\mathbf{K}_{t}$\end{document}</tex-math></alternatives></inline-formula>:<disp-formula id="equ8"><alternatives><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>𝐊</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>𝐃</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐀</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐃</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math><tex-math id="t8">\begin{document}$$\displaystyle \mathbf{K}_{t}=\mathbf{D}^{-1/2}\mathbf{A}_{t}\mathbf{D}^{-1/2}$$\end{document}</tex-math></alternatives></disp-formula></p><p><bold>Initial Connectivity Matrix:</bold> Initialize the connectivity matrix <inline-formula><alternatives><mml:math id="inf54"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>PHATE</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft54">\begin{document}$\mathbf{C}_{\text{PHATE}}$\end{document}</tex-math></alternatives></inline-formula> with zeros. Next, populate it with the kernel matrices, <inline-formula><alternatives><mml:math id="inf55"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft55">\begin{document}$\mathbf{K}_{t}$\end{document}</tex-math></alternatives></inline-formula> , along its diagonal, reflecting self-connections within each cluster at each time point.</p><p><bold>Update Transition Probabilities:</bold> For each pair of adjacent time points <inline-formula><alternatives><mml:math id="inf56"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft56">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf57"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft57">\begin{document}$t+1$\end{document}</tex-math></alternatives></inline-formula>, compute a transition probability matrix to determine how points transition between clusters <inline-formula><alternatives><mml:math id="inf58"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft58">\begin{document}$C_{t}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf59"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft59">\begin{document}$C_{t+1}$\end{document}</tex-math></alternatives></inline-formula>. Each entry <inline-formula><alternatives><mml:math id="inf60"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft60">\begin{document}$p_{ij}$\end{document}</tex-math></alternatives></inline-formula> in this matrix represents the probability of moving from cluster <italic>i</italic> at time <inline-formula><alternatives><mml:math id="inf61"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft61">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> to cluster <inline-formula><alternatives><mml:math id="inf62"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>j</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft62">\begin{document}$j$\end{document}</tex-math></alternatives></inline-formula> at time <inline-formula><alternatives><mml:math id="inf63"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft63">\begin{document}$t+1$\end{document}</tex-math></alternatives></inline-formula> is calculated by counting the number of points moving from cluster <italic>i</italic> to cluster <italic>j</italic> and normalizing by the total number of points in cluster <italic>i</italic> at time <inline-formula><alternatives><mml:math id="inf64"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft64">\begin{document}$ t$\end{document}</tex-math></alternatives></inline-formula>. This can be expressed as:<disp-formula id="equ9"><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>Number of points moving from </mml:mtext><mml:mi>i</mml:mi><mml:mtext> to </mml:mtext><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>Total number of points in cluster </mml:mtext><mml:mi>i</mml:mi><mml:mtext> at time </mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle  p_{ij}=\frac{\text{Number of points moving from }i\text{ to }j}{\text{Total number of points in cluster }i\text{ at time }t}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Use these transition probabilities to populate the off-diagonal blocks of <inline-formula><alternatives><mml:math id="inf65"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>PHATE</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft65">\begin{document}$\mathbf{C}_{\text{PHATE}}$\end{document}</tex-math></alternatives></inline-formula></p><p><bold>Dimensionality Reduction:</bold> Apply the PHATE algorithm to the final connectivity matrix <inline-formula><alternatives><mml:math id="inf66"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>PHATE</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft66">\begin{document}$\mathbf{C}_{\text{PHATE}}$\end{document}</tex-math></alternatives></inline-formula> to obtain the low-dimensional embedding <inline-formula><alternatives><mml:math id="inf67"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft67">\begin{document}$\mathbf{Y}$\end{document}</tex-math></alternatives></inline-formula>:<disp-formula id="equ10"><alternatives><mml:math id="m10"><mml:mrow><mml:mi>𝐘</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mtext>PHATE</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐂</mml:mi><mml:mtext>PHATE</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math><tex-math id="t10">\begin{document}$$\displaystyle \mathbf{Y}=\text{PHATE}(\mathbf{C}_{\text{PHATE}})$$\end{document}</tex-math></alternatives></disp-formula></p><p><bold>Visualization:</bold> Visualize low-dimensional embedding <inline-formula><alternatives><mml:math id="inf68"><mml:mstyle><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft68">\begin{document}$  \mathbf{Y}$\end{document}</tex-math></alternatives></inline-formula> in CytoSHOW.</p></boxed-text><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups" id="AL2"><thead><tr><th align="left" valign="bottom">Algorithm 2. C-PHATE</th></tr></thead><tbody><tr><td align="left" valign="bottom">1:  <bold>Input:</bold> Output of the Diffusion Condensation algorithm, number of iterations <inline-formula><alternatives><mml:math id="inf69"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>T</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft69">\begin{document}$T$\end{document}</tex-math></alternatives></inline-formula><break/>2:  <bold>Output:</bold> Low-dimensional embedding <inline-formula><alternatives><mml:math id="inf70"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft70">\begin{document}$\mathbf{Y}$\end{document}</tex-math></alternatives></inline-formula><break/>3:  <bold>Initialize:</bold> Load affinity matrices and cluster assignments from diffusion condensation output<break/>4:  <bold>for</bold> <inline-formula><alternatives><mml:math id="inf71"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft71">\begin{document}$t=1$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf72"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>T</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft72">\begin{document}$T$\end{document}</tex-math></alternatives></inline-formula> <bold>do</bold><break/>5:  Load affinity matrix <inline-formula><alternatives><mml:math id="inf73"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft73">\begin{document}$\mathbf{A}_{t}$\end{document}</tex-math></alternatives></inline-formula> from file<break/>6:  Compute degree matrix <inline-formula><alternatives><mml:math id="inf74"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft74">\begin{document}$\mathbf{D}_{t}$\end{document}</tex-math></alternatives></inline-formula> where <inline-formula><alternatives><mml:math id="inf75"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft75">\begin{document}$D_{t_{ii}}=\sum_{j}A_{t_{ij}}$\end{document}</tex-math></alternatives></inline-formula><break/>7:  Normalize to get kernel matrix <inline-formula><alternatives><mml:math id="inf76"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft76">\begin{document}$\mathbf{K}_{t}=\mathbf{D}_{t}^{-1/2}\mathbf{A}_{t}\mathbf{D}_{t}^{-1/2}$\end{document}</tex-math></alternatives></inline-formula><break/>8:  <bold>end for</bold><break/>9:  <inline-formula><alternatives><mml:math id="inf77"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>PHATE</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft77">\begin{document}$\mathbf{C}_{\text{PHATE}}\leftarrow$\end{document}</tex-math></alternatives></inline-formula> zero matrix with kernel matrices <inline-formula><alternatives><mml:math id="inf78"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">K</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft78">\begin{document}$\mathbf{K}_{t}$\end{document}</tex-math></alternatives></inline-formula> along the diagonal<break/>10:  <bold>for</bold> <inline-formula><alternatives><mml:math id="inf79"><mml:mstyle><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math><tex-math id="inft79">\begin{document}$  t=1$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf80"><mml:mstyle><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math><tex-math id="inft80">\begin{document}$  T-1$\end{document}</tex-math></alternatives></inline-formula> <bold>do</bold><break/>11:  Compute transition probabilities matrix <inline-formula><alternatives><mml:math id="inf81"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft81">\begin{document}$\mathbf{P}_{t,t+1}$\end{document}</tex-math></alternatives></inline-formula> for clusters from time <italic>t</italic> to <inline-formula><alternatives><mml:math id="inf82"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft82">\begin{document}$t+1$\end{document}</tex-math></alternatives></inline-formula><break/>12:  <inline-formula><alternatives><mml:math id="inf83"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:mrow><mml:mtext>Number of points moving from cluster </mml:mtext><mml:mi>i</mml:mi><mml:mtext> to cluster </mml:mtext><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>Total number of points in cluster </mml:mtext><mml:mi>i</mml:mi><mml:mtext> at time </mml:mtext><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft83">\begin{document}$\mathbf{P}_{t,t+1}[i,j]\leftarrow\frac{\text{Number of points moving from cluster }i\text{ to cluster }j}{\text{Total number of points in cluster }i \text{ at time }t}$\end{document}</tex-math></alternatives></inline-formula><break/>13:  Update off-diagonal blocks of <inline-formula><alternatives><mml:math id="inf84"><mml:mstyle><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>PHATE</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft84">\begin{document}$  \mathbf{C}_{\text{PHATE}}$\end{document}</tex-math></alternatives></inline-formula> based on <inline-formula><alternatives><mml:math id="inf85"><mml:mstyle><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft85">\begin{document}$  \mathbf{P}_{t,t+1}$\end{document}</tex-math></alternatives></inline-formula><break/>14:  <bold>end for</bold><break/>15:  Compute the PHATE embedding <inline-formula><alternatives><mml:math id="inf86"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft86">\begin{document}$\mathbf{Y}$\end{document}</tex-math></alternatives></inline-formula> from <inline-formula><alternatives><mml:math id="inf87"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mtext>PHATE</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft87">\begin{document}$\mathbf{C}_{\text{PHATE}}$\end{document}</tex-math></alternatives></inline-formula><break/>16:  <bold>Return:</bold><inline-formula><alternatives><mml:math id="inf88"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft88">\begin{document}$\mathbf{Y}$\end{document}</tex-math></alternatives></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s4-4-4"><title>Electron microscopy based 3-D models</title><p>To make 3-D models of neuron morphologies from vEM datasets, we created Image-J format regions of interest (ROIs) using published segmentation data (<xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>; <xref ref-type="bibr" rid="bib47">White et al., 1986</xref>; <xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref>). For a given cell, the stack of all sectioned ROIs was then used to draw binary image masks as input to a customized version of the marching cubes algorithm (<xref ref-type="bibr" rid="bib38">Schmid et al., 2010</xref>) to build and save a 3-D isosurface. All steps of this pipeline were executed within the ImageJ-based Java program, CytoSHOW (<xref ref-type="bibr" rid="bib16">Duncan et al., 2019</xref>). Slightly modified versions of this workflow were also followed for: (1) generating cell-to-cell contact ROIs and (2) for generating 3-D representations of synaptic objects. To align the 3-D models from the variously oriented vEM datasets, all surfaces from a given specimen were rotated and resized to fit a consensus orientation and scale. This was achieved by applying a rotation matrix multiplication and scaling factor to all vertex coordinates in isosurfaces comprising each modeled dataset (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). Each 3-D object (morphology, contact, or synapse) was then exported as a Wavefront file (.OBJ) and then web-optimized by conversion to a Draco-compressed .GLTF file. Each neuron was assigned a type-specific color that is consistent across all datasets to enable facile visual comparison. All the original EM annotations that were used to create the representative 3D models in NeuroSC have been preserved and can be accessed, with instructions via the sister app, CytoSHOW (<ext-link ext-link-type="uri" xlink:href="https://NeuroSC.cytoshow.org">https://NeuroSC.cytoshow.org</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/mohler/CytoSHOW">https://github.com/mohler/CytoSHOW</ext-link>; <xref ref-type="bibr" rid="bib16">Duncan et al., 2019</xref>).</p></sec><sec id="s4-4-5"><title>Morphologies</title><p>Neuron morphologies were linked across datasets for users to visualize changes over time. To enhance 3-D graphics performance without sacrificing gross morphologies, we employed a defined amount of data reduction when building each cell-morphology object. NeuroSC can therefore display multiple (or even all) neurons of a specimen within a single viewer. The number of vertices for a given object was decreased by reducing 10-fold the pixel resolution of the stacked 2-D masks input into the marching cubes algorithm of CytoSHOW.</p></sec><sec id="s4-4-6"><title>Nerve ring</title><p>To make a simplified mesh of the overall nerve ring shape, individual neuron ROIs were fused together into a single nerve-ring-scale-stack of image masks. This was used for input to the marching cubes algorithm. The union of all overlapping enlarged neurite ROIs in a vEM section was data reduced (20-fold reduced pixel resolution). This rendered a performance-friendly outer shell of the nerve ring. Importantly, as noted on the website, the nerve ring rendering should be added after all other manipulations have been made to the scene, as the nerve ring will prevent further interactivity with underlying neurons.</p></sec><sec id="s4-4-7"><title>Contacts</title><p>To build 3-D representations of neuron-neuron contacts, we captured the degree of overlap when an adjacent cell outline was expanded by the specimen-specific, empirically-defined pixel threshold distance listed in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). This was done for each cell outline. This expansion step employs a custom-written method in CytoSHOW that increases the scale of the adjacent outlined region by the pixel threshold distance (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1D and E</xref>), while maintaining its congruent shape. The entire collection of captured 2-D contact overlaps (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1C and F</xref>) for each adjacent neuron pair was then reconstructed as a single 3-D object (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1H</xref>). Contact patches shown in NeuroSC are largely reciprocal (e.g. if there is a AIML contact from PVQL then there will be a PVQL contact from AIML), but rarely, 2-D overlap regions may be too small to be reliably converted to 3-D isosurfaces by the marching cubes algorithm, resulting in absence of an expected reciprocal contact model within the collection. Contacts, like cell morphology models, are named to be automatically linked across time-point datasets and to facilitate user-driven visualization of changes over time.</p></sec><sec id="s4-4-8"><title>Synapses</title><p>Synaptic positions were derived from the original datasets and segmentations, which annotate synaptic sites in the EM cross-sections (<xref ref-type="bibr" rid="bib47">White et al., 1986</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>). To represent these coordinates in the 3-D segmented neurons, we used Blocks (presynaptic sites), Spheres (postsynaptic sites), and Stars (electrical synapses). The synaptic 3-D objects were placed at the annotated coordinates (<xref ref-type="bibr" rid="bib47">White et al., 1986</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>). Additionally, the objects were scaled with the scaling factor (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). Synaptic objects were named by using standard nomenclature across all datasets, as explained in <xref ref-type="fig" rid="fig8s3">Figure 8—figure supplement 3</xref>.</p><p>We note that the L4 and Adult datasets and the L1-L3 datasets were prepared and annotated by different groups (<xref ref-type="bibr" rid="bib47">White et al., 1986</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>). Integration of these datasets reveals nanoscale disagreements in the alignment of the boundaries and synapses. Our representations reflect the original annotations by the authors. Because of these disagreements in annotations, the synapses are not linked across datasets. However, all the original EM annotations that were used to create the representative 3D models in NeuroSC, including the synaptic annotations, have been preserved and can be accessed by the users via the sister app, CytoSHOW, along with detailed user instructions at <ext-link ext-link-type="uri" xlink:href="https://NeuroSC.cytoshow.org">https://NeuroSC.cytoshow.org</ext-link>.</p></sec><sec id="s4-4-9"><title>Website architecture</title><p>The NeuroSC website architecture and data structure were designed to integrate these key user-driven features via a modular platform and linked datasets. The architecture uses Geppetto, an open-source platform designed for neuroscience applications, modularity, and large datasets (<xref ref-type="bibr" rid="bib7">Cantarelli et al., 2018</xref>). Briefly, the architecture is effectively separated into two applications, a front end React/JavaScript bundle that is delivered to the client, rendering the neuron data and assets, and a Golang application that exposes a JSON API, serving the neuron data and assets based on user interactions (<xref ref-type="fig" rid="fig8s9">Figure 8—figure supplement 9</xref>). The backend uses a Postgres database to store underlying data (<xref ref-type="fig" rid="fig8s10">Figure 8—figure supplement 10</xref>), a Persistent Storage Volume that houses and serves static assets, and a variable number of Virtual Machines to run the front end and backend application code, scaling as needed to accommodate traffic. The User Interface is a React application that allows users to filter, sort, and search through the Neurons so that they can be added to an interactive canvas (<xref ref-type="fig" rid="fig8s9">Figure 8—figure supplement 9</xref>). When users add Neurons to a viewer, a .gltf file is loaded in for a given model (Synapses, Neurons, Contacts) at the selected developmental stage (<xref ref-type="fig" rid="fig8s9">Figure 8—figure supplement 9</xref>), which can then be manipulated in the 3D environment or layered with other meshes as needed. NeuroSC can be used on common web browsers (e.g. Google Chrome, Safari) and mobile devices.</p><p>The underlying data model makes use of tables representing Synapses, Neurons, Contacts, and Developmental Stages. Relationships between these models are represented by foreign keys (<xref ref-type="fig" rid="fig8s10">Figure 8—figure supplement 10</xref>). Source data is defined in a file-tree structure containing various assets (such as .gltf files representing various entities), as well as CSVs which store relationships across entities. The directory structure outlines a vertical hierarchy, starting at the developmental stages, then branching downwards onto neuron and synapse data. A Python script is invoked to traverse the directory tree and parse the files, writing to the database accordingly. This configuration enables: (1) verification of the ingested data and (2) quick search times through the datasets to identify related items. Code is version-controlled in GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/colonramoslab/NeuroSCAN">https://github.com/colonramoslab/NeuroSCAN</ext-link>, <xref ref-type="bibr" rid="bib18">Emerson, 2025</xref>) and deployed through a CI/CD pipeline when updates are committed to the main branch (<xref ref-type="fig" rid="fig8s9">Figure 8—figure supplement 9</xref>).</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Jamie I. Emerson is affiliated with Bilte Co. Ventura. The author has no financial interests to declare</p></fn><fn fn-type="COI-statement" id="conf3"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Software, Formal analysis, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Methodology</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Methodology</p></fn><fn fn-type="con" id="con6"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con7"><p>Validation, Investigation</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Software, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Supervision, Methodology</p></fn><fn fn-type="con" id="con10"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Nerve ring regions, resolutions, and pixel threshold distances used to calculate adjacency matrices and to create contact sites for each dataset.</title></caption><media xlink:href="elife-103977-supp1-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Scaling factors and rotation corrections for 3-D representations of Neurons, Contacts, and Synapses for each dataset.</title></caption><media xlink:href="elife-103977-supp2-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>Stratum 1 (Red) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</title></caption><media xlink:href="elife-103977-supp3-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp4"><label>Supplementary file 4.</label><caption><title>Stratum 2 (Purple) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</title></caption><media xlink:href="elife-103977-supp4-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp5"><label>Supplementary file 5.</label><caption><title>Stratum 3 (Blue) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</title></caption><media xlink:href="elife-103977-supp5-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp6"><label>Supplementary file 6.</label><caption><title>Stratum 4 (Green) Sankey diagrams of clustered neurons for each Diffusion Condensation iteration in each dataset.</title></caption><media xlink:href="elife-103977-supp6-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp7"><label>Supplementary file 7.</label><caption><title>Sankey diagrams of AIM, PVQ, and AVF containing clusters for each Diffusion Condensation iteration in each dataset.</title></caption><media xlink:href="elife-103977-supp7-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp8"><label>Supplementary file 8.</label><caption><title>L1 (0 hours post hatching) adjacency counts and searchable counter for summed adjacencies.</title><p>Type the name of a ‘Neuron of Interest’ (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p></caption><media xlink:href="elife-103977-supp8-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp9"><label>Supplementary file 9.</label><caption><title>L1 (5 hours post hatching) adjacency counts and searchable counter for summed adjacencies.</title><p>Type the name of a ‘Neuron of Interest’ (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p></caption><media xlink:href="elife-103977-supp9-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp10"><label>Supplementary file 10.</label><caption><title>L2 (23 hours post hatching) adjacency counts and searchable counter for summed adjacencies.</title><p>Type the name of a ‘Neuron of Interest’ (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p></caption><media xlink:href="elife-103977-supp10-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp11"><label>Supplementary file 11.</label><caption><title>L3 (27 hours post hatching) adjacency counts and searchable counter for summed adjacencies.</title><p>Type the name of a ‘Neuron of Interest’ (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p></caption><media xlink:href="elife-103977-supp11-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp12"><label>Supplementary file 12.</label><caption><title>L4 (36 hours post hatching) adjacency counts and searchable counter for summed adjacencies.</title><p>Type the name of a ‘Neuron of Interest’ (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p></caption><media xlink:href="elife-103977-supp12-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="supp13"><label>Supplementary file 13.</label><caption><title>Adult (48 hours post hatching) adjacency counts and searchable counter for summed adjacencies.</title><p>Type the name of a ‘Neuron of Interest’ (NOI) in the indicated cell to filter for the summed adjacency counts for each contact partner. For each partner, there are two columns: Total number of contacts (number of EM sections NOI and partner are in contact) and Total Weights (summed number of pixels NOI and partner contacts).</p></caption><media xlink:href="elife-103977-supp13-v1.xlsx" mimetype="application" mime-subtype="xlsx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-103977-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All datasets analyzed in this study are publicly available. Electron microscopy reconstructions of <italic>C. elegans</italic> developmental connectomes are accessible through the NeuroSC platform (<ext-link ext-link-type="uri" xlink:href="https://neurosc.net/">https://neurosc.net/</ext-link>) and CytoSHOW (<ext-link ext-link-type="uri" xlink:href="https://neurosc.cytoshow.org/">https://neurosc.cytoshow.org/</ext-link>), with raw data and downloadable files provided in .OBJ and .glTF formats. Supplementary tables containing adjacency matrices, diffusion condensation iterations, and contact statistics are included with this article. All code for NeuroSC development is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/colonramoslab/NeuroSCAN">https://github.com/colonramoslab/NeuroSCAN</ext-link> (<xref ref-type="bibr" rid="bib18">Emerson, 2025</xref>). The original EM datasets were generated and published by <xref ref-type="bibr" rid="bib47">White et al., 1986</xref>, <xref ref-type="bibr" rid="bib5">Brittin et al., 2021</xref> and <xref ref-type="bibr" rid="bib48">Witvliet et al., 2021</xref>, and are publicly available through their respective repositories.</p><p>The following previously published datasets were used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Brittin</surname><given-names>C</given-names></name><name><surname>Cook</surname><given-names>S</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Emmons</surname><given-names>S</given-names></name><name><surname>Cohen</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>A multiscale brain map derived from whole-brain volumetric reconstructions</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.4383277</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Ben Mulcahy</surname><given-names>DW</given-names></name><name><surname>James</surname><given-names>MK</given-names></name><name><surname>Yaron</surname><given-names>M</given-names></name><name><surname>Daniel</surname><given-names>BR</given-names></name><name><surname>Yuelong</surname><given-names>W</given-names></name><name><surname>Yufang</surname><given-names>L</given-names></name><name><surname>Xian</surname><given-names>KW</given-names></name><name><surname>Rajeev</surname><given-names>P</given-names></name><name><surname>Douglas</surname><given-names>H</given-names></name><name><surname>Richard</surname><given-names>SL</given-names></name><name><surname>Nir</surname><given-names>S</given-names></name><name><surname>Andrew</surname><given-names>CD</given-names></name><name><surname>Jeff</surname><given-names>LW</given-names></name><name><surname>Aravinthan</surname><given-names>SDT</given-names></name><name><surname>Mei</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Eight high-resolution electron microscopy volumes of <italic>C. elegans</italic> brains at different stages of development, spanning from birth to adulthood</data-title><source>Bossdb.org</source><pub-id pub-id-type="doi">10.60533/BOSS-2020-FQI7</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We are grateful for current and former members of the Colón-Ramos lab for their guidance and suggestions, in particular, Agustín Almoril-Porras and Malcom Díaz García for assisting with data formatting, Patricia Chanabá-López and Andrea Cuentas-Condori for feedback on the NeuroSC website, Mayra Blakey for administrative roles in managing contracts for funding distribution, and Ben Clark and Milind Singh for feedback on the paper. We also thank Stephen Larson, Dario Del Piano and Zoran Sinnema (MetaCell) for initial website software development, method reporting and hosting services. We thank Brandi Mattson for editing early paper drafts. We acknowledge Ryan Christensen and Hari Shroff (Janelia Research Campus) and Patrick La Riviere (University of Chicago) for helpful discussions and guidance for the NeuroSC website. We thank the Research Center for Minority Institutions program, the Marine Biological Laboratories (MBL), and the Instituto de Neurobiología de la Universidad de Puerto Rico for providing meeting and brainstorming platforms. DAC-R acknowledges the Whitman Fellows program at MBL for providing funding and space for discussions valuable to this work. Research in DAC-R and WAM labs was supported by NIH grant R24-OD016474. This work was also funded by the NIH/NINDS grant R35 NS132156-01, DP1 NS111778 and R01 NS076558–2.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Altun</surname><given-names>ZF</given-names></name><name><surname>Herndon</surname><given-names>LA</given-names></name><name><surname>Wolkow</surname><given-names>CA</given-names></name><name><surname>Crocker</surname><given-names>C</given-names></name><name><surname>Lints</surname><given-names>R</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>WormAtlas</article-title><ext-link ext-link-type="uri" xlink:href="http://www.wormatlas.org">http://www.wormatlas.org</ext-link><date-in-citation iso-8601-date="2025-08-20">August 20, 2025</date-in-citation></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barabási</surname><given-names>DL</given-names></name><name><surname>Bianconi</surname><given-names>G</given-names></name><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Burgess</surname><given-names>M</given-names></name><name><surname>Chung</surname><given-names>S</given-names></name><name><surname>Eliassi-Rad</surname><given-names>T</given-names></name><name><surname>George</surname><given-names>D</given-names></name><name><surname>Kovács</surname><given-names>IA</given-names></name><name><surname>Makse</surname><given-names>H</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Papadimitriou</surname><given-names>C</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name><name><surname>Stachenfeld</surname><given-names>K</given-names></name><name><surname>Toroczkai</surname><given-names>Z</given-names></name><name><surname>Towlson</surname><given-names>EK</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Barabási</surname><given-names>AL</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Neuroscience needs network science</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>5989</fpage><lpage>5995</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1014-23.2023</pub-id><pub-id pub-id-type="pmid">37612141</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boergens</surname><given-names>KM</given-names></name><name><surname>Berning</surname><given-names>M</given-names></name><name><surname>Bocklisch</surname><given-names>T</given-names></name><name><surname>Bräunlein</surname><given-names>D</given-names></name><name><surname>Drawitsch</surname><given-names>F</given-names></name><name><surname>Frohnhofen</surname><given-names>J</given-names></name><name><surname>Herold</surname><given-names>T</given-names></name><name><surname>Otto</surname><given-names>P</given-names></name><name><surname>Rzepka</surname><given-names>N</given-names></name><name><surname>Werkmeister</surname><given-names>T</given-names></name><name><surname>Werner</surname><given-names>D</given-names></name><name><surname>Wiese</surname><given-names>G</given-names></name><name><surname>Wissler</surname><given-names>H</given-names></name><name><surname>Helmstaedter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>webKnossos: efficient online 3D data annotation for connectomics</article-title><source>Nature Methods</source><volume>14</volume><fpage>691</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4331</pub-id><pub-id pub-id-type="pmid">28604722</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Brittin</surname><given-names>CA</given-names></name><name><surname>Cook</surname><given-names>SJ</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Emmons</surname><given-names>SW</given-names></name><name><surname>Cohen</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Volumetric reconstruction of main <italic>Caenorhabditis elegans</italic> neuropil at two different time points</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/485771</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brittin</surname><given-names>CA</given-names></name><name><surname>Cook</surname><given-names>SJ</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Emmons</surname><given-names>SW</given-names></name><name><surname>Cohen</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A multi-scale brain map derived from whole-brain volumetric reconstructions</article-title><source>Nature</source><volume>591</volume><fpage>105</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03284-x</pub-id><pub-id pub-id-type="pmid">33627874</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brugnone</surname><given-names>N</given-names></name><name><surname>Gonopolskiy</surname><given-names>A</given-names></name><name><surname>Moyle</surname><given-names>MW</given-names></name><name><surname>Kuchroo</surname><given-names>M</given-names></name><name><surname>van Dijk</surname><given-names>D</given-names></name><name><surname>Moon</surname><given-names>KR</given-names></name><name><surname>Colon-Ramos</surname><given-names>D</given-names></name><name><surname>Wolf</surname><given-names>G</given-names></name><name><surname>Hirn</surname><given-names>MJ</given-names></name><name><surname>Krishnaswamy</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Coarse graining of data via inhomogeneous diffusion condensation</article-title><source>Proceedings</source><volume>2019</volume><fpage>2624</fpage><lpage>2633</lpage><pub-id pub-id-type="doi">10.1109/BigData47090.2019.9006013</pub-id><pub-id pub-id-type="pmid">32747879</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantarelli</surname><given-names>M</given-names></name><name><surname>Marin</surname><given-names>B</given-names></name><name><surname>Quintana</surname><given-names>A</given-names></name><name><surname>Earnshaw</surname><given-names>M</given-names></name><name><surname>Court</surname><given-names>R</given-names></name><name><surname>Gleeson</surname><given-names>P</given-names></name><name><surname>Dura-Bernal</surname><given-names>S</given-names></name><name><surname>Silver</surname><given-names>RA</given-names></name><name><surname>Idili</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Geppetto: a reusable modular open platform for exploring neuroscience data and models</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>373</volume><elocation-id>20170380</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2017.0380</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>YK</given-names></name><name><surname>Feng</surname><given-names>L</given-names></name><name><surname>Jeong</surname><given-names>WK</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Connecto-informatics at the mesoscale: current advances in image processing and analysis for mapping the brain connectivity</article-title><source>Brain Informatics</source><volume>11</volume><elocation-id>15</elocation-id><pub-id pub-id-type="doi">10.1186/s40708-024-00228-9</pub-id><pub-id pub-id-type="pmid">38833195</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>FS</given-names></name><name><surname>Fink</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The human genome project</article-title><source>Alcohol Health and Research World</source><volume>19</volume><fpage>190</fpage><lpage>195</lpage><pub-id pub-id-type="pmid">31798046</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collinson</surname><given-names>LM</given-names></name><name><surname>Bosch</surname><given-names>C</given-names></name><name><surname>Bullen</surname><given-names>A</given-names></name><name><surname>Burden</surname><given-names>JJ</given-names></name><name><surname>Carzaniga</surname><given-names>R</given-names></name><name><surname>Cheng</surname><given-names>C</given-names></name><name><surname>Darrow</surname><given-names>MC</given-names></name><name><surname>Fletcher</surname><given-names>G</given-names></name><name><surname>Johnson</surname><given-names>E</given-names></name><name><surname>Narayan</surname><given-names>K</given-names></name><name><surname>Peddie</surname><given-names>CJ</given-names></name><name><surname>Winn</surname><given-names>M</given-names></name><name><surname>Wood</surname><given-names>C</given-names></name><name><surname>Patwardhan</surname><given-names>A</given-names></name><name><surname>Kleywegt</surname><given-names>GJ</given-names></name><name><surname>Verkade</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Volume EM: a quiet revolution takes shape</article-title><source>Nature Methods</source><volume>20</volume><fpage>777</fpage><lpage>782</lpage><pub-id pub-id-type="doi">10.1038/s41592-023-01861-8</pub-id><pub-id pub-id-type="pmid">37076630</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colón-Ramos</surname><given-names>DA</given-names></name><name><surname>Margeta</surname><given-names>MA</given-names></name><name><surname>Shen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Glia promote local synaptogenesis through UNC-6 (netrin) signaling in <italic>C. elegans</italic></article-title><source>Science</source><volume>318</volume><fpage>103</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1126/science.1143762</pub-id><pub-id pub-id-type="pmid">17916735</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>SJ</given-names></name><name><surname>Jarrell</surname><given-names>TA</given-names></name><name><surname>Brittin</surname><given-names>CA</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Bloniarz</surname><given-names>AE</given-names></name><name><surname>Yakovlev</surname><given-names>MA</given-names></name><name><surname>Nguyen</surname><given-names>KCQ</given-names></name><name><surname>Tang</surname><given-names>LTH</given-names></name><name><surname>Bayer</surname><given-names>EA</given-names></name><name><surname>Duerr</surname><given-names>JS</given-names></name><name><surname>Bülow</surname><given-names>HE</given-names></name><name><surname>Hobert</surname><given-names>O</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Emmons</surname><given-names>SW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Whole-animal connectomes of both <italic>Caenorhabditis elegans</italic> sexes</article-title><source>Nature</source><volume>571</volume><fpage>63</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1352-7</pub-id><pub-id pub-id-type="pmid">31270481</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>SJ</given-names></name><name><surname>Kalinski</surname><given-names>CA</given-names></name><name><surname>Hobert</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Neuronal contact predicts connectivity in the <italic>C. elegans</italic> brain</article-title><source>Current Biology</source><volume>33</volume><fpage>2315</fpage><lpage>2320</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2023.04.071</pub-id><pub-id pub-id-type="pmid">37236179</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuentas-Condori</surname><given-names>A</given-names></name><name><surname>Mulcahy</surname><given-names>B</given-names></name><name><surname>He</surname><given-names>S</given-names></name><name><surname>Palumbos</surname><given-names>S</given-names></name><name><surname>Zhen</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title><italic>C. elegans</italic> neurons have functional dendritic spines</article-title><source>eLife</source><volume>8</volume><elocation-id>e47918</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.47918</pub-id><pub-id pub-id-type="pmid">31584430</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dorkenwald</surname><given-names>S</given-names></name><name><surname>Matsliah</surname><given-names>A</given-names></name><name><surname>Sterling</surname><given-names>AR</given-names></name><name><surname>Schlegel</surname><given-names>P</given-names></name><name><surname>Yu</surname><given-names>SC</given-names></name><name><surname>McKellar</surname><given-names>CE</given-names></name><name><surname>Lin</surname><given-names>A</given-names></name><name><surname>Costa</surname><given-names>M</given-names></name><name><surname>Eichler</surname><given-names>K</given-names></name><name><surname>Yin</surname><given-names>Y</given-names></name><name><surname>Silversmith</surname><given-names>W</given-names></name><name><surname>Schneider-Mizell</surname><given-names>C</given-names></name><name><surname>Jordan</surname><given-names>CS</given-names></name><name><surname>Brittain</surname><given-names>D</given-names></name><name><surname>Halageri</surname><given-names>A</given-names></name><name><surname>Kuehner</surname><given-names>K</given-names></name><name><surname>Ogedengbe</surname><given-names>O</given-names></name><name><surname>Morey</surname><given-names>R</given-names></name><name><surname>Gager</surname><given-names>J</given-names></name><name><surname>Kruk</surname><given-names>K</given-names></name><name><surname>Perlman</surname><given-names>E</given-names></name><name><surname>Yang</surname><given-names>R</given-names></name><name><surname>Deutsch</surname><given-names>D</given-names></name><name><surname>Bland</surname><given-names>D</given-names></name><name><surname>Sorek</surname><given-names>M</given-names></name><name><surname>Lu</surname><given-names>R</given-names></name><name><surname>Macrina</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Bae</surname><given-names>JA</given-names></name><name><surname>Mu</surname><given-names>S</given-names></name><name><surname>Nehoran</surname><given-names>B</given-names></name><name><surname>Mitchell</surname><given-names>E</given-names></name><name><surname>Popovych</surname><given-names>S</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Jia</surname><given-names>Z</given-names></name><name><surname>Castro</surname><given-names>M</given-names></name><name><surname>Kemnitz</surname><given-names>N</given-names></name><name><surname>Ih</surname><given-names>D</given-names></name><name><surname>Bates</surname><given-names>AS</given-names></name><name><surname>Eckstein</surname><given-names>N</given-names></name><name><surname>Funke</surname><given-names>J</given-names></name><name><surname>Collman</surname><given-names>F</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name><name><surname>Jefferis</surname><given-names>G</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Murthy</surname><given-names>M</given-names></name><collab>FlyWire Consortium</collab></person-group><year iso-8601-date="2023">2023</year><article-title>Neuronal wiring diagram of an adult brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.06.27.546656</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>LH</given-names></name><name><surname>Moyle</surname><given-names>MW</given-names></name><name><surname>Shao</surname><given-names>L</given-names></name><name><surname>Sengupta</surname><given-names>T</given-names></name><name><surname>Ikegami</surname><given-names>R</given-names></name><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Guo</surname><given-names>M</given-names></name><name><surname>Christensen</surname><given-names>R</given-names></name><name><surname>Santella</surname><given-names>A</given-names></name><name><surname>Bao</surname><given-names>Z</given-names></name><name><surname>Shroff</surname><given-names>H</given-names></name><name><surname>Mohler</surname><given-names>W</given-names></name><name><surname>Colón-Ramos</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Isotropic light-sheet microscopy and automated cell lineage analyses to catalogue <italic>Caenorhabditis elegans</italic> embryogenesis with subcellular resolution</article-title><source>Journal of Visualized Experiments</source><volume>148</volume><elocation-id>59533-v</elocation-id><pub-id pub-id-type="doi">10.3791/59533-v</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eberle</surname><given-names>AL</given-names></name><name><surname>Zeidler</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Multi-beam scanning electron microscopy for high-throughput imaging in connectomics research</article-title><source>Frontiers in Neuroanatomy</source><volume>12</volume><elocation-id>112</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2018.00112</pub-id><pub-id pub-id-type="pmid">30618653</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Emerson</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>NeuroSCAN</data-title><version designator="c54fc98">c54fc98</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/colonramoslab/NeuroSCAN">https://github.com/colonramoslab/NeuroSCAN</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feinberg</surname><given-names>EH</given-names></name><name><surname>Vanhoven</surname><given-names>MK</given-names></name><name><surname>Bendesky</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>G</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Shen</surname><given-names>K</given-names></name><name><surname>Bargmann</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>GFP Reconstitution Across Synaptic Partners (GRASP) defines cell contacts and synapses in living nervous systems</article-title><source>Neuron</source><volume>57</volume><fpage>353</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.11.030</pub-id><pub-id pub-id-type="pmid">18255029</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fenyves</surname><given-names>BG</given-names></name><name><surname>Szilágyi</surname><given-names>GS</given-names></name><name><surname>Vassy</surname><given-names>Z</given-names></name><name><surname>Sőti</surname><given-names>C</given-names></name><name><surname>Csermely</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Synaptic polarity and sign-balance prediction using gene expression data in the <italic>Caenorhabditis elegans</italic> chemical synapse neuronal connectome network</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007974</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007974</pub-id><pub-id pub-id-type="pmid">33347479</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flavell</surname><given-names>SW</given-names></name><name><surname>Raizen</surname><given-names>DM</given-names></name><name><surname>You</surname><given-names>YJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Behavioral states</article-title><source>Genetics</source><volume>216</volume><fpage>315</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.1534/genetics.120.303539</pub-id><pub-id pub-id-type="pmid">33023930</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galili</surname><given-names>DS</given-names></name><name><surname>Jefferis</surname><given-names>GS</given-names></name><name><surname>Costa</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Connectomics and the neural basis of behaviour</article-title><source>Current Opinion in Insect Science</source><volume>54</volume><elocation-id>100968</elocation-id><pub-id pub-id-type="doi">10.1016/j.cois.2022.100968</pub-id><pub-id pub-id-type="pmid">36113710</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Altun</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>WormAtlas: The anatomy of <italic>Caenorhabditis elegans</italic></article-title><ext-link ext-link-type="uri" xlink:href="https://www.wormatlas.org">https://www.wormatlas.org</ext-link><date-in-citation iso-8601-date="2025-05-21">May 21, 2025</date-in-citation></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaiser</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Connectomes: from a sparsity of networks to large-scale databases</article-title><source>Frontiers in Neuroinformatics</source><volume>17</volume><elocation-id>1170337</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2023.1170337</pub-id><pub-id pub-id-type="pmid">37377946</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasthuri</surname><given-names>N</given-names></name><name><surname>Hayworth</surname><given-names>KJ</given-names></name><name><surname>Berger</surname><given-names>DR</given-names></name><name><surname>Schalek</surname><given-names>RL</given-names></name><name><surname>Conchello</surname><given-names>JA</given-names></name><name><surname>Knowles-Barley</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Vázquez-Reina</surname><given-names>A</given-names></name><name><surname>Kaynig</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>TR</given-names></name><name><surname>Roberts</surname><given-names>M</given-names></name><name><surname>Morgan</surname><given-names>JL</given-names></name><name><surname>Tapia</surname><given-names>JC</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Roncal</surname><given-names>WG</given-names></name><name><surname>Vogelstein</surname><given-names>JT</given-names></name><name><surname>Burns</surname><given-names>R</given-names></name><name><surname>Sussman</surname><given-names>DL</given-names></name><name><surname>Priebe</surname><given-names>CE</given-names></name><name><surname>Pfister</surname><given-names>H</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Saturated reconstruction of a volume of neocortex</article-title><source>Cell</source><volume>162</volume><fpage>648</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.06.054</pub-id><pub-id pub-id-type="pmid">26232230</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lichtman</surname><given-names>JW</given-names></name><name><surname>Pfister</surname><given-names>H</given-names></name><name><surname>Shavit</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The big data challenges of connectomics</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1448</fpage><lpage>1454</lpage><pub-id pub-id-type="doi">10.1038/nn.3837</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Maitin-Shepard</surname><given-names>J</given-names></name><name><surname>Baden</surname><given-names>A</given-names></name><name><surname>Silversmith</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Google/neuroglancer</data-title><version designator="v2.23">v2.23</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5573294">https://doi.org/10.5281/zenodo.5573294</ext-link></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moon</surname><given-names>KR</given-names></name><name><surname>van Dijk</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Gigante</surname><given-names>S</given-names></name><name><surname>Burkhardt</surname><given-names>DB</given-names></name><name><surname>Chen</surname><given-names>WS</given-names></name><name><surname>Yim</surname><given-names>K</given-names></name><name><surname>van denElzen</surname><given-names>A</given-names></name><name><surname>Hirn</surname><given-names>MJ</given-names></name><name><surname>Coifman</surname><given-names>RR</given-names></name><name><surname>Ivanova</surname><given-names>NB</given-names></name><name><surname>Wolf</surname><given-names>G</given-names></name><name><surname>Krishnaswamy</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Visualizing structure and transitions in high-dimensional biological data</article-title><source>Nature Biotechnology</source><volume>37</volume><fpage>1482</fpage><lpage>1492</lpage><pub-id pub-id-type="doi">10.1038/s41587-019-0336-3</pub-id><pub-id pub-id-type="pmid">31796933</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moyle</surname><given-names>MW</given-names></name><name><surname>Barnes</surname><given-names>KM</given-names></name><name><surname>Kuchroo</surname><given-names>M</given-names></name><name><surname>Gonopolskiy</surname><given-names>A</given-names></name><name><surname>Duncan</surname><given-names>LH</given-names></name><name><surname>Sengupta</surname><given-names>T</given-names></name><name><surname>Shao</surname><given-names>L</given-names></name><name><surname>Guo</surname><given-names>M</given-names></name><name><surname>Santella</surname><given-names>A</given-names></name><name><surname>Christensen</surname><given-names>R</given-names></name><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Moon</surname><given-names>KR</given-names></name><name><surname>Wolf</surname><given-names>G</given-names></name><name><surname>Krishnaswamy</surname><given-names>S</given-names></name><name><surname>Bao</surname><given-names>Z</given-names></name><name><surname>Shroff</surname><given-names>H</given-names></name><name><surname>Mohler</surname><given-names>WA</given-names></name><name><surname>Colón-Ramos</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Structural and developmental principles of neuropil assembly in <italic>C. elegans</italic></article-title><source>Nature</source><volume>591</volume><fpage>99</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-03169-5</pub-id><pub-id pub-id-type="pmid">33627875</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname><given-names>MEJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Modularity and community structure in networks</article-title><source>PNAS</source><volume>103</volume><fpage>8577</fpage><lpage>8582</lpage><pub-id pub-id-type="doi">10.1073/pnas.0601602103</pub-id><pub-id pub-id-type="pmid">16723398</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Packer</surname><given-names>JS</given-names></name><name><surname>Zhu</surname><given-names>Q</given-names></name><name><surname>Huynh</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A lineage-resolved molecular atlas of <italic>C. elegans</italic> embryogenesis at single-cell resolution</article-title><source>Science</source><volume>365</volume><elocation-id>1971</elocation-id><pub-id pub-id-type="doi">10.1126/science.aax1971</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perez</surname><given-names>AJ</given-names></name><name><surname>Seyedhosseini</surname><given-names>M</given-names></name><name><surname>Deerinck</surname><given-names>TJ</given-names></name><name><surname>Bushong</surname><given-names>EA</given-names></name><name><surname>Panda</surname><given-names>S</given-names></name><name><surname>Tasdizen</surname><given-names>T</given-names></name><name><surname>Ellisman</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A workflow for the automatic segmentation of organelles in electron microscopy image stacks</article-title><source>Frontiers in Neuroanatomy</source><volume>8</volume><elocation-id>126</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2014.00126</pub-id><pub-id pub-id-type="pmid">25426032</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phelps</surname><given-names>JS</given-names></name><name><surname>Hildebrand</surname><given-names>DGC</given-names></name><name><surname>Graham</surname><given-names>BJ</given-names></name><name><surname>Kuan</surname><given-names>AT</given-names></name><name><surname>Thomas</surname><given-names>LA</given-names></name><name><surname>Nguyen</surname><given-names>TM</given-names></name><name><surname>Buhmann</surname><given-names>J</given-names></name><name><surname>Azevedo</surname><given-names>AW</given-names></name><name><surname>Sustar</surname><given-names>A</given-names></name><name><surname>Agrawal</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Shanny</surname><given-names>BL</given-names></name><name><surname>Funke</surname><given-names>J</given-names></name><name><surname>Tuthill</surname><given-names>JC</given-names></name><name><surname>Lee</surname><given-names>WCA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Reconstruction of motor control circuits in adult Drosophila using automated transmission electron microscopy</article-title><source>Cell</source><volume>184</volume><fpage>759</fpage><lpage>774</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.12.013</pub-id><pub-id pub-id-type="pmid">33400916</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poole</surname><given-names>RJ</given-names></name><name><surname>Flames</surname><given-names>N</given-names></name><name><surname>Cochella</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Neurogenesis in <italic>Caenorhabditis elegans</italic></article-title><source>Genetics</source><volume>228</volume><elocation-id>iyae116</elocation-id><pub-id pub-id-type="doi">10.1093/genetics/iyae116</pub-id><pub-id pub-id-type="pmid">39167071</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Randi</surname><given-names>F</given-names></name><name><surname>Sharma</surname><given-names>AK</given-names></name><name><surname>Dvali</surname><given-names>S</given-names></name><name><surname>Leifer</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Neural signal propagation atlas of <italic>Caenorhabditis elegans</italic></article-title><source>Nature</source><volume>623</volume><fpage>406</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1038/s41586-023-06683-4</pub-id><pub-id pub-id-type="pmid">37914938</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rapti</surname><given-names>G</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Shan</surname><given-names>A</given-names></name><name><surname>Lu</surname><given-names>Y</given-names></name><name><surname>Shaham</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Glia initiate brain assembly through noncanonical Chimaerin-Furin axon guidance in <italic>C. elegans</italic></article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1350</fpage><lpage>1360</lpage><pub-id pub-id-type="doi">10.1038/nn.4630</pub-id><pub-id pub-id-type="pmid">28846083</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Rivlin</surname><given-names>PK</given-names></name><name><surname>Januszewski</surname><given-names>M</given-names></name><name><surname>Longden</surname><given-names>KD</given-names></name><name><surname>Neace</surname><given-names>E</given-names></name><name><surname>Scheffer</surname><given-names>LK</given-names></name><name><surname>Ordish</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Connectomic analysis of mitochondria in the central brain of <italic>Drosophila</italic></article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.04.21.590464</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmid</surname><given-names>B</given-names></name><name><surname>Schindelin</surname><given-names>J</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Longair</surname><given-names>M</given-names></name><name><surname>Heisenberg</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A high-level 3D visualization API for Java and ImageJ</article-title><source>BMC Bioinformatics</source><volume>11</volume><elocation-id>274</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2105-11-274</pub-id><pub-id pub-id-type="pmid">20492697</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname><given-names>L</given-names></name><name><surname>Sternberg</surname><given-names>P</given-names></name><name><surname>Durbin</surname><given-names>R</given-names></name><name><surname>Thierry-Mieg</surname><given-names>J</given-names></name><name><surname>Spieth</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>WormBase: network access to the genome and biology of <italic>Caenorhabditis elegans</italic></article-title><source>Nucleic Acids Research</source><volume>29</volume><fpage>82</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1093/nar/29.1.82</pub-id><pub-id pub-id-type="pmid">11125056</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sulston</surname><given-names>JE</given-names></name><name><surname>Horvitz</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Post-embryonic cell lineages of the nematode, <italic>Caenorhabditis elegans</italic></article-title><source>Developmental Biology</source><volume>56</volume><fpage>110</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/0012-1606(77)90158-0</pub-id><pub-id pub-id-type="pmid">838129</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sulston</surname><given-names>JE</given-names></name><name><surname>Schierenberg</surname><given-names>E</given-names></name><name><surname>White</surname><given-names>JG</given-names></name><name><surname>Thomson</surname><given-names>JN</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The embryonic cell lineage of the nematode <italic>Caenorhabditis elegans</italic></article-title><source>Developmental Biology</source><volume>100</volume><fpage>64</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/0012-1606(83)90201-4</pub-id><pub-id pub-id-type="pmid">6684600</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Hobert</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Temporal transitions in the postembryonic nervous system of the nematode <italic>Caenorhabditis elegans</italic>: Recent insights and open questions</article-title><source>Seminars in Cell &amp; Developmental Biology</source><volume>142</volume><fpage>67</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/j.semcdb.2022.05.029</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swanson</surname><given-names>LW</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>From cajal to connectome and beyond</article-title><source>Annual Review of Neuroscience</source><volume>39</volume><fpage>197</fpage><lpage>216</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071714-033954</pub-id><pub-id pub-id-type="pmid">27442070</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>SR</given-names></name><name><surname>Santpere</surname><given-names>G</given-names></name><name><surname>Weinreb</surname><given-names>A</given-names></name><name><surname>Barrett</surname><given-names>A</given-names></name><name><surname>Reilly</surname><given-names>MB</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name><name><surname>Varol</surname><given-names>E</given-names></name><name><surname>Oikonomou</surname><given-names>P</given-names></name><name><surname>Glenwinkel</surname><given-names>L</given-names></name><name><surname>McWhirter</surname><given-names>R</given-names></name><name><surname>Poff</surname><given-names>A</given-names></name><name><surname>Basavaraju</surname><given-names>M</given-names></name><name><surname>Rafi</surname><given-names>I</given-names></name><name><surname>Yemini</surname><given-names>E</given-names></name><name><surname>Cook</surname><given-names>SJ</given-names></name><name><surname>Abrams</surname><given-names>A</given-names></name><name><surname>Vidal</surname><given-names>B</given-names></name><name><surname>Cros</surname><given-names>C</given-names></name><name><surname>Tavazoie</surname><given-names>S</given-names></name><name><surname>Sestan</surname><given-names>N</given-names></name><name><surname>Hammarlund</surname><given-names>M</given-names></name><name><surname>Hobert</surname><given-names>O</given-names></name><name><surname>Miller</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Molecular topography of an entire nervous system</article-title><source>Cell</source><volume>184</volume><fpage>4329</fpage><lpage>4347</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2021.06.023</pub-id><pub-id pub-id-type="pmid">34237253</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toga</surname><given-names>AW</given-names></name><name><surname>Clark</surname><given-names>KA</given-names></name><name><surname>Thompson</surname><given-names>PM</given-names></name><name><surname>Shattuck</surname><given-names>DW</given-names></name><name><surname>Van Horn</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Mapping the human connectome</article-title><source>Neurosurgery</source><volume>71</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1227/NEU.0b013e318258e9ff</pub-id><pub-id pub-id-type="pmid">22705717</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Vidal</surname><given-names>B</given-names></name><name><surname>Sural</surname><given-names>S</given-names></name><name><surname>Loer</surname><given-names>C</given-names></name><name><surname>Aguilar</surname><given-names>GR</given-names></name><name><surname>Merritt</surname><given-names>DM</given-names></name><name><surname>Toker</surname><given-names>IA</given-names></name><name><surname>Vogt</surname><given-names>MC</given-names></name><name><surname>Cros</surname><given-names>CC</given-names></name><name><surname>Hobert</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A neurotransmitter atlas of <italic>C. elegans</italic> males and hermaphrodites</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.12.24.573258</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>JG</given-names></name><name><surname>Southgate</surname><given-names>E</given-names></name><name><surname>Thomson</surname><given-names>JN</given-names></name><name><surname>Brenner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>The structure of the nervous system of the nematode <italic>Caenorhabditis elegans</italic></article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>314</volume><fpage>1</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1098/rstb.1986.0056</pub-id><pub-id pub-id-type="pmid">22462104</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Witvliet</surname><given-names>D</given-names></name><name><surname>Mulcahy</surname><given-names>B</given-names></name><name><surname>Mitchell</surname><given-names>JK</given-names></name><name><surname>Meirovitch</surname><given-names>Y</given-names></name><name><surname>Berger</surname><given-names>DR</given-names></name><name><surname>Wu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Koh</surname><given-names>WX</given-names></name><name><surname>Parvathala</surname><given-names>R</given-names></name><name><surname>Holmyard</surname><given-names>D</given-names></name><name><surname>Schalek</surname><given-names>RL</given-names></name><name><surname>Shavit</surname><given-names>N</given-names></name><name><surname>Chisholm</surname><given-names>AD</given-names></name><name><surname>Lichtman</surname><given-names>JW</given-names></name><name><surname>Samuel</surname><given-names>ADT</given-names></name><name><surname>Zhen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Connectomes across development reveal principles of brain maturation</article-title><source>Nature</source><volume>596</volume><fpage>257</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03778-8</pub-id><pub-id pub-id-type="pmid">34349261</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>CS</given-names></name><name><surname>Hayworth</surname><given-names>KJ</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Grob</surname><given-names>P</given-names></name><name><surname>Hassan</surname><given-names>AM</given-names></name><name><surname>García-Cerdán</surname><given-names>JG</given-names></name><name><surname>Niyogi</surname><given-names>KK</given-names></name><name><surname>Nogales</surname><given-names>E</given-names></name><name><surname>Weinberg</surname><given-names>RJ</given-names></name><name><surname>Hess</surname><given-names>HF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Enhanced FIB-SEM systems for large-volume 3D imaging</article-title><source>eLife</source><volume>6</volume><elocation-id>e25916</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.25916</pub-id><pub-id pub-id-type="pmid">28500755</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>CS</given-names></name><name><surname>Pang</surname><given-names>S</given-names></name><name><surname>Shtengel</surname><given-names>G</given-names></name><name><surname>Müller</surname><given-names>A</given-names></name><name><surname>Ritter</surname><given-names>AT</given-names></name><name><surname>Hoffman</surname><given-names>HK</given-names></name><name><surname>Takemura</surname><given-names>S-Y</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Pasolli</surname><given-names>HA</given-names></name><name><surname>Iyer</surname><given-names>N</given-names></name><name><surname>Chung</surname><given-names>J</given-names></name><name><surname>Bennett</surname><given-names>D</given-names></name><name><surname>Weigel</surname><given-names>AV</given-names></name><name><surname>Freeman</surname><given-names>M</given-names></name><name><surname>van Engelenburg</surname><given-names>SB</given-names></name><name><surname>Walther</surname><given-names>TC</given-names></name><name><surname>Farese</surname><given-names>RV</given-names><suffix>Jr</suffix></name><name><surname>Lippincott-Schwartz</surname><given-names>J</given-names></name><name><surname>Mellman</surname><given-names>I</given-names></name><name><surname>Solimena</surname><given-names>M</given-names></name><name><surname>Hess</surname><given-names>HF</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>An open-access volume electron microscopy atlas of whole cells and tissues</article-title><source>Nature</source><volume>599</volume><fpage>147</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03992-4</pub-id><pub-id pub-id-type="pmid">34616045</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yim</surname><given-names>H</given-names></name><name><surname>Choe</surname><given-names>DT</given-names></name><name><surname>Bae</surname><given-names>JA</given-names></name><name><surname>Choi</surname><given-names>M-K</given-names></name><name><surname>Kang</surname><given-names>H-M</given-names></name><name><surname>Nguyen</surname><given-names>KCQ</given-names></name><name><surname>Ahn</surname><given-names>S</given-names></name><name><surname>Bahn</surname><given-names>S-K</given-names></name><name><surname>Yang</surname><given-names>H</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Kim</surname><given-names>JS</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Comparative connectomics of dauer reveals developmental plasticity</article-title><source>Nature Communications</source><volume>15</volume><elocation-id>1546</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-024-45943-3</pub-id><pub-id pub-id-type="pmid">38413604</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Z</given-names></name><name><surname>Lauritzen</surname><given-names>JS</given-names></name><name><surname>Perlman</surname><given-names>E</given-names></name><name><surname>Robinson</surname><given-names>CG</given-names></name><name><surname>Nichols</surname><given-names>M</given-names></name><name><surname>Milkie</surname><given-names>D</given-names></name><name><surname>Torrens</surname><given-names>O</given-names></name><name><surname>Price</surname><given-names>J</given-names></name><name><surname>Fisher</surname><given-names>CB</given-names></name><name><surname>Sharifi</surname><given-names>N</given-names></name><name><surname>Calle-Schuler</surname><given-names>SA</given-names></name><name><surname>Kmecova</surname><given-names>L</given-names></name><name><surname>Ali</surname><given-names>IJ</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Trautman</surname><given-names>ET</given-names></name><name><surname>Bogovic</surname><given-names>JA</given-names></name><name><surname>Hanslovsky</surname><given-names>P</given-names></name><name><surname>Jefferis</surname><given-names>G</given-names></name><name><surname>Kazhdan</surname><given-names>M</given-names></name><name><surname>Khairy</surname><given-names>K</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Bock</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A complete electron microscopy volume of the brain of adult <italic>Drosophila melanogaster</italic></article-title><source>Cell</source><volume>174</volume><fpage>730</fpage><lpage>743</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id><pub-id pub-id-type="pmid">30033368</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103977.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kratsios</surname><given-names>Paschalis</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Chicago</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>NeuroSC is an accessible and interactive tool for streamlined observation of neuronal morphology, membrane contact, and synaptic connectivity across developmental stages in the nematode <italic>C. elegans</italic>. This <bold>important</bold> tool relies on <bold>solid</bold> electron microscopy datasets. This resource will be of high interest to <italic>C. elegans</italic> researchers interested in nervous system wiring and circuit function.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103977.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The authors have done a terrific job and addressed the questions raised in my previous review. There are only some minor requests that I have and list below.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103977.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary</p><p>The past several years has seen publication of both new (Witvliet et al., 2021) and newly analyzed (Cook et al., 2019; Moyle et al., 2021; Brittin et al., 2021) data for the <italic>C. elegans</italic> connectome. The increase in data availability for a single species allows researchers to examine variability due to both stochastic events and due to changes over development. The quantity of these data are huge. To help the community make these data more accessible, the authors present a new online tool that allows examination of 3D models for <italic>C. elegans</italic> neurons in the central neuropil across development. In addition to visualizing the overall structure of the neuronal processes and locations of synapses, the NeuroSC tool also allows users to probe into the C-PHATE visualization results, which this group previously pioneered to describe similarities in neuron adjacency (Moyle et al., 2021).</p><p>Strengths</p><p>The ability to visualize the data from both a connectomics and contactomics perspective across developmental time has significant power. The original <italic>C. elegans</italic> connectome (White et al., 1986) presented their circuits as line drawings with chemical and electrical synapses indicated through arrows and bars. While these line drawings are incredibly useful, they were necessary simplifications for a 2D publication and lack details of the complex architecture seen within each EM image. Koonce et al takes advantage of their own and others segmented image data of each neuronal process within the nerve ring to create a web interface where users can visualize 3D models for their neuron of choice. The C-PHATE visualization is intended to allow users to explore similarities among different neurons in terms of adjacency and then go directly to the 3D model for these neurons. The 3-D models it generates are beautiful and will likely be showing up in many future presentations and publications. The tool doesn't require any additional downloading and is open source. This revision includes an option where hovering over an individual neurons, synapse, or contact will pull up a statistics panel. The addition of text to the video tutorials in the revision is very useful.</p><p>Weaknesses</p><p>There are several bugs with this tool, which make it a bit clunky to use and suggest a lack of rigorous testing. There are also issues with data availability. I was disappointed that my &quot;recommendations for the authors&quot;, which focused on the user interface, were not addressed in the response to reviewers.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103977.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This work provides graphical tools for reconstructing the detailed anatomy of a nervous system from a series of sections imaged by electron microscopy. Contact between neuronal processes can direct outgrowth and is necessary for connectivity, thus function. A bioinformatic approach is used to group neurons according to shared features (e.g., contact, synapses) in a hierarchy of &quot;relatedness&quot; that can be interrogated at each step. In this work, Koonze et al analyze vEM data sets for the <italic>C. elegans</italic> nerve ring (NR), a dense fascicle of processes from181 neurons. In a bioinformatic approach, the clustering algorithm Diffusion Condensation (DC) groups neurons according to similar cell biological features in iterations that remove chunks of differences in feature data with each step ultimately merging all NR neurons in one cluster. DC results are displayed with C-Phate a 3D visualization tool to produce a trajectory that can be interrogated for cell identities and other features at each iterative step. In previous work by these authors, this approach was utilized to identify subgroups of neuronal processes or &quot;strata&quot; in the NR that can be grouped by physical contact and connectivity. Here they expand their analysis to include a series of available vEM data sets across <italic>C. elegans</italic> larval development. This approach suggests that strata initially established during embryonic development are largely preserved in the adult. Importantly, exceptions involving stage specific-specific reorganization of neuronal placement in specific strata were also detected. A case study featured in the paper demonstrates the utility of this approach for visualizing the integration of newly generated neurons into the existing NR anatomy. Visualization tools used in this work are publicly available at NeuroSCAN.</p><p>Strengths:</p><p>A web-based app, NeuroSCAN, that individual researchers can use to interrogate the structure and organization of the <italic>C. elegans</italic> nerve ring across development.</p><p>Weaknesses:</p><p>minor revisions</p><p>Comments on Revisions:</p><p>The authors have satisfactorily addressed my critiques.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103977.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Koonce</surname><given-names>Noelle L</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University School of Medicine</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Emerson</surname><given-names>Sarah E</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University School of Medicine</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Bhaskar</surname><given-names>Dhananjay</given-names></name><role specific-use="author">Author</role><aff><institution>University of Wisconsin-Madison</institution><addr-line><named-content content-type="city">Madison, WI</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Kuchroo</surname><given-names>Manik</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven, CT</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Moyle</surname><given-names>Mark W</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University School of Medicine</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Arroyo-Morales</surname><given-names>Pura</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Vázquez-Martínez</surname><given-names>Nabor</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University School of Medicine</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Emerson</surname><given-names>Jamie I</given-names></name><role specific-use="author">Author</role><aff><institution>Bilte.co</institution><addr-line><named-content content-type="city">Ventura</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Krishnaswamy</surname><given-names>Smita</given-names></name><role specific-use="author">Author</role><aff><institution>Yale School of Medicine</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Mohler</surname><given-names>William</given-names></name><role specific-use="author">Author</role><aff><institution>UConn Health</institution><addr-line><named-content content-type="city">Farmington</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Colón-Ramos</surname><given-names>Daniel A</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public review)</bold></p><p>Comment</p><p>Koonce et al. have generated a web-based visualization tool for exploring <italic>C. elegans</italic> neuronal morphology, contact area between neurons, and synaptic connectivity data. Here, the authors integrate volumetric segmentation of neurons and visualization of contact area patterns of individual neurons generated from Diffusion Condensation and C-PHATE embedding based on previous work from adult volumetric electron microscopy (vEM) data, extended to available vEM data for earlier developmental stages, which effectively summarizes modularity within the collated <italic>C. elegans</italic> contactomes to date. Overall, NeuroSC's relative ease of use for generating visualizations, its ability to quickly toggle between developmental stages, and its integration of a concise visualization of individual neurons' contact patterns strengthen its utility.</p></disp-quote><p>We thank that reviewer for this positive assessment of our work.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>NeuroSC provides an accessible and convenient platform. However, many of the characteristics of NeuroSC overlap with that of an existing tool for visualizing connectomics data, Neuroglancer, which is a widely-used and shared platform with data from other organisms. The authors do not make clear their motivation for generating this new tool rather than building on a system that has already collated previous connectomics data. Although the field will benefit from any tool that collates connectomics data and makes it more accessible and user-friendly, such a tool is only useful if it is kept up-to-date, and if data formatting for submitting electron microscopy data to be added to the tool is made clear. It is unclear from this manuscript whether NeuroSC will be updated with recently published and future <italic>C. elegans</italic> connectomes, or how additional datasets can be submitted to be added in the future.</p></disp-quote><p>We have added new language to more explicitly state the motivations for developing NeuroSC (Introduction, lines 98-111, and discussion lines 375-384). In a new discussion section, we also include comparisons of the features of NeuroSC with other existing tools, like Neuroglancer and Webknossos, (lines 393-417).</p><p>Briefly, the functional features of NeuroSC are substantially different (and do not exist) in other web-based tools for navigating EM datasets, including NeuroGlancer. This is because the intended use of NeuroSC is substantially different (and purposefully synergistic) to the intended use, and tools available, in NeuroGlancer.</p><p>NeuroGlancer is a versatile tool designed primarily for web-based visualizations and sharing of large EM datasets. NeuroSC was not designed to enable this type of access to the primary EM data (purposefully done because these features were already available through tools like NeuroGlancer).</p><p>Instead, the explicit goal of NeuroSC is to provide a platform specifically optimized for examining neuronal relationships across connectomic datasets. NeuroSC builds on the segmentations emerging from programs like NeuroGlancer, but the tools are tailored to explore relationships such as contact profiles in the context of neuronal morphologies and synaptic positions, and across datasets that represent different animals or different developmental stages.</p><p>To achieve this, all datasets in NeuroSC were optimized to facilitate comparisons across different connectomes of segmented neuronal features, including: (1) alignment of the neurons that are compared upon the display of the segmentations; (2) synchronization of the 3D windows; (3) implementation of a ‘universal color code’ across datasets for each neuron and relationship for easy visual comparisons; (4) use of the specific neuronal names to label instances of the same cells across all available datasets. The use of precise neuronal names among separate data sets allows integration of these objects with other catalogued datasets, including genomic and neuronal activity profiles.</p><p>The formatting and display of the datasets used in NeuroSC was accompanied by the development of new tools including: (1) Rendering of the contact profiles of all neurons in the context of the morphology of the cell and the synapses and (2) C-PHATE diagrams to inspect multidimensional relationship hierarchies based on these contact profiles. In NeuroSC, C-PHATEs can be navigated and compared across multiple stages of development while visualizing neuronal reconstructions, allowing users to compare neuronal relationships across individual datasets.</p><p>We agree with the reviewer that these tools are most useful when integrated. With that intention in mind, we designed NeuroSC as a series of modular, open-source tools that could be integrated into other programs, including Neuroglancer. In that sense our intent was not to produce another free-standing tool, but a set of tools that, if useful, could be integrated to other existing web-based connectomic resources to enhance the user experience of navigating complex EM datasets and draw biological meaning from the relationships between the neurons. Additionally, we intentionally designed NeuroSC to enable the ability to integrate new methods of understanding neuron relationships as they arise. We have dedicated a more detailed section to the discussion (lines 369- 417) to better convey this intention and directly address the unique abilities of NeuroSC as a complementary tool to the powerful existing tools, including Neuroglancer.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>The interface for visualizing contacts and synapses would be improved with better user access to the quantitative underlying data. When contact areas or synapses are added to the viewer, adding statistics on the magnitude of the contact area, the number of synapses, and the rank of these values among the neuron's top connections, would make the viewer more useful for hypothesis generation. Furthermore, synapses are currently listed individually, with names that are not very legible to the web user. Grouping them by pre- and postsynaptic neurons and linking these groups across developmental stages would also be an improvement.</p><p>[what do they even mean by linking?]</p></disp-quote><p>We thank the reviewer for this insightful comment and have implemented several improvements to address these suggestions. Specifically, we have added new features to enhance user access to quantitative data within the NeuroDevSCAN viewer:</p><p>Cell, Patch, and Synapse Statistics: Users can now see a statistics panel when clicking on a rendered neuron, contact patch, or a synapse. These panels provide the following information, respectively, and are highlighted in lines 303-315:</p><p>Cell Stats: Click on a cell rendering to show cell stats which displays the total volume and surface area of the selected neuron within the defined neuropil area of our datasets (see Methods).</p><p>Contact Stats: Click on a patch rendering to show ‘contact stats’. This pop up displays quantifications of the selected contact relationship. Rank compares the summed surface area of contacts (&quot;patches&quot;) between these two neurons relative to all other contact relationships for the primary neuron for the cell and the whole nerve ring. A rank of 1, for example, means this neuron pair shares the largest contact surface area of the examined relationship. “Total surface area” is displayed in nanometers, and is the summed surface area of all patches of this identity. Contact percentages are presented in two ways: (1) as the proportion of the primary cell's total surface area occupied by the contact in question, and (2) as the proportion of the total surface area of the nerve ring occupied by that same contact. (Showcased in figure S5).</p><p>Synapse Stats: A click on a synapse rendering now shows ‘synapse stats’, which displays the number of synapses of the selected identity within the primary neuron, including any polyadic synapse combinations involving the primary neurons. (Showcased in figure S7).</p><p>(1) Grouping and Readability Improvements: While individual synapses are still visualized, their display has been improved for legibility. We have condensed the lengthy naming scheme to improve clarity and codified the synapse type by using superscript letters C, E, U to represent chemical, electrical and undefined synapses, respectively. This is explained and shown in figure S7, we added arrows to indicate the directionality of presumed information flow at each synapse.</p><p>(2) Developmental Linkage: We can link objects across datasets via cellular identity, but each synapse in the dataset does not yet have an identity attributed to its spatial coordinates, preventing us from linking specific synapses across development beyond their connectivity (ie, that a given synapses connects cell X to cell Y, for instance), also addressed in R1.11.</p><p>Together, these improvements substantially enhance the utility of the viewer for hypothesis generation by making key quantitative data readily accessible.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>While the DC/C-PHATE visualizations are a useful tool for the user, it is difficult to understand when grouping or splitting of cell contact patterns is biologically significant. DC is a deterministic algorithm applied to a contactome from a single organism, and the authors do not provide quantitative metrics of distances between individual neurons or a number of DC iterations on the C-PHATE plot, nor is the selection process for the threshold for DC described in this manuscript. In the application of DC/C-PHATE to larval stage nerve ring strata organization shown by the authors, qualitative observations of C-PHATE plots colored based on adult data seem to be the only evidence shown for persistent strata during development (Figure 3) or changing architectural motifs across stages (Figure 4). Quantitation of differences in neuron position within the DC hierarchy, or differences in modularity across stages, is needed to support these conclusions. Furthermore, illustrating the quantitative differences in C-PHATE plots used to make these conclusions will provide a more instructive guide for users of NeuroSC in generating future hypotheses.</p></disp-quote><p>There are several ways to visualize DC outputs, and one way to quantitatively compare DC clustering events of neurons is via Sankey diagrams. To make the inclusion of these resources more clear, we have highlighted them in lines 175-178 (Supplemental Tables 3-6). ‘DC outputs for each strata across animals can also be inspected using Sankey diagrams (Supplemental Tables 3-6). These spreadsheets detail the neuron members at each iteration of DC, allowing the user to derive quantitative comparisons of clustering events.’</p><p>As the reviewer points out, DC is a deterministic algorithm that will iteratively cluster neurons based on the similarity of their contact profiles. To better explain the selection process for the threshold, the number of DC iterations and the quantitative metrics between the neurons, we have added new text in the Diffusion Condensation methods section. Briefly:</p><p>Number of DC iterations: During diffusion Condensation (DC) we track the modularity of the resulting clusters at each iteration and select the iteration with the highest modularity to define the clusters that represent the strata (Moyle et al., 2021), (Brugnone et al., 2019). Mathematically, modularity is calculated by comparing the actual number of edges within clusters to the expected number of such edges in a randomized network with the same degree distribution (Newman et al., 2006). A higher modularity value implies that nodes within the same cluster are more densely connected to each other than to nodes in other clusters. We now better explain this in lines 562-567.</p><p>Threshold for merging points: The threshold (epsilon) used to merge data points in each iteration is set as a small fraction of the spatial extent of the data: for each coordinate dimension (x, y, z), we compute the range (maximum minus minimum), take the maximum of these three values, and divide it by 10,000. This process is performed iteratively for each round of clustering until all data points cluster into a single point. We have updated the manuscript to clarify this threshold selection and included this information in the revised algorithm description and pseudocode. We now better explain this in lines 556-559.</p><p>Distances between neurons in DC C-PHATE: In our previous description in Box 1 algorithm 1, we had provided a general algorithm for DC for any high dimensional dataset. We have now revised the algorithm to indicate how we used DC for these EM datasets.</p><p>Distances between neurons are determined by the pixel overlap between their segmented shapes in the EM dataset. We use these distances to build a graph with weighted edges, in which the weight of the edge represents the pixel overlap (the adjacency in the actual EM segmentation). Affinities between neurons, which are a proxy for their distance in the graph, are then computed as now revised in Box 1, Algorithm 1. This process is done iteratively as neurons cluster. To better communicate this, we have changed the text in lines 533-538.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>R1.5. While the case studies presented by the authors help to highlight the utility of the different visualizations offered by the NeuroSC platform, the authors need to be more careful with the claims they make from these correlative observations. For example, in Figure 4, the authors use C-PHATE clustering patterns to make conclusions about changes in clustering patterns of individual neurons across development based on single animal datasets. In this and many other cases presented in this study with the limited existing datasets, it is difficult to differentiate between developmental changes and individual variability between the neurite positions, contacts, and synapse differences within these data. This caveat needs to be clearly addressed.</p></disp-quote><p>We now better explain in the manuscript that the selected case study, of the AVF neuron outgrowth, is not one of just correlation based solely on an EM dataset. Instead, the case study represents the NeuroSC-driven exploration of a biologically significant event supported by several independent datasets, as now explained in lines 257-276.</p><p>Briefly, we agree with the reviewer that examining differences across individual EM datasets is insufficient evidence to make conclusions about developmental changes. But the strength of NeuroSC is in its ability to combine and compare multiple datasets, bolstering observations that are not possible by looking at just one dataset, and providing new insights on the way to new hypotheses. We now better explain that we are not looking at single connectomes in isolation and then deriving conclusions, but instead using NeuroSC to compare across 9 EM datasets. We better explain how the tools in NeuroSC, including C-PHATE, enabled comparisons across these multiple connectomes to identify apparent differences in neuronal relationships. We then explain that by using NeuroSC, we could examine these variations in neuronal relationships at the level of individual, cell biological differences of neuronal morphologies between the developmental datasets. This could be due, as pointed by the reviewer, to differences due to development, or just differences between individual animals. In the case of AVF, that features are absent in all early specimens, then arise and persist in all specimens after a certain time point, which lead us to hypothesize they result from a developmental event. Because the segmented objects in NeuroSC are linked to neuronal identities, we are also able to cross reference our observations from the EM datasets with information in other datasets and the literature. In the specific case of postembryonic development of AVF outgrowth, we can now tie the knowledge, from developmental lineage information and molecular profiles, that AVF is a postembryonically born neuron (Sulston et al. 1977, Sun et al 2022, Poole et al 2024, wormatlas.org) to the outgrowth dynamics of its neurites using the postembryonic EM datasets. Our findings using NeuroSC provide a proof of concept of the utility of the resource and extended our understanding of how the outgrowth of this neuron affects the relationships between the neural circuits in the nerve ring.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>R1.6. Given that recent studies have also quantified contact area between neurons across multiple connectomes (Cook et al., Current Biology, 2023; Yim et al., Nature Communications, 2024), and that the authors use a slightly different approach to quantify contact area, a direct comparison between contact area values obtained in this study with prior studies seems appropriate.</p></disp-quote><p>We acknowledge that there are multiple different approaches to calculate adjacencies. In the papers cited above, there are 3 different algorithms used:</p><p>(1) Brittin 2019 (python parse Track EM, boundary thresholds), used in Cook et al 2023, Moyle 2021, and this study.</p><p>(2) Witvliet 2021 (Matlab 2D masks), used in Cook et al 2023.</p><p>(3) Yim 2024 (3D masks), used in Yim et al 2024.</p><p>To briefly describe the different approaches, and the methods we chose for this paper:</p><p>Algorithm 1 (used in this study) defines adjacency based on distances between boundary points in TrakEM2 segmentations, allowing threshold tuning to accommodate differences in resolution and image quality across datasets—an important feature for consistent cross-dataset comparisons.</p><p>Algorithm 2 infers contact via morphological dilation of VAST segmentations, identifying adjacency through overlapping expanded boundaries.</p><p>Algorithm 3 uses voxelwise contact detection with directional surface area measurements and normalization to account for dataset size differences.</p><p>In NeuroSC, we use algorithm 1, mostly because we had tested the rigor of this method in (Moyle et al. 2021), where we have shown that results were robust across a range of thresholds. This flexibility enables tailored application across datasets of varying quality and scale, critical for NeuroSC’s mission of curating data sets across differing methodologies to allow for direct relationship comparisons. We detail the methodology for defining thresholds for each dataset in methods section lines 492-521, defined in Supplementary table 1. Another difference between our analysis and the previously cited work is that for our analysis we also chose to include all individually resolved neurons, including post-embryonic cells, without collapsing them into left/right or dorsal/ventral symmetry classes. In this way our approach retains the full cellular resolution of the nervous system.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Neuroglancer is not mentioned at all in the manuscript, despite it being a very similar and widely accepted platform for vEM data visualization across model organisms. An explicit comparison of NeuroSC and Neuroglancer would be appropriate, given the similarity of the tools. Currently, published <italic>C. elegans</italic> data (Witvliet et al., 2021; Yim et al., 2024) use Neuroglancer-based viewers, and directly comparing NeuroSC and highlighting its strengths relative to Neuroglancer would strengthen the paper.</p></disp-quote><p>In the original manuscript we had not mentioned tools like Neuroglancer because we envisioned them as distinct, in intended use and output, from NeuroSC. But, as explained in R1.2 comment, in the revised version we have included a section in the Introduction lines 98-108 and in the Discussion (lines 369- 417) that compares these types of web-based tools and highlights synergies.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Assigning shorthand names to strata, such as &quot;shallow reflex circuit&quot; (page 4, line 172), may oversimplify this group of neurons. Either more detailed support for shorthand names of C-PHATE modules should be included, or less speculative names for strata should be used.</p></disp-quote><p>We appreciate this comment and understand that the original language used in the manuscript to describe strata categorizations may run the risk of oversimplification. We have now clarified the text to communicate that: (1) Strata are labeled by numbers (Strata 1, Strata 2, Strata 3 and Strata 4), rather than functional features of the neurons forming part of the strata, and that (2) the assignment of ‘strata’ is just one level of classification available via DC/CPHATE (as explained below).</p><p>To be sure, we have observed and published (Moyle et. al. Nature 2021) that within a given stratum, many neurons share the functional identities that we have used as summary descriptors for the strata (eg, shallow reflex circuits for Stratum 1; sensory and integrative circuits in Strata 3 and Strata 4; command interneurons in Strata 2, etc). However, those cell types are not the only members of the strata. We have adjusted the language in lines 197-204 to reflect this more clearly. “Stratum 1, which contains most neurons contributing to shallow reflex circuits that control aversive head movements in response to noxious stimuli, displayed the fewest changes among the developmental connectomes (Figure 3B–F; Supplementary Table 3). In contrast, <italic>C. elegans</italic> exhibit tractable behaviors that adapt to changing environmental conditions (Flavell et al., 2020). Strata 3 and 4 contain most neurons involved in circuits associated with such learned behaviors, including mechano- and thermo-sensation. This is reflected in Strata 3 and 4 showing the most change in neuronal relationships across postembryonic development.“</p><disp-quote content-type="editor-comment"><p>Comment</p><p>The authors state that NeuroSC can be applied to other model organisms. Since model organisms with greater neuron numbers include more individual neurons per cell class, the authors should support this by quantitatively demonstrating how DC/C-PHATE relationships correlate with shared functional roles among <italic>C. elegans</italic> neurons.</p></disp-quote><p>We now clarify in the manuscript that, like in other organisms, <italic>C. elegans</italic> neurons are also grouped into functional classes with shared characteristics. In the context of the cylindrical nerve ring of the animal, these neuronal classes are sometimes bilaterally symmetric (forming left-right pairs), four-fold symmetric and six-fold symmetric. We now explain in the discussion that the DC/CPHATE analyses group these neuron classes and their relationships (lines 442-451). In the specific section mentioned by the reviewer, we now also add new text to contextualize this concept and how it might relate to the possible use of these tools in organisms with larger nervous systems: ‘However, our previous work has demonstrated that DC/CPHATE clustering of <italic>C. elegans</italic> neurons consistently pulls out clusters of shared neuron classes and shared functional roles Moyle et al. (2021). Building on this foundation, we envision applying similar clustering approaches to larger connectomes, aiming to identify classes and functionally related neuronal groups in more complex nervous systems. We suggest that contact profiles, along with neuron morphologies and synaptic partners, can act as ‘fingerprints’ for individual neurons and neuron classes. These ‘fingerprints’ can be aligned across animals of the same species to create identities for neurons. Frameworks for systematic connectomics analysis in tractable model systems such as <italic>C. elegans</italic> are critical in laying a foundation for future analyses in other organisms with up to a billion-fold increase in neurons (Toga et al., 2012).’</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Lack of surface smoothing in NeuroSC leads to processes sometimes appearing to have gaps, which could be remedied by smoothing with a surface mesh.</p></disp-quote><p>We thank the reviewer for the suggestion, and understand the visibility of gaps in certain neuron processes can be distracting. But this was an intentional choice, with our main goal being to show the most accurate representation of the available data segmentation and avoid any rendering interpretations. In this way, we render the data with the highest fidelity we can and as close as possible to the ground truth of the EM segmentation. We have added language to describe this in the methods, lines 490-491, and in Figure legend 5b.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Toggling between time points while maintaining the same neurons and contact area in NeuroSC is a really valuable feature. The tool would be improved even more by extending this feature to synapses, specifically by allowing the user to add an entire group of synapses to the viewer at once (e.g. &quot;all synapses between AIM and PVQ&quot;), and to keep this synapse group invariant when toggling between developmental stages.</p></disp-quote><p>We thank the reviewer for this suggestion. In response we have now implemented a new feature to ‘clone’ a rendered scene across time while preserving the original elements to ease comparisons. Once the user has rendered a scene, they can use the in-viewer developmental slider to clone the renderings and assigned colors, but display the renderings of the newly selected timepoint. These renderings populate a new window tab which can be dragged to align developmental stage windows side by side. We have added a sentence to account for this in lines 315-317 and to the legend of supplemental Figure S11.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review)</bold></p><p>Comment</p><p>The ability to visualize the data from both a connectomics and contactomics perspective across developmental time has significant power. The original <italic>C. elegans</italic> connectome (White et al., 1986) presented their circuits as line drawings with chemical and electrical synapses indicated through arrows and bars. While these line drawings remain incredibly useful, they were also necessary simplifications for a 2D publication and they lack details of the complex architecture seen within each EM image. Koonce et al take advantage of segmented image data of each neuronal process within the nerve ring to create a web interface where users can visualize 3D models for their neuron of choice. The C-PHATE visualization allows users to explore similarities among different neurons in terms of adjacency and then go directly to the 3D model for these neurons. The 3D models it generates are beautiful and will likely be showing up in many future presentations and publications. The tool doesn't require any additional downloading and is open source.</p></disp-quote><p>We thank that reviewer for this positive assessment of our work.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>While it's impossible to create one tool that will satisfy all potential users, I found myself wanting to have numbers associated with the data. For example, knowing the number of connections or the total surface area of contacts between individual neurons wasn't possible through the viewer, which limits the utility of taking deep analytical dives. While connectivity data is readily accessible through other interfaces such as Nemanode and WormWiring, a more thorough integration may be helpful to some users.</p></disp-quote><p>We thank the reviewer for this feedback and in response have now implemented displays with quantitative information in NeuroSC. Now, upon hovering over a contact patch or synapse, the user will see the quantitative data of the relationship. For contact patches, you will see the total area shared between two neurons in that dataset. On hovering over a synapse, you will see how many synapses there are in total with the same members and throughout the dataset. We agree that this improves user analyses, (see also R1.3 response).</p><disp-quote content-type="editor-comment"><p>Comment</p><p>There were several issues with the user interface that made it a bit clunky to use. For example, as I added additional neurons to the filter search box, the loading time got longer and longer. I ran an experiment uploading all of the amphid neurons, one pair at a time. Each additional neuron pair added an additional 5-10 seconds to the loading. By the time I got to the last pair, it took over a minute to load. Issues like these, some of which may be unavoidable given the size of the data, could be conveyed through better documentation. I did not find the tutorial very helpful and the supplementary movies lacked any voiceover, so it wasn't always clear what they were trying to show.</p></disp-quote><p>We appreciate that some of the more complex models can take a while to load. One of our core goals is to keep the high resolution of our models to most accurately represent the EM data, so we had to compromise between resolution and loading times. But to address this concern we have now added a ‘loading’ prompt that reassures the user when there is a wait. We also added, as suggested, text guidance throughout all of the supplemental videos (Supplemental Videos 1-4).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public review)</bold></p><p>Comment</p><p>A web-based app, NeuroSC, that individual researchers can use to interrogate the structure and organization of the <italic>C. elegans</italic> nerve ring across development In the opinion of this reviewer, only minor revisions are required.</p></disp-quote><p>We thank that reviewer for this positive assessment of our work.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Contact is defined by length, why not contact area? How are these normalized for changes in the overall dimensions of neurons during development?</p></disp-quote><p>To clarify our methodology: the adjacency algorithm that we use generates a 2D adjacency profile by summing the number of adjacent boundary points per EM section, which are then summed across all EM z slices.</p><p>Contact area can be derived by multiplying the adjacency length in each slice by pixel resolution and z-thickness. Prompted by the reviewer we have now also calculated and display contact surface areas, along with their ranks among all contact relationships for a given neuron. These can be inspected directly via the interface by clicking on a rendered cell or contact patch (Figure S5 and lines 308-312). We believe these additional surface area metrics enhance the interpretability and utility of the viewer.</p><p>We apply normalization at the level of the adjacency threshold to account for dataset-specific differences such as contrast, boundary definition, and age-related changes in neuropil packing density. This normalization is applied before running the adjacency algorithm. We do not normalize by individual neuron size, as the contact data are intended to reflect relational differences between neurons, rather than absolute morphological scaling. In fact, our addition of a scale-spheroid within each rendered model emphasizes the large increase in spatial scale that the nerve ring experiences during larval growth.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Figure 1, C&amp;D, explanation unclear for how the adjacency matrix is correlated with C-Phate schematic in D.</p></disp-quote><p>We thank the reviewer for the comment and have clarified this section by adding greater detail to the explanation of how an adjacency matrix is computed (lines 149-155), as well as a description now in the figure legend 1C. Additionally, we revised Figure 1C and D to simplify neuron representations/colors and to simplify the adjacency heat map gradient. We also extended the area of contact between neurons on Figure 1C to better reflect what would be considered a “contact”. Lastly, in the figure, we changed the color and placement for the z plane arrow and label from black to white, to make it more visible, to highlight the method of computing adjacency for each z slice.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Figure 4, panels F &amp; G, unclear why AVF is shown in panel G (L3) but not panel F (L1). Explanation (see below) should be provided earlier, i.e., AVF is not generated until the end of the L1.</p></disp-quote><p>We have now clarified this important point by adding labels to Figure 4 panels F and G, ‘Pre-AVF outgrowth’ and ‘Post-AVF outgrowth’ respectively. Briefly, the point is that AVF grows into the nerve ring after the L2 stage, and that is why it is absent in panel F (L1 stage, now with the label ‘Pre-AVF outgrowth’).</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Line 146 What is the justification for the statement: &quot;By end of Larval Stage 1 (L1), neuronal differentiation has concluded....&quot;? This statement is confusing since this sentence also states that &quot;90% of neurons in the neuropil...have entered the nerve ring...&quot; which would suggest that at least 10% additional NR neurons have NOT fully differentiated.</p></disp-quote><p>We have fixed this sentence in the text. Now the sentence reads ‘By Larval stage 1 (L1) 90% of the neurons in the neuropil (161 neurons out of the 181 neurons) have grown into the nerve ring and adopted characteristic morphologies and positions.</p><disp-quote content-type="editor-comment"><p>Lines 171-175 What is meant by the statement that &quot;degree of these changes mapped onto...plasticity? What are examples of &quot;behavioral plasticity?&quot;</p></disp-quote><p>We have added the following new lines of text (lines 200-204) and now additionally cite a review discussing <italic>C. elegans</italic> behaviors to clarify and give context to behavioral plasticity. ‘<italic>C. elegans</italic> exhibit tractable behaviors which can adapt due to changing environmental conditions (Flavell et. al. Genetics 2020). Strata 3 and 4 contain most neurons belonging to circuits associated with such learned behaviors, including chemo, mechano and thermo sensation. This is seemingly reflected by strata 3 and 4 harboring the most readily recognized set of changes in neuronal relationships across postembryonic development.’</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Lines 189-190 The meaning of this sentence is unclear, &quot;The logic in....merge events.&quot;</p></disp-quote><p>This sentence has been deleted and we have instead refocused our descriptions of C-PHATES comparisons by neuronal clustering trajectories and cluster members (rather than iterations).</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Lines 193-208 This section reports varying levels of convergence across larval development in C-Phate maps for the interneurons AIML and PVQL. Iterations leading to convergence varied: 16 (L1), 14 (L2), 22 (L3), 20 (l4), 14 (adult). The authors suggest that these differences are biologically significant and reflect the reorganization of AIML and PVQL contact relationships especially between the L4 and adult. Are these differences in iterations significant?</p></disp-quote><p>We agree this could be confusing and instead of focusing on comparing the iteration at which each merging event occurs, we now focus on examining the differences in members of clusters, before and after the merge event. Cluster membership is easier to interpret than the differences in the number of DC iterations (lines 224-229).</p><disp-quote content-type="editor-comment"><p>Lines 240-241 States that AVF neurons &quot;terminally differentiate in the embryo&quot; which is not correct. AVF neurons are generated from neuronal precursors (P0 and P1) at the end of the L1 stage which accounts for their outgrowth into the NR during the L2 stage.</p></disp-quote><p>We thank the reviewer for the correction and have edited the text to read: ‘AVF neurons are generated from neuronal precursors (P0 and P1) at the end of the L1 stage Sulston et al. (1983); Sun and Hobert (2023); Poole et al. (2024); Hall and Altun (2008); Sulston and Horvitz (1977). AVF neurons do not grow into the nerve ring until the L2 stage, and continue to grow until the Adult stage (lines 261-266).’</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Lines 289-315. A detailed and highly technical description of website architecture would seem more appropriate for the Methods section.</p></disp-quote><p>We agree and have moved this section to the methods as suggested (lines 663-690).</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Line 307 &quot;source data is&quot; should be &quot;source data are&quot;</p></disp-quote><p>Thank you- we have fixed this grammatical error.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Line 324 &quot;circuits identities&quot; should be &quot;circuit identity&quot;.</p></disp-quote><p>Thank you- we have fixed this grammatical error.</p><disp-quote content-type="editor-comment"><p>Comment</p><p>Trademark/copyright conflict with these sites? <ext-link ext-link-type="uri" xlink:href="https://compumedicsneuroscan.com/about/">https://compumedicsneuroscan.com/about/</ext-link> <ext-link ext-link-type="uri" xlink:href="https://www.neuroscanai.com/">https://www.neuroscanai.com/</ext-link></p></disp-quote><p>We thank the reviewer for drawing our attention to this. To avoid potential conflicts, we have proactively altered the name to NeuroSC throughout the paper.</p></body></sub-article></article>