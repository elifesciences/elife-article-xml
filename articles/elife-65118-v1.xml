<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">65118</article-id><article-id pub-id-type="doi">10.7554/eLife.65118</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Cortical entrainment to hierarchical contextual rhythms recomposes dynamic attending in visual perception</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-219728"><name><surname>Yuan</surname><given-names>Peijun</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-219729"><name><surname>Hu</surname><given-names>Ruichen</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-219731"><name><surname>Zhang</surname><given-names>Xue</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-138502"><name><surname>Wang</surname><given-names>Ying</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5756-2480</contrib-id><email>wangying@psych.ac.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-82847"><name><surname>Jiang</surname><given-names>Yi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5746-7301</contrib-id><email>yijiang@psych.ac.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>State Key Laboratory of Brain and Cognitive Science, CAS Center for Excellence in Brain Science and Intelligence Technology, Institute of Psychology, Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution>Department of Psychology, University of Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution>Chinese Institute for Brain Research</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff4"><label>4</label><institution>Institute of Artificial Intelligence, Hefei Comprehensive National Science Center</institution><addr-line><named-content content-type="city">Hefei</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Luo</surname><given-names>Huan</given-names></name><role>Reviewing Editor</role><aff><institution>Peking University</institution><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Radboud University</institution><country>Netherlands</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>04</day><month>06</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e65118</elocation-id><history><date date-type="received" iso-8601-date="2020-11-23"><day>23</day><month>11</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-05-12"><day>12</day><month>05</month><year>2021</year></date></history><permissions><copyright-statement>Â© 2021, Yuan et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Yuan et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-65118-v1.pdf"/><abstract><p>Temporal regularity is ubiquitous and essential to guiding attention and coordinating behavior within a dynamic environment. Previous researchers have modeled attention as an internal rhythm that may entrain to first-order regularity from rhythmic events to prioritize information selection at specific time points. Using the attentional blink paradigm, here we show that higher-order regularity based on rhythmic organization of contextual features (pitch, color, or motion) may serve as a temporal frame to recompose the dynamic profile of visual temporal attention. Critically, such attentional reframing effect is well predicted by cortical entrainment to the higher-order contextual structure at the delta band as well as its coupling with the stimulus-driven alpha power. These results suggest that the human brain involuntarily exploits multiscale regularities in rhythmic contexts to recompose dynamic attending in visual perception, and highlight neural entrainment as a central mechanism for optimizing our conscious experience of the world in the time dimension.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>visual attention</kwd><kwd>temporal structure</kwd><kwd>neural entrainment</kwd><kwd>attentional blink</kwd><kwd>visual awareness</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31830037</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31771211</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Ying</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002367</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap></funding-source><award-id>XDB32010300</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002367</institution-id><institution>Chinese Academy of Sciences</institution></institution-wrap></funding-source><award-id>2018116</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Ying</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>2020AAA0105600</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The human brain involuntarily exploits multiscale regularities in rhythmic contexts to recompose the dynamic profile of visual temporal attention.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Deploying attention over time is crucial for guiding human activities within a rapidly changing environment. However, the constant influx of information goes far beyond our mental capacity, impeding even the most competent human brain from capturing every nuance of the details. How does the human brain surmount such limitations in temporal attention allocation during dynamic information processing?</p><p>One feasible solution, as that for spatial attention, is through selection, or by shining an attentional âspotlightâ on the most relevant information while filtering out the irrelevant regarding the task demands (<xref ref-type="bibr" rid="bib62">Posner, 1980</xref>). When it comes to the temporal domain, people tend to utilize regularities in the sensory information flow for directing attention to the moments when a target event is expected to occur (<xref ref-type="bibr" rid="bib53">Nobre et al., 2007</xref>; <xref ref-type="bibr" rid="bib54">Nobre and van Ede, 2018</xref>). As a great example, Jones and colleagues have shown in a series of studies that after listening to a rhythmic tone sequence, auditory perception in terms of pitch judgment and time discrimination was more accurate for target tones appearing at the expected than the unexpected time points (<xref ref-type="bibr" rid="bib31">Jones et al., 2002</xref>; <xref ref-type="bibr" rid="bib43">Large and Jones, 1999</xref>). Such facilitation effects have been extended to various aspects of visual perception and even across sensory modalities (<xref ref-type="bibr" rid="bib2">Bolger et al., 2014</xref>; <xref ref-type="bibr" rid="bib7">Brochard et al., 2013</xref>; <xref ref-type="bibr" rid="bib47">Mathewson et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Miller et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">ten Oever et al., 2014</xref>), implicating the involvement of a general attentional selection mechanism guided by the regularity in stimulus timing.</p><p>In this line of studies, perceptual responses were significantly improved for targets appearing within a rhythmic context but not within an arrhythmic context. These findings can be interpreted by the dynamic attending theory (DAT), which assumes attention as an internal oscillatory activity (or attending rhythm) that can be entrained to rhythmic structures of the exogenous events (<xref ref-type="bibr" rid="bib28">Jones, 1976</xref>; <xref ref-type="bibr" rid="bib29">Jones et al., 1981</xref>; <xref ref-type="bibr" rid="bib32">Jones and Boltz, 1989</xref>; <xref ref-type="bibr" rid="bib43">Large and Jones, 1999</xref>). In line with this assumption, electrophysiological research in humans and non-human primates have found entrainment of intrinsic neural oscillations to external stimulus rhythms, and regarded such process as an instrument for selective attention (<xref ref-type="bibr" rid="bib8">Calderone et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Obleser and Kayser, 2019</xref>; <xref ref-type="bibr" rid="bib65">Schroeder and Lakatos, 2009</xref>). Through neural entrainment, neuronal excitability aligns with the occurrence of rhythmic events, creating âtemporal attentional spotlightsâ that attract the brainâs attentional resources toward a string of selected moments (<xref ref-type="bibr" rid="bib8">Calderone et al., 2014</xref>; <xref ref-type="bibr" rid="bib26">Henry and Herrmann, 2014</xref>; <xref ref-type="bibr" rid="bib41">Lakatos et al., 2008</xref>; <xref ref-type="bibr" rid="bib42">Lakatos et al., 2013</xref>; <xref ref-type="bibr" rid="bib65">Schroeder and Lakatos, 2009</xref>).</p><p>The synchronization between the internal attending rhythm and the external rhythms allows us to direct attention proactively and enhance perception at the anticipated moments. With regard to forming a coherent perception of the dynamic environment, however, we should not only select information bound to the anticipated time points, but also allocate attentional resources among these points, raising the problem of dynamic attentional deployment over an information stream. For instance, when viewing a rapid serial visual presentation (RSVP) stream, there is a large chance that the observer would miss the second of two temporally proximate targets, as the allocation of attention to the first target hinders the redeployment of mental resources to the second one (<xref ref-type="bibr" rid="bib6">Broadbent and Broadbent, 1987</xref>). This phenomenon, vividly referred to as the attentional blink (AB)Â (<xref ref-type="bibr" rid="bib11">Chun and Potter, 1995</xref>; <xref ref-type="bibr" rid="bib63">Raymond et al., 1992</xref>), has attracted much interest as it reveals the limitations of attentional allocation and memory processes that may become a bottleneck for conscious awareness (<xref ref-type="bibr" rid="bib16">Dux and Marois, 2009</xref>; <xref ref-type="bibr" rid="bib46">Martens and Wyble, 2010</xref>; <xref ref-type="bibr" rid="bib67">Shapiro et al., 1997</xref>). More intriguingly, as items in the RSVP stream are all rhythmically presented and temporally predictable, the AB effect poses a challenge in dynamic attending that cannot be circumvented solely by the anticipation built upon stimulus timing.</p><p>To address this challenge, here we propose that, the brain has to rely, as a complement to the first-order regularity in rhythmic stimulation, on regularities in the higher-order temporal structure of the information stream. More specifically, if the endogenous attentional rhythm could entrain automatically not only to the stimulus rhythm but also to the higher-order structure based on the information content, the deployment of temporal attention might be reconstructed in a way that facilitates target detection in the AB task. To test this hypothesis, we synchronized the original AB stream (stimulation rate at 10 Hz) to a hierarchical contextual stream that possessed a feature-based temporal structureâa 2.5 Hz rhythm arising from periodic changes of a physical feature, superimposed on its stimulus rhythm at 10 Hz. Using temporal structures defined by a variety of features (pitch, color, etc.), we provided converging evidence that the structured context, which was task-irrelevant and even from a different modality, could regulate the dynamic deployment of visual attention so as to alleviate the AB effect. To further unravel the neural basis of the observed attentional modulation effect, we conducted an electroencephalogram (EEG) experiment. We are particularly interested in whether neural oscillations can entrain to the contextual temporal structure of stimulus feature along with that of stimulus onset timing, and more critically, whether and how the cortical entrainment to these hierarchical structures mediates the behavioral modulation effect.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Temporal structure of contextual auditory stream recomposes visual attentional deployment</title><p>In Experiment 1a, we first explored whether feature-defined temporal structure from a contextual auditory stream could regulate visual attentional deployment during the AB task. If so, the AB effect should be modulated by the positions of the visual targets relative to the structure-defined cycles arising from periodic changes of the background sound (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, see MaterialsÂ andÂ methods for details). Above all, we found a robust AB effect for Experiment 1a, as well as for the other experiments reported in the current study. The accuracy of T1 performance was very high in both the baseline session (meanÂ Â±SE: 0.959Â Â±Â 0.008) and the context session (0.953Â Â±Â 0.006), and the overall T1 performance ranged from 0.907 to 0.972 in all experiments. By contrast, the T2 detection accuracy conditioned on correct T1 response was generally impaired in the short-SOA conditions relative to that in the long-SOA condition (mean accuracyÂ &gt;0.9 for all experiments), during both the context session (<italic>t</italic>(15) = 5.443, p&lt;0.001, Cohenâs <italic>d</italic>Â =Â 1.361) and the baseline session (<italic>t</italic>(15) = 6.720, p&lt;0.001, Cohenâs <italic>d</italic>Â =Â 1.680).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Schematics of stimuli and results for Experiments 1a and 1b.</title><p>(<bold>A</bold>) In the AB task, participants were presented with rapid serial visual presentation (RSVP) streams at 10 Hz (top). Each stream contained two capital letter targets embedded in fourteen number distractors. Black and gray âT1â and âT2â denote two alternative options for target locations in the short-SOA conditions. These targets were located either in two adjacent cycles (the between-cycle condition, displayed on violet background for illustration only) or within the same rhythmic cycle (the within-cycle condition, displayed on green background for illustration only) defined by a rhythmic auditory context in Experiment 1a (middle). Arrhythmic context was used as a control in Experiment 1b (bottom). (B and C) T2 detection accuracy conditioned on correct T1 response for the experiments using rhythmic and arrhythmic contexts. Note that in the baseline (visual-only) session, the labels of âbetweenâ and âwithinâ were used to refer to the conditions where the two targets shared the same absolute positions with their corresponding conditions in the context (audiovisual) session. Error bars represent 1 SEM; *p&lt;0.05.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1âsource data 1.</label><caption><title>T2 detection accuracy for individual participants in Experiments 1a and 1b.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-65118-fig1-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-fig1-v1.tif"/></fig><p>More importantly, looking close at T2 performance in the short-SOA conditions (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), we found T2 was better identified when two targets appeared in two adjacent cycles (between-cycle condition) than within the same cycle defined by the background sounds (within-cycle condition). Notably, such difference was observed only for the context session (<italic>t</italic>(15) = 2.947, p=0.010, Cohenâs <italic>d</italic>Â =Â 0.737) but not for the baseline (no sound) session (<italic>t</italic>(15) = â0.212, p=0.835, Cohenâs <italic>d</italic>Â =Â 0.053), although the target positions were completely matched between these two sessions. Meanwhile, only in the between-cycle condition, the contextual sounds enhanced T2 detection accuracy relative to the baseline (<italic>t</italic>(15) = 2.287, p=0.037, Cohenâs <italic>d</italic>Â =Â 0.572), while in the within-cycle condition, the performance kept comparable between the context and baseline sessions (<italic>t</italic>(15) = â0.271, p=0.790, Cohenâs <italic>d</italic>Â =Â 0.068). The observed dissociation was further confirmed by a two-way repeated-measures ANOVA, which yielded a significant interaction between experimental session (baseline vs. context session) and target position (between- vs. within-cycle, defined by the context) (<italic>F</italic>(1, 15)=7. 151, p=0.017, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.323).</p><p>Results from Experiment 1a demonstrated that feature-based temporal structure of an auditory stream, although being task-irrelevant, could systematically modulate the allocation of visual attention over the AB stream. Since the temporal structure of the contextual sounds was defined by periodic changes of pitch, when two targets were located in distinct cycles as in the between-cycle condition, they were accompanied by different tones, in contrast to that when located within the same cycle they were accompanied by the same tone. It is possible that the contrast of physical stimulation (i.e. pitch) at T1 and T2 could account for the performance improvement in the between-cycle condition. To test this possibility, in Experiment 1b, we matched the pitch of tones at target occurrence with that in Experiment 1a for the between- and within-cycle condition respectively, whereas disrupted feature-based regularity in the temporal structure of the contextual sound sequence (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, bottom). Despite that the sounds paired with the targets were exactly the same as in Experiment 1a, the difference in T2 detection accuracy caused by the contextual sounds was no longer observed (<italic>t</italic>(15) = 0.433, p=0.671, Cohenâs <italic>d</italic>Â =Â 0.108), neither was its interaction with experimental session (<italic>F</italic>(1, 15)=2.734, p=0.119, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.154; <xref ref-type="fig" rid="fig1">Figure 1C</xref>). In other words, T2 was identified with similar accuracy across all the conditions in Experiment 1b, suggesting that it is the temporal structure of the contextual sounds, not the pitch difference at target presentation, that accounts for the between-cycle facilitation effect observed in Experiment 1a.</p></sec><sec id="s2-2"><title>Generalization of the modulation effect to different cycle frequencies</title><p>In Experiment 1a, the auditory context always changed its pitch value every four items, thatÂ is every 400 ms as one cycle, resulting in rhythmic cycles at 2.5 Hz. In Experiment 1 c, we tested whether the modulation effect we observed could be generalized to other cycle frequencies. We set the pitch change rate to 2 Hz (i.e. five items per cycle; <xref ref-type="fig" rid="fig2">Figure 2A</xref>, upper) and 3.3 Hz (i.e. three items per cycle; <xref ref-type="fig" rid="fig2">Figure 2A</xref>, lower). For both context frequencies, the T2 detection performance in the between-cycle condition was significantly higher than that in the within-cycle condition (<xref ref-type="fig" rid="fig2">Figure 2B</xref>; for 2 Hz, <italic>t</italic>(15) = 3.478, p=0.004, Cohenâs <italic>d</italic>Â =Â 0.869; for 3.3 Hz, <italic>t</italic>(15) = 2.467, p=0.030, Cohenâs <italic>d</italic>Â =Â 0.617), suggesting successful attentional modulation effects. Furthermore, a repeated-measures ANOVA on T2 accuracy revealed only a significant main effect of relative target position (i.e. between- vs. within-cycle) (<italic>F</italic>(1, 15)=23.320, p&lt;0.001, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.609), with a marginally significant main effect of frequency (<italic>F</italic>(1, 15)=4.337, p=0.055, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.224) and no interaction between these two factors (<italic>F</italic>(1, 15)=0.204, p=0.658, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.013).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Stimuli and results for Experiments 1 c, 1d and 1e.</title><p>(<bold>A</bold>) Contextual tone sequences with pitch changed every five tones (2 Hz, upper) and every three tones (3.3 Hz, lower) in Experiment 1 c. (<bold>B</bold>) T2 performance in short-SOA conditions for 2 Hz(upper) and 3.3 Hz (lower) sequence in Experiment 1 c. (<bold>C</bold>) The auditory context was grouped irregularly into four chunks with different numbers of tones (Irreg-G) in Experiment 1d (upper) and into four regular chunks (four tones in each) but with irregular onset timing (Irreg-T) in Experiment 1e (lower). (<bold>D</bold>) T2 performance in Experiment 1d (upper) and 1e (lower). Error bars represent 1 SEM; *p&lt;0.05, **p&lt;0.01.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2âsource data 1.</label><caption><title>T2 detection accuracy for individual participants in Experiments 1 c, 1d, and 1e.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-65118-fig2-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-fig2-v1.tif"/></fig></sec><sec id="s2-3"><title>The effect of temporal attention rather than perceptual grouping</title><p>As temporal structure of the context was constructed by auditory items sharing the same feature (i.e. pitch), one may argue that perceptual grouping on the basis of similarity (<xref ref-type="bibr" rid="bib5">Bregman, 1994</xref>), instead of dynamic attending guided by feature-based temporal regularities, contributes to the between-cycle benefit that we observed. To disentangle these factors, in Experiment 1d, we changed the pitch value of tone sequences irregularly to form auditory streams that could be grouped in varying lengths (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, upper). Although temporal grouping was reserved in this setting, no facilitation effect was observed when targets were separated in two distinct groups relative to when they were displayed within the same group (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, Irreg-G). T2 detection performance was comparable in the between- and the within-group conditions (<italic>t</italic>(15) = 0.348, p=0.733, Cohenâs <italic>d</italic>Â =Â 0.087).</p><p>Compared with Experiments 1a and 1 c, the strength of temporal grouping in Experiment 1d might be attenuated due to irregular number of items in each group, which could lead to the lack of behavioral modulation effect. To solve this issue, in Experiment 1e (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, lower), we changed the pitch every four items to keep the rule of temporal grouping exactly the same as that in Experiment 1a. Nevertheless, we disrupted the regularity of stimulus timing. Such manipulation would have a detrimental impact on dynamic deployment of temporal attention in general, according to the basic assumption of the DAT (<xref ref-type="bibr" rid="bib30">Jones et al., 1982</xref>; <xref ref-type="bibr" rid="bib32">Jones and Boltz, 1989</xref>; <xref ref-type="bibr" rid="bib43">Large and Jones, 1999</xref>). On the other hand, it would have little influence on the grouping effect. Therefore, if temporal attention rather than perceptual grouping is essential to the behavioral modulation effect observed in the current study, we should expect such effect to disappear in Experiment 1e. In line with our speculation, when the stimulus onset timing was randomized, T2 detection performance in the between-cycle condition was no longer improved relative to the within-cycle condition (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, Irreg-T; <italic>t</italic>(15) = 0.302, p=0.767, Cohenâs <italic>d</italic>Â =Â 0.076), despite the potential benefit of the grouping effect. Putting together, the absence of context-induced modulation effect in Experiments 1d and 1e consistently supports the idea that temporal grouping without dynamic attending guided by feature- and timing-related regularities in the auditory context is insufficient to cause the behavioral modulation effect.</p></sec><sec id="s2-4"><title>Temporal regularities in color-defined rhythmic structure recompose visual attentional deployment</title><p>Information from the auditory modality, like speech and music, is inherently organized in time and provides rich sources of rhythmic structures that can be proactively tracked by the human brain (<xref ref-type="bibr" rid="bib1">Arnal and Giraud, 2012</xref>; <xref ref-type="bibr" rid="bib15">Doelling and Poeppel, 2015</xref>; <xref ref-type="bibr" rid="bib23">Haegens and Zion Golumbic, 2018</xref>; <xref ref-type="bibr" rid="bib77">Zion Golumbic et al., 2012</xref>). This suggests a possibility that the role of rhythmic structure in guiding attention is exclusive to auditory context, which may explain the findings from Experiment 1 that temporal structures generated by rhythmic changes of auditory signals in the background automatically modulate the AB effect. To test this idea, we designed Experiment 2 to directly investigate whether temporal structures based on the change of visual properties would exert a similar influence on temporal attentional deployment. In Experiment 2a, we used visual patterns with periodic change in background color as the temporal context while observers were performing the same AB task (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). As a control experiment, Experiment 2b followed the same logic for Experiment 1b, in which we destroyed the structure of the visual context by changing the background color in random orders, but kept the background color presented with the targets the same as that in Experiment 2a (<xref ref-type="fig" rid="fig3">Figure 3C</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Stimuli and results for Experiments 2 and 3 using the visual contexts.</title><p>(<bold>A</bold>) The visual context with or without periodic changes in the background color and (<bold>B</bold>) the T2 performance in Experiment 2a. (<bold>C</bold>) The visual context with or without the background color changed irregularly and (<bold>D</bold>) the T2 performance in Experiment 2b. (<bold>E</bold>) Contextual rhythms defined by cyclic/random motion at a constant speed and (<bold>F</bold>) the T2 performance in Experiment 3. Error bars represent 1 SEM; *p&lt;0.05, **p&lt;0.01.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3âsource data 1.</label><caption><title>T2 detection accuracy for individual participants in Experiments 2a, 2b, and 3.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-65118-fig3-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-fig3-v1.tif"/></fig><p>Similar to findings obtained from Experiment 1a, the interaction between experimental session (baseline vs. context session) and target position (between- vs. within-cycle) was significant in Experiment 2a (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; <italic>F</italic>(1, 15)=5.180, p=0.038, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.257). In the context session only, T2 performance in the between-cycle condition was better than that in the within-cycle condition (<italic>t</italic>(15) = 3.538, p=0.003, Cohenâs <italic>d</italic>Â =Â 0.885). Compared with the baseline session, T2 performance was only improved in the between-cycle condition (<italic>t</italic>(15) = 2.274, p=0.038, Cohenâs <italic>d</italic>Â =Â 0.569). By contrast, in Experiment 2b, we did not observe a significant facilitation effect in the between-cycle condition compared with the within-cycle condition (<italic>t</italic>(15) = â1.176, p=0.258, Cohenâs <italic>d</italic>Â =Â 0.294) or with its counterpart in the baseline session (<italic>t</italic>(15) = 0.685, p=0.504, Cohenâs <italic>d</italic>Â =Â 0.171), nor did we observe the interaction between experimental session and target position (<xref ref-type="fig" rid="fig3">Figure 3D</xref>; <italic>F</italic>(1, 15)=1.435, p=0.250, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.087). These findings suggest that the utilization of feature-based temporal regularities in attentional guidance is a fundamental principle that holds true not only for auditory but also for visual processing.</p></sec><sec id="s2-5"><title>Excluding the impact of structure boundary: evidence from motion context</title><p>So far, results from Experiments 1 and 2 have demonstrated a general regulatory effect that feature-based temporal structure from task-irrelevant information recomposed visual attentional allocation during the AB task, which could be exerted within the same or cross different sensory modalities. In both experiments, however, the switch from one feature-based rhythmic cycle to another was always accompanied by an abrupt change in physical features (pitch or color), resulting in anÂ explicit boundary before T2 presentation in the between-cycle but not in the within-cycle condition. This abrupt change may serve as an attentional cue or alerting signal for the upcoming T2, and thus accounts for the improvement of performance in the between-cycle condition. To examine this possibility, in Experiment 3, we introduced a cyclic motion context that possessed feature-based rhythmicity identical to those contextual rhythms in previous experiments (for more details, see Materials and methods) but had no abrupt boundaries between cycles (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Once again, we observed significant improvement of T2 performance in the between-cycle condition relative to the within-cycle condition in the cyclic motion session (<xref ref-type="fig" rid="fig3">Figure 3F</xref>; <italic>t</italic>(15) = 2.674, p=0.017, Cohenâs <italic>d</italic>Â =Â 0.669), but this was not the case in the random motion session (<italic>t</italic>(15) = â0.330, p=0.746, Cohenâs <italic>d</italic>Â =Â 0.082), resulting in a significant interaction between experimental session (random vs. cyclic motion session) and target position (between- vs. within-cycle): <italic>F</italic>(1, 15)=9.253, p=0.008, Î·<italic><sub>p</sub></italic><sup>2</sup>Â =Â 0.382. These results provide compelling evidence that explicit perceptual boundaries are not necessary for the temporal structure in the context to regulate the allocation of attentional resources.</p></sec><sec id="s2-6"><title>EEG experiment: the role of neural entrainment in regulating attentional deployment</title><sec id="s2-6-1"><title>Neural tracking of higher-order temporal structure of contextual rhythms predicts the behavioral modulation effect</title><p>To investigate the neural mechanisms underlying the observed context-induced effect, we carried out an EEG experiment using the same task as that in Experiment 1a. First of all, we replicated the behavioral modulation effect that T2 performance was significantly better in the between-cycle condition versus the within-cycle condition, only in the context session (between-cycle: 0.567Â Â±Â 0.036, within-cycle: 0.520Â Â±Â 0.039, <italic>t</italic>(15) = 3.838, p=0.002, Cohenâs <italic>d</italic>Â =Â 0.960) but not in the baseline session (between-cycle: 0.519Â Â±Â 0.039, within-cycle: 0.527Â Â±Â 0.043, <italic>t</italic>(15) = 0.296, p=0.771, Cohenâs <italic>d</italic>Â =Â 0.074). Furthermore, to identify the oscillatory characteristics of EEG signals in response to stimulus rhythms, we examined the FFT spectral peaks by subtracting the mean power of two nearest neighboring frequencies from the power at the stimulus frequency. Power spectrum in <xref ref-type="fig" rid="fig4">Figure 4A</xref> shows several peaks for the context session, with the highest at 10 Hz (compared with zero using one-sample <italic>t</italic>-test, right-tailed, <italic>t</italic>(15) = 10.610, p&lt;0.001, FDR-corrected for multiple comparisons across frequencies) corresponding to the common stimulation frequency of the visual and auditory streams. More importantly, the second-highest peak appeared at 2.5 Hz (<italic>t</italic>(15) = 5.730, p&lt;0.001, FDR-corrected), followed by its harmonics at 5 and 7.5 Hz, indicating neural tracking of the feature-defined structure of the auditory context. In contrast with the observation in the context session, we only found significant power peak at 10 Hz (<italic>t</italic>(15) = 9.405, p&lt;0.001, FDR-corrected), but not at 2.5 Hz (<italic>t</italic>(15) = 0.301, p=0.384, FDR-corrected) in the baseline session where contextual rhythms were absent, and the power at 2.5 Hz was significantly weaker than that in the context session (<italic>t</italic>(15) = 3.421, p=0.002, FDR-corrected).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Neural entrainment to contextual rhythms and its correlation with the attentional modulation effect.</title><p>(<bold>A</bold>) The power spectrum of EEG signals averaged across all epochs and channels. For each frequency, power was normalized by subtracting the mean power of the two nearest neighboring frequencies from the power of the center frequency. Shaded areas indicate standard errors of the mean. (<bold>B</bold>) The 2.5 Hz power entrainment effect at the parieto-occipital cluster and the frontal cluster, as respectively indicated by orange and green stars in the scalp topographic map, significantly correlated with the behavioral modulation index (BMI). (C and D) Analysis of inter-trial phase coherence (ITPC) results yielded similar patterns to those for power.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4âsource data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-65118-fig4-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 1.</label><caption><title>Neural entrainment to contextual rhythms indexed by induced power and its correlation with the attentional modulation effect.</title><p>(<bold>A</bold>) The induced power spectrum estimated based on the average of single-trial spectral transforms across all epochs and channels. For each frequency, the resulting power was normalized by subtracting the mean power of the two nearest neighboring frequencies from the power of the center frequency. In the normalized power spectrum, peaks can be observed at stimulus frequenciesâ2.5 Hz (<italic>t</italic>(15) = 1.185, p=0.042, uncorrected) and 10 Hz (<italic>t</italic>(15) = 6.582, p&lt;0.001, FDR-corrected with a <italic>p</italic>-value thresholdÂ &lt;0.001; only positive peaks were shown). Shaded areas indicate standard errors of the mean. (<bold>B</bold>) The 2.5 Hz induced power is significantly correlated with the behavioral modulation index (BMI; <italic>r</italic>Â =Â 0.606, p=0.006) in a parieto-occipital cluster (P7, PO7, PO5, PO3, as indicated by orange stars in the scalp topographic map).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-fig4-figsupp1-v1.tif"/></fig></fig-group><p>The significant enhancement of EEG power at 2.5 Hz clearly demonstrates that the brain can entrain to the higher-order structure defined by changes in an auditory feature (i.e. pitch) of the contextual stream. Consistent with previous studies, we also observed a wide range of individual variation in such cortical tracking of contextual rhythms (<xref ref-type="bibr" rid="bib21">Grahn and McAuley, 2009</xref>; <xref ref-type="bibr" rid="bib39">Kranczioch, 2017</xref>; <xref ref-type="bibr" rid="bib56">Nozaradan et al., 2016</xref>). Could such variation predict oneâs ability to extract and utilize the feature-based structure at the neural level, and thus explain the individual differences in the attentional modulation effect? To explore this possibility, we calculated the Pearson correlation between the magnitude of the neural entrainment effect and the behavioral modulation index (BMI) using a cluster-based permutation test. In the context session, we identified two significant clusters showing positive correlation between power at 2.5 Hz and individualsâ behavioral effectâone in the parieto-occipital region (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; P5, PO7, PO5, PO3; <italic>r</italic>Â =Â 0.587, p=0.008, right-tailed) and the other in the frontal area (F3, F1, FZ, FC3, FC1, FCZ, C1, CZ; <italic>r</italic>Â =Â 0.681, p=0.002). By contrast, no significant clusters were found in the baseline session (p&gt;0.05).</p><p>To further examine the role of brain activity phase-locked with the rhythmic context, we also analyzed the inter-trial phase coherence (ITPC) of EEG signals. Consistent with the power spectrum, ITPC in the context session peaked at 2.5 and 10 Hz (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), suggesting a hierarchical entrainment effect elicited by both feature-based and time-based regularities. By contrast, ITPC in the baseline session only peaked at 10 Hz, mirroring the stimulation rate of the visual stream, and the ITPC at 2.5 Hz was significantly weaker than that in the context session (<italic>t</italic>(15) = 4.652, p&lt;0.001, FDR-corrected). Critically, only in the context session, the 2.5 Hz ITPC was positively correlated with the behavioral modulation index, yielding two significant clusters in the parieto-occipital area (<xref ref-type="fig" rid="fig4">Figure 4D</xref>; P7, P5, PO7, PO5, PO3, O1: <italic>r</italic>Â =Â 0.612, p=0.006) and the frontal area (FPZ, FP2, AF4, F2, F4, F6; <italic>r</italic>Â =Â 0.672, p=0.002). In addition to the above analysis of phase-locked neural responses, we also looked into the power spectrum based on the average of single-trial spectral transforms, thatÂ is the induced power, which puts emphasis on the intrinsic non-phase-locked activities. In line with the results of evoked power and ITPC, we found consistent patterns for the induced power (for details see <xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>). Taken together, the results of 2.5 Hz power and ITPC jointly demonstrate that the better oneâs brain oscillations entrain to the higher-order temporal structure of the contextual rhythms, the larger attentional enhancement one may exhibit in the between-cycle condition over the within-cycle condition.</p></sec><sec id="s2-6-2"><title>Neural responses to first-order rhythms at 10 Hz reflect the attentional modulation</title><p>Alpha oscillations have been considered to play a crucial and even causal role in temporal attention, particularly in the AB effect (<xref ref-type="bibr" rid="bib24">Hanslmayr et al., 2011</xref>; <xref ref-type="bibr" rid="bib37">Klimesch, 2012</xref>). As the AB phenomenon is characteristic of its stimulation frequency approximately at 10 Hz within the alpha band, the brain can be in a resonant state with the AB stream at the same frequency. It has been demonstrated that an increase in alpha power at the stimulus frequency indicated attentional orienting to the stimulus stream, providing an online measure of attentional allocation over the RSVP stream (<xref ref-type="bibr" rid="bib52">MÃ¼ller and HÃ¼bner, 2002</xref>). On the other hand, enhanced alpha power at stimulus rate in the AB task has also been shown to be associated with correct T2 detection (<xref ref-type="bibr" rid="bib27">Janson et al., 2014</xref>; <xref ref-type="bibr" rid="bib33">Keil et al., 2006</xref>). Motivated by these findings, we investigated whether the 10 Hz alpha activity related to T2 processing could reflect the attentional modulation in our study. We calculated alpha power around the stimulation frequency (9.5â10.5 Hz) within the time window of 0â100 ms after T2 onset, and found two significant clusters for the context sessionâone in the left parieto-occipital region (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; T7, C5, C3, TP7, CP5, CP3, P5, P3, PO5, PO3, O1) and the other in a right-lateralized region (AF4, F2, F4, FC4, FC6, FT8, C4, C6, T8, CP4, CP6, TP8, P8), both showing stronger 10 Hz alpha power in the between-cycle condition than in the within-cycle condition (for the left cluster, <italic>t</italic>(15) = 3.570, p=0.0014; for the right cluster, <italic>t</italic>(15) = 3.631, p=0.0012, right-tailed, cluster-based permutation test). To verify that the observed modulation effect was due to context-induced entrainment rather than a by-product of post-T2 processing, we further examined the 10 Hz alpha power within the time window of â100â0 ms prior to T2 onset. Results revealed an enhancement of this pre-T2 neural response for the between-cycle condition relative to the within-cycle condition, which is similar to that observed within the post-T2 time window but more restricted to the left parieto-occipital cluster (<xref ref-type="fig" rid="fig5">Figure 5A</xref>; CP3, CP5, P3, P5, PO3, PO5, POZ, O1, OZ; <italic>t</italic>(15) = 2.774, p=0.007).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Modulation effect of the alpha power and its coupling with the delta phase.</title><p>(<bold>A</bold>) 10 Hz alpha power averaged within the time window of â100â0 ms (left) and 0â100 ms (right) relative to the T2 onset was significantly higher in the between-cycle condition than in the within-cycle condition in a left parieto-occipital cluster (indicated by white stars). (<bold>B</bold>) The modulation index of phase-amplitude coupling (PAC) between the delta and alpha bands was higher for the between-cycle condition than for the within-cycle condition, and (<bold>C</bold>) the difference in normalized PAC strength could predict the BMI across individuals. Shadowed area in the topographic plot indicates the cluster showing significant behavioral relevance in both delta- and alpha-band activities. Error bars represent 1 SEM; *p&lt;0.05, **p&lt;0.01.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5âsource data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-65118-fig5-data1-v1.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-fig5-v1.tif"/></fig></sec><sec id="s2-6-3"><title>Cross-frequency coupling between delta phase and alpha power correlates with the attentional modulation effect</title><p>Examinations on delta-band entrainment effect, and 10 Hz alpha power both reveal behavioral relevance in our study. This leads to a natural question of whether the observed attentional modulation effect is implemented through a coordinative process between neural oscillations at delta and alpha bands. To address this question, we analyzed cross-frequency coupling between delta phase and alpha power, which has been found to support the attentional selection between competing stimuli (<xref ref-type="bibr" rid="bib20">Gomez-Ramirez et al., 2011</xref>; <xref ref-type="bibr" rid="bib74">Wilson and Foxe, 2020</xref>; <xref ref-type="bibr" rid="bib76">WÃ¶stmann et al., 2016</xref>). We conducted the analysis in two clusters whose neural responses in both the delta band (the ITPC at 2.5 Hz) and the alpha band (10 Hz alpha power) had an established link with the attentional modulation effect: one in the parieto-occipital region (P5, PO3, PO5, O1) and the other in the frontal region (AF4, F2, F4). We calculated the modulation index (MI) of phase-amplitude coupling (PAC) between delta (1.5â3.5 Hz) and alpha band (7â13 Hz) for each cluster. The MI was stronger in the between-cycle condition than in the within-cycle condition, while the effect reached significance only in the parieto-occipital region (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; <italic>t</italic>(15) = 2.432, p=0.028) but not in the frontal region (<italic>t</italic>(15) = 1.459, p=0.165). More importantly, this contrast effect of delta-alpha PAC showed a positive correlation with the attentional modulation effect on behavioral performance, which was also restricted to the parieto-occipital region (<xref ref-type="fig" rid="fig5">Figure 5C</xref>; <italic>r</italic>Â =Â 0.660, p=0.005) and not found in the frontal region (<italic>r</italic>Â =Â 0.154, p=0.569). To further confirm the association between the delta-alpha PAC and the observed attentional modulation effect, we did a cluster-based permutation test, which again yielded a positively significant cluster in the parieto-occipital region (PO7, PO5, PO3, O1, OZ; <italic>r</italic>Â =Â 0.697, p=0.003). These results, combined with the findings from single-band analyses, indicate that cortical tracking of hierarchical temporal structures of the auditory context, as well as the coordination of such cortical tracking effects in delta and alpha bands, may play a vital role in reconstructing the deployment of visual attention in the AB task.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Temporal attention guided by time- and feature-based regularities</title><p>Dynamic information flows, such as speech and music, are composed of rhythmic structures nested across multiple timescales (<xref ref-type="bibr" rid="bib14">Ding et al., 2016</xref>; <xref ref-type="bibr" rid="bib22">Gross et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Koelsch et al., 2013</xref>; <xref ref-type="bibr" rid="bib61">Peelle and Davis, 2012</xref>). These hierarchical structures are organized in time based on regularities in stimulus timing, that is, when sensory signals are emitted (time-based), as well as regularities in information content, that is, how physical or semantic features of the sensory inputs change over time (feature-based). Accrued evidence suggests that temporal structures formed by time-based regularities are effective in directing attention and enhance information selection at the expected time points (<xref ref-type="bibr" rid="bib31">Jones et al., 2002</xref>; <xref ref-type="bibr" rid="bib53">Nobre et al., 2007</xref>; <xref ref-type="bibr" rid="bib54">Nobre and van Ede, 2018</xref>). Yet the current study demonstrates the role of feature-based temporal structures in recomposing temporal attention deployment, which optimizes the distribution of attentional resources over two temporally proximate targets in the AB task.</p><p>We modified the standard AB paradigm by introducing a contextual stream whose physical property changed periodically to form perceivable, but unattended rhythmic cycles in the background. Although this feature-based temporal structure was task-irrelevant, it modulated the deployment of attentional resources along the AB stream, as indicated by higher T2 detection performance when the two targets were located in different cycles than in the same cycle. More intriguingly, this modulation effect was observed no matter whether the contextual stream was from the auditory (Experiment 1) or the visual (Experiment 2) modality. These findings provide clear evidence that temporal structures defined by periodic changes of physical features in a dynamic context can automatically reconstruct the temporal distribution of visual attention.</p><p>In the current study, the rhythmic cycles in the contextual stream consisted of a set of temporally grouped items, some with abrupt changes in physical features across the cycle boundaries. Could the attentional modulation effect be achieved purely on the basis of transient perceptual boundaries or temporal grouping? Findings from several control experiments do not agree with these assumptions. In Experiment 3, the rhythmic cycles of contextual rhythms were defined by cyclic motion without any abrupt changes at the boundaries. Even in this case, the cyclic motion yielded a significant attentional modulation effect, excluding the possibility that the observed effect was caused simply by perceptual changes of the background. In addition, results from Experiments 1d and 1e further confirm that temporal attention guided by temporal regularities rather than perceptual grouping is key to the reduced AB effect. On the one hand, simple grouping without feature-based temporal regularities had little influence on T2 detection (as in Experiment 1d, the feature-based grouping was irregular). On the other hand, when we disrupted time-based regularities by using stochastic stimulus timing, the attentional modulation effect also vanished, even though the rule of feature-based grouping remained in force (as in Experiment 1e, every four identical tones constituted one group). Jointly, these findings point to a mechanism of temporal attentional guidance independent of transient perceptual cues and simple perceptual grouping.</p><p>It is worth noting that the attentional modulation effect did not occur in the absence of regular stimulus timing. In other words, the feature-based regularities should work in tandem with the time-based regularities to reconstruct the dynamics of visual temporal attention, at least under the current experimental settings. This finding is consistent with the emerging view concerning the role of a diversity of temporal structures in guiding adaptive behavior (<xref ref-type="bibr" rid="bib54">Nobre and van Ede, 2018</xref>). It has been suggested by studies using auditory materials, mostly in speech and music perception, that temporal regularities embedded in information content can act along with the time-based anticipation in attentional guidance (<xref ref-type="bibr" rid="bib15">Doelling and Poeppel, 2015</xref>; <xref ref-type="bibr" rid="bib51">Morillon et al., 2016</xref>; <xref ref-type="bibr" rid="bib61">Peelle and Davis, 2012</xref>; <xref ref-type="bibr" rid="bib77">Zion Golumbic et al., 2012</xref>). Our findings extend these studies by establishing a mechanism in visual temporal attention that is guided by regularities in feature-defined structures on top of the anticipation based on stimulation timing.</p></sec><sec id="s3-2"><title>The roles of dynamic attentional deployment in reducing attentional blink and boosting awareness</title><p>The AB phenomenon represents a bottleneck of conscious awareness pertaining to the temporal resolution of visual attention. It is well known for its robustness that even long repetitive training cannot eliminate the AB effect (<xref ref-type="bibr" rid="bib4">Braun, 1998</xref>). Some studies have demonstrated attenuated AB magnitude, as manifested in increased T2 detectability, by enhancing T2 salience with color-salience training (<xref ref-type="bibr" rid="bib10">Choi et al., 2012</xref>), emotional arousal (<xref ref-type="bibr" rid="bib34">Keil and Ihssen, 2004</xref>), or concurrent sounds (<xref ref-type="bibr" rid="bib59">Olivers and Van der Burg, 2008</xref>). Another line of research has also reported improved T2 performance when explicitly cueing the target-onset-asynchrony (TOA) on a trial-by-trial basis (<xref ref-type="bibr" rid="bib45">Martens and Johnson, 2005</xref>) or manipulating the predictability of target onset (<xref ref-type="bibr" rid="bib69">Tang et al., 2014</xref>; <xref ref-type="bibr" rid="bib73">Visser et al., 2015</xref>). Despite implementing different approaches, all these studies tried to manipulate certain aspects of T2, regarding either its salience or predictability in time. By contrast, in our study, the salience of targets and temporal expectations about T2 onset were comparable across all experimental conditions. The only difference between the within- and between-cycle conditions was the positions of the two targets relative to the feature-defined temporal structure. Under this situation, items in the RSVP stream were no longer encoded in isolation, but treated as a part of a structured information flow that could be organized by periodic changes in the context. In particular, when T1 and T2 were separated in different cycles, the temporal relations between them were reframed, which might at least partially reduce the competition between the targets, thus improving the resolution of visual temporal attention and boosting the conscious access to T2. Instead of emphasizing the role of a given target or a certain time point, our findings highlight the significance of attentional deployment as a dynamic process in regulating visual awareness and the AB effect, which is modulated by temporal structures of the entire information flow.</p></sec><sec id="s3-3"><title>Neural entrainment to hierarchical contextual rhythms modulates dynamic attending in visual perception</title><p>Neural oscillations can be entrained to external rhythms across different frequencies (<xref ref-type="bibr" rid="bib8">Calderone et al., 2014</xref>; <xref ref-type="bibr" rid="bib18">Escoffier et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Henry et al., 2014</xref>; <xref ref-type="bibr" rid="bib48">Mathewson et al., 2012</xref>; <xref ref-type="bibr" rid="bib64">Schroeder et al., 2010</xref>; <xref ref-type="bibr" rid="bib65">Schroeder and Lakatos, 2009</xref>; <xref ref-type="bibr" rid="bib72">Thut et al., 2011</xref>), allowing the brain to encode dynamic information with multiplexed rhythmic structures across different timescales (<xref ref-type="bibr" rid="bib19">Fontolan et al., 2014</xref>; <xref ref-type="bibr" rid="bib40">Lakatos et al., 2005</xref>; <xref ref-type="bibr" rid="bib57">O'Connell et al., 2015</xref>). A fine example of this comes from studies of speech processing. The linguistic structure possesses a temporal hierarchyâfrom smaller phonetic elements to larger syllabic and phrasal units, which correspondingly elicit neural entrainment at multiple frequency bands (<xref ref-type="bibr" rid="bib1">Arnal and Giraud, 2012</xref>; <xref ref-type="bibr" rid="bib77">Zion Golumbic et al., 2012</xref>). Moreover, there is growing evidence that cortical tracking of the higher-order temporal structures plays a vital role in speech comprehension (<xref ref-type="bibr" rid="bib14">Ding et al., 2016</xref>; <xref ref-type="bibr" rid="bib22">Gross et al., 2013</xref>; <xref ref-type="bibr" rid="bib61">Peelle and Davis, 2012</xref>). In our EEG study, we demonstrate an analogous entrainment effect that not only keeps track of the original AB stream at 10 Hz but also represents the higher-order feature-based structure of contextual rhythms at 2.5 Hz. This effect, distinct from the hierarchical entrainment to speech signals, does not rely on previously acquired knowledge about the structured information and can be established automatically even when the higher-order structure comes from a task-irrelevant and cross-modal contextual rhythm. More importantly, the magnitude of the 2.5 Hz entrainment effect is significantly correlated with the strength of the attentional modulation effect. The scalp topographic map of correlation is lateralized and restricted to the left parietal region, which was found to be associated with temporal attention (<xref ref-type="bibr" rid="bib2">Bolger et al., 2014</xref>; <xref ref-type="bibr" rid="bib12">Coull and Nobre, 1998</xref>). These findings are in good accordance with our assumption that the cortical tracking of feature-based contextual structure is critical to the redeployment of attentional resources over the AB stream and may lead to the behavioral modulation effect, which sheds fresh light on the adaptive value of the structure-based entrainment effect by expanding its role from rhythmic information (e.g. speech) perception to temporal attention deployment.</p><p>There has been a debate about whether the neural alignment to rhythmic stimulation reflects active entrainment of endogenous oscillatory processes (i.e. induced activity) or a series of passively evoked steady-state responses (<xref ref-type="bibr" rid="bib35">Keitel et al., 2019</xref>; <xref ref-type="bibr" rid="bib55">Notbohm et al., 2016</xref>; <xref ref-type="bibr" rid="bib78">Zoefel et al., 2018</xref>). The latter process is also referred to as âentrainment in a broad senseâ by <xref ref-type="bibr" rid="bib58">Obleser and Kayser, 2019</xref>. Given that a presented rhythm always evokes event-related potentials, a better question might be whether the observed alignment reflects the entrainment of endogenous oscillations in addition to evoked steady-state responses. Here, we attempted to tackle this issue by measuring the induced power, which emphasizes the intrinsic non-phase-locked activity, in addition to the phase-locked evoked power. Specifically, we quantified these two kinds of neural activities with the average of single-trial EEG power spectra and the power spectra of trial-averaged EEG signals, respectively, according to <xref ref-type="bibr" rid="bib35">Keitel et al., 2019</xref>. In addition to the observation of evoked responses to the contextual structure, we also demonstrated an attention-related neural tracking of the higher-order temporal structure based on the induced power at 2.5 Hz (see <xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>), suggesting that the observed attentional modulation effect is at least partially derived from the entrainment of intrinsic oscillatory brain activity.</p><p>In our experiment, the 10 Hz alpha power around T2 is stronger in the between-cycle condition than in the within-cycle condition. A widely accepted function of alpha activity in attention is that alpha oscillations suppress irrelevant visual information during spatial selection (<xref ref-type="bibr" rid="bib36">Kelly et al., 2006</xref>; <xref ref-type="bibr" rid="bib71">Thut et al., 2006</xref>; <xref ref-type="bibr" rid="bib75">Worden et al., 2000</xref>). However, it becomes a controversial issue when there exists rhythmic sensory stimulation at alpha-band, just like the situation in the current study where both the visual stream and the contextual auditory rhythm were emitted at 10 Hz. In such a case, alpha-band neural responses at the stimulation frequency can be interpreted as either passively evoked steady-state responses (SSR) or actively synchronized intrinsic brain rhythms. From the former perspective (i.e. the SSR view), an increase in the amplitude or power at the stimulus frequency may indicate an enhanced attentional allocation to the stimulus stream that may result in better target detection (<xref ref-type="bibr" rid="bib27">Janson et al., 2014</xref>; <xref ref-type="bibr" rid="bib33">Keil et al., 2006</xref>; <xref ref-type="bibr" rid="bib52">MÃ¼ller and HÃ¼bner, 2002</xref>). Conversely, the latter view of the inhibitory function of intrinsic alpha oscillations would produce the opposite prediction. In a previous AB study, <xref ref-type="bibr" rid="bib27">Janson et al., 2014</xref> investigated this issue by separating the stimulus-evoked activity at 12 Hz (using the same power analysis method as ours) from the endogenous alpha oscillations ranging from 10.35 to 11.25 Hz (as indexed by individual alpha frequency, IAF). Interestingly, they found a dissociation between these two alpha-band neural responses, showing that the RSVP frequency power was higher in non-AB trials (T2 detected) than in AB trials (T2 undetected) while the IAF power exhibited the opposite pattern. According to these findings, the currently observed increase in alpha power for the between-cycle condition may reflect more of the stimulus-driven processes related to attentional enhancement. However, we doÂ not negate the effect of intrinsic alpha oscillations in our study, as the current design is not sufficient to distinguish between these two processes.</p><p>Further analysis reveals that, in the left parieto-occipital cluster that exhibits phase-locked neural responses to both feature-based contextual structures at 2.5 Hz and first-order stimulus frequency at 10 Hz, there is an enhancement of phase-amplitude coupling between the delta and alpha oscillations for the between- relative to the within-cycle condition. Moreover, the strength of this delta-alpha coupling enhancement predicts the effect of higher-order temporal structures on dynamic attentional allocation at the individual level. These findings corroborate the idea that neural entrainment to a slower external rhythm may serve as a mechanism of attentional deployment, with the phase of delta oscillation regulating the excitability of neural activity in the alpha band (<xref ref-type="bibr" rid="bib20">Gomez-Ramirez et al., 2011</xref>; <xref ref-type="bibr" rid="bib74">Wilson and Foxe, 2020</xref>; <xref ref-type="bibr" rid="bib76">WÃ¶stmann et al., 2016</xref>).</p><p>Taken together, findings from the current study have cast new light on the classic theory of DAT and its neural implementation. The DAT assumes attention to be inherently oscillatory and can be driven by the timing pattern of external events (<xref ref-type="bibr" rid="bib28">Jones, 1976</xref>; <xref ref-type="bibr" rid="bib30">Jones et al., 1982</xref>; <xref ref-type="bibr" rid="bib32">Jones and Boltz, 1989</xref>; <xref ref-type="bibr" rid="bib43">Large and Jones, 1999</xref>). By taking advantage of temporal regularities of isochronous or rhythmic events, attentional synchrony can be established and thus improve perceptual accuracy and elevate response speed. Our study extends the DAT to more general cases of dynamic information processing at both the behavioral and the neural levels. Primarily, our behavioral observations suggest that to utilize regularities in a hierarchical temporal structure, the internal attentional oscillation may not only align with first-order rhythmic structures based on stimulus timing, but also with higher-order rhythmic structures defined by content-based changes of the information flow. Such a dynamic attending process necessitates the synergy between time- and content-based regularities, which could be implemented by neural entrainment to the higher-order temporal structure and its coordination with the cortical tracking of the stimulus rhythm through cross-frequency coupling.</p></sec><sec id="s3-4"><title>Conclusion</title><p>In summary, the current study emphasizes the role of feature-defined contextual rhythms in reconstructing the deployment of visual attention along dynamic information streams. This work enriches our knowledge, as raised at the beginning of this article, about how we optimize the limited mental capacity to process successive inputs from this ever-changing world. Taking the AB phenomenon as an example, we provide a new perspective on visual temporal attention researchâwhen examining the perception of complex dynamic information, temporal context on multiple timescales should be taken into consideration because it provides a meaningful hierarchical temporal frame for attentional deployment. This temporal frame, implemented by neural entrainment, may serve to organize attentional resources in a prospective manner and help construct our conscious experience of the world in the dimension of time.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>A total of 144 volunteers (aged from 18 to 30 years, 69 females) were recruited and paid for their participation in the current study. One hundred and twenty-eight participated in the behavioral Experiments 1a-1e, 2a-2b, and 3 (16 for each experiment, with participantsâ gender balanced), and 16 (5 females) in the EEG experiment. All participants had normal or corrected-to-normal vision and normal hearing and were naÃ¯ve to the purpose of the experiment. Considering the individual differences in the AB effect, only participants who exhibited a typical AB effect (i.e. an impairment of T2 accuracy at short lags compared with that at long lags) during a pre-screening session were asked to take part in the formal experiments. All participants provided written informed consent in accordance with experimental procedures and protocols approved by the Institutional Review Board of the Institute of Psychology, Chinese Academy of Sciences (ethical approval number: H17028).</p></sec><sec id="s4-2"><title>Stimuli</title><p>The rapid visual serial presentation (RSVP) stream used in the AB task consisted of 16 items (except in Experiments 1c and 1d). Among these items, one or two were the targets (capital letters selected from the alphabet, excluding B, D, O, I, M, Q, S, W, and Z), and the remaining were distractors (one-digit numbers, 1 and 0 excluded, without repetitions between any two of four successive digits). The items were displayed for 83 ms each and were separated by 17 ms blank intervals (except Experiment 1e), generating a 10 Hz rhythm based on stimulus presentation (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>, top). Each item subtended 0.47Â°Ã0.57Â° of visual angle and was displayed in white within a gray square (3Â° Ã 3Â°) located at the center of a black screen. In each experiment, a contextual stream, which contained the same number of items as the AB stream but was organized by a feature-defined structure, was presented in synchronization with the AB stream. Stimuli were generated and displayed using MATLAB (The MathWorks Inc, Natick, MA) with the Psychophysics toolbox extension (<xref ref-type="bibr" rid="bib3">Brainard, 1997</xref>). Visual stimuli were presented on a 21-inch CRT monitor with a viewing distance of 55 cm in a dim room. Auditory stimuli were delivered binaurally over Bose QC3 headphones with the volume set to a comfortable listening level.</p></sec><sec id="s4-3"><title>Procedures</title><sec id="s4-3-1"><title>Behavioral experiments</title><p>In all experiments, participants were explicitly instructed to ignore the contextual events and focused attention on the AB task. Participants initiated each trial by pressing the enter key. A white fixation cross appeared for 600 ms at the center of the screen, followed by the presentation of an AB stream (along with an auditory/visual stream in the context session). After the last item disappeared, the central fixation turned blue to remind the participant to report the identities of the target(s) in the order they detected them by typing on the keyboard.</p><p>Experiment 1a had a baseline session followed by a context session. In the baseline session, participants viewed only the AB stream and performed the typical AB task. To induce the AB effect, the second target (T2) in the AB stream was located at the second lag of the first target (T1) with a short stimulus onset asynchrony (SOA) of 200 ms, as the magnitude of AB effect is most robust around the second and the third lags. In contrast with the short-SOA condition, we introduced a long-SOA condition where T2 always appeared at the 8th lag of T1 and could rarely be missed. To measure the false alarm rate, we also included catch trials in which only one target was displayed. The context session had the same settings and task as the baseline session, except that a task-irrelevant auditory stream was presented in synchronization with the original RSVP stream. Specifically, the auditory stream was composed of 16 tones, each aligned with the onset of a visual item and displayed for 30 ms. The tone sequence changed its pitch from high (2000 Hz) to low (1200 Hz) or vice versa every four items (corresponding to 400 ms), generating four auditory cycles (i.e. 4-4-4-4) at a rate of 2.5 Hz (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, middle). To examine the regulation effect of such pitch-defined rhythmic structures, we created two experimental conditions specifically for the short-SOA trials, by varying the positions of T1 and T2 relative to the contextual cycles. In the âbetween-cycle conditionâ, T1 and T2 were located in two adjacent cycles; and in the âwithin-cycle conditionâ, the two targets were located in the same cycle. To reduce observersâ anticipation about the timing of T1 onset across trials, we introduced various T1 positions while keeping T2 located within the middle two cycles. Each session had 120 experimental trials (40 trials for the between-cycle, within-cycle, and long SOA condition each) and 20 catch trials. These trials were divided into four equal blocks, with randomized trial order within each block.</p><p>Experiment 1b-1e adopted the same procedure as Experiment 1a but with the following exceptions. In Experiment 1b, as shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref> (bottom), we abolished the feature-based structure of the contextual streams by pseudo-randomizing the auditory tone sequences while keeping the pitch of tones at target locations the same as that in Experiment 1a. In Experiment 1 c, we changed the temporal structure of the contextual streams by altering their pitch change rate, generating two types of auditory sequences: one with four five-tone cycles displayed at 2 Hz (i.e., 5-5-5-5, see <xref ref-type="fig" rid="fig2">Figure 2A</xref>, upper), and the other with five three-tone cycles at 3.3 Hz (i.e. 3-3-3-3-3, see <xref ref-type="fig" rid="fig2">Figure 2A</xref>, lower). For both frequency conditions, T2 was located in the next to last or third from last cycles. In Experiment 1d, we varied the length of chunks in the contextual streams, generating auditory sequences with four chunks of different lengths (e.g. 5-2-4-3) but always having four tones in the third cycle where the second target appeared (see <xref ref-type="fig" rid="fig2">Figure 2C</xref>, upper). In Experiment 1e, the feature-based structure remained while the rhythm from stimulus timing was removed (see <xref ref-type="fig" rid="fig2">Figure 2C</xref>, lower). Specifically, the tone pitch changed every four items just as in Experiment 1a, whereas the stimulus onset asynchrony (SOA) of each visual item was selected randomly from a predetermined uniform distribution (50, 67, 83, 100, 100, 117, 133, 150 ms) to keep the total presentation time identical to that in Experiment 1a. In both Experiment 1d and 1e, T2 was always the second item in the 3rd cycle for the between-cycle condition and the last item in the 3rd cycle for the within-cycle condition.</p><p>Experiments 2a and 2b had a design similar to that of Experiments 1a and 1b, except that we replaced the auditory context with a visually presented contextual stream that possessed color-defined temporal structure. Specifically, in the context session of Experiment 2a, the color of the background square changed from green to red or vice versa at the same tempo as that for contextual tones in Experiment 1a (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, upper). And in Experiment 2b, the background color changed in arrhythmic patterns (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, upper). Luminance of the two colors was matched for each observer with a chromatic flicker fusion procedure before the experiments.</p><p>Experiment 3 consisted of an experimental session with a structured context as that in Experiment 2a and a control session with a random context as that in Experiment 2b. In the experimental session, the contextual rhythm was created by cyclic motion patterns in the background (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, upper). Specifically, a blue right-angle (widthÂ =Â 0.38Â°, side lengthÂ =Â 1.5Â°), initiating from one corner (the upper-left or the upper-right, balanced between blocks) of the background square, rotated clockwise at the same pace as the AB stream. In this way, one cycle of rotation corresponded to the appearance of four items (i.e. 400 ms), forming a 2.5 Hz structure based on the motion cycles. In the control session, no cyclic motion pattern remained but the right-angle shifted to a random quadrant under the constraint of identical initial quadrant in each âcycleâ (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, lower).</p><p>Note that in all these experiments, we also labeled the conditions in baseline and control sessions as âwithin-cycleâ or âbetween-cycleâ, just to indicate that these conditions shared the same absolute target positions with the corresponding conditions in the context session. This design was adopted to control for any potential influence of the absolute position of a target within the AB stream. Specifically, for each experimental condition (within- or between-cycle), we matched the absolute positions of T1 and T2 between the context session and the baseline session without a context (Experiments 1â2), or between the experimental session and the control session with a random context (Experiments 1 and 3).</p></sec></sec><sec id="s4-4"><title>EEG experiment</title><p>The procedure of the EEG experiment was mostly identical to that of Experiment 1a except for the following modifications. Black items were presented on a gray background and the item size was 0.59Â°Ã0.78Â°. In each trial, the fixation duration was 1000 ms and each item was displayed for 100 ms with no blank interval. T2 was always located withinÂ the third cycle of the contextual rhythm. After response, there was a 1.2â1.5 s blank interval. Each subject completed three baseline blocks followed by six experimental blocks with the auditory context. Each block consisted of 40 trials, with 17 short-SOA trials in each of the between- and within-cycle condition, and the remaining six as the catch trials, run in a random order.</p></sec><sec id="s4-5"><title>EEG recording</title><p>A SynAmps<sup>2</sup> Neuroscan amplifier system (Compumedics Ltd, Abbotsford, Australia) was used for data acquisition. EEG signals were recorded continuously from 64 Ag/AgCl electrodes mounted on an elastic cap according to the extended 10â20 system, with a reference electrode placed between Cz and CPz. Vertical and horizontal eye movements were monitored with two bipolar EOG electrode pairs positioned above and below the left eye and on the outer canthus of each eye. Data were acquired at a sampling rate of 1000 Hz with an online 0.05â100 Hz band-pass filter (notched at 50 Hz). Electrode impedances were kept below 8 kÎ© for all electrodes.</p></sec><sec id="s4-6"><title>EEG data analysis</title><sec id="s4-6-1"><title>Preprocessing</title><p>Data preprocessing and analysis was performed using EEGLAB toolbox (<xref ref-type="bibr" rid="bib13">Delorme and Makeig, 2004</xref>) and FieldTrip (<xref ref-type="bibr" rid="bib60">Oostenveld et al., 2011</xref>) in the MATLAB environment. EEG recordings were down-sampled offline to 500 Hz, high-pass filtered at 0.3 Hz, and then segmented into 2200 ms trials from â600 to 1600 ms relative to the onset of the AB stream. Ocular artifacts were then identified and removed using the ADJUST algorithm (<xref ref-type="bibr" rid="bib50">Mognon et al., 2011</xref>) based on independent component analysis (ICA). Segments with voltage deflections greater than 75 uV were rejected. Residual artifacts were checked by visual inspection. On average, 90 trials remained for each condition and each individual. The segmented data were re-referenced to the average potential of all electrodes excluding the mastoid and EOG electrodes.</p></sec><sec id="s4-6-2"><title>Power analysis</title><p>The preprocessed EEG signals were first demeaned by subtracting the average activity of the entire stream over time (i.e. from 0 to 1600 ms) for each epoch, and then averaged across trials for each condition, each participant, and each electrode. Then signals from stream onset were zero-padded and fast Fourier transformed, yielding amplitude and phase estimation at a frequency resolution of 0.5 Hz. Power spectra was calculated as the squared amplitude and then converted to decibel scale (i.e. 10*log<sub>10</sub>). To remove unrelated background noises from the frequency response of stimulus rhythms, for each frequency, the mean power at two nearest neighboring frequencies was subtracted from the power at that center frequency. The subtracted power at each frequency was then averaged across all channels (excluding M1, M2, VEO, HEO, CB1, and CB2) and compared with zero using one-sample <italic>t</italic> test to determine whether neural oscillations were entrained to temporal structures of the stimulus rhythms. Multiple comparisons across frequencies were controlled by the false discovery rate (FDR, p&lt;0.05) procedure.</p></sec><sec id="s4-6-3"><title>Phase locking analysis</title><p>Inter-trial phase coherence (ITPC) serves to indicate the consistency with which intrinsic neural oscillations were phase-locked to the external rhythms over trials. We first obtained phase estimation from spectral decomposition for each single trial based on fast Fourier transform, and then calculated ITPC as follows:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">C</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">â</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mi/><mml:mo>=</mml:mo><mml:mi/><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:math></disp-formula>where, for <italic>n</italic> trials, <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>Â is the spectral estimate of trial k at frequency <italic>f</italic>, and || represents the complex norm.</p></sec><sec id="s4-6-4"><title>Time-frequency analysis</title><p>In order to measure the neural activity time-locked to T2 at 10 Hz, time-frequency analysis was performed by convolving single-trial data with a complex Morlet tapered wavelet using the <italic>newtimef</italic> function of EEGLAB. To optimize the trade-off between temporal and frequency resolution, the length of wavelets increased linearly from one cycle at the lowest frequency (2 Hz) to 7.5 cycles at the highest frequency (30 Hz, in increments of 0.5 Hz), resulting in power estimates from â321 to 1321 ms around stream onset. For each frequency, power at each time point was then averaged across trials and divided by the average activity in the baseline period from â300 to â100 ms prior to stream onset and log-transformed to decibels. We averaged the alpha powers from 9.5 to 10.5 Hz around the stimulation frequency within the post-T2 (0â100 ms relative to T2 onset) and pre-T2 (-100â0 ms relative to T2 onset) time windows, respectively.</p></sec><sec id="s4-6-5"><title>Delta-alpha phase-amplitude coupling analysis</title><p>The modulation index (MI) of phase-amplitude coupling (PAC) was used to measure the coordinative modulation between the phase of ongoing oscillations in delta band (1.5â3.5 Hz) and the power in alpha bands (7â13 Hz) at each electrode. First, the low-frequency phase at delta band (<italic>f</italic><sub>p</sub>) and high-frequency amplitude at alpha band (<italic>f</italic><sub>a</sub>) were estimated by filtering each epoch with a Butterworth bandpass filter and then applying the Hilbert transform. The broad bandwidth of alpha band (7â13 Hz) was determined to be wide enough to contain the side-bands of the modulating frequency at <italic>f</italic><sub>p</sub> (2.5 Hz) (<xref ref-type="bibr" rid="bib17">Dvorak and Fenton, 2014</xref>; <xref ref-type="bibr" rid="bib66">Seymour et al., 2017</xref>). Next, the modulation index of PAC was quantified using the mean-vector length method first introduced by <xref ref-type="bibr" rid="bib9">Canolty et al., 2006</xref>. As shown in formula (2), for each epoch, the MI values were calculated by combining low-frequency phase and high-frequency amplitude into complex time series and then taking the length of the average vector within the selected time window (400â1200 ms relative to stream onset), which corresponded to the middle two cycles of the contextual stream. The first and last 400 ms of the stream was discarded to avoid the edge artifacts after bandpass filtering. The resulting MI values were then averaged across trials for each condition.<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>â</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mtext>A</mml:mtext><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">Î¦</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow/></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>where MI is estimated for a single trial with length of N samples or time points, <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mtext>A</mml:mtext></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>Â is the amplitude of higher-frequency at time point <italic>n</italic>, <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">Î¦</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>Â is the phase of lower-frequency at time point <italic>n</italic>, and || represents the complex norm.</p></sec><sec id="s4-6-6"><title>Correlation analysis</title><p>To examine whether the above EEG indices were associated with the observed attentional modulation effect, we correlated these EEG indices with individualâs behavioral modulation index (BMI), which was determined by the following formula:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">I</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal"/><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mi>I</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mi>I</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula>where <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mi>I</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were the accuracy rate of T2 identification in the between-cycle and the within-cycle conditions in the context session, respectively.</p></sec><sec id="s4-6-7"><title>Cluster-based permutation test</title><p>To identify clusters of channels that are significant in each statistical test, we used the cluster-based permutation test, which was first stated by <xref ref-type="bibr" rid="bib44">Maris and Oostenveld, 2007</xref> and used in a number of previous studies (<xref ref-type="bibr" rid="bib15">Doelling and Poeppel, 2015</xref>; <xref ref-type="bibr" rid="bib68">Spaak et al., 2014</xref>). Firstly, cluster-level statistics are calculated as the sum of channel-specific test statistics within every cluster. Then, the maximum of the cluster-level statistics is taken as the actual test statistic. Finally, the significance probability of the maximum cluster-level statistic is evaluated under the permutation distribution obtained with the Monte Carlo method in which the permutation cluster-level statistic is calculated by randomly swapping the conditions in participants 1000 times.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This research was supported by grants from the National Natural Science Foundation of China (31830037 and 31771211), the Strategic Priority Research Program (XDB32010300) and the Youth Innovation Promotion Association (2018116) of the Chinese Academy of Sciences, the National Key Research and Development Project (2020AAA0105600), and the Fundamental Research Funds for the Central Universities.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Software, Writing - original draft</p></fn><fn fn-type="con" id="con3"><p>Software</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Visualization, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Supervision, Funding acquisition, Methodology, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Human subjects: All participants provided written informed consent in accordance with experimental procedures and protocols approved by the Institutional Review Board of the Institute of Psychology, Chinese Academy of Sciences (ethical approval number: H17028).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-65118-transrepform-v1.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>We have provided the behavioral and EEG data for individual participants as additional data files. Source data files for Figures 1-5 have been uploaded to the Open Science Framework (<ext-link ext-link-type="uri" xlink:href="https://osf.io/4xzv7/">https://osf.io/4xzv7/</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Peijun</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Cortical entrainment to hierarchical contextual rhythms recomposes dynamic attending in visual perception</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="accession" xlink:href="https://osf.io/4xzv7/">4xzv7</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnal</surname> <given-names>LH</given-names></name><name><surname>Giraud</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Cortical oscillations and sensory predictions</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>390</fpage><lpage>398</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.05.003</pub-id><pub-id pub-id-type="pmid">22682813</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolger</surname> <given-names>D</given-names></name><name><surname>Coull</surname> <given-names>JT</given-names></name><name><surname>SchÃ¶n</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Metrical rhythm implicitly orients attention in time as indexed by improved target detection and left inferior parietal activation</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>593</fpage><lpage>605</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00511</pub-id><pub-id pub-id-type="pmid">24168222</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Vision and attention: the role of training</article-title><source>Nature</source><volume>393</volume><fpage>424</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1038/30875</pub-id><pub-id pub-id-type="pmid">9623997</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bregman</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="1994">1994</year><source>Auditory Scene Analysis: The Perceptual Organization of Sound</source><publisher-loc>MA, USA</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broadbent</surname> <given-names>DE</given-names></name><name><surname>Broadbent</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>From detection to identification: response to multiple targets in rapid serial visual presentation</article-title><source>Perception &amp; Psychophysics</source><volume>42</volume><fpage>105</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.3758/BF03210498</pub-id><pub-id pub-id-type="pmid">3627930</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brochard</surname> <given-names>R</given-names></name><name><surname>Tassin</surname> <given-names>M</given-names></name><name><surname>Zagar</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Got rhythmâ¦for better and for worse. Cross-modal effects of auditory rhythm on visual word recognition</article-title><source>Cognition</source><volume>127</volume><fpage>214</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2013.01.007</pub-id><pub-id pub-id-type="pmid">23454794</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calderone</surname> <given-names>DJ</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>Butler</surname> <given-names>PD</given-names></name><name><surname>Castellanos</surname> <given-names>FX</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Entrainment of neural oscillations as a modifiable substrate of attention</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>300</fpage><lpage>309</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.02.005</pub-id><pub-id pub-id-type="pmid">24630166</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Canolty</surname> <given-names>RT</given-names></name><name><surname>Edwards</surname> <given-names>E</given-names></name><name><surname>Dalal</surname> <given-names>SS</given-names></name><name><surname>Soltani</surname> <given-names>M</given-names></name><name><surname>Nagarajan</surname> <given-names>SS</given-names></name><name><surname>Kirsch</surname> <given-names>HE</given-names></name><name><surname>Berger</surname> <given-names>MS</given-names></name><name><surname>Barbaro</surname> <given-names>NM</given-names></name><name><surname>Knight</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>High gamma power is phase-locked to theta oscillations in human neocortex</article-title><source>Science</source><volume>313</volume><fpage>1626</fpage><lpage>1628</lpage><pub-id pub-id-type="doi">10.1126/science.1128115</pub-id><pub-id pub-id-type="pmid">16973878</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname> <given-names>H</given-names></name><name><surname>Chang</surname> <given-names>LH</given-names></name><name><surname>Shibata</surname> <given-names>K</given-names></name><name><surname>Sasaki</surname> <given-names>Y</given-names></name><name><surname>Watanabe</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Resetting capacity limitations revealed by long-lasting elimination of attentional blink through training</article-title><source>PNAS</source><volume>109</volume><fpage>12242</fpage><lpage>12247</lpage><pub-id pub-id-type="doi">10.1073/pnas.1203972109</pub-id><pub-id pub-id-type="pmid">22778408</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chun</surname> <given-names>MM</given-names></name><name><surname>Potter</surname> <given-names>MC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>A two-stage model for multiple target detection in rapid serial visual presentation</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>21</volume><fpage>109</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.21.1.109</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coull</surname> <given-names>JT</given-names></name><name><surname>Nobre</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Where and when to pay attention: the neural systems for directing attention to spatial locations and to time intervals as revealed by both PET and fMRI</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>7426</fpage><lpage>7435</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-18-07426.1998</pub-id><pub-id pub-id-type="pmid">9736662</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname> <given-names>A</given-names></name><name><surname>Makeig</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><volume>134</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname> <given-names>N</given-names></name><name><surname>Melloni</surname> <given-names>L</given-names></name><name><surname>Zhang</surname> <given-names>H</given-names></name><name><surname>Tian</surname> <given-names>X</given-names></name><name><surname>Poeppel</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cortical tracking of hierarchical linguistic structures in connected speech</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>158</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1038/nn.4186</pub-id><pub-id pub-id-type="pmid">26642090</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doelling</surname> <given-names>KB</given-names></name><name><surname>Poeppel</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical entrainment to music and its modulation by expertise</article-title><source>PNAS</source><volume>112</volume><fpage>E6233</fpage><lpage>E6242</lpage><pub-id pub-id-type="doi">10.1073/pnas.1508431112</pub-id><pub-id pub-id-type="pmid">26504238</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dux</surname> <given-names>PE</given-names></name><name><surname>Marois</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The attentional blink: a review of data and theory</article-title><source>Attention, Perception &amp; Psychophysics</source><volume>71</volume><fpage>1683</fpage><lpage>1700</lpage><pub-id pub-id-type="doi">10.3758/APP.71.8.1683</pub-id><pub-id pub-id-type="pmid">19933555</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dvorak</surname> <given-names>D</given-names></name><name><surname>Fenton</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Toward a proper estimation of phase-amplitude coupling in neural oscillations</article-title><source>Journal of Neuroscience Methods</source><volume>225</volume><fpage>42</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2014.01.002</pub-id><pub-id pub-id-type="pmid">24447842</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Escoffier</surname> <given-names>N</given-names></name><name><surname>Herrmann</surname> <given-names>CS</given-names></name><name><surname>Schirmer</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Auditory rhythms entrain visual processes in the human brain: evidence from evoked oscillations and event-related potentials</article-title><source>NeuroImage</source><volume>111</volume><fpage>267</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.02.024</pub-id><pub-id pub-id-type="pmid">25701698</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fontolan</surname> <given-names>L</given-names></name><name><surname>Morillon</surname> <given-names>B</given-names></name><name><surname>Liegeois-Chauvel</surname> <given-names>C</given-names></name><name><surname>Giraud</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The contribution of frequency-specific activity to hierarchical information processing in the human auditory cortex</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>4694</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms5694</pub-id><pub-id pub-id-type="pmid">25178489</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez-Ramirez</surname> <given-names>M</given-names></name><name><surname>Kelly</surname> <given-names>SP</given-names></name><name><surname>Molholm</surname> <given-names>S</given-names></name><name><surname>Sehatpour</surname> <given-names>P</given-names></name><name><surname>Schwartz</surname> <given-names>TH</given-names></name><name><surname>Foxe</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Oscillatory sensory selection mechanisms during intersensory attention to rhythmic auditory and visual inputs: a human electrocorticographic investigation</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>18556</fpage><lpage>18567</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2164-11.2011</pub-id><pub-id pub-id-type="pmid">22171054</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grahn</surname> <given-names>JA</given-names></name><name><surname>McAuley</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural bases of individual differences in beat perception</article-title><source>NeuroImage</source><volume>47</volume><fpage>1894</fpage><lpage>1903</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.04.039</pub-id><pub-id pub-id-type="pmid">19376241</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gross</surname> <given-names>J</given-names></name><name><surname>Hoogenboom</surname> <given-names>N</given-names></name><name><surname>Thut</surname> <given-names>G</given-names></name><name><surname>Schyns</surname> <given-names>P</given-names></name><name><surname>Panzeri</surname> <given-names>S</given-names></name><name><surname>Belin</surname> <given-names>P</given-names></name><name><surname>Garrod</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Speech rhythms and multiplexed oscillatory sensory coding in the human brain</article-title><source>PLOS Biology</source><volume>11</volume><elocation-id>e1001752</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001752</pub-id><pub-id pub-id-type="pmid">24391472</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haegens</surname> <given-names>S</given-names></name><name><surname>Zion Golumbic</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Rhythmic facilitation of sensory processing: a critical review</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>86</volume><fpage>150</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2017.12.002</pub-id><pub-id pub-id-type="pmid">29223770</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanslmayr</surname> <given-names>S</given-names></name><name><surname>Gross</surname> <given-names>J</given-names></name><name><surname>Klimesch</surname> <given-names>W</given-names></name><name><surname>Shapiro</surname> <given-names>KL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The role of Î± oscillations in temporal attention</article-title><source>Brain Research Reviews</source><volume>67</volume><fpage>331</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.brainresrev.2011.04.002</pub-id><pub-id pub-id-type="pmid">21592583</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname> <given-names>MJ</given-names></name><name><surname>Herrmann</surname> <given-names>B</given-names></name><name><surname>Obleser</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Entrained neural oscillations in multiple frequency bands comodulate behavior</article-title><source>PNAS</source><volume>111</volume><fpage>14935</fpage><lpage>14940</lpage><pub-id pub-id-type="doi">10.1073/pnas.1408741111</pub-id><pub-id pub-id-type="pmid">25267634</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname> <given-names>MJ</given-names></name><name><surname>Herrmann</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Low-Frequency neural oscillations support dynamic attending in temporal context</article-title><source>Timing &amp; Time Perception</source><volume>2</volume><fpage>62</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1163/22134468-00002011</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janson</surname> <given-names>J</given-names></name><name><surname>De Vos</surname> <given-names>M</given-names></name><name><surname>Thorne</surname> <given-names>JD</given-names></name><name><surname>Kranczioch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Endogenous and rapid serial visual Presentation-induced alpha band oscillations in the attentional blink</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>1454</fpage><lpage>1468</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00551</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Time, our lost dimension: toward a new theory of perception, attention, and memory</article-title><source>Psychological Review</source><volume>83</volume><fpage>323</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.83.5.323</pub-id><pub-id pub-id-type="pmid">794904</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>MR</given-names></name><name><surname>Kidd</surname> <given-names>G</given-names></name><name><surname>Wetzel</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Evidence for rhythmic attention</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>7</volume><fpage>1059</fpage><lpage>1073</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.7.5.1059</pub-id><pub-id pub-id-type="pmid">6457108</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>MR</given-names></name><name><surname>Boltz</surname> <given-names>M</given-names></name><name><surname>Kidd</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Controlled attending as a function of melodic and temporal context</article-title><source>Perception &amp; Psychophysics</source><volume>32</volume><fpage>211</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.3758/BF03206225</pub-id><pub-id pub-id-type="pmid">7177759</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>MR</given-names></name><name><surname>Moynihan</surname> <given-names>H</given-names></name><name><surname>MacKenzie</surname> <given-names>N</given-names></name><name><surname>Puente</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Temporal aspects of stimulus-driven attending in dynamic arrays</article-title><source>Psychological Science</source><volume>13</volume><fpage>313</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00458</pub-id><pub-id pub-id-type="pmid">12137133</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname> <given-names>MR</given-names></name><name><surname>Boltz</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Dynamic attending and responses to time</article-title><source>Psychological Review</source><volume>96</volume><fpage>459</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.96.3.459</pub-id><pub-id pub-id-type="pmid">2756068</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keil</surname> <given-names>A</given-names></name><name><surname>Ihssen</surname> <given-names>N</given-names></name><name><surname>Heim</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Early cortical facilitation for emotionally arousing targets during the attentional blink</article-title><source>BMC Biology</source><volume>4</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.1186/1741-7007-4-23</pub-id><pub-id pub-id-type="pmid">16857054</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keil</surname> <given-names>A</given-names></name><name><surname>Ihssen</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Identification facilitation for emotionally arousing verbs during the attentional blink</article-title><source>Emotion</source><volume>4</volume><fpage>23</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1037/1528-3542.4.1.23</pub-id><pub-id pub-id-type="pmid">15053724</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keitel</surname> <given-names>C</given-names></name><name><surname>Keitel</surname> <given-names>A</given-names></name><name><surname>Benwell</surname> <given-names>CSY</given-names></name><name><surname>Daube</surname> <given-names>C</given-names></name><name><surname>Thut</surname> <given-names>G</given-names></name><name><surname>Gross</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Stimulus-Driven brain rhythms within the alpha band: the Attentional-Modulation conundrum</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>3119</fpage><lpage>3129</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1633-18.2019</pub-id><pub-id pub-id-type="pmid">30770401</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname> <given-names>SP</given-names></name><name><surname>Lalor</surname> <given-names>EC</given-names></name><name><surname>Reilly</surname> <given-names>RB</given-names></name><name><surname>Foxe</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Increases in alpha oscillatory power reflect an active retinotopic mechanism for distracter suppression during sustained visuospatial attention</article-title><source>Journal of Neurophysiology</source><volume>95</volume><fpage>3844</fpage><lpage>3851</lpage><pub-id pub-id-type="doi">10.1152/jn.01234.2005</pub-id><pub-id pub-id-type="pmid">16571739</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimesch</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Î±-band oscillations, attention, and controlled access to stored information</article-title><source>Trends in Cognitive Sciences</source><volume>16</volume><fpage>606</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2012.10.007</pub-id><pub-id pub-id-type="pmid">23141428</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelsch</surname> <given-names>S</given-names></name><name><surname>Rohrmeier</surname> <given-names>M</given-names></name><name><surname>Torrecuso</surname> <given-names>R</given-names></name><name><surname>Jentschke</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Processing of hierarchical syntactic structure in music</article-title><source>PNAS</source><volume>110</volume><fpage>15443</fpage><lpage>15448</lpage><pub-id pub-id-type="doi">10.1073/pnas.1300272110</pub-id><pub-id pub-id-type="pmid">24003165</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kranczioch</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Individual differences in dual-target RSVP task performance relate to entrainment but not to individual alpha frequency</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0178934</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0178934</pub-id><pub-id pub-id-type="pmid">28604795</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>Shah</surname> <given-names>AS</given-names></name><name><surname>Knuth</surname> <given-names>KH</given-names></name><name><surname>Ulbert</surname> <given-names>I</given-names></name><name><surname>Karmos</surname> <given-names>G</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An oscillatory hierarchy controlling neuronal excitability and stimulus processing in the auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>1904</fpage><lpage>1911</lpage><pub-id pub-id-type="doi">10.1152/jn.00263.2005</pub-id><pub-id pub-id-type="pmid">15901760</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>Karmos</surname> <given-names>G</given-names></name><name><surname>Mehta</surname> <given-names>AD</given-names></name><name><surname>Ulbert</surname> <given-names>I</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Entrainment of neuronal oscillations as a mechanism of attentional selection</article-title><source>Science</source><volume>320</volume><fpage>110</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1126/science.1154735</pub-id><pub-id pub-id-type="pmid">18388295</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakatos</surname> <given-names>P</given-names></name><name><surname>Musacchia</surname> <given-names>G</given-names></name><name><surname>O'Connel</surname> <given-names>MN</given-names></name><name><surname>Falchier</surname> <given-names>AY</given-names></name><name><surname>Javitt</surname> <given-names>DC</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The spectrotemporal filter mechanism of auditory selective attention</article-title><source>Neuron</source><volume>77</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.11.034</pub-id><pub-id pub-id-type="pmid">23439126</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Large</surname> <given-names>EW</given-names></name><name><surname>Jones</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The dynamics of attending: how people track time-varying events</article-title><source>Psychological Review</source><volume>106</volume><fpage>119</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.106.1.119</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname> <given-names>E</given-names></name><name><surname>Oostenveld</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martens</surname> <given-names>S</given-names></name><name><surname>Johnson</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Timing attention: cuing target onset interval attenuates the attentional blink</article-title><source>Memory &amp; Cognition</source><volume>33</volume><fpage>234</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.3758/BF03195312</pub-id><pub-id pub-id-type="pmid">16028578</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martens</surname> <given-names>S</given-names></name><name><surname>Wyble</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The attentional blink: past, present, and future of a blind spot in perceptual awareness</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>34</volume><fpage>947</fpage><lpage>957</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2009.12.005</pub-id><pub-id pub-id-type="pmid">20025902</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathewson</surname> <given-names>KE</given-names></name><name><surname>Fabiani</surname> <given-names>M</given-names></name><name><surname>Gratton</surname> <given-names>G</given-names></name><name><surname>Beck</surname> <given-names>DM</given-names></name><name><surname>Lleras</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Rescuing stimuli from invisibility: inducing a momentary release from visual masking with pre-target entrainment</article-title><source>Cognition</source><volume>115</volume><fpage>186</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2009.11.010</pub-id><pub-id pub-id-type="pmid">20035933</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathewson</surname> <given-names>KE</given-names></name><name><surname>Prudhomme</surname> <given-names>C</given-names></name><name><surname>Fabiani</surname> <given-names>M</given-names></name><name><surname>Beck</surname> <given-names>DM</given-names></name><name><surname>Lleras</surname> <given-names>A</given-names></name><name><surname>Gratton</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Making waves in the stream of consciousness: entraining oscillations in EEG alpha and fluctuations in visual awareness with rhythmic visual stimulation</article-title><source>Journal of Cognitive Neuroscience</source><volume>24</volume><fpage>2321</fpage><lpage>2333</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00288</pub-id><pub-id pub-id-type="pmid">22905825</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>JE</given-names></name><name><surname>Carlson</surname> <given-names>LA</given-names></name><name><surname>McAuley</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>When what you hear influences when you see: listening to an auditory rhythm influences the temporal allocation of visual attention</article-title><source>Psychological Science</source><volume>24</volume><fpage>11</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1177/0956797612446707</pub-id><pub-id pub-id-type="pmid">23160202</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mognon</surname> <given-names>A</given-names></name><name><surname>Jovicich</surname> <given-names>J</given-names></name><name><surname>Bruzzone</surname> <given-names>L</given-names></name><name><surname>Buiatti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>ADJUST: an automatic EEG artifact detector based on the joint use of spatial and temporal features</article-title><source>Psychophysiology</source><volume>48</volume><fpage>229</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2010.01061.x</pub-id><pub-id pub-id-type="pmid">20636297</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morillon</surname> <given-names>B</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name><name><surname>Arnal</surname> <given-names>LH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temporal prediction in lieu of periodic stimulation</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>2342</fpage><lpage>2347</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0836-15.2016</pub-id><pub-id pub-id-type="pmid">26911682</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MÃ¼ller</surname> <given-names>MM</given-names></name><name><surname>HÃ¼bner</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Can the spotlight of attention be shaped like a doughnut? evidence from steady-state visual evoked potentials</article-title><source>Psychological Science</source><volume>13</volume><fpage>119</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00422</pub-id><pub-id pub-id-type="pmid">11933994</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nobre</surname> <given-names>A</given-names></name><name><surname>Correa</surname> <given-names>A</given-names></name><name><surname>Coull</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The hazards of time</article-title><source>Current Opinion in Neurobiology</source><volume>17</volume><fpage>465</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2007.07.006</pub-id><pub-id pub-id-type="pmid">17709239</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nobre</surname> <given-names>AC</given-names></name><name><surname>van Ede</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Anticipated moments: temporal structure in attention</article-title><source>Nature Reviews Neuroscience</source><volume>19</volume><fpage>34</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1038/nrn.2017.141</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Notbohm</surname> <given-names>A</given-names></name><name><surname>Kurths</surname> <given-names>J</given-names></name><name><surname>Herrmann</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Modification of brain oscillations via rhythmic light stimulation provides evidence for entrainment but not for superposition of Event-Related responses</article-title><source>Frontiers in Human Neuroscience</source><volume>10</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2016.00010</pub-id><pub-id pub-id-type="pmid">26869898</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nozaradan</surname> <given-names>S</given-names></name><name><surname>Peretz</surname> <given-names>I</given-names></name><name><surname>Keller</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Individual differences in rhythmic cortical entrainment correlate with predictive behavior in sensorimotor synchronization</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>20612</elocation-id><pub-id pub-id-type="doi">10.1038/srep20612</pub-id><pub-id pub-id-type="pmid">26847160</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connell</surname> <given-names>MN</given-names></name><name><surname>Barczak</surname> <given-names>A</given-names></name><name><surname>Ross</surname> <given-names>D</given-names></name><name><surname>McGinnis</surname> <given-names>T</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Multi-Scale entrainment of coupled neuronal oscillations in primary auditory cortex</article-title><source>Frontiers in Human Neuroscience</source><volume>9</volume><elocation-id>655</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2015.00655</pub-id><pub-id pub-id-type="pmid">26696866</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Obleser</surname> <given-names>J</given-names></name><name><surname>Kayser</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural entrainment and attentional selection in the listening brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>913</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.08.004</pub-id><pub-id pub-id-type="pmid">31606386</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olivers</surname> <given-names>CN</given-names></name><name><surname>Van der Burg</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bleeping you out of the blink: sound saves vision from oblivion</article-title><source>Brain Research</source><volume>1242</volume><fpage>191</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2008.01.070</pub-id><pub-id pub-id-type="pmid">18304520</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname> <given-names>R</given-names></name><name><surname>Fries</surname> <given-names>P</given-names></name><name><surname>Maris</surname> <given-names>E</given-names></name><name><surname>Schoffelen</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id><pub-id pub-id-type="pmid">21253357</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peelle</surname> <given-names>JE</given-names></name><name><surname>Davis</surname> <given-names>MH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural oscillations carry speech rhythm through to comprehension</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>320</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00320</pub-id><pub-id pub-id-type="pmid">22973251</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Posner</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Orienting of attention</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>32</volume><fpage>3</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1080/00335558008248231</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raymond</surname> <given-names>JE</given-names></name><name><surname>Shapiro</surname> <given-names>KL</given-names></name><name><surname>Arnell</surname> <given-names>KM</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Temporary suppression of visual processing in an RSVP task: an attentional blink?</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>18</volume><fpage>849</fpage><lpage>860</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.18.3.849</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Wilson</surname> <given-names>DA</given-names></name><name><surname>Radman</surname> <given-names>T</given-names></name><name><surname>Scharfman</surname> <given-names>H</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dynamics of active sensing and perceptual selection</article-title><source>Current Opinion in Neurobiology</source><volume>20</volume><fpage>172</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2010.02.010</pub-id><pub-id pub-id-type="pmid">20307966</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Lakatos</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Low-frequency neuronal oscillations as instruments of sensory selection</article-title><source>Trends in Neurosciences</source><volume>32</volume><fpage>9</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2008.09.012</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seymour</surname> <given-names>RA</given-names></name><name><surname>Rippon</surname> <given-names>G</given-names></name><name><surname>Kessler</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The detection of phase amplitude coupling during sensory processing</article-title><source>Frontiers in Neuroscience</source><volume>11</volume><elocation-id>487</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2017.00487</pub-id><pub-id pub-id-type="pmid">28919850</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shapiro</surname> <given-names>KL</given-names></name><name><surname>Raymond</surname> <given-names>JE</given-names></name><name><surname>Arnell</surname> <given-names>KM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The attentional blink</article-title><source>Trends in Cognitive Sciences</source><volume>1</volume><fpage>291</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(97)01094-2</pub-id><pub-id pub-id-type="pmid">21223931</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spaak</surname> <given-names>E</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Local entrainment of Î± oscillations by visual stimuli causes cyclic modulation of perception</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>3536</fpage><lpage>3544</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4385-13.2014</pub-id><pub-id pub-id-type="pmid">24599454</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname> <given-names>MF</given-names></name><name><surname>Badcock</surname> <given-names>DR</given-names></name><name><surname>Visser</surname> <given-names>TA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Training and the attentional blink: limits overcome or expectations raised?</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>21</volume><fpage>406</fpage><lpage>411</lpage><pub-id pub-id-type="doi">10.3758/s13423-013-0491-3</pub-id><pub-id pub-id-type="pmid">23884691</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>ten Oever</surname> <given-names>S</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name><name><surname>Poeppel</surname> <given-names>D</given-names></name><name><surname>van Atteveldt</surname> <given-names>N</given-names></name><name><surname>Zion-Golumbic</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Rhythmicity and cross-modal temporal cues facilitate detection</article-title><source>Neuropsychologia</source><volume>63</volume><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.08.008</pub-id><pub-id pub-id-type="pmid">25128589</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thut</surname> <given-names>G</given-names></name><name><surname>Nietzel</surname> <given-names>A</given-names></name><name><surname>Brandt</surname> <given-names>SA</given-names></name><name><surname>Pascual-Leone</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Alpha-band electroencephalographic activity over occipital cortex indexes visuospatial attention Bias and predicts visual target detection</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>9494</fpage><lpage>9502</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0875-06.2006</pub-id><pub-id pub-id-type="pmid">16971533</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thut</surname> <given-names>G</given-names></name><name><surname>Schyns</surname> <given-names>PG</given-names></name><name><surname>Gross</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Entrainment of perceptually relevant brain oscillations by Non-Invasive rhythmic stimulation of the human brain</article-title><source>Frontiers in Psychology</source><volume>2</volume><elocation-id>170</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2011.00170</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Visser</surname> <given-names>TAW</given-names></name><name><surname>Ohan</surname> <given-names>JL</given-names></name><name><surname>Enns</surname> <given-names>JT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Temporal cues derived from statistical patterns can overcome resource limitations in the attentional blink</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>77</volume><fpage>1585</fpage><lpage>1595</lpage><pub-id pub-id-type="doi">10.3758/s13414-015-0880-y</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>TJ</given-names></name><name><surname>Foxe</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cross-frequency coupling of alpha oscillatory power to the entrainment rhythm of a spatially attended input stream</article-title><source>Cognitive Neuroscience</source><volume>11</volume><fpage>71</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1080/17588928.2019.1627303</pub-id><pub-id pub-id-type="pmid">31154906</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Worden</surname> <given-names>MS</given-names></name><name><surname>Foxe</surname> <given-names>JJ</given-names></name><name><surname>Wang</surname> <given-names>N</given-names></name><name><surname>Simpson</surname> <given-names>GV</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Anticipatory biasing of visuospatial attention indexed by retinotopically specific alpha-band electroencephalography increases over occipital cortex</article-title><source>The Journal of Neuroscience</source><volume>20</volume><elocation-id>RC63</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-06-j0002.2000</pub-id><pub-id pub-id-type="pmid">10704517</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>WÃ¶stmann</surname> <given-names>M</given-names></name><name><surname>Herrmann</surname> <given-names>B</given-names></name><name><surname>Maess</surname> <given-names>B</given-names></name><name><surname>Obleser</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spatiotemporal dynamics of auditory attention synchronize with speech</article-title><source>PNAS</source><volume>113</volume><fpage>3873</fpage><lpage>3878</lpage><pub-id pub-id-type="doi">10.1073/pnas.1523357113</pub-id><pub-id pub-id-type="pmid">27001861</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zion Golumbic</surname> <given-names>EM</given-names></name><name><surname>Poeppel</surname> <given-names>D</given-names></name><name><surname>Schroeder</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Temporal context in speech processing and attentional stream selection: a behavioral and neural perspective</article-title><source>Brain and Language</source><volume>122</volume><fpage>151</fpage><lpage>161</lpage><pub-id pub-id-type="doi">10.1016/j.bandl.2011.12.010</pub-id><pub-id pub-id-type="pmid">22285024</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoefel</surname> <given-names>B</given-names></name><name><surname>Ten Oever</surname> <given-names>S</given-names></name><name><surname>Sack</surname> <given-names>AT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The involvement of endogenous neural oscillations in the processing of rhythmic input: more than a regular repetition of evoked neural responses</article-title><source>Frontiers in Neuroscience</source><volume>12</volume><elocation-id>95</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2018.00095</pub-id><pub-id pub-id-type="pmid">29563860</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.65118.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Luo</surname><given-names>Huan</given-names></name><role>Reviewing Editor</role><aff><institution>Peking University</institution><country>China</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.12.21.423786">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.12.21.423786v1">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This study, by using a series of behavioral experiments and EEG recordings, demonstrates that attention is essentially modulated by higher-order rhythmic regularity, supporting the notion that rhythmic context implements a second-order temporal structure to the first-order regularities posited in dynamic attention theory.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Cortical entrainment to hierarchical contextual rhythms recomposes dynamic attending in visual perception&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Floris de Lange as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>All the reviewers agree that it is a well-designed study and the results are exciting by using an innovative approach to modulate attention blink. The reviewers have raised several major concerns that need the authors to address and do additional analysis.</p><p>Evaluation Summary: This study by Wang et al. used a series of carefully designed behavioral experiments to convincingly demonstrate that the attentional blink (AB) could be modulated by higher-order rhythmic regularity. EEG results further support the link between the elicited neural entrainment and the AB modulation effect. They propose that the rhythmic context implements a second-order temporal structure to the first-order regularities posited in dynamic attention theory.</p><p>Essential Revisions:</p><p>1. The current AB behavior results lack several key aspects shown in typical AB experiments. First, typical AB effect would not just test one lag as did here. The authors should show the behavioral results for several lags, i.e., a full AB curve. The results would be informative as to how cortical entrainment affects the whole AB curve. Moreover, there is no data regarding T1 performance, and it is important to show that the better performance for T2 is not due to worse performance in detecting T1. Finally, typical AB design would examine T2 performance when T1 is ignored relative to when T1 has to be detected, but the data is not provided here.</p><p>2. About the EEG results. A general concern is whether the observed behavioral related neural index, e.g., alpha-band power, cross-frequency coupling, could be simply explained in terms of ERP response for T2. For example, when the ERP response for T2 is larger for between-chunk condition compared to within-chunk condition, the alpha-power for T2 would be also larger for between-chunk condition. Likewise, this might also explain the cross-frequency coupling results. The authors should do more control analyses to address the possibility, e.g., plotting the ERP response for the two conditions and regressing them out from the oscillatory index.</p><p>3. The alpha-band increase for T2 is indeed contradictory to the well-known inhibitory function of alpha-band in attention. How could a target that is better discriminated elicit stronger inhibitory response? Related to the above point, the observed enhancement in alpha-band power and its coupling to low-frequency oscillation might derive from an enhanced ERP response for T2 target.</p><p>4. To support that it is the context-induced entrainment that leads to the modulation in AB effect, the authors could examine pre-T2 response, e.g., alpha-power, and cross-frequency coupling, as well as its relationship to behavioral performance. The pre-stimulus response might be more convincing to support the authors' claim.</p><p>5. About the entrainment to rhythmic context and its relation to behavioral modulation index. Previous studies have demonstrated the hierarchical temporal structure in speech signals, e.g., emergence of word-level entrainment introduced by language experience. Therefore, it is well expected that imposing a second-order structure on a visual stream would elicit the corresponding steady-state response. The authors should add more discussions explaining how their findings contribute new understandings to the neural mechanism for the intriguing phenomena.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.65118.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential Revisions:</p><p>1. The current AB behavior results lack several key aspects shown in typical AB experiments. First, typical AB effect would not just test one lag as did here. The authors should show the behavioral results for several lags, i.e., a full AB curve. The results would be informative as to how cortical entrainment affects the whole AB curve. Moreover, there is no data regarding T1 performance, and it is important to show that the better performance for T2 is not due to worse performance in detecting T1. Finally, typical AB design would examine T2 performance when T1 is ignored relative to when T1 has to be detected, but the data is not provided here.</p></disp-quote><p>We appreciate the reviewer for his/her thoughtful comments. To demonstrate the AB effect, we did include two T2 lag conditions in our study (Experiments 1a, 1b, 2a, and 2b) â a short-SOA condition where T2 was located at the second lag of T1 (i.e., SOA = 200 ms), and a long-SOA condition where T2 appeared at the 8th lag of T1 (i.e., SOA = 800 ms). In a typical AB effect, T2 performance at short lags is remarkably impaired compared with that at long lags. In our study, we consistently replicated this effect across the experiments, as reported in the Results section of Experiment 1 (page 5, line 106). Overall, the T2 detection accuracy conditioned on correct T1 response was significantly impaired in the short-SOA condition relative to that in the long-SOA condition (mean accuracy &gt; 0.9 for all experiments), during both the context session and the baseline session. More crucially, when looking into the magnitude of the AB effect as measured by (ACC<sub>long-SOA</sub> â ACC<sub>short-SOA</sub>)/ACC<sub>long-SOA</sub>, we still obtained a significant attentional modulation effect (for Experiment 1a, <italic>t</italic>(15) = -2.729, <italic>p</italic> = .016, Cohenâs <italic>d</italic> = 0.682; for Experiment 2a, <italic>t</italic>(15) = -4.143, <italic>p</italic> &lt;.001, Cohenâs <italic>d</italic> = 1.036) similar to that reflected by the short-SOA condition alone, further confirming that cortical entrainment effectively influences the AB effect.</p><p>Although we included both the long- and short-SOA conditions in the current study, we focused on T2 performance in the short-SOA condition rather than along the whole AB curve for the following reasons. Firstly, for the long-SOA conditions, the T2 performance is at ceiling level, making it an inappropriate baseline to probe the attentional modulation effect. We focused on Lag 2 because previous research has identified a robust AB effect around the second lag (Raymond et al., 1992), which provides a reasonable and sensitive baseline to probe the potential modulation effect of the contextual auditory and visual rhythms. Note that instead of using multiple lags, we varied the length of the rhythmic cycles (i.e., a cycle of 300 ms, 400 ms, and 500 ms corresponding to a rhythm frequency of 3.3 Hz, 2.5 Hz, and 2 Hz, respectively, all within the delta band), and showed that the attentional modulation effect could be generalized to these different delta-band rhythmic contexts, regardless of the absolute positions of the targets within the rhythmic cycles.</p><p>As to the T1 performance, the overall accuracy was very high, ranging from 0.907 to 0.972, in all of our experiments. The corresponding results have been added to the Results section of the revised manuscript (page 5, line 103). Notably, we did not find T1-T2 trade-offs in most of our experiments, except in Experiment 2a where T1 performance showed a moderate decrease in the between-cycle condition relative to that in the within-cycle condition (mean Â± SE: 0.888 Â± 0.026 vs. 0.933 Â± 0.016, respectively; <italic>t</italic>(15) = -2.217, <italic>p</italic> = .043). However, by examining the relationship between the modulation effects (i.e., the difference between the two experimental conditions) on T1 and T2, we did not find any significant correlation (<italic>p</italic> = .403), suggesting that the better performance for T2 was not simply due to the worse performance in detecting T1.</p><p>Finally, previous studies have shown that ignoring T1 would lead to ceiling-level T2 performance (Raymond et al., 1992). Therefore, we did not include such manipulation in the current study, as in that case, it would be almost impossible for us to detect any contextual modulation effect.</p><disp-quote content-type="editor-comment"><p>2. About the EEG results. A general concern is whether the observed behavioral related neural index, e.g., alpha-band power, cross-frequency coupling, could be simply explained in terms of ERP response for T2. For example, when the ERP response for T2 is larger for between-chunk condition compared to within-chunk condition, the alpha-power for T2 would be also larger for between-chunk condition. Likewise, this might also explain the cross-frequency coupling results. The authors should do more control analyses to address the possibility, e.g., plotting the ERP response for the two conditions and regressing them out from the oscillatory index.</p></disp-quote><p>Thanks for the comments. In general, the rhythmic stimulation in the AB paradigm prevents EEG signals from returning to the baseline. Therefore, we cannot observe typical ERP components purely related to individual items, except for the P1 and N1 components related to the stream onset, which reveals no difference between the two conditions and are trailed by steady-state responses (SSRs) resonating at the stimulus rate (<xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>).</p><p>To further inspect the potential differences in the target-related ERP signals between the within- and between-cycle conditions, we plotted the target-aligned waveforms for these experimental conditions. As shown in <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>, a drop of ERP amplitude occurred for both conditions around T2 onset, and the difference between these two conditions was not significant (paired <italic>t</italic>-test estimated on mean amplitude every 20 ms from 0 to 700 ms relative to T1 onset, <italic>p</italic> &gt;.05, FDR-corrected).</p><p>Since there is a trend of enhanced ERP response for the between-cycle relative to the within-cycle condition during the period of 0 to 100 ms after T2 onset (paired <italic>t</italic>-test on mean amplitude, <italic>p</italic> = .065, uncorrected), we then directly examined whether such post-T2 responses contribute to the behavioral attentional modulation effect and behavior-related neural indices. Crucially, we did not find any significant correlation of such T2-related ERP enhancement with the behavioral modulation index (BMI), or with the reported effects of alpha power and cross-frequency coupling (PAC). Furthermore, after controlling for the T2-related ERP responses, there still remains a significant correlation between the delta-alpha PAC and the BMI (<italic>r</italic><sub>partial</sub> = .596, <italic>p</italic> = .019), which is not surprising given that the PAC is calculated based on an 800-ms time window covering more pre-T2 than post-T2 periods (see the response to point #4 for details) rather than around the T2 onset. Taken together, these results clearly suggest that the T2-related ERP responses cannot explain the attentional modulation effect and the observed behavior-related neural indices.</p><fig id="sa2fig1"><label>Author response image 1.</label><caption><title>ERPs aligned to stream onset.</title><p>EEG signals were filtered between 1â30 Hz, baseline-corrected (-200 to 0 ms before stream onset), and averaged across the electrodes in left parieto-occipital area where 10-Hz alpha power showed attentional modulation effect.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-resp-fig1-v1.tif"/></fig><fig id="sa2fig2"><label>Author response image 2.</label><caption><title>ERPs aligned to T1 onset.</title><p>EEG signals were filtered between 1â30 Hz, and baseline-corrected using signals -100 to 0 ms before T1 onset. The two dash lines indicate the onset of T1 and T2, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-65118-resp-fig2-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>3. The alpha-band increase for T2 is indeed contradictory to the well-known inhibitory function of alpha-band in attention. How could a target that is better discriminated elicit stronger inhibitory response? Related to the above point, the observed enhancement in alpha-band power and its coupling to low-frequency oscillation might derive from an enhanced ERP response for T2 target.</p></disp-quote><p>Thanks for the comment. A widely accepted function of alpha activity in attention is that alpha oscillations suppress irrelevant visual information during spatial selection (Kelly et al., 2006; Thut et al., 2006; Worden et al., 2000). However, it becomes a controversial issue when there exists rhythmic sensory stimulation at alpha-band, just like the situation in the current study where both the visual stream and the contextual auditory rhythm were emitted at 10 Hz. In such a case, alpha-band neural responses at the stimulation frequency can be interpreted as either passively evoked steady-state responses (SSR) or actively synchronized intrinsic brain rhythms. From the former perspective (i.e., the SSR view), an increase in the amplitude or power at the stimulus frequency may indicate an enhanced attentional allocation to the stimulus stream that may result in better target detection (Janson et al., 2014; Keil et al., 2006; MÃ¼ller and HÃ¼bner, 2002). Conversely, the latter view of the inhibitory function of intrinsic alpha oscillations would produce the opposite prediction. In a previous AB study, Janson and colleagues (2014) investigated this issue by separating the stimulus-evoked activity at 12 Hz (using the same power analysis method as ours) from the endogenous alpha oscillations ranging from 10.35 to 11.25 Hz (as indexed by individual alpha frequency, IAF). Interestingly, they found a dissociation between these two alpha-band neural responses, showing that the RSVP frequency power was higher in non-AB trials (T2 detected) than in AB trials (T2 undetected) while the IAF power exhibited the opposite pattern. According to these findings, the currently observed increase in alpha power for the between-cycle condition may reflect more of the stimulus-driven processes related to attentional enhancement. However, we do not negate the effect of intrinsic alpha oscillations in our study, as the current design is not sufficient to distinguish between these two processes. We have discussed this point in the revised manuscript (page 18, line 477). Also, we have to admit that âalpha powerâ may not be the most precise term to describe our findings of the stimulus-related results. Thus, we have specified it as âneural responses to first-order rhythms at 10 Hzâ and â10 Hz alpha powerâ in the revised manuscript (see page 12 in the Results section and page 18 in the Discussion section).</p><p>As for the contribution of T2-related ERP response to the observed effect of 10 Hz power and cross-frequency coupling, please refer to our response to point #2.</p><disp-quote content-type="editor-comment"><p>4. To support that it is the context-induced entrainment that leads to the modulation in AB effect, the authors could examine pre-T2 response, e.g., alpha-power, and cross-frequency coupling, as well as its relationship to behavioral performance. The pre-stimulus response might be more convincing to support the authors' claim.</p></disp-quote><p>Thanks for the insightful suggestion. Following this suggestion, we have examined the 10 Hz alpha power within the time window of -100â0 ms before T2 onset and found stronger activity for the between-cycle condition than for the within-cycle condition. This pre-T2 response is similar to the post-T2 response except that it is more restricted to the left parieto-occipital cluster (CP3, CP5, P3, P5, PO3, PO5, POZ, O1, OZ, <italic>t</italic>(15) = 2.774, <italic>p</italic> = .007), which partially overlaps with the cluster that exhibits a delta-alpha coupling effect significantly correlated with the BMI. We have incorporated these findings into the main text (page 12, line 315) and the Figure 5A of the revised manuscript.</p><p>As for the coupling results reported in our manuscript, the coupling index (PAC) was calculated based on the activity during the second and third cycles (i.e., 400 to 1200 ms from stream onset) of the contextual rhythm, most of which covers the pre-T2 period as T2 always appeared in the third cycle for both conditions. Together, these results on pre-T2 10 Hz alpha power and cross-frequency coupling, as well as its relationship to behavioral performance, jointly suggest that the observed modulation effect is caused by the context-induced entrainment rather than being a by-product of post-T2 processing.</p><disp-quote content-type="editor-comment"><p>5. About the entrainment to rhythmic context and its relation to behavioral modulation index. Previous studies have demonstrated the hierarchical temporal structure in speech signals, e.g., emergence of word-level entrainment introduced by language experience. Therefore, it is well expected that imposing a second-order structure on a visual stream would elicit the corresponding steady-state response. The authors should add more discussions explaining how their findings contribute new understandings to the neural mechanism for the intriguing phenomena.</p></disp-quote><p>Thanks for the suggestion. We have provided more discussion on this important issue in the revised manuscript (page 17, line 447). In brief, our study demonstrates how cortical tracking of feature-based hierarchical structure reframes the deployment of attentional resources over visual streams. This effect, distinct from the hierarchical entrainment to speech signals (Ding et al., 2016; Gross et al., 2013), does not rely on previously acquired knowledge about the structured information and can be established automatically even when the higher-order structure comes from a task-irrelevant and cross-modal contextual rhythm. On the other hand, our finding sheds fresh light on the adaptive value of the structure-based entrainment effect by expanding its role from rhythmic information (e.g., speech) perception to temporal attention deployment. To our knowledge, few studies have tackled this issue in visual or speech processing.</p><p>References:</p><p>Raymond, J. E., Shapiro, K. L., and Arnell, K. M. (1992). Temporary suppression of visual processing in an RSVP task: An attentional blink? Journal of Experimental Psychology: Human Perception and Performance, 18(3), 849â860. https://doi.org/10.1037/0096-1523.18.3.849</p><p>Janson, J., De Vos, M., Thorne, J. D., and Kranczioch, C. (2014). Endogenous and Rapid Serial Visual Presentation-induced Alpha Band Oscillations in the Attentional Blink. Journal of Cognitive Neuroscience, 26(7), 1454â1468. https://doi.org/10.1162/jocn_a_00551</p><p>Keil, A., Ihssen, N., and Heim, S. (2006). Early cortical facilitation for emotionally arousing targets during the attentional blink. BMC Biology, 4(1), 23. https://doi.org/10.1186/1741-7007-4-23</p><p>Kelly, S. P., Lalor, E. C., Reilly, R. B., and Foxe, J. J. (2006). Increases in Alpha Oscillatory Power Reflect an Active Retinotopic Mechanism for Distracter Suppression During Sustained Visuospatial Attention. Journal of Neurophysiology, 95(6), 3844â3851. https://doi.org/10.1152/jn.01234.2005</p><p>MÃ¼ller, M. M., and HÃ¼bner, R. (2002). Can the Spotlight of Attention Be Shaped Like a Doughnut? Evidence From Steady-State Visual Evoked Potentials. Psychological Science, 13(2), 119â124. https://doi.org/10.1111/1467-9280.00422</p><p>Thut, G., Nietzel, A., Brandt, S., and Pascual-Leone, A. (2006). Alpha-band electroencephalographic activity over occipital cortex indexes visuospatial attention bias and predicts visual target detection. The Journal of Neuroscienceâ¯: The Official Journal of the Society for Neuroscience, 26(37), 9494â9502. https://doi.org/10.1523/JNEUROSCI.0875-06.2006</p><p>Worden, M. S., Foxe, J. J., Wang, N., and Simpson, G. V. (2000). Anticipatory Biasing of Visuospatial Attention Indexed by Retinotopically Specific Î±-Bank Electroencephalography Increases over Occipital Cortex. Journal of Neuroscience, 20(6), RC63âRC63. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.20-06-j0002.2000">https://doi.org/10.1523/JNEUROSCI.20-06-j0002.2000</ext-link></p><p>Ding, N., Melloni, L., Zhang, H., Tian, X., and Poeppel, D. (2016). Cortical tracking of hierarchical linguistic structures in connected speech. Nature Neuroscience, 19(1), 158â164. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4186">https://doi.org/10.1038/nn.4186</ext-link></p><p>Gross, J., Hoogenboom, N., Thut, G., Schyns, P., Panzeri, S., Belin, P., and Garrod, S. (2013). Speech Rhythms and Multiplexed Oscillatory Sensory Coding in the Human Brain. PLoS Biol, 11(12). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1001752">https://doi.org/10.1371/journal.pbio.1001752</ext-link></p></body></sub-article></article>