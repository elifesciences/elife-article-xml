<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">68980</article-id><article-id pub-id-type="doi">10.7554/eLife.68980</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Decoding the brain state-dependent relationship between pupil dynamics and resting state fMRI signal fluctuation</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-233730"><name><surname>Sobczak</surname><given-names>Filip</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9169-0243</contrib-id><email>fsobczak@tue.mpg.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-233627"><name><surname>Pais-Roldán</surname><given-names>Patricia</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9381-3048</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-233626"><name><surname>Takahashi</surname><given-names>Kengo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3532-1512</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-176681"><name><surname>Yu</surname><given-names>Xin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9890-5489</contrib-id><email>XYU9@mgh.harvard.edu</email><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution>Translational Neuroimaging and Neural Control Group, High Field Magnetic Resonance Department, Max Planck Institute for Biological Cybernetics</institution><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution>Graduate Training Centre of Neuroscience, International Max Planck Research School, University of Tuebingen</institution><addr-line><named-content content-type="city">Tuebingen</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution>Institute of Neuroscience and Medicine 4, Medical Imaging Physics, Forschungszentrum Jülich</institution><addr-line><named-content content-type="city">Jülich</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution>Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital and Harvard Medical School</institution><addr-line><named-content content-type="city">Charlestown, Massachusetts</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>31</day><month>08</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e68980</elocation-id><history><date date-type="received" iso-8601-date="2021-03-31"><day>31</day><month>03</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-08-27"><day>27</day><month>08</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-02-25"><day>25</day><month>02</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.02.24.432768"/></event></pub-history><permissions><copyright-statement>© 2021, Sobczak et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Sobczak et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-68980-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-68980-figures-v2.pdf"/><abstract><p>Pupil dynamics serve as a physiological indicator of cognitive processes and arousal states of the brain across a diverse range of behavioral experiments. Pupil diameter changes reflect brain state fluctuations driven by neuromodulatory systems. Resting-state fMRI (rs-fMRI) has been used to identify global patterns of neuronal correlation with pupil diameter changes; however, the linkage between distinct brain state-dependent activation patterns of neuromodulatory nuclei with pupil dynamics remains to be explored. Here, we identified four clusters of trials with unique activity patterns related to pupil diameter changes in anesthetized rat brains. Going beyond the typical rs-fMRI correlation analysis with pupil dynamics, we decomposed spatiotemporal patterns of rs-fMRI with principal component analysis (PCA) and characterized the cluster-specific pupil–fMRI relationships by optimizing the PCA component weighting via decoding methods. This work shows that pupil dynamics are tightly coupled with different neuromodulatory centers in different trials, presenting a novel PCA-based decoding method to study the brain state-dependent pupil–fMRI relationship.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>pupil</kwd><kwd>fMRI</kwd><kwd>decoding</kwd><kwd>principal component analysis</kwd><kwd>neuromodulation</kwd><kwd>brain state</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004189</institution-id><institution>Max-Planck-Gesellschaft</institution></institution-wrap></funding-source><award-id>internal funding</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>RF1NS113278-01</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>YU215/2-1</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002347</institution-id><institution>Bundesministerium für Bildung und Forschung</institution></institution-wrap></funding-source><award-id>01GQ1702</award-id><principal-award-recipient><name><surname>Sobczak</surname><given-names>Filip</given-names></name><name><surname>Yu</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01MH111438-01</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>Yu215/3-1</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>S10 MH124733-01</award-id><principal-award-recipient><name><surname>Yu</surname><given-names>Xin</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The variability of the pupil–fMRI relationship was characterized through a combination of clustering and prediction methods, which revealed brain state-specific subcortical and neuromodulatory activation patterns reflected in pupil dynamics.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Pupil diameter change reflects the brain state and cognitive processing (<xref ref-type="bibr" rid="bib5">Beatty and Lucero-Wagoner, 2000</xref>; <xref ref-type="bibr" rid="bib27">Eckstein et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Laeng et al., 2012</xref>; <xref ref-type="bibr" rid="bib93">Wilhelm and Wilhelm, 2003</xref>). It contains information about behavioral variables as diverse as a subject’s arousal fluctuation (<xref ref-type="bibr" rid="bib49">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib96">Yoss et al., 1970</xref>; <xref ref-type="bibr" rid="bib47">McCormick et al., 2020</xref>), sensory task performance (<xref ref-type="bibr" rid="bib49">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib30">Hakerem and Sutton, 1966</xref>), movement (<xref ref-type="bibr" rid="bib84">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Salkoff et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib67">Reimer et al., 2014</xref>), exerted mental effort (<xref ref-type="bibr" rid="bib31">Hess and Polt, 1964</xref>; <xref ref-type="bibr" rid="bib34">Kahneman and Beatty, 1966</xref>; <xref ref-type="bibr" rid="bib2">Alnæs et al., 2014</xref>), expected reward (<xref ref-type="bibr" rid="bib59">O’Doherty et al., 2003</xref>), task-related uncertainty (<xref ref-type="bibr" rid="bib72">Satterthwaite et al., 2007</xref>; <xref ref-type="bibr" rid="bib56">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib69">Richer and Beatty, 1987</xref>), or upcoming decisions (<xref ref-type="bibr" rid="bib23">de Gee et al., 2014</xref>; <xref ref-type="bibr" rid="bib77">Sheng et al., 2020</xref>). This richness of behavioral correlates is partly explained by the fact that multiple neuronal sources drive pupil activity. Pupil diameter changes reflect spontaneous neural activity across the cortex (<xref ref-type="bibr" rid="bib84">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Salkoff et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="bib95">Yellin et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>) and in major subcortical areas (<xref ref-type="bibr" rid="bib84">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="bib33">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib91">Wang et al., 2012</xref>; <xref ref-type="bibr" rid="bib74">Schneider et al., 2016</xref>; <xref ref-type="bibr" rid="bib66">Ranson and Magoun, 1933</xref>). Both sympathetic and parasympathetic systems innervate muscles controlling pupil dilation and constriction (<xref ref-type="bibr" rid="bib13">Bonvallet and Zbrozyna, 1963</xref>; <xref ref-type="bibr" rid="bib48">McDougal and Gamlin, 2015</xref>; <xref ref-type="bibr" rid="bib97">Yüzgeç et al., 2018</xref>), and the activity of subcortical nuclei mediating neuromodulation has been tightly coupled with pupillary movements (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>; <xref ref-type="bibr" rid="bib33">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib68">Reimer et al., 2016</xref>; <xref ref-type="bibr" rid="bib65">Rajkowski, 1993</xref>; <xref ref-type="bibr" rid="bib24">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Murphy et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Breton-Provencher and Sur, 2019</xref>). In particular, rapid and sustained pupil size changes are associated with cortical noradrenergic and cholinergic projections, respectively (<xref ref-type="bibr" rid="bib68">Reimer et al., 2016</xref>), and direct recordings of the noradrenergic locus coeruleus demonstrate neuronal activity highly correlated with pupil dynamics (<xref ref-type="bibr" rid="bib33">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib65">Rajkowski, 1993</xref>; <xref ref-type="bibr" rid="bib14">Breton-Provencher and Sur, 2019</xref>; <xref ref-type="bibr" rid="bib4">Aston-Jones and Cohen, 2005</xref>). Also, pupil diameter changes are regulated through dopaminergic neuromodulation under drug administration (<xref ref-type="bibr" rid="bib76">Shannon et al., 1976</xref>) and in reward-related tasks (<xref ref-type="bibr" rid="bib59">O’Doherty et al., 2003</xref>; <xref ref-type="bibr" rid="bib24">de Gee et al., 2017</xref>). Studies also show that pupil dilation and constriction can be controlled by serotonergic agonists and antagonists, respectively (<xref ref-type="bibr" rid="bib90">Vitiello et al., 1997</xref>; <xref ref-type="bibr" rid="bib73">Schmid et al., 2015</xref>). These studies have revealed the highly complex relationship between pupil dynamics and brain state fluctuations (<xref ref-type="bibr" rid="bib47">McCormick et al., 2020</xref>; <xref ref-type="bibr" rid="bib67">Reimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib97">Yüzgeç et al., 2018</xref>; <xref ref-type="bibr" rid="bib43">Lowenstein et al., 1963</xref>).</p><p>Resting-state fMRI (rs-fMRI) studies have uncovered global pupil–fMRI correlation patterns in human brains as well as revealed that the pupil dynamics–fMRI relationship changed under different lighting conditions or when subjects engaged in mental imagery (<xref ref-type="bibr" rid="bib95">Yellin et al., 2015</xref>; <xref ref-type="bibr" rid="bib74">Schneider et al., 2016</xref>). The dynamic functional connectivity changes detected by fMRI, possibly modulated by the interplay of cholinergic and noradrenergic systems (<xref ref-type="bibr" rid="bib79">Shine, 2019</xref>), are also reflected in pupil dynamics both at rest (<xref ref-type="bibr" rid="bib78">Shine et al., 2016</xref>) and in task conditions (<xref ref-type="bibr" rid="bib45">Mäki-Marttunen, 2020</xref>). Furthermore, rs-fMRI has been used to display a differential correlation pattern with brainstem noradrenergic nuclei, e.g., A5 cell group, depending on the cortical cross-frequency coupling state in the animal model (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>). Although rs-fMRI enables brain-wide pupil–fMRI correlation analysis across different states, the linkage of brain state-dependent pupil dynamics with distinct activation patterns of neuromodulatory nuclei remains to be thoroughly investigated beyond the conventional analysis methods.</p><p>Here, we aimed to differentiate brain states with varied coupling patterns of pupil dynamics with the subcortical activity of major neuromodulatory nuclei in an anesthetized rat model. First, we demonstrated that the pupil–fMRI relationship is not uniform across different scanning trials and employed a clustering procedure to identify distinct pupil–fMRI spatial correlation patterns from a cohort of datasets. Next, we modeled the relationship of the two modalities for each cluster using principal component analysis (PCA)-based decoding methods (gated recurrent unit [GRU] [<xref ref-type="bibr" rid="bib18">Cho, 2014</xref>] neural networks and linear regression) and characterized unique subcortical activation patterns coupled with specific pupil dynamic features. This work demonstrates the effectiveness of PCA-based decoding to dissect the time-varied pupil–fMRI relationship corresponding to different forms of brain state-dependent neuromodulation.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Identification of brain states with distinct pupil dynamics correlation patterns</title><p>To investigate brain state-dependent pupil dynamics, we acquired whole-brain rs-fMRI with real-time pupillometry in anesthetized rats (n = 10) as previously reported (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>). Initially, the pupil dilation and fMRI time series from all 15 min trials (n = 74) were concatenated. A voxel-wise correlation map of the concatenated pupil signals with fMRI time courses showed a global negative correlation (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). However, the generated map was not representative of all trials, which was revealed by creating correlation maps for individual trials (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). These maps demonstrated high variability of pupil–fMRI correlations, which is presented by the histogram distribution of spatial correlation values between individual-trial spatial maps and the concatenated all-trial map (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Variability of the pupil–fMRI linkage.</title><p>(<bold>A</bold>) Pupil–fMRI correlation map created by correlating the two modalities’ concatenated signals from all trials. (<bold>B</bold>) Selected individual-trial correlations maps. (<bold>C</bold>) Histogram of spatial correlations between the all-trial correlation map and individual-trial maps. High variability of similarities between the maps shows that the pupil–fMRI relationship is not stationary and changes across trials.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>The mean correlation map (A), all individual correlation maps (B), and the spatial correlation values (C) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig1-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig1-v2.tif"/></fig><p>Next, we clustered all trials into different groups based on pupil–fMRI correlation maps (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). To facilitate the clustering analysis, we reduced the dimensionality of the spatial correlation maps using the uniform manifold approximation and projection (UMAP) method (<xref ref-type="bibr" rid="bib50">McInnes et al., 2020</xref>) and decreased the number of features used for clustering from the number of voxels (n = 20,804) to 72 for each map. Three to seven clusters were identified with Gaussian mixture modeling and examined using silhouette analysis (<xref ref-type="bibr" rid="bib51">McLachlan and Basford, 1988</xref>; <xref ref-type="bibr" rid="bib70">Rousseeuw, 1987</xref>). Here, we focused on the four-cluster categorization since this division yielded the highest mean silhouette scores (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) across 100 random UMAP and GMM initializations. For each trial, we selected its most common cluster membership across the 100 repetitions and used it in the following analysis. The clustering results exhibited a very high degree of reproducibility as seen in the plots displaying the reproducibility of cluster labels and mean cluster correlation maps (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). The clusters had the following trial counts: n<sub>1</sub> = 8; n<sub>2</sub> = 30; n<sub>3</sub> = 24; n<sub>4</sub> = 12. The mean power spectral density (PSD) estimates of pupil dynamics based on the cluster division were plotted in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. PSD of cluster one showed a distinct peak at 0.018 Hz as well as the lowest baseline pupil diameter values. In contrast, cluster 4 had the highest mean baseline diameter and a peak at 0.011 Hz. Clusters 2 and 3 showed peaks of oscillatory power at less than 0.01 Hz. The ultra-slow oscillation is typical for spontaneous pupil fluctuations (<xref ref-type="bibr" rid="bib52">McLaren et al., 1992</xref>). All PSDs and example pupil signals from each cluster are shown in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>. We recreated pupil–fMRI correlation maps based on the four clusters (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Three clusters (1, 2, and 4) showed negative correlations across large parts of the brain, with the correlation strength differing across clusters. In contrast, cluster 3 displayed a very low mean correlation with positive coefficients spreading across the entire brain. It is also noteworthy that cluster 1 showed a high positive correlation in the periaqueductal gray and ventral midbrain regions. The distinct qualities of identified clusters supported the usage of data-driven clustering for identifying brain state-dependent pupil dynamics.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Clustering of trials with distinct pupil–fMRI correlation patterns.</title><p>(<bold>A</bold>) Schematic of the clustering procedure. UMAP is used to reduce the dimensionality of all individual-trial correlation maps to 72 dimensions. A 2D UMAP-projection of the real data is shown. Each dot represents a single trial. The trials are clustered using Gaussian mixture model clustering. Different numbers of clusters are evaluated. (<bold>B</bold>) The final number of clusters is selected based on silhouette analysis. The highest average silhouette score is obtained with k = 4 clusters. Shaded area shows standard deviations. (<bold>C</bold>) Pupil power spectral density estimates (PSD) of each of the four clusters. Signals were downsampled to match the fMRI sampling rate. Shaded areas show standard deviations. (<bold>D</bold>) Cluster-specific correlation maps based on concatenated signals belonging to the respective groups.</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Cluster trial labels, individual silhouette scores (B), mean cluster PSDs (C), and cluster-specific correlation maps (D) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig2-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Cluster reproducibility across 100 repetitions with random UMAP and GMM initializations.</title><p>(<bold>A</bold>) Matrix displaying the ratio of cluster membership labels matching the most common cluster membership assignment across the 100 repetitions. (<bold>B</bold>) Matrix displaying the mean spatial correlation between the 100 cluster-specific maps and the maps based on the most common cluster membership assignment.</p><p><supplementary-material id="fig2s1sdata1"><label>Figure 2—figure supplement 1—source data 1.</label><caption><title>The label match ratios (A) and map similarity values (B) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig2-figsupp1-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Cluster-specific pupil fluctuation features.</title><p>(<bold>A</bold>) PSDs of all trials divided based on their cluster memberships. Clusters 1 and 3 show specific peak frequencies. Cluster 4 shows the largest PSDs, hence the largest pupil size fluctuations. Cluster 1 shows the opposite. (<bold>B</bold>) Two example pupil diameter time courses are plotted per cluster. The magnitude of changes reflects the PSD differences visible in (<bold>A</bold>).</p><p><supplementary-material id="fig2s2sdata1"><label>Figure 2—figure supplement 2—source data 1.</label><caption><title>All PSDs (A) are available in the source data file.</title><p>All pupil signals (B) are available online (see Materials and methods).</p></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig2-figsupp2-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Clustering reproducibility across 100 clustering repetitions based on HRF-convolved pupil signals.</title><p>(<bold>A</bold>) HRFs with different peak times were used to create the convolved and lagged pupil signals. (<bold>B</bold>) Mean match ratio of cluster membership labels created using the convolved signals and those employed throughout the manuscript. The shaded area shows the standard deviation. (<bold>C</bold>) Mean spatial correlation between cluster-specific maps created using the convolved and non-convolved signals. The shaded area shows the standard deviation.</p><p><supplementary-material id="fig2s3sdata1"><label>Figure 2—figure supplement 3—source data 1.</label><caption><title>The HRF kernels (A), cluster membership label match ratios (B), and map similarity values (C) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig2-figsupp3-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Cluster reproducibility across 100 repetitions of split-halves clustering.</title><p>(<bold>A</bold>) Matrix displaying the ratio of split-halves cluster membership labels matching the cluster membership assignment based on all trials across 100 repetitions. (<bold>B</bold>) Matrix displaying the mean spatial correlation between the 100 split-halves cluster-specific maps and maps based on all trials.</p><p><supplementary-material id="fig2s4sdata1"><label>Figure 2—figure supplement 4—source data 1.</label><caption><title>The label match ratios (A) and map similarity values (B) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig2-figsupp4-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig2-figsupp4-v2.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>Cluster reproducibility across 100 sets of artificially generated surrogates with values and spatial autocorrelations matching those of real maps.</title><p>(<bold>A</bold>) A real pupil–fMRI correlation map and three example surrogate maps. (<bold>B</bold>) Matrix displaying the ratio of cluster membership labels generated based on the surrogate maps and those based on real data. (<bold>C</bold>) Matrix displaying the mean spatial correlation between the surrogate cluster-specific maps and those based on real data.</p><p><supplementary-material id="fig2s5sdata1"><label>Figure 2—figure supplement 5—source data 1.</label><caption><title>Ten example surrogate sets (i.e. 740 maps total) (A), label match ratios (B), and map similarity values (C) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig2-figsupp5-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig2-figsupp5-v2.tif"/></fig><fig id="fig2s6" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 6.</label><caption><title>Mean silhouette scores based on 100 clustering repetitions performed on shorter trials.</title><p>Based on the silhouette score criterion, the n = 4 clusters result should be chosen even when dividing the trials into three parts.</p><p><supplementary-material id="fig2s6sdata1"><label>Figure 2—figure supplement 6—source data 1.</label><caption><title>Individual silhouette scores are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig2-figsupp6-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig2-figsupp6-v2.tif"/></fig></fig-group><p>Lastly, we performed a series of analyses to investigate cluster reproducibility beyond the initial random initializations. First, to compensate for the possible lag between pupil and fMRI, we convolved pupil signals with hemodynamic response function (HRF) kernels with different peak times (<xref ref-type="bibr" rid="bib95">Yellin et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>; <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3A</xref>). We regenerated the correlation maps and repeated the clustering procedure 100 times for each kernel. The high cluster membership and correlation map reproducibility across a range of HRF peak times (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3B,C</xref>) justify the use of non-convolved signals and emphasize the impact of slow fluctuations on the correlation results. Similarly to <xref ref-type="bibr" rid="bib1">Allen et al., 2014</xref>, we performed 100 half-split reproducibility analyses and showed that to a large degree the cluster memberships are preserved when using half of the trials (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). The match might be imperfect, e.g., due to smaller numbers of a particular cluster’s samples in a half-split interacting with UMAP dimensionality reduction parameters. Next, using spatial surrogate maps with spatial autocorrelation and value distribution matching that of real correlation maps (<xref ref-type="bibr" rid="bib15">Burt et al., 2020</xref>) (see Materials and methods), we verified that the spatial location of correlation values and not the mean values or spatial autocorrelation properties were driving the clustering (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). Finally, we showed that when splitting the trials into shorter runs, clustering the data into n = 4 clusters should be selected based on the silhouette score criterion up to a 300 s trial length (<xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>). The conducted analyses further justified the selection of n = 4 clusters and verified the reproducibility of the UMAP and GMM clustering procedure.</p></sec><sec id="s2-2"><title>Decoding-based investigation of the relationship between whole-brain rs-fMRI and pupil dynamics</title><p>To characterize the pupil–fMRI relationship beyond the conventional correlation analysis, we implemented data-driven decoding models to couple the dynamics of the two modalities. First, we validated the approach in a setting involving all trials. We then employed it to investigate the pupil–fMRI coupling in the previously identified clusters. First, we performed principal component analysis (PCA) to extract spatiotemporal features of whole-brain rs-fMRI signals (n = 300) and trained either linear regression (LR) or a gated recurrent unit (GRU) neural network to predict pupil dynamics based on rs-fMRI PCA time courses (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Furthermore, we compared the LR and GRU prediction models with a correlation-template-based pupil dynamics estimation used in previous studies (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>; <xref ref-type="bibr" rid="bib17">Chang et al., 2016</xref>). All methods were trained on randomly chosen 64 trials using cross-validation and then were tested on additional 10 unseen trials from the same animals. The PCA model was fit with the 64 training trials only. As the correlation-template-based predictions were bounded to the &lt;−1; 1&gt; range, Pearson’s correlation coefficient was used to evaluate the decoding of all methods. We optimized the hyperparameters of GRUs and linear regression variants using Bayesian optimization and fourfold cross-validation (hyperparameter values are listed in Materials and methods). Both linear regression and GRU outperformed the correlation-template approach on both training (CC<sub>base</sub> = 0.37 ± 0.27 s.d., CC<sub>LR</sub> = 0.45 ± 0.26 s.d., CC<sub>GRU</sub> = 0.46 ± 0.25 s.d., p<sub>LR</sub> = 4.3*10<sup>–6</sup>, p<sub>GRU</sub> = 2.4 × 10<sup>–6</sup>) and test sets (CC<sub>base</sub> = 0.25 ± 0.17 s.d., CC<sub>LR</sub> = 0.44 ± 0.24 s.d., CC<sub>GRU</sub> = 0.45 ± 0.27 s.d., p<sub>LR</sub> = 0.003, p<sub>GRU</sub> = 0.01) (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Notably, the test set prediction scores do not reflect generalization across different rats as the training and test data could belong to the same animals. We repeated the linear regression prediction procedure (including the PCA step) on 100 other random train-test trial splits and validated that the obtained scores are representative of the distribution (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). We also verified the number of rs-fMRI PCA components by testing varied component counts, showing that the highest prediction scores were achieved with 300 components (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B,C</xref>). In addition, when varying the temporal shift between pupil dynamics and rs-fMRI signals, we obtained the highest prediction scores with zero shift between the input and output signals (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). Similarly, the highest prediction scores were obtained based on pupil signals convolved with an HRF kernel with a peak at 0 s (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>). Interestingly, the component which explained the most pupillary variance (explained var. = 7.03%) and had the highest linear regression weight, explained only 0.8% of the fMRI variance (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Furthermore, the component that explained the most fMRI variance (explained var. = 22.01%) was weakly coupled with the pupil fluctuation (explained var. = 0.51%). Thus, this prediction-based PCA component weighting scheme enabled the dissection of unique brain activity features for the modeling of the pupil−fMRI relationship. It should also be noted that GRU and linear regression methods obtained comparable scores and both methods showed similar prediction performance (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref> shows prediction maps created by integrating PCA components using linear regression weights or averaged GRU gradients (details in Materials and methods). The resemblance of the two maps suggests that despite GRU’s potential for encoding complex and non-linear functions, a linear regression-based rs-fMRI mapping scheme was sufficient for predicting pupil dynamics.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Decoding pupil dynamics based on fMRI signals.</title><p>(<bold>A</bold>) Schematic of the decoding procedure. PCA was applied to fMRI data. The PCA time courses were fed into either linear regression or GRU decoders, which generated pupil signal predictions. The prediction quality was evaluated by comparing the generated signals with real pupil fluctuations using Pearson’s correlation coefficients. (<bold>B</bold>) Comparison of the three methods’ pupil dynamics predictions. Linear regression and GRU performed better than the correlation-based baseline method on both the cross-validation splits (CC<sub>base</sub> = 0.37 ± 0.27 s.d., CC<sub>LR</sub> = 0.45 ± 0.26 s.d., CC<sub>GRU</sub> = 0.46 ± 0.25 s.d., p<sub>LR</sub> = 4.3*10<sup>–6</sup>, p<sub>GRU</sub> = 2.4 × 10<sup>–6</sup>) and on test data (CC<sub>base</sub> = 0.25 ± 0.17 s.d., CC<sub>LR</sub> = 0.44 ± 0.24 s.d., CC<sub>GRU</sub> = 0.45 ± 0.27 s.d., p<sub>LR</sub> = 0.003, p<sub>GRU</sub> = 0.01). Scattered points show individual prediction scores. (<bold>C</bold>) Linear regression and GRU predictions of three selected trials (CC<sub>GRU-top</sub> = 0.79, CC<sub>LR-top</sub> = 0.77, CC<sub>GRU-middle</sub> = 0.75,CC<sub>LR-middle</sub> = 0.73, CC<sub>GRU-bottom</sub> = 0.02, CC<sub>LR-bottom</sub> = 0.06). Qualitatively, linear regression and GRU predictions were very similar.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Prediction scores (B) and all predicted time courses (C) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig3-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Prediction score dependence on train-test split trial selection, number of PCA components, and temporal shifts between pupil and fMRI signals.</title><p>(<bold>A</bold>) Mean test and train set prediction scores across 100 random train-test splits. The red dot shows values described in the manuscript. (<bold>B</bold>) The influence of temporal shifts and different component counts on prediction scores. Temporally shifting the fMRI and pupil fluctuation signals reduced prediction accuracy. Predictions generated based on 300 PCA components obtained the best scores. (<bold>C</bold>) The influence of predicting the HRF-convolved pupil signals and using different component counts on prediction scores. Predicting signals convolved with an HRF with a peak at 0 s generated the highest scores. Predictions generated based on 300 PCA components obtained the best scores.</p><p><supplementary-material id="fig3s1sdata1"><label>Figure 3—figure supplement 1—source data 1.</label><caption><title>Individual prediction scores across all trial mixes (A) and the mean prediction scores (BC) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig3-figsupp1-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>PCA decoupling of pupil-related fMRI activity from other signal sources.</title><p>(<bold>A</bold>) fMRI variance explained by individual PCA components. Components are ordered by variance explained. Black dot marks the component with the most explained pupil variance. (<bold>B</bold>) Pupil variance explained by the PCA signals. Same ordering as in (<bold>A</bold>). The component explaining the most pupil variance (explained var. = 7.03%) explains only 0.8% of fMRI variance. Black dot marks the component with the most explained pupil variance. (<bold>C</bold>) Weights of the linear regression model trained to decode pupil signals based on fMRI-PCA data. Each weight corresponds to a single PCA component’s time course. The highest absolute weights are not assigned to the components explaining the most fMRI variance. Black dot marks the component with the most explained pupil variance.</p><p><supplementary-material id="fig3s2sdata1"><label>Figure 3—figure supplement 2—source data 1.</label><caption><title>The variance explained values (AB) and linear regression weights (C) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig3-figsupp2-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Similarity of GRU and linear regression prediction maps.</title><p>Spatial maps were generated by integrating PCA spatial maps with either linear regression weights or average GRU gradients. The maps highlight the same areas. This observation coupled with the similarity of predictions generated by both methods and the short GRU training time suggests that a linear mapping was sufficient for this decoding task.</p><p><supplementary-material id="fig3s3sdata1"><label>Figure 3—figure supplement 3—source data 1.</label><caption><title>The maps are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig3-figsupp3-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig3-figsupp3-v2.tif"/></fig></fig-group><p>The map generated by combining PCA components with the linear regression decoder enabled the identification of brain nuclei which were not highlighted in the correlation map shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref>. <xref ref-type="fig" rid="fig4">Figure 4</xref> shows an overview of the PCA-based fMRI prediction map overlaid on the brain atlas, revealing pupil-related activation patterns at key neuromodulatory nuclei of the ascending reticular activating system (ARAS) – the dopaminergic ventral tegmental area, substantia nigra and supramammillary nucleus, the serotonergic raphe and B9 cells, the histaminergic tuberomammillary nucleus, the cholinergic laterodorsal tegmental and pontine nuclei, the glutamatergic parabrachial nuclei, and the area containing the noradrenergic locus coeruleus. Positive weights were also located in subcortical regions involved in autonomous regulation – the lateral and preoptic hypothalamus and the periaqueductal gray. In addition, the subcortical basal forebrain nuclei (the horizontal limb of the diagonal band, nucleus accumbens, and olfactory tubercle) and the septal area were positively coupled with pupil dynamics. Lastly, regions of the hippocampal formation – the hippocampus, entorhinal cortex, and subiculum, as well as cingulate, retrosplenial, and visual cortices displayed positive weighting. It should be noted that the thalamus and the hippocampus displayed both positive and negative weights. Negative coupling was also found in the cerebellum and most somatosensory cortical regions. The voxel-wise statistical significance (p&lt;0.01) was validated using randomization tests and corrected for multiple comparisons with false discovery rate correction (details in Materials and methods). The identification of pupil-related information in brain regions closely tied to neuromodulatory activity and to autonomous and brain state regulation (<xref ref-type="bibr" rid="bib26">Duyn et al., 2020</xref>; <xref ref-type="bibr" rid="bib8">Benarroch, 2018</xref>; <xref ref-type="bibr" rid="bib22">Dampney, 2016</xref>; <xref ref-type="bibr" rid="bib80">Silvani et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Kuwaki and Zhang, 2010</xref>; <xref ref-type="bibr" rid="bib29">Grimaldi et al., 2014</xref>; <xref ref-type="bibr" rid="bib88">van den Brink et al., 2019</xref>) highlights the advantage of using PCA decomposition combined with prediction-based decoding methods instead of conventional correlation analysis to identify pupil-related subcortical activation patterns.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Localization of pupil dynamics-related information content across the brain.</title><p>The spatial map highlights regions from which pupil-related information was decoded. It was created by integrating PCA spatial maps with weights of the trained linear regression model. The map displays positive weights in all neuromodulatory regions of the ascending reticular activating system as well as in other regions involved in autonomous regulation – the lateral and preoptic hypothalamus and the periaqueductal gray. The subcortical basal forebrain nuclei (the horizontal limb of the diagonal band, nucleus accumbens, and olfactory tubercle) and the septal area were also positively coupled to pupil dynamics. Finally, regions of the hippocampal formation – the hippocampus, entorhinal cortex and subiculum, as well as cingulate, retrosplenial and visual cortices showed positive weights. The thalamus and the hippocampus had both positive and negative weights. Strong negative weighting was found in the cerebellum and most somatosensory cortical regions. Masked regions (white) did not pass the false discovery rate corrected significance threshold (p=0.01). Abbreviations: B9 – B9 serotonergic cells, Ce – cerebellum, CgCx – cingulate cortex, DB – horizontal limb of the diagonal band, ECx – entorhinal cortex, Hp – hippocampus, LC – locus coeruleus, LDT – laterodorsal tegmental nuclei, LH – lateral hypothalamus, NA – nucleus accumbens, OTu – olfactory tubercle, PAG – periaqueductal gray, PB – parabrachial nuclei, PO – preoptic nuclei, PPT – pedunculopontine tegmental nuclei, Ra – raphe, RF – reticular formation, RsCx – retrosplenial cortex, Sb – subiculum, SCx – somatosensory cortex, Se – septal nuclei, SN – substantia nigra, SuM – supramammillary nucleus, Th – thalamus, TuM – tuberomammillary nucleus, VTA – ventral tegmental area.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>The masked map is available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig4-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig4-v2.tif"/></fig></sec><sec id="s2-3"><title>Characterization of brain state-dependent PCA-based pupil–fMRI prediction maps</title><p>To differentiate brain state-dependent subcortical activation patterns related to different pupil dynamics, we retrained the linear regression model based on the four different clusters shown in <xref ref-type="fig" rid="fig2">Figure 2D</xref> and created PCA-based fMRI prediction maps for each cluster (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Characterization of brain state-specific pupil–fMRI relationships.</title><p>(<bold>A</bold>) Pupil information content maps generated by integrating PCA spatial maps with weights of linear regression models trained on cluster-specific trials. In all clusters, negative weights were found in the somatosensory cortex, the cerebellum, and posterior parts of the thalamus. All clusters had positive weights in anterior thalamic, preoptic and hypothalamic nuclei, subiculum, parts of the hippocampus and in the region containing the tuberomammillary nucleus. Clusters 1–3 displayed positive weights in neuromodulatory brainstem regions, substantia nigra, and ventral tegmental area, as well as the entorhinal cortex. The cingulate cortex and retrosplenial cortex and supramammillary nucleus were positive in clusters 2–4. Marked with gray are frames plotted in (<bold>B</bold>). (<bold>B</bold>) Cluster-specific spatial patterns are portrayed on slices selected from <bold>A</bold> (marked with gray rectangles). Characteristic to cluster 1 were positive weights in the dopaminergic substantia nigra and ventral tegmental area as well as in their efferent projections in the nucleus accumbens and caudate-putamen. Positive weighting was also found in the periaqueductal gray and brainstem laterodorsal tegmental and parabrachial nuclei, as well as in the superior colliculus. Cluster 2 was characterized by the strongest positive weights in hypothalamic regions, lateral in particular. Brainstem areas containing the arousal-regulating locus coeruleus, laterodorsal tegmental, and parabrachial nuclei, as well as the septal area and the olfactory tubercle displayed high positive weights. In cluster 3, as in cluster 2, the area containing the locus coeruleus, laterodorsal tegmental, and parabrachial nuclei showed positive linkage with pupil dynamics. The highest cluster 3 values were located in preoptic and other hypothalamic areas, as well as in stria terminalis carrying primarily afferent hypothalamic fibers, caudate-putamen, and globus pallidus. In cluster 4, the neuromodulatory region showing the strongest positive weights was the caudal raphe. The anterior parts of the brainstem displayed negative weighting. Characteristic to cluster 4 were high weights in the thalamus and in the hippocampus and the subiculum forming the hippocampal formation. Masked regions (white) did not pass the false discovery rate corrected significance threshold (p=0.01). Abbreviations: Ce – cerebellum, CgCx – cingulate cortex, CP – caudate-putamen, GP – globus pallidus, Hp – hippocampus, Hy – hypothalamus, LC – locus coeruleus, LDT – laterodorsal tegmental nuclei, LH – lateral hypothalamus, NA – nucleus accumbens, OTu – olfactory tubercle, PAG – periaqueductal gray, PB – parabrachial nuclei, PO – preoptic nuclei, Ra – raphe, Sb – subiculum, SC – superior colliculus, Se – septal area, SN – substantia nigra, ST – stria terminalis, Th – thalamus, VTA – ventral tegmental area.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>The unmasked cluster maps (A) and the masked maps based on randomization tests with a different random seed (B) are available in the source data file.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-68980-fig5-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>The spatial map based on cluster 1 trials highlights regions from which pupil-related information was decoded.</title><p>Masked regions (white) did not pass the false discovery rate corrected significance threshold (p=0.01). Abbreviations: Ce – cerebellum, CP – caudate-putamen, ECx – entorhinal cortex, Hp – hippocampus, Hy – hypothalamus, LDT – laterodorsal tegmental nuclei, LH – lateral hypothalamus, NA – nucleus accumbens, PAG – periaqueductal gray, PB – parabrachial nuclei, Sb – subiculum, SC – superior colliculus, SCx – somatosensory cortex, SN – substantia nigra, Th – thalamus, TuM – tuberomammillary nucleus, VTA – ventral tegmental area.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>The spatial map based on cluster 2 trials highlights regions from which pupil-related information was decoded.</title><p>Masked regions (white) did not pass the false discovery rate corrected significance threshold (p=0.01). Abbreviations: B9 – B9 serotonergic cells, Ce – cerebellum, CgCx – cingulate cortex, ECx – entorhinal cortex, Hp – hippocampus, Hy – hypothalamus, LC – locus coeruleus, LDT – laterodorsal tegmental nuclei, LH – lateral hypothalamus, OTu – olfactory tubercle, PB – parabrachial nuclei, PPT – pedunculopontine tegmental nuclei, Ra – raphe, RsCx – retrosplenial cortex, Sb – subiculum, SCx – somatosensory cortex, Se – septal nuclei, SN – substantia nigra, SuM – supramammillary nucleus, Th – thalamus, TuM – tuberomammillary nucleus, VTA – ventral tegmental area.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>The spatial map based on cluster 3 trials highlights regions from which pupil-related information was decoded.</title><p>Masked regions (white) did not pass the false discovery rate corrected significance threshold (p=0.01). Abbreviations: Ce – cerebellum, CgCx – cingulate cortex, CP – caudate-putamen, ECx – entorhinal cortex, GP – globus pallidusHp – hippocampus, LC – locus coeruleus, LDT – laterodorsal tegmental nuclei, LH – lateral hypothalamus, PAG – periaqueductal gray, PB – parabrachial nuclei, PO – preoptic nuclei, Ra – raphe, RF – reticular formation, RsCx – retrosplenial cortex, Sb – subiculum, SCx – somatosensory cortex, SN – substantia nigra, ST – stria terminalis, SuM – supramammillary nucleus, Th – thalamus, TuM – tuberomammillary nucleus, VTA – ventral tegmental area.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig5-figsupp3-v2.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>The spatial map based on cluster 4 trials highlights regions from which pupil-related information was decoded.</title><p>Masked regions (white) did not pass the false discovery rate corrected significance threshold (p=0.01). Abbreviations: Ce – cerebellum, CgCx – cingulate cortex, Hp – hippocampus, LH – lateral hypothalamus, Ra – raphe, RsCx – retrosplenial cortex, Sb – subiculum, SCx – somatosensory cortex, SuM – supramammillary nucleus, Th – thalamus, TuM – tuberomammillary nucleus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68980-fig5-figsupp4-v2.tif"/></fig></fig-group><p>Each PCA-based prediction map portrayed a cluster-specific spatial pattern (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Cluster 1 was characterized by strong positive weights in the dopaminergic substantia nigra and ventral tegmental area as well as in their efferent projections in the striatum (nucleus accumbens and caudate-putamen) (<xref ref-type="bibr" rid="bib6">Beckstead et al., 1979</xref>). Positive coupling was also displayed in the periaqueductal gray and brainstem laterodorsal tegmental and parabrachial nuclei as well as in the superior colliculus. Cluster 2 had the strongest positive weights in hypothalamic regions, lateral in particular, but also in brainstem arousal-regulating areas containing the locus coeruleus, laterodorsal tegmental, and parabrachial nuclei. High positive values were also found in the septal area and the olfactory tubercle. In cluster 3, the highest values were visible in preoptic and other hypothalamic areas, as well as in stria terminalis carrying primarily afferent hypothalamic fibers (<xref ref-type="bibr" rid="bib25">De Olmos and Ingram, 1972</xref>), caudate-putamen, and globus pallidus. As in cluster 2, the region containing the locus coeruleus, laterodorsal tegmental, and parabrachial nuclei showed positive linkage with pupil dynamics. Contrastingly, in cluster 4, caudal raphe was the neuromodulatory region showing the strongest positive weights and the anterior parts of the brainstem displayed negative weighting. Characteristic to cluster 4 were high weights in the hippocampus and the subiculum forming the hippocampal formation, as well as in thalamic and amygdaloid areas. In all clusters, negative weights were detected across somatosensory cortices, the cerebellum, and posterior parts of the thalamus, as well as positive weights in hypothalamic and anterior thalamic nuclei and in the area containing the tuberomammillary nucleus. The subiculum and parts of the hippocampus were also positive in all clusters; however, the entorhinal cortex, also belonging to the hippocampal formation, was positive only in clusters 1–3. The same three clusters showed major positive weights in the neuromodulatory brainstem regions, substantia nigra, and ventral tegmental area. Clusters 2–4 displayed strong weights in the supramammillary nucleus, retrosplenial cortex, and the cingulate cortex, which has been coupled with both noradrenergic modulation (<xref ref-type="bibr" rid="bib4">Aston-Jones and Cohen, 2005</xref>) and pupil dynamics (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>; <xref ref-type="bibr" rid="bib33">Joshi et al., 2016</xref>). Enlarged cluster-specific maps are displayed in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1</xref>–<xref ref-type="fig" rid="fig5s4">4</xref>. Here, we demonstrated the effectiveness of combining the PCA-based approach with clustering methods to reveal brain state-specific subcortical activity patterns related to pupil diameter changes.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Previous studies analyzed the relationship of fMRI and pupil dynamics either by directly correlating pupil size changes with the fMRI signal fluctuation (<xref ref-type="bibr" rid="bib95">Yellin et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>; <xref ref-type="bibr" rid="bib74">Schneider et al., 2016</xref>) or by applying a general linear model to produce voxel-wise activation maps (<xref ref-type="bibr" rid="bib2">Alnæs et al., 2014</xref>; <xref ref-type="bibr" rid="bib53">Murphy et al., 2014</xref>; <xref ref-type="bibr" rid="bib20">Clewett et al., 2018</xref>). Here, we performed PCA-based dimensionality reduction to decouple spatiotemporal features of fMRI signals (<xref ref-type="bibr" rid="bib55">Mwangi et al., 2014</xref>) and implemented prediction methods to decode pupil dynamics based on the optimized PCA component weighting (<xref ref-type="fig" rid="fig3">Figure 3</xref>).</p><p>Two advantages can be highlighted in the present pupil–fMRI dynamic mapping scheme. First, conventional correlation analysis relies on the temporal features of fMRI time courses from individual voxels or regions of interest. Hence, it could not decouple the superimposed effects of multiple signal sources (<xref ref-type="bibr" rid="bib16">Carbonell et al., 2011</xref>; <xref ref-type="bibr" rid="bib86">Tong et al., 2019</xref>) or characterize the state-dependent dynamic subcortical correlation patterns. On the other hand, the PCA decomposition scheme solved these issues by decoupling multiple components of rs-fMRI signals with unique spatiotemporal patterns carrying pupil-related information. Second, the data-driven training of prediction methods optimized the weighting of individual rs-fMRI PCA components. Using the optimized neural network (GRU) or linear regression (LR)-based decoding models, we created prediction maps linking pupil dynamics with fMRI signal fluctuation of specific subcortical nuclei (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Also, the decoding models showed much better pupil dynamics prediction than the correlation-template-based approach reported previously (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>; <xref ref-type="bibr" rid="bib17">Chang et al., 2016</xref>). Meanwhile, it should be noted that both LR and GRU models generated qualitatively similar prediction maps, highlighting the pupil-related rs-fMRI signal fluctuation from the same subcortical brain regions (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). Unlike our previous single-vessel fMRI prediction study (<xref ref-type="bibr" rid="bib81">Sobczak et al., 2021a</xref>), the GRU-based neural network prediction scheme may require much bigger training datasets to outperform linear regression modeling (<xref ref-type="bibr" rid="bib75">Schulz et al., 2020</xref>). Another plausible explanation is that the pupil dynamics were predominantly and linearly driven by only a few rs-fMRI PCA components (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), presenting brain activation patterns related to arousal fluctuation and autonomous regulation (<xref ref-type="bibr" rid="bib26">Duyn et al., 2020</xref>; <xref ref-type="bibr" rid="bib58">Özbay, 2019</xref>).</p><p>The PCA-based prediction modeling provides a novel scheme to decipher subcortical spatial patterns of fMRI signal fluctuation related to brain state-dependent pupil dynamics. Most notably, neuromodulatory nuclei of ARAS and other subcortical nuclei involved in brain state modulation, as well as autonomous regulation were identified in the PCA-prediction map created from all trials. The highlighted hypothalamus, basal forebrain, and neuromodulatory brainstem nuclei are responsible for both global brain state modulation and autonomous cardiovascular, respiratory, and baroreflex control (<xref ref-type="bibr" rid="bib26">Duyn et al., 2020</xref>; <xref ref-type="bibr" rid="bib8">Benarroch, 2018</xref>; <xref ref-type="bibr" rid="bib22">Dampney, 2016</xref>; <xref ref-type="bibr" rid="bib80">Silvani et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Kuwaki and Zhang, 2010</xref>; <xref ref-type="bibr" rid="bib29">Grimaldi et al., 2014</xref>; <xref ref-type="bibr" rid="bib88">van den Brink et al., 2019</xref>). Consequently, the source of pupil-related information found across the cortex was probably modulated through global subcortical projections rather than a more direct causal interaction with pupil size changes (<xref ref-type="bibr" rid="bib68">Reimer et al., 2016</xref>; <xref ref-type="bibr" rid="bib40">Lecrux and Hamel, 2016</xref>). Noradrenergic neurons of the locus coeruleus are the hypothesized drivers of pupil dilation (<xref ref-type="bibr" rid="bib33">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib4">Aston-Jones and Cohen, 2005</xref>), and both the area containing the locus coeruleus and many of its input regions (<xref ref-type="bibr" rid="bib14">Breton-Provencher and Sur, 2019</xref>) were highlighted in the PCA map. However, the observed activation of the hypothalamus and other neuromodulatory nuclei suggests that, in the anesthetized state, pupil diameter fluctuation reflects a complex interaction of subcortical homeostatic and brain state-modulating centers.</p><p>Also, we have shown that these subcortical interactions and the neural correlates of pupil dynamics are not stationary but change across trials in a brain state-dependent manner. Based on the correlation patterns, we identified four clusters of trials with distinct pupil–fMRI coupling. The clusters displayed a high degree of reproducibility when repeating the clustering procedure with all trials; however, the lower label match ratios of clusters 1 and 2 in half-split analyses (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>) should be considered. Our results demonstrate that pupil size changes can be modulated by different combinations of subcortical nuclei, indicating varied brain state fluctuations underlying different oscillatory patterns of pupil dynamics (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). This is further exemplified by examining the cluster-specific PCA prediction maps. The map of cluster 2 demonstrates the strongest coupling of pupil dynamics with the hypothalamus, which is known to drive pupil dilation (<xref ref-type="bibr" rid="bib66">Ranson and Magoun, 1933</xref>) and also highlights other brain state-regulating nuclei of the ARAS. It is possible that the hypothalamus was the key driver of brain state fluctuation in cluster 2 (<xref ref-type="bibr" rid="bib29">Grimaldi et al., 2014</xref>; <xref ref-type="bibr" rid="bib41">Lee and Dan, 2012</xref>). On the other hand, hypothalamic weights were least prevalent in cluster 1, which displayed strong pupil coupling with the dopaminergic system known to modulate pupil dynamics (<xref ref-type="bibr" rid="bib59">O’Doherty et al., 2003</xref>; <xref ref-type="bibr" rid="bib24">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib76">Shannon et al., 1976</xref>). Finally, in trials of cluster 4, the caudal raphe nucleus was the brainstem neuromodulatory nucleus whose activity had the strongest positive weighting to predict pupil fluctuations. Additionally, the subiculum weights were the strongest in cluster 4 out of all clusters. The positive coupling of the raphe and subiculum hints at the possibility of pupillometry reflecting the activity of circuits responsible for autonomous stress modulation (<xref ref-type="bibr" rid="bib44">Lowry, 2002</xref>). The PCA prediction maps identify key nuclei coupled with pupil dynamics at different states and also highlight the complexity of brain activation patterns responsible for autonomous and brain state regulation.</p><p>The presented results should be interpreted in light of employing anesthesia to acquire BOLD fMRI signals within the MRI scanner. Alpha-chloralose was employed due to the quality of BOLD fMRI responses under this anesthetic (<xref ref-type="bibr" rid="bib32">Hyder et al., 2016</xref>; <xref ref-type="bibr" rid="bib3">Alonso et al., 2011</xref>). The neural correlates of brain state-dependent pupil–fMRI correlation differences under alpha-chloralose anesthesia have previously been verified (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>). However, as alpha-chloralose has been reported to inhibit the sympathetic system’s responses (<xref ref-type="bibr" rid="bib28">Gaumann and Yaksh, 1990</xref>), its influence on pupil size and brain state changes should be investigated similarly to what has been done with other anesthetics. Previous studies report that the use of propofol dampened higher frequency pupil size changes observed in the awake state (<xref ref-type="bibr" rid="bib7">Behrends et al., 2019</xref>), and slow pupil diameter fluctuations were influenced by both isoflurane and urethane anesthesia (<xref ref-type="bibr" rid="bib37">Kum et al., 2016</xref>; <xref ref-type="bibr" rid="bib12">Blasiak et al., 2013</xref>). Furthermore, the brain state changes we observed across trials could be a typical feature of brain activity observed in unanesthetized human subjects e.g. due to arousal or sleep state changes (<xref ref-type="bibr" rid="bib1">Allen et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Kaufmann et al., 2006</xref>; <xref ref-type="bibr" rid="bib85">Tagliazucchi and Laufs, 2014</xref>) but could also be driven by the anesthetic, as in the case of urethane inducing sleep-like state changes (<xref ref-type="bibr" rid="bib12">Blasiak et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">Clement et al., 2008</xref>). Although the present study is based on the anesthetized rat model, it provides a framework that could be applied to analyze human datasets. Working with awake subjects would mitigate the potential impact of anesthesia on the activity of the sympathetic system, which controls pupillary movements in an antagonistic relationship with the parasympathetic system (<xref ref-type="bibr" rid="bib13">Bonvallet and Zbrozyna, 1963</xref>; <xref ref-type="bibr" rid="bib48">McDougal and Gamlin, 2015</xref>). Additionally, the cognitive component of brain activity reflected in pupil diameter changes of awake human subjects could be investigated using the PCA-based fMRI decoding method.</p><p>Further research should also be directed toward investigating the state-dependent coupling of pupil dynamics and brain activity at finer temporal scales. Importantly, assuming stationarity of the relationship at any scale could lead to oversimplification of the results, as already evidenced by our ability to differentiate four distinct pupil–fMRI coupling patterns instead of one common correlation map. Combining the analysis of individual fMRI frames (<xref ref-type="bibr" rid="bib42">Liu et al., 2013</xref>; <xref ref-type="bibr" rid="bib87">Tseng and Poppenk, 2020</xref>) with the phase of pupil diameter fluctuation, which is known to reflect the activity of different cortical neural populations (<xref ref-type="bibr" rid="bib67">Reimer et al., 2014</xref>), would demonstrate whole-brain activity patterns coupled with pupil dilation and constriction. Finally, regions like the subiculum, which previously have not been linked to pupil dynamics, but displayed strong coupling weights in our study, could guide future electrophysiological studies to reveal novel neuronal regulatory mechanisms underlying pupil dynamics.</p><sec id="s3-1"><title>Conclusion</title><p>We provided a framework to investigate the brain state-dependent relationship between pupil dynamics and fMRI. The pupil-related brain activity was decoupled from other signal sources based on PCA decomposition and the cluster-specific pupil–fMRI relationship was identified by integrating optimized PCA weighting features using decoding methods. Eventually, distinct subcortical activation patterns were revealed to highlight varied neuromodulatory nuclei corresponding to pupil dynamics.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animal preparation</title><p>All experimental procedures were approved by the Animal Protection Committee of Tübingen (Regierungsprasidium Tübingen; protocol KY12-14) and performed following the guidelines. Pupillometry and fMRI data acquired from 10 male Sprague Dawley rats had been previously published (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>). The rats were imaged under alpha-chloralose anesthesia. For details related to the experimental procedures, refer to <xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>.</p></sec><sec id="s4-2"><title>fMRI acquisition and preprocessing</title><p>All MRI measurements were performed on a 14.1 T/26 cm magnet (Magnex, Oxford) with an Avance III console (Bruker, Ettlingen) using an elliptic trans-receiver surface coil (~2 × 2.7 cm). To acquire functional data, a whole-brain 3D EPI sequence was used. The sequence parameters were as follows: 1 s TR, 12.5 ms TE, 48 × 48 × 32 matrix size, 400 × 400 × 600 µm resolution. Each run had a length of 925 TRs (15 min 25 s). The RARE sequence was used to acquire an anatomical image for each rat. The RARE parameters were as follows: 4 s TR, 9 ms TE, 128 × 128 matrix size, 32 slices, 150 µm in-plane resolution, 600 µm slice thickness, 8× RARE factor. The data from all rats were spatially co-registered. First, for each EPI run, all volumes were registered to the EPI mean. The EPI means were registered to corresponding anatomical images. To register all data to a common template, all RARE images were registered to a selected RARE image. The obtained registration matrices were then applied to the functional data. A temporal filter (0.002, 0.15 Hz) was applied to the co-registered data. The registration was performed using the AFNI software package (<xref ref-type="bibr" rid="bib21">Cox, 1996</xref>). Principal component analysis (PCA) implemented in the Python scikit-learn library (<xref ref-type="bibr" rid="bib64">Pedregosa, 2011</xref>) was used to reduce the dimensionality of fMRI data for prediction purposes. The PCA time courses were variance normalized before the optimization of linear regression and GRU weights. The functional and anatomical data are available online (<xref ref-type="bibr" rid="bib82">Sobczak et al., 2021b</xref>).</p></sec><sec id="s4-3"><title>Pupillometry acquisition and pupil diameter extraction</title><p>For each fMRI scan, a video with the following parameters was recorded: 24 bits per pixel, 240 × 352 pixels, 29.97 frames/s, RGB24 format. A customized MRI-compatible camera was used. For details related to the setup, refer to <xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>. The DeepLabCut toolbox (<xref ref-type="bibr" rid="bib46">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib57">Nath, 2018</xref>) was used to extract the pupil position from each video frame. The toolbox’s artificial neural network was optimized using 1330 manually labeled images extracted from 74 eye monitoring videos. Training frames were selected using an automated clustering-based DeepLabCut procedure. Four pupil edge points were manually labeled in each training image. Using the trained network, the four points were located in each recorded frame and their coordinates were used to calculate the pupil diameter as follows:<disp-formula id="equ1"><mml:math id="m1"><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msqrt><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>+</mml:mo><mml:msqrt><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>Simultaneously, in each video, the eye size was calculated based on manual landmark identification. The eye size was then used to normalize the pupil size, such that pupil diameter values were limited to the &lt;0, 1&gt; range. The pupil diameter signals were averaged over 1 s windows to match the fMRI temporal resolution while reducing noise. Pupillometry time courses were variance normalized before the optimization of linear regression and GRU weights. The time courses are available online (<xref ref-type="bibr" rid="bib82">Sobczak et al., 2021b</xref>).</p></sec><sec id="s4-4"><title>Hemodynamic response function convolution</title><p>Pupil signals were convolved with HRF kernels with varied peak times to investigate the influence of correcting for the lag between pupil and fMRI signals. The following equation, involving a positive component for the positive response and a negative one for the undershoot, was used to generate the kernels:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mn>0.3</mml:mn><mml:mfrac><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>12</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf1"><mml:mi>a</mml:mi></mml:math></inline-formula> is a parameter controlling the peak time, and Γ is the gamma function. HRFs with peaks in the &lt;0; 5&gt; s range were used.</p></sec><sec id="s4-5"><title>UMAP dimensionality reduction</title><p>The uniform manifold approximation and projection (UMAP) (<xref ref-type="bibr" rid="bib50">McInnes et al., 2020</xref>) algorithm was employed to reduce the dimensionality of pupil–fMRI correlation maps before clustering. We used the Python implementation of the algorithm provided by the authors of the method. First, UMAP finds a k-nearest neighbor graph. Based on silhouette scores we set k = 7. To facilitate clustering, we set the minimum allowed distance between points on the low dimensional manifold to 0. We projected the data from the voxel space (n = 20,804) to a 72-dimensional representation, as this was the highest number of dimensions the method permitted given 74 input trials.</p></sec><sec id="s4-6"><title>Gaussian mixture model clustering</title><p>To cluster the trials in the low dimensional space resulting from the UMAP embedding, we used the expectation-maximization algorithm fitting mixture of Gaussians models to the data (<xref ref-type="bibr" rid="bib51">McLachlan and Basford, 1988</xref>). We used the Python implementation from the scikit-learn library (<xref ref-type="bibr" rid="bib64">Pedregosa, 2011</xref>) with default parameters.</p></sec><sec id="s4-7"><title>Silhouette analysis – cluster number verification</title><p>To find the number of clusters for successive analyses, we evaluated clustering results using silhouette analysis (<xref ref-type="bibr" rid="bib70">Rousseeuw, 1987</xref>) implemented in the Python scikit-learn library (<xref ref-type="bibr" rid="bib64">Pedregosa, 2011</xref>). For each point, the method computes a silhouette score which evaluates how similar it is to points in its cluster versus points in other clusters. The clustering of the entire dataset was evaluated by computing the mean silhouette score across all points. The clustering result with the highest mean silhouette score was selected for successive analyses.</p></sec><sec id="s4-8"><title>Cluster reproducibility</title><p>The cluster membership label of each trial was specified based on 100 repetitions of UMAP dimensionality reduction and GMM clustering applied to all trials. We found the final cluster labels by identifying which trials clustered together most often. These final labels were used to create cluster-specific correlation maps. Both the labels and maps were compared with those generated in following analyses to evaluate cluster reproducibility. In particular, we compared label match ratios and cluster map similarities (spatial correlations). We generated alternative clustering results based on: half-split analysis (randomly dividing the 74 trials into groups of 37), using HRF-convolved pupil signals, temporally splitting the data into more trials with shorter durations, and employing spatial surrogates with properties matching those of real maps. We repeated each analysis 100 times and compared results with the initial clustering.</p></sec><sec id="s4-9"><title>Surrogate map generation</title><p>Surrogate maps were created using the Brainsmash toolbox (<xref ref-type="bibr" rid="bib15">Burt et al., 2020</xref>). For each correlation map, we generated 100 artificial surrogates that had the same values and spatial autocorrelation as the real map but different spatial patterns. By showing that clustering results based on surrogates were different, we verified that our clustering was not dependent on, e.g., mean map values but on the spatial patterns and regions highlighted in the maps.</p></sec><sec id="s4-10"><title>Power spectral density estimation</title><p>The spectral analysis was performed using the Python SciPy library (<xref ref-type="bibr" rid="bib89">Virtanen et al., 2020</xref>). To compute the PSDs of utilized signals, we employed Welch’s method (<xref ref-type="bibr" rid="bib92">Welch, 1967</xref>), with the following parameters: 512 discrete Fourier transform points; Hann window; 50% overlap.</p></sec><sec id="s4-11"><title>Correlation map-based prediction</title><p>Following a strategy described in previous studies (<xref ref-type="bibr" rid="bib60">Pais-Roldán et al., 2020</xref>; <xref ref-type="bibr" rid="bib17">Chang et al., 2016</xref>) we used a pupil–fMRI correlation map to predict pupillometry time courses given fMRI input data. To create the correlation map, pupillometry and fMRI data were concatenated across all trials and the pupil diameter fluctuation signal was correlated with each voxel’s signal. This generated a 3D volume (the correlation map), which was then spatially correlated with each individual fMRI volume yielding a single predicted value for each time point. As the resulting time courses’ amplitudes were bounded to the &lt;−1; 1&gt; range and not informative of the target signals amplitudes, Pearson’s correlation coefficient was used to evaluate the quality of the predictions on a trial-by-trial basis.</p></sec><sec id="s4-12"><title>Linear regression variants</title><p>Linear regression was used to predict pupillometry data given fMRI-PCA inputs. Four linear regression variants were available to a Bayesian optimizer, which selected both the linear model type and its parameters. The available variants were ordinary least squares, Ridge, Lasso and elastic-net regression models. Python scikit-learn library (<xref ref-type="bibr" rid="bib64">Pedregosa, 2011</xref>) implementations were used. L2 Ridge regression with a regularization parameter <inline-formula><mml:math id="inf2"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>19861</mml:mn></mml:math></inline-formula> obtained the best prediction scores and was found using the Hyperopt toolbox (<xref ref-type="bibr" rid="bib10">Bergstra, 2011</xref>; <xref ref-type="bibr" rid="bib11">Bergstra et al., 2013</xref>).</p></sec><sec id="s4-13"><title>GRU</title><p>The second model employed for pupillometry decoding was the gated recurrent unit (GRU) (<xref ref-type="bibr" rid="bib18">Cho, 2014</xref>) artificial neural network. The GRU is a recurrent neural network, which encodes each element of the input fMRI-PCA sequence <inline-formula><mml:math id="inf3"><mml:mi>x</mml:mi></mml:math></inline-formula> into a hidden state vector <inline-formula><mml:math id="inf4"><mml:mi>h</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> through the following computations:<disp-formula id="equ3"><mml:math id="m3"><mml:mi>r</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>h</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></disp-formula><disp-formula id="equ4"><mml:math id="m4"><mml:mi>z</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mi>h</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></disp-formula><disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⊙</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf5"><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> are the reset, update, and new gates, <inline-formula><mml:math id="inf6"><mml:mi>W</mml:mi></mml:math></inline-formula> are matrices connecting the inputs, gates, and hidden states, <inline-formula><mml:math id="inf7"><mml:mi>σ</mml:mi><mml:mfenced separators="|"><mml:mrow/></mml:mfenced></mml:math></inline-formula> and <inline-formula><mml:math id="inf8"><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced separators="|"><mml:mrow/></mml:mfenced></mml:math></inline-formula> are the sigmoid and hyperbolic tangent functions, <inline-formula><mml:math id="inf9"><mml:mi>b</mml:mi></mml:math></inline-formula> are bias vectors, and ⨀ is the elementwise product. A linear decoder generated predictions based on the hidden state vector:<disp-formula id="equ7">.<mml:math id="m7"><mml:mi>y</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>h</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>The correlation coefficient was used as the loss function. The networks were trained in PyTorch (<xref ref-type="bibr" rid="bib62">Paszke, 2019</xref>) using the Adam optimizer (<xref ref-type="bibr" rid="bib36">Kingma and Ba, 2017</xref>). Hyperparameters were found using Bayesian optimization using the tree of Parzen estimators algorithm (Hyperopt toolbox, n = 200) (<xref ref-type="bibr" rid="bib10">Bergstra, 2011</xref>; <xref ref-type="bibr" rid="bib11">Bergstra et al., 2013</xref>). The optimized hyperparameters have been described in <xref ref-type="table" rid="table1">Table 1</xref>. Early stopping was used in the Bayesian optimization procedure. To set the final number of training epochs for the best network, cross-validation was repeated and the GRU was trained for 100 epochs on each split. Training for seven epochs yielded the best performance.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Optimized GRU hyperparameters.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter name</th><th align="left" valign="bottom">Description</th><th align="left" valign="bottom">Range</th><th align="left" valign="bottom">Final value</th></tr></thead><tbody><tr><td align="left" valign="middle">Number of layers</td><td align="left" valign="bottom">Multiple recurrent layers could be stacked on top of each other.</td><td align="left" valign="bottom">[1; 3]</td><td align="left" valign="bottom">1</td></tr><tr><td align="left" valign="middle">Hidden size</td><td align="left" valign="bottom">Hidden state vector size.</td><td align="left" valign="bottom">[10; 500]</td><td align="left" valign="bottom">300</td></tr><tr><td align="left" valign="middle">Learning rate</td><td align="left" valign="bottom">The rate at which network weights were updated during training.</td><td align="left" valign="bottom">[10<sup>–6</sup>; 1]</td><td align="left" valign="bottom">0.0023</td></tr><tr><td align="left" valign="middle">L2</td><td align="left" valign="bottom">Strength of the L2 weight regularization.</td><td align="left" valign="bottom">[0; 10]</td><td align="left" valign="bottom">0.0052</td></tr><tr><td align="left" valign="middle">Gradient clipping</td><td align="left" valign="bottom">Gradient clipping (<xref ref-type="bibr" rid="bib61">Pascanu et al., 2013</xref>) limits the gradient magnitude at a specified maximum value.</td><td align="left" valign="bottom">[yes; no]</td><td align="left" valign="bottom">Yes</td></tr><tr><td align="left" valign="middle">Max. gradient</td><td align="left" valign="bottom">Value at which the gradients are clipped.</td><td align="left" valign="bottom">[0.1, 2]</td><td align="left" valign="bottom">1</td></tr><tr><td align="left" valign="middle">Dropout</td><td align="left" valign="bottom">During training, a percentage of units could be set to 0 for regularization purposes (<xref ref-type="bibr" rid="bib83">Srivastava et al., 2014</xref>).</td><td align="left" valign="bottom">[0; 0.2]</td><td align="left" valign="bottom">0</td></tr><tr><td align="left" valign="middle">Residual connection</td><td align="left" valign="bottom">Feeding the input directly to the linear decoder bypassing the RNN’s computation.</td><td align="left" valign="bottom">[yes; no]</td><td align="left" valign="bottom">No</td></tr><tr><td align="left" valign="middle">Batch size</td><td align="left" valign="bottom">The number of training trials fed into the network before each weight update.</td><td align="left" valign="bottom">[3; 20]</td><td align="left" valign="bottom">12</td></tr></tbody></table></table-wrap></sec><sec id="s4-14"><title>Cross-validation</title><p>The available 74 trials were divided into training (n = 64) and test (n = 10) sets. Linear regression and GRU parameters were found based on the training set with fourfold cross-validation. The final performance was evaluated on the test set. Scores of the correlation-template-based prediction were based on the same data splits.</p></sec><sec id="s4-15"><title>Spatial map – linear regression</title><p>To create spatial maps highlighting areas that contributed to linear regression predictions, we weighted PCA component maps by their associated linear regression weights, summed them, and took their means. Region borders from the rat brain atlas (<xref ref-type="bibr" rid="bib63">Paxinos and Watson, 2006</xref>) were matched to and overlaid on spatial map slices.</p></sec><sec id="s4-16"><title>Spatial map – GRU</title><p>To create spatial maps highlighting areas that contributed to GRU predictions, we computed gradients of each of the predicted time points with respect to the 300 input features. We then averaged the gradients across all time points for each of the features and used these mean values just like the weights in the case of linear regression map generation.</p></sec><sec id="s4-17"><title>Variance explained</title><p>We obtained the fMRI variance explained by each PCA component directly from the scikit-learn (<xref ref-type="bibr" rid="bib64">Pedregosa, 2011</xref>) PCA model. To compute the pupil variance explained by each of the PCA time courses, we used an approach described in <xref ref-type="bibr" rid="bib54">Musall et al., 2019</xref> with fourfold cross-validation. The explained variance of each component was found by randomly shuffling the time points of all other components, training the Ridge linear regression model (<inline-formula><mml:math id="inf10"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>19861</mml:mn></mml:math></inline-formula>) on shuffled data and assessing the explained variance based on generated predictions.</p></sec><sec id="s4-18"><title>Statistical tests – prediction</title><p>We used a paired t-test to compare the prediction scores across methods.</p></sec><sec id="s4-19"><title>Statistical tests – linear regression spatial maps</title><p>To test which linear regression spatial map values significantly contributed to the predictions, we used randomization tests. For each cluster, we shuffled the input and output pairings 10,000 times, trained a linear model, and created a spatial map for each of those pairings. We then compared the values in the original maps with the shuffled ones. Values that were at least as extreme as the shuffled values at the 0.005 positive or negative percentile (p=0.01) were considered significant. The results were controlled for false discovery rate with adjustment (<xref ref-type="bibr" rid="bib9">Benjamini and Hochberg, 1995</xref>; <xref ref-type="bibr" rid="bib94">Yekutieli and Benjamini, 1997</xref>).</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>None</p></fn><fn fn-type="COI-statement" id="conf2"><p>none</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Software, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Project administration, Resources, Supervision, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experimental procedures were approved by the Animal Protection Committee of Tübingen (Regierungsprasidium Tübingen; protocol KY12-14) and performed following the guidelines. The rats were imaged under alpha-chloralose anesthesia.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-68980-transrepform1-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All fMRI datasets, as well as the synchronized pupil-size vectors, reported in this paper have been deposited in Zenodo at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/4670277">https://zenodo.org/record/4670277</ext-link> (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4670277">https://doi.org/10.5281/zenodo.4670277</ext-link>). Source data for all figures have been uploaded in the system.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Pais-Roldán</surname><given-names>P</given-names></name><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Sobczak</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Zhao</surname><given-names>X</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Raw data for &quot;Indexing brain state-dependent pupil dynamics with simultaneous fMRI and optical fiber calcium recording&quot;</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.3677525</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Dr. R Pohmann and Dr. K Buckenmaier for technical support; Dr. E Weiler, Dr. P Douay, Mrs. R König, Ms. S Fischer, Ms. H Schulz, and Dr. Jörn Engelmann for animal/lab maintenance and support; and the Analysis of Functional NeuroImages (AFNI) team for software support. Funding: This research was supported by internal funding from Max Planck Society, NIH Brain Initiative funding (RF1NS113278–01, R01MH111438–01) and shared instrument grant (S10 MH124733-01), German Research Foundation (DFG) YU215/2-1 and Yu215/3–1, BMBF 01GQ1702.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>EA</given-names></name><name><surname>Damaraju</surname><given-names>E</given-names></name><name><surname>Plis</surname><given-names>SM</given-names></name><name><surname>Erhardt</surname><given-names>EB</given-names></name><name><surname>Eichele</surname><given-names>T</given-names></name><name><surname>Calhoun</surname><given-names>VD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Tracking whole-brain connectivity dynamics in the resting state</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>663</fpage><lpage>676</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs352</pub-id><pub-id pub-id-type="pmid">23146964</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alnæs</surname><given-names>D</given-names></name><name><surname>Sneve</surname><given-names>MH</given-names></name><name><surname>Espeseth</surname><given-names>T</given-names></name><name><surname>Endestad</surname><given-names>T</given-names></name><name><surname>van de Pavert</surname><given-names>SHP</given-names></name><name><surname>Laeng</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil size signals mental effort deployed during multiple object tracking and predicts brain activity in the dorsal attention network and the locus coeruleus</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>1</elocation-id><pub-id pub-id-type="doi">10.1167/14.4.1</pub-id><pub-id pub-id-type="pmid">24692319</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alonso</surname><given-names>B</given-names></name><name><surname>Makarova</surname><given-names>T</given-names></name><name><surname>Hess</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>On the use of α-chloralose for repeated bold FMRI measurements in rats</article-title><source>Journal of Neuroscience Methods</source><volume>195</volume><fpage>236</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.12.010</pub-id><pub-id pub-id-type="pmid">21163302</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An integrative theory of locus coeruleus-norepinephrine function: Adaptive gain and optimal performance</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Beatty</surname><given-names>J</given-names></name><name><surname>Lucero-Wagoner</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>The Pupillary System. Handbook of Psychophysiology</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beckstead</surname><given-names>RM</given-names></name><name><surname>Domesick</surname><given-names>VB</given-names></name><name><surname>Nauta</surname><given-names>WJH</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Efferent connections of the substantia nigra and ventral tegmental area in the rat</article-title><source>Brain Research</source><volume>175</volume><fpage>191</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(79)91001-1</pub-id><pub-id pub-id-type="pmid">314832</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrends</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>MD</given-names></name><name><surname>Neice</surname><given-names>AE</given-names></name><name><surname>Bokoch</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Suppression of pupillary unrest by general anesthesia and propofol sedation</article-title><source>Journal of Clinical Monitoring and Computing</source><volume>33</volume><fpage>317</fpage><lpage>323</lpage><pub-id pub-id-type="doi">10.1007/s10877-018-0147-y</pub-id><pub-id pub-id-type="pmid">29785552</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benarroch</surname><given-names>EE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Brainstem integration of arousal, sleep, cardiovascular, and respiratory control</article-title><source>Neurology</source><volume>91</volume><fpage>958</fpage><lpage>966</lpage><pub-id pub-id-type="doi">10.1212/WNL.0000000000006537</pub-id><pub-id pub-id-type="pmid">30355703</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Controlling the false discovery rate: A practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society. Series B</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bergstra</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><conf-name>Nips’11: Proceedings of the 24th International Conference on neural information processing systems</conf-name><article-title>Algorithms for hyper-parameter optimization</article-title><fpage>2546</fpage><lpage>2554</lpage></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bergstra</surname><given-names>J</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name><name><surname>Cox</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2013">2013</year><conf-name>Proceedings of the 30th International Conference on International Conference on Machine Learning</conf-name><article-title>Making a science of model search</article-title></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blasiak</surname><given-names>T</given-names></name><name><surname>Zawadzki</surname><given-names>A</given-names></name><name><surname>Lewandowski</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Infra-slow oscillation (ISO) of the pupil size of urethane-anaesthetised rats</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e62430</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0062430</pub-id><pub-id pub-id-type="pmid">23638082</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonvallet</surname><given-names>M</given-names></name><name><surname>Zbrozyna</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Les commandes Réticulaires du Système Autonome et En particulier de l’innervation Sympathique et Parasympathique de la Pupille</article-title><source>Archives Italiennes de Biologie</source><volume>101</volume><fpage>174</fpage><lpage>207</lpage></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breton-Provencher</surname><given-names>V</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Active control of arousal by a locus coeruleus gabaergic circuit</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>218</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0305-z</pub-id><pub-id pub-id-type="pmid">30643295</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burt</surname><given-names>JB</given-names></name><name><surname>Helmer</surname><given-names>M</given-names></name><name><surname>Shinn</surname><given-names>M</given-names></name><name><surname>Anticevic</surname><given-names>A</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Generative modeling of brain maps with spatial autocorrelation</article-title><source>NeuroImage</source><volume>220</volume><elocation-id>S1053-8119(20)30524-3</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117038</pub-id><pub-id pub-id-type="pmid">32585343</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carbonell</surname><given-names>F</given-names></name><name><surname>Bellec</surname><given-names>P</given-names></name><name><surname>Shmuel</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Global and system-specific resting-state fmri fluctuations are uncorrelated: Principal component analysis reveals anti-correlated networks</article-title><source>Brain Connectivity</source><volume>1</volume><fpage>496</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1089/brain.2011.0065</pub-id><pub-id pub-id-type="pmid">22444074</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Schölvinck</surname><given-names>ML</given-names></name><name><surname>Mandelkow</surname><given-names>H</given-names></name><name><surname>Picchioni</surname><given-names>D</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Turchi</surname><given-names>JN</given-names></name><name><surname>Duyn</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Tracking brain arousal fluctuations with FMRI</article-title><source>PNAS</source><volume>113</volume><fpage>4518</fpage><lpage>4523</lpage><pub-id pub-id-type="doi">10.1073/pnas.1520613113</pub-id><pub-id pub-id-type="pmid">27051064</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Learning Phrase Representations Using RNN Encoder–Decoder for Statistical Machine Translation</source><publisher-name>Association for Computational Linguistics</publisher-name></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clement</surname><given-names>EA</given-names></name><name><surname>Richard</surname><given-names>A</given-names></name><name><surname>Thwaites</surname><given-names>M</given-names></name><name><surname>Ailon</surname><given-names>J</given-names></name><name><surname>Peters</surname><given-names>S</given-names></name><name><surname>Dickson</surname><given-names>CT</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cyclic and sleep-like spontaneous alternations of brain state under urethane anaesthesia</article-title><source>PLOS ONE</source><volume>3</volume><elocation-id>e2004</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0002004</pub-id><pub-id pub-id-type="pmid">18414674</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clewett</surname><given-names>DV</given-names></name><name><surname>Huang</surname><given-names>R</given-names></name><name><surname>Velasco</surname><given-names>R</given-names></name><name><surname>Lee</surname><given-names>TH</given-names></name><name><surname>Mather</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Locus coeruleus activity strengthens prioritized memories under arousal</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>1558</fpage><lpage>1574</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2097-17.2017</pub-id><pub-id pub-id-type="pmid">29301874</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>AFNI: Software for analysis and visualization of functional magnetic resonance neuroimages</article-title><source>Computers and Biomedical Research, an International Journal</source><volume>29</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><pub-id pub-id-type="pmid">8812068</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dampney</surname><given-names>RAL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Central neural control of the cardiovascular system: Current perspectives</article-title><source>Advances in Physiology Education</source><volume>40</volume><fpage>283</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1152/advan.00027.2016</pub-id><pub-id pub-id-type="pmid">27445275</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decision-related pupil dilation reflects upcoming choice and individual bias</article-title><source>PNAS</source><volume>111</volume><elocation-id>E618</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.1317557111</pub-id><pub-id pub-id-type="pmid">24449874</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic modulation of decision biases by brainstem arousal systems</article-title><source>eLife</source><volume>6</volume><elocation-id>e23232</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23232</pub-id><pub-id pub-id-type="pmid">28383284</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Olmos</surname><given-names>JS</given-names></name><name><surname>Ingram</surname><given-names>WR</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>The projection field of the stria terminalis in the rat brain. An experimental study</article-title><source>The Journal of Comparative Neurology</source><volume>146</volume><fpage>303</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1002/cne.901460303</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duyn</surname><given-names>JH</given-names></name><name><surname>Ozbay</surname><given-names>PS</given-names></name><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Picchioni</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Physiological changes in sleep that affect fmri inference</article-title><source>Current Opinion in Behavioral Sciences</source><volume>33</volume><fpage>42</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2019.12.007</pub-id><pub-id pub-id-type="pmid">32613032</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Guerra-Carrillo</surname><given-names>B</given-names></name><name><surname>Miller Singley</surname><given-names>AT</given-names></name><name><surname>Bunge</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Beyond eye gaze: What else can eyetracking reveal about cognition and cognitive development?</article-title><source>Developmental Cognitive Neuroscience</source><volume>25</volume><fpage>69</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2016.11.001</pub-id><pub-id pub-id-type="pmid">27908561</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaumann</surname><given-names>DM</given-names></name><name><surname>Yaksh</surname><given-names>TL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Alpha-chloralose anesthesia inhibits the somato-sympathetic reflex response in cats more effectively than halothane</article-title><source>Zentralblatt Fur Veterinarmedizin. Reihe A</source><volume>37</volume><fpage>669</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1111/j.1439-0442.1990.tb00960.x</pub-id><pub-id pub-id-type="pmid">2127972</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grimaldi</surname><given-names>D</given-names></name><name><surname>Silvani</surname><given-names>A</given-names></name><name><surname>Benarroch</surname><given-names>EE</given-names></name><name><surname>Cortelli</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Orexin/hypocretin system and autonomic control: New insights and clinical correlations</article-title><source>Neurology</source><volume>82</volume><fpage>271</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1212/WNL.0000000000000045</pub-id><pub-id pub-id-type="pmid">24363130</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hakerem</surname><given-names>GAD</given-names></name><name><surname>Sutton</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Pupillary response at visual threshold</article-title><source>Nature</source><volume>212</volume><fpage>485</fpage><lpage>486</lpage><pub-id pub-id-type="doi">10.1038/212485a0</pub-id><pub-id pub-id-type="pmid">5970183</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hess</surname><given-names>EH</given-names></name><name><surname>Polt</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Pupil size in relation to mental activity during simple problem-solving</article-title><source>Science</source><volume>143</volume><fpage>1190</fpage><lpage>1192</lpage><pub-id pub-id-type="doi">10.1126/science.143.3611.1190</pub-id><pub-id pub-id-type="pmid">17833905</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyder</surname><given-names>F</given-names></name><name><surname>Behar</surname><given-names>KL</given-names></name><name><surname>Martin</surname><given-names>MA</given-names></name><name><surname>Blamire</surname><given-names>AM</given-names></name><name><surname>Shulman</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dynamic magnetic resonance imaging of the rat brain during forepaw stimulation</article-title><source>Journal of Cerebral Blood Flow &amp; Metabolism</source><volume>14</volume><fpage>649</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1038/jcbfm.1994.81</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kahneman</surname><given-names>D</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Pupil diameter and load on memory</article-title><source>Science</source><volume>154</volume><fpage>1583</fpage><lpage>1585</lpage><pub-id pub-id-type="doi">10.1126/science.154.3756.1583</pub-id><pub-id pub-id-type="pmid">5924930</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>C</given-names></name><name><surname>Wehrle</surname><given-names>R</given-names></name><name><surname>Wetter</surname><given-names>TC</given-names></name><name><surname>Holsboer</surname><given-names>F</given-names></name><name><surname>Auer</surname><given-names>DP</given-names></name><name><surname>Pollmächer</surname><given-names>T</given-names></name><name><surname>Czisch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Brain activation and hypothalamic functional connectivity during human non-rapid eye movement sleep: An EEG/FMRI study</article-title><source>Brain</source><volume>129</volume><fpage>655</fpage><lpage>667</lpage><pub-id pub-id-type="doi">10.1093/brain/awh686</pub-id><pub-id pub-id-type="pmid">16339798</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name><name><surname>Ba</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Adam: A Method for Stochastic Optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kum</surname><given-names>JE</given-names></name><name><surname>Han</surname><given-names>HB</given-names></name><name><surname>Choi</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil size in relation to cortical states during isoflurane anesthesia</article-title><source>Experimental Neurobiology</source><volume>25</volume><fpage>86</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.5607/en.2016.25.2.86</pub-id><pub-id pub-id-type="pmid">27122995</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuwaki</surname><given-names>T</given-names></name><name><surname>Zhang</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Orexin neurons as arousal-associated modulators of central cardiorespiratory regulation</article-title><source>Respiratory Physiology &amp; Neurobiology</source><volume>174</volume><fpage>43</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.resp.2010.04.018</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Laeng</surname><given-names>B</given-names></name><name><surname>Sirois</surname><given-names>S</given-names></name><name><surname>Gredebäck</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Pupillometry: A Window to the Preconscious</source><publisher-name>Perspectives on Psychological Science</publisher-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lecrux</surname><given-names>C</given-names></name><name><surname>Hamel</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neuronal networks and mediators of cortical neurovascular coupling responses in normal and altered brain states</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>371</volume><elocation-id>20150350</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2015.0350</pub-id><pub-id pub-id-type="pmid">27574304</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuromodulation of brain states</article-title><source>Neuron</source><volume>76</volume><fpage>209</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.012</pub-id><pub-id pub-id-type="pmid">23040816</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Chang</surname><given-names>C</given-names></name><name><surname>Duyn</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Decomposition of spontaneous brain activity into distinct FMRI co-activation patterns</article-title><source>Frontiers in Systems Neuroscience</source><volume>7</volume><elocation-id>101</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2013.00101</pub-id><pub-id pub-id-type="pmid">24550788</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lowenstein</surname><given-names>O</given-names></name><name><surname>Feinberg</surname><given-names>R</given-names></name><name><surname>Loewenfeld</surname><given-names>IE</given-names></name></person-group><year iso-8601-date="1963">1963</year><article-title>Pupillary movements during acute and chronic fatigue: A new test for the objective evaluation of tiredness</article-title><source>Investigative Ophthalmology &amp; Visual Science</source><volume>2</volume><fpage>138</fpage><lpage>157</lpage></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lowry</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Functional subsets of serotonergic neurones: Implications for control of the hypothalamic-pituitary-adrenal axis</article-title><source>Journal of Neuroendocrinology</source><volume>14</volume><fpage>911</fpage><lpage>923</lpage><pub-id pub-id-type="doi">10.1046/j.1365-2826.2002.00861.x</pub-id><pub-id pub-id-type="pmid">12421345</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mäki-Marttunen</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil-Based States of Brain Integration across Cognitive States</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.12.15.422870</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Deeplabcut: Markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Nestvogel</surname><given-names>DB</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neuromodulation of brain state and behavior</article-title><source>Annual Review of Neuroscience</source><volume>43</volume><fpage>391</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-100219-105424</pub-id><pub-id pub-id-type="pmid">32250724</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDougal</surname><given-names>DH</given-names></name><name><surname>Gamlin</surname><given-names>PD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Autonomic control of the eye</article-title><source>Comprehensive Physiology</source><volume>5</volume><fpage>439</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1002/cphy.c140014</pub-id><pub-id pub-id-type="pmid">25589275</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>David</surname><given-names>SV</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title><source>Neuron</source><volume>87</volume><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.038</pub-id><pub-id pub-id-type="pmid">26074005</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>McInnes</surname><given-names>L</given-names></name><name><surname>Healy</surname><given-names>J</given-names></name><name><surname>Melville</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1802.03426">https://arxiv.org/abs/1802.03426</ext-link></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLachlan</surname><given-names>GJ</given-names></name><name><surname>Basford</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Mixture models: Inference and applications to clustering</article-title><source>Applied Statistics</source><volume>38</volume><elocation-id>2348072</elocation-id><pub-id pub-id-type="doi">10.2307/2348072</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaren</surname><given-names>JW</given-names></name><name><surname>Erie</surname><given-names>JC</given-names></name><name><surname>Brubaker</surname><given-names>RF</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Computerized analysis of pupillograms in studies of alertness</article-title><source>Investigative Ophthalmology &amp; Visual Science</source><volume>33</volume><fpage>671</fpage><lpage>676</lpage></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>O’Connell</surname><given-names>RG</given-names></name><name><surname>O’Sullivan</surname><given-names>M</given-names></name><name><surname>Robertson</surname><given-names>IH</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil diameter covaries with bold activity in human locus coeruleus</article-title><source>Human Brain Mapping</source><volume>35</volume><fpage>4140</fpage><lpage>4154</lpage><pub-id pub-id-type="doi">10.1002/hbm.22466</pub-id><pub-id pub-id-type="pmid">24510607</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mwangi</surname><given-names>B</given-names></name><name><surname>Tian</surname><given-names>TS</given-names></name><name><surname>Soares</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A review of feature reduction techniques in neuroimaging</article-title><source>Neuroinformatics</source><volume>12</volume><fpage>229</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1007/s12021-013-9204-3</pub-id><pub-id pub-id-type="pmid">24013948</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nath</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Using Deeplabcut for 3d Markerless Pose Estimation across Species and Behaviors</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/476531</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Özbay</surname><given-names>PS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sympathetic activity contributes to the FMRI signal</article-title><source>Communications Biology</source><volume>2</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/s42003-019-0659-0</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Critchley</surname><given-names>H</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Temporal difference models and reward-related learning in the human brain</article-title><source>Neuron</source><volume>38</volume><fpage>329</fpage><lpage>337</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(03)00169-7</pub-id><pub-id pub-id-type="pmid">12718865</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pais-Roldán</surname><given-names>P</given-names></name><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Sobczak</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Zhao</surname><given-names>X</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Indexing brain state-dependent pupil dynamics with simultaneous FMRI and optical fiber calcium recording</article-title><source>PNAS</source><volume>117</volume><fpage>6875</fpage><lpage>6882</lpage><pub-id pub-id-type="doi">10.1073/pnas.1909937117</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Mikolov</surname><given-names>T</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><conf-name>On the difficulty of training recurrent neural networks</conf-name><article-title>proceedings of the 30th international conference on international conference on machine learning</article-title></element-citation></ref><ref id="bib62"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Pytorch: An Imperative Style</source><publisher-name>High-Performance Deep Learning Library.8024--8035</publisher-name></element-citation></ref><ref id="bib63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paxinos</surname><given-names>G</given-names></name><name><surname>Watson</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>The Rat Brain in Stereotaxic Coordinates</source><publisher-name>Hard Cover Edition (Elsevier</publisher-name></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: Machine Learning in Python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib65"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rajkowski</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1993">1993</year><source>Correlations between Locus Coeruleus (LC) Neural Activity, Pupil Diameter and Behavior in Monkey Support a Role of LC in Attention</source><publisher-name>Soc. Neurosc., Abstract</publisher-name></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranson</surname><given-names>SW</given-names></name><name><surname>Magoun</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1933">1933</year><article-title>Respiratory and pupillary reactions: Induced by electrical stimulation of the hypothalamus</article-title><source>Journal of Nervous and Mental Disease</source><volume>29</volume><fpage>1179</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1192/BJP.80.328.128-B</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Cadwell</surname><given-names>CR</given-names></name><name><surname>Yatsenko</surname><given-names>D</given-names></name><name><surname>Denfield</surname><given-names>GH</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pupil fluctuations track fast switching of cortical states during quiet wakefulness</article-title><source>Neuron</source><volume>84</volume><fpage>355</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.09.033</pub-id><pub-id pub-id-type="pmid">25374359</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Rodenkirch</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13289</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id><pub-id pub-id-type="pmid">27824036</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richer</surname><given-names>F</given-names></name><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Contrasting effects of response uncertainty on the task-evoked pupillary response and reaction time</article-title><source>Psychophysiology</source><volume>24</volume><fpage>258</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1987.tb00291.x</pub-id><pub-id pub-id-type="pmid">3602280</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rousseeuw</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</article-title><source>Journal of Computational and Applied Mathematics</source><volume>20</volume><fpage>53</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1016/0377-0427(87)90125-7</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salkoff</surname><given-names>DB</given-names></name><name><surname>Zagha</surname><given-names>E</given-names></name><name><surname>McCarthy</surname><given-names>E</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Movement and performance explain widespread cortical activity in a visual detection task</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>421</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz206</pub-id><pub-id pub-id-type="pmid">31711133</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satterthwaite</surname><given-names>TD</given-names></name><name><surname>Green</surname><given-names>L</given-names></name><name><surname>Myerson</surname><given-names>J</given-names></name><name><surname>Parker</surname><given-names>J</given-names></name><name><surname>Ramaratnam</surname><given-names>M</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dissociable but inter-related systems of cognitive control and reward during decision making: Evidence from pupillometry and event-related FMRI</article-title><source>NeuroImage</source><volume>37</volume><fpage>1017</fpage><lpage>1031</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.066</pub-id><pub-id pub-id-type="pmid">17632014</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmid</surname><given-names>Y</given-names></name><name><surname>Enzler</surname><given-names>F</given-names></name><name><surname>Gasser</surname><given-names>P</given-names></name><name><surname>Grouzmann</surname><given-names>E</given-names></name><name><surname>Preller</surname><given-names>KH</given-names></name><name><surname>Vollenweider</surname><given-names>FX</given-names></name><name><surname>Brenneisen</surname><given-names>R</given-names></name><name><surname>Müller</surname><given-names>F</given-names></name><name><surname>Borgwardt</surname><given-names>S</given-names></name><name><surname>Liechti</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Acute effects of lysergic acid diethylamide in healthy subjects</article-title><source>Biological Psychiatry</source><volume>78</volume><fpage>544</fpage><lpage>553</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2014.11.015</pub-id><pub-id pub-id-type="pmid">25575620</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>M</given-names></name><name><surname>Hathway</surname><given-names>P</given-names></name><name><surname>Leuchs</surname><given-names>L</given-names></name><name><surname>Sämann</surname><given-names>PG</given-names></name><name><surname>Czisch</surname><given-names>M</given-names></name><name><surname>Spoormaker</surname><given-names>VI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spontaneous pupil dilations during the resting state are associated with activation of the Salience network</article-title><source>NeuroImage</source><volume>139</volume><fpage>189</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.06.011</pub-id><pub-id pub-id-type="pmid">27291493</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schulz</surname><given-names>M-A</given-names></name><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Vogelstein</surname><given-names>JT</given-names></name><name><surname>Mourao-Miranada</surname><given-names>J</given-names></name><name><surname>Kather</surname><given-names>JN</given-names></name><name><surname>Kording</surname><given-names>K</given-names></name><name><surname>Richards</surname><given-names>B</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Different scaling of linear models and deep learning in Ukbiobank brain images versus machine-learning datasets</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>4238</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-18037-z</pub-id><pub-id pub-id-type="pmid">32843633</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>RP</given-names></name><name><surname>Mead</surname><given-names>A</given-names></name><name><surname>Sears</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>The effect of dopamine on the intraocular pressure and pupil of the rabbit eye</article-title><source>Investigative Ophthalmology &amp; Visual Science</source><volume>15</volume><fpage>371</fpage><lpage>380</lpage></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheng</surname><given-names>F</given-names></name><name><surname>Ramakrishnan</surname><given-names>A</given-names></name><name><surname>Seok</surname><given-names>D</given-names></name><name><surname>Zhao</surname><given-names>WJ</given-names></name><name><surname>Thelaus</surname><given-names>S</given-names></name><name><surname>Cen</surname><given-names>P</given-names></name><name><surname>Platt</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Decomposing loss aversion from gaze allocation and pupil dilation</article-title><source>PNAS</source><volume>117</volume><fpage>11356</fpage><lpage>11363</lpage><pub-id pub-id-type="doi">10.1073/pnas.1919670117</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shine</surname><given-names>JM</given-names></name><name><surname>Bissett</surname><given-names>PG</given-names></name><name><surname>Bell</surname><given-names>PT</given-names></name><name><surname>Koyejo</surname><given-names>O</given-names></name><name><surname>Balsters</surname><given-names>JH</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Moodie</surname><given-names>CA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The dynamics of functional brain networks: Integrated network states during cognitive task performance</article-title><source>Neuron</source><volume>92</volume><fpage>544</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.018</pub-id><pub-id pub-id-type="pmid">27693256</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shine</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuromodulatory influences on integration and segregation in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>572</fpage><lpage>583</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.04.002</pub-id><pub-id pub-id-type="pmid">31076192</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silvani</surname><given-names>A</given-names></name><name><surname>Calandra-Buonaura</surname><given-names>G</given-names></name><name><surname>Benarroch</surname><given-names>EE</given-names></name><name><surname>Dampney</surname><given-names>RAL</given-names></name><name><surname>Cortelli</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Bidirectional interactions between the baroreceptor reflex and arousal: An update</article-title><source>Sleep Medicine</source><volume>16</volume><fpage>210</fpage><lpage>216</lpage><pub-id pub-id-type="doi">10.1016/j.sleep.2014.10.011</pub-id><pub-id pub-id-type="pmid">25616389</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sobczak</surname><given-names>F</given-names></name><name><surname>He</surname><given-names>Y</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Predicting the FMRI signal fluctuation with recurrent neural networks trained on vascular network dynamics</article-title><source>Cerebral Cortex</source><volume>31</volume><fpage>826</fpage><lpage>844</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhaa260</pub-id><pub-id pub-id-type="pmid">32940658</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Sobczak</surname><given-names>F</given-names></name><name><surname>Pais-Roldan</surname><given-names>P</given-names></name><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2021">2021b</year><data-title>Raw Data for &quot;Decoding the Brain State-Dependent Relationship between Pupil Dynamics and Resting State FMRI Signal Fluctuation</data-title><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4670277">https://doi.org/10.5281/zenodo.4670277</ext-link></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Salakhutdinov</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title><source>Journal of Machine Learning Research</source><volume>15</volume><fpage>1929</fpage><lpage>1958</lpage></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>255</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tagliazucchi</surname><given-names>E</given-names></name><name><surname>Laufs</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding wakefulness levels from typical FMRI resting-state data reveals reliable drifts between wakefulness and sleep</article-title><source>Neuron</source><volume>82</volume><fpage>695</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.03.020</pub-id><pub-id pub-id-type="pmid">24811386</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname><given-names>Y</given-names></name><name><surname>Hocke</surname><given-names>LM</given-names></name><name><surname>Frederick</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Low Frequency Systemic Hemodynamic “Noise” in Resting State BOLD fMRI: Characteristics, Causes, Implications, Mitigation Strategies, and Applications</article-title><source>Frontiers in Neuroscience</source><volume>13</volume><elocation-id>787</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2019.00787</pub-id><pub-id pub-id-type="pmid">31474815</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tseng</surname><given-names>J</given-names></name><name><surname>Poppenk</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain meta-state transitions demarcate thoughts across task contexts exposing the mental noise of trait neuroticism</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3480</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17255-9</pub-id><pub-id pub-id-type="pmid">32661242</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Brink</surname><given-names>RL</given-names></name><name><surname>Pfeffer</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brainstem modulation of large-scale intrinsic cortical activity correlations</article-title><source>Frontiers in Human Neuroscience</source><volume>13</volume><elocation-id>340</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2019.00340</pub-id><pub-id pub-id-type="pmid">31649516</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Carey</surname><given-names>CJ</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Henriksen</surname><given-names>I</given-names></name><name><surname>Quintero</surname><given-names>EA</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>van Mulbregt</surname><given-names>P</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SCIPY 1.0: Fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vitiello</surname><given-names>B</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name><name><surname>Hill</surname><given-names>J</given-names></name><name><surname>Mack</surname><given-names>C</given-names></name><name><surname>Molchan</surname><given-names>S</given-names></name><name><surname>Martinez</surname><given-names>R</given-names></name><name><surname>Murphy</surname><given-names>DL</given-names></name><name><surname>Sunderland</surname><given-names>T</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Cognitive and behavioral effects of cholinergic, dopaminergic, and serotonergic blockade in humans</article-title><source>Neuropsychopharmacology</source><volume>16</volume><fpage>15</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/S0893-133X(96)00134-0</pub-id><pub-id pub-id-type="pmid">8981385</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>CA</given-names></name><name><surname>Boehnke</surname><given-names>SE</given-names></name><name><surname>White</surname><given-names>BJ</given-names></name><name><surname>Munoz</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Microstimulation of the monkey superior colliculus induces pupil dilation without evoking saccades</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3629</fpage><lpage>3636</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5512-11.2012</pub-id><pub-id pub-id-type="pmid">22423086</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welch</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>The use of fast fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms</article-title><source>IEEE Transactions on Audio and Electroacoustics</source><volume>15</volume><fpage>70</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1109/TAU.1967.1161901</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilhelm</surname><given-names>H</given-names></name><name><surname>Wilhelm</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Clinical applications of pupillography</article-title><source>Journal of Neuro-Ophthalmology</source><volume>23</volume><fpage>42</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1097/00041327-200303000-00010</pub-id><pub-id pub-id-type="pmid">12616089</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yekutieli</surname><given-names>D</given-names></name><name><surname>Benjamini</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics</article-title><source>Journal of Statistical Planning and Inference</source><volume>82</volume><fpage>171</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1016/S0378-3758(99)00041-5</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yellin</surname><given-names>D</given-names></name><name><surname>Berkovich-Ohana</surname><given-names>A</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Coupling between pupil fluctuations and resting-state fmri uncovers a slow build-up of antagonistic responses in the human cortex</article-title><source>NeuroImage</source><volume>106</volume><fpage>414</fpage><lpage>427</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.11.034</pub-id><pub-id pub-id-type="pmid">25463449</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoss</surname><given-names>RE</given-names></name><name><surname>Moyer</surname><given-names>NJ</given-names></name><name><surname>Hollenhorst</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Pupil size and spontaneous pupillary waves associated with alertness, drowsiness, and sleep</article-title><source>Neurology</source><volume>20</volume><fpage>545</fpage><lpage>554</lpage><pub-id pub-id-type="doi">10.1212/wnl.20.6.545</pub-id><pub-id pub-id-type="pmid">5463609</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yüzgeç</surname><given-names>Ö</given-names></name><name><surname>Prsa</surname><given-names>M</given-names></name><name><surname>Zimmermann</surname><given-names>R</given-names></name><name><surname>Huber</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupil size coupling to cortical states protects the stability of deep sleep via parasympathetic modulation</article-title><source>Current Biology</source><volume>28</volume><fpage>392</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.12.049</pub-id><pub-id pub-id-type="pmid">29358069</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.68980.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Willem de Gee</surname><given-names>Jan</given-names></name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.02.24.432768">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.02.24.432768v1">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Pupil diameter is used as an index of the brain's arousal system, and has traditionally thought to be a non-invasive index of specific neuromodulatory activity. It is therefore been heavily used as a measure in neuroscience. More recent data suggests a more complex picture whereby a pupil dilation might track cocktail of different neuromodulators. This paper provides firm data supporting this view, and introduces the new view that the make-up of this cocktail changes significantly over time. Pupil dynamics are linked with different neuromodulatory centers over different intervals of time. This is clearly important data across a broad range of human and animal systems neuroscience.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Decoding the brain state-dependent relationship between pupil dynamics and resting state fMRI signal fluctuation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by Timothy Behrens as the Senior and Reviewing Editor. The following individual involved in review of your submission has agreed to reveal their identity: Jan Willem de Gee (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>After our discussion, we believe the following 3 points from the review are essential. All remaining points are strongly recommended to improve the paper, but are discretionary.</p><p>Essential points</p><p>From Reviewer 2:</p><p>(1) First point in public review – the lag between pupil and BOLD</p><p>From Reviewer 3's public review:</p><p>(2) assessing reproducibility of the clusters,</p><p>(3) potential inter-dependence between train/testing data.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>My specific suggestions for addressing the above points are as follows:</p><p>1) Regarding reproducibility and comparison against null models, the authors might refer to the paper Allen et al., 2014 (&quot;Tracking whole-brain connectivity…&quot;), which examined the reproducibility of time-varying fMRI connectivity matrices using a split-halves analysis, and compared the results against &quot;null&quot; data that matched the actual data in terms of mean, variance, and autocorrelation.</p><p>2) In the power spectral density (PSD) of pupil dynamics for each cluster (Figure 2c), it may be helpful to display some measure of variability over the trials within each cluster -- otherwise it is unclear whether the spectral profiles are distinct across the clusters. Also, how should these different spectral peaks be interpreted in light of the corresponding fMRI spatial maps?</p><p>3) Regarding the decoding models – from what I understood, the PCA step included all 74 scans, including the test data, which would be a source of leakage between train/test sets. It was also not clear whether trials from the same rat could appear in both training and testing sets, which would also affect the interpretation of the decoding accuracy.</p><p>4) It is also mentioned that models were trained on 64 trials, and tested on 10 held-out trials. Since the result might be quite sensitive to the 10 particular trials that were held out, it may be helpful to do a nested cross-validation, holding out multiple subsets of trials for testing (and averaging over the resulting test-set errors).</p><p>5) On first reading, I was a bit confused that the paper first shows 1) that different pupil-fMRI correlation patterns were found in different scans, and then 2) that generalizable models (including linear models) could be trained to predict pupil waveforms from fMRI. The section beginning on p. 9 seems to link these sections by fitting models separately across clusters, but it may be helpful to make this conceptually clearer at the outset.</p><p>6) As clustering is currently performed over 15-min intervals (entire trials), I wondered if the authors had experimented with using shorter intervals. In other words, based on the mechanisms that could drive these changes in pupil-fMRI correlation (and accounting for limitations of fMRI temporal resolution), how quickly would the correlation patterns expect to shift?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.68980.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential points</p><p>From Reviewer 2:</p><p>(1) First point in public review – the lag between pupil and BOLD</p><p>From reviewer 3's public review:</p><p>(2) assessing reproducibility of the clusters,</p><p>(3) potential inter-dependence between train/testing data.</p></disp-quote><p>We thank the reviewers for the positive feedback and for providing ways of improving the study. We addressed the issues pointed out by the reviewers to the best of our capability, in particular, the three essential points as highlighted.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>My specific suggestions for addressing the above points are as follows:</p><p>1) Regarding reproducibility and comparison against null models, the authors might refer to the paper Allen et al., 2014 (&quot;Tracking whole-brain connectivity…&quot;), which examined the reproducibility of time-varying fMRI connectivity matrices using a split-halves analysis, and compared the results against &quot;null&quot; data that matched the actual data in terms of mean, variance, and autocorrelation.</p></disp-quote><p>The point has been addressed in the public review response, however, here we provide an explanation for using the spatial surrogates instead of the temporal ones employed in Allen et al., 2014. We perform dimensionality reduction and clustering on spatial correlation maps. Using temporal surrogates from Allen et al., (2014) did not provide an adequate null model, as (a) applying the same phase shifts to both pupil and fMRI data resulted in creating almost the same spatial correlation maps and the same final results and (b) applying random phase shifts to pupil and fMRI signals before correlating them resulted in close to 0 correlation values and completely random maps. On the other hand, using the Brainsmash toolbox (Burt et al., (2020)), we generated surrogate maps with preserved spatial autocorrelation and value distribution, which allowed us to show that it’s not those two features but the region-specific spatial patterns that drive the clustering.</p><disp-quote content-type="editor-comment"><p>2) In the power spectral density (PSD) of pupil dynamics for each cluster (Figure 2c), it may be helpful to display some measure of variability over the trials within each cluster -- otherwise it is unclear whether the spectral profiles are distinct across the clusters. Also, how should these different spectral peaks be interpreted in light of the corresponding fMRI spatial maps?</p></disp-quote><p>We now plot the standard deviation of the cluster-specific PSD values (Figure 2C). We also included plots of all individual PSDs and example raw pupil signal data (Figure 2 —figure supplement 2). As the different spectral peaks originated from the clustering analysis, they could indicate varied neuromodulatory mechanisms, which were presented in the corresponding fMRI spatial maps. One of our current work is aiming to elucidate the neuronal basis of the varied slow oscillatory features of pupil dynamics based on electrophysiological recordings.</p><disp-quote content-type="editor-comment"><p>3) Regarding the decoding models – from what I understood, the PCA step included all 74 scans, including the test data, which would be a source of leakage between train/test sets. It was also not clear whether trials from the same rat could appear in both training and testing sets, which would also affect the interpretation of the decoding accuracy.</p></disp-quote><p>Point addressed in the public review response.</p><disp-quote content-type="editor-comment"><p>4) It is also mentioned that models were trained on 64 trials, and tested on 10 held-out trials. Since the result might be quite sensitive to the 10 particular trials that were held out, it may be helpful to do a nested cross-validation, holding out multiple subsets of trials for testing (and averaging over the resulting test-set errors).</p></disp-quote><p>Point addressed in the public review response.</p><disp-quote content-type="editor-comment"><p>5) On first reading, I was a bit confused that the paper first shows 1) that different pupil-fMRI correlation patterns were found in different scans, and then 2) that generalizable models (including linear models) could be trained to predict pupil waveforms from fMRI. The section beginning on p. 9 seems to link these sections by fitting models separately across clusters, but it may be helpful to make this conceptually clearer at the outset.</p></disp-quote><p>We now clarified the connection between the decoding analysis and the clustering results at the beginning of the decoding analysis section (Page 5).</p><disp-quote content-type="editor-comment"><p>6) As clustering is currently performed over 15-min intervals (entire trials), I wondered if the authors had experimented with using shorter intervals. In other words, based on the mechanisms that could drive these changes in pupil-fMRI correlation (and accounting for limitations of fMRI temporal resolution), how quickly would the correlation patterns expect to shift?</p></disp-quote><p>Based on the comment, we split the data into shorter trials and repeated the clustering analysis. Based on the silhouette score criterion, selecting n=4 clusters holds up to the length of ~300 s (Figure 2 —figure supplement 6).</p></body></sub-article></article>