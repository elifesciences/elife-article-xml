<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">31209</article-id><article-id pub-id-type="doi">10.7554/eLife.31209</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mouse color and wavelength-specific luminance contrast sensitivity are non-uniform across visual space</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-94945"><name><surname>Denman</surname><given-names>Daniel J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1075-1265</contrib-id><email>danield@alleninstitute.org</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-95963"><name><surname>Luviano</surname><given-names>Jennifer A</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-95964"><name><surname>Ollerenshaw</surname><given-names>Douglas R</given-names></name><email>dougo@alleninstitute.org</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-95965"><name><surname>Cross</surname><given-names>Sissy</given-names></name><email>sissyc@alleninstitute.org</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-59999"><name><surname>Williams</surname><given-names>Derric</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-95966"><name><surname>Buice</surname><given-names>Michael A</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-73112"><name><surname>Olsen</surname><given-names>Shawn R</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-4315"><name><surname>Reid</surname><given-names>R Clay</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8697-6797</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>Allen Institute for Brain Science</institution><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-21650"><name><surname>Callaway</surname><given-names>Ed</given-names></name><role>Reviewing Editor</role><aff><institution>Salk Institute</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>10</day><month>01</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>7</volume><elocation-id>e31209</elocation-id><history><date date-type="received" iso-8601-date="2017-08-12"><day>12</day><month>08</month><year>2017</year></date><date date-type="accepted" iso-8601-date="2017-12-13"><day>13</day><month>12</month><year>2017</year></date></history><permissions><copyright-statement>© 2017, Denman et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Denman et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-31209-v1.pdf"/><abstract><object-id pub-id-type="doi">10.7554/eLife.31209.001</object-id><p>Mammalian visual behaviors, as well as responses in the neural systems underlying these behaviors, are driven by luminance and color contrast. With constantly improving tools for measuring activity in cell-type-specific populations in the mouse during visual behavior, it is important to define the extent of luminance and color information that is behaviorally accessible to the mouse. A non-uniform distribution of cone opsins in the mouse retina potentially complicates both luminance and color sensitivity; opposing gradients of short (UV-shifted) and middle (blue/green) cone opsins suggest that color discrimination and wavelength-specific luminance contrast sensitivity may differ with retinotopic location. Here we ask how well mice can discriminate color and wavelength-specific luminance changes across visuotopic space. We found that mice were able to discriminate color and were able to do so more broadly across visuotopic space than expected from the cone-opsin distribution. We also found wavelength-band-specific differences in luminance sensitivity.</p></abstract><abstract abstract-type="executive-summary"><object-id pub-id-type="doi">10.7554/eLife.31209.002</object-id><title>eLife digest</title><p>Color is a key part of our visual experience. Humans can distinguish between colors thanks to light-sensitive cells at the back of the eye called cones. Our eyes contain three types of cones, most simply named red, green and blue. When light enters the eye, it activates each cone type to a different degree. The combined activity of the three types of cone determines which color we see. However, in about 8% of men, one of the cone types is missing or faulty. This leads to color blindness, usually in the form of an inability to distinguish between reds and greens.</p><p>Most other mammals can also see colors. This includes mice, which are used increasingly to study the mechanisms underlying vision. But it was not clear if mice also use color to guide their behavior. Mice have only two types of cones, some of which respond to green light and others to ultraviolet light. To complicate matters, the two types of cones are distributed unevenly across the back of the mouse eye. This suggests that mice may see colors differently in different parts of a visual scene.</p><p>Denman et al. trained mice to lick a spout whenever they noticed a change in the color or brightness of a dot appearing at various locations on a screen. The results revealed that mice could detect changes in both color and brightness. But the mice's ability to do so depends on where the change occurs. In the upper part of the visual field, corresponding to the area above the horizon, mice could distinguish between different colors. In the lower part of the visual field, below the horizon, they could not. By contrast, mice were able to detect changes in brightness at many different locations.</p><p>This information will make it easier to design and interpret experiments that use mice to try to understand how the brain generates vision. This should help scientists develop new treatments for disorders that affect vision, and possibly for many forms of cognitive impairment too.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>vision</kwd><kwd>color</kwd><kwd>luminance</kwd><kwd>retinotopy</kwd><kwd>psychophysics</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Allen Institute for Brain Science</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Luviano</surname><given-names>Jennifer A</given-names></name><name><surname>Ollerenshaw</surname><given-names>Douglas R</given-names></name><name><surname>Cross</surname><given-names>Sissy</given-names></name><name><surname>Williams</surname><given-names>Derric</given-names></name><name><surname>Buice</surname><given-names>Michael A</given-names></name><name><surname>Olsen</surname><given-names>Shawn R</given-names></name><name><surname>Reid</surname><given-names>R Clay</given-names></name><name><surname>Denman</surname><given-names>Daniel J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Mice can detect changes in hue independent of luminance, with differing sensitivity to hue and luminance in different parts of visual space.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The mouse visual system is increasingly (<xref ref-type="bibr" rid="bib5">Baker, 2013</xref>; <xref ref-type="bibr" rid="bib41">Priebe and McGee, 2014</xref>) being used as a model system for studying both cortical sensory processing (<xref ref-type="bibr" rid="bib22">Glickfeld et al., 2013</xref>, <xref ref-type="bibr" rid="bib23">2014</xref>; <xref ref-type="bibr" rid="bib35">Niell and Stryker, 2008</xref>, <xref ref-type="bibr" rid="bib36">2010</xref>; <xref ref-type="bibr" rid="bib51">Wang et al., 2011a</xref>) and behavior (<xref ref-type="bibr" rid="bib7">Busse et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Harvey et al., 2012</xref>; <xref ref-type="bibr" rid="bib25">Histed et al., 2012</xref>; <xref ref-type="bibr" rid="bib26">Hoy et al., 2016</xref>; <xref ref-type="bibr" rid="bib32">Montijn et al., 2015</xref>). While most physiological work has used achromatic stimuli (<xref ref-type="bibr" rid="bib15">Durand et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Niell and Stryker, 2008</xref>), mice, like most other mammals, display physiological color-opponent signals in the retina (<xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib4">Baden et al., 2016</xref>; <xref ref-type="bibr" rid="bib6">Breuninger et al., 2011</xref>; <xref ref-type="bibr" rid="bib8">Chang et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Joesch and Meister, 2016</xref>), through LGN (<xref ref-type="bibr" rid="bib12">Denman et al., 2017</xref>) and possibly V1 (<xref ref-type="bibr" rid="bib49">Tan et al., 2015</xref>). The mouse retina displays asymmetric and mixed expression of its two opsins along the dorsal-ventral axis of the retina, creating opposing gradients of short and middle opsins (<xref ref-type="bibr" rid="bib2">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib52">Wang et al., 2011b</xref>) and resulting in gradients of wavelength-band-specific responses (<xref ref-type="bibr" rid="bib8">Chang et al., 2013</xref>; <xref ref-type="bibr" rid="bib12">Denman et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Rhim et al., 2017</xref>). Therefore, the substrate for cone-driven color-opponent signals, and any color sensitivity, exists only in the overlapping ‘opsin transition zone’ (<xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib12">Denman et al., 2017</xref>). However, short and middle opsin responses broadly overlap in V1 and higher visual areas (<xref ref-type="bibr" rid="bib43">Rhim et al., 2017</xref>) and rod-cone antagonism can also create color opponency in some mouse retinal ganglion cells (<xref ref-type="bibr" rid="bib29">Joesch and Meister, 2016</xref>), presenting the possibility that behaviorally relevant color information could be extracted more broadly across retinotopic space.</p><p>Whether mice can use color information to guide visual behavior is an open question. There is some evidence for color discrimination (<xref ref-type="bibr" rid="bib27">Jacobs et al., 2004</xref>), but it remains unclear how this depends on overall luminance, luminance contrast, or retinotopic position. Further, it is not known if the gradients in opsin distribution lead to variations in behavioral luminance sensitivity across space. Such non-uniformity would impact studies of visuotopically extended V1 populations, such as studies of population sparsity (<xref ref-type="bibr" rid="bib18">Froudarakis et al., 2014</xref>), population correlations (<xref ref-type="bibr" rid="bib33">Montijn et al., 2016a</xref>) and other notions of population coding (<xref ref-type="bibr" rid="bib32">Montijn et al., 2015</xref>; <xref ref-type="bibr" rid="bib37">Okun et al., 2015</xref>).</p><p>Here, we use a simple behavior, change detection, to determine where in visual space mice can discriminate changes in chromaticity and luminance at ethologically-relevant mesopic (10<sup>−3</sup> - 3 cd/m<sup>2</sup>, [<xref ref-type="bibr" rid="bib54">Wyszecki and Stiles, 1982</xref>]) luminance levels. By measuring detectability of luminance and color changes separately across elevation (spanning ~75°), we are able to generate an estimate of wavelength-specific contrast sensitivity across visual space. Mice were able to discriminate color, but only at elevations above the horizon. We find both wavelength-specific luminance and color contrast sensitivity to be dependent on retinotopic location, but that these differences in sensitivity were less dramatic than expected from the cone opsin distribution, suggesting behavioral access to differential activation of rods and cones.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral task</title><p>To examine the psychophysical and physiological basis of mouse color vision, we first trained mice in a go/no-go change detection task (<xref ref-type="bibr" rid="bib25">Histed et al., 2012</xref>) in an immersive visual stimulation environment customized for delivering stimuli in the spectral bands of the mouse short and middle wavelength opsins (<xref ref-type="fig" rid="fig1">Figure 1A</xref>; Materials and methods). We use the system here to deliver a video stimulus driven by a green and ultraviolet LED projector; for each point on the stimulus, the green and ultraviolet intensity could be independently modulated. Total luminance was in the mesopic range (&lt;3 cd/m<sup>2</sup>), over which mice are both behaviorally active (<xref ref-type="bibr" rid="bib11">Daan et al., 2011</xref>) and color opponent signals have been demonstrated in the retina (<xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Joesch and Meister, 2016</xref>). Briefly, under this paradigm, mice indicate that they have perceived a change in the stimulus by licking a reward spout within 1 s of the change (<xref ref-type="fig" rid="fig1">Figure 1B</xref>); subsequent licks allow reward consumption (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p><fig-group><fig id="fig1" position="float"><object-id pub-id-type="doi">10.7554/eLife.31209.003</object-id><label>Figure 1.</label><caption><title>Change detection task in an immersive visual stimulation environment capable of delivering short- and middle-wavelength band stimulation.</title><p>(<bold>A</bold>) The visual stimulation environment, with the positions and size of stimuli shown; the colored edges were not a part of the presented stimulus, but indicate the color scheme used to denote elevation throughout the other figures. (<bold>B</bold>) A schematic of the task. The background was set to mean intensity for each wavelength band. At variable times, t<sub>n</sub>, the intensity of short and middle wavelength bands within a 15° diameter circle changed. If the mouse licked within 1 s of this change (indicate by the dark grey boxes), a reward was delivered. Schematic short and middle band intensities are shown on the lower plot; corresponding stimulus changes are shown both in blocks and cirlces above each epoch. The schematized circles are larger than actual stimuli, for clarity. (<bold>C</bold>) Example performance in a single session across 250 trials. Each lick is shown relative to stimulus change; the response window is overlaid in grey. A histogram of lick times is shown above. Error bars are S.E.M. (<bold>D</bold>) The distribution of change times (t in panel <bold>B</bold>) across the trials used for analysis of change detection performance. The distribution follows a log sampling distribution, enforcing roughly equal probability of a change occurring as the mouse continues to wait.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31209-fig1-v1"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31209.004</object-id><label>Figure 1—figure supplement 1.</label><caption><title>Eye position during performance of the change detection task at four elevations.</title><p>(<bold>A</bold>) Schematic depicting the geometry of the eye tracking and immersive display system. The mouse was centered in the display sphere to aid in estimation of gaze in visuotopic coordinates. Infrared dichroic mirrors were placed in front of each eye as depicted. (<bold>B</bold>) Example images from the pupil tracking of the left eye (left) and the right eye (right). For the right eye (<bold>C</bold>) Example traces depicting sensitivity of the eye tracking system and the amplitude of typical movements, in both pixels coordinates of the eye tracking images (top) and following conversion to visual coordinates (bottom). The conversion is schematized between the plots, showing an orthographic projection of the pixel coordinate system in to spherical coordinates, which are then aligned to the visual coordinate system based on the geometry depicted in panel <bold>A</bold>. (<bold>D</bold>) Estimate of the resolution of each eye tracking image, showing that 95% of frame-to-frame changes are &lt; 1° for the right eye and &lt; 4° for the left eye. (<bold>E</bold>) Eye position across the four elevation conditions. The elevation and azimuth are not statistically different between any pair of conditions (p&gt;0.05, t-test, box plots). For each elevation, the center position of an ellipse fit to the pupil is shown projected into visual coordinates, with the color of each point representing the density of overlapping points.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31209-fig1-figsupp1-v1"/></fig></fig-group><p>Following pre-training on a luminance change detection task (see Materials and methods), we switched to change detection sessions in which the ultraviolet and green intensity, centered on the mouse short and middle wavelength bands, respectively, were varied independently on each trial. Each trial contained a change in intensity within a 15° test circle on a mean luminance background at one of four elevations: −10°, 10°, 30°, and in some cases 50° (relative to both the horizon and the placement of the rotating mouse platform). We varied position only along elevation because both rods and cones are relatively uniform across the azimuthal axis of the retina (<xref ref-type="bibr" rid="bib48">Sterratt et al., 2013</xref>). Eye position did not change with stimulus location (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). Stimuli at change times were modulations in ultraviolet and green intensities within the stimulus spot, resulting in changes in short and middle band stimulation. Changes in ultraviolet and green intensity were independent of each other, and of the previous intensities, resulting in mainly trials that contained luminance changes, but also some in which short and middle opsin activation oppose each to create an effective hue exchange without a luminance change. Changes covered all of the color space available using our display. There is no explicit level of chance performance in this task design, as false-positive rate could vary depending on the strategy used to guess; we include catch trials in which the stimulus did not change in order to estimate false positive rate at each elevation. To achieve sufficient trials to cover this space, we presented a total of 127,659 trials (n = 4/5 total mice trained, 284 sessions). To control for motivation, we calculated a running average of the reward rate and selected trials where this reward rate remained above four rewards per minute; only these engaged trials (44%; 56,112/127,659) were used for analysis.</p></sec><sec id="s2-2"><title>Short and middle wavelength band specific contrast sensitivity</title><p>We first examined our results to estimate the relative luminance contrast sensitivities to short and middle-wavelength band stimulation across the visual field. Although the green and ultraviolet projector LEDs nearly isolate responses of the middle and short wavelength-sensitive opsins (<xref ref-type="bibr" rid="bib16">Estévez and Spekreijse, 1982</xref>), they do not necessarily isolate responses of individual cones, most of which express a combination of the two opsins. Nor do they necessarily measure the relative weight of the cone opsins themselves, as rods also may contribute to light sensitivity at these luminance levels. Rather, we present a measure of the relative perceptual weight to stimuli of the middle and short wavelength bands covered by our stimulus LEDs (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), as combined through both cone opsins and rods.</p><p>Total luminance change detection saturated by ~30% at all elevations (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) and the half-saturation threshold (hereafter referred to as ‘threshold’) was less than 12% for each elevation (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The highest sensitivity was in the upper visual field, at 5.5% threshold, a threshold that is consistent with previous reports for a 15° (~0.07 cyc/°) stimulus (<xref ref-type="bibr" rid="bib25">Histed et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Prusky et al., 2000</xref>; <xref ref-type="bibr" rid="bib45">Sinex et al., 1979</xref>; <xref ref-type="bibr" rid="bib50">Umino et al., 2008</xref>). Sensitivity to increments in contrast was similar for all elevations (10.5–12.1%). Consistent with previous physiological measurements in V1 of mouse (<xref ref-type="bibr" rid="bib49">Tan et al., 2015</xref>) and other species (<xref ref-type="bibr" rid="bib30">Kremkow et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Wang et al., 2015</xref>), sensitivity to decrements in contrast was higher than sensitivity to increments (5.4%–10.4%). Notably, this was most pronounced in the upper visual field (difference: 5%) than the lower visual field (difference: 1.3%).</p><fig-group><fig id="fig2" position="float"><object-id pub-id-type="doi">10.7554/eLife.31209.005</object-id><label>Figure 2.</label><caption><title>Short and middle wavelength band specific contrast sensitivity.</title><p>(<bold>A</bold>) Performance of luminance contrast change detection at three elevations (green lines: −10°, light blue lines: 10°, dark blue lines: 30°). For each elevation, a fit with hyperbolic ratio function is shown overlaid on mean performance; mean performance line thickness shows S.E.M. across mice. The stimulus is schematized above the performance, showing the corresponding relative change in each wavelength band for each condition. (<bold>B</bold>) Contrast sensitivity at each elevation, from the fits in panel <bold>A</bold>; closed circles: decrements in contrast, open circles: increments in contrast. (<bold>C,D</bold>) short-band specific luminance contrast performance across elevation, as in panels (<bold>A,B</bold>). (<bold>E,F</bold>) middle-band specific luminance contrast performance across elevation, as in panels <bold>A,B</bold>.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31209-fig2-v1"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31209.006</object-id><label>Figure 2—figure supplement 1.</label><caption><title>Spectral radiance of various illumination sources from 350 to 750 nm.</title><p>(<bold>A</bold>) The spectral radiance of the lighting in the Allen Institute animal housing facility, including the behavioral testing suite during lights on (blue line, left axes) and lights off (red line, right axes) conditions. Note the lack of any irradiance below 400 nm. (<bold>B</bold>) The spectral radiance off of the stimulation dome at each elevation for equal short and middle LED drive. (<bold>C</bold>) The spectral radiance off of the stimulation dome at each elevation after adjustment for wavelength-band specific non-uniformity. For panels <bold>B</bold> and <bold>C</bold>, green = −10°, light blue = 10°, dark blue = 30°, and pink = 50°.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31209-fig2-figsupp1-v1"/></fig></fig-group><p>To determine the independent contributions of short and middle wavelength bands, we examined change trials that contained increments or decrements of only one of the two LEDs. For the short wavelength band (i.e. UV), contrast sensitivity was non-uniform, with the highest sensitivity in the upper visual field (<xref ref-type="fig" rid="fig2">Figure 2C,D</xref>; 8% threshold). As with total luminance, mice were more sensitive to decrements than increments in contrast. The non-uniformity across elevation was more pronounced for short-wavelength-specific sensitivity than total luminance, but was restricted to decrements. The middle-wavelength (i.e. green) luminance contrast sensitivity was also non-uniform, across elevation, but with the opposite relationship as the short wavelength and total luminance: higher sensitivity at the two lower elevations and the highest tested elevation (<xref ref-type="fig" rid="fig2">Figure 2E–F</xref>). Middle-wavelength sensitivity was very similar for increments and decrements, again different than total and short-wavelength luminance contrast sensitivity. In summary, we found that luminance contrast sensitivity was non-uniform, with significant opposing wavelength-band-specific non-uniformities, although less than what would be predicted from the opsin expression or photoreceptor response alone, as shown below.</p></sec><sec id="s2-3"><title>Determination of relative short and middle wavelength band contributions at several retinotopic locations and comparison with predicted cone weights</title><p>We next determined the relative strength of short- and middle-wavelength stimulation across the visual field. Despite existing measurements of the cone gradients and non-uniformity in V1 response (<xref ref-type="bibr" rid="bib43">Rhim et al., 2017</xref>), we were uncertain about the relative contributions of rods and cones at the tested light levels (i.e. relative contributions of the rod and middle opsin to middle band stimulation), so we first determined which combinations of wavelength band activation effectively opposed each other at each elevation.</p><p>For both this determination of relative wavelength band weight, and our study of color sensitivity (see below), our approach is schematized in <xref ref-type="fig" rid="fig3">Figure 3A</xref>: for each trial, we plot the change (at the change time in the task, see <xref ref-type="fig" rid="fig1">Figure 1B</xref>) of each LED intensity against the other. Equal but opposite changes in the activation of the short and middle bands should oppose each other and lead to some change in chromaticity (colorfulness relative to luminance), but only a subset of changes will have sufficient change in chromaticity to be distinguishable (<xref ref-type="bibr" rid="bib31">MacAdam, 1942</xref>), if the mouse can distinguish chromaticity at all. Unbalanced changes in intensity create a luminance change, and often a chromaticity and hue change as well, with only those that have equal changes to each wavelength band produce a pure luminance change. Because sensitivity is higher to any luminance change than pure chromaticity changes, the resulting performance forms an elongated ellipse when plotted this way. If our stimulation of each band were equal, the major axis of this ellipse would fall along the unity line, indicating equiluminant stimuli that contain chromaticity change without a luminance change. However, the relative expression of each opsin are not equal across the retina (<xref ref-type="bibr" rid="bib2">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Ortín-Martínez et al., 2014</xref>), so the slope of the major axis of the observed ellipse, hereafter called the ‘equiluminant line’, indicates the relative weight of each luminance band at that location. As such, a slope of 1 lies on the unity and equal short and middle-band weight (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, left); slopes &gt;1 indicate middle band domination (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, right) and &lt;1 short band domination. Note that the axes of these plots are changes in band activation, not absolute intensity levels. The trials in any given bin in the plot have different absolute values of color, both before and after the change point, but the movement within any color space at the change point is always the same (in both direction and magnitude).</p><fig-group><fig id="fig3" position="float"><object-id pub-id-type="doi">10.7554/eLife.31209.007</object-id><label>Figure 3.</label><caption><title>Relative short and middle-wavelength band weights and color discrimination across elevation.</title><p>(<bold>A</bold>) Schematic representation of two possible relative short and middle band weight scenarios, including some putative color contrast sensitivity. The left scenario shows equal weight of short and middle bands, leading to balanced sensitivity and chance performance in response to equal and opposite changes in short and middle band contrast, along the unity line. The right scenario shows higher middle band sensitivity, resulting in a positive shift of the slope, where the larger changes in short band contrast are required to balance changes in middle band contrast. For both scenarios, low luminance and hue contrast should yield low change detection performance (purple ellipses). Any hue discrimination occurs along the major axis of this purple ellipse, and color contrast is high near the edges (orange ellipses). Axes indicate change in each wavelength band intensity, combining the same relative changes in color and luminance across many absolute hue, chromaticity, and luminance values. (<bold>B</bold>) Observed relative weights of short and middle band weights, as in panel <bold>A</bold>., at elevations of −10° (green outline, bottom), 10° (light blue outline, middle), and 30° (dark blue outline, top). (<bold>C</bold>) Fit of the relative weights in panel <bold>B</bold> with two-dimensional Gaussians, including a plot of the major axis of the fit. These major axes are isolated in the plot below. Color corresponds to stimulus elevation (green lines: −10°, light blue lines: 10°, dark blue lines: 30°). (<bold>D</bold>) Schematic of sensitivity testing after adjusting for the wavelength band weights in panels <bold>B</bold> and <bold>C</bold> (top panels showing adjusted intensities across elevation, normalized to the non-adjusted values. Following this adjustment, the central region should be along the line of equiluminance (bottom left), so subsequent testing was focused on this spear-like region (arrow to bottom right). Actual data at elevation = 50° same as panel <bold>E</bold>. (<bold>E</bold>) Performance of change detection at four elevations (green lines: −10°, light blue lines: 10°, dark blue lines: 30°, pink lines: 50°) after short and middle weights adjustment. Because short and middle weight were not exactly balanced, performance was fit with a two-dimensional Gaussian and color sensitivity measured along the major axis (lines overlaid on each plot). (<bold>F</bold>) Hue sensitivity at each elevation. Fit with hyperbolic ratio function is shown overlaid on mean performance; mean performance line thickness shows S.E.M. across mice. The stimulus is schematized above the performance, showing the corresponding equal and opposite relative change in each wavelength band for each condition. (<bold>G</bold>) Contrast sensitivity at each elevation, from fits in panel F. Closed circles: decrements in contrast, open circles: increments in contrast.</p></caption><graphic mime-subtype="x-tiff" mimetype="image" xlink:href="elife-31209-fig3-v1"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><object-id pub-id-type="doi">10.7554/eLife.31209.008</object-id><label>Figure 3—figure supplement 1.</label><caption><title>Estimating short and middle cone weights in the coordinates of our behavioral apparatus from retinal expression and functional data.</title><p>(<bold>A</bold>) To generate predictions of the relative weights of each wavelength band at each elevation tested in our paradigm, we projected retinal spatial distributions of both opsin expression and functional responses (schematized as purple and green lines, for short and middle opsins, respectively) from published reports into visual coordinates according to the eye position measured in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>. (<bold>B</bold>) Normalized difference between the predicted (cone opsin expression, cone opsin functional response, V1 responses from three published reports, <xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>, <xref ref-type="bibr" rid="bib43">Rhim et al., 2017</xref>, and <xref ref-type="bibr" rid="bib1">Aihara et al., 2017</xref>) and the observed behavioral weights, for −10°, 10, and 30°. The difference between our behaviorally observed middle/short ratio at each elevation and the middle/short ratios at those elevation predicted by the measures of cone opsin weight in the literature was divided by the observed ratio to estimate the proportion of the middle band weight provided by rods under our luminance conditions.</p></caption><graphic mime-subtype="png" mimetype="image" xlink:href="elife-31209-fig3-figsupp1-v1"/></fig></fig-group><p>We measured the axis along which opposite changes in short and middle wavelength stimulation effectively canceled each other at several elevations. The performance across pairwise combinations of changes in short and middle band luminance (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) was fit with an ellipse (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, top), and the major axis of this ellipse was taken to be the equiluminance line (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, bottom). We found the mouse to be more sensitive to middle band stimulation than expected at all elevations tested, including at 30° where, given the eye positioning (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), short-opsin expression dominates. In fact, surprisingly, the mice were more sensitive to middle than short-band changes at all elevations, with the following middle/short ratios: 3.4, 3.6, and 2.25 at –10°, 10°, and 30°, respectively.</p><p>We compared our measure of the wavelength-band-specific perceptual contributions to predictions from the cone expression distribution, the cone functional response, and intrinsic imaging of the mouse visual system (<xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib43">Rhim et al., 2017</xref>). By projecting (<xref ref-type="bibr" rid="bib48">Sterratt et al., 2013</xref>) the spatial profile of cones into visuotopic coordinates based on estimations of the mean eye position during our experiments (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), we computed expected middle/short ratios for each of the elevations we tested (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Similar to the estimated relative opsin weights across V1 under photopic conditions (<xref ref-type="bibr" rid="bib1">Aihara et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Rhim et al., 2017</xref>), 2.3, 0.81, 0.81, the cone functional distribution predicts 2.3, 1.0, and 0.44 at –10°, 10°, and 30°, respectively. Both predict far less middle-band sensitivity that we observed. This result suggests that rod opsins, centered near the middle-band, contribute significantly to mouse perceptual sensitivity at these light levels, at least as much as 60% (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) at higher elevations.</p></sec><sec id="s2-4"><title>Can mice discriminate color?</title><p>We continued to ask if mice could report a change in chromaticity independent of any luminance change. Instead of explicitly creating a device that normalized total luminance during chromaticity changes (<xref ref-type="bibr" rid="bib19">Gagin et al., 2014</xref>; <xref ref-type="bibr" rid="bib31">MacAdam, 1942</xref>; <xref ref-type="bibr" rid="bib54">Wyszecki and Stiles, 1982</xref>), we presented sufficient combinations of wavelength-band-specific luminance changes to experimentally determine when chromaticity changes occurred independent of luminance changes. We began with the approach (and data) described above for <xref ref-type="fig" rid="fig3">Figure 3A–C</xref>, but now specifically examining which combinations indicate color discrimination independent of luminance change. Again note that the axes of these plots are changes in band activation, not absolute intensity levels, so the major axis of the ellipse is equivalent to chromaticity changes and the minor axis lightness change, collapsed across all hues.</p><p>We start with the assumption that a lack of change in luminance or chromaticity is not discriminable to the observer. All luminance and color contrast changes that are behaviorally indistinguishable from this ‘no change’ condition (the 0,0 point in <xref ref-type="fig" rid="fig3">Figure 3A,B</xref>) form an ellipse of non-discriminability analogous to a MacAdam ellipse of human non-discriminability on the human chromatcity diagram (<xref ref-type="bibr" rid="bib31">MacAdam, 1942</xref>); in our case, this ellipse is in a chromaticity-luminance space (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref>). As noted above, the major axis of this ellipse specifies this equiluminance line for the wavelength band sensitivities at that elevation). This line is equivalent to a slice through the equiluminant plane in a DKL color space (<xref ref-type="bibr" rid="bib14">Derrington et al., 1984</xref>), and by examining change detection performance along this experimentally defined axis of chromaticity change, we can ask if mice can discriminate color independent of luminance (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, left, orange ellipses).</p><p>Indeed, qualitative inspection of the extremes of the equiluminance lines in <xref ref-type="fig" rid="fig3">Figure 3B</xref> indicated color discrimination ability at some elevations, and differences across visuotopic space. However, because of the shift of short versus middle contributions across space (slopes of the lines in <xref ref-type="fig" rid="fig3">Figure 3C</xref>), we were concerned that the stimuli along the measured equiluminance line at each elevation (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) could contain a within-stimulus luminance gradient that allowed the mice to exploit small within-stimulus luminance changes to detect changes we interpreted as color changes. Further, because the range of chromaticities presented at each elevation was unequal (lengths of the lines in <xref ref-type="fig" rid="fig3">Figure 3C</xref>), we were concerned that the mouse could be sensitive to chromaticity changes at −10° outside of the range of the stimuli presented. To overcome these issues, we adjusted the intensity of the middle band stimulation by fitting an exponential to the slopes of the equiluminance lines across space, normalizing this to the maximum possible intensity of the green LED (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, top). This should create conditions of uniform luminance contrast across all elevations, shifting the major axis of the ellipse at all elevations to the unity line (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, bottom). As such, we limited our testing conditions to the changes around the unity line in order to reduce the number of sessions needed to achieve sufficient trials in each condition; this results in spear-like plots focused on luminance-independent color change. While our adjustment failed to perfectly compensate for variable short-middle weights, we were still able to capture more chromaticities at each elevation and minimize potential luminance gradients.</p><p>We found color discrimination to depend on elevation. Examining the adjusted data (<xref ref-type="fig" rid="fig3">Figure 3F–H</xref>), we found color discrimination was negligible at −10°, but mice were capable of varying levels of color sensitivity at all other elevations tested (<xref ref-type="fig" rid="fig3">Figure 3F,G</xref>). The performance along the equiluminant line at −10° was not well fit by a hyperbolic ratio function, and the performance in catch trials (0% contrast change, false-positive rate) was not significantly different from any point along the line (p&gt;0.05, student’s t-test). We were able to fit the performance at each of the other elevations tested, up to 50° above the horizon. Color contrast sensitivity was highest for decrements in short-middle opponency at 10° elevation (13.4%); color sensitivity was nearly identical for decrements in short-middle opponent contrast at 30 and 50° and for increments at all elevations above the horizon (29.3–32.1%). Notably, the false-positive rate (0% contrast change, catch trials) was markedly different between the lowest and other elevations. We interpret this is a shift in strategy in order to maximize reward volume, as the total volume of reward did not differ between −10° and the other elevations (0.8−0.92 mL/session, p&gt;0.2, Welch’s t-test), despite the lack of color discrimination at −10°.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The finding that both wavelength-specific luminance (<xref ref-type="fig" rid="fig2">Figure 2</xref>) and color contrast (<xref ref-type="fig" rid="fig3">Figure 3E–F</xref>) sensitivity is not uniform across the visual field is in accordance with the distributions of both retinal and primary visual cortical (<xref ref-type="bibr" rid="bib43">Rhim et al., 2017</xref>) responses. However, we found that middle-band sensitivity was both higher and more uniform than expected (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This suggests that rod sensitivity contributes significantly to perceptual sensitivity at these light levels (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>This finding may be important for studies of the mouse visual system that use visuotopically extended stimulation (<xref ref-type="bibr" rid="bib18">Froudarakis et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Montijn et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">Montijn et al., 2016b</xref>; <xref ref-type="bibr" rid="bib40">Pouille et al., 2009</xref>; <xref ref-type="bibr" rid="bib55">Zhuang et al., 2017</xref>), especially those that measure the underlying population representation of the stimuli. Because the spatial scale of luminance and contrast adaptation can be large (<xref ref-type="bibr" rid="bib46">Smirnakis et al., 1997</xref>), the adaptation to large single-band stimuli (such as those produced by LCD or other sRGB displays) in these studies may underestimate the contrast sensitivity for cells in upper visual field. This spatial scale is especially relevant because of the scale of mouse vision – 50% differences can be seen across a small number (~5) receptive field diameters.</p><p>Our results also demonstrate that color sensitivity depends on retinotopy, and that some retinotopic locations appear to not support color discrimination. A goal of many large-scale data collection efforts, both completed (<xref ref-type="bibr" rid="bib4">Baden et al., 2016</xref>) and underway (brain-map.org/visualcoding) as well as smaller-scale surveys (<xref ref-type="bibr" rid="bib15">Durand et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Gao et al., 2010</xref>; <xref ref-type="bibr" rid="bib35">Niell and Stryker, 2008</xref>; <xref ref-type="bibr" rid="bib39">Piscopo et al., 2013</xref>) from retina to V1 is the classification or clustering of response properties in order to define functional channels. Because color-opponent cells, both single and double (<xref ref-type="bibr" rid="bib44">Shapley and Hawken, 2011</xref>), are thought to underlie such behavior, our findings indicate that mice may have at least one, likely at least two, color-opponent cell types; the presence of such functional cell types may depend strongly on retinotopy. Notably, our animals are housed in an environment with fluorescent lighting that does not provide UV-B for reflection (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), suggesting that the behavior we observed is developmentally specified, not learned, and further not lost through lack of use.</p><p>Any color-opponency depends on the underlying distribution of opsins in the retinal photoreceptor layer. The distributions of cone opsins in the mouse retina has been well described, with only a subset of pure cones expressing only a single opsin and 40% of cones expressing a mix of both, and a non-uniform distribution of both pure and mixed cones: middle-wavelength opsin dominates the dorsal retina, although it also extends ventrally, while the short-wavelength opsin is more constrained to the ventral retina. (<xref ref-type="bibr" rid="bib2">Applebury et al., 2000</xref>; <xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Ortín-Martínez et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">Wang et al., 2011b</xref>). In total, cones are relatively uniform across the dorsal-ventral axis of the retina, although others report some increased density in the ventral retina. Rods, on the other hand, are uniform across the dorsal-ventral axis of the retina and are much more numerous than cones (<xref ref-type="bibr" rid="bib28">Jeon et al., 1998</xref>). If color responses, both physiological and behavioral, rely only on cone signals they should follow the cone opsin distribution exactly: more in the transition zone, some in the upper visual field, and none in the lower visual field. Our results are consistent with cone-cone opponency, as we observed a lack of color discrimination only in the lower visual field. However, our result also indicates some rod-cone opponency, as color change detection behavior thresholds relatively unchanged across 10° to 50°, despite the steep decline in middle opsin expression across this range of the retina (<xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>).</p><p>Mice, while often considered nocturnal (<xref ref-type="bibr" rid="bib17">Febinger et al., 2014</xref>), can be behaviorally active across a range of luminance conditions; C57BL/6 mice in particular can shift between diurnal, crepuscular, and nocturnal behavioral patterns over the course of the year (<xref ref-type="bibr" rid="bib11">Daan et al., 2011</xref>). Previous studies on color signaling in the mouse have offered several hypotheses for the ethological uses of color signals. Our results are consistent with the hypothesis (<xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>) that non-uniform wavelength-specific sensitivity is matched to the luminance statistics of natural scenes (UV in the upper visual field, green in the lower), and high sensitivity to decrements in the short wavelengths may be particularly helpful during the shift toward UV in the spectral radiance distribution the during twilight hours (<xref ref-type="bibr" rid="bib47">Spitschan et al., 2016</xref>). Another hypothesis, that short-middle opponency is useful for identifying mouse urine posts (<xref ref-type="bibr" rid="bib29">Joesch and Meister, 2016</xref>), is inconsistent with our demonstration of a lack of color discrimination at −10°, at least in absence of significant excursions in eye position or head movements. Our results suggest that, under the mesopic condition during which mice are often active, color signals may be mediated by both cone-cone and some rod-cone opponency, and this may facilitate the specialization of cone opsin distributions for sampling natural luminance statistics (<xref ref-type="bibr" rid="bib3">Baden et al., 2013</xref>; <xref ref-type="bibr" rid="bib9">Chiao et al., 2000</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>All procedures were approved by the Allen Institute for Brain Science Institutional Animal Care and Use Committee.</p><sec id="s4-1"><title>Animals and surgical preparation</title><p>All animals used in this study (n = 5) were C57Bl/6J male mice aged 30–300 days obtained from The Jackson Laboratories (IMSR_JAX:000664). To fix the animal's head within the behavioral apparatus, a single surgery to permanently attach a headpost was performed. During this surgery, the animal was deeply anesthetized with 5% isoflurane and anesthesia maintained throughout the surgery with 1.5–2% continuous inhaled isoflurane. The mouse was secured in a strereotax with ear bars; hair was removed and the exposed skin sterilized with three rounds of betadine. An anterior-posterior incision was made in the skin from anterior of the eyes to posterior of the ears. The skin was removed in a tear drop shape exposing the skull. The skull was leveled and the headpost was placed using a custom stereotaxic headpost placement jig. A custom 11 mm diameter metal headpost with mounting wings was affixed to the skull using dental cement. The exposed skull inside the headpost was covered with a thin protective layer of clear dental cement and further covered with Kwikcast. The animal was allowed to recover for at least 5 days prior to the initiation of behavioral training.</p><p>After headpost implantation, animals were kept on a reverse light cycle (lights OFF from 9AM to 9PM) and behavioral testing was done between 9AM and 1PM. Mice were habituated to handling gradually, through sessions of increasing duration. Mice were also habituated to the behavioral apparatus, first by allowing periods of free exploration and subsequently with head fixation sessions increasing from 10 min to 1 hr over the course of 1 week. Water restriction began with habituation; all mice were maintained at 85% of the original body weight for the duration of training and testing.</p></sec><sec id="s4-2"><title>Stimulus environment and stimuli</title><p>Ultraviolet and human-visible stimuli were provided across a range of retinotopic locations using a custom spherical stimulus enclosure (<xref ref-type="bibr" rid="bib12">Denman et al., 2017</xref>) (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). A custom DLP-projector designed for the mouse visual system provided independent spatiotemporal modulation of ultraviolet (peak 380 nm, <xref ref-type="fig" rid="fig1">Figure 1B</xref>) and green (peak 532 nm, <xref ref-type="fig" rid="fig1">Figure 1B</xref>) light. The projection system operated at 1024 × 768 pixel resolution and a refresh rate of 60 Hz, achieving a maximum intensity of ~3 cd/m2. Planar stimuli were spatially warped according to a custom fisheye warp for presentation on a curved screen; the fisheye warp was created through an iterative mapping protocol using the meshmapper utility (<ext-link ext-link-type="uri" xlink:href="http://paulbourke.net/dome/meshmapper/">http://paulbourke.net/dome/meshmapper/</ext-link>) calibrated on the behavioral environment to achieve maximal accuracy.</p><p>Stimuli were presented in the right visual hemifield and consisted of 15° diameter circles of varying color on a mean intensity background using custom written software extensions of the PsychoPy package (<ext-link ext-link-type="uri" xlink:href="http://www.psychopy.org">http://www.psychopy.org</ext-link>, RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_006571">SCR_006571</ext-link>). The background intensity was 1.52 cd/m<sup>2</sup>. For some testing sessions, the color of the display was adjusted to match the mouse's spectral sensitivity in order to create uniform and balanced sensitivity to the projector's LED sources across the visual stimulus enclosure. To do so, a second custom warp was applied that included a spatially dependent adjustment of the intensity of each LED (near-UV and ‘green’), according to the results shown in <xref ref-type="fig" rid="fig3">Figure 3C</xref>.</p><p>Animals were head-fixed on a freely rotating disc in the center of the spherical enclosure and allowed to run freely during the course of training and testing. A lick spout was positioned approximately 0.5 cm in front of the mouse within range of tongue extension.</p><p>In some experiments, infrared short-pass dichroic mirrors (750 nm short-pass filter, Edmund Optics) were placed in front of each eye to allow for video tracking of the pupil. Cameras (Mako and Manta, AVT technologies) placed behind the animal were aligned to record a reflected image of the pupil; infrared illumination and a reference corneal reflection was provided via an LED positioned near the camera. Movies of the eye position during presentation of the stimuli used in the task was acquired at &gt;=60 Hz, with the eye occupying &gt;60% of the image at 300 × 300 pixels. Data from these sessions were not included in the performance analysis to avoid any potential artifact caused by the infrared dichroic.</p></sec><sec id="s4-3"><title>Behavioral task</title><p>Animals were first shaped to associate changes in luminance with a reward. After each change in luminance, a water reward was automatically delivered, regardless of mouse licking behavior. During these sessions, the reward was constant at 10 µL. Incorrect licks were punished by resetting the trial, such that the mouse had to wait longer for the next change. This ‘shaping’ phase lasted a minimum of 2 days, but for most mice extended to several weeks. For some animals (2/5), subsequent epochs of this automatic reward shaping served as task reinforcement when performance in testing blocks dropped.</p><p>During each testing session, a circle was presented at a single visuotopic location and remained at this location for the duration of the session. At non-regular intervals, again selected from an exponential distribution, the color and/or luminance of the stimulus was changed, and the mouse had to report detection of change by licking the reward spout within 1 s of the change in order to receive reward (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Licks were detected through a capacitive sensor connected to the reward spout. No water was present on the reward spout before the first lick; if the animal correctly detected a change, a water reward (3–10 µL, depending on animal and stage of training) was delivered through this spout (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Sessions were 50–60 min and typically included ~300 trials. The percent correct reported throughout this work is the total number of trials of that condition in which the mouse licked within 1 s of the change, divided by the total number of trials of that condition. The percent correct on catch trials, in which no stimulus change occurred but rewards were delivered for licks within 1 s of fictive change, is interpreted as the false positive or ‘chance’ performance level.</p><p>Mice were first trained to associate changes of a 15° stimulus at 100% luminance contrast with a reward. In these sessions (total of 3 to 25 sessions), the contrast of a stimulus (10° elevation, relative to the horizon) changed at exponentially distributed intervals from 50% positive relative to the background to 50% negative (from white to black), or vice versa (black to white). If a lick occurred within 1 s of an actual stimulus change (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), a reward was delivered to the spout and liquid reward was consumed subsequent licks (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). If a lick occurred outside of this window the trial was aborted, extending the time the mouse must wait and effectively creating a ‘time-out’ period. Mice advanced from this protocol after performance exceeded 75% for consecutive sessions.</p><p>In subsequent testing sessions, the intensity of the ultraviolet and green intensities were varied independently on each trial. Each trial contained a change in LED intensity for a 15° test circle on a mean luminance background at one of four elevations: −10°, 10°, 30°, and in some cases 50°. The first 8–20 trials of each session were 100% contrast changes, as described for the training blocks, with rewards automatically delivered. The number of these daily ‘free’ rewards was reduced to eight for as long as the mouse received &gt;1.0 mL of reward during training or performed well enough to reach satiety and disengage from the task. We attempted to correct for sessions with poor performance by increasing these ‘free’ rewards on subsequent days before gradually reducing them again. To control for motivation in the results, we calculated a running average of the reward rate and selected trials where this reward rate remained above four rewards per minute; only these engaged trials (44%; 56,112/127,659) were used for analysis.</p></sec><sec id="s4-4"><title>Analysis</title><p>All analyses were done using Python (RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008394">SCR_008394</ext-link>) and common scientific packages (numpy RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008633">SCR_008633</ext-link>, scipy RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008058">SCR_008058</ext-link>, matplotllib RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/SCR_008624">SCR_008624</ext-link>, and pandas). Code is publicly available (<xref ref-type="bibr" rid="bib13">Denman, 2017</xref>) and includes a Jupyter notebook that contains code for generation of our figures from the data. Data from each training session was saved and combined into a common data structure, also available from <xref ref-type="bibr" rid="bib13">Denman, 2017</xref>, that was used for all analysis. Individual sessions were analyzed to drive adjustments in the training parameters such as the number of automatic ‘free’ rewards. Following data collection for all animals, all sessions were loaded into a single object for analysis. This data structure can be recreated from the files made available from <ext-link ext-link-type="uri" xlink:href="https://github.com/danieljdenman/mouse_chromatic">https://github.com/danieljdenman/mouse_chromatic</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/mouse_chromatic">https://github.com/elifesciences-publications/mouse_chromatic</ext-link>).</p><p>To quantify performance, from each trial the following parameters were extracted: change times (the time of stimulus change), lick times (the time of each lick, as detected through the capacitive sensor connected to the reward spout), and the stimulus conditions. A trial was scored ‘correct’ if the first lick after a change time occurred with one second, and if there was actually change in intensity of either green or ultraviolet at that change time.</p><p>For each mouse, the percent correct was computed for each pair of LED state transitions, that is, each pairwise combination of change in short-band luminance and change in middle-band luminance (e.g. <xref ref-type="fig" rid="fig3">Figure 3C</xref>). For each mouse, performance was ignored if three trials were not presented for those conditions. For fitting, missing data were replaced via a nearest neighbors approach, with the mean of the surrounding data. Our sampling strategies focused on the areas of changing performance, ensuring that cases of missing data were limited to the areas where performance had saturated at or near the lapse rate. Psychophysical curves for wavelength band-specific and color sensitivity were taken from the appropriate slices of this color space. Sensitivity was taken from the c<sub>50</sub> parameter of fit a hyperbolic ratio fit (<xref ref-type="bibr" rid="bib10">Contreras and Palmer, 2003</xref>) with an additional offset term, R<sub>0</sub>, to account for shift in false-positive rate across conditions.</p><p>A total of five mice entered training on the task; one mouse failed to reach consecutive sessions of 75% performance during the initial high luminance contrast change detection phase, and so did not continue to testing in the color contrast discrimination phase. We did not use any statistical methods to determine mouse or trial sample size prior to the study, determining based on stability and consistency of results when sufficient samples had been collected. Statistical tests were student’s t-test unless otherwise specified.</p><p>Eyetracking analysis was done via a semi-automated starburst algorithm; full details are available from the Allen Brain Observatory Visual Coding Overview v.4, June 2017 &lt;<ext-link ext-link-type="uri" xlink:href="http://help.brain-map.org/display/observatory/Documentation">http://help.brain-map.org/display/observatory/Documentation</ext-link>&gt;. Briefly, the algorithm fits an ellipse to the pupil or corneal reflection (CR) area within user specified windows outlining the location of the pupil and corneal reflection.. A seed point is identified by convolution with a black square (for the pupil) and white square (for the corneal reflection). An ellipse was fit to candidate boundary points identified using ray tracing using a random sample consensus algorithm. The fit parameters were first reported in coordinate centered on the mouse eye. To convert the tracked pupil positions from pixel coordinates in the eye tracking images to visuotopic coordinates, we first converted the pixel coordinates to spherical coordinates using an orthographic projection of the image onto a sphere with a radius of 1.16 mm, the reported radius if the mouse eye. Because the mouse was positioned in the center of the stimulus enclosure (see the diagrams in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, panel A), which is also a sphere, the position of the pupil in these ‘eye’ spherical coordinates can be converted to visuotopic coordinates by projecting the center of the ‘eye’ sphere on to the visuotopic sphere. The reflection of an infrared LED off of the cornea indicated the center of each eye, and we use the placement of each mirror relative to the mouse (right eye: 51.2° in azimuth, 0° in elevation; left eye: 60° in azimuth and −10° in azimuth) to determine the direction of gaze. As such, the corneal reflection in each eye tracking movie indicates a known reference point in visuotopic space, determined by the relationship of the imaging plan to the eye sphere, and the difference between the corneal reflection and the pupil allows for estimation of gaze position in visual coordinates. Coordinates for eye position were extracted independently for each frame of the eye position movie. This calculation assumes that the center of both eyes are at the center of the visual stimulation dome, that the each eye is a sphere, and that the movements of the eye are rotations about the center, none of which is strictly true. While left and right eye movies had different contrast and noise levels (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, panels C-D), estimations of eye position in visual degrees brought disparate pixel measurement from each eye into good agreement with each other (compare y pixel measures to elevation in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, panel C). We believe this calculation to be accurate enough for comparison of relative eye positions and, given the small displacement of the eyes from the center (&lt;1 cm) of the dome (30 cm radius), reasonable for using published retinotopic distributions to estimate relative opsin distributions in visuotopic coordinates.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We would like to thank Saskia de Vries, Justin Kiggins, and Brian Long for useful discussions in the preparation of this manuscript. We would also like to thank the Neurosurgery and Behavior team, Animal Care team, and Naveen Oullette for assistance in animal surgery, care, and handling. We wish to thank the Allen Institute founders, Paul G Allen and Jody Allen, for their vision, encouragement and support.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Supervision, Investigation, Visualization, Methodology, Writing—original draft, Writing—review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con4"><p>Investigation, Writing—review and editing</p></fn><fn fn-type="con" id="con5"><p>Software, Writing—review and editing</p></fn><fn fn-type="con" id="con6"><p>Software, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con7"><p>Software, Supervision, Methodology, Writing—review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Supervision, Writing—original draft, Writing—review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures were approved by the Allen Institute for Brain Science Institutional Animal Care and Use Committee (IACUC, protocol 1506).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><object-id pub-id-type="doi">10.7554/eLife.31209.009</object-id><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-31209-transrepform-v1.docx"/></supplementary-material></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aihara</surname> <given-names>S</given-names></name><name><surname>Yoshida</surname> <given-names>T</given-names></name><name><surname>Hashimoto</surname> <given-names>T</given-names></name><name><surname>Ohki</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Color representation is retinotopically biased but locally intermingled in mouse V1</article-title><source>Frontiers in Neural Circuits</source><volume>11</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.3389/fncir.2017.00022</pub-id><pub-id pub-id-type="pmid">28405186</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Applebury</surname> <given-names>ML</given-names></name><name><surname>Antoch</surname> <given-names>MP</given-names></name><name><surname>Baxter</surname> <given-names>LC</given-names></name><name><surname>Chun</surname> <given-names>LL</given-names></name><name><surname>Falk</surname> <given-names>JD</given-names></name><name><surname>Farhangfar</surname> <given-names>F</given-names></name><name><surname>Kage</surname> <given-names>K</given-names></name><name><surname>Krzystolik</surname> <given-names>MG</given-names></name><name><surname>Lyass</surname> <given-names>LA</given-names></name><name><surname>Robbins</surname> <given-names>JT</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The murine cone photoreceptor: a single cone type expresses both S and M opsins with retinal spatial patterning</article-title><source>Neuron</source><volume>27</volume><fpage>513</fpage><lpage>523</lpage><pub-id pub-id-type="pmid">11055434</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baden</surname> <given-names>T</given-names></name><name><surname>Schubert</surname> <given-names>T</given-names></name><name><surname>Chang</surname> <given-names>L</given-names></name><name><surname>Wei</surname> <given-names>T</given-names></name><name><surname>Zaichuk</surname> <given-names>M</given-names></name><name><surname>Wissinger</surname> <given-names>B</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A tale of two retinal domains: near-optimal sampling of achromatic contrasts in natural scenes through asymmetric photoreceptor distribution</article-title><source>Neuron</source><volume>80</volume><fpage>1206</fpage><lpage>1217</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.030</pub-id><pub-id pub-id-type="pmid">24314730</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baden</surname> <given-names>T</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Franke</surname> <given-names>K</given-names></name><name><surname>Román Rosón</surname> <given-names>M</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The functional diversity of retinal ganglion cells in the mouse</article-title><source>Nature</source><volume>529</volume><fpage>345</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1038/nature16468</pub-id><pub-id pub-id-type="pmid">26735013</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Through the eyes of a mouse</article-title><source>Nature</source><volume>502</volume><fpage>156</fpage><lpage>158</lpage></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breuninger</surname> <given-names>T</given-names></name><name><surname>Puller</surname> <given-names>C</given-names></name><name><surname>Haverkamp</surname> <given-names>S</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Chromatic bipolar cell pathways in the mouse retina</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>6504</fpage><lpage>6517</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0616-11.2011</pub-id><pub-id pub-id-type="pmid">21525291</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busse</surname> <given-names>L</given-names></name><name><surname>Ayaz</surname> <given-names>A</given-names></name><name><surname>Dhruv</surname> <given-names>NT</given-names></name><name><surname>Katzner</surname> <given-names>S</given-names></name><name><surname>Saleem</surname> <given-names>AB</given-names></name><name><surname>Schölvinck</surname> <given-names>ML</given-names></name><name><surname>Zaharia</surname> <given-names>AD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The detection of visual contrast in the behaving mouse</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>11351</fpage><lpage>11361</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6689-10.2011</pub-id><pub-id pub-id-type="pmid">21813694</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname> <given-names>L</given-names></name><name><surname>Breuninger</surname> <given-names>T</given-names></name><name><surname>Euler</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Chromatic coding from cone-type unselective circuits in the mouse retina</article-title><source>Neuron</source><volume>77</volume><fpage>559</fpage><lpage>571</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.12.012</pub-id><pub-id pub-id-type="pmid">23395380</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiao</surname> <given-names>CC</given-names></name><name><surname>Vorobyev</surname> <given-names>M</given-names></name><name><surname>Cronin</surname> <given-names>TW</given-names></name><name><surname>Osorio</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Spectral tuning of dichromats to natural scenes</article-title><source>Vision Research</source><volume>40</volume><fpage>3257</fpage><lpage>3271</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(00)00156-5</pub-id><pub-id pub-id-type="pmid">11008142</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Contreras</surname> <given-names>D</given-names></name><name><surname>Palmer</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Response to contrast of electrophysiologically defined cell classes in primary visual cortex</article-title><source>Journal of Neuroscience</source><volume>23</volume><fpage>6936</fpage><lpage>6945</lpage><pub-id pub-id-type="pmid">12890788</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daan</surname> <given-names>S</given-names></name><name><surname>Spoelstra</surname> <given-names>K</given-names></name><name><surname>Albrecht</surname> <given-names>U</given-names></name><name><surname>Schmutz</surname> <given-names>I</given-names></name><name><surname>Daan</surname> <given-names>M</given-names></name><name><surname>Daan</surname> <given-names>B</given-names></name><name><surname>Rienks</surname> <given-names>F</given-names></name><name><surname>Poletaeva</surname> <given-names>I</given-names></name><name><surname>Dell'Omo</surname> <given-names>G</given-names></name><name><surname>Vyssotski</surname> <given-names>A</given-names></name><name><surname>Lipp</surname> <given-names>HP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Lab mice in the field: unorthodox daily activity and effects of a dysfunctional circadian clock allele</article-title><source>Journal of Biological Rhythms</source><volume>26</volume><fpage>118</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1177/0748730410397645</pub-id><pub-id pub-id-type="pmid">21454292</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denman</surname> <given-names>DJ</given-names></name><name><surname>Siegle</surname> <given-names>JH</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name><name><surname>Blanche</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatial organization of chromatic pathways in the mouse dorsal lateral geniculate nucleus</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>1102</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1742-16.2016</pub-id><pub-id pub-id-type="pmid">27986926</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Denman</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Mouse_chromatic</data-title><source>Github</source><version designator="88afef9">88afef9</version><ext-link ext-link-type="uri" xlink:href="https://github.com/danieljdenman/mouse_chromatic/tree/master/Denman_behavior_2017">https://github.com/danieljdenman/mouse_chromatic/tree/master/Denman_behavior_2017</ext-link></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derrington</surname> <given-names>AM</given-names></name><name><surname>Krauskopf</surname> <given-names>J</given-names></name><name><surname>Lennie</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Chromatic mechanisms in lateral geniculate nucleus of macaque</article-title><source>The Journal of Physiology</source><volume>357</volume><fpage>241</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1984.sp015499</pub-id><pub-id pub-id-type="pmid">6512691</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Durand</surname> <given-names>S</given-names></name><name><surname>Iyer</surname> <given-names>R</given-names></name><name><surname>Mizuseki</surname> <given-names>K</given-names></name><name><surname>de Vries</surname> <given-names>S</given-names></name><name><surname>Mihalas</surname> <given-names>S</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A comparison of visual response properties in the lateral geniculate nucleus and primary visual cortex of awake and anesthetized mice</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>12144</fpage><lpage>12156</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1741-16.2016</pub-id><pub-id pub-id-type="pmid">27903724</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Estévez</surname> <given-names>O</given-names></name><name><surname>Spekreijse</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>The &quot;silent substitution&quot; method in visual research</article-title><source>Vision Research</source><volume>22</volume><fpage>681</fpage><lpage>691</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(82)90104-3</pub-id><pub-id pub-id-type="pmid">7112962</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Febinger</surname> <given-names>HY</given-names></name><name><surname>George</surname> <given-names>A</given-names></name><name><surname>Priestley</surname> <given-names>J</given-names></name><name><surname>Toth</surname> <given-names>LA</given-names></name><name><surname>Opp</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Effects of housing condition and cage change on characteristics of sleep in mice</article-title><source>Journal of the American Association for Laboratory Animal Science</source><volume>53</volume><fpage>29</fpage><lpage>37</lpage><pub-id pub-id-type="pmid">24411777</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Froudarakis</surname> <given-names>E</given-names></name><name><surname>Berens</surname> <given-names>P</given-names></name><name><surname>Ecker</surname> <given-names>AS</given-names></name><name><surname>Cotton</surname> <given-names>RJ</given-names></name><name><surname>Sinz</surname> <given-names>FH</given-names></name><name><surname>Yatsenko</surname> <given-names>D</given-names></name><name><surname>Saggau</surname> <given-names>P</given-names></name><name><surname>Bethge</surname> <given-names>M</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Population code in mouse V1 facilitates readout of natural scenes through increased sparseness</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>851</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1038/nn.3707</pub-id><pub-id pub-id-type="pmid">24747577</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gagin</surname> <given-names>G</given-names></name><name><surname>Bohon</surname> <given-names>KS</given-names></name><name><surname>Butensky</surname> <given-names>A</given-names></name><name><surname>Gates</surname> <given-names>MA</given-names></name><name><surname>Hu</surname> <given-names>JY</given-names></name><name><surname>Lafer-Sousa</surname> <given-names>R</given-names></name><name><surname>Pulumo</surname> <given-names>RL</given-names></name><name><surname>Qu</surname> <given-names>J</given-names></name><name><surname>Stoughton</surname> <given-names>CM</given-names></name><name><surname>Swanbeck</surname> <given-names>SN</given-names></name><name><surname>Conway</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Color-detection thresholds in rhesus macaque monkeys and humans</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.1167/14.8.12</pub-id><pub-id pub-id-type="pmid">25027164</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname> <given-names>E</given-names></name><name><surname>DeAngelis</surname> <given-names>GC</given-names></name><name><surname>Burkhalter</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Parallel input channels to mouse primary visual cortex</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>5912</fpage><lpage>5926</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6456-09.2010</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname> <given-names>ME</given-names></name><name><surname>Nauhaus</surname> <given-names>I</given-names></name><name><surname>Marshel</surname> <given-names>JH</given-names></name><name><surname>Callaway</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topography and areal organization of mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12587</fpage><lpage>12600</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1124-14.2014</pub-id><pub-id pub-id-type="pmid">25209296</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickfeld</surname> <given-names>LL</given-names></name><name><surname>Andermann</surname> <given-names>ML</given-names></name><name><surname>Bonin</surname> <given-names>V</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortico-cortical projections in mouse visual cortex are functionally target specific</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>219</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1038/nn.3300</pub-id><pub-id pub-id-type="pmid">23292681</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickfeld</surname> <given-names>LL</given-names></name><name><surname>Reid</surname> <given-names>RC</given-names></name><name><surname>Andermann</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A mouse model of higher visual cortical function</article-title><source>Current Opinion in Neurobiology</source><volume>24</volume><fpage>28</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.08.009</pub-id><pub-id pub-id-type="pmid">24492075</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Coen</surname> <given-names>P</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Choice-specific sequences in parietal cortex during a virtual-navigation decision task</article-title><source>Nature</source><volume>484</volume><fpage>62</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1038/nature10918</pub-id><pub-id pub-id-type="pmid">22419153</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Histed</surname> <given-names>MH</given-names></name><name><surname>Carvalho</surname> <given-names>LA</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Psychophysical measurement of contrast sensitivity in the behaving mouse</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>758</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1152/jn.00609.2011</pub-id><pub-id pub-id-type="pmid">22049334</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoy</surname> <given-names>JL</given-names></name><name><surname>Yavorska</surname> <given-names>I</given-names></name><name><surname>Wehr</surname> <given-names>M</given-names></name><name><surname>Niell</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Vision drives accurate approach behavior during prey capture in laboratory mice</article-title><source>Current Biology</source><volume>26</volume><fpage>3046</fpage><lpage>3052</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.09.009</pub-id><pub-id pub-id-type="pmid">27773567</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname> <given-names>GH</given-names></name><name><surname>Williams</surname> <given-names>GA</given-names></name><name><surname>Fenwick</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Influence of cone pigment coexpression on spectral sensitivity and color vision in the mouse</article-title><source>Vision Research</source><volume>44</volume><fpage>1615</fpage><lpage>1622</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2004.01.016</pub-id><pub-id pub-id-type="pmid">15135998</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeon</surname> <given-names>CJ</given-names></name><name><surname>Strettoi</surname> <given-names>E</given-names></name><name><surname>Masland</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The major cell populations of the mouse retina</article-title><source>Journal of Neuroscience</source><volume>18</volume><fpage>8936</fpage><lpage>8946</lpage><pub-id pub-id-type="pmid">9786999</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joesch</surname> <given-names>M</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A neuronal circuit for colour vision based on rod-cone opponency</article-title><source>Nature</source><volume>532</volume><fpage>236</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1038/nature17158</pub-id><pub-id pub-id-type="pmid">27049951</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kremkow</surname> <given-names>J</given-names></name><name><surname>Jin</surname> <given-names>J</given-names></name><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Alonso</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Principles underlying sensory map topography in primary visual cortex</article-title><source>Nature</source><volume>533</volume><fpage>52</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1038/nature17936</pub-id><pub-id pub-id-type="pmid">27120164</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacAdam</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="1942">1942</year><article-title>Visual sensitivities to color differences in daylight*</article-title><source>Journal of the Optical Society of America</source><volume>32</volume><elocation-id>247</elocation-id><pub-id pub-id-type="doi">10.1364/JOSA.32.000247</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montijn</surname> <given-names>JS</given-names></name><name><surname>Goltstein</surname> <given-names>PM</given-names></name><name><surname>Pennartz</surname> <given-names>CMA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mouse V1 population correlates of visual detection rely on heterogeneity within neuronal response patterns</article-title><source>eLife</source><volume>4</volume><fpage>1</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.7554/eLife.10163</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montijn</surname> <given-names>JS</given-names></name><name><surname>Meijer</surname> <given-names>GT</given-names></name><name><surname>Lansink</surname> <given-names>CS</given-names></name><name><surname>Pennartz</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Population-level neural codes are robust to single-neuron variability from a multidimensional coding perspective</article-title><source>Cell Reports</source><volume>16</volume><fpage>2486</fpage><lpage>2498</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2016.07.065</pub-id><pub-id pub-id-type="pmid">27545876</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montijn</surname> <given-names>JS</given-names></name><name><surname>Olcese</surname> <given-names>U</given-names></name><name><surname>Pennartz</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Visual stimulus detection correlates with the consistency of temporal sequences within stereotyped events of V1 neuronal population activity</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>8624</fpage><lpage>8640</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0853-16.2016</pub-id><pub-id pub-id-type="pmid">27535910</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Cossell</surname> <given-names>L</given-names></name><name><surname>Iacaruso</surname> <given-names>MF</given-names></name><name><surname>Ko</surname> <given-names>H</given-names></name><name><surname>Barthó</surname> <given-names>P</given-names></name><name><surname>Moore</surname> <given-names>T</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Diverse coupling of neurons to populations in sensory cortex</article-title><source>Nature</source><volume>521</volume><fpage>511</fpage><lpage>515</lpage><pub-id pub-id-type="doi">10.1038/nature14273</pub-id><pub-id pub-id-type="pmid">25849776</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ortín-Martínez</surname> <given-names>A</given-names></name><name><surname>Nadal-Nicolás</surname> <given-names>FM</given-names></name><name><surname>Jiménez-López</surname> <given-names>M</given-names></name><name><surname>Alburquerque-Béjar</surname> <given-names>JJ</given-names></name><name><surname>Nieto-López</surname> <given-names>L</given-names></name><name><surname>García-Ayuso</surname> <given-names>D</given-names></name><name><surname>Villegas-Pérez</surname> <given-names>MP</given-names></name><name><surname>Vidal-Sanz</surname> <given-names>M</given-names></name><name><surname>Agudo-Barriuso</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Number and distribution of mouse retinal cone photoreceptors: differences between an albino (Swiss) and a pigmented (C57/BL6) strain</article-title><source>PLoS One</source><volume>9</volume><elocation-id>e102392</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0102392</pub-id><pub-id pub-id-type="pmid">25029531</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piscopo</surname> <given-names>DM</given-names></name><name><surname>El-Danaf</surname> <given-names>RN</given-names></name><name><surname>Huberman</surname> <given-names>AD</given-names></name><name><surname>Niell</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Diverse visual features encoded in mouse lateral geniculate nucleus</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>4642</fpage><lpage>4656</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5187-12.2013</pub-id><pub-id pub-id-type="pmid">23486939</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pouille</surname> <given-names>F</given-names></name><name><surname>Marin-Burgin</surname> <given-names>A</given-names></name><name><surname>Adesnik</surname> <given-names>H</given-names></name><name><surname>Atallah</surname> <given-names>BV</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Input normalization by global feedforward inhibition expands cortical dynamic range</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1577</fpage><lpage>1585</lpage><pub-id pub-id-type="doi">10.1038/nn.2441</pub-id><pub-id pub-id-type="pmid">19881502</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname> <given-names>NJ</given-names></name><name><surname>McGee</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mouse vision as a gateway for understanding how experience shapes neural circuits</article-title><source>Frontiers in Neural Circuits</source><volume>8</volume><elocation-id>123</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2014.00123</pub-id><pub-id pub-id-type="pmid">25324730</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prusky</surname> <given-names>GT</given-names></name><name><surname>West</surname> <given-names>PW</given-names></name><name><surname>Douglas</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Behavioral assessment of visual acuity in mice and rats</article-title><source>Vision Research</source><volume>40</volume><fpage>2201</fpage><lpage>2209</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(00)00081-X</pub-id><pub-id pub-id-type="pmid">10878281</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rhim</surname> <given-names>I</given-names></name><name><surname>Coello-Reyes</surname> <given-names>G</given-names></name><name><surname>Ko</surname> <given-names>HK</given-names></name><name><surname>Nauhaus</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Maps of cone opsin input to mouse V1 and higher visual areas</article-title><source>Journal of Neurophysiology</source><volume>117</volume><fpage>1674</fpage><lpage>1682</lpage><pub-id pub-id-type="doi">10.1152/jn.00849.2016</pub-id><pub-id pub-id-type="pmid">28100658</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shapley</surname> <given-names>R</given-names></name><name><surname>Hawken</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Color in the cortex: single- and double-opponent cells</article-title><source>Vision Research</source><volume>51</volume><fpage>701</fpage><lpage>717</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2011.02.012</pub-id><pub-id pub-id-type="pmid">21333672</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sinex</surname> <given-names>DG</given-names></name><name><surname>Burdette</surname> <given-names>LJ</given-names></name><name><surname>Pearlman</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>A psychophysical investigation of spatial vision in the normal and reeler mutant mouse</article-title><source>Vision Research</source><volume>19</volume><fpage>853</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(79)90018-X</pub-id><pub-id pub-id-type="pmid">516456</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smirnakis</surname> <given-names>SM</given-names></name><name><surname>Berry</surname> <given-names>MJ</given-names></name><name><surname>Warland</surname> <given-names>DK</given-names></name><name><surname>Bialek</surname> <given-names>W</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Adaptation of retinal processing to image contrast and spatial scale</article-title><source>Nature</source><volume>386</volume><fpage>69</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1038/386069a0</pub-id><pub-id pub-id-type="pmid">9052781</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spitschan</surname> <given-names>M</given-names></name><name><surname>Aguirre</surname> <given-names>GK</given-names></name><name><surname>Brainard</surname> <given-names>DH</given-names></name><name><surname>Sweeney</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Variation of outdoor illumination as a function of solar elevation and light pollution</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>26756</elocation-id><pub-id pub-id-type="doi">10.1038/srep26756</pub-id><pub-id pub-id-type="pmid">27272736</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterratt</surname> <given-names>DC</given-names></name><name><surname>Lyngholm</surname> <given-names>D</given-names></name><name><surname>Willshaw</surname> <given-names>DJ</given-names></name><name><surname>Thompson</surname> <given-names>ID</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Standard anatomical and visual space for the mouse retina: computational reconstruction and transformation of flattened retinae with the Retistruct package</article-title><source>PLoS Computational Biology</source><volume>9</volume><elocation-id>e1002921</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002921</pub-id><pub-id pub-id-type="pmid">23468609</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname> <given-names>Z</given-names></name><name><surname>Sun</surname> <given-names>W</given-names></name><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Kim</surname> <given-names>D</given-names></name><name><surname>Ji</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal representation of ultraviolet visual stimuli in mouse primary visual cortex</article-title><source>Scientific Reports</source><volume>5</volume><elocation-id>12597</elocation-id><pub-id pub-id-type="doi">10.1038/srep12597</pub-id><pub-id pub-id-type="pmid">26219604</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Umino</surname> <given-names>Y</given-names></name><name><surname>Solessio</surname> <given-names>E</given-names></name><name><surname>Barlow</surname> <given-names>RB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Speed, spatial, and temporal tuning of rod and cone vision in mouse</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>189</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3551-07.2008</pub-id><pub-id pub-id-type="pmid">18171936</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>Gao</surname> <given-names>E</given-names></name><name><surname>Burkhalter</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011a</year><article-title>Gateways of ventral and dorsal streams in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>1905</fpage><lpage>1918</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3488-10.2011</pub-id><pub-id pub-id-type="pmid">21289200</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>YV</given-names></name><name><surname>Weick</surname> <given-names>M</given-names></name><name><surname>Demb</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2011">2011b</year><article-title>Spectral and temporal sensitivity of cone-mediated responses in mouse retinal ganglion cells</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>7670</fpage><lpage>7681</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0629-11.2011</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Jin</surname> <given-names>J</given-names></name><name><surname>Kremkow</surname> <given-names>J</given-names></name><name><surname>Lashgari</surname> <given-names>R</given-names></name><name><surname>Komban</surname> <given-names>SJ</given-names></name><name><surname>Alonso</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Columnar organization of spatial phase in visual cortex</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>97</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1038/nn.3878</pub-id><pub-id pub-id-type="pmid">25420070</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wyszecki</surname> <given-names>G</given-names></name><name><surname>Stiles</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1982">1982</year><source>Color Science: Concepts and Methods, Quantitative Data and Formulae</source><publisher-loc>Hoboken, United States</publisher-loc><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhuang</surname> <given-names>J</given-names></name><name><surname>Ng</surname> <given-names>L</given-names></name><name><surname>Williams</surname> <given-names>D</given-names></name><name><surname>Valley</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Garrett</surname> <given-names>M</given-names></name><name><surname>Waters</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An extended retinotopic map of mouse cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e18372</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18372</pub-id><pub-id pub-id-type="pmid">28059700</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="SA1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.31209.011</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Callaway</surname><given-names>Ed</given-names></name><role>Reviewing Editor</role><aff><institution>Salk Institute</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife includes the editorial decision letter and accompanying author responses. A lightly edited version of the letter sent to the authors after peer review is shown, indicating the most substantive concerns; minor comments are not usually included.</p></boxed-text><p>Thank you for submitting your article &quot;Mouse hue and wavelength-specific luminance contrast sensitivity are non-uniform across visual space&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and David Van Essen as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Ed Callaway (Reviewer #1); Bevil R Conway (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>Summary:</p><p>This paper addresses the extent to which mice have color vision. Although it is known that mice have two different cone types, it is not completely clear that mice use the retinal signals to extract color information. The cone types are not intermingled across the retina as in trichromatic primates, but rather arranged in a counter-gradient across the dorsal ventral axis; moreover, many cone photoreceptors express more than one cone photo-pigment, again unlike trichromatic primates. These observations, documented previously, suggest that signals from the different cone types are not contributing to color vision operations analogous to those found in trichromatic mammals (or other dichromatic mammals), but used instead to support specialized behaviors such as tracking urine, or spatial navigation. Nonetheless, pioneering work by Jacobs and colleagues demonstrated luminance-invariant color discrimination behavior in mice, supporting the idea that mice are capable of some dichromatic color vision. The main advance of the current report is a thorough quantification of the color abilities of mice across the topography of the retina. The experiments are very ingenious and well designed, especially given the challenge of obtaining psychophysical measurements from head-fixed mice, and the requirement of stimulating precise elevations over the visual field. Thus, the paper presents major technical innovations that couple eye tracking and careful color-psychophysical tests in alert mice. The work is heroic, requiring many hours of animal-behavior testing. The results will be of interest to the growing number of laboratories that are investigating neural and molecular mechanisms supporting vision in mice. The results are surprising: the color abilities assessed in the paper do not correspond to predictions based on the gradients of cone pigments. The authors speculate that this discrepancy reflects a substantial contribution of rods to the behavioral tests, which is supported by recent physiological evidence of rod-cone opponency in mice from Meister's group.</p><p>Essential revisions:</p><p>Despite the expertise of the reviewers, all three had some trouble following the descriptions of the visual stimuli used to assess hue sensitivity and the related presentation of results in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Because each reviewer had somewhat different comments, rather than synthesizing them, they are all copied below to show the different sources of confusion. You will therefore find some redundancy in these comments.</p><p>Another essential revision will be to address concerns about measurements of eye position as summarized below.</p><p>1) Visual stimuli, hue sensitivity and <xref ref-type="fig" rid="fig3">Figure 3</xref>:</p><p>Reviewer 2 –</p><p>The stimulus is not completely clear to me. On a conventional CRT one might have a neutral adapting background and replace a section of the background with a stimulus spot through silent substitution; alternatively, one might superimpose the stimulus on the background, so that the stimulus has the mixture of background and stimulus (which might be used to selectively adapt a cone type). It's not entirely clear from the description of the stimulus which method is being deployed. Also, it would be conventional to determine for the stimuli the expected photoreceptor activation (the percentage photoreceptor contrast). The authors estimate the pigment density at the retinal locations of their stimuli, so presumably it should be possible to also report the cone (and rod) contrast for the stimuli in the various figures.</p><p><xref ref-type="fig" rid="fig3">Figure 3</xref> contains the main result, but it is a little confusing. I realize <xref ref-type="fig" rid="fig3">Figure 3A</xref> is a schematic, but it would help if there were some units, or at minimum, the location of (0,0). Is it the case that the (0,0) is at the center of the purple ellipse, and not at the bottom left corner (as would be typical for Cartesian coordinates)? The text states that the major axis of the ellipse corresponds to a line of &quot;constant saturation and lightness but varying hue&quot; in HSV space. I don't think this is accurate. If the purple ellipse passes through (0,0), then it would pass through a point of zero saturation (at least if I am correctly interpreting the top panel of <xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p><p><xref ref-type="fig" rid="fig3">Figure 3D</xref>. It is not clear how &quot;attempted compensation for relative short and middle band weights&quot; was performed, and specifically how this is reflected in the graph (how is <xref ref-type="fig" rid="fig3">Figure 3D</xref> different from <xref ref-type="fig" rid="fig3">Figure 3A</xref>?).</p><p>In <xref ref-type="fig" rid="fig3">Figure 3F</xref>, is 50% correct equivalent to &quot;chance&quot;? I'm inclined to believe this is so, but then what is the interpretation for the significant performance below chance at several elevations (and for equiluminant stimuli of low color contrast)? And in the case where my interpretation is wrong, then how does one square the significant performance at the lowest elevation, at all color-contrast changes, with the performance on catch trials?</p><p><xref ref-type="fig" rid="fig3">Figure 3G</xref>, shows that there is a set of stimuli defined by a ratio of S increment/M decrement (or M increment/S decrement) that is relatively invisible to the animals. The balance point of S/M is slightly different across the retina, with the more ventral visual field (dorsal retina) showing greater sensitivity to M than S, compared to the dorsal visual field. This suggests that the dorsal retina has a higher M:S ratio, which I believe is consistent with the cone-opsin distribution. Is this interpretation of the results correct? If so, aren't the behavioral data more consistent with the opsin distribution than the conclusions drawn by the authors?</p><p>Reviewer 3 –</p><p>I found the last section of the Results, with the description of <xref ref-type="fig" rid="fig3">Figure 3D-G</xref> and how hue sensitivity was measured, quite unclear in several parts (see my specific &quot;minor&quot; comments below). This description should be more detailed and much clearer, in order for a reader to fully grasp the meaning and implications of their findings.</p><p>I have trouble understanding the experiments and data analysis to measure the sensitivity to hue changes <xref ref-type="fig" rid="fig3">Figure 3D-G</xref>). Here is what I think I have understood and what I have not:</p><p>The authors want to test if mice can detect changes along the diagonal line of perceived equiluminance (i.e., simultaneous and opposite changes of luminance in the two channels that are not detected by the rats as an overall change of luminance). Since, as they show in <xref ref-type="fig" rid="fig3">Figure 3B-C</xref>, the perceived equiluminant line has not slope = 1, then the authors use this perceived line to measure hue sensitivity along it.… is this correct? Is this what they meant with <xref ref-type="fig" rid="fig3">Figure 3D</xref>? Or, instead, did they actually show combinations of the two channels that are along the unity line? In any event, I don't understand why the shape of the purple bar changes when going from <xref ref-type="fig" rid="fig3">Figure 3D</xref> to <xref ref-type="fig" rid="fig3">Figure 3E</xref>. Shouldn't the purple region have the same spear-like (not rectangular) shape of the region in <xref ref-type="fig" rid="fig3">Figure 3D</xref> (and of the data shown below in <xref ref-type="fig" rid="fig3">Figure 3E</xref>)? More importantly, about the color matrixes shown in <xref ref-type="fig" rid="fig3">Figure 3E</xref>: shouldn't these data just be the same of those already shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref> (just taking those points along the equiluminant line)? What is the difference? Are these actually data resulting from different experiments? And if so, why? Finally, are the curves shown in <xref ref-type="fig" rid="fig3">Figure 3F</xref> derived from the data matrixes of <xref ref-type="fig" rid="fig3">Figure 3E</xref>? Are the curves an average of the data around the unity line? Or around the perceptual equiluminant line? If so, how many data points of the matrixes in <xref ref-type="fig" rid="fig3">Figure 3E</xref> are used to obtain the curves of <xref ref-type="fig" rid="fig3">Figure 3F</xref>. In summary, this whole analysis needs far more details and explanations to be fully understandable?</p><p>2) Comments about measurement of eye position:</p><p>The data suggest that the paradigm provides an accurate assessment of mouse visual ability. It is conceivable that the false-positive (false-alarm) response rate is not fixed, but changes depending on the detectability of the stimulus. It's not clear how this (or shifts in criterion) would impact the results. The authors show that the mice do not have systematically different eye positions across trial types, but it is important to show that the experimental technique could recover differences in eye positions if these differences existed. What is the resolution of the eye tracking compared to the measured eye movements made by the animals in the experiment?</p><p>The authors mention that they have used an eye tracker, which, I believe, is essential to allow them to make accurate predictions of perceptual sensitivity, based on the known opsins' retinal distributions. However, as I far as I understand, the eye tracker was not used systematically, but only in some control sessions, whose data were not those used to obtain the sensitivity measures. I wonder then how the authors can be sure about the position of the mouse eye during the main experimental sessions (it may change form session to session or during a session, making their prediction unreliable). In addition, the authors do not provide any details (or any specific reference) about the eye tracking method they use, especially how they calibrated the eye tracker. Such a calibration is always challenging in rodents (since they do not saccade to target locations over the stimulus display). The authors report that they are able to obtain measurers in degrees, but they do not explain at all how they convert pixels to degree (these clarifications about the eye data are essential if we have to believe their predictions).</p></body></sub-article><sub-article article-type="reply" id="SA2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.31209.012</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Despite the expertise of the reviewers, all three had some trouble following the descriptions of the visual stimuli used to assess hue sensitivity and the related presentation of results in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Because each reviewer had somewhat different comments, rather than synthesizing them, they are all copied below to show the different sources of confusion. You will therefore find some redundancy in these comments.</p><p>Another essential revision will be to address concerns about measurements of eye position as summarized below.</p><p>1) Visual stimuli, hue sensitivity and <xref ref-type="fig" rid="fig3">Figure 3</xref>:</p><p>Reviewer 2 –</p><p>The stimulus is not completely clear to me. On a conventional CRT one might have a neutral adapting background and replace a section of the background with a stimulus spot through silent substitution; alternatively, one might superimpose the stimulus on the background, so that the stimulus has the mixture of background and stimulus (which might be used to selectively adapt a cone type). It's not entirely clear from the description of the stimulus which method is being deployed.</p></disp-quote><p>We apologize that the stimulus was not clear, and have added sentences describing the stimulus in better detail to beginning of the Results section. Neither method is exactly being employed here. The stimulus replaces a constant background, as you describe, but the change in each “primary” (green and UV LEDs in the projector) is random at each replacement. We do not explicitly isolate specific photoreceptor types [especially as many mouse cones express multiple opsins] with these replacements. Instead, most changes modulate the activity of most photoreceptors [and all opsins, rod and both cones]. A subset of the stimuli should achieve the same total quantal catch, but with different combinations of the two “primaries” of our LEDs. But we did not know <italic>a priori</italic> which stimuli these would be, instead determining it empirically (<xref ref-type="fig" rid="fig3">Figure 3A-C</xref>).</p><disp-quote content-type="editor-comment"><p>Also, it would be conventional to determine for the stimuli the expected photoreceptor activation (the percentage photoreceptor contrast). The authors estimate the pigment density at the retinal locations of their stimuli, so presumably it should be possible to also report the cone (and rod) contrast for the stimuli in the various figures.</p></disp-quote><p>Because of the mixing of both opsins in many cones, it would be difficult to compute cone contrast per se, but it may be possible to compute “opsin” contrast as you suggest. We chose not do this because we could not be confident in the absolute calibration of our eye tracking system (see more extensive discussion of this below in the response, and also now in the manuscript in subsection “Analysis”). As such, we use eye tracking for the important controls of relative (not absolute) gaze elevation, and limit the use the absolute mapping between retinotopic to an estimation of relative opsin weight useful for putting our result in <xref ref-type="fig" rid="fig3">Figure 3A-C</xref> in context. Some error in the visuotopic gaze calculation would not effect that interpretation – that there is more rod contribution than expected. However, we were not comfortable stating stimulus intensities in terms of opsin contrast because of the potential inaccuracies of the method.</p><disp-quote content-type="editor-comment"><p><xref ref-type="fig" rid="fig3">Figure 3</xref> contains the main result, but it is a little confusing. I realize <xref ref-type="fig" rid="fig3">Figure 3A</xref> is a schematic, but it would help if there were some units, or at minimum, the location of (0,0). Is it the case that the (0,0) is at the center of the purple ellipse, and not at the bottom left corner (as would be typical for Cartesian coordinates)?</p></disp-quote><p>We have updated both <xref ref-type="fig" rid="fig3">Figure 3</xref> and text describing it to clarify the result (subsection “Determination of relative short and middle wavelength band contributions at several retinotopic locations and comparison with predicted cone weights” and subsection “Can mice discriminate color changes?”). The schematic panels (A and D) of <xref ref-type="fig" rid="fig3">Figure 3</xref> now include both units and an indication of the (0,0) points. Note that these axes are the <underline>change</underline> in each wavelength band, not the absolute value of each. So, at the (0,0) point the absolute hue, saturation, and lightness can be different, but there is no change (at the change time in the task) from whatever those absolute values are. At other points in these plots, the start and end colors can be different, but the magnitude and direction of the changes are the same. We also believe our stimulus diagrams for <xref ref-type="fig" rid="fig3">Figure 3F</xref> (and <xref ref-type="fig" rid="fig2">Figure 2A,C,E</xref>) may have confused this issue. They are meant to indicate the relative change in each condition, not the absolute change, and this was not clear. We have therefore explicitly labeled the diagrams to not that they indicate that they are the relative change in each primary in each condition.</p><disp-quote content-type="editor-comment"><p>The text states that the major axis of the ellipse corresponds to a line of &quot;constant saturation and lightness but varying hue&quot; in HSV space. I don't think this is accurate. If the purple ellipse passes through (0,0), then it would pass through a point of zero saturation (at least if I am correctly interpreting the top panel of <xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p></disp-quote><p>We greatly appreciate the reviewers pointing out of this error. This is in fact a total misrepresentation of HSL color space and the data, and it has been removed. We believe the major axis of the ellipse corresponds to an axis of saturation changes, collapsed across hues.</p><disp-quote content-type="editor-comment"><p><xref ref-type="fig" rid="fig3">Figure 3D</xref>. It is not clear how &quot;attempted compensation for relative short and middle band weights&quot; was performed, and specifically how this is reflected in the graph (how is <xref ref-type="fig" rid="fig3">Figure 3D</xref> different from <xref ref-type="fig" rid="fig3">Figure 3A</xref>?).</p></disp-quote><p>We have clarified the difference between <xref ref-type="fig" rid="fig3">Figure 3A</xref> and <xref ref-type="fig" rid="fig3">Figure 3D</xref> in both the Figure (by adding to the schematic in <xref ref-type="fig" rid="fig3">Figure 3D</xref>) and text (subsection “Can mice discriminate color changes?”). The “attempted compensation” was made based on the observed short:middle weights at each elevation in <xref ref-type="fig" rid="fig3">Figure 3C</xref>. We use the slopes of these lines to adjust the intensity of the green LED as a function of space. If the relative short:middle weights had remained the same after this adjustment, performance should have moved to the unity. This adjustment appears, not unexpectedly in retrospect, to have changed the relative rod:cone contribution and therefore the short:middle weight, though it did improve.</p><disp-quote content-type="editor-comment"><p>In <xref ref-type="fig" rid="fig3">Figure 3F</xref>, is 50% correct equivalent to &quot;chance&quot;? I'm inclined to believe this is so, but then what is the interpretation for the significant performance below chance at several elevations (and for equiluminant stimuli of low color contrast)?</p></disp-quote><p>In our task the level of chance performance is not fixed by the task design, but can vary depending on strategy the mouse uses. It is fully possible for the mouse to regularly lick regardless of whether they have actually detected a change. In this regime, they would often restart the trial and enter the ‘time-out’, but every trial in which they (by chance) licked after a change (regardless of perceptibility) would result in reward. In this sense, the animal could reach 100% performance simply by ignoring the task and guessing, and thus “chance” could be 100%. By including catch trials, in which there was no actual change, we can estimate false positive rate at each elevation. There is therefore no “below chance” performance at any elevation (except a little dip below the false alarm rate at low color contrast for elevations=30º and 50º, the dark blue and pink lines in <xref ref-type="fig" rid="fig3">Figure 3F</xref>, but these are small. One speculative interpretation of these dips is that below-threshold stimuli make the animal less likely to guess than no stimulus at all, possibly by adding uncertainty about whether there was a change or not, inhibiting the execution of a pure guess-after-some-time strategy).</p><disp-quote content-type="editor-comment"><p>And in the case where my interpretation is wrong, then how does one square the significant performance at the lowest elevation, at all color-contrast changes, with the performance on catch trials?</p></disp-quote><p>The observation that the false positive rate is very different at different elevations does require squaring. We believe that the increased false positive rate at the lowest elevation is due to a shift in guessing strategy by the mice correlated with the proportion of trials they can actually detect. At -10º, where the animal can’t detect many of the changes, the rate of guessing increases – the animal is willing to trade an increase in the number of time out penalties for an increase in false positive rewards. At the higher elevations, the animal is less willing to incur time outs, because a higher proportion of changes are detectable at these elevations. We went back and found the total number of rewards did not vary with elevation, even though the sensitivity varied, consistent with a change in strategy to maximize total volume of reward. We have added a brief discussion of this in the text (subsection “Can mice discriminate color changes?”).</p><disp-quote content-type="editor-comment"><p><xref ref-type="fig" rid="fig3">Figure 3G</xref>, shows that there is a set of stimuli defined by a ratio of S increment/M decrement (or M increment/S decrement) that is relatively invisible to the animals. The balance point of S/M is slightly different across the retina, with the more ventral visual field (dorsal retina) showing greater sensitivity to M than S, compared to the dorsal visual field. This suggests that the dorsal retina has a higher M:S ratio, which I believe is consistent with the cone-opsin distribution. Is this interpretation of the results correct? If so, aren't the behavioral data more consistent with the opsin distribution than the conclusions drawn by the authors?</p></disp-quote><p>This interpretation is correct, and we did not mean to suggest that our results are wholly inconsistent with the cone opsin distribution. Instead, we meant to highlight that the cone opsin distribution <italic>alone</italic> does not account completely for our results, both the relative increments/decrements required at each elevation (slopes of the ellipse major axes) and which elevations had the highest color sensitivity (change detectability along the major axes). We have changed some language throughout, and made this more explicit in the Introduction and in the Discussion section.</p><disp-quote content-type="editor-comment"><p>Reviewer 3 –</p><p>I found the last section of the Results, with the description of <xref ref-type="fig" rid="fig3">Figure 3D-G</xref> and how hue sensitivity was measured, quite unclear in several parts (see my specific &quot;minor&quot; comments below). This description should be more detailed and much clearer, in order for a reader to fully grasp the meaning and implications of their findings.</p></disp-quote><p>We apologize for the lack of detail and clarity, here and elsewhere. We have added more detail and rewritten much of this section to improve clarity subsection “Determination of relative short and middle wavelength band contributions at several retinotopic locations and comparison with predicted cone weights” and subsection “Can mice discriminate color changes?”).</p><disp-quote content-type="editor-comment"><p>I have trouble understanding the experiments and data analysis to measure the sensitivity to hue changes <xref ref-type="fig" rid="fig3">Figure 3D-G</xref>). Here is what I think I have understood and what I have not:</p><p>The authors want to test if mice can detect changes along the diagonal line of perceived equiluminance (i.e., simultaneous and opposite changes of luminance in the two channels that are not detected by the rats as an overall change of luminance). Since, as they show in <xref ref-type="fig" rid="fig3">Figure 3B-C</xref>, the perceived equiluminant line has not slope = 1, then the authors use this perceived line to measure hue sensitivity along it.… is this correct?</p></disp-quote><p>This is correct. We apologize for the lack of clarity in the Figure and our description of it. We have provided more detail and tried to clarify in the text and the figure.</p><disp-quote content-type="editor-comment"><p>Is this what they meant with <xref ref-type="fig" rid="fig3">Figure 3D</xref>? Or, instead, did they actually show combinations of the two channels that are along the unity line? In any event, I don't understand why the shape of the purple bar changes when going from <xref ref-type="fig" rid="fig3">Figure 3D</xref> to <xref ref-type="fig" rid="fig3">Figure 3E</xref>. Shouldn't the purple region have the same spear-like (not rectangular) shape of the region in <xref ref-type="fig" rid="fig3">Figure 3D</xref> (and of the data shown below in <xref ref-type="fig" rid="fig3">Figure 3E</xref>)? More importantly, about the color matrixes shown in <xref ref-type="fig" rid="fig3">Figure 3E</xref>: shouldn't these data just be the same of those already shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref> (just taking those points along the equiluminant line)? What is the difference? Are these actually data resulting from different experiments? And if so, why?</p></disp-quote><p>The data in <xref ref-type="fig" rid="fig3">Figures 3D-G</xref> are not the same as that shown in <xref ref-type="fig" rid="fig3">Figure 3A-C</xref>. The data in <xref ref-type="fig" rid="fig3">Figure 3B</xref> do indicate color sensitivity (along the equiluminance lines of not slope=1) at some elevations, but not at the lowest. However, we wanted to be sure that this observed color sensitivity was not due to some within-stimulus luminance gradient due the uniformity of the stimulus and gradient of opsins, even within the stimulus region, which was relativelity large (15º). So we took the equiluminance lines, obtained by fitting ellipses to the matrices in <xref ref-type="fig" rid="fig3">Figure 3B</xref>, and adjusted the green stimulus uniformity. We then performed more testing sessions under these adjusted conditions, resulting in the data presented in <xref ref-type="fig" rid="fig3">Figure 3D-G</xref>, with equiluminance lines closer to slope=1 and therefore less chance of any luminance gradient within the stimulus.</p><p>We have clarified the difference between panels <xref ref-type="fig" rid="fig3">Figure 3A and 3D</xref> in both the Figure (by adding to the schematic in <xref ref-type="fig" rid="fig3">Figure 3D</xref>) and text (subsection “Can mice discriminate color changes?”). The “attempted compensation” was made based on the observed short:middle weights at each elevation in <xref ref-type="fig" rid="fig3">Figure 3C</xref>. We use the slopes of these lines to adjust the intensity of the green LED as a function of space. If the relative short:middle weights had remained the same after this adjustment, performance should have moved to the unity. This adjustment appears, not unexpectedly in retrospect, to have changed the relative rod:cone contribution and therefore the short:middle weight, though it did improve.</p><disp-quote content-type="editor-comment"><p>Finally, are the curves shown in <xref ref-type="fig" rid="fig3">Figure 3F</xref> derived from the data matrixes of <xref ref-type="fig" rid="fig3">Figure 3E</xref>? Are the curves an average of the data around the unity line? Or around the perceptual equiluminant line? If so, how many data points of the matrixes in <xref ref-type="fig" rid="fig3">Figure 3E</xref> are used to obtain the curves of <xref ref-type="fig" rid="fig3">Figure 3F</xref>. In summary, this whole analysis needs far more details and explanations to be fully understandable?</p></disp-quote><p>The curves in <xref ref-type="fig" rid="fig3">Figure 3F</xref> are obtained along the lines in <xref ref-type="fig" rid="fig3">Figure 3E</xref>. These lines in 3F which are from ellipse fit like those in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. There are 20 points in these curves.</p><disp-quote content-type="editor-comment"><p>2) Comments about measurement of eye position:</p><p>The data suggest that the paradigm provides an accurate assessment of mouse visual ability. It is conceivable that the false-positive (false-alarm) response rate is not fixed, but changes depending on the detectability of the stimulus. It's not clear how this (or shifts in criterion) would impact the results.</p></disp-quote><p>The observation that the false-positive rate is not fixed, and that in our data it changes based on the overall detectability at that elevation, is astute. Indeed, we believe that the false-positive rate did rise for sets of stimuli with lower overall detectability – for example, the color-focused changes at -10º in <xref ref-type="fig" rid="fig3">Figure 3F</xref> (compare the green to other lines). Because we include catch trials as well as several other conditions that are likely below the detectability of the mouse, we believe the empirical measurement of false-positive rate is robust.</p><p>As you note, shifts in false-positive rate may impact estimation of the threshold. By using thresholds defined by a fit to the data, and allowing the offset and saturation parameters (subsection “Analysis”) the fit functions to be free should minimize the effect of the shifting false-positive rate. It is important that the false positive rate not be so high as to compress the range over which the true positive rates can be measured, but even in the case where performance was not distinguishable from the false positive rate (color discrimination at -10º, <xref ref-type="fig" rid="fig3">Figure 3F</xref>), false-positive rate remained below 50%. As such, we do not believe the shifting false positive rate affects our conclusions.</p><disp-quote content-type="editor-comment"><p>The authors show that the mice do not have systematically different eye positions across trial types, but it is important to show that the experimental technique could recover differences in eye positions if these differences existed. What is the resolution of the eye tracking compared to the measured eye movements made by the animals in the experiment?</p></disp-quote><p>We believe the eye tracking system had more than enough resolution to recover potential differences in gaze elevation across stimulus conditions. Individual eye movements ranged from ~2 – 30º (see example movements added to <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, and see below for more on the pixels-to-degrees conversion), and the eye tracker followed individual movements well large movements well. We have added an example period of eye tracking, which shows both the amplitude of these movements and the noise in the eye tracking. The frame-to-frame noise was ~1º [based on 95% of all frame-to-frame differences below 1º, for the right eye. Due to lower contrast in the eyetracking movie and higher magnification, the same measurement of the left eye was noiser, at &lt; 4º. This has also been included in the eye tracking figure. As has been noted by others (Niell and Stryker, 2013), there were more, and larger, eye movements in the horizontal/azimuthal direction than vertical/elevation.</p><disp-quote content-type="editor-comment"><p>The authors mention that they have used an eye tracker, which, I believe, is essential to allow them to make accurate predictions of perceptual sensitivity, based on the known opsins' retinal distributions. However, as I far as I understand, the eye tracker was not used systematically, but only in some control sessions, whose data were not those used to obtain the sensitivity measures. I wonder then how the authors can be sure about the position of the mouse eye during the main experimental sessions (it may change form session to session or during a session, making their prediction unreliable).</p></disp-quote><p>We cannot be absolutely sure that the eye position was the same in the main behavioral testing sessions as it was in our eyetracking sessions, as you rightly note that we did not include eyetracking during these sessions. Nonetheless, we believe the eyetracking session accurately reflect the eye positions during other behavioral testing sessions. The eyetracking sessions were completed under conditions as close to the testing sessions as possible – using the same stimulus conditions in the same immersive visual environment at the same time of day. Given the consistency of the result with the cone opsin distribution and the overall lack of vertical eye movements, we don’t see reason to expect such a difference between the eye tracking sessions and the majority psychophysical testing sessions.</p><disp-quote content-type="editor-comment"><p>In addition, the authors do not provide any details (or any specific reference) about the eye tracking method they use, especially how they calibrated the eye tracker. Such a calibration is always challenging in rodents (since they do not saccade to target locations over the stimulus display). The authors report that they are able to obtain measurers in degrees, but they do not explain at all how they convert pixels to degree (these clarifications about the eye data are essential if we have to believe their predictions).</p></disp-quote><p>We apologize for the lack of detail and have added more to the Materials and methods section of the paper and several panels to the eye tracking figure. Calibration by guiding the mouse’s eye movements to specific known points on the display is indeed well beyond what we can do with our behavioral control of these animals. As such, the eye tracker is not explicitly calibrated. Instead we convert to degrees based on the geometry of the cameras, the position of the pupil relative to the corneal reflections of infrared LEDs, and an orthographic projection of the 2D eyetracking image onto a sphere. We now describe this conversion from pixels to degrees in the text (subsection “Analysis”), but it is also copied below:</p><p>To convert the tracked pupil positions from pixel coordinates in the eye tracking images to visuotopic coordinates, we first converted the pixel coordinates to spherical coordinates using an orthographic projection of the image onto a sphere with a radius of 1.16mm, the reported radius if the mouse eye. Because the mouse was positioned in the center of the stimulus enclosure (see the diagrams in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>), which is also a sphere, the position of the pupil in these “eye” spherical coordinates can be converted to visuotopic coordinates by projecting the center of the “eye” sphere on to the visuotopic sphere. The reflection of an infrared LED off of the cornea indicated the center of each eye, and we use the placement of each mirror relative to the mouse (right eye: 51.2º in azimuth, 0º in elevation; left eye: 60º in azimuth and -10º in azimuth) to determine the direction of gaze. As such, the corneal reflection in each eye tracking movie indicates a known reference point in visuotopic space, determined by the relationship of the imaging plan to the eye sphere, and the difference between the corneal reflection and the pupil allows for estimation of gaze position in visual coordinates. Coordinates for eye position were extracted independently for each frame of the eye position movie. This calculation assumes that the center of both eyes are at the center of the visual stimulation dome, that each eye is a sphere, and that the movements of the eye are rotations about the center, none of which is strictly true. While left and right eye movies had different contrast and noise levels (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C-D</xref>), estimations of eye position in visual degrees brought disparate pixel measurement from each eye into good agreement with each other (compare y pixel measures to elevation in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>). We believe this calculation to be accurate enough for comparison of relative eye positions and, given the small displacement of the eyes from the center (&lt;1cm) of the dome (30 cm radius), reasonable for using published retinotopic distributions to estimate relative opsin distributions in visuotopic coordinates.</p><p>Because we cannot calibrate the system, we limit the eyetracking information to two uses: (1) a relative measurement of gaze, a crucial control that should not depend on the absolute accuracy of our calculation or the lack of calibration and (2) an interpretation of the opsin weight calculation that should be relatively insensitive to some error in this calculation. Even if our estimation of the retinotpoic-visuotpoic mapping was off in either direction, there would still be need to be more rod contribution to account for the observe middle-band sensitivity.</p><p>Finally, a specific reference for the eye tracking algorithm, to a technical white paper published on the Allen Institute website is provided in the text (the Allen Brain Observatory Visual Coding Overview v.4, June 2017 &lt;http://help.brain-map.org/display/observatory/Documentation&gt;).</p></body></sub-article></article>