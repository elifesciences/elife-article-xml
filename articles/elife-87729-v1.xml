<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">87729</article-id><article-id pub-id-type="doi">10.7554/eLife.87729</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87729.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A generative model of electrophysiological brain responses to stimulation</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-232714"><name><surname>Vidaurre</surname><given-names>Diego</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9650-2229</contrib-id><email>dvidaurre@cfin.au.dk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01aj84f44</institution-id><institution>Center for Functionally Integrative Neuroscience, Department of Clinical Medicine, Aarhus University</institution></institution-wrap><addr-line><named-content content-type="city">Aarhus</named-content></addr-line><country>Denmark</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Psychiatry, Oxford University</institution></institution-wrap><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Luo</surname><given-names>Huan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>17</day><month>01</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP87729</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-03-29"><day>29</day><month>03</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-03-13"><day>13</day><month>03</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.01.03.522583"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-05-31"><day>31</day><month>05</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87729.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-12-21"><day>21</day><month>12</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87729.2"/></event></pub-history><permissions><copyright-statement>© 2023, Vidaurre</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Vidaurre</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-87729-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-87729-figures-v1.pdf"/><abstract><p>Each brain response to a stimulus is, to a large extent, unique. However this variability, our perceptual experience feels stable. Standard decoding models, which utilise information across several areas to tap into stimuli representation and processing, are fundamentally based on averages. Therefore, they can focus precisely on the features that are most stable across stimulus presentations. But which are these features exactly is difficult to address in the absence of a generative model of the signal. Here, I introduce <italic>genephys</italic>, a generative model of brain responses to stimulation publicly available as a Python package that, when confronted with a decoding algorithm, can reproduce the structured patterns of decoding accuracy that we observe in real data. Using this approach, I characterise how these patterns may be brought about by the different aspects of the signal, which in turn may translate into distinct putative neural mechanisms. In particular, the model shows that the features in the data that support successful decoding—and, therefore, likely reflect stable mechanisms of stimulus representation—have an oscillatory component that spans multiple channels, frequencies, and latencies of response; and an additive, slower response with a specific (cross-frequency) relation to the phase of the oscillatory component. At the individual trial level, still, responses are found to be highly variable, which can be due to various factors including phase noise and probabilistic activations.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>stimulus processing</kwd><kwd>neural variability</kwd><kwd>genephys</kwd><kwd>generative model</kwd><kwd>brain responses</kwd><kwd>M/EEG</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100009708</institution-id><institution>Novo Nordisk Fonden</institution></institution-wrap></funding-source><award-id>NNF19OC-0054895</award-id><principal-award-recipient><name><surname>Vidaurre</surname><given-names>Diego</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010661</institution-id><institution>Horizon 2020 Framework Programme</institution></institution-wrap></funding-source><award-id>ERC-StG-2019-850404</award-id><principal-award-recipient><name><surname>Vidaurre</surname><given-names>Diego</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004440</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>215573/Z/19/Z</award-id><principal-award-recipient><name><surname>Vidaurre</surname><given-names>Diego</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010269</institution-id><institution>Wellcome Trust</institution></institution-wrap></funding-source><award-id>106183/Z/14/Z</award-id><principal-award-recipient><name><surname>Vidaurre</surname><given-names>Diego</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication. For the purpose of Open Access, the authors have applied a CC BY public copyright license to any Author Accepted Manuscript version arising from this submission.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Genephys is a generative model for dissecting the different aspects that compound our neural responses to perceptual stimulation, identifying which aspects remain stable and which ones vary across experimental repetitions.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>There are virtually infinite manners by which a constant stimulus can impinge into the sensorium of an animal. For instance, our noses have many receptors that can sense a given odorant molecule, but only a small subset of those are excited each time the odour is perceived (<xref ref-type="bibr" rid="bib1">Axel, 1995</xref>). Similarly, photons hit and excite photoreceptors in the retina randomly and sparsely for a given presented image (<xref ref-type="bibr" rid="bib7">Dowling, 1987</xref>). An important aspect of sensation and perception is that never the exact same receptors are excited every time we perceive and, still, our perceptual experiences feel quite stable. So the brain must have a way to transit from lack of invariance at the microscopic sensory level towards invariance at the macroscopic level, which ultimately supports the invariant aspects of conscious perception and behaviour. However, we observe significant variability in the brain responses at the trial level (<xref ref-type="bibr" rid="bib24">Stein et al., 2005</xref>; <xref ref-type="bibr" rid="bib19">McIntosh et al., 2008</xref>; <xref ref-type="bibr" rid="bib10">Garrett et al., 2013</xref>), including at the earliest layers of the perceptual hierarchy (<xref ref-type="bibr" rid="bib5">Croner et al., 1993</xref>; <xref ref-type="bibr" rid="bib9">Freeman, 1978</xref>)—that is, each perceptual experience is associated with a unique neural trajectory that does not repeat. How the gap between stability in subjective perception and the changing nature of brain responses is bridged is an important question in neuroscience. Here, I investigate the distributed aspects of brain activity that are most stable across experimental repetitions, and are therefore most likely to relate to stable perceptual experiences.</p><p>Decoding analysis uses multivariate machine-learning algorithms to predict the identity of the observed stimulus from brain data (<xref ref-type="bibr" rid="bib12">Haxby et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Stokes et al., 2015</xref>). This way, per time point, it estimates a function of the data that maximally discriminate between conditions, as well as a temporal measure of accuracy that reflects how much information the data convey about the stimuli per time point. The assessment, via decoding accuracy, of how the discriminative space changes throughout the trial offers a view of the properties of stimuli representation and processing. However, it is not straightforward to know what specific aspects of the signal cause the patterns of decoding accuracy that we observe in perceptual experiments. Without this capacity, it is hard to link these patterns to actual neural mechanisms.</p><p>To gain insight into what aspects of the signal underpin decoding accuracy, and therefore the most stable aspects of stimulus processing, I introduce a generative model of multichannel electrophysiological activity (e.g. electroencephalography[EEG] or magnetoencephalography [MEG]) that, under no stimulation, exhibits chaotic phasic and amplitude fluctuations; and that, when stimulated, responds by manipulating certain aspects of the data, such as ongoing phase or signal amplitude, in a stimulus-specific manner. Specifically, in every trial, each channel may or may not respond to stimulation, according to a certain probability. In the model, when a channel responds, it can do it in different ways: (1) by phase resetting the ongoing oscillation to a given target phase and then entraining to a given frequency, (2) by an additive oscillatory response independent of the ongoing oscillation, (3) by modulating the amplitude of the stimulus-relevant oscillations, or (4) by an additive non-oscillatory (slower) response. This (not exhaustive) list of effects was considered given previous literature (<xref ref-type="bibr" rid="bib23">Shah et al., 2004</xref>; <xref ref-type="bibr" rid="bib18">Mazaheri and Jensen, 2006</xref>; <xref ref-type="bibr" rid="bib17">Makeig et al., 2002</xref>; <xref ref-type="bibr" rid="bib27">Vidaurre et al., 2021</xref>), and each effect may be underpinned by distinct neural mechanisms. For example, it is not completely clear the extent to which stimulus processing is sustained by oscillations, and disentangling these effects can help resolving this question. I named this model <italic>genephys</italic> by <italic>gen</italic>erative model of <italic>e</italic>mpirical electro<italic>phys</italic>iological signals. Genephys is empirical in the sense that it purely accounts for features in the signal that are observable, without making assumptions about the underlying neurobiological causes; that is, it can generate signals that, with the right parametrisation, can share empirical properties with real data. In particular, when confronted with a decoding algorithm, the data generated by this model can show patterns of decoding accuracy with similar characteristics to what we observe in real data.</p><p>Given the effects that we observe in the stimulus processing literature, and using an example of visual perception as a reference, I observed that two different mechanisms can produce realistic decoding results as we see in real perception: either phase resetting to a stimulus-specific phase followed by frequency entrainment, or an additive oscillation (unrelated to the ongoing oscillations) with a stimulus-specific phase. Either way, a cross-frequency coupling effect is also necessary, where an additive slower response holds a specific phasic relation with the oscillatory (faster) response. Furthermore, the stimulus-related oscillation needs to span multiple channels, and have a diversity of frequencies and latencies of response across channels. Other experimental paradigms, including motor tasks and decision making, can be investigated with g<italic>enephys</italic>, which is publicly available as a Python package in PyPI <ext-link ext-link-type="uri" xlink:href="http://github.com/vidaurre/genephys">http://github.com/vidaurre/genephys</ext-link>; <ext-link ext-link-type="uri" xlink:href="http://genephys-doc.readthedocs.io/en/latest/">http://genephys-doc.readthedocs.io/en/latest/</ext-link>.</p></sec><sec id="s2" sec-type="methods"><title>Methods</title><sec id="s2-1"><title>A generative model of empirical electrophysiological signals: <italic>genephys</italic></title><p>While the system is unperturbed, <italic>genephys</italic> is based on sampling spontaneously varying instantaneous frequency and amplitude (i.e. square root of power) time series, <inline-formula><mml:math id="inf1"><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula>, respectively, that are analytically combined to form the sampled signal <inline-formula><mml:math id="inf3"><mml:mi>x</mml:mi></mml:math></inline-formula>. Amplitude and frequency are allowed to oscillate within ranges <inline-formula><mml:math id="inf4"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf5"><mml:msup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> . Instantaneous frequency here refers to angular frequency, from which we can obtain the ordinary frequency in Hertz as <inline-formula><mml:math id="inf6"><mml:mfrac><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula>, where <inline-formula><mml:math id="inf7"><mml:mi>F</mml:mi></mml:math></inline-formula> is the sampling frequency of the signal. Both <inline-formula><mml:math id="inf8"><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf9"><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> are sampled separately from autoregressive processes of order one, endowing them with chaotic, non-oscillatory dynamics. Specifically, given autoregressive parameters  <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and Gaussian-noise variables <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>,<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, I generate <inline-formula><mml:math id="inf13"><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf14"><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> for a given channel as<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p><p>Without stimulation, a phase time series <inline-formula><mml:math id="inf15"><mml:msup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msup></mml:math></inline-formula> is then built as<disp-formula id="equ5"><mml:math id="m5"><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></disp-formula><disp-formula id="equ6"><mml:math id="m6"><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup></mml:math></disp-formula></p><p>Then, given some Gaussian-distributed measurement noise <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with standard deviation <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , I build <inline-formula><mml:math id="inf18"><mml:mi>x</mml:mi></mml:math></inline-formula> (in absence of stimulation) as<disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>This process is done separately per channel and per trial. Note that, under no stimulation, the channel time series are (asymptotically) uncorrelated. We can think of them as dipoles in brain space. We can induce correlations for instance by projecting these time series onto a higher-dimensional space, which we can consider to be in sensor space, or by using correlated noise. Altogether, this generates chaotic oscillatory data relatively akin to real data.</p><p>When a stimulus <italic>k</italic> is presented at time point <italic>τ</italic> of the trial, a perturbation is introduced into the system on the <inline-formula><mml:math id="inf19"><mml:mi>p</mml:mi></mml:math></inline-formula> channels that are stimulus relevant (which can be a subset of the total number of channels). When a channel is not relevant, it does not respond; when it is relevant, it responds to the stimulus with a given probability:</p><list list-type="simple"><list-item><p>Prob (channel <italic>j</italic> responds | channel <italic>j</italic> is relevant) = <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></p></list-item><list-item><p>Prob (channel <italic>j</italic> responds | channel <italic>j</italic> is not relevant) = 0</p></list-item></list><p>where <inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is a hyperparameter representing a channel-specific probability. In simpler words, relevant channels might respond in some trials, but not in others. In all the simulations, I set all channel probabilities to a single value, <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>θ</mml:mi></mml:math></inline-formula>, but other configurations are possible.</p><p>Given some stimulus presentation at time point <inline-formula><mml:math id="inf23"><mml:mi>τ</mml:mi></mml:math></inline-formula>, a channel may respond:</p><list list-type="simple"><list-item><p>- By phase resetting to a condition-specific target phase, and then, when the target phase is reached, by frequency entraining to a given target frequency.</p></list-item><list-item><p>- By adding a transient (damped), oscillatory response with a condition-specific phase, amplitude, and frequency.</p></list-item><list-item><p>- By increasing the (absolute) amplitude of the ongoing oscillation following stimulus presentation (with no phase effect).</p></list-item><list-item><p>- By adding a transient, non-oscillatory response with a condition-specific amplitude.</p></list-item></list><p>The timing of the effect is controlled by a response function. I use an double logarithmic response function, asymmetric around the time of maximum effect <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> . For the left side (i.e. before <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), this function is parametrised by: <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , reflecting the latency of the response in number of time points; and <inline-formula><mml:math id="inf27"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , reflecting how many time points it takes the logarithmic function to go from zero to its maximum before it changes to the right-side logarithmic function. Therefore, <inline-formula><mml:math id="inf28"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:math></inline-formula>. I introduce some noise in <inline-formula><mml:math id="inf29"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> per trial to make the timing of the response to vary, as per <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>Uniform</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , where <inline-formula><mml:math id="inf31"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> is a model hyperparameter. This latency noise could be fixed for all channels (absolute stochastic latency) or has a value per channel (relative stochastic latency; <xref ref-type="bibr" rid="bib27">Vidaurre et al., 2021</xref>). It is also possible to use different response function parametrisations per channel. For example, we can induce a diversity of latencies for the different channels by using different values of <inline-formula><mml:math id="inf32"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> per channel, so that some channels (e.g. those more closely related to primary sensory areas) respond earlier than others (e.g. those related to associative areas). Once the activation reaches its maximum at <inline-formula><mml:math id="inf33"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> , the decay is also parametrised by a logarithmic function with a parameter <inline-formula><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , reflecting how many time points it takes the logarithmic function to go from its maximum (at <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula>) to zero. A different response function can be used for each type of effect, which can be combined. The next subsection provides a full mathematical specification of the response function.</p><p>With respect to the phase reset and frequency entrainment effect, the phase reset occurs before <inline-formula><mml:math id="inf36"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> , when the target phase is reached. Given condition or stimulus <italic>k</italic>, for each trial and channel,<disp-formula id="equ8"><mml:math id="m8"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>with<disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false"><mml:mtr><mml:mtd><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext>i</mml:mtext><mml:mtext>f</mml:mtext><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mtext>i</mml:mtext><mml:mtext>f</mml:mtext><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>π</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mtext>i</mml:mtext><mml:mtext>f</mml:mtext><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>π</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where, for each trial, <inline-formula><mml:math id="inf37"><mml:msup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is randomly sampled from a von Mises distribution with mean equal the target phase <inline-formula><mml:math id="inf38"><mml:mover accent="false"><mml:mrow><mml:msup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> and standard deviation <inline-formula><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> ; <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the polar gradient between the target phase and the ongoing phase <inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> ; and <inline-formula><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the value taken by the response function at time point <inline-formula><mml:math id="inf43"><mml:mi>t</mml:mi></mml:math></inline-formula>. After <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> , phase resetting is over, and the phase entrainment period starts,<disp-formula id="equ10"><mml:math id="m10"><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup></mml:math></disp-formula></p><p>The system then entrains to a possibly stimulus-specific, possibly channel-specific, target frequency <inline-formula><mml:math id="inf45"><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>, with a strength that logarithmically decreases as <inline-formula><mml:math id="inf46"><mml:mi>t</mml:mi></mml:math></inline-formula> moves away from <inline-formula><mml:math id="inf47"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> .</p><p>With respect to the additive oscillatory response, we consider a sinusoidal oscillator, which is damped by the action of the response function <inline-formula><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>:<disp-formula id="equ11"><mml:math id="m11"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mtext>sin</mml:mtext><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf49"><mml:msup><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> reflects the amplitude of the additive oscillation, <inline-formula><mml:math id="inf50"><mml:msup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> its frequency, and <inline-formula><mml:math id="inf51"><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> its phase.</p><p>For the amplitude modulation, I apply a multiplying factor to the ongoing amplitude time series:<disp-formula id="equ12"><mml:math id="m12"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>rest</mml:mtext></mml:mrow></mml:msubsup></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf52"><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a proportional increment; for example, <inline-formula><mml:math id="inf53"><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math></inline-formula> would produce an increment of 10% in amplitude at <inline-formula><mml:math id="inf54"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> .</p><p>With respect to the additive non-oscillatory response, we have:<disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf55"><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is sampled from a Gaussian distribution, <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , where <inline-formula><mml:math id="inf57"><mml:mover accent="false"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> is stimulus specific.</p><p>Given these elements, the signal is built as<disp-formula id="equ14"><mml:math id="m14"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>This model can be trivially extended to have correlated noise <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> across channels.</p><p><xref ref-type="fig" rid="fig1">Figure 1</xref> shows two examples of how the effect of stimulation looks for one trial and one channel. The left panel corresponds to a phase resetting plus frequency entrainment effect, and the middle panel corresponds to an additive oscillation; both are accompanied by an additive non-oscillatory response. Here, the sampled signal <inline-formula><mml:math id="inf59"><mml:mi>x</mml:mi></mml:math></inline-formula> is shown in blue on top, and the phase <inline-formula><mml:math id="inf60"><mml:mi>φ</mml:mi></mml:math></inline-formula>, frequency <inline-formula><mml:math id="inf61"><mml:mi>f</mml:mi></mml:math></inline-formula>, amplitude <inline-formula><mml:math id="inf62"><mml:mi>a</mml:mi></mml:math></inline-formula>, additive non-oscillatory response <inline-formula><mml:math id="inf63"><mml:mi>z</mml:mi></mml:math></inline-formula>, and additive oscillatory response <inline-formula><mml:math id="inf64"><mml:mi>y</mml:mi></mml:math></inline-formula> are shown in red underneath. For comparison, the right panel shows real MEG data from a passive visual experiment where a number of images are shown to the subjects at a rate of one image per second (<xref ref-type="bibr" rid="bib4">Cichy et al., 2016</xref>); the measured (filtered) signal is shown in blue, while the red curves correspond to analytical phase, frequency, and amplitude (computed via the Hilbert transform on the filtered signal). <xref ref-type="table" rid="table1">Table 1</xref> summarises all the hyperparameters that configure the model.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Left and middle: single-trial example of the generated signal (in blue) and its constitutive components (in red): instantaneous phase, frequency, and amplitude, as well as an additive non-oscillatory and oscillatory response components; the left panel reflects a phase resetting plus frequency entrainment effect, while the middle panel corresponds to an additive oscillatory response.</title><p>Right: real (filtered) magnetoencephalography data collected during passive stimuli viewing; the red curves are the analytically computed phase, frequency, and amplitude (via the Hilbert transform).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig1-v1.tif"/></fig><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title><italic>genephys</italic> configuration hyperparameters.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Parameter</th><th align="left" valign="top">Math. notation</th></tr></thead><tbody><tr><td align="left" valign="top">Frequency autoregressive parameter</td><td align="left" valign="top"><inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Amplitude autoregressive parameter</td><td align="left" valign="top"><inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Frequency range</td><td align="left" valign="top"><inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Amplitude range</td><td align="left" valign="top"><inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Measurement noise standard deviation</td><td align="left" valign="top"><inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Channel activation probability</td><td align="left" valign="top"><inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Number of relevant channels</td><td align="left" valign="top"><inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Response function—latency</td><td align="left" valign="top"><inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Response function—rise slope</td><td align="left" valign="top"><inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Response function—fall slope</td><td align="left" valign="top"/></tr><tr><td align="left" valign="top">Target phase, mean</td><td align="left" valign="top"><inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Target phase, standard deviation</td><td align="left" valign="top"><inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Additive oscillatory response, phase</td><td align="left" valign="top"><inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Additive oscillatory response, amplitude</td><td align="left" valign="top"><inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Additive oscillatory response, frequency</td><td align="left" valign="top"><inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>ω</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Amplitude modulation</td><td align="left" valign="top"><inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Additive non-oscillatory response, mean</td><td align="left" valign="top"><inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="top">Additive non-oscillatory response, standard deviation</td><td align="left" valign="top"><inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></sec><sec id="s2-2"><title>A full mathematical description of the response function</title><p>Assuming the stimulus was presented at time point <italic>τ</italic> within a given trial, and that both <inline-formula><mml:math id="inf82"><mml:mi>t</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf83"><mml:mi>τ</mml:mi></mml:math></inline-formula> are expressed in number of time points, the response function is asymmetric around <inline-formula><mml:math id="inf84"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> , when the function takes the value 1.0 from both sides. In the experiments above, both left and right parts are logarithmic. Mathematically,<disp-formula id="equ15"><mml:math id="m15"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:math></disp-formula><disp-formula id="equ16"><mml:math id="m16"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>ς</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ17"><mml:math id="m17"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>ς</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ18"><mml:math id="m18"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ19"><mml:math id="m19"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">t</mml:mi><mml:mo>&gt;</mml:mo><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where</p><p>- <inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> reflects the latency of the response in number of time points,</p><p>- <inline-formula><mml:math id="inf86"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is how many time points it takes the left logarithmic function to go from 0.0 to 1.0,</p><p>- <inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is how many time points it takes the right logarithmic function to go from 1.0 to 0.0,</p><p>- <inline-formula><mml:math id="inf88"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi></mml:math></inline-formula> is the time point of maximum response (i.e. the changing point between the two functions),</p><p>- <inline-formula><mml:math id="inf89"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf90"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf91"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , and <inline-formula><mml:math id="inf92"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are normalisation constants chosen such that the logarithmic functions are bounded between 0.0 and 1.0, and <inline-formula><mml:math id="inf93"><mml:mi>G</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:math></inline-formula> from both sides,</p><p>- <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>ς</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>ς</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> determine the shape of the logarithmic functions (here chosen to 2 and 4, respectively).</p><p>Note that, thanks to the normalisation constants, both the left and the right sides of the response function take values between 0.0 and 1.0. There is also the possibility of using an exponential function—which is faster to decay—in either side, but I did not use it in the experiments. For example, in the left part, this would take the form:<disp-formula id="equ20"><mml:math id="m20"><mml:mrow><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>0.5</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>τ</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:mrow></mml:msup><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf95"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are normalisation constants.</p></sec><sec id="s2-3"><title>Decoding accuracy to characterise structured invariance</title><p>One possible approach to characterise the stable aspects of brain responses to stimulation is the analysis of average evoked responses potentials or fields (ERP/F) (<xref ref-type="bibr" rid="bib6">Dawson, 1954</xref>; <xref ref-type="bibr" rid="bib16">Luck and Kappenman, 2011</xref>; <xref ref-type="bibr" rid="bib21">Pfurtscheller and Lopes da Silva, 1999</xref>). However, this approach is limited because perceptual experiences emerge from activity patterns across multiple brain areas acting in a distributed fashion, whereas ERP/Fs are separately evaluated channel by channel. Also, ERP/F analyses are not concerned with what aspects of the signal carry specific information about the stimulus—that is they are not predictive of the stimulus (<xref ref-type="bibr" rid="bib14">Kragel et al., 2018</xref>).</p><p>I instead focus on decoding, which finds, in a multivariate fashion, patterns of differential activity between conditions across channels and throughout time (<xref ref-type="bibr" rid="bib11">Grootswagers et al., 2017</xref>). I use linear discriminant analysis, which estimates a projection or subspace in the data that maximally discriminate between conditions. Throughout the trial, this set of projections reflects information about the dynamics of stimulus processing.</p><p>As the read-out of decoding analysis, I use the temporal generalisation matrix (TGM), a <italic>T</italic> × <italic>T</italic> matrix of decoding accuracies (where <italic>T</italic> is the number of time points in the trial), such that one decoding model is trained per time point and tested on every time point of the trial using cross-validation (<xref ref-type="bibr" rid="bib13">King and Dehaene, 2014</xref>). The diagonal of the TGM reflects how well we can decode information time point by time point, while the off-diagonal shows how well decoding models generalise to time points different from those where they were trained. As illustrated in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, where I show a real-data TGM from a subject performing a simple visual task (<xref ref-type="bibr" rid="bib4">Cichy et al., 2016</xref>), the TGM exhibits some characteristic features that we often see throughout the literature. First, there is a strong diagonal band that is relatively narrow early in the trial, often surrounded by areas of worse-than-baseline accuracy. Then, the accuracy on the diagonal becomes progressively wider and weaker, expanding until relatively late in the trial. Also, there are bands of higher-than-baseline accuracy stemming vertically and horizontally from the time points of maximum accuracy (after a brief period of depression), which often show oscillatory behaviour throughout the band. <xref ref-type="fig" rid="fig2">Figure 2B</xref> presents TGMs from six subjects, where these features can also be appreciated yet with substantial variability across subjects. Below, I explore <italic>genephys</italic>’ configuration space in relation to its ability to produce patterns of decoding accuracy similar to these that we observe in real data.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Empirical decoding results from (real) data, where subjects underwent a passive viewing experiment.</title><p>(<bold>A</bold>) One example subject’s temporal generalisation matrix (TGM), where the different characteristic features have been highlighted. (<bold>B</bold>) TGMs from six example subjects.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig2-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="results"><title>Results</title><p>I confronted <italic>genephys</italic> to classification-based decoding analysis to characterise how brain activity carries stimulus-specific information. In each simulation, I generated 10 data sets per combination of parameters, each with <italic>N</italic> = 250 trials and <italic>T</italic> = 250 time points per trial (1 s for a sampling frequency of 250 Hz). The number of channels is 32. Only one endogenous oscillation was sampled, with (angular) frequencies spontaneously ranging between 0.01 and 0.25π (0.4–10 Hz). I computed a TGM per run and took the average across runs.</p><p>For reference, I considered MEG data recorded while participants viewed object images across 118 categories, as presented in <xref ref-type="bibr" rid="bib4">Cichy et al., 2016</xref>. Each image category was presented 30 times. Presentation occurred during the first 500 ms of the trial, and trials were 1 s long, sampled at 250 Hz. The multi-channel sensor-space data, epoched around the presentation of each visual stimulus, can be used to train a decoder to predict which visual image is being presented (<xref ref-type="bibr" rid="bib4">Cichy et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Vidaurre et al., 2021</xref>). Here, I decoded whether the image corresponded to an animate category (a dog) or inanimate (a pencil). <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows a TGM for an example subject, where some archetypal characteristics are highlighted. In the experiments below, specifically, I focus on the strong narrow diagonal at the beginning of the trial, the broadening of accuracy later in the trial, and the vertical/horizontal bars of higher-than-chance accuracy. Importantly, given the variability observed across subjects (as seen in <xref ref-type="fig" rid="fig2">Figure 2B</xref>, which shows TGMs for six subjects), this example is only meant as a reference; therefore I did not optimise the model hyperparameters to this TGM (except in the last subsection), or showed any quantitative metric of similarity.</p><sec id="s3-1"><title>Oscillatory components underlying the observed decoding patterns</title><p>In real data, we often see oscillatory patterns in the TGM, indicating that the subspace of brain activity that carries information about the stimulus must have oscillatory elements. At least two distinct mechanisms may be behind this phenomenon: first, an ongoing oscillation might reset its phase and then entrain to a given frequency in a stimulus-specific fashion; second, a stimulus-specific oscillatory response might by added to the signal after stimulus presentation on top of the existing ongoing oscillation. Essentially, the difference between the two is that, in the phase-resetting case, the ongoing oscillations are altered; while in the other case the additive oscillation coexists with the ongoing oscillations. Next, I use <italic>genephys</italic> together with decoding analysis to compare between these two alternatives, showing that both can produce decoding patterns similar to what we observe empirically in real experiments.</p><p>In the simulations, all 32 channels convey information but with a relatively low activation probability (<inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>). For phase resetting and frequency entrainment, I considered a diverse range of entrainment frequencies (between 0.1 and 0.2 in angular frequency) and latencies of response (<inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>−</mml:mo><mml:mn>160</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) across channels. For the additive oscillatory response, I considered a similar range of frequencies and latencies of response across channels. (I will show below that channel stochasticity and frequency diversity are both important to produce realistic decoding patterns.) The difference between the two fictitious stimuli lied in their different target frequencies (i.e. <inline-formula><mml:math id="inf99"><mml:mover accent="false"><mml:mrow><mml:msup><mml:mrow><mml:mi>φ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> for phase resetting and <inline-formula><mml:math id="inf100"><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> for the additive oscillation; see specification of the model in Methods). I also included an additive non-oscillatory response with a stimulus-specific amplitude, which (as I will also show later) is important to produce realistic decoding results. I did not optimise the parameters of the model to reflect the fine details from real-data TGMs, since TGMs vary across subjects (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>) and experimental paradigms (<xref ref-type="bibr" rid="bib13">King and Dehaene, 2014</xref>).</p><p><xref ref-type="fig" rid="fig3">Figure 3</xref> shows TGMs (top) together with one-channel ERPs (where each stimulus is represented by a different tonality of blue or red; bottom) for the sampled signal <inline-formula><mml:math id="inf101"><mml:mi>x</mml:mi></mml:math></inline-formula> and its various constitutive elements: ongoing phase <inline-formula><mml:math id="inf102"><mml:mi>φ</mml:mi></mml:math></inline-formula>, frequency <inline-formula><mml:math id="inf103"><mml:mi>f</mml:mi></mml:math></inline-formula>, amplitude <inline-formula><mml:math id="inf104"><mml:mi>a</mml:mi></mml:math></inline-formula>, additive non-oscillatory response <inline-formula><mml:math id="inf105"><mml:mi>z</mml:mi></mml:math></inline-formula>, and, when applicable, an additive oscillatory response <inline-formula><mml:math id="inf106"><mml:mi>y</mml:mi></mml:math></inline-formula>. The left panels show results for phase reset plus frequency entrainment, where we can see an effect on the ongoing phase. The middle panels show results for the additive oscillation; here, there is no effect on the ongoing phase, and, instead, the additive oscillatory response <inline-formula><mml:math id="inf107"><mml:mi>y</mml:mi></mml:math></inline-formula> is shown at the bottom. The right panels show an example from real data, where phase, frequency, and amplitude were computed analytically using the Hilbert transform on the filtered data.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Examples of two configurations based on phase resetting and frequency entrainment (left) and additive oscillatory responses (middle), shown together with results obtained from real data (right).</title><p>The top panels show temporal generalisation matrices (TGMs) from standard decoding analysis. The bottom panels show average evoked responses (ERP/F) for the sampled signal (blue) and its components (red); the two stimuli are represented with different tonalities of blue or red.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig3-v1.tif"/></fig><p>Although the exact details differ from the right panels of the figure, both types of effects produce patterns reproducing the characteristic signatures of real data. These include the strong diagonal, the vertical/horizontal bands of high generalisation accuracy, and the broadening of accuracy in later stages of the trial. Note that phase resetting plus frequency entrainment is, everything else held constant, a stronger effect than the additive oscillatory response. This is because, for the latter, the ongoing oscillations (here, non-stimulus specific) can interfere with the phase of the additive response, impeding cross-trial phase locking throughout the trial. For phase resetting, on the other hand, the ongoing oscillation <italic>is</italic> the effect and there is no interference. In this particular example, anyway, the range for the additive oscillation (0.1–0.2) was much narrower than that of the ongoing oscillation (0.01–0.25π), making the interference more unlikely; that is, the ongoing oscillation phase is approximately averaged out, and treated as noise by the decoding algorithm.</p></sec><sec id="s3-2"><title>The distribution of stimulus-specific information spans multiple channels and is stochastic</title><p>Next, I use <italic>genephys</italic> to show that the stimulus-specific information spans a large number of channels, and do so stochastically. I focus on the additive oscillatory response effect, which, as shown in the previous section, can produce comparable results to phase resetting plus frequency entrainment.</p><p>I varied the number of relevant channels <inline-formula><mml:math id="inf108"><mml:mi>p</mml:mi></mml:math></inline-formula> as well as the probability of activation <inline-formula><mml:math id="inf109"><mml:mi>θ</mml:mi></mml:math></inline-formula> for the relevant channels, so that the subset of channels that activate is different for every trial. <xref ref-type="fig" rid="fig4">Figure 4</xref> shows the TGMs for various combinations of <inline-formula><mml:math id="inf110"><mml:mi>p</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf111"><mml:mi>θ</mml:mi></mml:math></inline-formula>, from a configuration where there are few relevant channels that always respond (<inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) to another where there are many relevant channels that only respond sparsely (<inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). As previously, channels have diverse frequencies and latencies of response. An additive non-oscillatory response is also included as an effect.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Having more dimensions (channels) carrying stimulus-specific information, but with a larger degree of stochasticity, produces more realistic decoding patterns than having fewer dimensions with a lower degree of stochasticity.</title><p>Here, stochasticity referred to the channels’ probability of activation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig4-v1.tif"/></fig><p>Contrary to empirical TGMs (which have a relatively stylised diagonal), having only a few relevant channels (first three panels of <xref ref-type="fig" rid="fig4">Figure 4</xref>) produces unrealistically geometric patterns. This indicates that, in real data, the subspace of the data that contains information about the stimulus needs to be multi-dimensional; that is, that the amount of relevant channels must be relatively high (as in the fourth panel of <xref ref-type="fig" rid="fig4">Figure 4</xref>). However, the contribution of each channel must entail some sort of noise or instability (in this case expressed by having probabilistic activations), or else the decoding accuracy becomes unrealistically perfect. In summary, the subspace of brain activity that carries out information about the condition is highly stochastic at the single-trial level.</p></sec><sec id="s3-3"><title>The oscillatory effect spans multiple frequencies and latencies</title><p>In the previous sections, I showed that a noisy, additive oscillation effect (or, alternatively, a phase reset plus frequency entrainment effect) across multiple channels can generate decoding patterns as we see in real data. Next, I demonstrate that the effect must span a diversity of frequencies across channels, as well as a diversity of latencies of response. In real data, frequency diversity can be expressed as, for example, a gradient of frequencies from primary towards more associative areas; while latency diversity could reflect phenomena such that primary areas responding earlier than associative areas.</p><p>For frequency diversity, each channel is endowed with a different effect-related frequency, such that frequencies are not multiples of each other (specifically, they have different values of <inline-formula><mml:math id="inf114"><mml:msup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> between 0.1 and 0.2 in angular frequency; see Methods). For latency diversity, channels do not respond simultaneously but with different values of <inline-formula><mml:math id="inf115"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> between 0 and 120 ms. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows a two-by-two design. On the left column, I set <italic>genephys</italic> to have a uniform frequency of response (i.e. all channels have the same frequency of response), while on the right column it uses a diversity of frequencies. On the top row, we have a uniform latency of response (i.e. all channels have the same latency of response), whereas on the bottom row we have a diversity of latencies of response. See <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for a similar result for phase resetting followed by frequency entrainment.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Oscillatory responses to stimulation occur in a diversity of frequencies and latencies across channels.</title><p>Top row, single latency of response; bottom row, diverse latencies across channels. Left column, single frequency; right column, diverse frequencies across channels. Bottom-right is the most realistic temporal generalisation matrix (TGM).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Phase reset plus frequency entrainment effect.</title><p>Top row, single latency of response; bottom row, diverse latencies across channels; left column, single frequency; right column; diverse frequencies across channels.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig5-figsupp1-v1.tif"/></fig></fig-group><p>As mentioned, real data normally yield a relatively tight band of high decoding accuracy along the diagonal, often accompanied from contiguous parallel bands of below-baseline accuracy. Critically, the fact that we do not typically observe a chequer pattern means that the trajectory of phase across channels does not repeat itself periodically. If it did, it would show patterns as in the top-left panel, where the uniformity of frequencies and latencies gives rise to an unrealistically regular pattern—such that a decoder trained at a certain time point will become equally accurate again after one cycle at the entrained frequency. Having a diversity of latencies but not of frequencies produces another regular pattern consisting of alternating, parallel bands of higher/lower than baseline accuracy. This, shown in the bottom-left panel, is not what we see in real data either. Having a diversity of frequencies but not of latencies gets us closer to a realistic pattern, as we see in the top-right panel. Finally, having diversity of both frequencies and latencies produces the most realistic pattern, as we can see by comparing to the examples in <xref ref-type="fig" rid="fig2">Figure 2</xref>, and many others throughout the literature (<xref ref-type="bibr" rid="bib13">King and Dehaene, 2014</xref>). Similar conclusions can be drawn from <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for phase resetting plus frequency entrainment.</p><p>In summary, these results show that it is not only important for the stimulus-relevant subspace of activity to be spatially high dimensional, but also temporally high dimensional.</p></sec><sec id="s3-4"><title>A slower additive component is coupled with the oscillatory response</title><p>In real data, we normally see a broadening of decoding accuracy in the TGM as time progresses throughout the trial (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). This is often interpreted as neural representations becoming more stable at latter stages of the trial, which is putatively linked to memory encoding and higher cognitive processes. In <xref ref-type="fig" rid="fig6">Figure 6</xref>, I show that this effect can be reproduced on synthetic data through the addition of a slowly progressing, non-oscillatory response.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>An additive non-oscillatory response is needed to produce realistic temporal generalisation matrices (TGMs) with a broadening of decoding accuracy at later stages of the trial.</title><p>(<bold>A</bold>) By increasing the strength of the non-oscillatory response, the broadening of accuracy becomes more prominent. (<bold>B</bold>) Changing the nature of the phasic relationship between the slower and the faster (oscillatory component) greatly influences the TGM, from having all channels in-phase (left) towards having all channels anti-phase (right).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig6-v1.tif"/></fig><p>Specifically, I set up a response function such that, after stimulus presentation, the non-oscillatory additive response ramps up to a stimulus-specific target value in about 100 s, and then slowly decays to finally vanish at around 800 ms. Also, I modulate the strength of the oscillatory response using values of <inline-formula><mml:math id="inf116"><mml:mover accent="false"><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> (see Methods) that differ between the two stimuli by a magnitude that ranges from 0.0 (no difference) to 1.0 (for reference, the examples in the previous figures had a difference of 0.5). As seen in <xref ref-type="fig" rid="fig6">Figure 6A</xref>, the strength of decoding accuracy grows as the difference in the slow response increases.</p><p>Another feature commonly seen on real data are the vertical and horizontal bars of high accuracy stemming from the time point of maximum accuracy (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>), which is sometimes interpreted as evidence of stimulus representation recurrence in the brain. I show in <xref ref-type="fig" rid="fig6">Figure 6B</xref> that this feature emerges from a phase coupling between the oscillatory component and the slower component (with respect to the stimuli). For example, following the notation established in Methods, an in-phase relationship means that the sign of <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> at <inline-formula><mml:math id="inf118"><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula> is the same than the sign of <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Note that the sign of <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> will likely be maintained for most of the trial since this component is slow, therefore creating the effect in the TGM. That was the case for all panels of <xref ref-type="fig" rid="fig6">Figure 6A</xref>. For <xref ref-type="fig" rid="fig6">Figure 6B</xref>, while keeping <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> = 0.5 (as in the middle panel of <xref ref-type="fig" rid="fig6">Figure 6A</xref>), I varied the phase consistency between the oscillatory and the non-oscillatory components. In the leftmost panel, the oscillatory and the non-oscillatory components are in-phase for all channels, while in the rightmost panel, they are anti-phase for all channels; in between, 25%, 50%, and 75% of the channels are in-phase (and 75%, 50%, and 25% are anti-phase, respectively). As observed, the type of phase consistency between the oscillatory and the non-oscillatory component has a strong impact on the TGM. In particular, the in-phase relation bears the most consistent patterns with the considered real data.</p></sec><sec id="s3-5"><title>Amplitude increases modulate the size of the effect</title><p>Are modulations in the amplitude of the stimulus-specific oscillation necessary for the effects we observe in real data? They are not, but they can enhance the already existing patterns.</p><p>I generated data sets with an additive oscillatory component effect. In each of them, I applied a different amount of amplitude enhancement, from no increase to a fivefold increase. These did not entail any effect on the signals’ phase. I considered two characteristic features of the TGM: (1) the diagonal, and (2) a vertical slice stemming from the time point of maximum accuracy. <xref ref-type="fig" rid="fig7">Figure 7</xref> shows the results. As observed, the main features are present in all runs regardless of the size of the amplitude effect, although they were more prominent for higher amplitude modulations. An amplitude modulation on a phase-resetting effect causes a similar effect (not shown). Note that an amplitude effect without a phase effect would not result in any phase locking across trials, and therefore could not lead to any significant decoding accuracy.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Enhancing the amplitude of the stimulus-relevant oscillation is not strictly necessary to produce realistic temporal generalisation matrices (TGMs), but it can enlarge the effects.</title><p>Two features of the TGM are highlighted: the diagonal, and a vertical slice at the time point of maximum accuracy.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig7-v1.tif"/></fig></sec><sec id="s3-6"><title>Fitting an empirical TGM</title><p>The previous analyses were descriptive in the sense that they did not quantify how much the generated TGMs resembled a specific empirical TGM. This was deliberate, because empirical TGMs vary across subjects and experiments, and I aimed at characterising them as generally as possible by looking at some characteristic features in broad terms. For example, while TGMs typically have a strong diagonal and horizontal/vertical bars of high accuracy, questions such as when these effects emerge and for how long are highly dependent on the experimental paradigm. For the same reason, I did not optimise the model hyperparameters, limiting myself to observing the behaviour of the model across some characteristic configurations. But, often, one’s interests are more specific. Then, it would be interesting to optimise some key hyperparameters of the model to maximise the correlation with a particular empirical TGM.</p><p>To illustrate how a data set could be more explicitly considered, I took an empirical TGM computed from the visual experiment in <xref ref-type="bibr" rid="bib4">Cichy et al., 2016</xref>. Specifically, this is a cross-average TGM (over 10 subjects) obtained from decoding animate versus inanimate stimuli. Using an additive oscillatory response, and fixing the rest of the hyperparameters to a sensible configuration (the one that produced the middle panel in <xref ref-type="fig" rid="fig6">Figure 6A</xref>), I varied, within a reasonable range, two parameters of the response function that control the temporal shape of the effect: the rise slope <inline-formula><mml:math id="inf122"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and the fall slope <inline-formula><mml:math id="inf123"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> ; see Methods. From each pair of parameters, I generated 10 data sets and computed 10 TGMs; I then correlated the average of these with the empirical TGM from real data. <xref ref-type="fig" rid="fig8">Figure 8</xref> shows a heatmap of the resulting correlations. For a specific configuration (<inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.06</mml:mn><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.09</mml:mn><mml:mi>s</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), the correlation peaks at <italic>r</italic> = 0.7.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Correlation between an empirical temporal generalisation matrix (TGM) and the sampled TGM (averaged across 10 runs of the simulation) across a range of configurations of the response function, which defines the temporal dynamics of the effect.</title><p>The maximum correlation with the empirical TGM is slightly over 0.7.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-87729-fig8-v1.tif"/></fig></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>Brain’s responses to even the simplest stimuli are characteristically variable. This is not surprising, given the brain’s plasticity, and the fact that its endogenous activity is ever-changing. It also speaks to the brain’s degeneracy (<xref ref-type="bibr" rid="bib8">Edelman and Gally, 2001</xref>)—that is that there are many possible neural trajectories that can achieve a single purpose. How this variability translates into behaviour and experience is however an open question. Anyhow, it seems reasonable that, at some level, brain responses must keep some invariant aspects so that our perceptual experiences remain stable. Here, I investigated, using a novel generative model, the most stable aspects of brain responses to stimuli as seen through the lens of decoding accuracy, which is, by definition, based on averaging. Previous work has analysed the nature of brain responses to perceptual stimulation using average evoked responses (<xref ref-type="bibr" rid="bib22">Sauseng et al., 2007</xref>), arguing either for a predominant role of additive responses (<xref ref-type="bibr" rid="bib23">Shah et al., 2004</xref>; <xref ref-type="bibr" rid="bib18">Mazaheri and Jensen, 2006</xref>) or phase resetting (<xref ref-type="bibr" rid="bib17">Makeig et al., 2002</xref>). These studies looked at the average response to a given stimulus, but did not investigate what aspects of the data carry information about the identity of the stimulus; this is the focus of this paper and the goal of genephys, the proposed model.</p><p>Genephys has different available types of effect, including phase resets, additive damped oscillations, amplitude modulations, and non-oscillatory responses. All of these elements, which may relate to distinct neurobiological mechanisms, are configurable and can be combined to generate a plethora of TGMs that, in turn, can be contrasted to specific empirical TGMs. This way, we can gain insight on what mechanisms might be at play in a given task.</p><p>The demonstrations here are not meant to be tailored to a specific data set, and are, for the most part, intentionally qualitative. TGMs do vary across experiments and subjects; and the hyperparameters of the model can be explicitly optimised to specific scientific questions, data sets, and even individuals. In order to explore the space of configurations effectively, an automatic optimisation of the hyperparameter space using, for instance, Bayesian optimisation (<xref ref-type="bibr" rid="bib15">Lorenz et al., 2017</xref>) could be advantageous. This may lead to the identification of very specific (spatial, spectral, and temporal) features in the data that may be neurobiologically interpreted.</p><p>Importantly, the list of effects that I have explored here is not exhaustive. For example, I have considered additive oscillatory responses in the form of sinusoidal waves. Another possibility could be to have additive oscillatory responses that are non-linear, that is with a tendency to spend more time in certain phases (e.g. having wider peaks than throughs); in this case, even in the absence of phase locking between trials, we could potentially have a significant evoked response due to phase asymmetry (<xref ref-type="bibr" rid="bib20">Nikulin et al., 2007</xref>). For simplicity, also, I have considered independent sources of activity that exhibit correlations only through the induced effect. In practice, brain areas are in constant communication even in the absence of stimulation. Alternatives where sources are modelled as coupled oscillators (<xref ref-type="bibr" rid="bib2">Breakspear et al., 2010</xref>; <xref ref-type="bibr" rid="bib3">Cabral et al., 2014</xref>), or where there is correlated noise, are also possible. Also for simplicity, I have considered that every channel has one endogenous fundamental frequency only; in practice, multiple ongoing frequencies coexist and interact, potentially affecting the TGM if they are not completely averaged out across trials. Finally, the inherent stochasticity of the stimulus-specific space of activity can take various forms; here, I have explored a probabilistic activation of the channels, but others, such as noise in the phase distribution, are also possible and can also be simulated using <italic>genephys</italic>.</p><p>Also importantly, I have shown that standard decoding analysis can differentiate between these explanations only to some extent. For example, the effects induced by phase resetting and the use of additive oscillatory components are not enormously different in terms of the resulting TGMs. In future work, alternatives to standard decoding analysis and TGMs might be used to disentangle these sources of variation (<xref ref-type="bibr" rid="bib26">Vidaurre et al., 2019</xref>).</p><p>Overall, the results obtained from applying <italic>genephys</italic> suggest that the stable aspects of brain activity regarding stimulus processing comprise phasic modulations of an oscillatory component coupled with a slower component, with an important role played by the nature of this coupling. The subspace of brain activity induced by the effect is high dimensional in both the spatial domain (it must span many channels) and the frequency domain (it must involve a great diversity of frequencies and exhibit a diversity of latencies). This effect may be accompanied by an amplitude modulation. Above and beyond these average patterns, the stimulus-specific subspace of brain responses remains highly stochastic at the trial level.</p><sec id="s4-1"><title>Code accessibility</title><p>The model is available as a Python package in PyPI and Github.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>I used existing data, collected following standard ethical protocols.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-87729-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The simulated data can be regenerated using the code included as an example in the genephys Github repository at <ext-link ext-link-type="uri" xlink:href="http://github.com/vidaurre/genephys">http://github.com/vidaurre/genephys</ext-link> (copy archived at <xref ref-type="bibr" rid="bib28">Vidaurre, 2024</xref>). The real visual paradigm is openly available from the original publication <xref ref-type="bibr" rid="bib4">Cichy et al., 2016</xref> at: <ext-link ext-link-type="uri" xlink:href="http://userpage.fu-berlin.de/rmcichy/fusion_project_page/main.html">http://userpage.fu-berlin.de/rmcichy/fusion_project_page/main.html</ext-link>.</p><p>The following previously published datasets were used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Pantazis</surname><given-names>D</given-names></name><name><surname>Oliva</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Spatio-temporal dynamics of information flow in ventral &amp; dorsal visual cortex - 118 images</data-title><source>Userpage</source><pub-id pub-id-type="accession" xlink:href="http://userpage.fu-berlin.de/rmcichy/fusion_project_page/main.html">rmcichy/fusion_project_page/main.html</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Pantazis</surname><given-names>D</given-names></name><name><surname>Oliva</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Index of /MEG2_MEG_Epoched_Raw_Data</data-title><source>MIT CSAIL</source><pub-id pub-id-type="accession" xlink:href="http://wednesday.csail.mit.edu/MEG2_MEG_Epoched_Raw_Data/">MEG2_MEG_Epoched_Raw_Data/</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>DV is supported by a Novo Nordisk Foundation Emerging Investigator Fellowship (NNF19OC-0054895) and an ERC Starting Grant (ERC-StG-2019-850404). I also thank the Wellcome Trust for support (106183/Z/14/Z, 215573/Z/19/Z).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Axel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The molecular logic of smell</article-title><source>Scientific American</source><volume>273</volume><fpage>154</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1038/scientificamerican1095-154</pub-id><pub-id pub-id-type="pmid">7481719</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Heitmann</surname><given-names>S</given-names></name><name><surname>Daffertshofer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Generative models of cortical oscillations: Neurobiological implications of the kuramoto model</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>190</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00190</pub-id><pub-id pub-id-type="pmid">21151358</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cabral</surname><given-names>J</given-names></name><name><surname>Luckhoo</surname><given-names>H</given-names></name><name><surname>Woolrich</surname><given-names>M</given-names></name><name><surname>Joensson</surname><given-names>M</given-names></name><name><surname>Mohseni</surname><given-names>H</given-names></name><name><surname>Baker</surname><given-names>A</given-names></name><name><surname>Kringelbach</surname><given-names>ML</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Exploring mechanisms of spontaneous functional connectivity in MEG: How delayed network interactions lead to structured amplitude envelopes of band-pass filtered oscillations</article-title><source>NeuroImage</source><volume>90</volume><fpage>423</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.11.047</pub-id><pub-id pub-id-type="pmid">24321555</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Pantazis</surname><given-names>D</given-names></name><name><surname>Oliva</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Similarity-based fusion of MEG and fMRI reveals spatio-temporal dynamics in human cortex during visual object recognition</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>3563</fpage><lpage>3579</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw135</pub-id><pub-id pub-id-type="pmid">27235099</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Croner</surname><given-names>LJ</given-names></name><name><surname>Purpura</surname><given-names>K</given-names></name><name><surname>Kaplan</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Response variability in retinal ganglion cells of primates</article-title><source>PNAS</source><volume>90</volume><fpage>8128</fpage><lpage>8130</lpage><pub-id pub-id-type="doi">10.1073/pnas.90.17.8128</pub-id><pub-id pub-id-type="pmid">8367474</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dawson</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="1954">1954</year><article-title>A summation technique for the detection of small evoked potentials</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>6</volume><fpage>65</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(54)90007-3</pub-id><pub-id pub-id-type="pmid">13141922</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dowling</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="1987">1987</year><source>The Retina: An Approachable Part of the Brain</source><publisher-name>Harvard University Press</publisher-name><pub-id pub-id-type="doi">10.1097/OPX.0b013e3182805b2b</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edelman</surname><given-names>GM</given-names></name><name><surname>Gally</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Degeneracy and complexity in biological systems</article-title><source>PNAS</source><volume>98</volume><fpage>13763</fpage><lpage>13768</lpage><pub-id pub-id-type="doi">10.1073/pnas.231499798</pub-id><pub-id pub-id-type="pmid">11698650</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>WJ</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Spatial properties of an EEG event in the olfactory bulb and cortex</article-title><source>Electroencephalography and Clinical Neurophysiology</source><volume>44</volume><fpage>586</fpage><lpage>605</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(78)90126-8</pub-id><pub-id pub-id-type="pmid">77765</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname><given-names>DD</given-names></name><name><surname>Samanez-Larkin</surname><given-names>GR</given-names></name><name><surname>MacDonald</surname><given-names>SWS</given-names></name><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>McIntosh</surname><given-names>AR</given-names></name><name><surname>Grady</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Moment-to-moment brain signal variability: a next frontier in human brain mapping?</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>37</volume><fpage>610</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2013.02.015</pub-id><pub-id pub-id-type="pmid">23458776</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grootswagers</surname><given-names>T</given-names></name><name><surname>Wardle</surname><given-names>SG</given-names></name><name><surname>Carlson</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Decoding dynamic brain patterns from evoked responses: A tutorial on multivariate pattern analysis applied to time series neuroimaging data</article-title><source>Journal of Cognitive Neuroscience</source><volume>29</volume><fpage>677</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01068</pub-id><pub-id pub-id-type="pmid">27779910</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding neural representational spaces using multivariate pattern analysis</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>435</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062012-170325</pub-id><pub-id pub-id-type="pmid">25002277</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id><pub-id pub-id-type="pmid">24593982</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kragel</surname><given-names>PA</given-names></name><name><surname>Koban</surname><given-names>L</given-names></name><name><surname>Barrett</surname><given-names>LF</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Representation, pattern information, and brain signatures: From neurons to neuroimaging</article-title><source>Neuron</source><volume>99</volume><fpage>257</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.06.009</pub-id><pub-id pub-id-type="pmid">30048614</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorenz</surname><given-names>R</given-names></name><name><surname>Hampshire</surname><given-names>A</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neuroadaptive bayesian optimization and hypothesis testing</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>155</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.01.006</pub-id><pub-id pub-id-type="pmid">28236531</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Luck</surname><given-names>SJ</given-names></name><name><surname>Kappenman</surname><given-names>ES</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>The Oxford Handbook of Event-Related Potential Components</source><publisher-name>Oxford Academic</publisher-name><pub-id pub-id-type="doi">10.1093/oxfordhb/9780195374148.001.0001</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makeig</surname><given-names>S</given-names></name><name><surname>Westerfield</surname><given-names>M</given-names></name><name><surname>Jung</surname><given-names>TP</given-names></name><name><surname>Enghoff</surname><given-names>S</given-names></name><name><surname>Townsend</surname><given-names>J</given-names></name><name><surname>Courchesne</surname><given-names>E</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Dynamic brain sources of visual evoked responses</article-title><source>Science</source><volume>295</volume><fpage>690</fpage><lpage>694</lpage><pub-id pub-id-type="doi">10.1126/science.1066168</pub-id><pub-id pub-id-type="pmid">11809976</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazaheri</surname><given-names>A</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Posterior alpha activity is not phase-reset by visual stimuli</article-title><source>PNAS</source><volume>103</volume><fpage>2948</fpage><lpage>2952</lpage><pub-id pub-id-type="doi">10.1073/pnas.0505785103</pub-id><pub-id pub-id-type="pmid">16473952</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McIntosh</surname><given-names>AR</given-names></name><name><surname>Kovacevic</surname><given-names>N</given-names></name><name><surname>Itier</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Increased brain signal variability accompanies lower behavioral variability in development</article-title><source>PLOS Computational Biology</source><volume>4</volume><elocation-id>e1000106</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000106</pub-id><pub-id pub-id-type="pmid">18604265</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikulin</surname><given-names>VV</given-names></name><name><surname>Linkenkaer-Hansen</surname><given-names>K</given-names></name><name><surname>Nolte</surname><given-names>G</given-names></name><name><surname>Lemm</surname><given-names>S</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name><name><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><name><surname>Curio</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A novel mechanism for evoked responses in the human brain</article-title><source>The European Journal of Neuroscience</source><volume>25</volume><fpage>3146</fpage><lpage>3154</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2007.05553.x</pub-id><pub-id pub-id-type="pmid">17561828</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfurtscheller</surname><given-names>G</given-names></name><name><surname>Lopes da Silva</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Event-related EEG/MEG synchronization and desynchronization: Basic principles</article-title><source>Clinical Neurophysiology</source><volume>110</volume><fpage>1842</fpage><lpage>1857</lpage><pub-id pub-id-type="doi">10.1016/s1388-2457(99)00141-8</pub-id><pub-id pub-id-type="pmid">10576479</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauseng</surname><given-names>P</given-names></name><name><surname>Klimesch</surname><given-names>W</given-names></name><name><surname>Gruber</surname><given-names>WR</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Freunberger</surname><given-names>R</given-names></name><name><surname>Doppelmayr</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Are event-related potential components generated by phase resetting of brain oscillations? A critical discussion</article-title><source>Neuroscience</source><volume>146</volume><fpage>1435</fpage><lpage>1444</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2007.03.014</pub-id><pub-id pub-id-type="pmid">17459593</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>AS</given-names></name><name><surname>Bressler</surname><given-names>SL</given-names></name><name><surname>Knuth</surname><given-names>KH</given-names></name><name><surname>Ding</surname><given-names>M</given-names></name><name><surname>Mehta</surname><given-names>AD</given-names></name><name><surname>Ulbert</surname><given-names>I</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neural dynamics and the fundamental mechanisms of event-related brain potentials</article-title><source>Cerebral Cortex</source><volume>14</volume><fpage>476</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhh009</pub-id><pub-id pub-id-type="pmid">15054063</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname><given-names>RB</given-names></name><name><surname>Gossen</surname><given-names>ER</given-names></name><name><surname>Jones</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neuronal variability: Noise or part of the signal?</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>389</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1038/nrn1668</pub-id><pub-id pub-id-type="pmid">15861181</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>MG</given-names></name><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Spaak</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Decoding rich spatial information with high temporal resolution</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>636</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.08.016</pub-id><pub-id pub-id-type="pmid">26440122</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vidaurre</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>NE</given-names></name><name><surname>Stokes</surname><given-names>M</given-names></name><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Temporally unconstrained decoding reveals consistent but time-varying stages of stimulus processing</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>863</fpage><lpage>874</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy290</pub-id><pub-id pub-id-type="pmid">30535141</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vidaurre</surname><given-names>D</given-names></name><name><surname>Cichy</surname><given-names>RM</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dissociable components of information encoding in human perception</article-title><source>Cerebral Cortex</source><volume>31</volume><fpage>5664</fpage><lpage>5675</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhab189</pub-id><pub-id pub-id-type="pmid">34291294</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Vidaurre</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Genephys</data-title><version designator="swh:1:rev:994179448e380155f997efbfaa3bd04aba4fecfb">swh:1:rev:994179448e380155f997efbfaa3bd04aba4fecfb</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:b835c738cf4bf2057701c138df5287a1ffa2de5c;origin=https://github.com/vidaurre/genephys;visit=swh:1:snp:d3d2d5bd4926f13dd9fd7e5ce9d25175a2f778e2;anchor=swh:1:rev:994179448e380155f997efbfaa3bd04aba4fecfb">https://archive.softwareheritage.org/swh:1:dir:b835c738cf4bf2057701c138df5287a1ffa2de5c;origin=https://github.com/vidaurre/genephys;visit=swh:1:snp:d3d2d5bd4926f13dd9fd7e5ce9d25175a2f778e2;anchor=swh:1:rev:994179448e380155f997efbfaa3bd04aba4fecfb</ext-link></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87729.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Luo</surname><given-names>Huan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Peking University</institution><country>China</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This study presents a <bold>valuable</bold> finding on developing a state-of-the-art generative model of brain electrophysiological signals to explain temporal decoding matrices widely used in cognitive neuroscience. The evidence supporting the authors' claims is <bold>convincing</bold>. The results will be strengthened by providing more clear mappings between neurobiological mechanisms and signal generators in the model. The work will be of interest to cognitive neuroscientists using electrophysiological recordings.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87729.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>With genephys, the author provides a generative model of brain responses to stimulation. This generative model allows to mimic specific parameters of a brain response at the sensor level, to test the impact of those parameters on critical analytic methods utilized on real M/EEG data. Specifically, they compare the decoding output for differently set parameters to the decoding pattern observed in a classical passive viewing study in terms of the resulting temporal generalization matrix (TGM). They identify that the correspondence between the mimicked and the experimental TGM to depend on an oscillatory component that spans multiple channels, frequencies, and latencies of response; and an additive, slower response with a specific (cross-frequency) relation to the phase of the oscillatory, faster component.</p><p>A strength of the article is that it considers the complexity of neural data that contribute to the findings obtained in stimulation experiments. An additional strength is the provision of a Python package that allows scientists to explore the potential contribution of different aspects of neural signals to obtained experimental data and thereby to potentially test their theoretical assumptions critical parameters that contribute to their experimental data.</p><p>A weakness of the paper is that the power of the model is illustrated for only one specific set of parameters, added in a stepwise manner and the comparison to on specific empirical TGM, assumed to be prototypical; And that this comparison remains descriptive. (That is could a different selection of parameters lead to similar results and is there TGM data which matches these settings less well.) It further remained unclear to me, which implications may be drawn from the generative model, following from the capacities to mimic this specific TGM (i) for more complex cases, such as the comparison between experimental conditions, and (ii) about the complex nature of neural processes involved.</p><p>Towards this end I would appreciate (i) a more profound explanation of the conclusions that can be drawn from this specific showcase, including potential limitations, as well as wider considerations of how scientists may empower the generative model to (ii) understand their experimental data better and (iii) which added value the model may have in understanding the nature of underlaying brain mechanism (rather than a mere technical characterization of sensor data).</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87729.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This paper introduces a new model that aims to explain the generators of temporal decoding matrices (TGMs) in terms of underlying signal properties. This is important because TGMs are regularly used to investigate neural mechanisms underlying cognitive processes, but their interpretation in terms of underlying signals often remains unclear. Furthermore, neural signals are often variant over different instances of stimulation despite behaviour being relatively stable. The author aims to tackle these concerns by developing a generative model of electrophysiological data and then showing how different parameterizations can explain different features of TGMs. The developed technique is able to capture empirical observations in terms of fundamental signal properties. Specifically, the model shows that complexity is necessary in terms of spatial configuration, frequencies and latencies to obtain a TGM that is comparable to empirical data.</p><p>The major strength of the paper is that the novel technique has the potential to further our understanding of the generators of electrophysiological signals which are an important way to understand brain function. The paper clearly outlines how the method can be used to capture empirical data. Furthermore, the used techniques are state-of-the-art and the developed model is publicly shared in open source code.</p><p>On the other hand, there is no unambiguous mapping between neurobiological mechanisms and different signal generators, making it hard to draw firm conclusions about neural underpinnings based on this analysis.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.87729.3.sa3</article-id><title-group><article-title>Author Response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Vidaurre</surname><given-names>Diego</given-names></name><role specific-use="author">Author</role><aff><institution>Aarhus University</institution><addr-line><named-content content-type="city">Aarhus</named-content></addr-line><country>Denmark</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1:</bold></p><p>A weakness of the paper is that the power of the model is illustrated for only one specific set of parameters, added in a stepwise manner and the comparison to one specific empirical TGM, assumed to be prototypical; And that this comparison remains descriptive. (That is could a different selection of parameters lead to similar results and is there TGM data which matches these settings less well.)</p></disp-quote><p>The fact that the comparisons in the paper are descriptive is a central point of criticism from both reviewers. As mentioned in my preliminary response, I intentionally did not optimise the model to a specific TGM or show an explicit metric of fitness. As I now explicitly mention in the new experimental section of the paper:</p><p>“The previous analyses were descriptive in the sense that they did not quantify how much the generated TGMs resembled a specific empirical TGM. This was deliberate, because empirical TGMs vary across subjects and experiments, and I aimed at characterising them as generally as possible by looking at some characteristic features in broad terms. For example, while TGMs typically have a strong diagonal and horizontal/vertical bars of high accuracy, questions such as when these effects emerge and for how long are highly dependent on the experimental paradigm. For the same reason, I did not optimise the model hyperparameters, limiting myself to observing the behaviour of the model across some characteristic configurations”</p><p>And, in the Discussion:</p><p>“The demonstrations here are not meant to be tailored to a specific data set, and are, for the most part, intentionally qualitative. TGMs do vary across experiments and subjects; and the hyperparameters of the model can be explicitly optimised to specific scientific questions, data sets, and even individuals. In order to explore the space of configurations effectively, an automatic optimisation of the hyperparameter space using, for instance, Bayesian optimisation (Lorenz, et al., 2017) could be advantageous. This may lead to the identification of very specific (spatial, spectral and temporal) features in the data that may be neurobiologically interpreted.”</p><p>Nonetheless, it is possible to fit the model to a specific TGMs by using a explicit metric of fitness. For illustration, this is what I did in the new experimental section Fitting and empirical TGM, where I used correlation with an empirical TGM to optimise two temporal parameters: the rise slope and the fall slope. As can be seen in the Figure 8, the correlation with the empirical TGM was as high as 0.7, even though I did not fit the other parameters of the model. As mentioned in the paragraph above, more sophisticated techniques such as Bayesian optimisation might be necessary for a more exhaustive exploration, but this would be beyond the scope of the current paper.</p><p>I would also like to point out that fitting the parameters in a step-wise manner was a necessity for interpretation. I suggest to think of the way we use F-tests in regression analyses as a comparison: if we want to know how important a feature is, we compare the model with and without this feature and see how much we loss.</p><disp-quote content-type="editor-comment"><p>It further remained unclear to me, which implications may be drawn from the generative model, following from the capacities to mimic this specific TGM (i) for more complex cases, such as the comparison between experimental conditions, and (ii) about the complex nature of neural processes involved.</p></disp-quote><p>Following on the previous points, the object of this paper (besides presenting the model and the associated toolbox) was not to mimic a specific TGM, but to characterise the main features that we generally see across studies in the field. To clarify this, I have added Figure 2 (previously a Supplemental Information figure), and added the following to the Results section:</p><p>“Figure 2 shows a TGM for an example subject, where some archetypal characteristics are highlighted. In the experiments below, specifically, I focus on the strong narrow diagonal at the beginning of the trial, the broadening of accuracy later in the trial, and the vertical/horizontal bars of higher-than-chance accuracy. Importantly, this specific example in Figure 2 is only meant as a reference, and therefore I did not optimise the model hyperparameters to this TGM (except in the last subsection), or showed any quantitative metric of similarity.”</p><p>I mention the possibility of using the model to explore more complex cases in the Introduction, although doing so here would be out of scope:</p><p>“Other experimental paradigms, including motor tasks and decision making, can be investigated with genephys”</p><disp-quote content-type="editor-comment"><p>Towards this end, I would appreciate (i) a more profound explanation of the conclusions that can be drawn from this specific showcase, including potential limitations, as well as wider considerations of how scientists may empower the generative model to (ii) understand their experimental data better and (iii) which added value the model may have in understanding the nature of underlying brain mechanism (rather than a mere technical characterization of sensor data).</p></disp-quote><p>To better illustrate how to use genephys to explore a specific data set, I have added a section (Fitting an empirical TGM) where I show how to fit specific hyperparameters to an empirical TGM in a simple manner.</p><p>In the Introduction, I briefly mentioned:</p><p>“This (not exhaustive) list of effects was considered given previous literature (Shah, et al., 2004; Mazaheri &amp; Jensen, 2006; Makeig, et al., 2002; Vidaurre, et al., 2021), and each effect may be underpinned by distinct neural mechanisms. For example, it is not completely clear the extent to which stimulus processing is sustained by oscillations, and disentangling these effects can help resolving this question”</p><p>In the Discussion, I have further commented:</p><p>“Genephys has different available types of effect, including phase resets, additive damped oscillations, amplitude modulations, and non-oscillatory responses. All of these elements, which may relate to distinct neurobiological mechanisms, are configurable and can be combined to generate a plethora of TGMs that, in turn, can be contrasted to specific empirical TGMs. This way, we can gain insight on what mechanisms might be at play in a given task.</p><p>The demonstrations here are not meant to be tailored to a specific data set, and are, for the most part, intentionally qualitative. TGMs do vary across experiments and subjects; and the hyperparameters of the model can be explicitly optimised to specific scientific questions, data sets, and even individuals. In order to explore the space of configurations effectively, an automatic optimisation of the hyperparameter space using, for instance, Bayesian optimisation (Lorenz, et al., 2017) could be advantageous. This may lead to the identification of very specific (spatial, spectral and temporal) features in the data that may be neurobiologically interpreted. “</p><disp-quote content-type="editor-comment"><p>On p. 15 &quot;Having a diversity of frequencies but not of latencies produces another regular pattern consisting of alternating, parallel bands of higher/lower than baseline accuracy. This, shown in the bottom left panel, is not what we see in real data either. Having a diversity of latencies but not of frequencies gets us closer to a realistic pattern, as we see in the top right panel.&quot; The terms frequency and latency seem to be confused.</p></disp-quote><p>The Reviewer is right. I have corrected this now. Thank you.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2:</bold></p><p>The results of comparisons between simulations and real data are not always clear for an inexperienced reader. For example, the comparisons are qualitative rather than quantitative, making it hard to draw firm conclusions. Relatedly, it is unclear whether the chosen parameterizations are the only/best ones to generate the observed patterns or whether others are possible. In the case of the latter, it is unclear what we can actually conclude about underlying signal generators. It would have been different if the model was directly fitted to empirical data, maybe of different cognitive conditions. Finally, the neurobiological interpretation of different signal properties is not discussed. Therefore, taken together, in its currently presented form, it is unclear how this method could be used exactly to further our understanding of the brain.</p></disp-quote><p>This critique coincides with that of Reviewer 1. In the current version, I made more clear the fact that I am not fitting a specific empirical TGM and why, and that, instead, I am referring to general features that appear broadly throughout the literature. See more detailed changes below.</p><p>Regarding whether the chosen parameterizations are the only/best ones to generate the observed patterns, the Discussion reflects this limitation:</p><p>“Also importantly, I have shown that standard decoding analysis can differentiate between these explanations only to some extent. For example, the effects induced by phase-resetting and the use of additive oscillatory components are not enormously different in terms of the resulting TGMs. In future work, alternatives to standard decoding analysis and TGMs might be used to disentangle these sources of variation (Vidaurre, et al., 2019). ”</p><p>And</p><p>“Importantly, the list of effects that I have explored here is not exhaustive …”</p><p>Of course, since the list of signal features I have explored is not exhaustive, it cannot be claimed without a doubt that these features are the ones generating the properties we observe in real TGMs. The model, however, is a step forward in that direction, as it provides us with a tool to at least rule out some causes.</p><disp-quote content-type="editor-comment"><p>Firstly, it was not entirely clear to me from the introduction what gap exactly the model is supposed to fill: is it about variance in neural responses in general, about which signal properties are responsible for decoding, or about capturing stability of signals? It seems like it does all of these, but this needs to be made clearer in the introduction. It would be helpful to emphasize exactly what insights the model can provide that are unable to be obtained with the current methods.</p></disp-quote><p>I have now made this explicit in in the Introduction, as suggested:</p><p>“To gain insight into what aspects of the signal underpin decoding accuracy, and therefore the most stable aspects of stimulus processing, I introduce a generative model”</p><p>To help illustrating what insights the model can provide, I have added the following sentence as an example:</p><p>“For example, it is not completely clear the extent to which stimulus processing is sustained by oscillations, and disentangling these effects can help resolving this question.”</p><disp-quote content-type="editor-comment"><p>Furthermore, I was unclear on why these specific properties were chosen (lines 71 to 78). Is there evidence from neuroscience to suggest that these signal properties are especially important for neural processing? Or, if the logic has more to do with signal processing, why are these specific properties the most important to include?</p></disp-quote><p>To clarify this the text now reads:</p><p>“In the model, when a channel responds, it can do it in different ways: (i) by phase-resetting the ongoing oscillation to a given target phase and then entraining to a given frequency, (ii) by an additive oscillatory response independent of the ongoing oscillation, (iii) by modulating the amplitude of the stimulus-relevant oscillations, or (iv) by an additive non-oscillatory (slower) response. This (not exhaustive) list of effects was considered given previous literature (Shah, et al., 2004; Mazaheri &amp; Jensen, 2006; Makeig, et al., 2002; Vidaurre, et al., 2021), and each effect may be underpinned by distinct neural mechanisms”</p><disp-quote content-type="editor-comment"><p>The general narrative and focus of the paper could also be improved. It might help to start off with an outline of what the goal is at the start of the paper and then explicitly discuss how each of the steps works toward that goal. For example, I got the idea that the goal was to capture specific properties of an empirical TGM. If this was the case, the empirical TGM could be placed in the main body of the text as a reference picture for all simulated TGMs. For each simulation step, it could be emphasized more clearly exactly which features of the TGM is captured and what that means for interpreting these features in real data.</p></disp-quote><p>Thank you. To clarify the purpose of the paper better, I have brought Figure 2 to the front (before a Supplementary Figure), and in the first part of Results I have now added:</p><p>“Figure 2 shows a TGM for an example subject, where some archetypal characteristics are highlighted. In the experiments below, specifically, I focus on the strong narrow diagonal at the beginning of the trial, the broadening of accuracy later in the trial, and the vertical/horizontal bars of higher-than-chance accuracy. Importantly, this specific example in Figure 2 is only meant as a reference, and therefore I did not optimise the model hyperparameters to this TGM (except in the last subsection), or showed any quantitative metric of similarity. ”</p><p>I have enunciated the goals more clearly in the Introduction:</p><p>“To gain insight into what aspects of the signal underpin decoding accuracy, and therefore the most stable aspects of stimulus processing, …”</p><disp-quote content-type="editor-comment"><p>Relatedly, it would be good to connect the various signal properties to possible neurobiological mechanisms. I appreciate that the author tries to remain neutral on this in the introduction, but I think it would greatly increase the implications of the analysis if it is made clearer how it could eventually help us understand neural processes.</p></disp-quote><p>The Reviewer is right in pointing out that I preferred to remain neutral on this. While I have still kept that tone of neutrality throughout the paper, I have now included the following sentence as an example of a neurobiological question that could be investigated with the model:</p><p>“For example, it is not completely clear the extent to which stimulus processing is sustained by oscillations, and disentangling these effects can help resolving this question.”</p><p>And, more generally,</p><p>“Genephys has different available types of effect, including phase resets, additive damped oscillations, amplitude modulations, and non-oscillatory responses. All of these elements, which may relate to distinct neurobiological mechanisms, are configurable and can be combined to generate a plethora of TGMs that, in turn, can be contrasted to specific empirical TGMs. This way, we can gain insight on what mechanisms might be at play in a given task. ”</p><disp-quote content-type="editor-comment"><p>Line 57: this sentence is very long, making it hard to follow, could you break up into smaller parts?</p></disp-quote><p>Thank you. The sentence is fragmented now.</p><disp-quote content-type="editor-comment"><p>Please replace angular frequencies with frequencies in Hertz for clarity.</p></disp-quote><p>Here I have preferred to stick to angular frequencies because it is more general than if I talk about Hertz, because that would entail having a specific sampling frequency. I think doing so would create confusion precisely of the sorts that I am trying to clarify in this revision: that is, that these results are not specific of one TGM but reflect general features that we see broadly in the literature.</p><p>There are quite some types throughout the paper, please recheck</p><p>Thank you. I have revised and have made my best to clear them out.</p></body></sub-article></article>