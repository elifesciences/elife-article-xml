<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">75197</article-id><article-id pub-id-type="doi">10.7554/eLife.75197</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Intracranial human recordings reveal association between neural activity and perceived intensity for the pain of others in the insula</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-296491"><name><surname>Soyman</surname><given-names>Efe</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0192-1541</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-85781"><name><surname>Bruls</surname><given-names>Rune</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-261671"><name><surname>Ioumpa</surname><given-names>Kalliopi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-219230"><name><surname>Müller-Pinzler</surname><given-names>Laura</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5567-5430</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-261672"><name><surname>Gallo</surname><given-names>Selene</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="pa1">‡</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-284490"><name><surname>Qin</surname><given-names>Chaoyi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-261673"><name><surname>van Straaten</surname><given-names>Elisabeth CW</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-50550"><name><surname>Self</surname><given-names>Matthew W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5731-579X</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-261674"><name><surname>Peters</surname><given-names>Judith C</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-261675"><name><surname>Possel</surname><given-names>Jessy K</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-228328"><name><surname>Onuki</surname><given-names>Yoshiyuki</given-names></name><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-261676"><name><surname>Baayen</surname><given-names>Johannes C</given-names></name><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-261677"><name><surname>Idema</surname><given-names>Sander</given-names></name><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-64909"><name><surname>Keysers</surname><given-names>Christian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2845-5467</contrib-id><email>c.keysers@nin.knaw.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-64910"><name><surname>Gazzola</surname><given-names>Valeria</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0324-0619</contrib-id><email>v.gazzola@nin.knaw.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con15"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05csn2x06</institution-id><institution>Social Brain Lab, Netherlands Institute for Neuroscience, Royal Netherlands Academy of Art and Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00jzwgz36</institution-id><institution>Social Cognitive and Affective Neuroscience Lab, Koc University</institution></institution-wrap><addr-line><named-content content-type="city">Istanbul</named-content></addr-line><country>Turkey</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00t3r8h32</institution-id><institution>Social Neuroscience Lab, Department of Psychiatry and Psychotherapy, University of Lübeck</institution></institution-wrap><addr-line><named-content content-type="city">Lübeck</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/008xxew50</institution-id><institution>Department of Neurology and Clinical Neurophysiology, Amsterdam UMC, Vrije Universiteit Amsterdam</institution></institution-wrap><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/043c0p156</institution-id><institution>Department of Vision and Cognition, Netherlands Institute of Neuroscience, Royal Netherlands Academy of Art and Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jz4aj89</institution-id><institution>Department of Cognitive Neuroscience, Faculty of Psychology and Neuroscience, Maastricht University</institution></institution-wrap><addr-line><named-content content-type="city">Maastricht</named-content></addr-line><country>Netherlands</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jz4aj89</institution-id><institution>Maastricht Brain Imaging Center (M-BIC), Maastricht University</institution></institution-wrap><addr-line><named-content content-type="city">Maastricht</named-content></addr-line><country>Netherlands</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/010hz0g26</institution-id><institution>Department of Neurosurgery, Jichi Medical University</institution></institution-wrap><addr-line><named-content content-type="city">Shimotsuke</named-content></addr-line><country>Japan</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05grdyy37</institution-id><institution>Department of Neurosurgery, VUmc, Amsterdam University Medical Center</institution></institution-wrap><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff><aff id="aff10"><label>10</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>Brain and Cognition, Department of Psychology, University of Amsterdam</institution></institution-wrap><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zgy1s35</institution-id><institution>University Medical Center Hamburg-Eppendorf</institution></institution-wrap><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zgy1s35</institution-id><institution>University Medical Center Hamburg-Eppendor</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="present-address" id="pa1"><label>‡</label><p>Department of Psychiatry, Amsterdam University Medical Center, Amsterdam, Netherlands</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>03</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e75197</elocation-id><history><date date-type="received" iso-8601-date="2021-11-02"><day>02</day><month>11</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-11-02"><day>02</day><month>11</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-06-24"><day>24</day><month>06</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.06.23.449371"/></event></pub-history><permissions><copyright-statement>© 2022, Soyman, Bruls, Ioumpa et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Soyman, Bruls, Ioumpa et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-75197-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-75197-figures-v2.pdf"/><abstract><p>Based on neuroimaging data, the insula is considered important for people to empathize with the pain of others. Here, we present intracranial electroencephalographic (iEEG) recordings and single-cell recordings from the human insula while seven epilepsy patients rated the intensity of a woman’s painful experiences seen in short movie clips. Pain had to be deduced from seeing facial expressions or a hand being slapped by a belt. We found activity in the broadband 20–190 Hz range correlated with the trial-by-trial perceived intensity in the insula for both types of stimuli. Within the insula, some locations had activity correlating with perceived intensity for our facial expressions but not for our hand stimuli, others only for our hand but not our face stimuli, and others for both. The timing of responses to the sight of the hand being hit is best explained by kinematic information; that for our facial expressions, by shape information. Comparing the broadband activity in the iEEG signal with spiking activity from a small number of neurons and an fMRI experiment with similar stimuli revealed a consistent spatial organization, with stronger associations with intensity more anteriorly, while viewing the hand being slapped.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>insula</kwd><kwd>pain</kwd><kwd>empathy</kwd><kwd>intracranial eeg</kwd><kwd>broadband gamma</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>452-14-015</award-id><principal-award-recipient><name><surname>Gazzola</surname><given-names>Valeria</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>453-15-009</award-id><principal-award-recipient><name><surname>Keysers</surname><given-names>Christian</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Intracranial recordings indicate that the insula encodes, in a partially intermixed layout, both static and dynamic cues from different body parts that reflect the intensity of pain experienced by others.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Sharing the distress of others is central to empathy. fMRI studies show that a number of brain regions involved in the direct experience of pain also increase their activity while participants perceive the pain of others, including the cingulate cortex, the insula, and the somatosensory cortices (<xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Keysers et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Lamm et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>). Across humans, primates, and rodents, lesions in these regions impair the perception and the sharing of others’ emotions (<xref ref-type="bibr" rid="bib52">Paradiso et al., 2021</xref>), providing evidence for their causal contribution to the perception or sharing of the emotions of others. A number of recent studies have used multivoxel pattern analysis to explore how these regions encode the pain of others using fMRI signals, with particular attention to the insula. <xref ref-type="bibr" rid="bib35">Krishnan et al., 2016</xref> showed participants’ images of hands or feet in painful or innocuous situations and found a pattern across voxels in the insula that could predict how much pain people reported they would feel in the depicted situations. <xref ref-type="bibr" rid="bib15">Corradi-Dell’Acqua et al., 2016</xref> also reported that the pattern of insula activity could discriminate between trials in which a cue signaled that someone else was receiving a shock from nonshock trials. Finally, <xref ref-type="bibr" rid="bib75">Zhou et al., 2020</xref> reanalyzed a dataset in which participants viewed photographs of hands in painful or nonpainful situations, or of painful and neutral facial expressions. They found that, in the insula, similar but dissociable patterns supported painfulness decoding for hands and faces: similar in that a pattern trained to discriminate painfulness from faces could do so from hands and vice versa, with the rostral insula contributing to both patterns; but dissociable in that many voxels contributed only to decoding of either faces or hands.</p><p>Directly recording electrical signals from these regions in humans would complement these more indirect fMRI measurements and sharpen our understanding of how these regions represent the intensity of other people’s pain for at least two reasons. First, fMRI records a mixed signal that includes synaptic input and local neural processing. Localizing blood-oxygen-level-dependent (BOLD) activity that encodes a particular stimulus property thus cannot ensure that neurons in that region actually have spiking activity that encodes that property (<xref ref-type="bibr" rid="bib9">Boynton, 2011</xref>). For instance, BOLD signals in V1 fluctuate based on whether a stimulus is perceived or not in binocular rivalry (<xref ref-type="bibr" rid="bib9">Boynton, 2011</xref>; <xref ref-type="bibr" rid="bib45">Maier et al., 2008</xref>). In contrast, simultaneous electrical recordings in V1 show that broadband gamma activity, which is tightly coupled to spiking (<xref ref-type="bibr" rid="bib5">Bartoli et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Buzsáki et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Miller et al., 2014</xref>), responds to a stimulus equally well whether it is perceived or suppressed. Only the slower components, &lt;20 Hz, that are known to carry feedback synaptic input fluctuate with perception (<xref ref-type="bibr" rid="bib45">Maier et al., 2008</xref>). Being able to record electrical activity, particularly in the broadband gamma range, would thus be critical to localize where in this circuitry neuronal spiking indeed represents the pain of others. Second, fMRI’s low temporal resolution makes it difficult to characterize the time course of responses.</p><p>For the anterior cingulate, we have intracranial recordings: <xref ref-type="bibr" rid="bib25">Hutchison et al., 1999</xref> documented a single neuron in epileptic patients that responded to the sight of a finger being pin-pricked with increased firing rate, and a recent rodent study revealed that cingulate neurons responding to pain experience have responses that increase with the intensity of the pain experienced by another rat (<xref ref-type="bibr" rid="bib11">Carrillo et al., 2019</xref>). In contrast, although the insula is central in the neuroimaging literature on empathy, and shows increases of BOLD signal for watching painful compared to nonpainful social stimuli (<xref ref-type="bibr" rid="bib27">Jabbi et al., 2007</xref>; <xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Lamm et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Meffert et al., 2013</xref>; <xref ref-type="bibr" rid="bib62">Singer et al., 2004</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>; <xref ref-type="bibr" rid="bib71">Wicker et al., 2003</xref>), and shows patterns that encode painfulness (<xref ref-type="bibr" rid="bib15">Corradi-Dell’Acqua et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Krishnan et al., 2016</xref>; <xref ref-type="bibr" rid="bib75">Zhou et al., 2020</xref>), we still lack insular intracranial recordings while individuals witness the pain of others. Intracranial electroencephalography (iEEG) has been recorded in the insula during the self-experience of pain (<xref ref-type="bibr" rid="bib7">Bastuji et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Bastuji et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Liberati et al., 2020</xref>), and the insula and adjacent SII are the only cortical regions where iEEG electrode stimulation can induce painful sensations (<xref ref-type="bibr" rid="bib30">Jobst et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Mazzola et al., 2012</xref>), but to our knowledge there are no published studies recording from insular electrodes while patients witness the pain of others. The degree to which neuronal activity local to the insula, as opposed to feedback synaptic input from other regions such as the cingulate, encodes the intensity of other people’s pain therefore remains unclear and the time course of such neural activity remains undercharacterized.</p><p>To fill this gap and characterize the electrophysiological responses of the insula to the pain of others, we collected depth electrode recordings from seven epileptic patients during presurgical exploration, while they rated the different intensities of pain they perceived in another person in a video (<xref ref-type="fig" rid="fig1">Figure 1a and b</xref>). All these patients had macroelectrodes in their insulae that yielded local field potentials (LFPs) capable of measuring broadband gamma activity (circles in <xref ref-type="fig" rid="fig1">Figure 1c</xref>). Three patients, additionally, had microelectrodes at the tip of some macroelectrodes to record from isolated insular neurons (pluses in <xref ref-type="fig" rid="fig1">Figure 1c</xref>). Our stimuli also included two ways in which pain is perceived in others (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Half the stimuli (Faces) showed a female receiving electroshocks on the hand and expressing pain through facial expressions (furrowing eyebrows and tightening eyes). The other half (Hands) showed the protagonist’s hand slapped by a leather belt, and pain intensity had to be deduced from the movements of the belt and the hand. In both cases, movies, rather than static images, were chosen to provide richer and more ecological stimuli and provide information about the temporal dynamics with which such movies are represented in a field still dominated by the presentation of static images (<xref ref-type="bibr" rid="bib3">Adolphs et al., 2003</xref>; <xref ref-type="bibr" rid="bib76">Zinchenko et al., 2018</xref>). We used these two classes of stimuli because both tap into the visual perception of other people’s pain, and we start to understand that they do so through partially overlapping and partially dissociable routes (<xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Keysers et al., 2010</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>). For instance, the Hand stimuli depend on the hand region of the somatosensory cortex (<xref ref-type="bibr" rid="bib22">Gallo et al., 2018</xref>), while facial expressions depend on both the ventral somatosensory cortex and the insula (<xref ref-type="bibr" rid="bib2">Adolphs et al., 2000</xref>; <xref ref-type="bibr" rid="bib18">Dal Monte et al., 2013</xref>; <xref ref-type="bibr" rid="bib47">Mattavelli et al., 2019</xref>), whereby the insula appears to show partially overlapping and partially discriminable patterns encoding painfulness for these two types of stimuli (<xref ref-type="bibr" rid="bib75">Zhou et al., 2020</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design, recording site locations, and behavioral pain ratings.</title><p>(<bold>a</bold>) Frames extracted from a Hand and a Face movie. For the Face, the first second of each movie showed a neutral facial expression, the second, the facial reaction to the shock. For the Hand, the movie started with the belt resting on the hand. The first second showed the belt lifting and coming down again, to hit the hand at the 1 s mark exactly. The hand then reacted to the force of the belt. Both the slap and the shock delivery happened in the middle of the movies, splitting them into a 1 s neutral and a 1 s pain period. (<bold>b</bold>) Single-trial structure diagram. After the presentation of each video, patients expressed their choice at their pace using the keyboard keys f, g, j, and k for pain intensities 1–2, 3–4, 5–6, and 7–8, respectively. ITI started with participant’s response. (<bold>c</bold>) Position (i.e., the midpoint between two adjacent electrodes) of the 85 bipolar macroelectrode recording sites shown as dots and of the microelectrode locations shown as pluses, color-coded by patient. Data from the two hemispheres and all lateromedial coordinates are projected here onto a single sagittal slice of the insula taken at X = 38 from the brain of one of the patients. For a list of all MNI coordinates, see <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>. (<bold>d</bold>) Graphical illustration of how a bipolar recording for one patient and one insular electrode was computed. In green, the CT, and in gray, the T1 scan from patient C. The annular structures along the electrode shaft in the CT correspond to individual macroelectrode contacts (green 1, 2, 3 …). Recordings from adjacent pairs of contacts along the electrode were subtracted to calculate bipolar recordings (white 1–2, 2–3 …). (<bold>e</bold>) From left to right, Spearman’s correlation coefficient <italic>r</italic>, intercept, and slope values from the linear regression for Hand (green) and Face (purple). Histograms: values for the control group illustrate the similarity between the ratings of each participant in the control group and the average of the other controls, and are shown as gray; the similarity between each of the seven patients with the average of the control group is shown in colors. Dotted lines mark the 2.5 and 97.5% of the control group. Bar graphs: mean ± SEM of the controls (gray) and the seven included patients (color) with individual patients as circles. In the bar graphs, we also show as Xs the corresponding behavioral performance metrics of the two patients that were excluded due to atypical use of the response keys. These patients were not included in the mean and SEM calculations.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Mean MNI coordinates of recording sites.</title><p>In black, the MNI coordinates resulting from the average MNI coordinates of the two adjacent electrodes used for re-referencing for all macroelectrodes. In gray, the MNI coordinates of the microelectrodes. The color coding and patient identifiers reflect those used in <xref ref-type="fig" rid="fig1">Figure 1c</xref>.</p></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-75197-fig1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig1-v2.tif"/></fig><p>Our aim is to localize insular recording sites that do or do not encode the perceived intensity of others’ experiences from Face and/or Hand stimuli and to exploit the temporal resolution of iEEG to explore the timing of intensity coding and how it relates to the timing of intensity-relevant stimulus features. To provide evidence that a specific recording site does not encode intensity for a stimulus type, we supplement frequentist statistics with Bayesian statistics, which generate a Bayes factor (BF<sub>10</sub>; <xref ref-type="bibr" rid="bib33">Keysers et al., 2020</xref>). The Bayes factor indicates the probability of the data if there is intensity encoding (H<sub>1</sub>) divided by that if there isn’t (H<sub>0</sub>). A BF<sub>10</sub> &lt; ⅓, which indicates the data is at least three times more likely under H<sub>0</sub> than H<sub>1</sub>, is considered evidence for the absence of intensity coding. Importantly, in Bayesian statistics, whenever possible, it is advised to commit to a directional hypothesis (H+) that endows the BF<sub>+0</sub> with higher sensitivity to detect evidence for both H+ and H<sub>0</sub> (<xref ref-type="bibr" rid="bib33">Keysers et al., 2020</xref>; <xref ref-type="bibr" rid="bib70">Wagenmakers et al., 2016</xref>). Given that fMRI experiments overwhelmingly report voxels with <italic>increases</italic> of BOLD signals for pain compared to no-pain stimuli, we therefore commit ourselves to a directional hypothesis and look for sites and neurons that increase their broadband activity or firing rate for stimuli that are perceived as more painful.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The pain intensity ratings of patients were within the normal range</title><p>To assess whether the behavior of the patients was representative of the general population, we compared patients’ (three males, four females, 34.3 years ± 9 SD) ratings with those of 93 healthy volunteers (54 females, 32.7 years ± 9 SD, Table 4), who took part in an online version of the video pain rating task. <xref ref-type="table" rid="table1">Table 1</xref> shows the distribution of ratings separately for patients and on average for controls. We calculated three metrics of similarity between the ratings of the patients and the control group: the Spearman’s rank-order correlation, the slope, and the intercept of a simple linear regression between each patient’s ratings and the average ratings of the control sample (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). The patients revealed correlation coefficients, slopes, and intercepts (green and purple bars) within the 2.5 and 97.5 percentiles of the corresponding control sample distributions (gray bars), except for one correlation coefficient for Faces, where a patient rated the Faces with unusually high concordance with the average of the control groups. This verified that these seven patients were not impaired in their ability to rate intensity from our videos. In both the patient and the control sample, we observed that correlation coefficients for Faces were significantly greater than for Hands (patient: <italic>t</italic><sub>(6)</sub> = 3.81, p<sub>2</sub>=0.009, BF<sub>10</sub> = 7.39; control: <italic>W</italic> = 3895, p<sub>2</sub>=10<sup>–12</sup>, BF<sub>10</sub> = 3 × 10<sup>5</sup>, <xref ref-type="fig" rid="fig1">Figure 1e</xref>), suggesting more interpersonal agreement in pain intensity ratings for Faces than Hands. In contrast to the higher agreement for Faces, the average rating was slightly higher for Hands than Faces in both the patient and the control sample (patient: <italic>t</italic><sub>(6)</sub> = 2.60, p<sub>2</sub>=0.041, BF<sub>10</sub> = 2.31; control: <italic>W</italic> = 2738.5, p<sub>2</sub>=0.001, BF<sub>10</sub> = 39.40). Taken together, these findings indicate that the intensity rating behavior of the patient samples was similar to the patterns observed in the healthy population.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Pain ratings in patients and controls.</title><p>Left: the percentage of trials (out of the 60 Hand and 60 Face trials for patients, or 30 and 30 for controls) per rating per participant for the Hand and Face conditions. For the age- and gender-matched control group, only the average across the 93 controls is shown. Middle: mean (M) rating for the Hand or Face. Our patients reported slightly higher pain intensity ratings for our Hand than Face stimuli (<italic>t</italic><sub>(6)</sub> = 2.60, p<sub>2</sub>=0.041, BF<sub>10</sub> = 2.31), the same was true for the age- and gender-matched controls (n = 93, <italic>W</italic> = 2738.5, p<sub>2</sub>=0.001, BF<sub>10</sub> = 39.40). This was somewhat surprising because the Hand and Face stimuli were rated as similarly intense in a validation study that preceded stimulus selection (<xref ref-type="bibr" rid="bib22">Gallo et al., 2018</xref>). Right<bold>:</bold> standard deviation of the ratings for each participant. Because the efficiency of a regression depends on the standard deviation of the predictor, and much of our results depend on the relation between rating and intracranial electroencephalographic (iEEG) responses, we calculated the standard deviation for each participant and condition. The standard deviations were normally distributed (all Shapiro–Wilk p&gt;0.25), we then used a <italic>t</italic>-test to compare them across the two conditions. We found no significant difference amongst the patients (<italic>t</italic><sub>(6)</sub> = 1.44, p<sub>2</sub>=0.199, BF<sub>10</sub> = 0.75). Differences we find in the correlations between rating and iEEG across Hand and Face stimuli therefore cannot be due to difference in the efficiency of these two estimations.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="3" colspan="2"/><th align="center" valign="middle" colspan="8">Rating</th><th align="center" valign="middle" colspan="2">M (rating)</th><th align="center" valign="middle" colspan="2">SD (rating)</th></tr><tr><th align="center" valign="middle" colspan="4">Hand</th><th align="center" valign="middle" colspan="4">Face</th><th align="center" valign="middle" rowspan="2">Hand</th><th align="center" valign="middle" rowspan="2">Face</th><th align="center" valign="middle" rowspan="2">Hand</th><th align="center" valign="middle" rowspan="2">Face</th></tr><tr><th align="center" valign="middle">1–2</th><th align="center" valign="middle">3–4</th><th align="center" valign="middle">5–6</th><th align="center" valign="middle">7–8</th><th align="center" valign="middle">1–2</th><th align="center" valign="middle">3–4</th><th align="center" valign="middle">5–6</th><th align="center" valign="middle">7–8</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="8">Patient</td><td align="center" valign="middle">A</td><td align="center" valign="middle">1.67</td><td align="center" valign="middle">38.33</td><td align="center" valign="middle">43.33</td><td align="center" valign="middle">16.67</td><td align="center" valign="middle">40.00</td><td align="center" valign="middle">28.33</td><td align="center" valign="middle">25.00</td><td align="center" valign="middle">6.67</td><td align="center" valign="middle">2.75</td><td align="center" valign="middle">1.98</td><td align="center" valign="middle">0.75</td><td align="center" valign="middle">0.97</td></tr><tr><td align="center" valign="middle">B</td><td align="center" valign="middle">0.00</td><td align="center" valign="middle">16.67</td><td align="center" valign="middle">50.00</td><td align="center" valign="middle">33.33</td><td align="center" valign="middle">36.67</td><td align="center" valign="middle">35.00</td><td align="center" valign="middle">13.33</td><td align="center" valign="middle">15.00</td><td align="center" valign="middle">3.17</td><td align="center" valign="middle">2.07</td><td align="center" valign="middle">0.69</td><td align="center" valign="middle">1.06</td></tr><tr><td align="center" valign="middle">C</td><td align="center" valign="middle">0.00</td><td align="center" valign="middle">0.00</td><td align="center" valign="middle">43.33</td><td align="center" valign="middle">56.67</td><td align="center" valign="middle">56.67</td><td align="center" valign="middle">43.33</td><td align="center" valign="middle">0.00</td><td align="center" valign="middle">0.00</td><td align="center" valign="middle">3.57</td><td align="center" valign="middle">1.43</td><td align="center" valign="middle">0.50</td><td align="center" valign="middle">0.50</td></tr><tr><td align="center" valign="middle">D</td><td align="center" valign="middle">1.67</td><td align="center" valign="middle">38.33</td><td align="center" valign="middle">38.33</td><td align="center" valign="middle">21.67</td><td align="center" valign="middle">35.00</td><td align="center" valign="middle">41.67</td><td align="center" valign="middle">23.33</td><td align="center" valign="middle">0.00</td><td align="center" valign="middle">2.80</td><td align="center" valign="middle">1.88</td><td align="center" valign="middle">0.80</td><td align="center" valign="middle">0.76</td></tr><tr><td align="center" valign="middle">E</td><td align="center" valign="middle">28.33</td><td align="center" valign="middle">28.33</td><td align="center" valign="middle">31.67</td><td align="center" valign="middle">11.67</td><td align="center" valign="middle">35.00</td><td align="center" valign="middle">20.00</td><td align="center" valign="middle">28.33</td><td align="center" valign="middle">16.67</td><td align="center" valign="middle">2.27</td><td align="center" valign="middle">2.27</td><td align="center" valign="middle">1.01</td><td align="center" valign="middle">1.12</td></tr><tr><td align="center" valign="middle">F</td><td align="center" valign="middle">25.00</td><td align="center" valign="middle">40.00</td><td align="center" valign="middle">25.00</td><td align="center" valign="middle">10.00</td><td align="center" valign="middle">38.33</td><td align="center" valign="middle">31.67</td><td align="center" valign="middle">25.00</td><td align="center" valign="middle">5.00</td><td align="center" valign="middle">2.20</td><td align="center" valign="middle">1.97</td><td align="center" valign="middle">0.94</td><td align="center" valign="middle">0.92</td></tr><tr><td align="center" valign="middle">G</td><td align="center" valign="middle">38.33</td><td align="center" valign="middle">23.33</td><td align="center" valign="middle">26.67</td><td align="center" valign="middle">11.67</td><td align="center" valign="middle">36.67</td><td align="center" valign="middle">28.33</td><td align="center" valign="middle">25.00</td><td align="center" valign="middle">10.00</td><td align="center" valign="middle">2.12</td><td align="center" valign="middle">2.08</td><td align="center" valign="middle">1.06</td><td align="center" valign="middle">1.01</td></tr><tr><td align="center" valign="middle">Mean ± SEM</td><td align="center" valign="middle">13.57<break/>± 5.74</td><td align="center" valign="middle">26.43<break/>± 5.10</td><td align="center" valign="middle">36.90<break/>± 3.29</td><td align="center" valign="middle">23.10<break/>± 5.90</td><td align="center" valign="middle">39.76<break/>± 2.68</td><td align="center" valign="middle">32.62<break/>± 2.85</td><td align="center" valign="middle">20.00<break/>± 3.50</td><td align="center" valign="middle">7.62<break/>± 2.33</td><td align="center" valign="middle">2.70</td><td align="center" valign="middle">1.95</td><td align="center" valign="middle">0.82</td><td align="center" valign="middle">0.91</td></tr><tr><td align="center" valign="middle">Control</td><td align="center" valign="middle">Mean ± SEM</td><td align="center" valign="middle">33.01<break/>± 2.13</td><td align="center" valign="middle">38.89<break/>± 1.30</td><td align="center" valign="middle">21.25<break/>± 1.73</td><td align="center" valign="middle">6.85<break/>± 1.12</td><td align="center" valign="middle">44.55<break/>± 1.69</td><td align="center" valign="middle">32.76<break/>± 1.05</td><td align="center" valign="middle">16.99<break/>± 1.19</td><td align="center" valign="middle">5.70<break/>± 0.93</td><td align="center" valign="middle">2.02</td><td align="center" valign="middle">1.84</td><td align="center" valign="middle">0.74</td><td align="center" valign="middle">0.81</td></tr></tbody></table></table-wrap></sec><sec id="s2-2"><title>LFP activity in the insula correlates with the perceived intensity of the pain of others</title><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Post-hoc comparisons of <xref ref-type="fig" rid="fig2">Figure 2f</xref>.</title><p>To follow up on the repeated-measures ANOVA (rmANOVA) on the 1 s broadband power (BBP) with factors period (neutral, pain) × rating (1–2, 3–4, 5–6, 7–8), the table reports, for each contrast of interest indicated over the first two left columns: the average (SEM) of % power change, the <italic>W</italic> (if normality was violated) or <italic>t</italic> (when the data was normal) test values, and the two-tailed p and BF<sub>10</sub> values for the tested comparison.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle">Period</th><th align="center" valign="middle">Pain rating</th><th align="center" valign="middle">% power change</th><th align="center" valign="middle"><italic>W</italic></th><th align="center" valign="middle"><italic>t</italic><sub>(84)</sub></th><th align="center" valign="middle">p<sub>2</sub></th><th align="center" valign="middle">BF<sub>10</sub></th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="4">Neutral vs. pain period</td><td align="center" valign="middle">1–2</td><td align="center" valign="middle">–1.34 (0.35) vs. –1.16 (0.56)</td><td align="center" valign="middle">1903</td><td align="center" valign="middle"/><td align="center" valign="middle">0.742</td><td align="center" valign="middle">0.13</td></tr><tr><td align="center" valign="middle">3–4</td><td align="center" valign="middle">–1.43 (0.32) vs. –0.92 (0.55)</td><td align="center" valign="middle">1801</td><td align="center" valign="middle"/><td align="center" valign="middle">0.909</td><td align="center" valign="middle">0.15</td></tr><tr><td align="center" valign="middle">5–6</td><td align="center" valign="middle">–1.48 (0.35) vs. 0.36 (0.67)</td><td align="center" valign="middle"/><td align="center" valign="middle">3.42</td><td align="center" valign="middle">0.001</td><td align="center" valign="middle">24.31</td></tr><tr><td align="center" valign="middle">7–8</td><td align="center" valign="middle">0.84 (0.67) vs. 6.07 (1.05)</td><td align="center" valign="middle"/><td align="center" valign="middle">7.29</td><td align="center" valign="middle">2 × 10<sup>–10</sup></td><td align="center" valign="middle">6 × 10<sup>7</sup></td></tr><tr><td align="center" valign="middle" rowspan="3">Pain period</td><td align="center" valign="middle">1–2 vs. 3–4</td><td align="center" valign="middle">–1.16 (0.56) vs. –0.92 (0.55)</td><td align="center" valign="middle">1966</td><td align="center" valign="middle"/><td align="center" valign="middle">0.545</td><td align="center" valign="middle">0.12</td></tr><tr><td align="center" valign="middle">3–4 vs. 5–6</td><td align="center" valign="middle">–0.92 (0.55) vs. 0.36 (0.67)</td><td align="center" valign="middle">1065</td><td align="center" valign="middle"/><td align="center" valign="middle">8 × 10<sup>–4</sup></td><td align="center" valign="middle">15.21</td></tr><tr><td align="center" valign="middle">5–6 vs. 7–8</td><td align="center" valign="middle">0.36 (0.67) vs. 6.07 (1.05)</td><td align="center" valign="middle">309</td><td align="center" valign="middle"/><td align="center" valign="middle">3 × 10<sup>–11</sup></td><td align="center" valign="middle">950,944</td></tr></tbody></table></table-wrap><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Post-hoc comparisons of <xref ref-type="fig" rid="fig2">Figure 2h</xref>.</title><p>To follow up on the two significant stimulus (Hand, Face) × rating repeated-measures ANOVAs (rmANOVAs), one for the early, one for the late period, the table reports, for each contrast of interest indicated over the first three left columns: the average (SEM) of % power change, the <italic>W</italic> (if normality was violated) or <italic>t</italic> (when the data was normal) test values, and the two-tailed p and BF<sub>10</sub> values for the tested comparison. The degrees of freedom were 47, as n = 48 since all possible rating options were only used by four patients with a total of 48 electrodes. Patients who used only some of the ratings are included in analyses using <italic>r</italic>(BBP,rating), but cannot be included in this rmANOVA approach.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle">Period</th><th align="center" valign="middle">Stimulus</th><th align="center" valign="middle">Pain rating</th><th align="center" valign="middle">% power change</th><th align="center" valign="middle"><italic>W</italic></th><th align="center" valign="middle"><italic>t</italic><sub>(84)</sub></th><th align="center" valign="middle">p<sub>2</sub></th><th align="center" valign="middle">BF<sub>10</sub></th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="6">Early period</td><td align="center" valign="middle" rowspan="3">Hand</td><td align="center" valign="middle">1–2 vs. 3–4</td><td align="center" valign="middle">2.11 (1.59) vs. –3.16 (0.94)</td><td align="center" valign="middle">1014</td><td align="center" valign="middle"/><td align="center" valign="middle">3 × 10<sup>–6</sup></td><td align="center" valign="middle">847.14</td></tr><tr><td align="center" valign="middle">3–4 vs. 5–6</td><td align="center" valign="middle">–3.16 (0.94) vs. 2.44 (1.03)</td><td align="center" valign="middle"/><td align="center" valign="middle">5.97</td><td align="center" valign="middle">3 × 10<sup>–7</sup></td><td align="center" valign="middle">51,110</td></tr><tr><td align="center" valign="middle">5–6 vs. 7–8</td><td align="center" valign="middle">2.44 (1.03) vs. 8.32 (1.61)</td><td align="center" valign="middle">188</td><td align="center" valign="middle"/><td align="center" valign="middle">2 × 10<sup>–5</sup></td><td align="center" valign="middle">764.63</td></tr><tr><td align="center" valign="middle" rowspan="3">Face</td><td align="center" valign="middle">1–2 vs. 3–4</td><td align="center" valign="middle">–1.81 (0.6) vs. –1.75 (0.6)</td><td align="center" valign="middle"/><td align="center" valign="middle">0.1</td><td align="center" valign="middle">0.92</td><td align="center" valign="middle">0.16</td></tr><tr><td align="center" valign="middle">3–4 vs. 5–6</td><td align="center" valign="middle">–1.75 (0.6) vs. –1.54 (0.95)</td><td align="center" valign="middle"/><td align="center" valign="middle">0.25</td><td align="center" valign="middle">0.803</td><td align="center" valign="middle">0.16</td></tr><tr><td align="center" valign="middle">5–6 vs. 7–8</td><td align="center" valign="middle">–1.54 (0.95) vs. –1.83 (1.35)</td><td align="center" valign="middle"/><td align="center" valign="middle">0.23</td><td align="center" valign="middle">0.817</td><td align="center" valign="middle">0.16</td></tr><tr><td align="center" valign="middle" rowspan="3">Late period</td><td align="center" valign="middle" rowspan="3">Hand and Face</td><td align="center" valign="middle">1–2 vs. 3–4</td><td align="center" valign="middle">–0.76 (1.01) vs. –0.73 (0.84)</td><td align="center" valign="middle">597</td><td align="center" valign="middle"/><td align="center" valign="middle">0.931</td><td align="center" valign="middle">0.16</td></tr><tr><td align="center" valign="middle">3–4 vs. 5–6</td><td align="center" valign="middle">–0.73 (0.84) vs. 1.96 (1.13)</td><td align="center" valign="middle"/><td align="center" valign="middle">3.46</td><td align="center" valign="middle">0.001</td><td align="center" valign="middle">25.15</td></tr><tr><td align="center" valign="middle">5–6 vs. 7–8</td><td align="center" valign="middle">1.96 (1.13) vs. 4.75 (1.44)</td><td align="center" valign="middle"/><td align="center" valign="middle">2.9</td><td align="center" valign="middle">0.006</td><td align="center" valign="middle">6.29</td></tr></tbody></table></table-wrap><p>Correlating power with reported pain intensity, irrespectively of whether Hand or Face videos were shown, revealed a cluster of positive correlations ranging from 20 to 190 Hz and 1.12–1.62 s (p<sub>1</sub>&lt;0.001; p<sub>1</sub>=one-tailed p-value), another cluster of positive correlations at very low frequencies (1–6 Hz, 0.02–2.06 s; p<sub>1</sub>&lt;0.001), and a small cluster of negative correlations (13–17 Hz, 1.30–1.83 s; p<sub>1</sub>=0.004, not further discussed; <xref ref-type="fig" rid="fig2">Figure 2a</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a</xref>). Intensity coding was apparent in all traditional frequency ranges, except alpha (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), and, as expected, was significant in the pain period. With no obvious differences among frequency bands above alpha, we henceforth used the frequency band 20–190 Hz for all analyses and refer to it as broadband power (BBP). We concentrate on BBP rather than oscillatory signals in lower frequencies because BBP is more closely linked to neural spiking (<xref ref-type="bibr" rid="bib5">Bartoli et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Buzsáki et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Miller et al., 2014</xref>), cannot be explored in noninvasive EEG recordings, and is the frequency range that can supplement the information available for the substantial fMRI literature (<xref ref-type="bibr" rid="bib9">Boynton, 2011</xref>; <xref ref-type="bibr" rid="bib45">Maier et al., 2008</xref>). The temporal profile of the BBP–rating association revealed two periods with significant positive correlations: 1.14–1.54 s and 1.74–1.96 s (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). Averaging BBP over the entire pain period revealed that, out of 85 macrocontacts within the insula, 27 (32%) showed a significant positive correlation (assessed as p<sub>1</sub>&lt;0.05, <xref ref-type="fig" rid="fig2">Figure 2c</xref>) between perceived intensity and BBP (n = 120 trials, all <italic>r</italic><sub>S(118)</sub> &gt; 0.156, p<sub>1</sub>&lt;0.045), which was extremely unlikely to occur by chance (binomial p<sub>1</sub>=5 × 10<sup>–15</sup>, BF<sub>+0</sub> = 3 × 10<sup>12</sup>). Furthermore, randomly picking 85 electrodes anywhere in the brain (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplements 2</xref> and <xref ref-type="fig" rid="fig2s3">3</xref>) yielded BBP–rating associations that were significantly lower than those we found in the insula (p<sub>1</sub>=4 × 10<sup>–5</sup>, <xref ref-type="fig" rid="fig2">Figure 2d</xref>), confirming that the BBP in the insula has enriched intensity coding. Splitting trials based on reported intensity and identifying moments in which the intensity coding is significant in an ANOVA confirmed that BBP scaled with pain ratings from 1.10 to 1.70 s (<xref ref-type="fig" rid="fig2">Figure 2e</xref>). Averaging the BBP over the 1 s neutral and 1 s pain period and using a period (neutral, pain) × rating repeated-measures ANOVA (rmANOVA) revealed a significant interaction effect (<italic>F</italic><sub>(2.445,205.348)</sub> = 37.49, p=8 × 10<sup>–17</sup>, BF<sub>incl</sub> = 85,925, <xref ref-type="fig" rid="fig2">Figure 2f</xref>). Planned comparisons indicate that the effect of reported intensity depends mainly on BBP increases for the two highest intensity ratings relative to the neutral period and lower ratings (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, <xref ref-type="table" rid="table2">Table 2</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Intensity coding in the insula local field potential (LFP) activity for Hands and Faces together.</title><p>(<bold>a</bold>) For each frequency and time relative to stimulus onset, the average <italic>r<sub>S</sub></italic> value over all insular bipolar recordings between intracranial electroencephalographic (iEEG) power and rating for Face and Hand trials together, without (left) and with (right) cluster correction for multiple comparisons. BBP: broadband power, the cluster of significant positive intensity coding frequencies (i.e., <italic>r<sub>S</sub></italic> &gt;0, 20–190 Hz) used throughout the article. The time–frequency decomposition per rating can be found in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>. (<bold>b</bold>) Mean ± SEM time course of intensity coding in different frequencies and BBP over all insular bipolar recordings when Face and Hand trials are combined. Above the x-axis, black and yellow-to-red bars show periods of significant intensity coding after circular shift correction for multiple comparisons during the neutral and pain periods, respectively. Below the x-axis, the black bar marks the neutral and the yellow-to-red bar indicates the pain period. (<bold>c</bold>) Intensity coding in the 85 bipolar recordings is shown as significant (p<sub>1</sub>&lt;0.05, filled black circles) or nonsignificant (p<sub>1</sub>&gt;0.05, open circles) based on the MNI y (anterior–posterior) and z (dorsoventral) coordinates. The heatmap shows the interpolated intensity coding values between these locations. Electrodes in the right and left insula are projected onto the same sagittal representation. (<bold>d</bold>) The <italic>t</italic>-value of a <italic>t</italic>-test comparing the intensity coding of all insular 85 bipolar recordings combining Hand and Face trials within the pain period (1–2 s post-stimulus onset) in the insula against zero (red bar) was higher than the distribution of the corresponding <italic>t</italic>-values obtained when performing the same test using 85 bipolar recordings randomly selected 100,000 times from the macroelectrode contacts of our seven patients anywhere in the brain (see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> for a map of all macrocontacts and <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref> for the anatomical distributions of these macrocontacts). (<bold>e</bold>) Mean ± SEM time course of percent power change from baseline in BBP (20–190 Hz) over all insular bipolar recordings and over the Hand and Face conditions, but plotted separately for trials rated 1–2, 3–4, 5–6, and 7–8. (<bold>f</bold>) Mean ± SEM percent power change values over all insular bipolar recordings as a function of reported intensity separately for the neutral (black) and pain (yellow-to-red) periods when combining Hand and Face trials. BF<sub>10</sub> values: Bayes factor quantifying evidence for H<sub>1</sub> relative to H<sub>0</sub> from a nonparametric <italic>t</italic>-test comparing BBP during the pain period against that during the neutral period. ***p&lt;0.001 relative to the preceding reported intensity. See <xref ref-type="table" rid="table2">Table 2</xref> for a complete description of the statistical values. (<bold>g</bold>) Mean ± SEM time course of intensity coding in BBP (20–190 Hz) over all insular bipolar recordings for Hands and Faces separately. <italic>r<sub>S</sub></italic> &gt; 0 indicated with green bars for Hands and purple bars for Faces. Black bars indicate <italic>r<sub>S_</sub></italic><sub>Hand</sub> &gt; <italic>r<sub>S_Face</sub></italic>. The early and late periods that result for Hands and Faces, respectively, are used throughout the article. <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref> depicts the percent power change values as a function of time for ratings 1–2, 3–4, 5–6, and 7–8 separately for Hands and Faces. (<bold>h</bold>) Mean ± SEM percent power change in the broadband frequency over all insular bipolar recordings as a function of rating for Hands and Faces in the early and late periods separately. Green *p&lt;0.001 for Hand. Black *p&lt;0.01 for the main effect of rating, that is, combining Hand and Face. See <xref ref-type="table" rid="table3">Table 3</xref> for a complete description of the statistical values.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Time–frequency decomposition as a function of intensity rating.</title><p>(<bold>a</bold>) Mean percent power changes relative to the baseline period (1 s before the onset of videos) over all 85 insular bipolar recordings as a function of time and frequency for all trials rated 1–2 (first column), 3–4 (second column), 5–6 (third column), and 7–8 (fourth column) combining Hand and Face stimuli. (<bold>b</bold>) Same as (<bold>a</bold>), but separately for the Hand (top row) and Face (bottom row) trials.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Glass brain representation of all macrocontacts available in the seven patients.</title><p>Patients are color-coded as in <xref ref-type="fig" rid="fig1">Figure 1c</xref> and <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>. The analysis depicted in <xref ref-type="fig" rid="fig2">Figure 2c</xref> was performed by randomly sampling 85 electrodes 100,000 times from these macrocontacts.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Overview of the anatomical distribution of all macrocontacts available in the seven patients.</title><p>For each electrode, the region it belongs to was determined based on the <xref ref-type="bibr" rid="bib20">Faillenot et al., 2017</xref> atlas by choosing the region with the highest probability of occurrence within 3 mm from the center of the selected electrode. The pie chart simply illustrates the total number of contacts falling within a particular lobe. The complete list can be found at <ext-link ext-link-type="uri" xlink:href="https://osf.io/mcahz/files/osfstorage/62b97b3702d1f3107cf27c39">here</ext-link>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Broadband power (BBP) time course as a function of rating and stimulus.</title><p>Mean ± SEM time course of percent power change from baseline in BBP (20–190 Hz) over all insular bipolar recordings plotted separately for trials rated 1–2, 3–4, 5–6, and 7–8, and for the Hand and Face conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig2-figsupp4-v2.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Intensity coding arises earlier for Hands than Faces</title><p>To investigate how intensity coding depends on the stimulus, we focused on the BBP range of interest (20–190 Hz), identified independently of stimulus type (<xref ref-type="fig" rid="fig2">Figure 2a</xref>), and found significant intensity coding for the Hand from 1.01 to 1.44 s (hereafter called early period) and for the Face from 1.75 to 1.86 s and from 1.91 to 1.98 s (jointly called late period, <xref ref-type="fig" rid="fig2">Figure 2g</xref>). The insula thus reflects, in broadband activity, the perceived intensity with differential time courses for the Hand and Face videos in this study.</p><p>To explore the shape of the BBP–rating relation, we averaged BBP over time for the early and the late periods for each pain rating separately (<xref ref-type="fig" rid="fig2">Figure 2h</xref>). For the early period, a stimulus (Hand, Face) × rating rmANOVA revealed a significant interaction (Greenhouse×Geisser-corrected <italic>F</italic><sub>(2.183,102.621)</sub> = 13.55, p=3 × 10<sup>–6</sup>, BF<sub>incl</sub> = 2 × 10<sup>6</sup>). Planned comparisons provided evidence that BBP for Faces in the early period was similar for consecutively increasing painfulness level pairs, whereas an orderly increase in BBP was observed for increasing pain ratings for Hands from 3 to 4 onward (see <xref ref-type="table" rid="table3">Table 3</xref> for the results of the statistical tests). However, BBP for ratings of 1–2 was unexpectedly higher than ratings of 3–4. A similar ANOVA for the late period revealed evidence for the absence of an interaction (<italic>F</italic><sub>(3,141)</sub> = 0.55, p=0.650, BF<sub>incl</sub> = 0.03). There was only a significant main effect of rating (<italic>F</italic><sub>(3,141)</sub> = 16.54, p=3 × 10<sup>–9</sup>, BF<sub>incl</sub> = 2 × 10<sup>7</sup>), indicating that BBP in the late period of the Hand and Face videos together was the same for ratings 1–2 and 3–4, but thereafter showed significant increases with each consecutive increase in pain ratings (see <xref ref-type="table" rid="table3">Table 3</xref> for the results of the statistical tests). Taken together, these analyses indicate that BBP in the insula reflects perceived intensity only for the Hand stimuli in the early, and for both stimulus types in the late period.</p></sec><sec id="s2-4"><title>The timing of shape information matches that of Face intensity coding</title><p>Having observed differences in the temporal profiles of intensity coding for Hands and Faces, we next assessed whether these differences could arise from the timing of different intensity cues depicted in the two video types. We first subjected our stimuli to more detailed, time-resolved analyses to describe the temporal evolution of the motion information in the Hand videos, and the motion and the shape information in the Face videos. Motion information for both Hands and Faces was quantified based on pixel-based intensity changes across consecutive frame pairs. Shape information for Faces was estimated using an automated face analysis software to extract the two most reliable shape features of painful facial expressions: how lowered the eyebrows and how tightened the eyelids are (facial action units [AUs] 4 and 7, respectively, <xref ref-type="fig" rid="fig3">Figure 3a</xref>, <xref ref-type="bibr" rid="bib38">Kunz et al., 2019</xref>). Appendix 1 indicates that for Faces static shape information was sufficient to explain video ratings, while for Hands, the shape information was not.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Temporal dynamics of pain rating and intensity coding in the insula broadband activity.</title><p>(<bold>a–c</bold>) Motion and shape signals as a function of time and perceived intensity for the Face and Hand videos rated as 1–2, 3–4, 5–6, and 7–8 separately. Each colored curve represents the mean ± SEM for each rating. Purple and green bars indicate the periods with significant broadband power (BBP)–rating correlations for Faces and Hands, respectively (as in <xref ref-type="fig" rid="fig2">Figure 2g</xref>). Black lines represent the partial least-square regression (PLSR) beta coefficients predicting perceived intensity ratings using motion (for Hand and Faces) or shape information (for Faces). The white transparent circles over the inlet figure in (<bold>a</bold>) shows the action units (AUs) 4 and 7 that were used to estimate the intensity of the shape information in Face videos. (<bold>d–f</bold>) Accuracy with which the motion or shape signal across all frames can be used to predict the intensity rating of the movie. The histogram shows the actual predictive accuracy averaged over cross-validation folds (green and purple) relative to the null distribution of shuffled ratings (gray), with the median and top 5% of the null distribution shown as full and dashed line. In all cases, the actual accuracy was higher than all 10,000 shuffling values, as indicated by p&lt;10<sup>–4</sup>. (<bold>g–i</bold>) Mean ± SEM time courses of the correlations between BBP and pain ratings (green and purple, as in <xref ref-type="fig" rid="fig2">Figure 2g</xref>) superimposed with black lines from (<bold>a–c</bold>) for visualization of the temporal similarity between the two curves. (<bold>j–l</bold>) Mean ± SEM lagged correlation (left) and partial correlation coefficients (middle and right) between the temporal profile of BBP–rating correlations and that of the PLSR beta coefficients for the corresponding stimulus information. For partial correlation analyses, middle panel shows <italic>r<sub>P</sub></italic>(BBP(t),Motion(t+lag)|Shape(t+lag)) and the right panel shows <italic>r<sub>P</sub></italic>(BBP(t),Shape(t+lag)|Motion(t+lag)). All correlations are shown for lags from 0 to 1000 ms in steps of 40 ms. The correlation was calculated separately for each of the 85 bipolar recordings. The black bars represent periods of significant correlations, tested using a <italic>t</italic>-test of the 85 correlation values against zero followed by false discovery rate (FDR) correction at q = 0.05. (<bold>m</bold>) Mean ± SEM <italic>r<sub>s</sub></italic> between motion energy and BBP (blue) or between subjective rating and BBP (orange) for the six consecutive bins of 333 ms during the movie. All statistics are two-tailed parametric <italic>t</italic>-tests against zero because <italic>r<sub>s</sub></italic> values were normally distributed (all Shapiro–Wilk p&gt;0.05). Values are indicated in the table above each panel for each time bin of ⅓ s. FDR correction is over the six bins. No <italic>r<sub>s</sub></italic>-to-<italic>z</italic> transform was used because the <italic>r<sub>s</sub></italic> values were in the range –0.5 &lt; <italic>r<sub>S</sub></italic> &lt; 0.5 for which <italic>r</italic> and <italic>z</italic> values are extremely similar. (<bold>n</bold>) As in (<bold>m</bold>), but partial correlations: <italic>r<sub>S</sub></italic>(BBP,motion|rating) in blue and <italic>r<sub>S</sub></italic>(BBP,rating|motion) in orange.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig3-v2.tif"/></fig><p>Leveraging the high temporal resolution of our iEEG recordings, we next asked whether the motion or the shape information better matches the timing of our intensity coding for Faces in the insula. <xref ref-type="fig" rid="fig3">Figure 3a</xref> shows shape information increases toward the end of the movies with rating intensity. Comparing the timing of intensity coding for the Face in the insula BBP (purple bar in <xref ref-type="fig" rid="fig2">Figures 2g</xref> and <xref ref-type="fig" rid="fig3">3a</xref>) with the timing of the shape information for Faces (separation between the curves in <xref ref-type="fig" rid="fig3">Figure 3a</xref>) shows a nice correspondence, with both BBP and shape information being highest toward the end of the movie. Furthermore, a partial least-squares regression (PLSR) analysis indicated that the time course of shape information could predict the rating of our patients with very high accuracy (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). Regarding kinematics, we calculated the changes in pixel values across consecutive frames to track the timing of motion (<xref ref-type="fig" rid="fig3">Figure 3b</xref>), and this information could also predict the rating of our patients with high accuracy for Faces (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). Comparing the timing of intensity coding in the insula for Faces (purple bar in <xref ref-type="fig" rid="fig2">Figure 2g</xref>) with the timing of motion information (separation between the curves in <xref ref-type="fig" rid="fig3">Figure 3b</xref>) shows that intensity coding maximizes when motion information has already declined significantly.</p><p>We complemented these observations with a quantitative approach that estimates how the neural intensity coding lags behind the shape or motion information (<xref ref-type="fig" rid="fig3">Figure 3g, h, j and k</xref>). If motion were, for instance, the driver of neural response to Face stimuli, we would expect that when motion information increases, neural responses should start increasing within ~200 ms, given typical latencies in the insula for facial expressions (<xref ref-type="bibr" rid="bib13">Chen et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">Cornwell et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Krolak-Salmon et al., 2003</xref>; <xref ref-type="bibr" rid="bib49">Meeren et al., 2013</xref>) or other painful or nonpainful sensory stimulations (<xref ref-type="bibr" rid="bib7">Bastuji et al., 2018</xref>; <xref ref-type="bibr" rid="bib7">Bastuji et al., 2018</xref>; <xref ref-type="bibr" rid="bib34">Kobayakawa et al., 1996</xref>; <xref ref-type="bibr" rid="bib42">Liberati et al., 2020</xref>; <xref ref-type="bibr" rid="bib41">Liberati et al., 2016</xref>; <xref ref-type="bibr" rid="bib63">Taniguchi et al., 2022</xref>). Thus, we conducted correlation analyses to test how much the temporal profiles of shape or motion information are associated with the temporal profiles of intensity coding at various lags. Note that to directly contrast the predictive power of the shape and motion information, we used partial correlations. For Faces, partial correlations were positive for shape information in time windows centered at 40–320 ms and for motion at 560–1000 ms lags (<xref ref-type="fig" rid="fig3">Figure 3j and k</xref>). As discussed in more detail in the section ‘Discussion,’ given typical insular response onset latencies, intensity coding for Faces in the insula is more likely to be primarily triggered by shape information.</p></sec><sec id="s2-5"><title>Rating-related motion information could drive Hand intensity coding</title><p>Motion energy is also a reliable predictor of pain intensity ratings for Hands (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). In our Hand videos, motion occurs at two time points: early, when the belt is lifted up, and then again, around the moment when the belt hits the hand (<xref ref-type="fig" rid="fig3">Figure 3c</xref>). Pain, however, occurs only at the second point in time. This allows us to explore whether the insula is coding movement in general, or movement that is associated with pain more specifically. We thus divided the 2 s of the Hand movies into six segments and asked, for each segment, how well BBP relates to motion energy in the same segment (<xref ref-type="fig" rid="fig3">Figure 3m and n</xref>). Over the 85 channels, we had evidence of absence for a relationship during the neutral period that contained the period during which the belt was seen to move upward (all BF<sub>10</sub> &lt; 1/3), and evidence for a relationship during the first 666 ms of the pain period when the belt is seen to slap the hand (both p<sub>unc</sub>&lt;0.003 or p<sub>FDR</sub>&lt;0.018 corrected for six bins, both BF<sub>10</sub> &gt; 8.8). Indeed an rmANOVA comparing the correlation values across the six bins confirms that the relationship between motion energy and BBP changes as a function of time (<italic>F</italic><sub>(5,420)</sub> = 2.9, p=0.014, BF<sub>incl</sub> = 1.52). This shows that the BBP response in the insula does not code motion in general, but motion at a time when it is relevant, here to assess the pain intensity. Next, we asked whether subjective rating or motion energy was the best predictor of BBP across the six bins (<xref ref-type="fig" rid="fig3">Figure 3m and n</xref>). Rating per se was an even better predictor of BBP than motion energy (rmANOVA, 2 predictor × 6 bin, main effect of predictor: <italic>F</italic><sub>(1,84)</sub> = 23, p=7 × 10<sup>–6</sup>, BF<sub>incl</sub> = 13,473). Interestingly, using partial correlations, we see that the correlation between rating and BBP remains highly significant when seeing the belt hit the hand even after removing what can be explained by motion energy, but we have evidence for the absence of a correlation between motion energy and BBP if removing the variance explained by rating (<xref ref-type="fig" rid="fig3">Figure 3n</xref>). Together, this data supports the idea that the insula could employ motion to encode the painfulness in our Hand videos, but does not respond to simply seeing the motion of the belt, and that subjective rating of intensity appears to mediate the relationship between motion and insular response.</p><p>We also conducted the same lagged correlation analysis for Hands, as described for Faces above: that is, calculating the correlation coefficients between the temporal profile of the motion information and the temporal profile of intensity coding for Hands at various lags (<xref ref-type="fig" rid="fig3">Figure 3i and l</xref>). This analysis showed that intensity coding in the insula is best associated with motion information in Hands in time windows with center points that lag behind by 0–80ms (<xref ref-type="fig" rid="fig3">Figure 3l</xref>).</p></sec><sec id="s2-6"><title>The insula contains a surprising number of intensity coding locations with stimulus preference</title><p>We next focused on how individual recording sites in the insula reflected perceived intensity. In the early period, for Hands, 21/85 (25%) showed significant intensity coding (rating–BBP correlations, n = 60 trials, all <italic>r</italic><sub>S(58)</sub>&gt;0.219, p<sub>1</sub>&lt;0.046), which was above chance (binomial, 21/85 at alpha = 0.05, p<sub>1</sub>=9 × 10<sup>–10</sup>, BF<sub>+0</sub> = 2 × 10<sup>7</sup>). In contrast, for Faces, only 3/85 (4%) showed intensity coding in the early period, which is expected by chance (binomial p<sub>1</sub>=0.804, BF<sub>+0</sub> = 0.03). During the late period, above-chance numbers of recordings showed intensity coding for Hands (14/85, 17%, p<sub>1</sub>=8 × 10<sup>–5</sup>, BF<sub>+0</sub> = 201.41), and the same was true for Faces (15/85, 18%, binomial p<sub>1</sub>=2 × 10<sup>–5</sup>, BF<sub>+0</sub> = 808.49; <xref ref-type="fig" rid="fig4">Figure 4a</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>The relationship between Hand and Face intensity coding in the insula broadband activity.</title><p>(<bold>a</bold>) Topographical maps of broadband power (BBP)–rating correlation coefficients for Hands and Faces in the early and late periods. Each circle is one of the recording sites (as in <xref ref-type="fig" rid="fig1">Figure 1c</xref>), with filled circles indicating locations with significant correlation coefficients (p<sub>1</sub>&lt;0.05). (<bold>b</bold>) Classification of recording locations based on their Hand (early period) and Face (late period) intensity coding. Bipolar recordings in the gray zone (n = 5) significantly co-represent intensity for Hands and Faces (both p<sub>1</sub>&lt;0.05, i.e., beyond dashed line). Recordings in the purple (n = 6) and green (n = 10) zone represent intensity coding preference for Faces or Hands, respectively (i.e., p<sub>1</sub>&lt;0.05 for Hands and BF<sub>+0</sub> &lt; ⅓ for Faces, and vice versa). (<bold>c</bold>) Location of all 85 bipolar recordings, color-coded by stimulus preference as described in (<bold>b</bold>). Note that locations Hand and Face without further specification are those with <italic>r<sub>S</sub></italic> values for at least one of the stimulus types falling between the dashed and dotted lines, thus providing inconclusive evidence and showing neither significant dual coding, nor evidence of absence. (<bold>d</bold>) Correlation coefficients for Hands and Faces separated by coding characteristics in (<bold>b</bold>) for all patients together (left) and for an exemplary patient (right). p<sub>bino</sub> refers to the likelihood to find the observed number of locations in that quadrant using a binomial distribution as detailed in section ‘Probability of Face-but-not-Hand, Hand-but-not-Face, and dual-intensity coding LFPs’. (<bold>e</bold>) The left two panels depict the average correlation coefficients, together with corresponding resampling null distributions, as a measure of the accuracy of decoding intensity ratings using the partial least-square regression (PLSR) beta coefficients of BBP in the early period for Hands and in the late period for Faces. The right panels are similar to the left panels, but show the accuracy of cross-decoding, that is, predicting Hand ratings from the Face BBP and vice versa. The dotted lines indicate 95th percentiles of the resampling null distributions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig4-v2.tif"/></fig><p>If the insula simply represents salience, one might expect a tight association between intensity coding for Hands and Faces, and an above-chance number of locations showing dual-intensity coding for both Faces and Hands. In contrast, if the insula also represents more specific information, we would expect above-chance numbers of locations with intensity coding for Faces, but not Hands and vice versa. Statistically, we infer the presence of intensity coding based on <italic>r<sub>S</sub></italic> &gt; 0, p<sub>1</sub>&lt;0.05, like elsewhere in the article, and its absence using Bayesian statistics (<xref ref-type="bibr" rid="bib33">Keysers et al., 2020</xref>), with BF<sub>+0</sub> &lt; ⅓. Plotting each bipolar recording’s <italic>r<sub>S</sub></italic> values on an x–y plot, with x representing <italic>r</italic><sub><italic>S</italic></sub> for Hands and y for Faces, with dashed and dotted lines at critical <italic>r<sub>S</sub></italic> values corresponding to p<sub>1</sub>&lt;0.05 and BF<sub>+0</sub> &lt; ⅓, we define nine quadrants, three of which are of conceptual importance (<xref ref-type="fig" rid="fig4">Figure 4b</xref>): those of locations with dual-intensity coding (i.e., p<sub>1</sub>&lt;0.05 for Faces and Hands), those with intensity coding preference for Faces (i.e., p<sub>1</sub>&lt;0.05 for Faces, but BF<sub>+0</sub> &lt; ⅓ for Hands) and those with intensity coding preference for Hands (i.e., p<sub>1</sub>&lt;0.05 for Hands, but BF<sub>+0</sub> &lt; ⅓ for Faces). We then used binomial tests to compare the proportion of locations falling in these three quadrants against chance and found that all three quadrants contain more locations than expected by chance (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Indeed even within a single patient, among simultaneously recorded channels, we find above-chance numbers of channels with Face coding and with Hand coding preference (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Also, calculating the association between intensity coding across Hand and Face through a simple correlation of the respective <italic>r</italic> values confirms the presence of a significant but weak and barely worth mentioning (in a Bayesian sense) association (<italic>r<sub>K</sub></italic> = 0.131, p<sub>1</sub>=0.038, BF<sub>+0</sub> = 1.27). Together, this shows the insula is a patchwork, with some locations representing the Hand but not the Face, others the Face but not the Hand, and a small number finally representing both in terms of intensity coding. The spatial distribution of these locations is shown in <xref ref-type="fig" rid="fig4">Figure 4c</xref>.</p><p>In addition, we used a multivariate partial least-square regression (PLSR) approach to assess how well the pattern of BBP across the insula can predict participants’ pain ratings. BBP across the 85 sites in the early period for Hands can be used to predict the patients’ average rating of the stimulus with reasonably high accuracy (n = 10 trials since 1/3 of the 30 unique videos were used for testing decoding performance for each randomization, <italic>r</italic><sub>P(8)</sub> = 0.575, p<sub>1</sub>=9 × 10<sup>–4</sup> based on reshuffled distribution), and BBP in the late period for Faces with almost significant accuracy (<italic>r</italic><sub>P(8)</sub> = 0.331, p<sub>1</sub>=0.058, <xref ref-type="fig" rid="fig4">Figure 4e</xref>). A direct comparison of the performance of the two PLSR indicates that the performance was higher for Hands than for Faces (nonparametric test across the decoding performances, <italic>W</italic> = 944,605, p<sub>2</sub>=9 × 10<sup>–260</sup>, BF<sub>10</sub> = 7 × 10<sup>39</sup>). To test whether intensity was encoded through similar patterns for the two stimulus types, we repeated the analyses training the PLSR on one stimulus type and testing it on the other. We found above-chance cross-decoding in both cases (Hand -&gt; Face: <italic>r</italic><sub>P(8)</sub> = 0.343, p<sub>1</sub>=0.029; Face -&gt; Hand: <italic>r</italic><sub><italic>P(8)</italic></sub> = 0.389, p<sub>1</sub>=0.023; <xref ref-type="fig" rid="fig4">Figure 4e</xref>). However, when the five contacts that significantly co-represented intensity for both Hands and Faces (black dots in <xref ref-type="fig" rid="fig4">Figure 4c</xref>) were excluded from the analyses, the cross-decoding accuracy fell to insignificant levels (Hand -&gt; Face: <italic>r</italic><sub>P(8)</sub> = 0.175, p<sub>1</sub>=0.153; Face -&gt; Hand: <italic>r</italic><sub>P(8)</sub> = 0.185, p<sub>1</sub>=0.149). These findings corroborate the above results, indicating that perceived intensity is reflected in the insula as a mixture of Hand-but-not-Face, Face-but-not-Hand, and Hand–Face common representations.</p></sec><sec id="s2-7"><title>Intensity coding for Hands increases anteriorly as in a similar fMRI experiment</title><p>To examine the spatial distribution of intensity coding, we examined the relationship between MNI coordinates of the bipolar recordings and intensity coding (i.e., <italic>r<sub>S</sub></italic>(BBP,rating), <xref ref-type="fig" rid="fig5">Figure 5a</xref>). The only significant association was that more anterior recordings (i.e., more positive y-coordinates) have higher Hand intensity coding. Interestingly, we found evidence against a right–left difference (i.e., BF<sub>10</sub> &lt; ⅓ for x-coordinates) for the Face and Hand, providing moderate evidence against a left–right lateralization. To exclude that this finding could be driven by differences across patients, we also performed a random intercept mixed linear model using x, y, and z coordinates as predictors of Hand intensity coding (without interactions) with patients as random nesting variables. This analysis confirmed the y coordinates predict intensity coding for Hands (X: <italic>F</italic><sub>(1,79.23)</sub> = 0.02, p<sub>2</sub>=0.881; Y: <italic>F</italic><sub>(1,80.97)</sub> = 13.23, p<sub>2</sub>=5 × 10<sup>–4</sup>; Z: <italic>F</italic><sub>(1,73.95)</sub> = 0.17, p<sub>2</sub>=0.685).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>The relationship between the insula broadband and blood-oxygen-level-dependent (BOLD) activity during pain intensity ratings.</title><p>(<bold>a</bold>) Correlations (<italic>r<sub>K</sub></italic>) between MNI coordinates and broadband power (BBP) intensity coding, separately for Hands (green) and Faces (purple). Bold numbers mark evidence for (BF<sub>10</sub> &gt; 3) or against (BF<sub>10</sub> &lt; 1/3) a significant correlation. Statistical values were obtained by correlating separately the x, y, or z coordinate of each bipolar recording with the <italic>r<sub>S</sub></italic>(BBP,rating) of each recording over all 85 recordings. Tau refers to Kendall’s tau, p<sub>2</sub> and BF<sub>10</sub> the two-tailed probability and BF based on H<sub>0</sub>:tau = 0. (<bold>b</bold>) Results of the regression analysis between resting state connectivity and intensity coding for the 85 bipolar recording coordinates for Hands. Significant positive and negative regression values are indicated by warm and cold colors, respectively. Results are corrected at the cluster level at p<sub>FWE</sub>&lt;0.05 using initial cluster cutting at p<sub>unc</sub>&lt;0.001, <italic>t</italic>(82) = 3.19, and then setting the minimum cluster size to FWEc = 772 as determined by the random field theoretical calculation in SPM. The detailed results of this analysis are provided in <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>. (<bold>c</bold>) Mean ± SEM of the predictive performance of a partial least-square regression (PLSR) trained to predict ratings based on the pattern of BOLD activity across all voxels in the insula for different ratings. A leave-one-out cross-validation was used, and each circle represents the <italic>r<sub>K</sub></italic> between the predicted and actual rating for each left-out participant, and the p<sub>1</sub> and BF<sub>+0</sub> values then test these n = 23 correlation values against zero using a nonparametric test. Results are shown separately for Hand and Face trials and using two or three PLSR components separately. (<bold>d</bold>) Topography of intensity coding for the Hand (left) and Face (right), as assessed at the group level, by the parametric modulator capturing changes in BOLD activity that correlate with trial-by-trial differences in participant’s ratings. <italic>t</italic>-values testing the parametric modulator &gt;0 at the group level are shown as a function of y and z coordinate in the insula mask. For each coordinate, the maximum value across all x coordinates within the two insulae is indicated. (<bold>e</bold>) Correlation (<italic>r<sub>P</sub></italic> because of normality) between the <italic>t</italic>-value of the parametric modulator for the rating in the fMRI BOLD responses (x-axis) and the BBP intensity coding (computed in the early period for the Hand, green; late period for the Face, purple) in the intracranial electroencephalographic (iEEG) signal (y-axis) for each of the 85 contact locations. Note that for the fMRI signal the value is taken from the voxel closest to the MNI coordinates of the corresponding contact in the iEEG signal. (<bold>f</bold>) Same as (<bold>e</bold>) but for the difference between Hand and Face coding, calculated as the Hand–Face difference in the correlation between BBP and rating for the iEEG, and the <italic>t</italic>-value of the paired comparison between the parametric rating modulator for Hand–Face in the fMRI data.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Resting state connectivity results.</title><p>The table indicates for each significant cluster the size in number of voxels of the cluster; the number of voxels of that clusters that have been assigned to cytoarchitectonic areas based on the Anatomy toolbox for SPM (<ext-link ext-link-type="uri" xlink:href="http://www.fz-juelich.de/ime/spm_anatomy_toolbox">http://www.fz-juelich.de/ime/spm_anatomy_toolbox</ext-link>); the number of voxels assigned expressed in percentage; the hemisphere covered by the cluster (L = left, R = right); the cytoarchitectonic area those voxels have been assigned to when the information is available, or the anatomical description of the area voxels fell in; the percentage of the cytoarchitectonic area covered by the assigned voxels; the <italic>t</italic>-values of the identified peaks of activity with the respective MNI coordinates.</p></caption><media mimetype="application" mime-subtype="xlsx" xlink:href="elife-75197-fig5-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig5-v2.tif"/></fig><p>To better understand the origin of the anterior gradient for intensity coding for Hands, we performed a regression analysis between intensity coding of the 85 insular recording locations (for Hands and Faces separately) and resting state connectivity seeded at corresponding MNI locations in Neurosynth (<xref ref-type="bibr" rid="bib72">Yarkoni et al., 2011</xref>). Insular locations with higher Hand intensity coding had higher resting state connectivity with the left anterior insula and ventral prefrontal cortex (including BA44/45, OP8/9, Fp1), with the right frontal orbital cortex; with the bilateral cingulate (including BA24/33); and the right cerebellum (Crus I and lobules VI, VII, and VIII, <xref ref-type="fig" rid="fig5">Figure 5b</xref>, <xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>). In line with the lack of spatial gradients for Faces in the insula of our patients, examining which voxels had higher resting state connectivity with insular locations with higher Face intensity coding did not yield any significant voxels (all p<sub>unc</sub>&gt;0.001).</p><p>Finally, we leveraged existing unpublished fMRI data from our lab to test whether the spatial gradient observed in the iEEG data resembles the spatial distribution of BOLD signals in the insula correlating with intensity ratings. Twenty-three independent healthy volunteers participated in the fMRI-adapted version of the rating task. As for the iEEG experiment, participants were asked to rate Hand and Face 2 s videos on painfulness. The stimuli depicted the same actor as in the iEEG experiment and were made following the same procedure. To test whether the pattern of BOLD activity in the insula can be used to predict the ratings of the participants, we defined eight separate regressors in each participant, capturing all trials that participants rated with intensity 0–2, 3–4, 5–6, or 7–8 separately for Hand and Face trials. We then performed a PLSR with either two or three components using all voxels in the insula to predict the intensity rating. A leave-one-out cross-validation was used, and the correlation between the predicted and actual rating for each left-out participant was compared against zero. This confirmed that BOLD activity in the insula can be used to predict the perceived intensity for Hands (one-sample <italic>t</italic>-tests for two components: <italic>t</italic><sub>(22)</sub> = 3.42, p<sub>1</sub>=0.001, BF<sub>+0</sub> = 32.32 and three components: <italic>t</italic><sub>(22)</sub> = 2.88, p<sub>1</sub>=0.004, BF<sub>+0</sub> = 10.95) and Faces (one-sample <italic>t</italic>-tests for two components: <italic>t</italic><sub>(22)</sub> = 2.78, p<sub>1</sub>=0.016, BF<sub>+0</sub> = 3.61 and three components: <italic>t</italic><sub>(22)</sub> = 3.86, p<sub>1</sub>&lt;0.001, BF<sub>+0</sub> = 81.35; <xref ref-type="fig" rid="fig5">Figure 5c</xref>), and performance did not differ across Hands and Faces (paired <italic>t</italic>-test comparing the leave-one-subject-out performance for Hands and Faces, with two components, <italic>t</italic><sub>(22)</sub> = 0.675, p<sub>2</sub>=0.507, BF<sub>10</sub> = 0.27; three components: <italic>t</italic><sub>(22)</sub> = –0.39, p<sub>2</sub>=0.700, BF<sub>10</sub> = 0.23). To compare the spatial pattern of intensity coding across the iEEG and fMRI data, we defined separate regressors for the Hand videos, Face videos, rating scale and button presses, and used the trial-by-trial ratings given by the participants as parametric modulators, one for the Face and one for the Hand trials, on the respective video regressor. For both Hands and Faces, visually inspecting <xref ref-type="fig" rid="fig5">Figure 5d</xref> reveals a gradient along the y-axis with more anterior locations showing stronger, and more positive associations between BOLD activity and rating. For Hands, across our 85 bipolar recordings in the patients, locations with higher BBP intensity coding in iEEG also show higher <italic>t</italic>-values comparing the parametric modulator for rating against zero in the BOLD signal (<xref ref-type="fig" rid="fig5">Figure 5e</xref>). For Faces, on the other hand, we found evidence of absence for an association of the two measures (<xref ref-type="fig" rid="fig5">Figure 5e</xref>). Finally, we also found that locations that had a stronger preference in their intensity rating for Hand over Face in the iEEG, also had a stronger preference in the fMRI data (<xref ref-type="fig" rid="fig5">Figure 5f</xref>).</p></sec><sec id="s2-8"><title>The insula contains neurons with intensity coding for Hands and/or Faces</title><p>The insula thus displays intensity coding in a broad frequency range, including locations with Hand-but-not-Face or Face-but-not-Hand intensity coding, as well as locations showing intensity coding for both stimulus types. To explore this representation at the level of single neurons, we analyzed the microelectrode data from the three patients (patients C, D, and E) that had microwires in the ventral anterior insula (pluses in <xref ref-type="fig" rid="fig1">Figure 1c</xref>). Spike sorting resulted in a total of 28 candidate neurons. From these, 13 showed more spikes during the pain period than the pre-stimulus baseline. Among those, eight show intensity coding for Faces and/or Hands (<xref ref-type="fig" rid="fig6">Figure 6</xref>), with significant Kendall’s tau correlations between perceived intensity (1–2, 3–4, 5–6, 7–8) and spike count during the pain period (1–2 s post-stimulus onset) for at least one stimulus type: 4/8 for Faces and 5/8 for Hands (binomial test, Face: p<sub>1</sub>=0.003, BF<sub>+0</sub> = 27; Hands: p<sub>1</sub>=3 × 10<sup>–4</sup>, BF<sub>+0</sub> = 282). Considering the p<sub>1</sub>-value for the intensity coding, two cells (a, b) showed intensity coding for both Hands and Faces, three (c–e) only for Hands, and three (f–h) only for Faces. If we additionally consider the BF<sub>+0</sub> values below ⅓ as evidence for the absence of coding in the other stimulus type, we find three Hand-but-not-Face coding cells (c–e) and two Face-but-not-Hand coding cells (g, h). Importantly, within patient D, we observe the coexistence of Hand-but-not-Face (c, d) and Face-but-not-Hand intensity coding (g).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Intensity coding in the insula single units and the corresponding broadband activity.</title><p>(<bold>a–h</bold>) Left (Face) and right (Hand) columns display, for each single unit, the rastergrams and peri-stimulus time histograms (PSTH) for eight cells that showed intensity coding for at least one stimulus type. For the PSTH, each curve represents the mean ± SEM of the firing rate in each bin for trials with the corresponding rating. Not all patients gave all possible ratings in each condition. For the rastergram, trials are sorted in order of rating, with the highest ratings upmost. The color bar next to the rastergram indicates the rows corresponding to each rating. p<sub>1</sub> and BF<sub>+0</sub> values result from a one-tailed test of the Kendall’s tau between rating and spike count in the pain period (marked by the dashed lines). *Significant intensity coding (p<sub>1</sub>&lt;0.05), t: trend (p<sub>1</sub>&lt;0.1), X: evidence of absence for a positive intensity coding (BF<sub>+0</sub> &lt; 1/3). The x-axis (time) is relative to the movie onset. The color bar on the leftmost side indicates from which patient the data is taken. Middle columns show the broadband power (BBP) averaged over the pain period for the microelectrode (from which the corresponding single unit was extracted) as a function of rating where boxplots show variance across trials. The box and whiskers represent the quartiles across trials, and the p<sub>1</sub> and BF<sub>+0</sub>, the Kendall’s tau test of the association of rating and BBP. Note that cells c and d were taken from the same microwire, and therefore have only one BBP graph.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-fig6-v2.tif"/></fig><p>To explore how spiking relates to BBP, we analyzed the BBP from the 10 microelectrodes that yielded the 13 cells showing stimulus triggered responses. Using Kendall’s tau correlations between BBP (20–190 Hz) and patients’ intensity ratings (1–2, 3–4, 5–6, 7–8) and comparing these results with the coding of the cells on the same wire reveals a relationship between the two. For Hands, 2/3 microelectrodes that yielded cells with intensity coding also showed significant association between ratings and BBP (<xref ref-type="fig" rid="fig6">Figure 6a, c and d</xref>). Indeed, intensity coding (i.e., correlation between intensity rating and spiking/BBP) was significantly correlated across the 10 microwires (<italic>r<sub>K</sub></italic> = 0.57, p<sub>1</sub>=0.012, BF<sub>+0</sub> = 7.69). For Faces, only 1/5 microelectrodes with spike intensity coding cells showed significant intensity coding in the BBP, and 2/5 showed a trend. Across the wires, there was a trend toward an association between the intensity coding in the spikes and BBP (<italic>r<sub>K</sub></italic> = 0.34, p<sub>1</sub>=0.088, BF<sub>+0</sub> = 1.63).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Here we characterize how the insula’s iEEG activity encodes the intensity of other people’s emotions using pain as an important category. LFPs indicate that neural activity in the insula within a broad range of frequencies, including the conventional theta, beta, and gamma frequency bands, scales with the perceived intensity of pain expressed by others. Interestingly, the insula only appeared to be recruited once the perceived pain level was at least moderate: activity was increased for moderate (5–6) compared to mild (3–4) and for severe (7–8) compared to moderate. However, activity for mild pain (3–4) was not significantly increased compared to minimal pain (1–2), or baseline activity. This echoes a recent finding that BBP activity in the insula is selectively increased only once thermal stimulation is consistently painful (<xref ref-type="bibr" rid="bib42">Liberati et al., 2020</xref>). Furthermore, we isolate a small number of insular neurons increasing their firing with increases in the intensity of pain experienced by others.</p><p>As mentioned in the section ‘Introduction,’ BOLD signals can dissociate from neural spiking (<xref ref-type="bibr" rid="bib9">Boynton, 2011</xref>; <xref ref-type="bibr" rid="bib45">Maier et al., 2008</xref>). Just as V1 BOLD signals fluctuate with perception while spiking in V1 does not (<xref ref-type="bibr" rid="bib45">Maier et al., 2008</xref>), the observation that BOLD signals in the insula fluctuate with perceived pain intensity alone cannot guarantee that neuronal spiking in the insula does. The insula’s BOLD signal could instead fluctuate with perceived intensity simply as a result of feedback synaptic input from other brain regions that encode perceived intensity (e.g., area 24 in the cingulate gyrus; <xref ref-type="bibr" rid="bib11">Carrillo et al., 2019</xref>). The foremost impact of our broadband gamma and spiking data is thus to provide what is arguably the first evidence that the intensity of other people’s pain is indeed locally encoded in the activity of neurons in the insula.</p><p>The human insula has been in the focus of pain neuroscience as part of the pain matrix recruited by first-hand experience of pain (<xref ref-type="bibr" rid="bib26">Ingvar, 1999</xref>). In this tradition, neuroimaging evidence for activation of the insula while witnessing pain experienced by others has led many to suggest it may represent a neural basis for empathy for pain (<xref ref-type="bibr" rid="bib8">Bernhardt and Singer, 2012</xref>; <xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Lamm et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>). However, the insula is also recruited by a variety of tasks beyond nociception and pain empathy, including other affective states, sensorimotor functions, and decision-making under uncertainty (<xref ref-type="bibr" rid="bib16">Craig, 2002</xref>; <xref ref-type="bibr" rid="bib17">Craig, 2009</xref>; <xref ref-type="bibr" rid="bib67">Uddin, 2015</xref>; <xref ref-type="bibr" rid="bib68">Uddin et al., 2017</xref>). With so many tasks recruiting the insula, the idea has become popular that it may play a key role in attaching salience to behaviorally important stimuli (<xref ref-type="bibr" rid="bib40">Legrain et al., 2011</xref>; <xref ref-type="bibr" rid="bib67">Uddin, 2015</xref>; <xref ref-type="bibr" rid="bib68">Uddin et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Zaki et al., 2016</xref>). In this study, we do not intend to (and cannot) address the selectivity of the insula for the pain of others over other emotions, and we do not claim the neural responses we report are pain-specific. Instead, we characterize how the insula’s iEEG activity encodes the intensity of other people’s emotions, using pain as an important category, and use the agnostic terminology of ‘intensity coding’ rather than ‘pain intensity coding’ throughout the article to refer to recording sites. That the insula’s broadband activity correlated with motion energy in our Hand stimuli only while the motion was associated with pain (during the slapping), but not while motion was innocuous (during the initial belt lifting), shows that the effects we measured cannot be reduced to visual motion detection. That perceived intensity was mediating the association between motion and broadband activity further speaks against an interpretation of our results as reflecting unspecific motion processing. Future experiments using a wider gamut of control stimuli that are matched in motion but differ in emotions will be critical to address the specificity of the responses we describe, and hence, what state they could reliably signal (<xref ref-type="bibr" rid="bib74">Zaki et al., 2016</xref>). For the Hand stimuli, this could include seeing hands experience a range of different salient affective experiences, such as a hand being hurt, being caressed, and being rejected in addition to a neutral handshake (<xref ref-type="bibr" rid="bib50">Meffert et al., 2013</xref>), or the actor in our Hand movies could have been asked to reposition their hand after each slap. For the face, this could include disgusted, angry, fearful, and happy facial expressions matched for motion. In general, using multiple actors and painful hand interaction could help characterize how intensity coding in the insula is influenced by details of the stimuli that convey it, including the identity and gender of the actor, and how well our results generalize to other stimulus sets (<xref ref-type="bibr" rid="bib73">Yarkoni, 2020</xref>).</p><p>An important and somewhat related question has been whether pain or salience cues are represented in a modality-specific or modality-general manner in the insula. fMRI studies have shown that the anterior insula is coactivated with different brain regions depending on whether the pain of others is conveyed via indirect cues or via the actual body part, such as the hand, that directly receives the noxious stimulation (<xref ref-type="bibr" rid="bib22">Gallo et al., 2018</xref>; <xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Keysers et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Lamm et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>). Here, we provide electrophysiological measures of neural activity that speak to that issue. We focus on the broadband gamma signal known to have comparatively high spatial specificity and be closest to neural spiking (<xref ref-type="bibr" rid="bib5">Bartoli et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Buzsáki et al., 2012</xref>; <xref ref-type="bibr" rid="bib51">Miller et al., 2014</xref>), and find a mixed organization, consisting of modality-specific and -general locations in a partially intermixed layout. That is, we found locations with broadband activity and spiking associated with perceived intensity for the Hand, but not the Face; others associated with the Face, but not the Hand; and others still associated with perceived intensity for both. This echoes findings in recent fMRI studies that show that at the level of BOLD response within the insula some voxels encode intensity for both Hand and Face stimuli, while some only significantly contribute to intensity coding for one stimulus type (<xref ref-type="bibr" rid="bib75">Zhou et al., 2020</xref>).</p><p>Leveraging our high temporal and spatial resolution, we found that locations showing intensity coding for the Hand stimuli have activity timing that echoes that of pain-related motion cues with very short lags (&lt;80 ms). These optimal lags seem at odds with the much longer response onset latencies reported in the literature (<xref ref-type="bibr" rid="bib7">Bastuji et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Bastuji et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">Chen et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">Cornwell et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Krolak-Salmon et al., 2003</xref>; <xref ref-type="bibr" rid="bib42">Liberati et al., 2020</xref>; <xref ref-type="bibr" rid="bib41">Liberati et al., 2016</xref>), but differ from response onset latencies in two ways. First, our BBP is calculated within time windows of 8× the inverse of the frequency. Hence, for the lowest broadband frequency of 20 Hz, power at time <italic>t</italic> includes signals that occur in a window starting 4 × 1/20 = 200 ms earlier and ending 200 ms later. The peak of BBP would thus still align with the peak of neural activity, but the onset of our BBP estimate may underestimate the onset of neural activity by up to 200 ms. Second, <xref ref-type="fig" rid="fig3">Figure 3i</xref> illustrates that our short lags do not reflect a mysterious lack of delay between the <italic>onset</italic> of motion information and the <italic>onset</italic> of its neural encoding, but rather, the close alignment of their <italic>peaks</italic>. The onset of motion information (~920 ms) actually precedes the peak neural intensity encoding (~1300 ms) by almost 400 ms, in line with typical response latencies. The close alignment of stimulus information and neural encoding peaks rather reflects a property of naturalistic dynamic stimuli in which information typically builds up progressively: in such situations, neural processing, perhaps through predictive coding, appears to overcome significant neural response latencies to synchronize its peak responses to the peak of the stimuli (<xref ref-type="bibr" rid="bib53">Perrett et al., 2009</xref>; <xref ref-type="bibr" rid="bib56">Reddy et al., 2015</xref>). Locations that show intensity coding for the Face appear to have activity echoing the timing of shape information, with lags in the 40–320 ms range. These lags are in a range similar to those found in other studies using facial expressions in the insula (<xref ref-type="bibr" rid="bib13">Chen et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">Cornwell et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Krolak-Salmon et al., 2003</xref>; <xref ref-type="bibr" rid="bib49">Meeren et al., 2013</xref>). Using automated software to detect the level of activation of the facial action units 4 and 7 (i.e., lowering the eyebrows and tightening the eyelids), we find that this action unit information suffices to predict participants’ rating of the stimuli with high accuracy and follows the time course of the neural activity in the Face intensity encoding locations well enough to suggest that it provides traction on the analyses of dynamic pain-related facial expressions. On the other hand, the long neuronal lags we revealed for the facial motion information, with the earliest significant associations occurring in windows centered on 560 ms after the motion information, are unusually long for the start of responses to sensory stimuli in the insula as the onset latency for visual, auditory, tactile, or nociceptive responses is usually well below 560 ms (<xref ref-type="bibr" rid="bib7">Bastuji et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Bastuji et al., 2016</xref>; <xref ref-type="bibr" rid="bib13">Chen et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">Cornwell et al., 2008</xref>; <xref ref-type="bibr" rid="bib36">Krolak-Salmon et al., 2003</xref>; <xref ref-type="bibr" rid="bib42">Liberati et al., 2020</xref>; <xref ref-type="bibr" rid="bib41">Liberati et al., 2016</xref>), although insular activity can persist into such longer intervals (<xref ref-type="bibr" rid="bib49">Meeren et al., 2013</xref>; <xref ref-type="bibr" rid="bib63">Taniguchi et al., 2022</xref>). Together, this suggests that shape information is more likely than motion information to be the primary driver of the intensity coding to our facial stimuli.</p><p>An important consideration is whether preference for Face or Hand stimuli in specific locations could simply originate from some participants finding our facial stimuli more salient, and others the Hand stimuli, particularly given that our patients rated the Hand stimuli with slightly higher pain intensity than our Face stimuli. That we find Face and Hand preference side-by-side in simultaneously recorded locations and neurons in single patients suggests that this cannot suffice to explain our data. This is because if a patient were to find Hand stimuli more salient than Face stimuli, and the insula simply codes saliency, we would expect to find Hand-but-not-Face intensity coding in that patient’s insula, but we would not expect to find side-by-side locations with Hand-but-not-Face and Face-but-not-Hand coding. This also makes it unlikely that broadband activity simply reflects categorization uncertainty (<xref ref-type="bibr" rid="bib24">Grinband et al., 2006</xref>). Indeed, it would be uneconomical for all insular neurons to redundantly encode the same exact signal of salience or categorization uncertainty. Our findings instead suggest that different locations might encode behaviorally relevant (and hence salient) information about the intensity of the pain of others with some degree of specialization for a particular type of information (Hand vs. Face). The insula intensity coding we measure could have a dual function: help perceive the intensity of other people’s emotions and tag intense emotions as salient, thereby reconciling the notion that it contributes to empathy and saliency. One peculiar observation in our data is that BBP for the Hand stimuli did not increase monotonically as a function of reported pain intensity, but in a J shape, with higher power for the lowest than second lowest rating. Some have argued that the insula may be part of an active inference circuitry in the brain that learns to predict emotionally relevant states and stimuli (<xref ref-type="bibr" rid="bib61">Seth and Friston, 2016</xref>). In such a perspective, a J-shaped response curve could reflect a combination of underlying neurons representing the intensity of other people’s emotions (with a monotonic increase in activity) and others representing the prediction error (which for randomly presented intensities would have a U shape centered on the average intensity). Future experiments could contrast responses to a given pain intensity in blocks of high and blocks of low average presented intensity to disentangle the effect of observed and expected intensity on neural responses in the insula and shed further light on this predictive component.</p><p>On the other hand, we also found evidence that some locations and cells represent intensity coding for both the Hand and the Face stimuli. In addition, if we train a PLSR to predict perceived intensity from the activity pattern across all recorded locations, we find that training the decoder on Hand activity pattern and testing it on Face activity patterns (or vice versa) leads to above-chance decoding. This confirms that the insular representation of intensity can support stimulus-independent decoding – despite our PLSR not being biased to focus on signals that do generalize well across stimulus types. This provides an electrophysiological basis for recent fMRI studies that show that stimuli depicting situations in which others’ experience is painful or not can be discriminated using the same pattern across Hand and Face stimuli (<xref ref-type="bibr" rid="bib75">Zhou et al., 2020</xref>).</p><p>In addition to the broadband results we report in detail, we find that theta power increases with perceived intensity. Given a growing animal literature establishing that interareal theta synchronization promotes learning about threats (<xref ref-type="bibr" rid="bib44">Likhtik et al., 2014</xref>; <xref ref-type="bibr" rid="bib43">Likhtik and Gordon, 2014</xref>; <xref ref-type="bibr" rid="bib64">Taub et al., 2018</xref>; <xref ref-type="bibr" rid="bib66">Tovote et al., 2015</xref>), examining the coherence in the theta range across iEEG electrodes in different brain regions during pain observation may in the future shed light on how humans learn about safety through others.</p><p>Spatially, we found that Hand intensity coding was enriched in the anterior dorsal insula, where we also found the largest proportion of locations encoding both Hand and Face intensity. This anterior bias was also observed in our BOLD signal for similar Hand stimuli. A recent meta-analysis identified that the most consistent BOLD activations when observing limbs in painful situations within the insula occur bilaterally around MNI coordinates y = 13 and z = 10 (<xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>), which closely matches where we find the highest density of Hand intensity coding (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). Interestingly, locations with higher Hand intensity coding have increased connectivity at rest with extrainsular regions involved in processing two relevant stimulus dimensions. Connectivity was higher with cerebellar lobules VI, VII, and VIII, and with the inferior frontal gyrus, all of which are recruited by <xref ref-type="bibr" rid="bib1">Abdelgabar et al., 2019</xref>; <xref ref-type="bibr" rid="bib12">Caspers et al., 2010</xref>; <xref ref-type="bibr" rid="bib23">Gazzola and Keysers, 2009</xref> and necessary for (<xref ref-type="bibr" rid="bib1">Abdelgabar et al., 2019</xref>; <xref ref-type="bibr" rid="bib32">Keysers et al., 2018</xref>; <xref ref-type="bibr" rid="bib54">Pobric and Hamilton, 2006</xref>) perceiving the very kinematics of hand actions we find to be good predictors of BBP activity in this study. Connectivity is also higher with the mid- and anterior cingulate cortex, which is associated with pain witnessing in humans (<xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Lamm et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>) and contains neurons with pain intensity coding in rats witnessing the pain of other rats (<xref ref-type="bibr" rid="bib11">Carrillo et al., 2019</xref>).</p><p>With respect to Faces, somewhat surprisingly, we did not find a clear spatial clustering of intensity coding in our electrophysiological data. Overall, our ability to decode perceived intensity from our Face stimuli was also lower than that from the Hand stimuli. In that context, it is important to reflect on the fact that, despite our efforts to match the perceived intensity based on previous data (<xref ref-type="bibr" rid="bib22">Gallo et al., 2018</xref>), patients (and to a lesser extent an age- and gender-matched control group) perceived the Hand stimuli as more intense than the Face stimuli. Given that responses were strongest for the highest rating, and that this rating was given more rarely for Faces than Hands, this difference could have contributed to making our Face results less consistent. At the same time, the variance in rating, a critical factor for determining the efficiency with which a regression can detect the presence of a rating–BBP relationship, did not differ across Hand and Face. Together, this difference in perceived intensity cautions us against overinterpreting the lack of detectability of a topographic organization of responses to Faces. Indeed, in our BOLD data, where decoding performance was similar for Hand and Face stimuli, Face intensity coding also had a clear spatial organization, being stronger more anteriorly, and meta-analyses show the left anterior insula to be reliably recruited by the observation of painful facial expressions (<xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>). However, that we found fewer locations and less reliable spatial organization for Face than Hand intensity coding dovetails with recent meta-analyses of the fMRI literature showing that the insula is more reliably recruited by the sight of limbs than by painful facial expressions (<xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>). Indeed, that we find a macroscopic organization of intensity coding for the Hand, but not the Face, is echoed at the mesoscale: microwires with cells with Hand intensity coding also tend to show Hand intensity coding in the BBP signal that is thought to pool the spiking of many neighboring neurons, but the same is not true for the Face. In terms of lateralization, we find that our data is more likely if one assumes that both hemispheres have similar intensity coding than if one hemisphere were dominant. This echoes the fact that during noxious stimulation of the right hand both insulae show significant iEEG responses (although slightly stronger in the left insula; <xref ref-type="bibr" rid="bib42">Liberati et al., 2020</xref>), and that fMRI fails to find robust lateralization of responses to empathy for pain (<xref ref-type="bibr" rid="bib28">Jauniaux et al., 2019</xref>; <xref ref-type="bibr" rid="bib65">Timmers et al., 2018</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>iEEG experiment</title><sec id="s4-1-1"><title>Participants</title><sec id="s4-1-1-1"><title>Patients</title><p>Depth electrode recordings were collected from nine epileptic volunteers admitted at the Amsterdam UMC to localize seizure origin. Patients received initial study information from the neurosurgeon and provided informed consent to the experimenter before the surgery occurred. Our single-session experiment started on average 4 days after surgery (SD = 1.89 days). Preliminary analyses indicated that the pain rating performance of two patients (Xs in <xref ref-type="fig" rid="fig1">Figure 1e</xref>) for Face videos was significantly poorer compared to an age- and gender-matched healthy control group. Hence, these two patients were excluded from all analyses, which yielded a final sample of seven patients (four females, 34.3 years ± 9 SD, <xref ref-type="table" rid="table4">Table 4</xref>). The study was approved by the medical ethical committee of the Vrije University Medical Center (protocol 2016/037), and each patient signed a written informed consent according to the Declaration of Helsinki.</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Participants’ demographics and epileptic status.</title><p>Our seven patients were matched in age and gender to the online control group from which we obtained normative movie ratings. The last column indicates the postoperative status of our patients. Three patients had other brain regions than insula surgically removed, and afterward had no more attacks (marked with 1), suggesting that the foci were clearly outside the insula. One patient had a region other than the insula surgically removed because the monitoring had suggested that the foci was outside of the insula; however, the patient continued to have post-surgical attacks (marked with 2). For three patients, no surgery was performed because there was no clear link between electrode locations and epileptic attacks (marked with 3).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle">Group</th><th align="center" valign="middle">Sample size (n)</th><th align="center" valign="middle">Age (mean ± SD years)</th><th align="center" valign="middle">Age-matched</th><th align="center" valign="middle">Gender (M/F)</th><th align="center" valign="middle">Gender-matched</th><th align="center" valign="middle">Epileptic location score</th></tr></thead><tbody><tr><td align="center" valign="middle">Patient</td><td align="center" valign="middle">7</td><td align="center" valign="middle">34.3 ± 9</td><td align="center" valign="middle" rowspan="2">Mann–Whitney <italic>U</italic>-test, p=0.7, BF<sub>01</sub> = 3.6</td><td align="center" valign="middle">3/4</td><td align="center" valign="middle" rowspan="2">Multinomial test, p=0.7, BF<sub>01</sub> = 7 .3</td><td align="center" valign="middle">A = 1, B = 1, C = 3, D = 3, E = 1, F = 3, G = 2</td></tr><tr><td align="center" valign="middle">Control</td><td align="center" valign="middle">93</td><td align="center" valign="middle">33.7 ± 9</td><td align="center" valign="middle">38/55</td><td align="center" valign="middle">N/A</td></tr></tbody></table></table-wrap><p>Clinical investigation revealed that for all our patients the epileptic incidents did not appear to originate around the electrode contacts in the insula that we analyzed here. In addition, for four of them, recordings pointed to origins of the epilepsy to be clearly outside the insula, leading to the surgical removal of extrainsular regions (<xref ref-type="table" rid="table4">Table 4</xref>). Finally, for the remaining three, no clear origin for the epilepsy could be localized, but there was no indication that the insula was involved in the initiation of the attacks.</p></sec><sec id="s4-1-1-2"><title>Control participants in the online video rating task</title><p>To assess whether the behavior of the patients was representative of the general population, we compared patients’ ratings with those of 93 volunteers (54 females, 32.7 years ± 9 SD), who took part in an online version of the video pain rating task. The matching with the seven patients was done by only including age- and gender-matched Dutch participants, and was successful (<xref ref-type="table" rid="table4">Table 4</xref>). The study was approved by the local ethical committee of the University of Amsterdam (2021-EXT-13608), and each participant signed an online informed consent form to participate in the study.</p></sec><sec id="s4-1-1-3"><title>Control participants in the online frame rating task</title><p>To determine whether participants could use shape information available in single frames to determine pain intensity in Hand and/or Face stimuli, 40 volunteers (23 females, 33.7 years ± 9 SD) from the same group who also performed the online video pain rating task participated in the online frame rating task, so they were already familiar with the videos and had a better understanding of where the single frames came from. This also allowed us to directly compare how they rate single frames with how they rated the movies from which the frames were taken. They were selected to approximate the age and gender distribution of the patient group.</p></sec></sec></sec><sec id="s4-2"><title>Stimuli and procedure</title><sec id="s4-2-1"><title>Video rating task</title><p>The 2 s videos were generated as in <xref ref-type="bibr" rid="bib22">Gallo et al., 2018</xref> and showed a Caucasian female receiving either electrical shocks to the hand (reaction conveyed by the facial expression only; Face condition) or a slap with a belt to the hand (reaction conveyed by the hand only; Hand condition). Hence, the location of the noxious stimulation was maintained across conditions (dorsum of the left hand), but the cues through which participants could deduce the painfulness differed. All videos started with 1 s of baseline: neutral facial expression for Face and static hand for Hand stimuli. The reactions of the actor were genuine, but enhanced: truly noxious stimuli were applied during recording, but the actor was encouraged to enhance her expressivity and not to suppress her reactions. This instruction was given in order to compensate for the fact that the intensity of the shock delivered had to be in balance with the fact that many videos had to be recorded. A mild pain was therefore used, in agreement with the actress, and enhancement was necessary to fully convey expressions of stronger pain. Movies were cut, so that evidence of pain started at 1 s (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Before the experiment, participants were instructed to rate pain intensity (‘How much pain do you think the person felt?’) on a scale from 0 (no pain at all) to 10 (the worst imaginable pain). To reassure patients that no real harm was inflicted to the actor in the movie, they were informed that during video recording stimulations in the 9–10 range were never used. Participants had to rate pain intensity after each video at their own pace, using four keyboard keys (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Only the relevant keys were presented on the screen, intensities were not indicated. Patients watched each of the 60 videos (30 Hand, 30 Face) twice in fully randomized fashion with a random interval of 1.5 s ± 0.5. The videos were matched in terms of intensity and standard deviation based on a validation in <xref ref-type="bibr" rid="bib22">Gallo et al., 2018</xref>.</p></sec><sec id="s4-2-2"><title>Online video rating task</title><p>The stimuli and the task were the same as in the electrophysiology experiment, except each video was presented only once. Prolific Academic (<ext-link ext-link-type="uri" xlink:href="https://www.prolific.co/">https://www.prolific.co/</ext-link>) was used to recruit participants, and the experiment was implemented on Gorilla (<xref ref-type="bibr" rid="bib4">Anwyl-Irvine et al., 2020</xref>; <ext-link ext-link-type="uri" xlink:href="https://gorilla.sc/">https://gorilla.sc/</ext-link>).</p></sec><sec id="s4-2-3"><title>Online frame rating task</title><p>The task was similar to the pain rating experiment, except still frames instead of the full videos were presented for 2 s. For faces, frames at the 1.8 s of the Face videos were used (except for one video where the eyes were closed at 1.8 s, so the frame was taken at 1.68 s). This timepoint was selected because facial expressions were most pronounced toward the end of the movies, and more formal analyses confirmed that this corresponds to a time where shape information plateaued (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). To use a comparable stimulus set for Hands, which portrayed maximal configuration information, we selected from each Hand video separately, the frame at which the hand was maximally depressed by the force of the belt slap (timepoint mean ± SD = 1.001 ± 0.013 s).</p></sec></sec><sec id="s4-3"><title>Data acquisition</title><p>Patients were implanted with Behnke–Fried depth electrodes (Ad-Tech Medical Instrument Corporation; <xref ref-type="bibr" rid="bib21">Fried et al., 1999</xref>) targeted at the right or left, anterior or posterior insula. Electrodes were inserted via a guide tube under the guidance of an online stereotactic positioning system. They consisted of a silastic hollow tube with 9–12 platinum outer macrocontacts, 1.28 mm in diameter, 1.57 mm in length with the first two macrocontacts spaced 3 mm from each other and the rest spaced 5 mm from each other. This hollow tube had nine platinum microwires (eight recording and one reference contact) running through it, each 38 micron in diameter, protruding as a ‘pigtail’ formation out of the tip of the electrode. Macrocontact recordings were amplified using unity gain, DC amplifiers (Braintronics BrainBox 1166 system), low-pass filtered at 1500 Hz (–3 dB point, –12 db/octave), and sampled at 32,768 Hz. The digital signal was decimated to a final sample rate of 512 Hz or 1024 Hz and was pre-filtered with a three-section FIR equiripple filter (0.01 dB passband ripple) with the passband set to 1/3 of the sample frequency and the stopband set to 1/2 of the sample frequency. Signals from the microcontacts were amplified with respect to a skull-screw ground using a unity gain HS-9 head-stage amplifier (NeuraLynx). The signal was high-pass filtered at 1 Hz and low-pass filtered at 5 kHz and had a sampling rate of 32 kHz. There were a total of 85 macroelectrodes and 32 microwires across all patients in the insula that we recorded from.</p></sec><sec id="s4-4"><title>Electrode localization</title><p>For each patient, the T1 structural MR image taken before the electrode implantation surgery and the CT scan taken after the electrode placement were co-registered (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). Using SPM12 (<ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk">https://www.fil.ion.ucl.ac.uk</ext-link>), the T1 image was segmented to determine the normalization parameters, and MR and CT images were then normalized to the MNI space using these parameters. CT scan and gray matter were overlaid with insula probability maps (<xref ref-type="bibr" rid="bib20">Faillenot et al., 2017</xref>), and macrocontacts within the boundaries of the insula map were detected based on detailed visual examination using MRIcron (<ext-link ext-link-type="uri" xlink:href="https://www.nitrc.org/projects/mricron">https://www.nitrc.org/projects/mricron</ext-link>). Not the individual subdivision maps, but the combination of all the subdivision maps as one general insula map was used for localization because the coverage of different subdivisions was highly uneven across patients. Since macrocontact recordings were analyzed in a bipolar layout, the coordinates of each bipolar recording were estimated as the midpoint of its macrocontacts (see <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref> for MNI coordinates).</p></sec><sec id="s4-5"><title>Data analysis</title><sec id="s4-5-1"><title>General statistical approach</title><p>Much of the analyses in this article assess intensity coding, which examines the relationship between brain activity (measured based on LFP, spiking, or BOLD activity) and rating. Because the rating of pain intensity was along discrete categories (1–2, 3–4, 5–6, 7–8), which might be linear but is certainly ordinal, we tend to use association measures that are appropriate for ordinal scales when we relate brain activity to the rating of a single participant. That includes Spearman’s <italic>r</italic> in most of our MATLAB codes, when analyses need to be repeated for every electrode because it is the most widely used rank-order correlation metric. We use Kendall’s tau when using Bayesian analyses implemented in JASP because these analyses are not yet available for Spearman’s <italic>r</italic>. When examining the association between variables that are more continuous and normally distributed, we use Pearson’s <italic>r</italic>.</p><p>When using <italic>t</italic>-tests, we examined normality using the Shapiro–Wilk test. If normality is preserved, we report <italic>t-</italic>tests and <italic>t</italic>-values; if not, we use Wilcoxon signed-rank or Mann–Whitney <italic>U</italic>-tests, as indicated by <italic>W</italic> or <italic>U</italic> values, respectively. When possible, or when evidence of absence is important for the interpretation of the data, we supplement the frequentist p-values with Bayesian statistics calculated using JASP (<ext-link ext-link-type="uri" xlink:href="https://jasp-stats.org">https://jasp-stats.org</ext-link>). We use the abbreviation p<sub>1</sub> to represent one-tailed p-values and p<sub>2</sub> to represent two-tailed p-values. BF<sub>10</sub> and BF<sub>01</sub> represent relative evidence in the form of the Bayes factor for H<sub>1</sub> and H<sub>0</sub>, respectively, when two-tailed hypotheses are used. When we look for intensity coding, we focus here on positive intensity coding, and thus use directed hypotheses, marked with p<sub>1</sub> or BF<sub>+0</sub> or BF<sub>0+</sub>, with the + indicating a directed H<sub>1</sub>, using conventions as in <xref ref-type="bibr" rid="bib33">Keysers et al., 2020</xref>. It should be noted that the use of one-tailed statistics, which is sometimes criticized when exclusively using frequentist statistics, has important advantages when combining the frequentist with a Bayesian framework, in that it increases the sensitivity for falsifying the alternative hypothesis in a Bayesian framework. When multiple tests were performed across a high number (&gt;1500) of adjacent frequency–time intersections or timepoints separately, we used cluster-based corrections that reveal large spectral and/or temporal windows of significance because the main focus of these analyses was to discover these critical windows, not the precise time- or frequency points. These cluster-based corrections are explained in detail in the section <italic>‘</italic>Intensity coding in LFPs.’ On the other hand, when multiple tests were performed across a low number (&lt;30) of adjacent timepoints, we used false discovery rate (FDR) corrections since these analyses aimed at finding the significance of precise timepoints, not that of wide temporal windows. When testing multiple neurons or multiple bipolar recordings, we do not correct for multiple comparisons when attributing a property to a location as this would result in changing the property of a location based on how many locations have been tested. Instead, we then examine whether the number of electrodes with a certain property exceeds the number expected by chance using binomial distributions. When performing Bayesian ANOVAs, we report BF<sub>incl</sub>, which is the likelihood of models including a particular factor (or interaction of factors) divided by the likelihood of models excluding that particular factor (or interaction), as recommended by Rouder and coworkers and implemented in JASP (<xref ref-type="bibr" rid="bib60">Rouder et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Rouder et al., 2016</xref>; <xref ref-type="bibr" rid="bib58">Rouder et al., 2012</xref>). When performing Bayesian <italic>t</italic>-tests in JASP, we use the default priors and methods proposed by <xref ref-type="bibr" rid="bib57">Rouder et al., 2009</xref>. For nonparametric tests in JASP, we used the method described in <xref ref-type="bibr" rid="bib69">van Doorn et al., 2020</xref>.</p></sec><sec id="s4-5-2"><title>Behavioral analyses</title><p>To explore whether patients were impaired in their ability to perform the task, our rationale was to consider the average rating of all control participants as the normative rating. We then compared the vector of 30 ratings (one per movie for 30 movies) of each member of the control group against the average of the other members of the control group to define a distribution of how far from the normative rating healthy volunteers tend to fall. For the patients, we compared their ratings against the average rating of the control group, and compared how similar patient ratings were to the normative average against the distribution of how similar left-out control participants are to the normative average. We calculated three metrics of similarity: the Spearman’s rank-order correlation, the slope, and the intercept of a simple linear regressions between the ratings of each of the patients and the average rating of all control samples.</p></sec><sec id="s4-5-3"><title>Preprocessing of LFPs</title><p>To reduce artifacts and extract local signals, iEEG macrocontact recordings were digitally re-referenced in a bipolar layout (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). This generated 85 bipolar recordings from 102 contacts in the insula, with patients having between 5 and 19 bipolar channels (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, <xref ref-type="supplementary-material" rid="fig1sdata1">Figure 1—source data 1</xref>). Re-referencing attenuated 50 Hz noise sufficiently to omit digital filters that distort data. Continuous recordings were separated into trials of 4 s: 1 s premovie baseline, 2 s video, and 1 s postmovie. Trials were visually checked for ground failure and amplitude saturation (none was detected), downsampled to 400 Hz, and detrended.</p></sec><sec id="s4-5-4"><title>Time–frequency decomposition of LFPs</title><p>A sliding window Hanning taper-based approach was used for each trial with the following parameters: frequencies from 1 to 200 Hz in steps of 1 Hz; timepoints from –1 s (relative to movie onset) to 3 s in steps of 0.0025 s; and for each frequency, a single-sliding Hanning taper window with the duration of eight cycles (maximum = 1 s; minimum = 0.1 s). Trials were expressed as % power change relative to baseline (–1 s to 0 s) separately for each frequency: y(t) = ((P(t) – P<sub>0</sub>)/P<sub>0</sub>), with P<sub>0</sub> = average of baseline. Points with y(t) ± 10 standard deviations from the mean of the other trials were excluded to not reject entire trials, but only outlier time–frequency points in some trials (rejections were rare, mean rejected time–frequency points = 0.0032% ± 0.0035 SD).</p></sec><sec id="s4-5-5"><title>Intensity coding in LFPs</title><p>In the LFP signal, we consider that a bipolar channel shows intensity coding if its trial-by-trial power variations correlate positively with the variation in the pain intensity reported by the patient. We always coded the 1–2, 3–4, 5–6, and 7–8 rating options as 1, 2, 3, and 4. For each bipolar recording, we then calculated the Spearman’s rank correlations (due to the ordinal nature of intensity ratings) between the patient’s behavioral intensity ratings and the neural activity power estimate over all trials. In time–frequency-resolved analyses, these correlation analyses were conducted separately using the power estimates at each time–frequency intersection separately. In frequency band analyses, the correlation was calculated using the average of the power estimates within a specific frequency band. For both analysis types, a one-sample <italic>t</italic>-test was used to test whether the average correlation over the 85 bipolar recordings were greater than 0. Correlations were not Fisher <italic>r</italic>-&gt;<italic>z</italic> transformed because <italic>r</italic> and <italic>z</italic> values remain virtually identical for –0.5 &lt; <italic>r</italic> &lt; 0.5, which is the range in which the correlations we examined remain. These time–frequency-resolved analyses were conducted separately for each of a large number of time–frequency intersections. Since we were interested in finding relatively large time–frequency windows of significance, these multiple tests were corrected using a modified version of the nonparametric cluster-based correction method described by <xref ref-type="bibr" rid="bib46">Maris and Oostenveld, 2007</xref>. Specifically, we used a circular shift procedure that consisted of 1000 iterations to generate a null distribution. In each iteration, the time–frequency profile of the correlation coefficients for each contact was randomly shifted in the time domain. Then, all such time-shifted profiles were entered into an analysis, which, as described above, tested the significance of the correlation coefficients at each time–frequency intersection via a separate one-sample <italic>t</italic>-test against 0. Finally, the sum of the largest significant positive and negative clusters was calculated separately. At the end of the 1000 iterations, two separate null distributions were generated, one for positive and one for negative clusters, which showed the maximum sum of the significant clusters expected by chance. For statistical inference, the probabilities of the cluster sums observed in our data were calculated under the corresponding null distributions. The multiple tests in the time-resolved frequency band analyses were corrected based on exactly the same circular-shift and nonparametric cluster-correction method.</p><p>We performed a similar analysis to identify time–frequency bands with significant intensity coding when separating the Hand and Face trials. Note that including half the number of trials makes this analysis less powerful than the Hand and Face combined analysis, which is why we used the broadband frequency band (20–190 Hz) resulting from the combined analysis. To directly compare the time–frequency profiles of intensity coding for Hand vs. Face trials, we performed a similar analysis for cluster correction, except that for each time–frequency point separately, the Hand and Face correlation coefficient distributions across the 85 electrodes were directly compared with a paired-samples <italic>t</italic>-test, and, instead of the circular shift randomization procedure, trials were randomly assigned as Hand and Face trials at each step of the 1000 iterations for generating the null distributions.</p></sec><sec id="s4-5-6"><title>Resampling LFPs from the entire brain</title><p>To test whether the BBP–rating association observed in the insular electrodes was enriched compared to what could have been observed in any 85 bipolar recordings anywhere in the brain, we made use of not just the insular but all the intracranial macroelectrodes that were implanted in the same patients (see <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplements 2</xref> and <xref ref-type="fig" rid="fig2s3">3</xref> for anatomical locations of all macrocontacts). The recordings from these electrodes were preprocessed exactly as described for the insular electrodes. The seven patients included in these analyses had between 91 and 149 (mean ± SD = 114 ± 20) bipolar recordings distributed throughout the two hemispheres and various regions of the four brain lobes. The BBP–rating Spearman’s correlation coefficients of each of these electrodes were entered into a resampling method, in which for each of the 100,000 iterations, from each patient, a random subset of these correlation coefficients were selected. The number that was selected for each patient was determined by the number of insular electrodes that patient had; that is, since patient A had five insular electrodes in the main analyses, five random electrodes were selected from the entire brain in these analyses. This was done to ensure that possible patient-specific biases in the analysis of insular electrodes were maintained in these analyses. This way, in each iteration, a total of 85 electrodes were selected randomly from the entire brain and tested with a one-sample <italic>t</italic>-test against 0. The resulting 100,000 <italic>t</italic>-values from all the iterations were used as the null distribution to test whether the <italic>t</italic>-value observed in the insula was greater than what would be expected if we were not focusing on the insula and were randomly sampling from the entire brain. It is important to note that while the anatomical location of electrodes in and close to the insula was carefully determined, this manual procedure was not performed for electrodes clearly outside the insula, making it possible that some of these extrainsular electrodes included in this resampling were located in the white matter or cerebrospinal fluid, and this analysis should thus be considered with a grain of salt.</p></sec><sec id="s4-5-7"><title>Extracting shape and motion information from videos</title><p>A recent systematic review has revealed that facial expressions of pain are most consistently characterized by lowering of the brow and tightening of the eyelid (<xref ref-type="bibr" rid="bib38">Kunz et al., 2019</xref>), corresponding to facial AUs 4 and 7 (<xref ref-type="bibr" rid="bib19">Ekman and Friesen, 1978</xref>; inlet in <xref ref-type="fig" rid="fig3">Figure 3a</xref>). More specifically, research has evidenced that people fall into four clusters that differ in how they express pain (<xref ref-type="bibr" rid="bib37">Kunz and Lautenbacher, 2014</xref>), and our protagonist fell within cluster IV, who express pain by furrowing brows and tightening eyes, but not opening the mouth or wrinkling the nose. Accordingly, we quantify the painfulness expressed in the shape of our protagonist’s face based on facial AUs 4 and 7. To get a replicable and objective measurement of these AU, we used the FaceReader software (Noldus, the Netherlands), which uses a deep convolutional neural net to automatically extract the level of activation of the classic facial action units (<xref ref-type="bibr" rid="bib19">Ekman and Friesen, 1978</xref>). FaceReader reliably obtained estimates for the facial AUs 4 and 7 from all but three frames from our 30 movies, and we thus quantified the pain-related shape information contained in each frame of our movies as the average of AUs 4 and 7. When applied to the frames used in our psychophysical experiment mentioned above, the average activation of AUs 4 and 7 correlated at <italic>r</italic><sub>p</sub> = 0.95 with the average rating from human observers of the same static images, validating the utility of this automated signal. Unfortunately, we found no software that could estimate muscular contraction from the hand in a similar way, and we thus did not see an obvious way to extract shape information from the Hand stimuli. Given that participants are also very poor in their ability to rate painfulness from static frames of the hand configuration in our stimuli, as shown by our psychophysics, we felt that not quantifying shape information for the Hand stimuli was acceptable.</p><p>To quantify motion over time for each video, we use motion energy, an established and objective way to extract dynamics from any movie, using the average of the Euclidean distances between the RGB vectors of the corresponding pixels across every two consecutive frames.</p></sec><sec id="s4-5-8"><title>PLSR decoding of intensity coding from shape and motion information</title><p>To identify when motion or shape information may contribute to predicting the overall intensity rating R of the movie i, we used PLSR analyses using the ‘plsregress’ function in MATLAB, with a single component. For the Hand, where no shape information was available, the predictor for each movie i was the motion M at frame t, and the plsregress thus identified the weights (B), such that R(i) = M(i,t)B(t) + B<sub>0</sub>(i). For the Face, where both motion and shape information S was available, as the average of AUs 4 and 7 in each frame, we concatenated M(i,t) and S(i,t) into a single predictor X to identify weights such that R(i) = XB + B<sub>0</sub>(i). We used PLSR here in particular because both M and S have high temporal autocorrelations and are mutually correlated, and PLSR is well suited for such cases.</p><p>Second, we can use the PLSR method to see how accurately the motion and/or shape profile across the entire movie can be used to predict the rating of the patients using a cross-validation. The predictive accuracy for both the motion and shape time course was calculated in 1000 iterations. In each iteration, the videos were randomly divided into three equal-sized samples. For each of these three samples separately, the remaining two samples were used to calculate PLSR beta coefficients, which were then used to predict the ratings of our patients. The Pearson’s correlation coefficient between the actual ratings and the predicted ratings was taken as measures of predictive accuracy and averaged across all iterations. A similar procedure was also applied to calculate the null distribution of such correlation coefficients, in which the 1000-iteration step described above was repeated for 10,000 times, each time with a different randomly shuffled version of the observed ratings. The probability of the observed decoding accuracies was then estimated by ranking the accuracy based on the actual ratings within the distribution of shuffled ratings. <xref ref-type="fig" rid="fig3">Figure 3d–f</xref> shows that motion and shape information each allows one to predict movie ratings with high accuracy.</p></sec><sec id="s4-5-9"><title>Probability of Face-but-not-Hand, Hand-but-not-Face, and dual-intensity coding LFPs</title><p>Correlations between BBP and rating were thresholded as significant or as providing evidence of absence as follows (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). At n = 60 trials, values above <italic>r</italic> = 0.214 show a significant positive association (p<sub>1</sub>&lt;0.05). Values below <italic>r</italic> = 0.085 provide evidence for the absence of a positive association (BF<sub>+0</sub> &lt; 1/3). Intermediate values are inconclusive (<xref ref-type="bibr" rid="bib33">Keysers et al., 2020</xref>). Both the frequentist and Bayesian criteria we use here are subject to type I/II errors, and we thus asked whether the number of bipolar recordings we find in these quadrants is above what we would expect by the probability of these errors. For the frequentist criterion, p<sub>1</sub>&lt;0.05, we expect 5% of locations to be classified as showing significant intensity coding even if H<sub>0</sub> was true (i.e., despite no real intensity coding). With regard to the dual-coding quadrant that we are interested in, two types of errors could be made. The most likely misclassification is for a location showing one intensity coding to be mistakenly classified as having dual intensity coding. To test whether we have above-chance numbers of dual-coding locations, we thus take all the locations with Hand intensity coding (21/85), and ask among those whether finding 5 also showing Face intensity coding is more than what we expect using a binomial (n = 21, k<sub>success</sub> = 5, α = 0.05) and the results showed clear evidence that there are more locations also representing the Face among the Hand locations (p<sub>1</sub>=0.003, BF<sub>+0</sub> = 17.09). The same could be done by looking whether 5 Hand intensity coding is overrepresented among 15 Face intensity coding locations (p<sub>1</sub>=0.0006, BF<sub>+0</sub> = 117). A less likely misclassification is for a location that shows neither intensity coding to be classified as having both (α = 0.05<sup>2</sup>). Making five such misclassifications among 85 recordings is also highly unlikely (p<sub>1</sub>=3 × 10<sup>–6</sup>, BF<sub>+0</sub> = 4446). For the Bayesian criterion, BF<sub>+0</sub> &lt; 1/3 this calculation is more difficult to perform because Bayesian criteria are not defined directly based on a false-positive rate. However, <xref ref-type="bibr" rid="bib29">Jeffreys, 1939</xref> chose the bound of BF &lt; 1/3 as evidence of absence or presence precisely because it roughly corresponds to a p=0.05 with a standard prior on the effect sizes in H<sub>1</sub>. We can thus, as a reasonable approximation, assume that if H<sub>1</sub> is actually true, and a location thus shows significant positive intensity coding, only 5% would be falsely classified as showing evidence against H<sub>1</sub>. With that approximation, among the 21 Hand intensity coding locations, it is highly unlikely to encounter 10/21 showing evidence that they do not encode the Face if in reality they did: (binomial with n = 21, k = 10, α = 0.05, p<sub>1</sub>=2 × 10<sup>–8</sup>, BF<sub>+0</sub> = 2 × 10<sup>6</sup>). Even if the false rejection rate were much higher (e.g., α = 0.25), 10/21 remain unlikely (binomial p<sub>1</sub>=0.025, BF<sub>+0</sub> = 4.2). Similarly, among the 15 locations with significant Face intensity coding, finding 6 with evidence for not encoding the Hand is again unlikely (binomial n = 15, k = 6, α = 0.05, p<sub>1</sub>=5 × 10<sup>–5</sup>, BF<sub>+0</sub> = 1334). We can thus conclude that preference is over-represented in the insula compared to what we would expect if all neurons showing a preference for one stimulus type would also show coding for the other.</p><p>The same analysis was applied to an exemplar participant (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Using the same logic in that patient, we find that the number of Hand-but-not-Face coding locations (p<sub>1</sub>=2 × 10<sup>–4</sup>, BF<sub>+0</sub> = 701) and the number of Face-but-not-Hand coding locations (p<sub>1</sub>=0.007, BF<sub>+0</sub> = 37) are surprising, but the number of dual-coding locations (1/15) is not surprising among the three Face (p<sub>1</sub>=0.143, BF<sub>+0</sub> = 1.9) or seven Hand (p<sub>1</sub>=0.3, BF<sub>+0</sub> = 0.48) coding locations.</p></sec><sec id="s4-5-10"><title>PLSR decoding of intensity from the LFP insula activity pattern</title><p>To explore how well the pattern of activity across all 85 bipolar recordings reflects the perceived intensity reported by our patients, we applied a PLSR regression approach similar to that used to infer how well shape or motion predicts ratings, except that instead of using motion over 50 frames, we used BBP over 85 electrodes. Specifically, BBP across the 85 sites, averaged over the early period for Hand videos and in the late period for Face videos, were separately used as predictors in two separate PLSR analyses predicting the participants’ average pain ratings. The decoding accuracies were each calculated in 1000 iterations. In each iteration, the videos were randomly divided into three equal-sized samples. For each one of these three samples, the remaining two samples were used as a training set to calculate PLSR beta coefficients, which were then used to predict the ratings in the remaining test sample. The Pearson’s correlation coefficient between the predicted ratings and the actual ratings of the patients was then taken as a measure of decoding accuracy and averaged across all iterations. We used Pearson here because the data was normally distributed, and we compared two ratings. A similar procedure was also applied to calculate the null distribution of such correlation coefficients, in which the 1000-iteration step described above was repeated for 10,000 times, each time with a different randomly shuffled version of the original ratings. The probability of the observed decoding accuracies was estimated under the corresponding null distributions as the rank of the actual average accuracy against the shuffled accuracies. We first performed this analysis within each stimulus type; that is, we trained and tested on Hand stimuli or we trained and tested on Face stimuli. Then, to explore whether the pattern of activity could generalize across stimulus type, we also performed cross-decoding analyses where we trained on one stimulus type (e.g., we determined the PLSR weights using ⅔ of Hand stimuli) and then tested them on the other (e.g., predicted 1/3 of the Face stimuli). We first performed this analysis using a single PLSR component and found a trend (Hand: <italic>r</italic><sub>P(8)</sub> = 0.281, p<sub>1</sub>=0.093; Face: <italic>r</italic><sub>P(8)</sub> = 0.3, p<sub>1</sub>=0.071). Using two components in the PLSR analyses improved results, which now became significant for the Hand (<italic>r</italic><sub>P(8)</sub> = 0.575, p<sub>1</sub>=9 × 10<sup>–4</sup>) and near significant for the Face (<italic>r</italic><sub>P(8)</sub> = 0.331, p<sub>1</sub>=0.058). Increasing to three or four components did not further improve this level of decoding. We thus report the results using two components (<xref ref-type="fig" rid="fig4">Figure 4e</xref>) and used two components also for the cross-stimulus decoding, which turned out significant in both directions.</p></sec><sec id="s4-5-11"><title>Resting state connectivity analysis</title><p>To interrogate what connectivity profile is characteristic for electrode pairs with high-intensity coding, we used Neurosynth (<xref ref-type="bibr" rid="bib72">Yarkoni et al., 2011</xref>) to extract a whole-brain resting state connectivity map for the MNI location of each of the 85 contact pairs in the insula (<xref ref-type="supplementary-material" rid="fig5sdata1">Figure 5—source data 1</xref>). Using SPM12 (<ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/spm12/">https://www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link>), we performed a regression analysis (general linear model) that included the 85 voxel-wise resting state connectivity maps and two predictors: the correlation between power and rating for the Hand in the early window, and for the Face in the late window. Results were thresholded at p&lt;0.001, corrected for multiple comparisons using family-wise error correction at the cluster level. Results were then illustrated on an inflated cortical template provided in SPM12, and significant voxels were attributed to specific brain regions using the <ext-link ext-link-type="uri" xlink:href="https://www.fz-juelich.de/inm/inm-7/EN/Resources/_doc/SPM%20Anatomy%20Toolbox_node.html">Anatomy toolbox 3.0</ext-link>.</p></sec><sec id="s4-5-12"><title>Spike sorting and selection of responsive single units</title><p>Three patients had microwires (Behnke–Fried electrodes, Ad-Tech Medical; <xref ref-type="bibr" rid="bib21">Fried et al., 1999</xref>) in the insula protruding from the electrode tip (plusses in <xref ref-type="fig" rid="fig1">Figure 1c</xref>). Spikes were detected and sorted using Wave_Clus2 (<xref ref-type="bibr" rid="bib55">Quiroga et al., 2004</xref>). In short, raw data was filtered between 300 and 3000 Hz. As per default settings, spike waveforms were extracted from 0.625 ms before to 1.375 ms after the signal exceeded a 5*noise threshold, where noise was the unbiased estimate of the median absolute deviation. Wave_Clus2 sorted and clustered the waveforms automatically and were manually checked by author RB. Clusters were excluded in which &gt;2% of spikes were observed with an interspike interval &lt; 2 ms or with firing rate &lt; 1 Hz. To identify cells that responded to our stimuli, we used a Wilcoxon signed-rank test comparing spike counts during baseline (–1 s to 0 s) against that during the pain period (1–2 s) for Hand and Face trials together. Only cells that showed a response to the stimuli (p<sub>1</sub>&lt;0.05), irrespective of pain intensity, were considered for further analysis.</p><p>Similar to LFP analyses, a cell was said to show intensity coding if spike counts rank correlated positively with reported intensity. Because JASP includes Bayesian statistics using Kendall’s tau but not Spearman’s <italic>r</italic>, we used the former to quantify evidence for or against intensity coding.</p></sec><sec id="s4-5-13"><title>Broadband power analysis in microelectrodes</title><p>To explore whether intensity coding in cells and the BBP (20–190 Hz; <xref ref-type="fig" rid="fig2">Figure 2a</xref>) from the same microwire were related, for the 10 microwires that yielded responsive neurons (whether these neurons showed intensity coding or not) we quantified the association between BBP averaged over the pain period (1–2 s) and intensity ratings (1–2, 3–4, 5–6, 7–8) using rank correlation coefficients separately for Face and Hand videos (again using Kendall’s tau to provide BF<sub>+0</sub> estimates). All eight microwires protruding from the same electrode were first re-referenced to the microwire with the least spiking and lowest artifacts, yielding seven microwire recordings for each of the four electrode tips with wires in the insula. Data were filtered to remove 50 Hz noise and harmonics at 100 and 150 Hz. Subsequently, they were separated into trials of 4 s (–1 s to 3 s relative to video onset), downsampled to 400 Hz, and visually checked for artifacts. The time–frequency decomposition of power followed the same procedure as for the macrocontact recordings. Finally, intensity coding at the level of spikes (i.e., <italic>r<sub>K</sub></italic>(spikes,rating)) and BBP (<italic>r<sub>K</sub></italic>(BBP,rating)) from the same wire was compared using a Kendall’s tau coefficient.</p></sec></sec><sec id="s4-6"><title>fMRI experiment</title><sec id="s4-6-1"><title>Participants</title><p>Twenty-five healthy volunteers participated in the study. The full dataset of two participants was excluded from the analyses because head motions were above 3 mm. Analyses were performed on the remaining 23 participants (13 females; mean age = 28.76 years old ± 6.16 SD). The study was approved by the local ethics committee of the University of Amsterdam (project number: 2017-EXT-8542).</p></sec><sec id="s4-6-2"><title>Stimuli and procedure</title><p>The video pain rating task was performed as described in the section <italic>‘</italic>Video rating task,’ but with the following differences. Each trial started with a gray fixation cross lasting 7–10 s, followed by a red fixation cross for 1 s, followed by the 2 s video, followed by a red fixation cross lasting 2–8 s, followed by the rating scale ranging from ‘not painful at all’ (‘0’) to ‘most intense imaginable pain’ (‘10’). The design also includes another condition we will not analyze here, in which participants viewed videos varying in color saturation and had to report on a scale from ‘not a change’ (‘0’) to ‘a very big change’ (‘10’). Participants were asked to provide a rating by moving the bar along the scale using two buttons for right and left (index and middle finger) and a third one for confirming their response (ring finger) using their left hand. The direction of the scale and the initial position of the bar was randomized in each trial. The videos used for the Face and Hand conditions for the electrophysiology and fMRI experiment were generated in the same way but were not identical. The task was split up into six blocks of 30 trials each: two blocks of electrical pain stimulations, two blocks of mechanical slaps by a belt, and two blocks of videos with changes in color saturation (presented in 46 separate fMRI acquisition runs). Anatomical images were recorded between the fourth and fifth run of fMRI acquisition.</p></sec><sec id="s4-6-3"><title>Data acquisition</title><p>MRI images were acquired with a 3-Tesla Philips Ingenia CX system using a 32-channel head coil. One T1-weighted structural image (matrix = 240 × 222; 170 slices; voxel size = 1 × 1 × 1 mm) was collected per participant together with echoplanar imaging (EPI) volumes (matrix M × P: 80 × 78; 32 transversal slices acquired in ascending order; TR = 1.7 s; TE = 27.6 ms; flip angle: 72.90°; voxel size = 3 × 3 × 3 mm, including a 0.349 mm slice gap).</p></sec><sec id="s4-6-4"><title>Data analysis</title><sec id="s4-6-4-1"><title>Preprocessing</title><p>MRI data were processed in SPM12. EPI images were slice-time-corrected to the middle slice and realigned to the mean EPI. High-quality T1 images were co-registered to the mean EPI image and segmented. The normalization parameters computed during the segmentation were used to normalize the gray matter segment (1 × 1 × 1 mm) and the EPI images (2 × 2 × 2 mm) to the MNI templates. Finally, EPIs images were smoothed with a 6 mm kernel.</p></sec><sec id="s4-6-4-2"><title>Voxel-wise analysis</title><p>At the first level, we defined separate regressors for the Hand videos, Face videos, rating scale, and button presses. Analyses focused on the 2 s that the videos were presented. The trial-by-trial ratings given by the participants were used as a parametric modulator, one modulator for the Face and one for the Hand trials, on the respective video regressor. The rating-scale regressor started from the moment the scale appeared and ended with participants’ confirmation button press. The button-press regressor, finally, had zero duration events aligned to the moment of each button press. Six additional regressors of no interest were included to model head movements. To quantify the degree to which each voxel in the insula had BOLD activity associated with trial-by-trial ratings, we then brought the parameter estimate for the parametric modulator obtained for Hand and Face trials separately to a second-level <italic>t</italic>-test with 23 participants, and then used the resulting <italic>t</italic>-value as a measure of the random effect size of the association for each voxel. We used <italic>t</italic>-values rather than the average value of the parametric modulator because these values are to be compared against out-of-sample values of patients, and the topography of <italic>t</italic>-values is a better predictor for out-of-sample generalizations. However, the average parameter value correlated above 0.9 with the <italic>t</italic>-value.</p></sec><sec id="s4-6-4-3"><title>Multivariate regression</title><p>To investigate whether the pattern of BOLD activity across all voxels in the insula encodes intensity, we additionally performed a multivariate regression analysis akin to the PLSR for the BBP described in above. For each participant, we performed a general linear model that estimated a separate parameter estimate for the video epoch of trials in which participants gave a rating of 0–2, 3–4, 5–6, or 7–8, respectively, separately for Hand and Face trials. In MATLAB, we then loaded for each subject the parameter estimate images for each level of rating and only included voxels that fell within our insula mask (<xref ref-type="bibr" rid="bib20">Faillenot et al., 2017</xref>). We then trained a weighted PLSR using the MATLAB function plsregress and the data from all but one participant to predict rating based on a linear combination of the parameter estimates in each voxel and used this linear combination to predict the rating of the left-out participant, repeating the procedure for each participant. We weighted the regression by replicating each parameter estimate image in the training and testing set by the number of trials that went into it. We quantified how accurately the regression predicted the rating of the left-out participants using Kendall’s tau, then tested whether the performance was above chance by comparing the 23 prediction accuracies (Kendall’s tau) against zero in a one-tailed test. Based on the analysis on the BBP, we performed this analysis with procedure using two or three components.</p></sec></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Validation, Visualization, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Software, Formal analysis, Validation, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Resources, Software, Formal analysis, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Visualization, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con10"><p>Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con12"><p>Resources, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con13"><p>Resources, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con14"><p>Conceptualization, Resources, Software, Formal analysis, Supervision, Funding acquisition, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con15"><p>Conceptualization, Resources, Software, Formal analysis, Supervision, Funding acquisition, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Written informed consent was obtained from each participant before participating in the study. All procedures on patients were approved by the medical ethical committee of the Vrije University Medical Center (protocol 2016/037). All procedures on healthy participants were approved by the local ethics committee of the University of Amsterdam (protocols 2017-EXT-8542 and 2021-EXT-13608). In addition, written informed consent to publish was obtained from the individual whose photographs are shown in Figures 1 and 3 of the article.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-75197-transrepform1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data presented in this work is publicly available at the Open Science Framework: <ext-link ext-link-type="uri" xlink:href="https://osf.io/mcahz/">https://osf.io/mcahz/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Gazzola</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Intracranial Human Recordings Reveal Intensity Coding for the Pain of Others in the Insula</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/mcahz/">mcahz</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Pieter Roelfsema for enabling the collaboration that led to the access to the patients, Eline Ramaaker for her assistance in electrode localization, Agneta Fischer and George Bulte at UvA for advice and help with the use of FaceReader, and Tess den Uyl for advice on how to use FaceReader specifically to analyze facial expressions of pain. This work was supported by Dutch Research Council (NWO) VIDI grant (452-14-015) to VG and VICI grant (453-15-009) to CK.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdelgabar</surname><given-names>AR</given-names></name><name><surname>Suttrup</surname><given-names>J</given-names></name><name><surname>Broersen</surname><given-names>R</given-names></name><name><surname>Bhandari</surname><given-names>R</given-names></name><name><surname>Picard</surname><given-names>S</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>De Zeeuw</surname><given-names>CI</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Action perception recruits the cerebellum and is impaired in patients with spinocerebellar ataxia</article-title><source>Brain</source><volume>142</volume><fpage>3791</fpage><lpage>3805</lpage><pub-id pub-id-type="doi">10.1093/brain/awz337</pub-id><pub-id pub-id-type="pmid">31747689</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Damasio</surname><given-names>H</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Cooper</surname><given-names>G</given-names></name><name><surname>Damasio</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A role for somatosensory cortices in the visual recognition of emotion as revealed by three-dimensional lesion mapping</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>2683</fpage><lpage>2690</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.20-07-02683.2000</pub-id><pub-id pub-id-type="pmid">10729349</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name><name><surname>Tranel</surname><given-names>D</given-names></name><name><surname>Damasio</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Dissociable neural systems for recognizing emotions</article-title><source>Brain and Cognition</source><volume>52</volume><fpage>61</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/s0278-2626(03)00009-5</pub-id><pub-id pub-id-type="pmid">12812805</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anwyl-Irvine</surname><given-names>AL</given-names></name><name><surname>Massonnié</surname><given-names>J</given-names></name><name><surname>Flitton</surname><given-names>A</given-names></name><name><surname>Kirkham</surname><given-names>N</given-names></name><name><surname>Evershed</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Gorilla in our midst: an online behavioral experiment builder</article-title><source>Behavior Research Methods</source><volume>52</volume><fpage>388</fpage><lpage>407</lpage><pub-id pub-id-type="doi">10.3758/s13428-019-01237-x</pub-id><pub-id pub-id-type="pmid">31016684</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartoli</surname><given-names>E</given-names></name><name><surname>Bosking</surname><given-names>W</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Sheth</surname><given-names>SA</given-names></name><name><surname>Beauchamp</surname><given-names>MS</given-names></name><name><surname>Yoshor</surname><given-names>D</given-names></name><name><surname>Foster</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Functionally distinct gamma range activity revealed by stimulus tuning in human visual cortex</article-title><source>Current Biology</source><volume>29</volume><fpage>3345</fpage><lpage>3358</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.08.004</pub-id><pub-id pub-id-type="pmid">31588003</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastuji</surname><given-names>H</given-names></name><name><surname>Frot</surname><given-names>M</given-names></name><name><surname>Perchet</surname><given-names>C</given-names></name><name><surname>Magnin</surname><given-names>M</given-names></name><name><surname>Garcia-Larrea</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pain networks from the inside: spatiotemporal analysis of brain responses leading from nociception to conscious perception</article-title><source>Human Brain Mapping</source><volume>37</volume><fpage>4301</fpage><lpage>4315</lpage><pub-id pub-id-type="doi">10.1002/hbm.23310</pub-id><pub-id pub-id-type="pmid">27391083</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastuji</surname><given-names>H</given-names></name><name><surname>Frot</surname><given-names>M</given-names></name><name><surname>Perchet</surname><given-names>C</given-names></name><name><surname>Hagiwara</surname><given-names>K</given-names></name><name><surname>Garcia-Larrea</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Convergence of sensory and limbic noxious input into the anterior insula and the emergence of pain from nociception</article-title><source>Scientific Reports</source><volume>8</volume><elocation-id>13360</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-31781-z</pub-id><pub-id pub-id-type="pmid">30190593</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Singer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The neural basis of empathy</article-title><source>Annual Review of Neuroscience</source><volume>35</volume><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150536</pub-id><pub-id pub-id-type="pmid">22715878</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boynton</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spikes, BOLD, attention, and awareness: a comparison of electrophysiological and fmri signals in V1</article-title><source>Journal of Vision</source><volume>11</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.1167/11.5.12</pub-id><pub-id pub-id-type="pmid">22199162</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The origin of extracellular fields and currents -- EEG, ECoG, LFP and spikes</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>407</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1038/nrn3241</pub-id><pub-id pub-id-type="pmid">22595786</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrillo</surname><given-names>M</given-names></name><name><surname>Han</surname><given-names>Y</given-names></name><name><surname>Migliorati</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Emotional mirror neurons in the rat’s anterior cingulate cortex</article-title><source>Current Biology</source><volume>29</volume><fpage>1301</fpage><lpage>1312</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.03.024</pub-id><pub-id pub-id-type="pmid">30982647</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caspers</surname><given-names>S</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name><name><surname>Laird</surname><given-names>AR</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Ale meta-analysis of action observation and imitation in the human brain</article-title><source>NeuroImage</source><volume>50</volume><fpage>1148</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.112</pub-id><pub-id pub-id-type="pmid">20056149</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>YH</given-names></name><name><surname>Dammers</surname><given-names>J</given-names></name><name><surname>Boers</surname><given-names>F</given-names></name><name><surname>Leiberg</surname><given-names>S</given-names></name><name><surname>Edgar</surname><given-names>JC</given-names></name><name><surname>Roberts</surname><given-names>TPL</given-names></name><name><surname>Mathiak</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The temporal dynamics of insula activity to disgust and happy facial expressions: a magnetoencephalography study</article-title><source>NeuroImage</source><volume>47</volume><fpage>1921</fpage><lpage>1928</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.04.093</pub-id><pub-id pub-id-type="pmid">19442746</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cornwell</surname><given-names>BR</given-names></name><name><surname>Carver</surname><given-names>FW</given-names></name><name><surname>Coppola</surname><given-names>R</given-names></name><name><surname>Johnson</surname><given-names>L</given-names></name><name><surname>Alvarez</surname><given-names>R</given-names></name><name><surname>Grillon</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Evoked amygdala responses to negative faces revealed by adaptive MEG beamformers</article-title><source>Brain Research</source><volume>1244</volume><fpage>103</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2008.09.068</pub-id><pub-id pub-id-type="pmid">18930036</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Corradi-Dell’Acqua</surname><given-names>C</given-names></name><name><surname>Tusche</surname><given-names>A</given-names></name><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Singer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Cross-Modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>10904</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms10904</pub-id><pub-id pub-id-type="pmid">26988654</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craig</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>How do you feel? interoception: the sense of the physiological condition of the body</article-title><source>Nature Reviews. Neuroscience</source><volume>3</volume><fpage>655</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1038/nrn894</pub-id><pub-id pub-id-type="pmid">12154366</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Craig</surname><given-names>ADB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>How do you feel--now? the anterior insula and human awareness</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>59</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/nrn2555</pub-id><pub-id pub-id-type="pmid">19096369</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dal Monte</surname><given-names>O</given-names></name><name><surname>Krueger</surname><given-names>F</given-names></name><name><surname>Solomon</surname><given-names>JM</given-names></name><name><surname>Schintu</surname><given-names>S</given-names></name><name><surname>Knutson</surname><given-names>KM</given-names></name><name><surname>Strenziok</surname><given-names>M</given-names></name><name><surname>Pardini</surname><given-names>M</given-names></name><name><surname>Leopold</surname><given-names>A</given-names></name><name><surname>Raymont</surname><given-names>V</given-names></name><name><surname>Grafman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A voxel-based lesion study on facial emotion recognition after penetrating brain injury</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>8</volume><fpage>632</fpage><lpage>639</lpage><pub-id pub-id-type="doi">10.1093/scan/nss041</pub-id><pub-id pub-id-type="pmid">22496440</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>P</given-names></name><name><surname>Friesen</surname><given-names>WV</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>Facial Action Coding System: A Technique for the Measurement of Facial Movement</source><publisher-loc>Palo Alto, CA</publisher-loc><publisher-name>Consulting Psychologists Press</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faillenot</surname><given-names>I</given-names></name><name><surname>Heckemann</surname><given-names>RA</given-names></name><name><surname>Frot</surname><given-names>M</given-names></name><name><surname>Hammers</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Macroanatomy and 3D probabilistic atlas of the human insula</article-title><source>NeuroImage</source><volume>150</volume><fpage>88</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.01.073</pub-id><pub-id pub-id-type="pmid">28179166</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Wilson</surname><given-names>CL</given-names></name><name><surname>Maidment</surname><given-names>NT</given-names></name><name><surname>Engel</surname><given-names>J</given-names></name><name><surname>Behnke</surname><given-names>E</given-names></name><name><surname>Fields</surname><given-names>TA</given-names></name><name><surname>MacDonald</surname><given-names>KA</given-names></name><name><surname>Morrow</surname><given-names>JW</given-names></name><name><surname>Ackerson</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cerebral microdialysis combined with single-neuron and electroencephalographic recording in neurosurgical patients technical note</article-title><source>Journal of Neurosurgery</source><volume>91</volume><fpage>697</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.3171/jns.1999.91.4.0697</pub-id><pub-id pub-id-type="pmid">10507396</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallo</surname><given-names>S</given-names></name><name><surname>Paracampo</surname><given-names>R</given-names></name><name><surname>Müller-Pinzler</surname><given-names>L</given-names></name><name><surname>Severo</surname><given-names>MC</given-names></name><name><surname>Blömer</surname><given-names>L</given-names></name><name><surname>Fernandes-Henriques</surname><given-names>C</given-names></name><name><surname>Henschel</surname><given-names>A</given-names></name><name><surname>Lammes</surname><given-names>BK</given-names></name><name><surname>Maskaljunas</surname><given-names>T</given-names></name><name><surname>Suttrup</surname><given-names>J</given-names></name><name><surname>Avenanti</surname><given-names>A</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The causal role of the somatosensory cortex in prosocial behaviour</article-title><source>eLife</source><volume>7</volume><elocation-id>e32740</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32740</pub-id><pub-id pub-id-type="pmid">29735015</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The observation and execution of actions share motor and somatosensory voxels in all tested subjects: single-subject analyses of unsmoothed fmri data</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>1239</fpage><lpage>1255</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn181</pub-id><pub-id pub-id-type="pmid">19020203</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grinband</surname><given-names>J</given-names></name><name><surname>Hirsch</surname><given-names>J</given-names></name><name><surname>Ferrera</surname><given-names>VP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A neural representation of categorization uncertainty in the human brain</article-title><source>Neuron</source><volume>49</volume><fpage>757</fpage><lpage>763</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.01.032</pub-id><pub-id pub-id-type="pmid">16504950</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hutchison</surname><given-names>WD</given-names></name><name><surname>Davis</surname><given-names>KD</given-names></name><name><surname>Lozano</surname><given-names>AM</given-names></name><name><surname>Tasker</surname><given-names>RR</given-names></name><name><surname>Dostrovsky</surname><given-names>JO</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Pain-Related neurons in the human cingulate cortex</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>403</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1038/8065</pub-id><pub-id pub-id-type="pmid">10321241</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ingvar</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Pain and functional imaging</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>354</volume><fpage>1347</fpage><lpage>1358</lpage><pub-id pub-id-type="doi">10.1098/rstb.1999.0483</pub-id><pub-id pub-id-type="pmid">10466155</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jabbi</surname><given-names>M</given-names></name><name><surname>Swart</surname><given-names>M</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Empathy for positive and negative emotions in the gustatory cortex</article-title><source>NeuroImage</source><volume>34</volume><fpage>1744</fpage><lpage>1753</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.10.032</pub-id><pub-id pub-id-type="pmid">17175173</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jauniaux</surname><given-names>J</given-names></name><name><surname>Khatibi</surname><given-names>A</given-names></name><name><surname>Rainville</surname><given-names>P</given-names></name><name><surname>Jackson</surname><given-names>PL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A meta-analysis of neuroimaging studies on pain empathy: investigating the role of visual information and observers’ perspective</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>14</volume><fpage>789</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1093/scan/nsz055</pub-id><pub-id pub-id-type="pmid">31393982</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jeffreys</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1939">1939</year><source>Theory of Probability</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jobst</surname><given-names>BC</given-names></name><name><surname>Gonzalez-Martinez</surname><given-names>J</given-names></name><name><surname>Isnard</surname><given-names>J</given-names></name><name><surname>Kahane</surname><given-names>P</given-names></name><name><surname>Lacuey</surname><given-names>N</given-names></name><name><surname>Lahtoo</surname><given-names>SD</given-names></name><name><surname>Nguyen</surname><given-names>DK</given-names></name><name><surname>Wu</surname><given-names>C</given-names></name><name><surname>Lado</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The insula and its epilepsies</article-title><source>Epilepsy Currents</source><volume>19</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1177/1535759718822847</pub-id><pub-id pub-id-type="pmid">30838920</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>Kaas</surname><given-names>JH</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Somatosensation in social perception</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>417</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1038/nrn2833</pub-id><pub-id pub-id-type="pmid">20445542</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>Paracampo</surname><given-names>R</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What neuromodulation and lesion studies tell us about the function of the mirror neuron system and embodied cognition</article-title><source>Current Opinion in Psychology</source><volume>24</volume><fpage>35</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/j.copsyc.2018.04.001</pub-id><pub-id pub-id-type="pmid">29734039</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Using Bayes factor hypothesis testing in neuroscience to establish evidence of absence</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>788</fpage><lpage>799</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0660-4</pub-id><pub-id pub-id-type="pmid">32601411</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobayakawa</surname><given-names>T</given-names></name><name><surname>Endo</surname><given-names>H</given-names></name><name><surname>Ayabe-Kanamura</surname><given-names>S</given-names></name><name><surname>Kumagai</surname><given-names>T</given-names></name><name><surname>Yamaguchi</surname><given-names>Y</given-names></name><name><surname>Kikuchi</surname><given-names>Y</given-names></name><name><surname>Takeda</surname><given-names>T</given-names></name><name><surname>Saito</surname><given-names>S</given-names></name><name><surname>Ogawa</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>The primary gustatory area in human cerebral cortex studied by magnetoencephalography</article-title><source>Neuroscience Letters</source><volume>212</volume><fpage>155</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1016/0304-3940(96)12798-1</pub-id><pub-id pub-id-type="pmid">8843096</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishnan</surname><given-names>A</given-names></name><name><surname>Woo</surname><given-names>CW</given-names></name><name><surname>Chang</surname><given-names>LJ</given-names></name><name><surname>Ruzic</surname><given-names>L</given-names></name><name><surname>Gu</surname><given-names>X</given-names></name><name><surname>López-Solà</surname><given-names>M</given-names></name><name><surname>Jackson</surname><given-names>PL</given-names></name><name><surname>Pujol</surname><given-names>J</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Somatic and vicarious pain are represented by dissociable multivariate brain patterns</article-title><source>eLife</source><volume>5</volume><elocation-id>e15166</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.15166</pub-id><pub-id pub-id-type="pmid">27296895</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krolak-Salmon</surname><given-names>P</given-names></name><name><surname>Hénaff</surname><given-names>MA</given-names></name><name><surname>Isnard</surname><given-names>J</given-names></name><name><surname>Tallon-Baudry</surname><given-names>C</given-names></name><name><surname>Guénot</surname><given-names>M</given-names></name><name><surname>Vighetto</surname><given-names>A</given-names></name><name><surname>Bertrand</surname><given-names>O</given-names></name><name><surname>Mauguière</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>An attention modulated response to disgust in human ventral anterior insula</article-title><source>Annals of Neurology</source><volume>53</volume><fpage>446</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1002/ana.10502</pub-id><pub-id pub-id-type="pmid">12666112</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Lautenbacher</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The faces of pain: a cluster analysis of individual differences in facial activity patterns of pain</article-title><source>European Journal of Pain</source><volume>18</volume><fpage>813</fpage><lpage>823</lpage><pub-id pub-id-type="doi">10.1002/j.1532-2149.2013.00421.x</pub-id><pub-id pub-id-type="pmid">24174396</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunz</surname><given-names>M</given-names></name><name><surname>Meixner</surname><given-names>D</given-names></name><name><surname>Lautenbacher</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Facial muscle movements encoding pain-a systematic review</article-title><source>Pain</source><volume>160</volume><fpage>535</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1097/j.pain.0000000000001424</pub-id><pub-id pub-id-type="pmid">30335682</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamm</surname><given-names>C</given-names></name><name><surname>Decety</surname><given-names>J</given-names></name><name><surname>Singer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Meta-analytic evidence for common and distinct neural networks associated with directly experienced pain and empathy for pain</article-title><source>NeuroImage</source><volume>54</volume><fpage>2492</fpage><lpage>2502</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.10.014</pub-id><pub-id pub-id-type="pmid">20946964</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legrain</surname><given-names>V</given-names></name><name><surname>Iannetti</surname><given-names>GD</given-names></name><name><surname>Plaghki</surname><given-names>L</given-names></name><name><surname>Mouraux</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The pain matrix reloaded: A salience detection system for the body</article-title><source>Progress in Neurobiology</source><volume>93</volume><fpage>111</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2010.10.005</pub-id><pub-id pub-id-type="pmid">21040755</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liberati</surname><given-names>G</given-names></name><name><surname>Klöcker</surname><given-names>A</given-names></name><name><surname>Safronova</surname><given-names>MM</given-names></name><name><surname>Ferrão Santos</surname><given-names>S</given-names></name><name><surname>Ribeiro Vaz</surname><given-names>JG</given-names></name><name><surname>Raftopoulos</surname><given-names>C</given-names></name><name><surname>Mouraux</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Nociceptive local field potentials recorded from the human insula are not specific for nociception</article-title><source>PLOS Biol</source><volume>14</volume><elocation-id>e1002345</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002345</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liberati</surname><given-names>G</given-names></name><name><surname>Mulders</surname><given-names>D</given-names></name><name><surname>Algoet</surname><given-names>M</given-names></name><name><surname>van den Broeke</surname><given-names>EN</given-names></name><name><surname>Santos</surname><given-names>SF</given-names></name><name><surname>Ribeiro Vaz</surname><given-names>JG</given-names></name><name><surname>Raftopoulos</surname><given-names>C</given-names></name><name><surname>Mouraux</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Insular responses to transient painful and non-painful thermal and mechanical spinothalamic stimuli recorded using intracerebral EEG</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>22319</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-79371-2</pub-id><pub-id pub-id-type="pmid">33339884</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Likhtik</surname><given-names>E</given-names></name><name><surname>Gordon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Circuits in sync: decoding theta communication in fear and safety</article-title><source>Neuropsychopharmacology</source><volume>39</volume><fpage>235</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/npp.2013.228</pub-id><pub-id pub-id-type="pmid">24317311</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Likhtik</surname><given-names>E</given-names></name><name><surname>Stujenske</surname><given-names>JM</given-names></name><name><surname>Topiwala</surname><given-names>MA</given-names></name><name><surname>Harris</surname><given-names>AZ</given-names></name><name><surname>Gordon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Prefrontal entrainment of amygdala activity signals safety in learned fear and innate anxiety</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>106</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1038/nn.3582</pub-id><pub-id pub-id-type="pmid">24241397</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maier</surname><given-names>A</given-names></name><name><surname>Wilke</surname><given-names>M</given-names></name><name><surname>Aura</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>C</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Divergence of fMRI and neural signals in V1 during perceptual suppression in the awake monkey</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>1193</fpage><lpage>1200</lpage><pub-id pub-id-type="doi">10.1038/nn.2173</pub-id><pub-id pub-id-type="pmid">18711393</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattavelli</surname><given-names>G</given-names></name><name><surname>Pisoni</surname><given-names>A</given-names></name><name><surname>Casarotti</surname><given-names>A</given-names></name><name><surname>Comi</surname><given-names>A</given-names></name><name><surname>Sera</surname><given-names>G</given-names></name><name><surname>Riva</surname><given-names>M</given-names></name><name><surname>Bizzi</surname><given-names>A</given-names></name><name><surname>Rossi</surname><given-names>M</given-names></name><name><surname>Bello</surname><given-names>L</given-names></name><name><surname>Papagno</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Consequences of brain tumour resection on emotion recognition</article-title><source>Journal of Neuropsychology</source><volume>13</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1111/jnp.12130</pub-id><pub-id pub-id-type="pmid">28700143</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazzola</surname><given-names>L</given-names></name><name><surname>Isnard</surname><given-names>J</given-names></name><name><surname>Peyron</surname><given-names>R</given-names></name><name><surname>Mauguière</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Stimulation of the human cortex and the experience of pain: wilder penfield’s observations revisited</article-title><source>Brain</source><volume>135</volume><fpage>631</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1093/brain/awr265</pub-id><pub-id pub-id-type="pmid">22036962</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meeren</surname><given-names>HKM</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Ahlfors</surname><given-names>SP</given-names></name><name><surname>Hämäläinen</surname><given-names>MS</given-names></name><name><surname>Hadjikhani</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Different cortical dynamics in face and body perception: an MEG study</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e71408</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0071408</pub-id><pub-id pub-id-type="pmid">24039712</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meffert</surname><given-names>H</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>den Boer</surname><given-names>JA</given-names></name><name><surname>Bartels</surname><given-names>AAJ</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reduced spontaneous but relatively normal deliberate vicarious representations in psychopathy</article-title><source>Brain</source><volume>136</volume><fpage>2550</fpage><lpage>2562</lpage><pub-id pub-id-type="doi">10.1093/brain/awt190</pub-id><pub-id pub-id-type="pmid">23884812</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>KJ</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Hermes</surname><given-names>D</given-names></name><name><surname>Rao</surname><given-names>RPN</given-names></name><name><surname>denNijs</surname><given-names>M</given-names></name><name><surname>Ojemann</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Broadband changes in the cortical surface potential track activation of functionally diverse neuronal populations</article-title><source>NeuroImage</source><volume>85</volume><fpage>711</fpage><lpage>720</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.070</pub-id><pub-id pub-id-type="pmid">24018305</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paradiso</surname><given-names>E</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural mechanisms necessary for empathy-related phenomena across species</article-title><source>Current Opinion in Neurobiology</source><volume>68</volume><fpage>107</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2021.02.005</pub-id><pub-id pub-id-type="pmid">33756399</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perrett</surname><given-names>DI</given-names></name><name><surname>Xiao</surname><given-names>D</given-names></name><name><surname>Barraclough</surname><given-names>NE</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>Oram</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Seeing the future: natural image sequences produce “anticipatory” neuronal activity and bias perceptual report</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>62</volume><fpage>2081</fpage><lpage>2104</lpage><pub-id pub-id-type="doi">10.1080/17470210902959279</pub-id><pub-id pub-id-type="pmid">19557666</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pobric</surname><given-names>G</given-names></name><name><surname>Hamilton</surname><given-names>AF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Action understanding requires the left inferior frontal cortex</article-title><source>Current Biology</source><volume>16</volume><fpage>524</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2006.01.033</pub-id><pub-id pub-id-type="pmid">16527749</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Nadasdy</surname><given-names>Z</given-names></name><name><surname>Ben-Shaul</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Unsupervised spike detection and sorting with wavelets and superparamagnetic clustering</article-title><source>Neural Computation</source><volume>16</volume><fpage>1661</fpage><lpage>1687</lpage><pub-id pub-id-type="doi">10.1162/089976604774201631</pub-id><pub-id pub-id-type="pmid">15228749</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reddy</surname><given-names>L</given-names></name><name><surname>Poncet</surname><given-names>M</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Peters</surname><given-names>JC</given-names></name><name><surname>Douw</surname><given-names>L</given-names></name><name><surname>van Dellen</surname><given-names>E</given-names></name><name><surname>Claus</surname><given-names>S</given-names></name><name><surname>Reijneveld</surname><given-names>JC</given-names></name><name><surname>Baayen</surname><given-names>JC</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning of anticipatory responses in single neurons of the human medial temporal lobe</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>8556</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms9556</pub-id><pub-id pub-id-type="pmid">26449885</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>JN</given-names></name><name><surname>Speckman</surname><given-names>PL</given-names></name><name><surname>Sun</surname><given-names>D</given-names></name><name><surname>Morey</surname><given-names>RD</given-names></name><name><surname>Iverson</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Bayesian T tests for accepting and rejecting the null hypothesis</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>16</volume><fpage>225</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.3758/PBR.16.2.225</pub-id><pub-id pub-id-type="pmid">19293088</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>JN</given-names></name><name><surname>Morey</surname><given-names>RD</given-names></name><name><surname>Speckman</surname><given-names>PL</given-names></name><name><surname>Province</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Default Bayes factors for ANOVA designs</article-title><source>Journal of Mathematical Psychology</source><volume>56</volume><fpage>356</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2012.08.001</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>JN</given-names></name><name><surname>Engelhardt</surname><given-names>CR</given-names></name><name><surname>McCabe</surname><given-names>S</given-names></name><name><surname>Morey</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Model comparison in ANOVA</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>1779</fpage><lpage>1786</lpage><pub-id pub-id-type="doi">10.3758/s13423-016-1026-5</pub-id><pub-id pub-id-type="pmid">27068543</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname><given-names>JN</given-names></name><name><surname>Morey</surname><given-names>RD</given-names></name><name><surname>Verhagen</surname><given-names>AJ</given-names></name><name><surname>Swagman</surname><given-names>AR</given-names></name><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Bayesian analysis of factorial designs</article-title><source>Psychological Methods</source><volume>22</volume><fpage>304</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1037/met0000057</pub-id><pub-id pub-id-type="pmid">27280448</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seth</surname><given-names>AK</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Active interoceptive inference and the emotional brain</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>371</volume><elocation-id>20160007</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0007</pub-id><pub-id pub-id-type="pmid">28080966</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>T</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>O’Doherty</surname><given-names>J</given-names></name><name><surname>Kaube</surname><given-names>H</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Empathy for pain involves the affective but not sensory components of pain</article-title><source>Science</source><volume>303</volume><fpage>1157</fpage><lpage>1162</lpage><pub-id pub-id-type="doi">10.1126/science.1093535</pub-id><pub-id pub-id-type="pmid">14976305</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taniguchi</surname><given-names>N</given-names></name><name><surname>Hironaga</surname><given-names>N</given-names></name><name><surname>Mitsudo</surname><given-names>T</given-names></name><name><surname>Tamura</surname><given-names>S</given-names></name><name><surname>Yamaura</surname><given-names>K</given-names></name><name><surname>Tobimatsu</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Late responses in the anterior insula reflect the cognitive component of pain: evidence of nonpain processing</article-title><source>Pain Reports</source><volume>7</volume><elocation-id>e984</elocation-id><pub-id pub-id-type="doi">10.1097/PR9.0000000000000984</pub-id><pub-id pub-id-type="pmid">35187379</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taub</surname><given-names>AH</given-names></name><name><surname>Perets</surname><given-names>R</given-names></name><name><surname>Kahana</surname><given-names>E</given-names></name><name><surname>Paz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Oscillations synchronize amygdala-to-prefrontal primate circuits during aversive learning</article-title><source>Neuron</source><volume>97</volume><fpage>291</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.042</pub-id><pub-id pub-id-type="pmid">29290553</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timmers</surname><given-names>I</given-names></name><name><surname>Park</surname><given-names>AL</given-names></name><name><surname>Fischer</surname><given-names>MD</given-names></name><name><surname>Kronman</surname><given-names>CA</given-names></name><name><surname>Heathcote</surname><given-names>LC</given-names></name><name><surname>Hernandez</surname><given-names>JM</given-names></name><name><surname>Simons</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Is empathy for pain unique in its neural correlates? A meta-analysis of neuroimaging studies of empathy</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>12</volume><elocation-id>289</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2018.00289</pub-id><pub-id pub-id-type="pmid">30542272</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tovote</surname><given-names>P</given-names></name><name><surname>Fadok</surname><given-names>JP</given-names></name><name><surname>Lüthi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal circuits for fear and anxiety</article-title><source>Nature Reviews. Neuroscience</source><volume>16</volume><fpage>317</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1038/nrn3945</pub-id><pub-id pub-id-type="pmid">25991441</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname><given-names>LQ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Salience processing and insular cortical function and dysfunction</article-title><source>Nature Reviews. Neuroscience</source><volume>16</volume><fpage>55</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1038/nrn3857</pub-id><pub-id pub-id-type="pmid">25406711</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname><given-names>LQ</given-names></name><name><surname>Nomi</surname><given-names>JS</given-names></name><name><surname>Hébert-Seropian</surname><given-names>B</given-names></name><name><surname>Ghaziri</surname><given-names>J</given-names></name><name><surname>Boucher</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Structure and function of the human insula</article-title><source>Journal of Clinical Neurophysiology</source><volume>34</volume><fpage>300</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1097/WNP.0000000000000377</pub-id><pub-id pub-id-type="pmid">28644199</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Doorn</surname><given-names>J</given-names></name><name><surname>Ly</surname><given-names>A</given-names></name><name><surname>Marsman</surname><given-names>M</given-names></name><name><surname>Wagenmakers</surname><given-names>E-J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Bayesian rank-based hypothesis testing for the RANK sum test, the signed RANK test, and spearman’s ρ</article-title><source>Journal of Applied Statistics</source><volume>47</volume><fpage>2984</fpage><lpage>3006</lpage><pub-id pub-id-type="doi">10.1080/02664763.2019.1709053</pub-id><pub-id pub-id-type="pmid">35707708</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname><given-names>EJ</given-names></name><name><surname>Verhagen</surname><given-names>AJ</given-names></name><name><surname>Ly</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How to quantify the evidence for the absence of a correlation</article-title><source>Behavior Research Methods</source><volume>48</volume><fpage>413</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.3758/s13428-015-0593-0</pub-id><pub-id pub-id-type="pmid">26148822</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wicker</surname><given-names>B</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>Plailly</surname><given-names>J</given-names></name><name><surname>Royet</surname><given-names>JP</given-names></name><name><surname>Gallese</surname><given-names>V</given-names></name><name><surname>Rizzolatti</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Both of US disgusted in my insula: the common neural basis of seeing and feeling disgust</article-title><source>Neuron</source><volume>40</volume><fpage>655</fpage><lpage>664</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(03)00679-2</pub-id><pub-id pub-id-type="pmid">14642287</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarkoni</surname><given-names>T</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Large-Scale automated synthesis of human functional neuroimaging data</article-title><source>Nature Methods</source><volume>8</volume><fpage>665</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1635</pub-id><pub-id pub-id-type="pmid">21706013</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarkoni</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The generalizability crisis</article-title><source>The Behavioral and Brain Sciences</source><volume>45</volume><elocation-id>e1</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X20001685</pub-id><pub-id pub-id-type="pmid">33342451</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaki</surname><given-names>J</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Singer</surname><given-names>T</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The anatomy of suffering: understanding the relationship between nociceptive and empathic pain</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>249</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.02.003</pub-id><pub-id pub-id-type="pmid">26944221</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>F</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Zhao</surname><given-names>W</given-names></name><name><surname>Xu</surname><given-names>L</given-names></name><name><surname>Zheng</surname><given-names>X</given-names></name><name><surname>Fu</surname><given-names>M</given-names></name><name><surname>Yao</surname><given-names>S</given-names></name><name><surname>Kendrick</surname><given-names>KM</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name><name><surname>Becker</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Empathic pain evoked by sensory and emotional-communicative cues share common and process-specific neural representations</article-title><source>eLife</source><volume>9</volume><elocation-id>e56929</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56929</pub-id><pub-id pub-id-type="pmid">32894226</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zinchenko</surname><given-names>O</given-names></name><name><surname>Yaple</surname><given-names>ZA</given-names></name><name><surname>Arsalidou</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Brain responses to dynamic facial expressions: a normative meta-analysis</article-title><source>Frontiers in Human Neuroscience</source><volume>12</volume><elocation-id>227</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2018.00227</pub-id><pub-id pub-id-type="pmid">29922137</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>How shape information influences participant’s rating</title><p>We collected data from a sample of 40 healthy participants in an online frame rating task to assess whether participants can recognize pain intensity from static frames taken at the key moment of the Face and Hand videos. <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref> shows that the rating of single frames of Faces was even slightly more consistent than the ratings of the entire videos from which they were taken (i.e., <italic>r<sub>S</sub></italic>(frame<sub>i</sub>,AV) &gt; <italic>r<sub>S</sub></italic>(movie<sub>i</sub>,AV), <italic>W</italic> = 193, p<sub>2</sub>=0.003, BF<sub>10</sub> = 31.29). In contrast, for Hands, the rating of the frames was poor compared to the rating of the movies (i.e., <italic>r<sub>S</sub></italic>(frame<sub>i</sub>,AV) &lt; <italic>r<sub>S</sub></italic>(movie<sub>i</sub>,AV), <italic>t</italic><sub>(38)</sub> = 11.96, p<sub>2</sub>=2 × 10<sup>–14</sup>, BF<sub>10</sub> = 4 × 10<sup>11</sup>). Directly comparing the change of performance across the two stimulus types as an interaction of an effector (Hand vs. Face) × stimulus (Movie vs. Frame) ANOVA revealed a highly significant effect (<italic>F</italic><sub>(1,38)</sub> = 178.98, p=6 × 10<sup>–16</sup>, BF<sub>incl</sub> = ∞). Finally, because for Hands, the accuracy was low, we also tested whether the accuracy was above zero, and it was (<italic>W</italic> = 580, p<sub>2</sub>=0.022, BF<sub>10</sub> = 6.19). Hence, for Faces, static shape information was sufficient to explain the rating of the videos, while for Hands, the shape information in the frames we selected was not sufficient. It should be noted that in principle information contained in other frames may have contained useful information, but informal reports of some participants confirmed that they paid attention more to kinematic than configurational cues.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Rating from shape information alone.</title><p>Mean ± SEM correlation coefficients between each participant’s ratings in the online <italic>frame</italic> rating task and the average ratings of the other participants in the online <italic>video</italic> rating task (<italic>r<sub>S</sub></italic>(frame,average_video), green and purple) compared against that between participant’s ratings in the online <italic>video</italic> rating task and the average ratings of the other participants in the same task (<italic>r<sub>S</sub></italic>(video,average_video), gray) for Hands and Faces separately. Black statistics above the bars compare the respective frame and video ratings, the colored statistics compare the frame ratings against zero. The black statistics under the bars compare the frame ratings between Hands and Faces.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75197-app1-fig1-v2.tif"/></fig></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75197.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zgy1s35</institution-id><institution>University Medical Center Hamburg-Eppendorf</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.06.23.449371" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.06.23.449371"/></front-stub><body><p>This fundamental work shows that insular broadband activity (20-190 Hz) correlates with the perceived intensity of others' painful experiences viewed as movies. This finding is not only important to the pain field but also constitutes an important contribution to the neuroscience of empathy. However, whereas the intracranial recording data are compelling, a limitation of the study remains the lack of specific control stimuli to determine whether the early broad-band insular response when viewing the hand could be related to the observation of body movement rather than &quot;intensity coding for the pain of others&quot;, and whether the late broadband response to a facial expression of pain might also be observed for other facial expressions.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75197.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Büchel</surname><given-names>Christian</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zgy1s35</institution-id><institution>University Medical Center Hamburg-Eppendorf</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Mouraux</surname><given-names>André</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02495e989</institution-id><institution>Université Catholique de Louvain</institution></institution-wrap><country>Belgium</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.06.23.449371">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.06.23.449371v3">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Intracranial Human Recordings Reveal Intensity Coding for the Pain of Others in the Insula&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 Reviewers, and the evaluation has been overseen by Drs. Shackman (Reviewing Editor) and Büchel (Senior Editor).</p><p>The Reviewers and Dr. Shackman discussed the critiques, and he has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>The 3 Reviewers expressed some enthusiasm for the report, noting that</p><p>– The paper addresses an important research question which is investigated in considerable detail.</p><p>– The authors are to be commended for the care and work they put into this manuscript.</p><p>– The study has much to recommend it. The iEEG data are rare and difficult to acquire, and the authors performed a number of interesting and creative analyses, including analyses of correlations with subjective rating, timing of pain rating-correlated iEEG signal relative to facial and motion information in the movies (and assessments of independent raters), and analyses of functional connectivity leveraging Neurosynth and a previously unpublished fMRI study.</p><p>– This study provides a very thorough analysis of insular activity recorded from 7 human participants while they viewed depictions of others in pain, evidenced by movies of both facial expressions made by a model or a hand being hit by a belt. These results provide a rare window into the neural underpinnings of the perception of others' pain, which is a critical ingredient of empathy and human sociality.</p><p>– The manuscript reports a highly original study using intracerebral recordings performed in humans for the diagnostic workup of epilepsy to explore whether and how the insula may encode pain experienced by others. The obtained results, showing that the magnitude of insular broadband activity (20-190 Hz) correlates with the perceived intensity of painful experiences viewed as movies (either facial expressions of pain or painful stimuli applied onto the hand), constitute an important contribution to the neuroscience of empathy.</p><p>– A strength of the manuscript is that, to better understand the time course of the elicited responses and their relation to perceived intensity and take full advantage of the temporal resolution of iEEG recordings, the authors conducted an in-depth analysis of the motion and shape information contained in each video clip, to understand how variations in these stimulus features as a function of time could be used by the participants to decode intensity of the viewed experience. Most importantly, the authors also characterized the relationship between the temporal dynamics of these stimulus features (motion and shape) and the time course of the correlation between insular activity and pain ratings.</p><p>– Assuming the &quot;trend-level&quot; responses related to pain facial expressions are reliable, there are several other interesting characteristics that emerged from the analyses. The analyses suggested overlapping, but separable, distributions of insular locations that encode pain from hands, faces, or both. This is consistent with work on population coding in other areas, and suggests (as the authors argue) that signals at many locations cannot be reduced to &quot;salience&quot; in general as they code for pain inferred from specific stimulus types. These results add to the literature, and appear to correspond with other fMRI studies that have examined intensity-coding of perceived pain. For example, Krishnan et al. 2016, <italic>eLife</italic> found that among individual brain areas that predict intensity of perceived pain from pictures of hands and feet, the insula was among the most strongly predictive. (They also found that a distributed network including other brain regions as well was much more strongly predictive). Zhou et al. 2020 <italic>eLife</italic> studied perceived pain from both facial expressions and pictures of body parts. They identified an overlapping area of the mid– and anterior insula that predicted perceived pain across both stimulus types. That area may be similar to the locations with overlapping encoding observed here, and the distribution across the insula of differentially predictive signals for body parts and faces may be similar to the distribution observed here. Both these studies analyzed relationships between brain activity and trial-by-trial ratings of perceived pain, and so are directly comparable.</p><p>– The present results are also consistent with earlier studies that did not test the relationship with perceived pain, but tested multiple types of stimuli related to pain or other emotions. Corradi-Dell'Acqua et al. 2011 studied fMRI responses to pain-related, non-painful but threatening images, and neutral images, and found responses in the insula to both types of negative images. Later, Corradi-Dell'Acqua et al. 2016 extended this overlap analysis to local multivariate patterns of activity in response to shock pain and disgusting tastes administered to self and other, and to perceived unfairness in the Ultimatum Game. They found evidence for common patterns, particularly in the right anterior insula. Based on these studies, it would be interesting to see whether the iEEG signals recorded in this study would respond similarly to other types of aversive stimuli, including somatic pain. That would inform the field on whether they are related to pain perception or to another, correlated affective state. Though the authors rightly argue that the differential encoding of perceived pain implies that the entire insula cannot simply be encoding &quot;salience&quot;. However, neurons respond to complex configurations of properties, and it may be possible to find signals in the insula or elsewhere that respond to many different combinations of stimulus properties, including conditional ones (e.g., only aversive stimuli delivered to the hand) without truly &quot;representing&quot; or encoding the perception of pain per se. Conclusively identifying a representation of perceived pain, or any other construct, is a noble but difficult challenge, however, and this work takes a step in this direction.</p><p>Narrative Clarity</p><p>– The manuscript is very dense, making it hard to follow. Some sections with many</p><p>statistics could be organized into tables. It was sometimes difficult to follow what was done, particularly in the fMRI section. The main paper has several analyses that really seem to be supplementary and are somewhat distracting (e.g., a long section in the main text on ratings of external observers of the stimuli making ratings).</p><p>Scholarship/Past Work</p><p>– In several places, particularly in the introduction, a small set of overlapping papers are cited that draw heavily on the authors' prior work, but omit some of the most critical other papers – Krishnan et al. 2016 is not cited at all, and Zhou et al. 2020 is mentioned only in passing, though it is the most similar paper in the literature in design and scope. Corradi dell'Acqua's papers are not cited. Most of the fMRI studies cited in the introduction look at the relatively coarse contrast of observed pain versus control, but do not identify signals that encode the intensity of pain within-person. The studies that have done this most directly are Krishnan et al. 2016 and Zhou et al. 2021. Both identify areas within the mid-insula that encode perceived pain.</p><p>Study Framing</p><p>– The paper is framed in the introduction around comparisons with direct pain experience, but there is no comparison with pain experience here, so this is somewhat misleading. The most relevant prior papers are not discussed.</p><p>Approach</p><p>– Key details about the non-insula recordings are omitted</p><p>A nice feature of the manuscript is the comparison of insular electrodes random electrodes &quot;throughout the brain&quot;, but what electrode locations were available, in how many individuals, and what is their distribution? Surely there are not electrode placements everywhere in the brain. Please clarify.</p><p>Approach/Results</p><p>– fMRI study is hard to follow and key details are omitted</p><p>One reviewer noted: Section 2.7 is very difficult to follow. I would very much welcome a careful rewrite of this section.</p><p>Another reviewer wrote that: The concept of the analyses using Neurosynth and fMRI are clever, but the fMRI study in particular is confusing. From the main text it is unclear how many conditions there were in the fMRI study (fMRI during both faces and hands? With ratings?), the sample size, what analyses were done (&quot;leave one subject out&quot; is mentioned but not explained), and whether fMRI activity predicts intensity for either faces or hands. It is stated that &quot;performance did not differ across Hands and Faces&quot;, but not that performance was significant for either or, indeed, what analysis was done.</p><p>Approach/Results/Discussion</p><p>– Unit recordings. Data from 28 unit recordings were provided as additional evidence of pain-of-other coding. This is a very low number of units across only 3 patients, especially given that the results are based on 13 units that showed higher firing during the pain period compared to the baseline period. These observations should probably be relegated to the supplement. At minimum, the wording related to these findings should be revised to reflect the exploratory nature of these results. For example, I do not believe these results warrant labels such as &quot;hand/face specific&quot;.</p><p>– Faces vs. hands effects. There do not seem to be significant brain correlations within faces alone that survive correction for multiple comparisons. Figure 3 shows a &quot;trend&quot;-level result, not significant. Could this indicate a &quot;hand vs. face&quot; effect that appears as a correlation in Figure 2? If hands are rated higher than faces, and hands produce greater BBP in the insula, then any electrode that responds to hands more than faces will show up as a correlation between brain and rated intensity. The way to test this would be to test and show correlations within hands and faces separately, but these were apparently not significant for faces. At minimum, the authors need to frankly address this concern in the Discussion</p><p>– Faces vs. hands effects . A main point of Figure 3 is that correlations with intensity ratings occur later for faces than hands. But the face signals are not really significant, which makes this kind of conclusion difficult, and there don't seem to be any inferential statistics on the timing of the effect. So it's unclear the timing difference is a real effect. Even though this is &quot;purely explorative&quot; it seems hard to justify an entire main figure and section of the text.</p><p>– Faces, hands, and bayes. The facial results appear to hinge on &quot;trend-level&quot; results in several places, and in part on an analysis of lack of differences between faces and hands. It's less desirable to make inferences about the lack of an interaction (a null effect; Figure 3). This is used to argue that there's &quot;no difference between hand and face in the late period&quot;. Another interpretation is that there's simply no correlation with intensity for faces. There is some evidence for an effect, but the study perhaps doesn't have enough power to tell for sure. It is helpful that Bayes Factors are reported, but what threshold do the authors think is required to demonstrate evidence for the null in the presence of these multiple tests? (And what is BFincl as opposed to BF10?)</p><p>Discussion</p><p>– Frank and complete discussion of latencies. The authors report timing effects in the range of 40-320 ms. They cite the well-known study by Krolak-Salmon and colleagues. But it is difficult to know what to make of the current results. On the one hand, latencies on the range of 200-300 ms (across the brain) would be compatible with some studies (but not others). How does one interpret latencies as low as 40-60 ms in the insula, which presumably are not really feasible? On the other hand, the results in the 560-1000 ms range are consistent with many studies but are discussed as &quot;too slow&quot;. Authors need to discuss the likely source of these latencies.</p><p>Discussion/Abstract</p><p>– Experimental approach does not warrant strong claims of specificity.</p><p>A Reviewer noted that: A question that one could raise – especially for the hand condition – is whether part of the trial-by-trial correlation between insular activity and ratings was the consequence of a relationship between that activity and low-level motion/shape features of the video clips, rather than a reflection of the insula being involved in &quot;intensity coding for the pain of others&quot;. Fortunately, this question was at least partly addresses with the available data, by showing that the recorded insular activity correlated with motion energy when the motion was associated with pain (during the slapping of the belt), but not while the motion was innocuous (during the initial lifting of the belt). Nevertheless, as mentioned by the authors themselves, future experiments using additional control stimuli such as stimuli matched in terms of motion content but differing in the emotions they convey are critical to better understand the specificity of the described insular responses.</p><p>S/he also noted that: The observation that insular activity correlated with motion energy when motion was associated with pain, and not during the initial lifting of the belt is indeed an indication that the insular responses cannot be reduced to motion detection. However, in these video clips, the first second showed the belt lifting without any movements of the hand. Then, when the belt came down to hit the hand, this was followed by a reaction/movement of the hand. Therefore, one may wonder whether part of the recorded activity could be related to the specific observation of body movement. This might also relate to the observation that stronger insular activity was observed in the hand condition as compared to the face condition might also bodily movements</p><p>A different Reviewer noted that: The study makes use of a fantastic stimulus set from the research group. But if I understand the set correctly, the same actor is used for different levels of pain (face– and hand-based). While this is an excellent set to study some aspects of coding related to stimulus &quot;preference&quot; I don't believe it's general enough to establish &quot;selectivity&quot;. Accordingly, I think it would be more reasonable to avoid the claims of &quot;selectivity&quot;.</p><p>A third Reviewer wrote that: Notably, the authors do not intend to interpret the generalizability to direct pain experience or other affective states, or specificity to pain compared with other affective conditions; but without more information about these, it is difficult to tell what the signals in the insula actually represent. It leaves open the possibility that there is another, better explanation for activation of insular neurons than perceived pain. e.g., It could be about representation of the body more generally, rather than perceived pain specifically. Could they be coding for choices (ratings) themselves? Baliki found that insular activity correlates with rating intensity of a simple visual stimulus, and other studies (e.g., Grinband et al., Neuron) have found that the insula correlates with simple perceptual magnitude decisions. This will be an ongoing project for future work.</p><p>S/he noted that: The stimulus set chosen was limited, and appears to relate to one specific type of painful stimulus on one hand model, and one set of facial expressions made by one female model. As it's well known in general that neurons often have complex receptive fields, it's unclear whether other types of painful hand stimuli or facial expressions made by other models would yield similar findings. Perhaps the insula would respond more strongly to other faces – or perhaps not at all. Other studies have shown that women's pain is discounted (Zhang et al. 2021). The need for diverse sets of stimuli to establish relationships with brain activity that are not stimulus-specific is becoming increasingly recognized (e.g., Yarkoni 2020, Westfall and Yarkoni).</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75197.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Narrative Clarity</p><p>– The manuscript is very dense, making it hard to follow. Some sections with many</p><p>statistics could be organized into tables. It was sometimes difficult to follow what was done, particularly in the fMRI section. The main paper has several analyses that really seem to be supplementary and are somewhat distracting (e.g., a long section in the main text on ratings of external observers of the stimuli making ratings).</p></disp-quote><p>Following the reviewer’s suggestion, we now moved some of the reported statistical values in tables, rather than in the main text. In particular, we added Table 2 and Table 3. We then introduced more information about the fMRI study already in the main text and moved the rating data obtained when observing shape information alone in Appendix 1 and Appendix 1 – figure 1. For the fMRI section, we now write:</p><p>“Finally, we leveraged existing unpublished fMRI data from our lab to in healthy participants to test whether the spatial gradient observed in the iEEG data resembles the spatial distribution of voxels in the insula correlating with intensity ratings. Twenty-three independent healthy volunteers participated in the fMRI-adapted version of the rating task. As for the iEEG experiment, participants were asked to rate Hand and Face 2 s videos on painfulness. The stimuli depicted the same actor as in the iEEG experiment and were made following the same procedure. To test whether the pattern of BOLD activity in the insula can be used to predict the ratings of the participants, we defined eight separate regressors in each participant, capturing all trials that participants rated with intensity 0-2, 3-4, 5-6 or 7-8, separately for Hand and Face trials (eight in total). […]”.</p><p>For the appendix, we now write:</p><p>“Appendix 1</p><p>How shape information influences participant’s rating</p><p>We collected data from a healthy sample of 40 healthy participants in an online frame rating task to assess whether participants can recognize pain intensity from static frames taken at the key moment of the Face and Hand videos. Appendix 1 – figure 1 shows that the rating of single frames of Faces were even slightly more consistent than the ratings of the entire videos from which they were taken (i.e., <italic>r<sub>S</sub></italic>(frame<sub>i</sub>,AV)&gt;<italic>r<sub>S</sub></italic>(movie<sub>i</sub>,AV), <italic>W</italic>=193, <italic>p<sub>2</sub></italic>=0.003, BF<sub>10</sub>=31.29). In contrast, for Hands, the rating of the frames was poor compared to the rating of the movies (i.e., <italic>r<sub>S</sub></italic>(frame<sub>i</sub>,AV)&lt;<italic>r<sub>S</sub></italic>(movie<sub>i</sub>,AV), <italic>t<sub>(38)</sub></italic>=11.96, <italic>p<sub>2</sub></italic>=2x10<sup>-14</sup>, BF<sub>10</sub>=4x10<sup>11</sup>). Directly comparing the change of performance across the two stimulus types as an interaction in a effector (Hand vs Face) x stimulus (Movie vs Frame) ANOVA revealed a highly significant effect (<italic>F<sub>(1,38)</sub></italic>=178.98, <italic>p</italic>=6x10<sup>-16</sup>, BF<sub>incl</sub>=∞). Finally, because for Hands, the accuracy was low, we also tested if the accuracy was above zero, and it was (<italic>W</italic>=580, <italic>p<sub>2</sub></italic>=0.022, BF<sub>10</sub>=6.19). Hence, for Faces, static shape information was sufficient to explain the rating of the videos, while for Hands, the shape information in the frames we selected was not sufficient. It should be noted that, in principle, information contained in other frames may have contained useful information, but informal reports of some participants confirmed that they paid attention more to kinematic than configurational cues.”</p><disp-quote content-type="editor-comment"><p>Scholarship/Past Work</p><p>– In several places, particularly in the introduction, a small set of overlapping papers are cited that draw heavily on the authors' prior work, but omit some of the most critical other papers – Krishnan et al. 2016 is not cited at all, and Zhou et al. 2020 is mentioned only in passing, though it is the most similar paper in the literature in design and scope. Corradi dell'Acqua's papers are not cited. Most of the fMRI studies cited in the introduction look at the relatively coarse contrast of observed pain versus control, but do not identify signals that encode the intensity of pain within-person. The studies that have done this most directly are Krishnan et al. 2016 and Zhou et al. 2021. Both identify areas within the mid-insula that encode perceived pain.</p></disp-quote><p>We thank the reviewer for this pointer and have edited the introduction to discuss these relevant references more extensively. This section now reads:</p><p>“A number of recent studies have used multivoxel pattern analysis to explore how these regions encode the pain of others using fMRI signals, with particular attention to the insula. Krishnan et al. (2016a) showed participants images of hands or feet in painful or innocuous situations and found a pattern across voxels in the insula that could predict how much pain people reported they would feel in the depicted situations. Corradi-Dell’Acqua et al. (2016) reported that the pattern of insula activity could discriminate between trials in which a cue signaled that someone else was receiving a shock from non-shock trials. Finally, Zhou et al. (2020) reanalysed a dataset in which participants viewed photographs of hands in painful or non painful situations or of painful and neutral facial expressions. They found that in the insula similar but dissociable patterns supported painfulness decoding for hands and faces: similar in that a pattern trained to discriminate painfulness from faces could do so from hands and vice versa, with the rostral insula contributing to both patterns; but dissociable because many voxels only contributed to either faces or hands decoding patterns”.</p><disp-quote content-type="editor-comment"><p>Study Framing</p><p>– The paper is framed in the introduction around comparisons with direct pain experience, but there is no comparison with pain experience here, so this is somewhat misleading. The most relevant prior papers are not discussed.</p></disp-quote><p>We agree that for the study at hand, the overlap with pain experience is not a highly relevant point. We therefore changed the emphasis by including the above-mentioned studies on decoding of perceived pain intensity.</p><disp-quote content-type="editor-comment"><p>Approach</p><p>– Key details about the non-insula recordings are omitted</p><p>A nice feature of the manuscript is the comparison of insular electrodes random electrodes &quot;throughout the brain&quot;, but what electrode locations were available, in how many individuals, and what is their distribution? Surely there are not electrode placements everywhere in the brain. Please clarify.</p></disp-quote><p>We thank the reviewer for motivating us to indicate the location of all the macro electrode contacts in all patients in the current study. We have now generated a glass brain representation of all macro-contacts available in the 7 patients in Figure 2—figure supplement 2, and a pie chart summarizing the locations covered by the macro contacts in Figure 2—figure supplement 3. The complete list of coordinates can also be found at OSF https://osf.io/mcahz/files/osfstorage/62b97b3702d1f3107cf27c39.</p><disp-quote content-type="editor-comment"><p>Approach/Results</p><p>– fMRI study is hard to follow and key details are omitted</p><p>One reviewer noted: Section 2.7 is very difficult to follow. I would very much welcome a careful rewrite of this section.</p><p>Another reviewer wrote that: The concept of the analyses using Neurosynth and fMRI are clever, but the fMRI study in particular is confusing. From the main text it is unclear how many conditions there were in the fMRI study (fMRI during both faces and hands? With ratings?), the sample size, what analyses were done (&quot;leave one subject out&quot; is mentioned but not explained), and whether fMRI activity predicts intensity for either faces or hands. It is stated that &quot;performance did not differ across Hands and Faces&quot;, but not that performance was significant for either or, indeed, what analysis was done.</p></disp-quote><p>We thank the reviewers for flagging that this section was difficult to follow. We edited the section with these comments in mind and, also mentioned the statistics regarding the Hand or Face conditions in the text, rather than only including them in the figure, as was the case in the previous version. This section now reads:</p><p>“Finally, to compare the spatial gradient we find using iEEG with that using fMRI, we leveraged existing data from an unpublished study in our lab using a similar design to measure brain activity using fMRI in healthy participants. Twenty-three independent participants performed an fMRI-adapted version of the rating task. Participants also viewed Hand and Face 2 s videos, presented in different blocks, and were asked to rate them on painfulness. The stimuli depicted the same actor as in the iEEG experiment and were made following the same procedure. To test whether the pattern of BOLD activity in the insula can be used to predict the ratings of the participants, we defined separate regressors in each participants for all trials that participants rates with intensity 0-2, 3-4, 5-6 or 7-8, separately for Hand and Face trials (eight in total). We then performed a partial least-square regression with either two or three components using all voxels in the insula to predict the intensity rating. A leave-one-out cross-validation was used, and the correlation between the predicted and actual rating for each left out participant were compared against zero. This confirmed tht BOLD activity in the insula can be used to predict the perceived intensity for Hands (one sample t-tests for 2 components: <italic>t<sub>(22)</sub></italic>=3.42, <italic>p<sub>1</sub></italic>=0.001, BF<sub>+0</sub>=32.32 and 3 components: <italic>t<sub>(22)</sub></italic>=2.88, <italic>p<sub>1</sub></italic>=0.004, BF<sub>+0</sub>=10.95) and Faces (one sample t-tests for 2 components: <italic>t<sub>(22)</sub></italic>=2.78, <italic>p<sub>1</sub></italic>=0.016, BF<sub>+0</sub>=3.61 and 3 components: <italic>t<sub>(22)</sub></italic>=3.86, <italic>p<sub>1</sub></italic>&lt;0.001, BF<sub>+0</sub>=81.35) (Figure 5c), and performance did not differ across Hands and Faces (paired t-test comparing the leave-one-subject out performance for Hands and Faces, with 2 components, <italic>t<sub>(22)</sub></italic>=0.675, <italic>p<sub>2</sub></italic>=0.5, BF<sub>10</sub>=0.27; 3 components: <italic>t<sub>(22)</sub></italic>=-0.39, <italic>p<sub>2</sub></italic>=0.7, BF<sub>10</sub>=0.23). To compare the spatial pattern of intensity coding across the iEEG and fMRI data, we defined separate regressors for the Hand videos, Face videos, rating-scale and button-presses and used the trial-by-trial ratings given by the participants as parametric modulator, one modulator for the Face and one for the Hand trials, on the respective video regressor. For both Hands and Faces, we found a gradient along the y axis with more anterior locations showing a stronger, and more positive association between BOLD activity and rating (Figure 5d). For Hands, across our 85 bipolar recordings in the patients, locations with higher BBP intensity coding in iEEG also show higher t values in the BOLD signal (Figure 5e). For Faces, on the other hand, we found evidence of absence for an association of the two measures (Figure 5e).”</p><disp-quote content-type="editor-comment"><p>Approach/Results/Discussion</p><p>– Unit recordings. Data from 28 unit recordings were provided as additional evidence of pain-of-other coding. This is a very low number of units across only 3 patients, especially given that the results are based on 13 units that showed higher firing during the pain period compared to the baseline period. These observations should probably be relegated to the supplement. At minimum, the wording related to these findings should be revised to reflect the exploratory nature of these results. For example, I do not believe these results warrant labels such as &quot;hand/face specific&quot;.</p></disp-quote><p>We thank the reviewer for the suggestion. With regard to specificity, we meant the term to reflect that a neuron increases its firing with increasing reported pain intensity for one, but not for the other stimulus set tested, i.e. within our sample of stimuli. To better describe this, we replaced ‘specificity’ throughout the manuscript with ‘preference’, and for the neurons, we now use terms closest to the data, namely Hand-but-not-Face, Face-but-not-Hand or Face-and-Hand to simply reflect the statistics we conducted. Given that <italic>ELife</italic> does not make use of supplementary material sections, moving this data to the supplementary materials is not an option. We hope that in the context of some other papers also reporting small numbers of neurons in humans (e.g. https://www.sciencedirect.com/science/article/pii/S1053811920309848 reporting 14 responsive neurons) readers will still find these neurons a source of information about the response properties of the insula. In the discussion we now specify that the number is small:</p><p>“Furthermore, we isolate a small number of insular neurons increasing their firing with increases in the intensity of pain experienced by others”</p><disp-quote content-type="editor-comment"><p>– Faces vs. hands effects. There do not seem to be significant brain correlations within faces alone that survive correction for multiple comparisons. Figure 3 shows a &quot;trend&quot;-level result, not significant. Could this indicate a &quot;hand vs. face&quot; effect that appears as a correlation in Figure 2? If hands are rated higher than faces, and hands produce greater BBP in the insula, then any electrode that responds to hands more than faces will show up as a correlation between brain and rated intensity. The way to test this would be to test and show correlations within hands and faces separately, but these were apparently not significant for faces. At minimum, the authors need to frankly address this concern in the Discussion</p></disp-quote><p>We apologize for confusing the reader with the time-frequency analysis separately for Hand and Face. The main reason we turn to iEEG is to exploit the broadband signal that is closest to neural spiking and inaccessible to conventional EEG. The broadband signal, unlike oscillations, is best analyzed by integrating power over its frequency range. After identifying the relevant BBP range in Figure 2a, which was done including all stimuli not to bias this range towards Hands or Faces (see Kriegeskorte et al., Nature Neuroscience 12 (2009): 535–40), all our statistical inferences in the paper are based on that overall power in that range (20-190Hz) as the proxy of neural activity. Importantly, within that BBP signal, there is significant coding of intensity for Hands and for Faces, after correcting for multiple comparisons in the temporal domain.</p><p>The time-frequency decompositions separated for Hand and Face were only meant to illustrate the data that went into the BBP analysis. This time-frequency decomposition is however not ideal to compare conditions, because it inappropriately considers each frequency of the BBP individually, as if these signals were independent, which leads to excessive correction for multiple comparisons and is thus less powered than our preferred BBP analysis that takes the broadband nature of this signal into account. Indeed, in the version of the manuscript we originally submitted, the time-frequency decomposition were in the supplementary materials, not in the main text (see Figure 2 in https://www.biorxiv.org/content/10.1101/2021.06.23.449371v2.full for the original submission). However, the <italic>eLife</italic> editorial team informed us that <italic>eLife</italic> does not support supplementary materials and asked us to include all data into the main manuscript. Accordingly the version seen by the reviewers showed these time-frequency decompositions prominently in Figure 3, and, because it takes much more space to present frequency resolved data than overall BBP data, these illustrations became so large, that they overshadowed the main analysis shown in subpanels 3g,h.</p><p>We therefore now moved these time-frequency decompositions into Figure 2—figure supplement 1, without inferential statistics, to focus the manuscript again onto our actual measure of interest, the overall BBP.</p><p>Critically, our main analysis (now Figure 2g,h), shows that both for the Hand and for the Face stimuli, there is significant intensity coding, with the relevant inferential statistics. This also addresses the question of whether the correlation observed in Hand and Face could be due to differences between Hand vs Faces, as we see significant intensity coding separately for Hand and for Face stimuli.</p><p>To acknowledge the comparatively weaker, although significant, intensity coding amongst our Face stimuli, in the discussion we also write:</p><p>“Overall, our ability to decode perceived intensity from our Face stimuli was also lower than that from the Hand stimuli”.</p><disp-quote content-type="editor-comment"><p>– Faces vs. hands effects. A main point of Figure 3 is that correlations with intensity ratings occur later for faces than hands. But the face signals are not really significant, which makes this kind of conclusion difficult, and there don't seem to be any inferential statistics on the timing of the effect. So it's unclear the timing difference is a real effect. Even though this is &quot;purely explorative&quot; it seems hard to justify an entire main figure and section of the text.</p></disp-quote><p>As mentioned in the previous comment, all our inferences are based on the BBP, which do show significant intensity coding for both Hands and Faces. The time-frequency decomposition, that was meant only to be illustrative of the raw data that flows into the BBP calculation, led the attention of the readers astray. We have now moved the time-frequency decompositions to the Figure 2—figure supplement 1 to focus the attention on the BBP analysis that does clearly show significant effects for both stimulus types.</p><disp-quote content-type="editor-comment"><p>– Faces, hands, and bayes. The facial results appear to hinge on &quot;trend-level&quot; results in several places, and in part on an analysis of lack of differences between faces and hands. It's less desirable to make inferences about the lack of an interaction (a null effect; Figure 3). This is used to argue that there's &quot;no difference between hand and face in the late period&quot;. Another interpretation is that there's simply no correlation with intensity for faces. There is some evidence for an effect, but the study perhaps doesn't have enough power to tell for sure. It is helpful that Bayes Factors are reported, but what threshold do the authors think is required to demonstrate evidence for the null in the presence of these multiple tests? (And what is BFincl as opposed to BF10?)</p></disp-quote><p>We thank the reviewer for this comment that raises several points we will address separately:</p><p>a) As mentioned in the two previous points, our inferences are based on the BBP analyses that do show significant effects separately for hand and face, and we have now moved the distracting time-frequency decompositions – that are indeed underpowered, and also at odds with the very concept of a broadband signal – back into a figure supplement, as it was in the original submission before we were asked to include them into the main manuscript by the editorial team.</p><p>b) Power considerations: Because our statistical inferences focus on the overall BBP in two time windows, and we have 60 trials per stimulus, we do have the power to detect modest correlations (a power-analysis reveals that with 60 trials, at α=0.05 and β=0.8, we can detect rho&gt;=0.3 in at least 80% of cases).</p><p>c) Evidence for the null: The trial numbers that afford us the power to detect a correlation also afford us the power to provide evidence for the null in a Bayesian framework using the conventional threshold of BF10&lt;⅓, as recommended by Jeffreys 1961. Of course, such a Bayes factor is only relative evidence that the data is 3 times more likely under H0 than H1. In the particular case of the 2 stimuli (Hand vs Face) x 4 ratings Anova, the conclusion that intensity coding was similar for hands and faces is based on BFincl=0.034, showing that the data is 29 times more likely under the hypothesis that the BBP-Rating relation is the same for Hand and Face than under the hypothesis that the relation is different.</p><p>d) BFincl: We follow the nomenclature used in JASP and in Rouder et al., 2016, that use BFincl for factorial ANOVA analyses that compare the likelihood of the data in all models including a particular factor (or interaction) against the likelihood of the data in models without that factor (or interaction). This has now been added to the Material and Methods section where we now write:</p><p>“When performing Bayesian ANOVAs, we report BFincl which is the likelihood of models including a particular factor (or interaction of factors) divided by the likelihood of models excluding that particular factor (or interaction), as recommended by Rouder and co-workers and implemented in JASP (Rouder et al., 2017, 2016, 2012).”</p><disp-quote content-type="editor-comment"><p>Discussion</p><p>– Frank and complete discussion of latencies. The authors report timing effects in the range of 40-320 ms. They cite the well-known study by Krolak-Salmon and colleagues. But it is difficult to know what to make of the current results. On the one hand, latencies on the range of 200-300 ms (across the brain) would be compatible with some studies (but not others). How does one interpret latencies as low as 40-60 ms in the insula, which presumably are not really feasible? On the other hand, the results in the 560-1000 ms range are consistent with many studies but are discussed as &quot;too slow&quot;. Authors need to discuss the likely source of these latencies.</p></disp-quote><p>We thank the reviewer for encouraging a more extensive discussion of latencies. We tried to identify a wider range of publications that examined latencies in the insula to complex sensory stimuli, and moved the discussion of latencies more towards the Discussion section. Examining the papers we found, we agree that latencies below 100ms are rare (but see Chen et al., 2009 for a 40ms report), with latencies around 150ms more frequent. We also found that although responses sometimes *last* beyond 500ms, we did not find studies that report responses to *start* with latencies above 560ms for visual stimuli – but if the reviewer knows of such examples, that would be valuable to us. Our search therefore continues to reinforce the notion that motion driven responses starting 560ms after the motion signal are not particularly in line with the existing literature. In the Discussion section we therefore now write:</p><p>“Leveraging our high temporal and spatial resolution, we found that locations that showed intensity-coding for the Hand stimuli have activity timing echoing the timing of pain-related motion cues, albeit with somewhat unusually relatively short latencies &lt;100 ms, and that the association of motion energy and broadband activity is mediated by the perceived intensity. Such short latencies are below what is typically reported for the onset latency to sensory stimuli in the insula, with most studies showing latencies above 80ms for most sensory stimuli (Bastuji et al., 2018, 2016; Chen et al., 2009; Cornwell et al., 2008; Krolak-Salmon et al., 2003; Liberati et al., 2020, 2016). A particularity of our movie stimuli, however, is that seeing the belt descend upon the hand provides the brain with the kind of temporal context that is known to trigger predictive processes that reduce the response latency of neurons substantially compared to stimuli presented in isolation (Perrett et al., 2009; Reddy et al., 2015). Such predictions could help explain the short latencies we observe here. Locations that show intensity coding for the Face appear to have activity echoing the timing of shape information with latencies in the 40-320 ms range. These latencies are in a range similar to those found in other studies using facial expressions in the insula (Chen et al., 2009; Cornwell et al., 2008; Krolak-Salmon et al., 2003; Meeren et al., 2013). following nociceptive stimulation (Liberati et al., 2020) or static disgusted facial expressions (Chen et al., 2009; Krolak-Salmon et al., 2003). Using automated software to detect the level of activation of the facial action units 4 and 7 (i.e., lowering the eye-brows and tightening the eye-lids), we found that this action unit information suffices to predict participants’ rating of the stimuli with high accuracy, and followed the time course of the neural activity in the Face intensity encoding locations well enough to suggest that it provides traction on the analyses of dynamic pain-related facial expressions. The long neuronal lags we revealed for the facial motion information on the other hand, with the earliest significant associations occurring 560ms after the motion information, are unusually long for the start of responses to sensory stimuli in the insula, as the onset latency for visual, auditory, tactile or nociceptive responses are usually well below 560ms (Bastuji et al., 2018, 2016; Chen et al., 2009; Cornwell et al., 2008; Krolak-Salmon et al., 2003; Liberati et al., 2020, 2016) – although insular activity can persist into such longer intervals (Meeren et al., 2013; Taniguchi et al., 2022). Together this suggests that shape information is more likely than motion information to be the primary driver of the intensity-coding to our facial stimuli”.</p><p>We hope that this answers the reviewer’s request.</p><disp-quote content-type="editor-comment"><p>Discussion/Abstract</p><p>– Experimental approach does not warrant strong claims of specificity.</p><p>A Reviewer noted that: A question that one could raise – especially for the hand condition – is whether part of the trial-by-trial correlation between insular activity and ratings was the consequence of a relationship between that activity and low-level motion/shape features of the video clips, rather than a reflection of the insula being involved in &quot;intensity coding for the pain of others&quot;. Fortunately, this question was at least partly addresses with the available data, by showing that the recorded insular activity correlated with motion energy when the motion was associated with pain (during the slapping of the belt), but not while the motion was innocuous (during the initial lifting of the belt). Nevertheless, as mentioned by the authors themselves, future experiments using additional control stimuli such as stimuli matched in terms of motion content but differing in the emotions they convey are critical to better understand the specificity of the described insular responses.</p><p>S/he also noted that: The observation that insular activity correlated with motion energy when motion was associated with pain, and not during the initial lifting of the belt is indeed an indication that the insular responses cannot be reduced to motion detection. However, in these video clips, the first second showed the belt lifting without any movements of the hand. Then, when the belt came down to hit the hand, this was followed by a reaction/movement of the hand. Therefore, one may wonder whether part of the recorded activity could be related to the specific observation of body movement. This might also relate to the observation that stronger insular activity was observed in the hand condition as compared to the face condition.</p></disp-quote><p>We fully agree with the reviewer and now write:</p><p>“Future experiments using a wider gamut of control stimuli, that are matched in motion but differ in emotions will be critical to address the specificity of the responses we describe, and hence, what state they could reliably signal (Zaki et al., 2016). For the Hand stimuli, this could include seeing hands experience a range of different salient affective experiences, such as a hand being hurt, being caressed and being rejected in addition to a neutral hand-shake (Meffert et al., 2013), or the actor in our Hand movies could have been asked to reposition their hand after each slap.”</p><disp-quote content-type="editor-comment"><p>A different Reviewer noted that: The study makes use of a fantastic stimulus set from the research group. But if I understand the set correctly, the same actor is used for different levels of pain (face– and hand-based). While this is an excellent set to study some aspects of coding related to stimulus &quot;preference&quot; I don't believe it's general enough to establish &quot;selectivity&quot;. Accordingly, I think it would be more reasonable to avoid the claims of &quot;selectivity&quot;.</p></disp-quote><p>We agree with the reviewer that using only two stimulus types, we can only conclude stimulus-preference for one of the stimulus types over the other, but not stimulus-selectivity in the general sense. We have now replaced all the occurrences of “selectivity” or “specificity” throughout the text to “preference”. The terms “Hand-selective coding” and “Face-selective coding” are also now replaced with “Hand-but-not-Face coding” and “Face-but-not-Hand coding”.</p><disp-quote content-type="editor-comment"><p>A third Reviewer wrote that: Notably, the authors do not intend to interpret the generalizability to direct pain experience or other affective states, or specificity to pain compared with other affective conditions; but without more information about these, it is difficult to tell what the signals in the insula actually represent. It leaves open the possibility that there is another, better explanation for activation of insular neurons than perceived pain. e.g., It could be about representation of the body more generally, rather than perceived pain specifically. Could they be coding for choices (ratings) themselves? Baliki found that insular activity correlates with rating intensity of a simple visual stimulus, and other studies (e.g., Grinband et al., Neuron) have found that the insula correlates with simple perceptual magnitude decisions. This will be an ongoing project for future work.</p></disp-quote><p>We agree with the reviewer and now write:</p><p>“An important consideration is whether preference for Face or Hand stimuli in specific locations could simply originate from some participants finding our facial stimuli more salient, and others the hand stimuli, particularly, given that our patients rated the Hand stimuli with slightly higher pain intensity than our Face stimuli. That we find Face and Hand preference side-by-side in simultaneously recorded locations and neurons in single patients suggests that this cannot suffice to explain our data. This is because if a patient were to find Hand stimuli more salient than Face stimuli, and the insula simply codes saliency, we would expect to find Hand-but-not-Face intensity coding in that patient’s insula, but we wouldn’t expect to find side by side locations with Hand-but-not-Face and Face-but-not-Hand coding. This also makes it unlikely that broadband activity simply reflects categorization uncertainty (Grinband et al., 2006). Indeed, it would be uneconomical for all insular neurons to redundantly encode the same exact signal of salience or categorization uncertainty.”</p><disp-quote content-type="editor-comment"><p>S/he noted that: The stimulus set chosen was limited, and appears to relate to one specific type of painful stimulus on one hand model, and one set of facial expressions made by one female model. As it's well known in general that neurons often have complex receptive fields, it's unclear whether other types of painful hand stimuli or facial expressions made by other models would yield similar findings. Perhaps the insula would respond more strongly to other faces – or perhaps not at all. Other studies have shown that women's pain is discounted (Zhang et al. 2021). The need for diverse sets of stimuli to establish relationships with brain activity that are not stimulus-specific is becoming increasingly recognized (e.g., Yarkoni 2020, Westfall and Yarkoni).</p></disp-quote><p>We agree, and now added in the discussion:</p><p>“In general, using multiple actors and painful hand interaction could help characterize how intensity coding in the insula is influenced by details of the stimuli that convey it, including the identity and gender of the actor, and how well our results generalize to other stimulus sets (Yarkoni, 2020)”.</p></body></sub-article></article>