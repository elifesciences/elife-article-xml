<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">53151</article-id><article-id pub-id-type="doi">10.7554/eLife.53151</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Network dynamics underlying OFF responses in the auditory cortex</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-166978"><name><surname>Bondanelli</surname><given-names>Giulio</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6781-4939</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-142925"><name><surname>Deneux</surname><given-names>Thomas</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9330-7655</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-141232"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9211-1960</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-38981"><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7473-1223</contrib-id><email>srdjan.ostojic@ens.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Laboratoire de Neurosciences Cognitives et Computationelles, Département d’études cognitives, ENS, PSL University, INSERM</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Neural Computation Laboratory, Center for Human Technologies, Istituto Italiano di Tecnologia (IIT)</institution><addr-line><named-content content-type="city">Genoa</named-content></addr-line><country>Italy</country></aff><aff id="aff3"><label>3</label><institution>Départment de Neurosciences Intégratives et Computationelles (ICN), Institut des Neurosciences Paris-Saclay (NeuroPSI), UMR 9197 CNRS, Université Paris Sud</institution><addr-line><named-content content-type="city">Gif-sur-Yvette</named-content></addr-line><country>France</country></aff><aff id="aff4"><label>4</label><institution>Institut Pasteur, INSERM, Institut de l’Audition</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Shinn-Cunningham</surname><given-names>Barbara G</given-names></name><role>Senior Editor</role><aff><institution>Carnegie Mellon University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>24</day><month>03</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e53151</elocation-id><history><date date-type="received" iso-8601-date="2019-10-30"><day>30</day><month>10</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2021-03-19"><day>19</day><month>03</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Bondanelli et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Bondanelli et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-53151-v2.pdf"/><abstract><p>Across sensory systems, complex spatio-temporal patterns of neural activity arise following the onset (ON) and offset (OFF) of stimuli. While ON responses have been widely studied, the mechanisms generating OFF responses in cortical areas have so far not been fully elucidated. We examine here the hypothesis that OFF responses are single-cell signatures of recurrent interactions at the network level. To test this hypothesis, we performed population analyses of two-photon calcium recordings in the auditory cortex of awake mice listening to auditory stimuli, and compared them to linear single-cell and network models. While the single-cell model explained some prominent features of the data, it could not capture the structure across stimuli and trials. In contrast, the network model accounted for the low-dimensional organization of population responses and their global structure across stimuli, where distinct stimuli activated mostly orthogonal dimensions in the neural state-space.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural networks</kwd><kwd>computational neuroscience</kwd><kwd>auditory cortex</kwd><kwd>calcium imaging</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-16-CE37-0016</award-id><principal-award-recipient><name><surname>Bondanelli</surname><given-names>Giulio</given-names></name><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id><institution>Agence Nationale de la Recherche</institution></institution-wrap></funding-source><award-id>ANR-17-EURE-0017</award-id><principal-award-recipient><name><surname>Bondanelli</surname><given-names>Giulio</given-names></name><name><surname>Ostojic</surname><given-names>Srdjan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Computational modeling demonstrates that population dynamics of neural calcium activity following stimulus offset are consistent with a network mechanism based on recurrent interactions.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Neural responses within the sensory cortices are inherently transient. In the auditory cortex (AC) even the simplest stimulus, for instance a pure tone, evokes neural responses that strongly vary in time following the onset and offset of the stimulus. A number of past studies have reported a prevalence of ON- compared to OFF-responsive neurons in different auditory areas (<xref ref-type="bibr" rid="bib77">Phillips et al., 2002</xref>; <xref ref-type="bibr" rid="bib63">Luo et al., 2008</xref>; <xref ref-type="bibr" rid="bib29">Fu et al., 2010</xref>; <xref ref-type="bibr" rid="bib79">Pollak and Bodenhamer, 1981</xref>). As a result, the transient onset component has been long considered the dominant feature of auditory responses and has been extensively studied across the auditory pathway (<xref ref-type="bibr" rid="bib62">Liu et al., 2019b</xref>; <xref ref-type="bibr" rid="bib55">Kuwada and Batra, 1999</xref>; <xref ref-type="bibr" rid="bib33">Grothe et al., 1992</xref>; <xref ref-type="bibr" rid="bib34">Guo and Burkard, 2002</xref>; <xref ref-type="bibr" rid="bib109">Yu et al., 2004</xref>; <xref ref-type="bibr" rid="bib40">Heil, 1997a</xref>; <xref ref-type="bibr" rid="bib41">Heil, 1997b</xref>), with respect to its neurophysiological basis and perceptual meaning (<xref ref-type="bibr" rid="bib77">Phillips et al., 2002</xref>). In parallel, due to less evidence of OFF-responsive neurons in anaesthetized animals, OFF cortical responses have received comparably less attention. Yet, OFF responses have been observed in awake animals throughout the auditory pathway, and in the mouse AC they arise in 30–70% of the responsive neurons (<xref ref-type="bibr" rid="bib88">Scholl et al., 2010</xref>; <xref ref-type="bibr" rid="bib51">Keller et al., 2018</xref>; <xref ref-type="bibr" rid="bib49">Joachimsthaler et al., 2014</xref>; <xref ref-type="bibr" rid="bib61">Liu et al., 2019a</xref>; <xref ref-type="bibr" rid="bib94">Sollini et al., 2018</xref>).</p><p>While the generation of ON responses has been attributed to neural mechanisms based on short-term adaptation, most likely inherited from the auditory nerve fibers (<xref ref-type="bibr" rid="bib77">Phillips et al., 2002</xref>; <xref ref-type="bibr" rid="bib92">Smith and Brachman, 1980</xref>; <xref ref-type="bibr" rid="bib93">Smith and Brachman, 1982</xref>), the mechanisms that generate OFF responses are more diverse and seem to be area-specific (<xref ref-type="bibr" rid="bib108">Xu et al., 2014</xref>; <xref ref-type="bibr" rid="bib54">Kopp-Scheinpflug et al., 2018</xref>). In subcortical regions, neurons in the dorsal cochlear nucleus and in the superior paraolivary nucleus of the brainstem nuclei may generate OFF responses by post-inhibitory rebound, a synaptic mechanism in which a neuron emits one or more spikes following the cessation of a prolonged hyperpolarizing current (<xref ref-type="bibr" rid="bib98">Suga, 1964</xref>; <xref ref-type="bibr" rid="bib35">Hancock and Voigt, 1999</xref>; <xref ref-type="bibr" rid="bib53">Kopp-Scheinpflug et al., 2011</xref>). In the midbrain inferior colliculus and in the medial geniculate body of the thalamus, OFF responses appear to be mediated by excitatory inputs from upstream areas and potentially boosted by a post-inhibitory facilitation mechanism (<xref ref-type="bibr" rid="bib50">Kasai et al., 2012</xref>; <xref ref-type="bibr" rid="bib102">Vater et al., 1992</xref>; <xref ref-type="bibr" rid="bib109">Yu et al., 2004</xref>; <xref ref-type="bibr" rid="bib39">He, 2003</xref>). Unlike in subcortical areas, OFF responses in AC do not appear to be driven by hyperpolarizing inputs during the presentation of the stimulus, since synaptic inhibition has been found to be only transient with respect to the stimulus duration (<xref ref-type="bibr" rid="bib80">Qin et al., 2007</xref>; <xref ref-type="bibr" rid="bib88">Scholl et al., 2010</xref>). The precise cellular or network mechanisms underlying transient OFF responses in cortical areas therefore remain to be fully elucidated.</p><p>Previous studies investigating the transient responses in the auditory system mostly adopted a single-neuron perspective (<xref ref-type="bibr" rid="bib44">Henry, 1985</xref>; <xref ref-type="bibr" rid="bib88">Scholl et al., 2010</xref>; <xref ref-type="bibr" rid="bib80">Qin et al., 2007</xref>; <xref ref-type="bibr" rid="bib38">He, 2002</xref>; <xref ref-type="bibr" rid="bib104">Wang et al., 2005</xref>; <xref ref-type="bibr" rid="bib105">Wang, 2007</xref>). However, in recent years, population approaches to neural data have proven valuable for understanding the role of transients dynamics in various cortical areas (<xref ref-type="bibr" rid="bib15">Buonomano and Maass, 2009</xref>; <xref ref-type="bibr" rid="bib81">Remington et al., 2018</xref>; <xref ref-type="bibr" rid="bib87">Saxena and Cunningham, 2019</xref>). Work in the olfactory system has shown that ON and OFF responses encode the stimulus identity in the dynamical patterns of activity across the neural population (<xref ref-type="bibr" rid="bib66">Mazor and Laurent, 2005</xref>; <xref ref-type="bibr" rid="bib95">Stopfer et al., 2003</xref>; <xref ref-type="bibr" rid="bib14">Broome et al., 2006</xref>; <xref ref-type="bibr" rid="bib28">Friedrich and Laurent, 2001</xref>; <xref ref-type="bibr" rid="bib84">Saha et al., 2017</xref>). In motor and premotor cortex, transient responses during movement execution form complex population trajectories (<xref ref-type="bibr" rid="bib20">Churchland and Shenoy, 2007</xref>; <xref ref-type="bibr" rid="bib18">Churchland et al., 2010</xref>) that have been hypothesized to be generated by a mechanism based on recurrent network dynamics (<xref ref-type="bibr" rid="bib91">Shenoy et al., 2011</xref>; <xref ref-type="bibr" rid="bib43">Hennequin et al., 2014</xref>; <xref ref-type="bibr" rid="bib99">Sussillo et al., 2015</xref>; <xref ref-type="bibr" rid="bib97">Stroud et al., 2018</xref>). In the AC, previous works have suggested a central role of the neural dynamics across large populations for the coding of different auditory features (<xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>; <xref ref-type="bibr" rid="bib84">Saha et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Lim et al., 2016</xref>), yet how these dynamics are generated remains an open question.</p><p>Leveraging the observation that the AC constitutes a network of neurons connected in a recurrent fashion (<xref ref-type="bibr" rid="bib60">Linden and Schreiner, 2003</xref>; <xref ref-type="bibr" rid="bib75">Oswald and Reyes, 2008</xref>; <xref ref-type="bibr" rid="bib74">Oswald et al., 2009</xref>; <xref ref-type="bibr" rid="bib5">Barbour and Callaway, 2008</xref>; <xref ref-type="bibr" rid="bib9">Bizley et al., 2015</xref>), in this study we test the hypothesis that transient OFF responses are generated by a recurrent network mechanism broadly analogous to the motor cortex (<xref ref-type="bibr" rid="bib17">Churchland et al., 2006</xref>; <xref ref-type="bibr" rid="bib43">Hennequin et al., 2014</xref>). We first analyzed OFF responses evoked by multiple auditory stimuli in large neural populations recorded using calcium imaging in the mouse AC (<xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>). These analyses identified three prominent features of the auditory cortical data: (i) OFF responses correspond to transiently amplified trajectories of population activity; (ii) for each stimulus, the corresponding trajectory explores a low-dimensional subspace; and (iii) responses to different stimuli lie mostly in orthogonal subspaces. We then determined to what extent these features can be accounted for by a linear single-cell or network model. We show that the single-cell model can reproduce the first two features of population dynamics in response to individual stimuli, but cannot capture the structure across stimuli and single trials. In contrast, the network model accounts for all three features. Identifying the mechanisms responsible for these features led to additional predictions that we verified on the data.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>ON/OFF responses in AC reflect transiently amplified population dynamics</title><p>We analyzed the population responses of 2343 cells from the AC of three awake mice recorded using calcium imaging techniques (data from <xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>). The neurons were recorded while the mice passively listened to randomized presentations of different auditory stimuli. In this study we consider a total of 16 stimuli, consisting of two groups of intensity modulated UP- or DOWN-ramping sounds. In each group, there were stimuli with different frequency content (either 8 kHz pure tones or white noise [WN] sounds), different durations (1 or 2 s) and different intensity slopes (either 50–85 dB or 60–85 dB and reversed, see <xref ref-type="table" rid="table1">Table 1</xref> and Materials and methods, Section 'The data set').</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Stimuli set.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Stimulus</th><th>Direction</th><th>Frequency</th><th>Duration (s)</th><th>Modulation (dB)</th></tr></thead><tbody><tr><td>1</td><td>UP</td><td>8 kHz</td><td>1 s</td><td>50–85</td></tr><tr><td>2</td><td>UP</td><td>8 kHz</td><td>1 s</td><td>60–85</td></tr><tr><td>3</td><td>UP</td><td>8 kHz</td><td>2 s</td><td>50–85</td></tr><tr><td>4</td><td>UP</td><td>8 kHz</td><td>2 s</td><td>60–85</td></tr><tr><td>5</td><td>UP</td><td>WN</td><td>1 s</td><td>50–85</td></tr><tr><td>6</td><td>UP</td><td>WN</td><td>1 s</td><td>60–85</td></tr><tr><td>7</td><td>UP</td><td>WN</td><td>2 s</td><td>50–85</td></tr><tr><td>8</td><td>UP</td><td>WN</td><td>2 s</td><td>60–85</td></tr><tr><td>9</td><td>DOWN</td><td>8 kHz</td><td>1 s</td><td>85–50</td></tr><tr><td>10</td><td>DOWN</td><td>8 kHz</td><td>1 s</td><td>85–60</td></tr><tr><td>11</td><td>DOWN</td><td>8 kHz</td><td>2 s</td><td>85–50</td></tr><tr><td>12</td><td>DOWN</td><td>8 kHz</td><td>2 s</td><td>85–60</td></tr><tr><td>13</td><td>DOWN</td><td>WN</td><td>1 s</td><td>85–50</td></tr><tr><td>14</td><td>DOWN</td><td>WN</td><td>1 s</td><td>85–60</td></tr><tr><td>15</td><td>DOWN</td><td>WN</td><td>2 s</td><td>85–50</td></tr><tr><td>16</td><td>DOWN</td><td>WN</td><td>2 s</td><td>85–60</td></tr></tbody></table></table-wrap><p>We first illustrate the responses of single cells to the presentation of different auditory stimuli, focusing on the periods following the onset and offset of the stimulus. The activity of individual neurons to different stimuli was highly heterogeneous. In response to a single stimulus, we found individual neurons that were strongly active only during the onset of the stimulus (ON responses), or only during the offset (OFF responses), while other neurons in the population responded to both stimulus onset and offset, consistent with previous analyses (<xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>). Importantly, across stimuli some neurons in the population exhibited ON and/or OFF responses only when specific stimuli were presented, showing stimulus-selectivity of transient responses, while others strongly responded at the onset and/or at the offset of multiple stimuli (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Strong transient ON and OFF responses in auditory cortex of mice passively listening to different sounds.</title><p>(<bold>A</bold>) <italic>Top</italic>: deconvolved calcium signals averaged over 20 trials showing the activity (estimated firing rate) of 20 out of 2343 neurons in response to a 8 kHz 1 s UP-ramp with intensity range 60–85 dB. We selected neurons with high signal-to-noise ratios (ratio between the peak activity during ON/OFF responses and the standard deviation of the activity before stimulus presentation). Neurons were ordered according to the difference between peak activity during ON and OFF response epochs. <italic>Bottom</italic>: activity of the same neurons as in the top panel in response to a white noise (WN) sound with the same duration and intensity profile. In all panels dashed lines indicate onset and offset of the stimulus, and green solid lines show the temporal region where OFF responses were analyzed (from 50 ms before stimulus offset to 300 ms after stimulus offset). (<bold>B</bold>) <italic>Left</italic>: cartoon showing the OFF response to one stimulus as a neural trajectory in the state space, where each coordinate represents the firing rate of one neuron (with respect to the baseline B). The length of the dashed line represents the distance between the population activity vector and its baseline firing rate, that is, <inline-formula><mml:math id="inf1"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula>. <italic>Right</italic>: the red trace shows the distance from baseline <inline-formula><mml:math id="inf2"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula> computed for the population response to the 8 kHz sound in <bold>A</bold>. The gray trace shows the distance from baseline averaged over the 8 kHz sounds of 1 s duration (four stimuli). The gray shading represents ±1 standard deviation. The dashed horizontal line shows the average level of the distance <inline-formula><mml:math id="inf3"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula> before stimulus presentation (even if baseline-subtracted responses were used, a value of the norm different from zero is expected because of noise in the spontaneous activity before stimulus onset). (<bold>C</bold>) Accuracy of stimulus classification between a 8 kHz versus WN UP-ramping sounds over time based on single trials (20 trials). The decoder is computed at each time step (spaced by ∼50 ms) and accuracy is computed using leave-one-out cross-validation. Orange trace: average classification accuracy over the cross-validation folds. Orange shaded area corresponds to ±1 standard error. The same process is repeated after shuffling stimulus labels across trials at each time step (chance level). Chance level is represented by the gray trace and shading, corresponding to its average and ±1 std computed over time. The red markers on the top indicate the time points where the average classification accuracy is lower than the average accuracy during the ON transient response (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>, two-tailed t-test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig1-v2.tif"/></fig><p>Because of the intrinsic heterogeneity of single-cell responses, we examined the structure of the transient ON and OFF responses to different stimuli using a population approach (<xref ref-type="bibr" rid="bib15">Buonomano and Maass, 2009</xref>; <xref ref-type="bibr" rid="bib87">Saxena and Cunningham, 2019</xref>). The temporal dynamics of the collective response of all the neurons in the population can be represented as a sequence of states in a high-dimensional state space, in which the <italic>i</italic>-th coordinate corresponds to the (baseline-subtracted) firing activity <inline-formula><mml:math id="inf5"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the <italic>i</italic>-th neuron in the population. At each time point, the population response is described by a population activity vector <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> which draws a <italic>neural trajectory</italic> in the state space (<xref ref-type="fig" rid="fig1">Figure 1B</xref> <italic>left panel</italic>).</p><p>To quantify the strength of the population transient ON and OFF responses, we computed the distance of the population activity vector from its baseline firing level (average firing rate before stimulus presentation), corresponding to the norm of the population activity vector <inline-formula><mml:math id="inf7"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib66">Mazor and Laurent, 2005</xref>). This revealed that the distance from baseline computed during ON and OFF responses was larger than the distance computed for the state at the end of stimulus presentation (<xref ref-type="fig" rid="fig1">Figure 1B</xref> <italic>right panel</italic>). We refer to this feature of the population transient dynamics as the transient amplification of ON and OFF responses.</p><p>To examine what the transient amplification of ON and OFF responses implies in terms of stimulus decoding, we trained a simple decoder to classify pairs of stimuli that differed in their frequency content, but had the same intensity modulation and duration. We found that the classification accuracy was highest during the transient phases corresponding to ON and OFF responses, while it decreased at the end of stimulus presentation (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). This result revealed a robust encoding of the stimulus features during ON and OFF responses, as previously found in the locust olfactory system (<xref ref-type="bibr" rid="bib66">Mazor and Laurent, 2005</xref>; <xref ref-type="bibr" rid="bib84">Saha et al., 2017</xref>).</p></sec><sec id="s2-2"><title>OFF responses rely on orthogonal low-dimensional subspaces</title><p>To further explore the structure of the neural trajectories associated with the population OFF responses to different stimuli, we analyzed neural activity using dimensionality reduction techniques (<xref ref-type="bibr" rid="bib21">Cunningham and Yu, 2014</xref>). We focused specifically on responses within the period starting 50 ms before stimulus offset to 300 ms after stimulus offset.</p><p>By performing principal component analysis (PCA) independently for the responses to individual stimuli, we found that the dynamics during the transient OFF responses to individual stimuli explored only about five dimensions, as 80% of the variance of the OFF responses to individual stimuli was explained on average by the first five principal components (<xref ref-type="fig" rid="fig2">Figure 2A</xref>; see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for cross-validated controls; note that, given the temporal resolution, the maximal dimensionality explaining 80% of the variance of the responses to individual stimuli was 9). The projection of the low-dimensional OFF responses to each stimulus onto the first two principal components revealed circular activity patterns, where the population vector smoothly rotated between the two dominant dimensions (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Low-dimensional structure of population OFF responses.</title><p>(<bold>A</bold>) Cumulative variance explained for OFF responses to individual stimuli, as a function of the number of principal components. The blue trace shows the cumulative variance averaged across all 16 stimuli. Error bars are smaller than the symbol size. The triangular marker indicates the number of PCs explaining 80% (red line) of the total response variance for individual stimuli. (<bold>B</bold>) <italic>Left</italic>: projection of the population OFF response to the 8 kHz and white noise (WN) sounds on the first two principal components computed for the OFF response to the 8 kHz sound. <italic>Right</italic>: projection of both responses onto the first two principal components computed for the OFF response to the WN sound. PCA was performed on the period from −50 ms to 300 ms with respect to stimulus offset. We plot the response from 50 ms before stimulus offset to the end of the trial duration. (<bold>C</bold>) Cumulative variance explained for the OFF responses to all 16 stimuli together as a function of the number of principal components. The triangular marker indicates the number of PCs explaining 80% of the total response variance for all stimuli. (<bold>D</bold>) Overlap between the subspaces defined by the first five principal components of the OFF responses corresponding to pairs of stimuli. The overlap is measured by the cosine of the principal angle between these subspaces (see Materials and methods, Section 'Correlations between OFF response subspaces'). (<bold>E</bold>) <italic>Left</italic>: correlation matrix between the initial population activity states <inline-formula><mml:math id="inf8"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> at the end of stimulus presentation (50 ms before offset) for each pair of stimuli. <italic>Right</italic>: linear correlation between subspace overlaps (<bold>D</bold>) and the overlap between initial states <inline-formula><mml:math id="inf9"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> (<bold>E</bold> <italic>left panel</italic>) for each stimulus pair. The component of the dynamics along the corresponding initial states was subtracted before computing the subspace overlaps.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Controls for PCA of OFF responses to individual stimuli and across stimuli.</title><p>(<bold>A</bold>) Solid blue trace: cumulative variance explained for population OFF responses to individual stimuli evaluated using PCA on raw calcium traces (13 data points). Gray trace: cumulative variance explained after shuffling cell indices independently at each time step to remove temporal correlations between time points. Responses where the temporal correlations have been removed exhibit higher dimensionality with respect to the original responses. For comparison, the cumulative variance explained computed on the temporally smoothed responses (see Materials and methods, Section 'Principal component analysis') is shown (dashed blue trace). (<bold>B</bold>) Cumulative variance explained evaluated using the cross-validated PCA (cvPCA) method (<xref ref-type="bibr" rid="bib96">Stringer et al., 2019</xref>) applied to the OFF responses to individual stimuli. For each stimulus we evaluated the cvPCA spectrum averaging over all pairs of trials extracted from 20 total trials (see Materials and methods, Section 'Cross-validated PCA'). The solid trace and color shading represent the mean and standard deviation of the cumulative variance over stimuli. (<bold>C</bold>) Cumulative variance explained evaluated using the cvPCA method applied to the OFF responses to all stimuli at once. Here the solid trace and color shading represent the mean and standard error of the cumulative variance computed over all pairs of trials. In both plots the triangular red markers indicate the cvPCA dimensionalities that explain at least 80% of the response variance.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Controls for the orthogonality between OFF response subspaces.</title><p>(<bold>A</bold>) Statistical control testing for the hypothesis that small subspace overlaps are due to the high dimensionality of neural responses. Blue and gray regions indicate stimulus pairs for which the p-value for the difference between the data and the controls is respectively smaller and larger or equal than 0.05 (lower tail test). Blue regions therefore indicate the stimulus pairs for which low values of the subspace overlaps are not attributable to the high dimensionality of the state-space. The number of shuffles is set to 200 (see Materials and methods, Section 'Controls for subspace overlaps and initial state-peak correlations'). (<bold>B</bold>) Statistical control testing for the hypothesis that small subspace overlaps are due to the trial-to-trial variability of neural responses. Blue and gray regions indicate stimulus pairs for which the p-value for the difference between the data and the controls is respectively smaller and larger or equal than 0.05 (two-tailed independent t-test). Blue regions therefore indicate the stimulus pairs for which low values of the subspace overlaps are not attributable to the trial-to-trial variability of neural activity. The number of trial subsamplings is set to 200 (see Materials and methods, Section 'Controls for subspace overlaps and initial state-peak correlations').</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Relation between ON and OFF responses in the auditory cortex.</title><p>(<bold>A</bold>) <italic>Left</italic>: projection of the population ON and OFF responses to a 8 kHz pure tone (1 s, UP-ramp, with intensity range 60–85 dB) on the first two principal components computed on the ON response. <italic>Right</italic>: projection of both ON and OFF responses to the same stimulus on the first two principal components computed on the OFF response. PCA was performed on the period from −50 ms to 300 ms with respect to stimulus onset and offset. (<bold>B</bold>) Subspace overlaps between the subspaces spanned by the ON and OFF population responses to individual stimuli. The subspace overlap is computed as the cosine of the principal angle between the ON and OFF subspaces, defined by the first five principal components of the ON and OFF population responses respectively. Error bars correspond to ±1 standard deviations computed over 100 subsamplings of the 80% of the units. (<bold>C</bold>) Projection of the population response for the stimulus in <bold>A</bold>, along the population activity vector at the peak of the transient ON and OFF responses (corresponding to the maximum distance from baseline).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Overlap between the states at the peak of the transient OFF responses.</title><p>(<bold>A</bold>) <italic>Left</italic>: overlap between the states at the peak of the OFF responses for each pair of stimuli. The peak time is defined as the time at which the distance from baseline of the population vector is maximum. <italic>Right</italic>: linear correlation between the overlaps between peak states and the overlaps between initial conditions for each stimulus pair. (<bold>B</bold>) Same as <bold>A</bold> except that, for each stimulus, the component of the peak state along the corresponding initial condition has been subtracted.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig2-figsupp4-v2.tif"/></fig></fig-group><p>A central observation revealed by the dimensionality reduction analysis was that the OFF response trajectories relative to stimuli with different frequency content spanned orthogonal low-dimensional subspaces. For instance, the response to the 8 kHz sound was poorly represented on the plane defined by the two principal components of the response to the WN sound (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), and vice versa, showing that they evolved in distinct subspaces. To quantify the relationship between the subspaces spanned by the OFF responses to different stimuli, we proceeded as follows. We first computed the first five principal components of the (baseline-subtracted) OFF response <inline-formula><mml:math id="inf10"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to each individual stimulus <italic>s</italic>. Therefore, for each stimulus <italic>s</italic> these dimensions define a five-dimensional subspace. Then, for each pair of stimuli, we computed the relative orientation of the corresponding pair of subspaces, measured by the subspace overlap (<xref ref-type="fig" rid="fig2">Figure 2D</xref>; see Materials and methods, Section 'Correlations between OFF response subspaces').</p><p>This approach revealed an interesting structure between the OFF response subspaces for different stimuli (<xref ref-type="fig" rid="fig2">Figure 2D</xref> and <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Stimuli with different frequency content evoked in general non-overlapping OFF responses reflected in low values of the subspace overlap. Two clusters of correlated OFF responses emerged, corresponding to the 8 kHz UP-ramps and WN UP-ramps of different durations and intensity. Surprisingly, DOWN-ramps evoked OFF responses that were less correlated than UP-ramps, even for sounds with the same frequency content.</p><p>The fact that most of the stimuli evoked non-overlapping OFF responses is reflected in the number of principal components that explain 80% of the variance for all OFF responses considered together, which is around 60 (<xref ref-type="fig" rid="fig2">Figure 2C</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). This number is in fact close to the number of dominant components of the joint response to all 16 stimuli (see <xref ref-type="table" rid="table1">Table 1</xref>) that we would expect if the responses to individual stimuli evolved on uncorrelated subspaces (given by #PC per stimulus × #stimuli ≈80). Notably this implies that while the OFF responses to individual stimuli span low-dimensional subspaces, the joint response across stimuli shows high-dimensional structure.</p><p>We finally examined to what extent the structure observed between the OFF response trajectories <inline-formula><mml:math id="inf11"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to different stimuli (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) could be predicted from the structure of the population activity states reached at the end of stimulus presentation, corresponding to the initial states <inline-formula><mml:math id="inf12"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Remarkably, we found that the initial states exhibited structure across stimuli that matched well the structure of OFF response dynamics (<xref ref-type="fig" rid="fig2">Figure 2E</xref> <italic>left panel</italic> and <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>), even though the component along the initial states was substracted from the corresponding OFF response trajectories (<xref ref-type="fig" rid="fig2">Figure 2E</xref> <italic>right panel</italic> and <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). This suggests that initial states contribute to determining the subsequent dynamics of the OFF responses.</p></sec><sec id="s2-3"><title>Single-cell model for OFF responses</title><p>Our analyses of auditory cortical data identified three prominent features of population dynamics: (i) OFF responses correspond to transiently amplified trajectories; (ii) responses to individual stimuli explore low-dimensional subspaces; (iii) responses to different stimuli lie in largely orthogonal subspaces. We next examined to what extent these three features could be accounted for by a single-cell mechanisms for OFF response generation.</p><p>The AC is not the first stage where OFF responses arise. Robust OFF responses are found throughout the auditory pathway, and in subcortical areas the generation of OFF responses most likely relies on mechanisms that depend on the interaction between the inhibitory and excitatory synaptic inputs to single cells (e.g. post-inhibitory rebound or facilitation, see <xref ref-type="bibr" rid="bib54">Kopp-Scheinpflug et al., 2018</xref>). To examine the possibility that OFF responses in AC are consistent with a similar single-cell mechanism, we considered a simplified, linear model that could be directly fit to calcium recordings in the AC. Adapting previously used models (<xref ref-type="bibr" rid="bib2">Anderson and Linden, 2016</xref>; <xref ref-type="bibr" rid="bib67">Meyer et al., 2016</xref>), we assumed that the cells received no external input after stimulus offset, and that the response of neuron <italic>i</italic> after stimulus offset is specified by a characteristic linear filter, which describes the cell’s intrinsic response generated by intracellular or synaptic mechanisms (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). We moreover assumed that the shape of this temporal response is set by intrinsic properties, and is therefore identical across different stimuli. In the model, each stimulus modulates the response of a single neuron linearly depending on its activity at stimulus offset, so that the (baseline-subtracted) OFF response of neuron <italic>i</italic> to stimulus <italic>s</italic> is written as:<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the modulation factor for neuron <italic>i</italic> and stimulus <italic>s</italic>. We estimated the single-cell responses <inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from the data by fitting basis functions to the responses of neurons subject to prior normalization by the modulation factors <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> using linear regression (see Materials and methods, Section 'Single-cell model for OFF response generation'). We first fitted the single-cell model to responses to a single stimulus, and then increased the number of stimuli.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Comparison between single-cell and network models for OFF response generation.</title><p>(<bold>A</bold>) Cartoon illustrating the single-cell model defined in <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>. The activity of each unit is described by a characteristic temporal response <inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (colored traces). Across stimuli, only the relative activation of the single units changes, while the temporal shape of the responses of each unit <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> does not vary. (<bold>B</bold>) Distance from baseline of the population activity vector during the OFF response to one example stimulus (red trace; same stimulus as in C <italic>left panel</italic>). The dashed vertical line indicates the time of stimulus offset. Gray dashed lines correspond to the norms of the population activity vectors obtained from fitting the single-cell model respectively to the OFF response to a single stimulus (dashed line), and simultaneously to the OFF responses to two stimuli (dash-dotted line; in this example, the two fitted stimuli are the ones considered in panel <bold>C</bold>). In light gray we plot the norm of 100 realizations of the fitted OFF response by simulating different initial states distributed in the vicinity of the fitted initial state (shown only for the simultaneous fit of two stimuli for clarity). Note that in the single-cell model fit (see Materials and methods, Section 'Fitting the single-cell model'), the fitted initial condition can substantially deviate from the initial condition taken from the data. (<bold>C</bold>) Colored traces: projection of the population OFF responses to two distinct example stimuli (same stimuli as in <xref ref-type="fig" rid="fig2">Figure 2B</xref>) onto the first two principal components of either stimulus. As in panel <bold>B</bold> gray dashed and dash-dotted traces correspond to the projection of the OFF responses obtained when fitting the single-cell model to one or two stimuli at once. (<bold>D</bold>) Goodness of fit (as quantified by coefficient of determination <inline-formula><mml:math id="inf18"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) computed by fitting the single-cell model (blue trace) and the network model (red trace) to the calcium activity data, as a function of the number of stimuli included in the fit. Both traces show the cross-validated value of the goodness of fit (10-fold cross-validation in the time domain). Error bars represent the standard deviation over multiple subsamplings of a fixed number of stimuli (reported on the abscissa). Prior to fitting, for each subsampling of stimuli, we reduced the dimensionality of the responses using PCA, and kept the dominant dimensions that accounted for 90% of the variance. (<bold>E</bold>) Examples of the OFF responses to distinct stimuli of two different auditory cortical neurons (each panel corresponds to a different neuron). The same neuron exhibits different temporal response profiles for different stimuli, a feature consistent with the network model (see <xref ref-type="fig" rid="fig6">Figure 6A,D</xref>), but not with the single-cell model. (<bold>F</bold>) Illustration of the recurrent network model. The variables defining the state of the network are the (baseline-subtracted) firing rates of the units, denoted by <inline-formula><mml:math id="inf19"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The strength of the connection from unit <italic>j</italic> to unit <italic>i</italic> is denoted by <inline-formula><mml:math id="inf20"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. (<bold>G</bold>) Distance from baseline of the population activity vector during the OFF response to one example stimulus (red trace; same stimulus as in C <italic>left panel</italic>). Gray traces correspond to the norms of the population activity vectors obtained from fitting the network model to the OFF response to a single stimulus and generated using the fitted connectivity matrix. The initial conditions were chosen in a neighborhood of the population activity vector 50 ms before sound offset. 100 traces corresponding to 100 random choices of the initial condition are shown. Dashed trace: average distance from baseline. (<bold>H</bold>) Colored traces: projection of the population OFF responses to two different stimuli (same stimuli as in <xref ref-type="fig" rid="fig2">Figure 2B</xref>) on the first two principal components. Gray traces: projections of multiple trajectories generated by the network model using the connectivity matrix fitted to the individual stimuli as in <bold>G</bold>. The initial condition is indicated with a dot. 100 traces are shown. Dashed trace: projection of the average trajectory. (<bold>I</bold>) <italic>Left</italic>: overlap between the subspaces corresponding to OFF response trajectories to pairs of stimuli (as in <xref ref-type="fig" rid="fig2">Figure 2D</xref>) generated using the connectivity matrix fitted to all stimuli at once. <italic>Right</italic>: linear correlation between subspace overlaps and the overlaps between the initial states <inline-formula><mml:math id="inf21"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> for each stimulus pair computed using the trajectories obtained by the fitted network model. The component of the dynamics along the corresponding initial states was subtracted before computing the subspace overlaps.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Goodness of fit for the network and single-cell models adjusted for the number of parameters.</title><p>Goodness of fit, as quantified by coefficient of determination <inline-formula><mml:math id="inf22"><mml:msubsup><mml:mi>R</mml:mi><mml:mi>Adj</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> adjusted for the numbers of parameters, when fitting the single-cell model (blue trace) and the network model (red trace) to the calcium activity data, as a function of the number of stimuli included in the fit. Both traces show the cross-validated value of the goodness of fit (10-fold cross-validation in the time domain). Error bars represent the standard deviation over multiple subsamplings of a fixed number of stimuli (on the abscissa). Prior to fitting, for each subsampling of stimuli, we reduced the dimensionality of the responses using PCA, and kept the dominant dimensions accounting for 90% of the variance.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Goodness of fit for the original and surrogate data sets.</title><p>Value of the goodness of fit for the network model (as quantified by the coefficient of determination <inline-formula><mml:math id="inf23"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) for the original data sets and for three types of surrogate data sets, computed using the activity pooled across the three animals (All) and the activity of individual animals (mouse 1, 2, and 3). For the original data set, the dot shows the goodness of fit averaged over the cross-validation. For the surrogate data sets, the average goodness of fit over cross-validation folds is shown for multiple (n=500) surrogates of the original data. The network model fits significantly better the original data than all three types of surrogate data sets (*** corresponds to p&lt;0.001; upper tail test using the value of the goodness of fit averaged over the cross-validations folds for each data set). Box-and-whisker plots show the distribution of the values for the three types of surrogates (Tukey convention: box lower end, middle line, and upper end represent the first quartile, median, and third quartile of the distributions; lower and upper whisker extends for 1.5 times the interquartile range). Fitting is performed on the population OFF responses to all 16 stimuli at once. The goodness of fit is computed using 10-fold cross-validation in the time domain. The parameters for the reduced-rank ridge regression for the three plots are respectively: <inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>All</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>70</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>70</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>90</mml:mn><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>λ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>90</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Goodness of fit as a function of PC dimensionality for original and surrogate data sets.</title><p>Value of the goodness of fit as a function of PC dimensionality for the original data set (black trace) and for the surrogate data sets (colored traces). The value of the goodness of fit was computed using ridge regression using 10-fold cross-validation. The ridge parameter is optimized for each choice of the PC dimensionality. For the original data set, error bars represent the standard error over the 10 cross-validation folds; for the surrogate data sets, error bars represent the average cross-validation standard error over all the surrogates. Here the number of surrogates is set to 100. For each choice of the PC dimensionality, red crosses indicate that the difference in goodness of fit between the original data set and the most constraining surrogate (TKC) is statistically significant (p&lt;0.01; upper tail test using the mean value of the goodness of fit over the cross-validation folds for each data set).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig3-figsupp3-v2.tif"/></fig></fig-group><p>The single-cell model accounted well for the first two features observed in the data: (i) because the single-cell responses <inline-formula><mml:math id="inf29"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are in general non-monotonic, the distance from baseline of the population activity vector displayed amplified dynamics (<xref ref-type="fig" rid="fig3">Figure 3B</xref>); (ii) at the population level, the trajectories generated by the single-cell model spanned low-dimensional subspaces of at least two dimensions (<xref ref-type="fig" rid="fig3">Figure 3C</xref>) and provided excellent fits to the trajectories in the data when the response to a single stimulus was considered (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). However, we found that the single-cell model could not account for the structure of responses across multiple stimuli. Indeed, although fitting the model to OFF responses to a single stimulus led to an excellent match with auditory cortical data (coefficient of determination <inline-formula><mml:math id="inf30"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula>), increasing the number of simultaneously fitted stimuli led to increasing deviations from the data (<xref ref-type="fig" rid="fig3">Figure 3B,C</xref>), and strongly decreased the goodness of fit (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). When fitting all stimuli at once, the goodness of fit was extremely poor (coefficient of determination <inline-formula><mml:math id="inf31"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>), and therefore the single-cell model could not provide useful information about the third feature of the data, the structure of subspaces spanned in response to different stimuli. A simple explanation for this inability to capture structure across stimuli is that in the single-cell model the temporal shape of the response of each neuron is the same across all stimuli, while this was not the case in the data (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p></sec><sec id="s2-4"><title>Network model for OFF responses</title><p>We contrasted the single-cell model with a network model that generated OFF responses through collective interactions between neurons. Specifically, we studied a linear network of <inline-formula><mml:math id="inf32"><mml:mi>N</mml:mi></mml:math></inline-formula> recurrently coupled linear rate units with time evolution given by: <disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The quantity <inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the deviation of the activity of the unit <italic>i</italic> from its baseline firing rate, while <inline-formula><mml:math id="inf34"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> denotes the effective strength of the connection from neuron <italic>j</italic> to neuron <italic>i</italic> (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). As in the single-cell model, we assumed that the network received no external input after stimulus offset. The only effect of the preceding stimulus was to set the initial pattern of activity of the network at <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. The internal recurrent dynamics then fully determined the subsequent evolution of the activity. Each stimulus <italic>s</italic> was thus represented by an initial state <inline-formula><mml:math id="inf36"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> that was mapped onto a trajectory of activity <inline-formula><mml:math id="inf37"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We focused on the dynamics of the network following stimulus offset, which we represent as <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>To quantify to what extent recurrent interactions could account for auditory cortical dynamics, we fitted the network model to OFF responses using linear regression (see Materials and methods, Section 'Fitting the network model'). For each stimulus, the pattern of initial activity <inline-formula><mml:math id="inf39"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> was taken from the data, and the connectivity matrix <inline-formula><mml:math id="inf40"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> was fitted to the responses to a progressively increasing number of stimuli.</p><p>Qualitatively, we found that the fitted network model reproduced well the first two features of the data, transient amplification and low-dimensional population trajectories (<xref ref-type="fig" rid="fig3">Figure 3G,H</xref>). Quantitatively, we evaluated the goodness of fit by computing the coefficient of determination <inline-formula><mml:math id="inf41"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. While the goodness of fit of the network model was lower than the single-cell model when fitting the response to a single stimulus (<inline-formula><mml:math id="inf42"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.52</mml:mn></mml:mrow></mml:math></inline-formula>), for the network model the goodness of fit remained consistently high as the number of simultaneously fitted stimuli was increased (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, <inline-formula><mml:math id="inf43"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.52</mml:mn></mml:mrow></mml:math></inline-formula> when fitted on the responses to all stimuli). Computing the goodness of fit by taking into account the number of parameters of the network and single-cell models led to the same conclusion (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). When fitted to all stimuli at once, the fitted network model captured the structure of the subspace overlaps (<xref ref-type="fig" rid="fig3">Figure 3I</xref> <italic>left panel</italic>) and its correlation with the structure of initial conditions (<xref ref-type="fig" rid="fig3">Figure 3I</xref> <italic>right panel</italic>). In contrast to the single-cell model, the network model therefore accounted well for the third feature of the data, the structure of responses across stimuli. This can be explained by the fact that, in the network model, the temporal OFF-responses of single cells can in general differ across stimuli (see Figure 6A,D), similar to the activity in the AC (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p></sec><sec id="s2-5"><title>Testing the network mechanisms of OFF responses on the data</title><p>Having found that the fitted network model reproduced the three main features of the data, we next analyzed this model to identify the mechanisms responsible for each feature. The identified mechanisms provided new predictions that we tested on the effective connectivity matrix <inline-formula><mml:math id="inf44"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> obtained from the fit to the data.</p></sec><sec id="s2-6"><title>Transiently amplified OFF responses</title><p>The first feature of the data was that the dynamics were transiently amplified, i.e. the OFF responses first deviated from baseline before eventually converging to it. A preliminary requirement to reproduce this feature is that dynamics are stable, that is, eventually decay to baseline following any initial state. This requirement leads to the usual condition that the eigenvalues of the connectivity matrix <inline-formula><mml:math id="inf45"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> have real parts less than unity. Provided this basic requirement is met, during the transient dynamics from the initial state at stimulus offset, the distance from baseline can either monotonically decrease, or transiently increase before eventually decreasing. To generate the transient increase, the connectivity matrix needs to belong to the class of non-normal matrices (<xref ref-type="bibr" rid="bib100">Trefethen and Embree, 2005</xref>; <xref ref-type="bibr" rid="bib69">Murphy and Miller, 2009</xref>; <xref ref-type="bibr" rid="bib31">Goldman, 2009</xref>; <xref ref-type="bibr" rid="bib42">Hennequin et al., 2012</xref>; see Materials and methods, Section 'Normal and non-normal connectivity matrices'), but this is not a sufficient condition. More specifically, the largest eigenvalue of the symmetric part defined by <inline-formula><mml:math id="inf46"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> needs to be larger than unity, while the initial state <inline-formula><mml:math id="inf47"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> needs to belong to a subset of amplified patterns (<xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>; see Materials and methods, Section 'Sufficient condition for amplified OFF responses').</p><p>To test the predictions derived from the condition for amplified transient responses, that is, that <inline-formula><mml:math id="inf48"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> belongs to a specific subset of non-normal matrices, we examined the spectra of the full connectivity <inline-formula><mml:math id="inf49"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> and of its symmetric part <inline-formula><mml:math id="inf50"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>). The eigenvalues of the fitted connectivity matrix had real parts smaller than one, indicating stable dynamics, and large imaginary parts (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Our theoretical criterion predicted that for OFF responses to be amplified, the spectrum of the symmetric part <inline-formula><mml:math id="inf51"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> must have at least one eigenvalue larger than unity. Consistent with this predictions, we found that the symmetric part of the connectivity had indeed a large number of eigenvalues larger than one (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) and could therefore produce amplified responses (<xref ref-type="fig" rid="fig3">Figure 3G</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Spectra of the connectivity matrix of the fitted network model.</title><p>(<bold>A</bold>) Eigenvalues of the connectivity matrix <inline-formula><mml:math id="inf52"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> obtained by fitting the network model to the population OFF responses to all 1 s stimuli at once. The dashed line marks the stability boundary given by <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="fraktur">R</mml:mi><mml:mi mathvariant="fraktur">e</mml:mi></mml:mrow><mml:mi>λ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>B</bold>) Probability density distribution of the eigenvalues of the symmetric part of the effective connectivity, <inline-formula><mml:math id="inf54"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula>. Eigenvalues larger than unity (<inline-formula><mml:math id="inf55"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>; highlighted in blue) determine strongly non-normal dynamics. In <bold>A</bold> and <bold>B</bold> the total dimensionality of the responses was set to 100. The fitting was performed on 20 bootstrap subsamplings (with replacement) of 80% of neurons out of the total population. Each bootstrap subsampling resulted in a set of 100 eigenvalues. In panel <bold>A</bold> we plotted the eigenvalues of <inline-formula><mml:math id="inf56"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> obtained across all subsamplings. In panel <bold>B</bold> the thin black lines indicate the standard deviation of the eigenvalue probability density across subsamplings. In panels <bold>A</bold> and <bold>B</bold>, the temporal window considered for the fit was extended from 350 ms to 600 ms, to include the decay to zero baseline of the OFF responses. The extension of the temporal window was possible only for the 1 s long stimuli (n=8), since the length of the temporal window following stimulus offset for the 2 s stimuli was limited by the length of the neural recordings.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig4-v2.tif"/></fig></sec><sec id="s2-7"><title>Low-dimensionality of OFF response trajectories</title><p>The second feature of auditory cortical data was that each stimulus generated a population response embedded in an approximately five-dimensional subspace of the full state space. We hypothesized that low-dimensional responses in the fitted network model originated from a low-rank structure in the connectivity (<xref ref-type="bibr" rid="bib65">Mastrogiuseppe and Ostojic, 2018</xref>), implying that the connectivity matrix could be approximated in terms of <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>R</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> modes, that is, as<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mi>𝐉</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where each mode was specified by two <inline-formula><mml:math id="inf58"><mml:mi>N</mml:mi></mml:math></inline-formula>-dimensional vectors <inline-formula><mml:math id="inf59"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf60"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, which we term the right and left connectivity patterns respectively (<xref ref-type="bibr" rid="bib65">Mastrogiuseppe and Ostojic, 2018</xref>). This set of connectivity patterns is uniquely defined from the singular value decomposition (SVD) of the connectivity matrix <inline-formula><mml:math id="inf61"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> (see Materials and methods, Section 'Low-dimensional dynamics').</p><p>To test the low-rank hypothesis, we re-fitted the network model while constraining the rank of connectivity matrix (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>; see Materials and methods, Section 'Fitting the network model'). Progressively increasing the rank <inline-formula><mml:math id="inf62"><mml:mi>R</mml:mi></mml:math></inline-formula>, we found that <inline-formula><mml:math id="inf63"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> was sufficient to capture more than 80% of the variance explained by the network model when fitting the responses to individual stimuli (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Low-dimensional structure of the dynamics of OFF responses to individual stimuli.</title><p>(<bold>A</bold>) Goodness of fit (coefficient of determination) as a function of the rank <inline-formula><mml:math id="inf64"><mml:mi>R</mml:mi></mml:math></inline-formula> of the fitted network, normalized by the goodness of fit computed using ordinary least squares ridge regression. The shaded area represents the standard deviation across individual stimuli. For <inline-formula><mml:math id="inf65"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> reduced-rank regression captures more than 80% (red solid line) of the variance explained by ordinary least squares regression. (<bold>B</bold>) <italic>Left</italic>: overlap matrix <inline-formula><mml:math id="inf66"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> consisting of the overlaps between left and right connectivity patterns of the connectivity <inline-formula><mml:math id="inf67"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> fitted on one example stimulus. The color code shows strong (and opposite in sign) correlation values between left and right connectivity patterns within pairs of nearby modes. Weak coupling is instead present between different rank-2 channels (highlighted by dark boxes). <italic>Right</italic>: histogram of the absolute values of the correlation between right and left connectivity patterns, across all stimuli, and across 20 random subsamplings of 80% of the neurons in the population for each stimulus. Left and right connectivity vectors are weakly correlated, except for the pairs corresponding to the off-diagonal couplings within each rank-2 channel. The two markers indicate the average values of the correlations within each group. When fitting individual stimuli the rank parameter <inline-formula><mml:math id="inf68"><mml:mi>R</mml:mi></mml:math></inline-formula> and the number of principal components are set respectively to 6 and 100. (<bold>C</bold>) <italic>Left</italic>: absolute value of the difference between <inline-formula><mml:math id="inf69"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf70"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> (see panel <bold>B</bold>) divided by 2, across stimuli. For a rank-R channel (here <inline-formula><mml:math id="inf71"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula>) comprising <inline-formula><mml:math id="inf72"><mml:mrow><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> rank-2 channels, the maximum difference <inline-formula><mml:math id="inf73"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> across the <inline-formula><mml:math id="inf74"><mml:mrow><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> rank-2 channels is considered. Large values of this difference indicate that the dynamics of the corresponding rank-R channel are amplified. <italic>Right</italic>: component of the initial state <inline-formula><mml:math id="inf75"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> on the left connectivity vectors <inline-formula><mml:math id="inf76"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, (i.e. <inline-formula><mml:math id="inf77"><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn> 2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ76">Equation (75)</xref>), obtained from the fitted connectivity <inline-formula><mml:math id="inf78"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> to individual stimuli (in green). The component of the initial condition along the left connectivity vectors <inline-formula><mml:math id="inf79"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (green box) is larger than the component of random vectors along the same vectors (gray box). In both panels the boxplots show the distributions across all stimuli of the corresponding average values over 20 random subsamplings of 80% of the neurons. The rank parameter and the number of principal components are the same as in <bold>B</bold>. (<bold>D</bold>) For each stimulus, we show the correlation between the state at the end of stimulus presentation and the state at the peak of the OFF response, defined as the time of maximum distance from baseline. Error bars represent the standard deviation computed over 2000 bootstrap subsamplings of 50% of the neurons in the population (2343 neurons). (<bold>E</bold>) Correlation between initial state and peak state obtained from fitting the single-cell (in green) and network models (in red) to a progressively increasing number of stimuli. For each fitted response the peak state is defined as the population vector at the time of maximum distance from baseline of the original response. The colored shaded areas correspond to the standard error over 100 subsamplings of a fixed number of stimuli (reported on the abscissa) out of 16 stimuli. For each subsampling of stimuli, the correlation is computed for one random stimulus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Selection of hyperparameters in rank-reduced ridge regression.</title><p>The ridge and rank hyperparameters <inline-formula><mml:math id="inf80"><mml:mi>λ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf81"><mml:mi>R</mml:mi></mml:math></inline-formula> are selected using 10-fold cross-validation in the time domain, when fitting the activity of the whole pseudopopulation (All) or the activity of individual animals (mouse 1, 2, and 3). (<bold>A</bold>) Goodness of fit as a function of the hyperparameters <inline-formula><mml:math id="inf82"><mml:mi>λ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf83"><mml:mi>R</mml:mi></mml:math></inline-formula>. The gray trace shows the value of <inline-formula><mml:math id="inf84"><mml:mi>λ</mml:mi></mml:math></inline-formula> for which the goodness of fit is maximum for each value of the rank parameter <inline-formula><mml:math id="inf85"><mml:mi>R</mml:mi></mml:math></inline-formula>. (<bold>B</bold>) Goodness of fit as a function of the hyperparameters <inline-formula><mml:math id="inf86"><mml:mi>λ</mml:mi></mml:math></inline-formula> for three different choices of the rank <inline-formula><mml:math id="inf87"><mml:mi>R</mml:mi></mml:math></inline-formula>. The value of <inline-formula><mml:math id="inf88"><mml:mi>λ</mml:mi></mml:math></inline-formula> for which the goodness of fit is maximum is indicated by the dashed line. (<bold>C</bold>) Goodness of fit as a function of the rank <inline-formula><mml:math id="inf89"><mml:mi>R</mml:mi></mml:math></inline-formula> for <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. The value of the goodness of fit as a function of the rank <inline-formula><mml:math id="inf91"><mml:mi>R</mml:mi></mml:math></inline-formula> does not exhibit a clear maximum, but rather tends to saturate at a certain value of the rank <inline-formula><mml:math id="inf92"><mml:msup><mml:mi>R</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Model recovery for simulated OFF responses using a low-rank network model.</title><p>Model recovery for OFF responses generated through a low-rank network model. The number of units was set to <inline-formula><mml:math id="inf93"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow></mml:math></inline-formula>. The connectivity matrix consisted of <inline-formula><mml:math id="inf94"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> orthogonal transient channels, each one with rank equal to one, given by <inline-formula><mml:math id="inf95"><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where all the left and right connectivity vectors are mutually orthogonal (<inline-formula><mml:math id="inf96"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo rspace="4.2pt">,</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>). We generated 10 OFF responses by setting the initial state of the network to 10 orthogonal left connectivity vectors <inline-formula><mml:math id="inf97"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. Input noise was injected into the system. Thus, the dynamics across stimuli spanned at least 20 dimensions. (<bold>A</bold>) Goodness of fit as a function of the rank parameter <inline-formula><mml:math id="inf98"><mml:mi>R</mml:mi></mml:math></inline-formula> in the reduced-rank regression fit, for two values of the PC dimensionality. Ten-fold cross-validation is used; error bars represent the standard error across the 10 cross-validation folds. The goodness of fit increases as a function of the rank <inline-formula><mml:math id="inf99"><mml:mi>R</mml:mi></mml:math></inline-formula> and stays approximately constant for values of the rank bigger or equal to 20 (dashed line). (<bold>B</bold>) Goodness of fit as a function of the PC dimensionality computed using ordinary least square regression (with no rank constraint, gray trace) and reduced-rank regression (with <inline-formula><mml:math id="inf100"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>, red trace). The dashed line indicated the number of dimensions spanned by the dynamics for all stimuli in case of zero input noise (equal to 20 in this case). For a value of the PC dimensionality larger than the number of dimensions spanned by the dynamics, the goodness of fit decreases due to overfitting. Cross-validation is performed as in <bold>A</bold>. (<bold>C</bold>) Similarity, as quantified by the coefficient of determination <inline-formula><mml:math id="inf101"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>, between the elements of connectivity resulting from the fitting procedure <inline-formula><mml:math id="inf102"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>fit</mml:mi></mml:msub></mml:math></inline-formula> and the projection of the real connectivity <inline-formula><mml:math id="inf103"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> on the top principal components, i.e. <inline-formula><mml:math id="inf104"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>PC</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐐</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐉𝐐</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf105"><mml:mi mathvariant="bold">𝐐</mml:mi></mml:math></inline-formula> contains as columns the principal components), as a function of the number of principal components considered. The gray trace corresponds to ordinary least square regression, while the red trace to reduced-rank regression with rank <inline-formula><mml:math id="inf106"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>D</bold>) Spectra of the matrices <inline-formula><mml:math id="inf107"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>fit</mml:mi></mml:msub></mml:math></inline-formula> (green dots) and <inline-formula><mml:math id="inf108"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>PC</mml:mi></mml:msub></mml:math></inline-formula> (red crosses) using ordinary least square regression (left) and reduced-rank regression (right) for fixed dimensionality (equal to 80, black marker in panel <bold>C</bold>). In all panels, the ridge parameter is set to <inline-formula><mml:math id="inf109"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig5-figsupp2-v2.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Controls for the orthogonality between initial and peak state.</title><p>(<bold>A</bold>) Statistical control testing for the hypothesis that small correlations are due to the high dimensionality of neural responses. The dark trace represents the absolute value of the correlation between initial and peak state for individual stimuli. The blue trace represents the correlations between initial and peak state after shuffling the labels ‘initial state’ and ‘peak state’ across trials (mean and standard error across shuffles is shown). Blue markers indicate stimulus indices for which the p-value for the difference between the data and the controls is smaller than 0.05 (lower tail test), where a low value of the correlation is not attributable to the high dimensionality of the state-space (see Materials and methods, Section 'Controls for subspace overlaps and initial state-peak correlations'). The number of shuffles is set to 1000. (<bold>B</bold>) Statistical control testing for the hypothesis that small correlations are due to the trial-to-trial variability of neural responses. The dark trace represents absolute value of the correlation between initial and peak state for individual stimuli (mean and standard error over 1000 subsampling of 10 trials are shown). The yellow trace represents the correlations between responses at the same time points but averaged over two different sets of trials (mean and standard error over 1000 permutations of trials are shown). Yellow markers indicate stimulus indices for which the p-value for the difference between the data and the controls is smaller than 0.05 (two-tailed independent t-test), where a low value of the correlation is not attributable to the trial-to-trial variability of neural responses (see Materials and methods, Section 'Controls for subspace overlaps and initial state-peak correlations').</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig5-figsupp3-v2.tif"/></fig></fig-group><p>The dynamics in the obtained low-rank network model are therefore fully specified by a set of patterns over the neural population: patterns corresponding to initial states <inline-formula><mml:math id="inf110"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> determined by the stimuli, and patterns corresponding to connectivity vectors <inline-formula><mml:math id="inf111"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf112"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> for <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> that determine the network dynamics. Recurrent neural networks based on such connectivity directly generate low-dimensional dynamics: for a given stimulus <italic>s</italic> the trajectory of the dynamics lies in the subspace spanned by the initial state <inline-formula><mml:math id="inf114"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and the set of right connectivity patterns <inline-formula><mml:math id="inf115"><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib65">Mastrogiuseppe and Ostojic, 2018</xref>; <xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>; <xref ref-type="bibr" rid="bib89">Schuessler et al., 2020</xref>; <xref ref-type="bibr" rid="bib6">Beiran et al., 2020</xref>). More specifically, the transient dynamics can be written as (see Materials and methods, Section 'Low-dimensional dynamics')<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf116"><mml:mi mathvariant="bold">𝐔</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf117"><mml:mi mathvariant="bold">𝐕</mml:mi></mml:math></inline-formula> are <inline-formula><mml:math id="inf118"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> matrices that contain respectively the <inline-formula><mml:math id="inf119"><mml:mi>R</mml:mi></mml:math></inline-formula> right and left connectivity vectors as columns, and <inline-formula><mml:math id="inf120"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>R</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> matrix of overlaps <inline-formula><mml:math id="inf122"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> between left and right connectivity vectors. This overlap matrix therefore fully determines the dynamics in the network (see Materials and methods, Section 'Low-dimensional dynamics').</p><p>Inspecting the overlap matrix <inline-formula><mml:math id="inf123"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> obtained from the fitted connectivity matrix revealed a clear structure, where left and right vectors were strongly correlated within pairs, but uncorrelated between different pairs (<xref ref-type="fig" rid="fig5">Figure 5B</xref> <italic>left panel</italic>). This structure effectively defined a series of <inline-formula><mml:math id="inf124"><mml:mrow><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> rank-2 channels that were orthogonal to each other. Within individual rank-2 channels, strong correlations were observed only across the two modes (e.g. between <inline-formula><mml:math id="inf125"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf126"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf127"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf128"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, etc.; <xref ref-type="fig" rid="fig5">Figure 5B</xref>), so that the connectivity matrix corresponding to each rank-2 channel can be written as<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:msub><mml:mi>𝐉</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf129"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf130"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> are two scalar values. Rank-2 matrices of this type have purely imaginary eigenvalues given by <inline-formula><mml:math id="inf131"><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>, reflecting the strong imaginary components in the eigenspectrum of the full matrix (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). These imaginary eigenvalues lead to strongly rotational dynamics in the plane defined by <inline-formula><mml:math id="inf132"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf133"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6C</xref>; see Materials and methods, Section 'Dynamics of a low-rank rotational channel'), qualitatively similar to the low-dimensional dynamics in the data (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Such rotational dynamics however do not necessarily imply transient amplification. In fact, a rank-2 connectivity matrix as in <xref ref-type="disp-formula" rid="equ5">Equation (5)</xref> generates amplified dynamics only if two conditions are satisfied (<xref ref-type="fig" rid="fig6">Figure 6B</xref>; see Materials and methods, Section 'Dynamics of a low-rank rotational channel'): (i) the difference <inline-formula><mml:math id="inf134"><mml:mrow><mml:mrow><mml:mo rspace="4.2pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mpadded></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> is greater than unity; (ii) the initial state <inline-formula><mml:math id="inf135"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> overlaps strongly with the left connectivity patterns <inline-formula><mml:math id="inf136"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. A direct consequence of these constraints is that when dynamics are transiently amplified, the population activity vector at the peak of the transient dynamics lies along a direction that is largely orthogonal to the initial state at stimulus offset (<xref ref-type="fig" rid="fig6">Figure 6C,E</xref>, see Materials and methods, Section 'Correlation between initial and peak state').</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Population OFF responses in a network model with low-rank rotational structure.</title><p>(<bold>A</bold>) Single-unit OFF responses to two distinct stimuli generated by orthogonal rank-2 rotational channels (see Materials and methods, Section 'Dynamics of a low-rank rotational channel'). The two stimuli were modeled as two different activity states <inline-formula><mml:math id="inf137"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf138"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> at the end of stimulus presentation (<inline-formula><mml:math id="inf139"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). We simulated a network of 1000 units. The connectivity consisted of the sum of <inline-formula><mml:math id="inf140"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula> rank-2 rotational channels of the form given by <xref ref-type="disp-formula" rid="equ5 equ6">Equation (5, 6)</xref> (<inline-formula><mml:math id="inf141"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref> and <inline-formula><mml:math id="inf142"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf143"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf144"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>). Here the two stimuli were chosen along two orthogonal vectors <inline-formula><mml:math id="inf145"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf146"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. Dashed lines indicate the time of stimulus offset. (<bold>B</bold>) Distance from baseline of the population activity vector during the OFF responses to the two stimuli in <bold>A</bold>. For each stimulus, the amplitude of the offset responses (quantified by the peak value of the distance from baseline) is controlled by the difference between the lengths of the right connectivity vectors of each rank-2 channel, that is, <inline-formula><mml:math id="inf147"><mml:mrow><mml:mrow><mml:mo rspace="4.2pt" stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mpadded></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>C</bold>) Projection of the population OFF responses to the two stimuli onto the first two principal components of either stimuli. The projections of the vectors <inline-formula><mml:math id="inf148"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (resp. <inline-formula><mml:math id="inf150"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) on the subspace defined by the first two principal components of stimulus 1 (resp. 2) are shown respectively as solid and dashed arrows. The subspaces defined by the vector pairs <inline-formula><mml:math id="inf152"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>,<inline-formula><mml:math id="inf153"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf154"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>,<inline-formula><mml:math id="inf155"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> are mutually orthogonal, so that the OFF responses to stimuli 1 and 2 evolve in orthogonal dimensions. (<bold>D</bold>) Firing rate of one example neuron in response to two distinct stimuli: in the recurrent network model the time course of the activity of one unit is not necessarily the same across stimuli. (<bold>E</bold>) Correlation between the initial state (i.e. the state at the end of stimulus presentation) and the state at the peak of the OFF responses, for five example stimuli. Error bars represent the standard deviation computed over 100 bootstrap subsamplings of 50% of the units in the population.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig6-v2.tif"/></fig><p>The theoretical analyses of the model therefore provide a new set of predictions that we directly tested on the connectivity fitted to the data. We first computed the differences <inline-formula><mml:math id="inf156"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> for each channel using the SVD of the fitted matrix <inline-formula><mml:math id="inf157"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, and found that they were sufficiently large to amplify the dynamics within each rank-<inline-formula><mml:math id="inf158"><mml:mi>R</mml:mi></mml:math></inline-formula> channel (<xref ref-type="fig" rid="fig5">Figure 5C</xref> <italic>left panel</italic>). We next examined for each stimulus the component of the initial state <inline-formula><mml:math id="inf159"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> on the <inline-formula><mml:math id="inf160"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s and found that it was significantly larger than the component on the <inline-formula><mml:math id="inf161"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s of a random vector, across all stimuli (<xref ref-type="fig" rid="fig5">Figure 5C</xref> <italic>right panel</italic>). Finally, computing the correlation between the peak state and the initial state at the end of stimulus presentation, we found that this correlation took values lower than values predicted by chance for almost all stimuli, consistent with the prediction of the network model (<xref ref-type="fig" rid="fig5">Figure 5D</xref>, <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). The single-cell model instead predicts stronger correlations between initial and peak states, in clear conflict with the data (<xref ref-type="fig" rid="fig5">Figure 5E</xref>).</p></sec><sec id="s2-8"><title>Orthogonal OFF response trajectories across stimuli</title><p>The third feature observed in the data was that population responses evoked by different stimuli were orthogonal for many of the considered stimuli. Orthogonal trajectories for different stimuli can be reproduced in the model under the conditions that (i) initial patterns of activity corresponding to different stimuli are orthogonal, (ii) the connectivity matrix is partitioned into a set of orthogonal low-rank terms, each individually leading to transiently amplified dynamics, and (iii) each stimulus activates one of the low-rank terms. Altogether, for <inline-formula><mml:math id="inf162"><mml:mi>P</mml:mi></mml:math></inline-formula> stimuli leading to orthogonal responses, the connectivity matrix can be partitioned in <inline-formula><mml:math id="inf163"><mml:mi>P</mml:mi></mml:math></inline-formula> different groups of modes:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mi>𝐉</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>P</mml:mi></mml:munderover><mml:msup><mml:mi>𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:munderover><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the vectors <inline-formula><mml:math id="inf164"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> have unit norm. The set of modes indexed by <italic>s</italic> correspond to the <italic>s</italic>-th stimulus, so that the pattern of initial activity <inline-formula><mml:math id="inf165"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> evoked by stimulus <italic>s</italic> overlaps only with those modes. Moreover, modes corresponding to different groups are orthogonal, and generate dynamics that span orthogonal subspaces (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Each term in <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref> can therefore be interpreted as an independent transient coding channel that can be determined from the OFF-response to stimulus <italic>s</italic> alone.</p><p>We therefore examined whether the fitted connectivity <inline-formula><mml:math id="inf166"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> consisted of independent low-rank coding channels (<xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>), a constraint that would generate orthogonal responses to different stimuli as observed in the data. If <inline-formula><mml:math id="inf167"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> consisted of fully independent channels as postulated in <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>, then it could be equivalently estimated by fitting the recurrent model to the OFF responses to each stimulus <italic>s</italic> independently, leading to one matrix <inline-formula><mml:math id="inf168"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> for each stimulus. The hypothesis of fully independent channels then implies that (i) the connectivity vectors for the different connectivity matrices are mutually orthogonal, (ii) the full connectivity matrix can be reconstructed by summing the matrices <inline-formula><mml:math id="inf169"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> estimated for individual stimuli. To test these two predictions, we estimated the connectivity matrices <inline-formula><mml:math id="inf170"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (the rank parameter for each stimulus was set to <inline-formula><mml:math id="inf171"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>). We then computed the overlaps between the connectivity vectors corresponding to different pairs of stimuli (see Materials and methods, Section 'Analysis of the transient channels') and compared them to the overlaps between the subspaces spanned in response to the same pairs of stimuli (see <xref ref-type="fig" rid="fig2">Figure 2D</xref>). We found a close match between the two quantities (<xref ref-type="fig" rid="fig7">Figure 7A,B</xref>): pairs of stimuli with strong subspace overlaps corresponded to high connectivity overlaps, and pairs of stimuli with low subspace overlaps corresponded to low connectivity overlaps. This indicated that some of the stimuli, but not all, corresponded to orthogonal coding channels. We further reconstructed the OFF responses using the matrix <inline-formula><mml:math id="inf172"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mi>s</mml:mi></mml:msub></mml:mpadded><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. We then compared the goodness of fit computed using the matrices <inline-formula><mml:math id="inf173"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf174"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> and multiple controls where the elements of the matrix <inline-formula><mml:math id="inf175"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula> were randomly shuffled. While the fraction of variance explained when using the matrix <inline-formula><mml:math id="inf176"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula> was necessarily lower than the one computed using <inline-formula><mml:math id="inf177"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula>, the model with connectivity <inline-formula><mml:math id="inf178"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula> yielded values of the goodness of fit significantly higher than the ones obtained from the shuffles (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). These results together indicated that the full matrix <inline-formula><mml:math id="inf179"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> can indeed be approximated by the sum of the low-rank channels represented by the <inline-formula><mml:math id="inf180"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Structure of the transient channels across stimuli.</title><p>(<bold>A</bold>) Overlaps between the transient channels corresponding to individual stimuli (<italic>connectivity overlaps</italic>), as quantified by the overlap between the right connectivity vectors <inline-formula><mml:math id="inf181"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> of the connectivities <inline-formula><mml:math id="inf182"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> fitted to each individual stimulus <italic>s</italic> (see Materials and methods, Section 'Analysis of the transient channels'). The ridge and rank parameters, and the number of principal components have been respectively set to <inline-formula><mml:math id="inf183"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf184"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf185"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">#</mml:mi><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> (the choice of <inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> maximized the coefficient of determination between the connectivity overlaps, <bold>A</bold>, and the subspace overlaps, <xref ref-type="fig" rid="fig2">Figure 2D</xref>). (<bold>B</bold>) Scatterplot showing the relationship between the subspace overlaps (see <xref ref-type="fig" rid="fig2">Figure 2D</xref>) and connectivity overlaps (panel <bold>A</bold>) for each pair of stimuli. (<bold>C</bold>) Goodness of fit computed by predicting the population OFF responses using the connectivity <inline-formula><mml:math id="inf187"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> (Full) or the connectivity given by the sum of the individual channels <inline-formula><mml:math id="inf188"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula> (Sum). These values are compared with the goodness of fit obtained by shuffling the elements of the matrix <inline-formula><mml:math id="inf189"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula> (Shuffle). Box-and-whisker plots show the distributions of the goodness of fit computed for each cross-validation partition (10-fold). For <inline-formula><mml:math id="inf190"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> the ridge and rank parameters, and the number of principal components were set to <inline-formula><mml:math id="inf191"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf192"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>70</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf193"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">#</mml:mi><mml:mo>⁢</mml:mo><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig7-v2.tif"/></fig></sec><sec id="s2-9"><title>Amplification of single-trial fluctuations</title><p>So far we examined the activity obtained by averaging for each neuron the response to the same stimulus over multiple trials. We next turned to trial-to-trial variability of simultaneously recorded neurons and compared the structure of the variability in the data with the network and single-cell models. Specifically, we examined the variance of the activity along a direction <inline-formula><mml:math id="inf194"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> of state-space (<xref ref-type="fig" rid="fig8">Figure 8A</xref>; <xref ref-type="bibr" rid="bib42">Hennequin et al., 2012</xref>), defined as:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">⟨</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">⟩</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf195"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula> denotes the averaging across trials. We compared the variance along the direction <inline-formula><mml:math id="inf196"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub></mml:math></inline-formula> corresponding to the maximum amplification (distance from baseline) of the trial-averaged dynamics with variance along a random direction <inline-formula><mml:math id="inf197"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub></mml:math></inline-formula>.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Structure of trial-to-trial variability generated by the network and single-cell models, compared to the auditory cortical data.</title><p>(<bold>A</bold>) Cartoon illustrating the structure of single-trial population responses along different directions in the state-space. The thick and thin blue lines represent respectively the trial-averaged and single-trial responses. Single-trial responses start in the vicinity of the trial-averaged activity <inline-formula><mml:math id="inf198"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. Both the network and single-cell mechanisms dynamically shape the structure of the single-trial responses, here represented as graded blue ellipses. The red and black lines represent respectively the amplified and random directions considered in the analyses. (<bold>B</bold>) Time course of the variability computed along the amplified direction (solid trace) and along a random direction (dashed trace) for one example stimulus and one example session (287 simultaneously recorded neurons). In this and all the subsequent panels the amplified direction is defined as the population activity vector at the time when the norm of the trial-averaged activity of the pseudo-population pooled over sessions and animals reaches its maximum value (thick dashed line). Thin dashed lines denote stimulus offset. Shaded areas correspond to the standard deviation computed over 20 bootstrap subsamplings of 19 trials out of 20. (<bold>C, E, and G</bold>) Variability amplification (VA) computed for the amplified and random directions on the calcium activity data (panel <bold>C</bold>), on trajectories generated using the network model (panel <bold>E</bold>) and the single-cell model (panel <bold>G</bold>); (see Materials and methods, Section 'Single-trial analysis of population OFF responses'), for one example stimulus (same as in <bold>B</bold>). The network and single-cell models were first fitted to the trial-averaged responses to individual stimuli, independently across all recordings sessions (13 sessions, 180 ± 72 neurons). 100 single-trial responses were then generated by simulating the fitted models on 100 initial conditions drawn from a random distribution with mean <inline-formula><mml:math id="inf199"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and covariance matrix equal to the covariance matrix computed from the single-trial initial states of the original responses (across neurons for the single-cell model, across PC dimensions for the recurrent model). Results did not change by drawing the initial conditions from a distribution with mean <inline-formula><mml:math id="inf200"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and isotropic covariance matrix (i.e. proportional to the identity matrix, as assumed for the theoretical analysis in Materials and methods, Section 'Single-trial analysis of population OFF responses'). In the three panels, the values of VA were computed over 50 subsamplings of 90% of the cells (or PC dimensions for the recurrent model) and 50 shuffles. Error bars represent the standard deviation over multiple subsamplings, after averaging over all sessions and shuffles. Significance levels were evaluated by first computing the difference in VA between amplified and random directions (<inline-formula><mml:math id="inf201"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>VA</mml:mi></mml:mrow></mml:math></inline-formula>) and then computing the p-value on the difference between <inline-formula><mml:math id="inf202"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Real</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf203"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Shuffles</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> across subsamplings (two-sided independent t-test). For the network model, the VA is higher for the amplified direction than for a random direction, and this effect is significantly stronger for the real than for the shuffled responses. Instead, for the single-cell model the values of the VA computed on the real responses are not significantly different from the ones computed on the shuffled responses. (<bold>D, F, and H</bold>) Values of the VA computed as in panels <bold>C, E, and G</bold> pooled across all 16 stimuli. Error bars represent the standard error across stimuli. Significance levels were evaluated computing the p-value on the difference between <inline-formula><mml:math id="inf204"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Real</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf205"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Shuffles</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> across stimuli (two-sided Wilcoxon signed-rank test). The fits of the network and single-cell models of panels <bold>E, G, F, and H</bold> were generated using ridge regression (<inline-formula><mml:math id="inf206"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> for both models).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig8-v2.tif"/></fig><p>Inspecting the variability during the OFF-responses in the AC data revealed two prominent features: (i) fluctuations across trials are amplified along the same direction <inline-formula><mml:math id="inf207"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub></mml:math></inline-formula> of state-space as trial-averaged dynamics, but not along random directions (<xref ref-type="fig" rid="fig8">Figure 8B,C,D</xref>); (ii) cancelling cross-correlations by shuffling trial labels independently for each cell strongly reduces the amplification of the variance (<xref ref-type="fig" rid="fig8">Figure 8C,D</xref>). This second feature demonstrates that the amplification of variance is due to noise-correlations across neurons that have been previously reported in the AC (<xref ref-type="bibr" rid="bib82">Rothschild et al., 2010</xref>). Indeed the variance along a direction <inline-formula><mml:math id="inf208"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> at time <inline-formula><mml:math id="inf209"><mml:mi>t</mml:mi></mml:math></inline-formula> can be expressed as<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mrow><mml:mi>var</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf210"><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> represents the covariance matrix of the population activity at time <inline-formula><mml:math id="inf211"><mml:mi>t</mml:mi></mml:math></inline-formula>. Shuffling trial labels independently for each cell effectively cancels the off-diagonal elements of the covariance matrix and leaves only the diagonal elements that correspond to single-neuron variances. The comparison between simultaneous and shuffled data (<xref ref-type="fig" rid="fig8">Figure 8C,D</xref>) demonstrates that an increase in single-neuron variance is not sufficient to explain the total increase in variance along the amplified direction <inline-formula><mml:math id="inf212"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub></mml:math></inline-formula>.</p><p>Simulations of the fitted models and a mathematical analysis show that the network model reproduces both features of trial-to-trial variability observed in the data (<xref ref-type="fig" rid="fig8">Figure 8E,F</xref>), based on a minimal assumption that variability originates from independent noise in the initial condition at stimulus offset (see Materials and methods, Section 'Structure of single-trial responses in the network model'). Surprisingly, the single-cell model also reproduces the first feature, the amplification of fluctuations along the same direction of state-spate as trial-averaged dynamics, although in that model the different neurons are not coupled and noise-correlations are absent (<xref ref-type="fig" rid="fig8">Figure 8G,H</xref>). Instead, the single-cell model fails to capture the second feature, as it produces amplified variability in both simultaneous and shuffled activity. This demonstrates that the amplification of variability in the single-cell model is due to an amplification of single-cell variances, that is, the diagonal elements of covariance matrix (see Materials and methods, Section 'Structure of single-trial responses in the single-cell model'). Somewhat counter-intuitively, the disagreement between the single-cell model and the data is not directly due to the lack of noise-correlations in that model, but due to the fact that the single-cell model does not predict accurately the variance of single-neuron activity during the OFF-responses, and therefore fails to capture variance in shuffled activity.</p><p>In summary, the network model accounts better than the single-cell model for the structure of single-trial fluctuations present in the AC data.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Adopting a population approach, we showed that strong OFF responses observed in auditory cortical neurons form transiently amplified trajectories that encode individual stimuli within low-dimensional subspaces. A geometrical analysis revealed a clear structure in the relative orientation of these subspaces, where subspaces corresponding to different auditory stimuli were largely orthogonal to each other. We found that a simple, linear single-neuron model captures well the average response to individual stimuli, but not the structure across stimuli and across individual trials. In contrast, we showed that a simple, linear recurrent network model accounts for all the properties of the population OFF responses, notably their global structure across multiple stimuli and the fluctuations across single trials. Our results therefore argue for a potential role of network interactions in shaping OFF responses in AC. Ultimately, future work could combine both single-cell and network mechanisms in a network model with more complex intrinsic properties of individual neurons (<xref ref-type="bibr" rid="bib7">Beiran and Ostojic, 2019</xref>; <xref ref-type="bibr" rid="bib70">Muscinelli et al., 2019</xref>).</p><p>In this study, we focused specifically on the responses following stimulus offset. Strong transients during stimulus onset display similar transient coding properties (<xref ref-type="bibr" rid="bib66">Mazor and Laurent, 2005</xref>) and could be generated by the same network mechanism as we propose for the OFF responses. However, during ON-transients, a number of additional mechanisms are likely to play a role, in particular single-cell adaptation, synaptic depression, or feed-forward inhibition. Indeed, recent work has shown that ON and OFF trajectories elicited by a stimulus are orthogonal to each other in the state-space (<xref ref-type="bibr" rid="bib84">Saha et al., 2017</xref>), and this was also the case in our data set (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Linear network models instead produce ON and OFF responses that are necessarily correlated and cannot account for the observed orthogonality of ON and OFF responses for a given stimulus. Distinct ON and OFF response dynamics could also result from intrinsic nonlinearities known to play a role in the AC (<xref ref-type="bibr" rid="bib16">Calhoun and Schreiner, 1998</xref>; <xref ref-type="bibr" rid="bib83">Rotman et al., 2001</xref>; <xref ref-type="bibr" rid="bib85">Sahani and Linden, 2003</xref>; <xref ref-type="bibr" rid="bib64">Machens et al., 2004</xref>; <xref ref-type="bibr" rid="bib106">Williamson et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>).</p><p>A major assumption of both the single-cell and network models we considered is that the AC does not receive external inputs after the auditory stimulus is removed. Indeed, the observation that the structure of the dynamics across stimuli could be predicted by the structure of their initial states (<xref ref-type="fig" rid="fig2">Figure 2D,E</xref> and <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>) indicates that autonomous dynamics at least partly shape the OFF responses. The comparisons between data and models moreover show that autonomous dynamics are in principle sufficient to reproduce a number of features of OFF responses in the absence of any external drive. However, neurons in the AC do receive direct afferents from the medial geniculate body of the thalamus, and indirect input from upstream regions of the auditory pathway, where strong OFF responses have been observed. Thus, in principle, OFF responses observed in AC could be at least partly inherited from upstream auditory regions (<xref ref-type="bibr" rid="bib54">Kopp-Scheinpflug et al., 2018</xref>). Disentangling the contributions of upstream inputs and recurrent dynamics is challenging if one has access only to auditory cortical activity (but see <xref ref-type="bibr" rid="bib90">Seely et al., 2016</xref> for an interesting computational approach). Ultimately, the origin of OFF responses in AC needs to be addressed by comparing responses between related areas, an approach recently adopted in the context of motor cortical dynamics (<xref ref-type="bibr" rid="bib56">Lara et al., 2018</xref>). A direct prediction of our model is that the inactivation of recurrent excitation in auditory cortical areas should weaken OFF responses (<xref ref-type="bibr" rid="bib58">Li et al., 2013</xref>). However, recurrency in the auditory system is not present only within the cortex but also between different areas along the pathway (<xref ref-type="bibr" rid="bib47">Ito and Malmierca, 2018</xref>; <xref ref-type="bibr" rid="bib107">Winer et al., 1998</xref>; <xref ref-type="bibr" rid="bib57">Lee et al., 2011</xref>). Therefore OFF responses could be generated at a higher level of recurrency and might not be abolished by inactivation of AC.</p><p>The dimensionality of the activity in large populations of neurons in the mammalian cortex is currently the subject of debate. A number of studies have found that neural activity explores low-dimensional subspaces during a variety of simple behavioral tasks (<xref ref-type="bibr" rid="bib30">Gao et al., 2017</xref>). In contrast, a recent study in the visual cortex has shown that the response of large populations of neurons to a large number of visual stimuli is instead high-dimensional (<xref ref-type="bibr" rid="bib96">Stringer et al., 2019</xref>). Our results provide a potential way of reconciling these two sets of observations. We find that the population OFF responses evoked by individual auditory stimuli are typically low-dimensional, but lie in orthogonal spaces, so that the dimensionality of the responses increases when considering an increasing number of stimuli. Note that in contrast to <xref ref-type="bibr" rid="bib96">Stringer et al., 2019</xref>, we focused here on the temporal dynamics of the population response. The dimensionality of these dynamics is in particular limited by the temporal resolution of the recordings (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><p>The analyses we performed in this study were directly inspired by an analogy between OFF responses in the sensory areas and neural activity in the motor cortices (<xref ref-type="bibr" rid="bib20">Churchland and Shenoy, 2007</xref>; <xref ref-type="bibr" rid="bib18">Churchland et al., 2010</xref>). Starting at movement onset, single-neuron activity recorded in motor areas exhibits strongly transient and multiphasic firing lasting a few hundreds of milliseconds. Population-level dynamics alternate between at least two dimensions, shaping neural trajectories that appear to rotate in the state-space. These results have been interpreted as signatures of an underlying dynamical system implemented by recurrent network dynamics (<xref ref-type="bibr" rid="bib19">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib91">Shenoy et al., 2011</xref>), where the population state at movement onset provides the initial condition able to generate the transient dynamics used for movement generation. Computational models have explored this hypothesis (<xref ref-type="bibr" rid="bib99">Sussillo et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Hennequin et al., 2014</xref>; <xref ref-type="bibr" rid="bib97">Stroud et al., 2018</xref>) and showed that the complex transient dynamics observed in motor cortex can be generated in network models with strong recurrent excitation balanced by fine-tuned inhibition (<xref ref-type="bibr" rid="bib43">Hennequin et al., 2014</xref>). Surprisingly, fitting a linear recurrent network model to auditory cortical data, we found that the arrangement of the eigenvalues of the connectivity matrix was qualitatively similar to the spectrum of this class of networks (<xref ref-type="bibr" rid="bib43">Hennequin et al., 2014</xref>), suggesting that a common mechanism might account for the responses observed in both areas.</p><p>The perceptual significance of OFF responses in the auditory pathway is still matter of ongoing research. Single-cell OFF responses observed in the auditory and visual pathways have been postulated to form the basis of duration selectivity (<xref ref-type="bibr" rid="bib13">Brand et al., 2000</xref>; <xref ref-type="bibr" rid="bib1">Alluri et al., 2016</xref>; <xref ref-type="bibr" rid="bib38">He, 2002</xref>; <xref ref-type="bibr" rid="bib4">Aubie et al., 2009</xref>; <xref ref-type="bibr" rid="bib24">Duysens et al., 1996</xref>). In the auditory brainstem and cortex, OFF responses of single neurons exhibit tuning in the frequency-intensity domain, and their receptive field has been reported to be complementary to the receptive field of ON responses (<xref ref-type="bibr" rid="bib44">Henry, 1985</xref>; <xref ref-type="bibr" rid="bib88">Scholl et al., 2010</xref>). The complementary spatial organization of ON and OFF receptive fields may result from two distinct sets of synaptic inputs to cortical neurons (<xref ref-type="bibr" rid="bib88">Scholl et al., 2010</xref>), and has been postulated to form the basis for higher-order stimulus features selectivity in single cells, such as frequency-modulated (FM) sounds (<xref ref-type="bibr" rid="bib94">Sollini et al., 2018</xref>) and amplitude-modulated (AM) sounds (<xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>), both important features of natural sounds (<xref ref-type="bibr" rid="bib94">Sollini et al., 2018</xref>; <xref ref-type="bibr" rid="bib72">Nelken et al., 1999</xref>). Complementary tuning has also been observed between cortical ON and OFF responses to binaural localization cues, suggesting OFF responses may contribute to the encoding of sound-source location or motion (<xref ref-type="bibr" rid="bib37">Hartley et al., 2011</xref>). At the population level, the proposed mechanism for OFF response generation may provide the basis for encoding complex sequences of sounds. Seminal work in the olfactory system has shown that sequences of odors evoked specific transient trajectories that depend on the history of the stimulation (<xref ref-type="bibr" rid="bib14">Broome et al., 2006</xref>; <xref ref-type="bibr" rid="bib15">Buonomano and Maass, 2009</xref>). Similarly, within our framework, different combinations of sounds could bring the activity at the end of stimulus offset to different regions of the state-space, setting the initial condition for the subsequent OFF responses. If the initial conditions corresponding to different sequences are associated with distinct transient coding channels, different sound sequences would evoke transient trajectories along distinct dimensions during the OFF responses, therefore supporting the robust encoding of complex sound sequences.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Data analysis</title><sec id="s4-1-1"><title>The data set</title><sec id="s4-1-1-1"><title>Neural recordings</title><p>Neural data was recorded and described in previous work (<xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>). We analyzed the activity of 2343 neurons in mouse AC recorded using two-photon calcium imaging while mice were passively listening to different sounds. Each sound was presented 20 times. Data included recordings from three mice across 13 different sessions. Neural recordings in the three mice comprised respectively 1251, 636, and 456 neurons. Recordings in different sessions were performed at different depths, typically with a 50 µm difference (never less than 20 µm). Since the soma diameter is ∼15 µm, this ensured that different cells were recorded in different sessions. We analyzed the trial-averaged activity of a pseudo-population of neurons built by pooling neural activity across all recording sessions and all animals. The raw calcium traces (imaging done at 31.5 frames per second) were smoothed using a Gaussian kernel with standard deviation <inline-formula><mml:math id="inf213"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:math></inline-formula> ms. We then subtracted the baseline firing activity (i.e. the average neural activity before stimulus presentation) from the activity of each neuron, and used the baseline-subtracted neural activity for the analyses.</p></sec><sec id="s4-1-1-2"><title>The stimuli set</title><p>The stimuli consisted of a randomized presentation of 16 different sounds, 8 UP-ramping sounds, and 8 DOWN-ramping sounds. For each type, sounds had different frequency content (either 8 kHz or WN), different durations (1 or 2 s), and different combinations of onset and offset intensity levels (for UP-ramps either 50–85 dB or 60–85 dB, while for DOWN-ramps 85–50 dB or 85–60 dB). The descriptions of the stimuli are summarized in <xref ref-type="table" rid="table1">Table 1</xref>.</p></sec></sec><sec id="s4-1-2"><title>Decoding analysis</title><p>To assess the accuracy of stimulus discrimination (8 kHz vs. WN sound) on single-trials, we trained and tested a linear discriminant classifier (<xref ref-type="bibr" rid="bib8">Bishop, 2006</xref>) using cross-validation. For each trial, the pseudo-population activity vectors (built by pooling across sessions and animals) were built at each 50 ms time bin. We used leave-one-out cross-validation. At each time bin we used 19 out of 20 trials for the training set, and tested the trained decoder on the remaining trial. The classification accuracy was computed as the average fraction of correctly classified stimuli over all 20 cross-validation folds.</p><p>At each time <inline-formula><mml:math id="inf214"><mml:mi>t</mml:mi></mml:math></inline-formula> the decoder for classification between stimuli <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> was trained using the trial-averaged pseudo-population vectors <inline-formula><mml:math id="inf215"><mml:msub><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf216"><mml:msub><mml:mi mathvariant="bold">𝐜</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. These vectors defined the decoder <inline-formula><mml:math id="inf217"><mml:msub><mml:mi mathvariant="bold">𝐰</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> and the bias term <inline-formula><mml:math id="inf218"><mml:msub><mml:mi mathvariant="bold">𝐛</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> as:<disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:mrow><mml:msub><mml:mi>𝐰</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>𝐜</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>𝐜</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo rspace="22.5pt">,</mml:mo><mml:mrow><mml:msub><mml:mi>𝐛</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>𝐜</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>𝐜</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>A given population vector <inline-formula><mml:math id="inf219"><mml:mi mathvariant="bold">𝐱</mml:mi></mml:math></inline-formula> was classified as either stimulus <italic>s</italic><sub>1</sub> or stimulus <italic>s</italic><sub>2</sub> according to the value of the function <inline-formula><mml:math id="inf220"><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐱</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">𝐰</mml:mi><mml:mi>t</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐱</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐛</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ11"><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Random performance was evaluated by training and testing the classifier using cross-validation on surrogate data sets built by shuffling stimulus single-trial labels at each time bin. We performed the same analysis using more sophisticated decoder algorithms, that is, Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and C-SVM decoders. For none of these decoder algorithms was the cross-validated accuracy substantially better than the naive classifier reported in <xref ref-type="fig" rid="fig1">Figure 1C</xref> (and for the QDA algorithm the accuracy was substantially worse; not shown).</p></sec></sec><sec id="s4-2"><title>Principal component analysis</title><p>To perform PCA on the population responses to <inline-formula><mml:math id="inf221"><mml:mi>C</mml:mi></mml:math></inline-formula> stimuli <inline-formula><mml:math id="inf222"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula> we considered the matrix <inline-formula><mml:math id="inf223"><mml:mrow><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf224"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of neurons and <inline-formula><mml:math id="inf225"><mml:mi>T</mml:mi></mml:math></inline-formula> is the number of time steps considered. The matrix <inline-formula><mml:math id="inf226"><mml:mi mathvariant="bold">𝐗</mml:mi></mml:math></inline-formula> contained the population OFF responses to the stimuli <inline-formula><mml:math id="inf227"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula>, centered around the mean over times and stimuli. If we denote by <inline-formula><mml:math id="inf228"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> the <italic>i</italic>-th eigenvalue of the covariance matrix <inline-formula><mml:math id="inf229"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the percentage of variance explained by the <italic>i</italic>-th principal component is given by:<disp-formula id="equ12"><mml:math id="m12"><mml:mrow><mml:mrow><mml:mi>𝖵𝖠𝖱</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo mathsize="210%" stretchy="false">/</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>while the cumulative percentage of variance explained by the first <inline-formula><mml:math id="inf230"><mml:mi>M</mml:mi></mml:math></inline-formula> principal components (<xref ref-type="fig" rid="fig2">Figure 2A,C</xref>) is given by:<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝖢𝖴𝖬𝖵𝖠𝖱</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo mathsize="210%" stretchy="false">/</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In <xref ref-type="fig" rid="fig2">Figure 2A</xref>, for each stimulus <inline-formula><mml:math id="inf231"><mml:mi>s</mml:mi></mml:math></inline-formula> we consider the matrix <inline-formula><mml:math id="inf232"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> containing the population OFF responses to stimulus <inline-formula><mml:math id="inf233"><mml:mi>s</mml:mi></mml:math></inline-formula>. We computed the cumulative variance explained as a function of the number of principal components <inline-formula><mml:math id="inf234"><mml:mi>M</mml:mi></mml:math></inline-formula> and then averaged over all stimuli.</p></sec><sec id="s4-3"><title>Cross-validated PCA</title><p>We used cross-validation to estimate the variance of OFF responses to individual stimuli and across stimuli attributable to the stimulus-related component, discarding the component due to trial-to-trial variability (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Specifically, we applied to the calcium activity data the method of cross-validated PCA (cvPCA) developed in <xref ref-type="bibr" rid="bib96">Stringer et al., 2019</xref>. This method provides an unbiased estimate of the stimulus-related variance by computing the covariance between a training and a test set of responses (e.g. two different trials or two different sets of trials) to an identical collection of stimuli. Let <inline-formula><mml:math id="inf235"><mml:msup><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf236"><mml:msup><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> be the <inline-formula><mml:math id="inf237"><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> matrices containing the mean-centered responses to the same <inline-formula><mml:math id="inf238"><mml:mi>C</mml:mi></mml:math></inline-formula> stimuli. We consider the training and test responses to be two distinct trials. We first perform ordinary PCA on the training responses <inline-formula><mml:math id="inf239"><mml:msup><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and find the principal component <inline-formula><mml:math id="inf240"><mml:msubsup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> (<inline-formula><mml:math id="inf241"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>). We then evaluate the cross-validated PCA spectrum <inline-formula><mml:math id="inf242"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> as:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mfrac></mml:mpadded><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>𝐮</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mrow><mml:mo maxsize="128%" minsize="128%">(</mml:mo><mml:mi mathsize="128%">train</mml:mi><mml:mo maxsize="128%" minsize="128%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐗</mml:mi><mml:mrow><mml:mrow><mml:mo maxsize="128%" minsize="128%">(</mml:mo><mml:mi mathsize="128%">test</mml:mi><mml:mo maxsize="128%" minsize="128%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐗</mml:mi><mml:mrow><mml:mo maxsize="128%" minsize="128%">(</mml:mo><mml:mi mathsize="128%">train</mml:mi><mml:mo maxsize="128%" minsize="128%">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>𝐮</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo maxsize="128%" minsize="128%">(</mml:mo><mml:mi mathsize="128%">train</mml:mi><mml:mo maxsize="128%" minsize="128%">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We repeat the procedure for all pairs of trials <inline-formula><mml:math id="inf243"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf244"><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> and average the result over pairs. The cross-validated cumulative variance is finally computed as in <xref ref-type="disp-formula" rid="equ13">Equation (13)</xref>.</p></sec><sec id="s4-4"><title>Correlations between OFF response subspaces</title><p>To quantify the degree of correlation between pairs of OFF responses corresponding to two different stimuli, termed <italic>subspace overlap</italic>, we computed the cosine of the principal angle between the corresponding low-dimensional subspaces (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <xref ref-type="fig" rid="fig3">Figure 3I</xref>). In general, the principal angle <inline-formula><mml:math id="inf245"><mml:msub><mml:mi>θ</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:math></inline-formula> between two subspaces <inline-formula><mml:math id="inf246"><mml:mi>U</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf247"><mml:mi>V</mml:mi></mml:math></inline-formula> corresponds to the largest angle between any two pairs of vectors in <inline-formula><mml:math id="inf248"><mml:mi>U</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf249"><mml:mi>V</mml:mi></mml:math></inline-formula> respectively, and it is defined by <xref ref-type="bibr" rid="bib10">Bjorck and Golub, 1973</xref>; <xref ref-type="bibr" rid="bib52">Knyazev and Argentati, 2002</xref>:<disp-formula id="equ15"><mml:math id="m15"><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:munder><mml:mi>max</mml:mi><mml:mrow><mml:mrow><mml:mi>𝐮</mml:mi><mml:mo>∈</mml:mo><mml:mi>U</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>𝐯</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mrow></mml:munder></mml:mpadded><mml:mo>⁡</mml:mo><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐯</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>To compute the correlations between the OFF responses to stimuli <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> we first identified the first <inline-formula><mml:math id="inf250"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> principal components of the response to stimulus <italic>s</italic><sub>1</sub> and organized them in a <inline-formula><mml:math id="inf251"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> matrix <inline-formula><mml:math id="inf252"><mml:mrow><mml:mi mathvariant="bold">𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We repeated this for stimulus <italic>s</italic><sub>2</sub>, which yielded a matrix <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi mathvariant="bold">𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore the columns of <inline-formula><mml:math id="inf254"><mml:mrow><mml:mi mathvariant="bold">𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf255"><mml:mrow><mml:mi mathvariant="bold">𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> define the two subspaces on which the responses to stimuli <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> live. The cosine of the principal angle between these two subspaces is given by <xref ref-type="bibr" rid="bib10">Bjorck and Golub, 1973</xref>; <xref ref-type="bibr" rid="bib52">Knyazev and Argentati, 2002</xref>:<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="160%" minsize="160%">(</mml:mo><mml:mrow><mml:mi>𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="160%" minsize="160%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf256"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐀</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the largest singular value of a matrix <inline-formula><mml:math id="inf257"><mml:mi mathvariant="bold">𝐀</mml:mi></mml:math></inline-formula>. We note that this procedure directly relates to canonical correlation analysis (CCA; see <xref ref-type="bibr" rid="bib46">Hotelling, 1936</xref>; <xref ref-type="bibr" rid="bib101">Uurtio et al., 2018</xref>). In particular the first principal angle corresponds to the first canonical weight between the subspaces spanned by the columns of <inline-formula><mml:math id="inf258"><mml:mrow><mml:mi mathvariant="bold">𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf259"><mml:mrow><mml:mi mathvariant="bold">𝐐</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib32">Golub and Zha, 1992</xref>; <xref ref-type="bibr" rid="bib10">Bjorck and Golub, 1973</xref>).</p></sec><sec id="s4-5"><title>Controls for subspace overlaps and initial state-peak correlations</title><p>In this section we describe the controls that we used to evaluate the statistical significance of the measures of orthogonality between subspaces spanned by neural activity during OFF responses to different stimuli (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <xref ref-type="fig" rid="fig3">Figure 3I</xref>), and between initial and peak activity vectors for a single stimulus (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). We assessed the significance of the orthogonality between OFF response subspaces across stimuli using two separate controls, which aim at testing for two distinct null hypotheses (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <xref ref-type="fig" rid="fig3">Figure 3I</xref>, <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). The first hypothesis is that small subspace overlaps (i.e. low correlations) between OFF responses to different stimuli may be due to the high number of dimensions of the state-space in which they are embedded. To test for this hypothesis we compared the subspace overlap computed on the trial-averaged activity with the subspace overlaps computed on the trial-averaged activity where the stimulus labels had been shuffled across trials for each pair of stimuli. We shuffled stimulus labels multiple times, resulting in one value of the subspace overlap for each shuffle. For each pair of stimuli, significance levels were then computed as the fraction of shuffles for which the subspace overlap was lower than the subspace overlap for the real data (lower tail test; <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A</xref>).</p><p>Alternatively, small subspace overlaps could be an artifact of the trial-to-trial variability present in the calcium activity data. In fact, for a single stimulus, maximum values of the correlation between two different trials were of the order of 0.2 (<xref ref-type="bibr" rid="bib23">Deneux et al., 2016</xref>). To test for the possibility that small subspace overlaps may be due to trial-to-trial variability, for each pair of stimuli we computed the values of the subspace overlaps by computing the trial-averaged activity on only half of the trials (10 trials), subsampling the set of 10 trials multiple times for each stimulus. This yielded a set of values <inline-formula><mml:math id="inf260"><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>real</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> are the specific stimuli considered and <inline-formula><mml:math id="inf261"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>shuffle</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. We then computed the subspace overlaps between the trial-averaged responses to the same stimulus, but averaged over two different sets of 10 trials each, over multiple permutations of the trials, resulting in a set of values <inline-formula><mml:math id="inf262"><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>shuffle</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf263"><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo rspace="4.2pt">,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the specific stimulus considered and <inline-formula><mml:math id="inf264"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>shuffle</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. For each pair of stimuli <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub>, significance levels were computed using two-tailed t-test and taking the maximum between the p-values given by <inline-formula><mml:math id="inf265"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>real</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>shuffle</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf266"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>real</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>shuffle</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for those stimulus pairs for which <inline-formula><mml:math id="inf267"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>real</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>shuffled</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf268"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>real</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>shuffled</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>:</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, where the bar symbol indicated the mean over shuffles (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2B</xref>).</p><p>The same null hypotheses have been used to test the significance of the orthogonality between initial state and peak state for individual stimuli (<xref ref-type="fig" rid="fig5">Figure 5D</xref>, <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). A procedure analogous to the one outlined above was employed. Here, instead of the subspace overlaps, the quantity of interest is the correlation (scalar product) between the initial and peak state. For the first control shuffled data are obtained by shuffling the labels ‘initial state’ and ‘peak state’ across trials. Significance levels were evaluated as outlined above for the first control (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3A</xref>). To test for the second hypothesis, we computed correlations between activity vectors defined at the same time point, but averaged over two different sets of 10 trials each. For each trial permutations we computed these correlations for all time points belonging to the OFF response (35 time points) and average over time points. Significance level was then assessed as outlined above for the second control (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3B</xref>).</p></sec><sec id="s4-6"><title>Single-cell model for OFF response generation</title><p>In the next section we describe the procedure used to fit the single-cell model to the auditory cortical OFF responses. We consider the single-cell model given by <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>, where <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> represents the initial state of the response of unit <italic>i</italic> to stimulus <italic>s</italic>. Without loss of generality we assume that the dynamic range of the temporal filters, defined as <inline-formula><mml:math id="inf270"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>max</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>min</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula>, is equal to unity, so that <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> represents the firing rate range of neuron <italic>i</italic> for stimulus <italic>s</italic>. If that was not true, i.e. if the single-neuron responses were given by <inline-formula><mml:math id="inf272"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf273"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>max</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>min</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>≠</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> we could always write the responses as <inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf275"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf276"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, formally equivalent to <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>.</p></sec><sec id="s4-7"><title>Fitting the single-cell model</title><p>To fit the single-cell OFF responses <inline-formula><mml:math id="inf277"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, we expressed the single-cell responses on a set of basis functions (<xref ref-type="bibr" rid="bib78">Pillow et al., 2008</xref>).<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the shape and the number of basis function <inline-formula><mml:math id="inf278"><mml:msub><mml:mi>N</mml:mi><mml:mi>basis</mml:mi></mml:msub></mml:math></inline-formula> are predetermined. We choose the functions <inline-formula><mml:math id="inf279"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to be Gaussian functions centered around a value <inline-formula><mml:math id="inf280"><mml:msub><mml:mover accent="true"><mml:mi>t</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> and with a given width <inline-formula><mml:math id="inf281"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf282"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>t</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The problem then consists in finding the coefficients <inline-formula><mml:math id="inf283"><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> that best approximate <xref ref-type="disp-formula" rid="equ17">Equation (17)</xref>. By dividing the left- and right-hand side of <xref ref-type="disp-formula" rid="equ17">Equation (17)</xref> by the firing rate range <inline-formula><mml:math id="inf284"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> we obtain:<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In general the coefficients <inline-formula><mml:math id="inf285"><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> could be fitted independently for each stimulus. However, the single-cell model assumes that the coefficients <inline-formula><mml:math id="inf286"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> do not change across stimuli (see <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>). Therefore, to find the stimulus-independent coefficients <inline-formula><mml:math id="inf287"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that best approximate <xref ref-type="disp-formula" rid="equ18">Equation (18)</xref> across a given set of stimuli, we minimize the mean squared error given by:<disp-formula id="equ19"><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mo>∫</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The minimization of the mean squared error can be solved using linear regression techniques. Suppose we want to fit the population responses to <inline-formula><mml:math id="inf288"><mml:mi>C</mml:mi></mml:math></inline-formula> different stimuli simultaneously. Let <inline-formula><mml:math id="inf289"><mml:msup><mml:mi mathvariant="bold">𝐑</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> be the matrix of size <inline-formula><mml:math id="inf290"><mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> obtained by concatenating the <inline-formula><mml:math id="inf291"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula> matrices <inline-formula><mml:math id="inf292"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> (<inline-formula><mml:math id="inf293"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf294"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf295"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) corresponding to the normalized responses to the <inline-formula><mml:math id="inf296"><mml:mi>C</mml:mi></mml:math></inline-formula> stimuli. Let <inline-formula><mml:math id="inf297"><mml:msup><mml:mi mathvariant="bold">𝐅</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> be the <inline-formula><mml:math id="inf298"><mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>basis</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> matrix obtained by concatenating <inline-formula><mml:math id="inf299"><mml:mi>C</mml:mi></mml:math></inline-formula> times the <inline-formula><mml:math id="inf300"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>basis</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula> matrix <inline-formula><mml:math id="inf301"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐟</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Let <inline-formula><mml:math id="inf302"><mml:mi mathvariant="bold">𝐁</mml:mi></mml:math></inline-formula> be the <inline-formula><mml:math id="inf303"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>basis</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> matrix given by <inline-formula><mml:math id="inf304"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐁</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Then <xref ref-type="disp-formula" rid="equ18">Equation (18)</xref> can be written as:<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐑</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>𝐁𝐅</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>which can be solved using linear regression.</p><p>In order to avoid normalizing by very small values, we fit only the most responding neurons in the population, as quantified by their firing rate range. We set <inline-formula><mml:math id="inf305"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>35</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf306"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>basis</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and we set the number of basis functions to <inline-formula><mml:math id="inf307"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>basis</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>, corresponding to the minimal number of basis functions sufficient to reach the highest cross-validated goodness of fit.</p></sec><sec id="s4-8"><title>The network model</title><p>We consider a recurrent network model of <inline-formula><mml:math id="inf308"><mml:mi>N</mml:mi></mml:math></inline-formula> randomly coupled linear rate units. Each unit <inline-formula><mml:math id="inf309"><mml:mi>i</mml:mi></mml:math></inline-formula> is described by the time-dependent variable <inline-formula><mml:math id="inf310"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which represents the difference between the firing rate of neuron <inline-formula><mml:math id="inf311"><mml:mi>i</mml:mi></mml:math></inline-formula> at time <inline-formula><mml:math id="inf312"><mml:mi>t</mml:mi></mml:math></inline-formula> and its baseline firing level. The equation governing the temporal dynamics of the network reads:<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mrow><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf313"><mml:mi>τ</mml:mi></mml:math></inline-formula> represents the time constant (fixed to unity), and <inline-formula><mml:math id="inf314"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the effective synaptic strength from neuron <inline-formula><mml:math id="inf315"><mml:mi>j</mml:mi></mml:math></inline-formula> to neuron <inline-formula><mml:math id="inf316"><mml:mi>i</mml:mi></mml:math></inline-formula>. The system has only one fixed point corresponding to <inline-formula><mml:math id="inf317"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf318"><mml:mi>i</mml:mi></mml:math></inline-formula>. To have stable dynamics, we require that the real part of the eigenvalues of the connectivity matrix <inline-formula><mml:math id="inf319"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> is smaller than unity, that is, <inline-formula><mml:math id="inf320"><mml:mrow><mml:msub><mml:mrow><mml:mo maxsize="160%" minsize="160%">(</mml:mo><mml:mrow><mml:mi>ℜ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>𝔢</mml:mi><mml:mo>⁢</mml:mo><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="160%" minsize="160%">)</mml:mo></mml:mrow><mml:mi>max</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. We represent each stimulus as the state of the system reached at the end of stimulus presentation, which we denote by the vector <inline-formula><mml:math id="inf321"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. We moreover assume that during the OFF response the network receives no external input. The OFF response to the stimulus associated with the state <inline-formula><mml:math id="inf322"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> therefore corresponds to the network dynamics starting from the initial condition <inline-formula><mml:math id="inf323"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>.</p></sec><sec id="s4-9"><title>Fitting the network model</title><p>In this section we describe the procedure we used for fitting a linear recurrent network model (<xref ref-type="disp-formula" rid="equ21">Equation (21)</xref>) to the auditory cortical data using ridge and reduced-rank ridge regression. To fit the network model to the responses to <inline-formula><mml:math id="inf324"><mml:mi>C</mml:mi></mml:math></inline-formula> stimuli, we first concatenate the <inline-formula><mml:math id="inf325"><mml:mi>C</mml:mi></mml:math></inline-formula> matrices <inline-formula><mml:math id="inf326"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf327"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf328"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf329"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) containing the neural responses to stimulus <italic>s</italic> across <inline-formula><mml:math id="inf330"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> timesteps and <inline-formula><mml:math id="inf331"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> neurons (or PC dimensions) along the first dimension, obtaining a matrix <inline-formula><mml:math id="inf332"><mml:mrow><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> contains the neural activity across <inline-formula><mml:math id="inf333"><mml:mi>C</mml:mi></mml:math></inline-formula> stimuli, <inline-formula><mml:math id="inf334"><mml:mi>T</mml:mi></mml:math></inline-formula> time steps, and <inline-formula><mml:math id="inf335"><mml:mi>D</mml:mi></mml:math></inline-formula> neurons or PC dimensions. We then fit the network model <inline-formula><mml:math id="inf336"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi mathvariant="bold">𝐗</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> by first computing from the data the velocity of the trajectory as<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Both ridge and reduced-rank ridge regression aim at minimizing the mean squared error <inline-formula><mml:math id="inf337"><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi mathvariant="bold">𝐗</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> subject to different constraints, which are described below. Since ridge regression involves computationally expensive matrix inversion, we first reduced the dimensionality of the original data set by using PCA. Unless otherwise stated, we kept a number of PC components equal to K = 100 for the fit of individual stimuli (<xref ref-type="fig" rid="fig3">Figure 3G,H</xref>, <xref ref-type="fig" rid="fig5">Figure 5A–C</xref>, <xref ref-type="fig" rid="fig8">Figure 8</xref>, <xref ref-type="fig" rid="fig7">Figure 7</xref>) and for the fit of all stimuli together (<xref ref-type="fig" rid="fig3">Figure 3I</xref>, <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig7">Figure 7C</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>; K = 100 principal components sufficed to explain more than 90% of the variance of the responses to all stimuli together). As a result, the data matrix <inline-formula><mml:math id="inf338"><mml:mrow><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>×</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> contains the activity across <inline-formula><mml:math id="inf339"><mml:mi>T</mml:mi></mml:math></inline-formula> time bins and across all <inline-formula><mml:math id="inf340"><mml:mi>K</mml:mi></mml:math></inline-formula> dimensions for a number <inline-formula><mml:math id="inf341"><mml:mi>C</mml:mi></mml:math></inline-formula> of stimuli.</p></sec><sec id="s4-10"><title>Ridge regression</title><p>Ridge regression aims at determining the connectivity matrix <inline-formula><mml:math id="inf342"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> that minimizes the mean squared error <inline-formula><mml:math id="inf343"><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi mathvariant="bold">𝐗</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> with a penalty for large entries of the matrix <inline-formula><mml:math id="inf344"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>, so that the cost function to minimize is given by <inline-formula><mml:math id="inf345"><mml:mrow><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi mathvariant="bold">𝐗</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf346"><mml:mi>λ</mml:mi></mml:math></inline-formula> is a hyperparameter of the model. We can write the ridge regression optimization problem as:<disp-formula id="equ23"><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula>where we defined <inline-formula><mml:math id="inf347"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>λ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mn/><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf348"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mi>λ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msqrt><mml:mi>λ</mml:mi></mml:msqrt><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The solution to <xref ref-type="disp-formula" rid="equ23">Equation (23)</xref> is given by:<disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>𝐉</mml:mi><mml:mi>λ</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mi>𝐈</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>𝐗</mml:mi><mml:mi>λ</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐗</mml:mi><mml:mi>λ</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>𝐗</mml:mi><mml:mi>λ</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>λ</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This procedure was used for fits shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>, and <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></sec><sec id="s4-11"><title>Reduced-rank ridge regression</title><p>Reduced-rank regression aims at minimizing the mean squared error <inline-formula><mml:math id="inf349"><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi mathvariant="bold">𝐗</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> under a rank constraint on the matrix <inline-formula><mml:math id="inf350"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf351"><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>rank</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐉</mml:mi></mml:mrow><mml:mo>≤</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf352"><mml:mi>R</mml:mi></mml:math></inline-formula> is a hyperparameter of the model (<xref ref-type="bibr" rid="bib48">Izenman, 1975</xref>; <xref ref-type="bibr" rid="bib22">Davies and Tso, 1982</xref>). Here we combined reduced-rank and ridge regression in the same framework. The reduced-rank ridge regression optimization problem with hyperparameters <inline-formula><mml:math id="inf353"><mml:mi>R</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf354"><mml:mi>λ</mml:mi></mml:math></inline-formula> can be therefore written as (<xref ref-type="bibr" rid="bib68">Mukherjee et al., 2015</xref>):<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>≤</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To solve <xref ref-type="disp-formula" rid="equ25">Equation (25)</xref> we consider the solution to the ridge regression problem given by <xref ref-type="disp-formula" rid="equ24">Equation (24)</xref>. If the matrix <inline-formula><mml:math id="inf355"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mi>λ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>λ</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> has SVD given by <inline-formula><mml:math id="inf356"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐗</mml:mi><mml:mi>λ</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>λ</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, then it can be shown that the solution to the reduced-rank ridge regression problem given by <xref ref-type="disp-formula" rid="equ25">Equation (25)</xref> can be written as:<disp-formula id="equ26"><mml:math id="m26"><mml:mrow><mml:msubsup><mml:mi>𝐉</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>𝐉</mml:mi><mml:mi>λ</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>R</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>𝐕</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>𝐕</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We note that each term in the sum of <xref ref-type="disp-formula" rid="equ26">Equation (26)</xref> has unit rank, so that the resulting matrix <inline-formula><mml:math id="inf357"><mml:msubsup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula> has rank equal to or less than <inline-formula><mml:math id="inf358"><mml:mi>R</mml:mi></mml:math></inline-formula>.</p><p>This procedure was used for fits shown in <xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig7">Figure 7</xref>, <xref ref-type="fig" rid="fig8">Figure 8</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, and <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>.</p></sec><sec id="s4-12"><title>Selection of hyperparameters for ridge regression</title><p>To select the value of the hyperparameter <inline-formula><mml:math id="inf359"><mml:mi>λ</mml:mi></mml:math></inline-formula>, we fitted the network model to the data and computed the goodness of fit as the coefficient of determination <inline-formula><mml:math id="inf360"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using cross-validation. We then selected the value of <inline-formula><mml:math id="inf361"><mml:mi>λ</mml:mi></mml:math></inline-formula> which maximized the goodness of fit.</p></sec><sec id="s4-13"><title>Selection of hyperparameters for reduced-rank ridge regression</title><p>To select the values of the hyperparameters <inline-formula><mml:math id="inf362"><mml:mi>λ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf363"><mml:mi>R</mml:mi></mml:math></inline-formula>, we fitted the network model to the data with hyperparameters <inline-formula><mml:math id="inf364"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and computed the goodness of fit as the coefficient of determination <inline-formula><mml:math id="inf365"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using cross-validation. We repeated the process for a range of values of <inline-formula><mml:math id="inf366"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We observed that, independent of the value of <inline-formula><mml:math id="inf367"><mml:mi>λ</mml:mi></mml:math></inline-formula>, the goodness of fit as a function of the rank <inline-formula><mml:math id="inf368"><mml:mi>R</mml:mi></mml:math></inline-formula> saturates at a particular value of the rank <inline-formula><mml:math id="inf369"><mml:msup><mml:mi>R</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula>, but does not exhibit a clear maximum. We took the value <inline-formula><mml:math id="inf370"><mml:msup><mml:mi>R</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> as the minimal rank hyperparameter, while we defined the best ridge parameter as <inline-formula><mml:math id="inf371"><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>argmax</mml:mi><mml:mi>λ</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p><p>For both ridge and reduced-rank ridge regression, we used <inline-formula><mml:math id="inf372"><mml:mi>K</mml:mi></mml:math></inline-formula>-fold cross-validation, with <inline-formula><mml:math id="inf373"><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>. When fitting multiple stimuli at once, for each stimulus we partitioned the temporal activity into <inline-formula><mml:math id="inf374"><mml:mi>K</mml:mi></mml:math></inline-formula> chunks, resulting in a total of <inline-formula><mml:math id="inf375"><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> chunks. At the <inline-formula><mml:math id="inf376"><mml:mi>i</mml:mi></mml:math></inline-formula>-th iteration of the cross-validation procedure, we leave out the <inline-formula><mml:math id="inf377"><mml:mi>i</mml:mi></mml:math></inline-formula>-th partition for each stimulus to construct the training set (consisting of <inline-formula><mml:math id="inf378"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:math></inline-formula> chunks) and test the trained model on the remaining <inline-formula><mml:math id="inf379"><mml:mi>C</mml:mi></mml:math></inline-formula> folds.</p><p>In <xref ref-type="fig" rid="fig4">Figure 4A,B</xref>, the temporal window considered for the fit was extended from 350 ms to 600 ms to include the decay to baseline of the OFF responses, thus obtaining stable eigenvalues. The extension of the temporal window was possible only for the 1 s long stimuli (<inline-formula><mml:math id="inf380"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:math></inline-formula>), since the length of the temporal window following stimulus offset for the 2 s stimuli was limited to approximately 380 ms by the length of the neural recordings.</p></sec><sec id="s4-14"><title>Control data sets</title><p>To evaluate whether the fitted network model captured nontrivial collective dynamics of auditory cortical OFF responses, we followed the approach introduced in <xref ref-type="bibr" rid="bib25">Elsayed and Cunningham, 2017</xref>. We first computed the goodness of fit (as quantified by the coefficient of determination <inline-formula><mml:math id="inf381"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>), then repeated the model fitting on control data sets which kept no additional structure than the one defined by correlations across time, neurons and stimuli of the original neural responses. We found that the goodness of fit obtained from fitting the model to the original data set was significantly higher than the one obtained from fitting the control data sets (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>), confirming that the recurrent network model captured nontrivial collective dynamics in the data beyond the correlations across time, neurons and stimuli.</p><p>We generated the control data sets using a recent method based on a maximum entropy model (<xref ref-type="bibr" rid="bib86">Savin and Tkačik, 2017</xref>) and described in <xref ref-type="bibr" rid="bib25">Elsayed and Cunningham, 2017</xref>. This method, termed Tensor Maximum Entropy, allowed us to build surrogate data sets that are maximally random (entropy maximization), but constrained in a way that their marginal means and covariances are equal to the means and covariances of the original data set.</p></sec><sec id="s4-15"><title>Marginal means and covariances</title><p>Let the temporal activity along all <inline-formula><mml:math id="inf382"><mml:mi>K</mml:mi></mml:math></inline-formula> dimensions for all <inline-formula><mml:math id="inf383"><mml:mi>C</mml:mi></mml:math></inline-formula> stimuli be organized in a tensor <inline-formula><mml:math id="inf384"><mml:mrow><mml:mi mathvariant="bold">𝐙</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The mean tensor <inline-formula><mml:math id="inf385"><mml:mi mathvariant="bold">𝐌</mml:mi></mml:math></inline-formula> is defined as the tensor that makes all the marginal means of <inline-formula><mml:math id="inf386"><mml:mi mathvariant="bold">𝐙</mml:mi></mml:math></inline-formula> vanish. Specifically, if <inline-formula><mml:math id="inf387"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐙</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐙</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐌</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the tensor <inline-formula><mml:math id="inf388"><mml:mi mathvariant="bold">𝐌</mml:mi></mml:math></inline-formula> is such that:<disp-formula id="equ27"><mml:math id="m27"><mml:mrow><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:msub><mml:mover accent="true"><mml:mi>𝐙</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:msub><mml:mover accent="true"><mml:mi>𝐙</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:mover accent="true"><mml:mi>𝐙</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The marginal covariances of the tensor <inline-formula><mml:math id="inf389"><mml:mover accent="true"><mml:mi mathvariant="bold">𝐙</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula> across times, neural dimensions, and stimuli are therefore defined as:<disp-formula id="equ28"><mml:math id="m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec><sec id="s4-16"><title>Tensor maximum entropy method</title><p>The method generates the desired number of surrogate data sets <inline-formula><mml:math id="inf390"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐒</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mo>×</mml:mo><mml:mi>K</mml:mi><mml:mo>×</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Each of these surrogates is randomly drawn from a probability distribution that assumes a priori no structure apart from that expected from the marginal means and covariances of the original data. Let µ, <inline-formula><mml:math id="inf391"><mml:msup><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf392"><mml:msup><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>K</mml:mi></mml:msup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf393"><mml:msup><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>C</mml:mi></mml:msup></mml:math></inline-formula> be the marginal means and covariances of surrogate <inline-formula><mml:math id="inf394"><mml:mi mathvariant="bold">𝐒</mml:mi></mml:math></inline-formula>. The method computes the probability <inline-formula><mml:math id="inf395"><mml:mrow><mml:mi>P</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐒</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> over the surrogates that maximizes the entropy function<disp-formula id="equ29"><label>(29)</label><mml:math id="m29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mtext> with </mml:mtext><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></disp-formula>subject to the constraints<disp-formula id="equ30"><label>(30)</label><mml:math id="m30"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>𝔼</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>𝐌</mml:mi></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>𝔼</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>𝔼</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>K</mml:mi></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>K</mml:mi></mml:msup></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>𝔼</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi mathvariant="normal">Λ</mml:mi><mml:mi>C</mml:mi></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mi>C</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf396"><mml:mrow><mml:msub><mml:mi>𝔼</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the expectation over the probability density <inline-formula><mml:math id="inf397"><mml:mi>P</mml:mi></mml:math></inline-formula>. We used three types of surrogate data sets, denoted as T, TK, and TKC. All the three types of surrogates obey to the first constraint in <xref ref-type="disp-formula" rid="equ30">Equation (30)</xref> on the marginal means. In addition, surrogates of type T obey the constraint on the time covariances, surrogates of type TK on time and dimension covariance, while surrogates TKC obey all the three covariance constraints.</p></sec><sec id="s4-17"><title>Analysis of the transient channels</title><p>In this section, we provide details on the analysis of the structure of the transient channels obtained from fitting the network model to OFF responses to individual stimuli using reduce-rank regression (<xref ref-type="fig" rid="fig7">Figure 7</xref>, see Materials and methods, Section 'Fitting the network model'). Let <inline-formula><mml:math id="inf398"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> be the connectivity matrix resulting from fitting the network model to the responses to all stimuli at once, and <inline-formula><mml:math id="inf399"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> the connectivity obtained from fitting the model to the response to stimulus <italic>s</italic>. Before fitting both matrices <inline-formula><mml:math id="inf400"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf401"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, we reduced the dimensionality of the responses to the first 100 principal components. We set the value of the rank parameter to <inline-formula><mml:math id="inf402"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>70</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf403"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> respectively for <inline-formula><mml:math id="inf404"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf405"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Using the SVD, we can write the matrices <inline-formula><mml:math id="inf406"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> as:<disp-formula id="equ31"><label>(31)</label><mml:math id="m31"><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐉</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐕</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf407"><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf408"><mml:msup><mml:mi mathvariant="bold">𝐕</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> contain respectively the <inline-formula><mml:math id="inf409"><mml:msub><mml:mi>R</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula> right and left connectivity vectors as columns (see <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>), while <inline-formula><mml:math id="inf410"><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> contains the norms of <inline-formula><mml:math id="inf411"><mml:msup><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> on the diagonal (see <xref ref-type="disp-formula" rid="equ6">Equation (6)</xref>). The transient dynamics elicited by stimulus <italic>s</italic> has a strong component along the state-space dimensions specified by the right connectivity vectors <inline-formula><mml:math id="inf412"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo>;</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (columns of <inline-formula><mml:math id="inf413"><mml:msup><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>; see also <xref ref-type="disp-formula" rid="equ44">Equation (43)</xref>). We therefore define the overlap between the transient channels (<italic>connectivity overlaps</italic>) corresponding to pairs of stimuli <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) as the principal angle between the subspaces defined by <inline-formula><mml:math id="inf414"><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf415"><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ15 equ16">Equations (15 and 16)</xref>). We show that the structure of the connectivity overlaps (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) matched well with the structure of the subspace overlaps (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) across pairs of stimuli in <xref ref-type="fig" rid="fig7">Figure 7B</xref>.</p><p>To test whether the connectivity fitted on all stimuli at once <inline-formula><mml:math id="inf416"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> consisted of the sum of low-rank transient coding channels, we defined the matrix <inline-formula><mml:math id="inf417"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula> as the sum of the individual transient channels for all stimuli (see <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>):<disp-formula id="equ32"><mml:math id="m32"><mml:mrow><mml:msub><mml:mi>𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐕</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐕</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐕</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>We then compared the cross-validated goodness of fit of the population OFF responses using the full matrix <inline-formula><mml:math id="inf418"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Full</mml:mi></mml:msub></mml:math></inline-formula> and the matrix <inline-formula><mml:math id="inf419"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>Sum</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig7">Figure 7C</xref>).</p><p>In <xref ref-type="fig" rid="fig7">Figure 7</xref>, when fitting individual stimuli, the ridge and rank hyperparameters have been set respectively to <inline-formula><mml:math id="inf420"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf421"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, which correspond to the values that maximize the agreement (coefficient of determination) between the connectivity overlaps (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) and the subspace overlaps (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). For these values the coefficient of determination between the transient channel overlaps and the subspace overlaps is &gt;0.7.</p></sec><sec id="s4-18"><title>Analysis of the network model</title><p>In this section we provide a detailed mathematical analysis of the network model given by <xref ref-type="disp-formula" rid="equ21">Equation (21)</xref><disp-formula id="equ33"><mml:math id="m33"><mml:mrow><mml:mrow><mml:mrow><mml:mi>τ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Specifically, we derive the conditions on the network components (i.e. connectivity spectra, connectivity vectors, and initial conditions) to produce low-dimensional, transiently amplified OFF responses in networks with low-rank connectivity. We then focus on the specific case of rotational channels in the connectivity.</p></sec><sec id="s4-19"><title>Normal and non-normal connectivity matrices</title><p>In this section, we summarize the relationship between amplified OFF responses and non-normal connectivity matrices in linear recurrent networks previously reported in <xref ref-type="bibr" rid="bib100">Trefethen and Embree, 2005</xref>; <xref ref-type="bibr" rid="bib42">Hennequin et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>. To characterize the amplification of OFF responses we focus on the temporal dynamics of the distance from baseline, defined as the norm of the population activity vector <inline-formula><mml:math id="inf422"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib43">Hennequin et al., 2014</xref>). The network generates an amplified OFF response to the stimulus associated with the initial condition <inline-formula><mml:math id="inf423"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> when the value of <inline-formula><mml:math id="inf424"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula> transiently increases before decaying to its asymptotic value <inline-formula><mml:math id="inf425"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Note that having a transiently increasing value of the distance from baseline implies that the OFF response <inline-formula><mml:math id="inf426"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of at least one unit displays non-monotonic temporal dynamics. Importantly, the transient behavior of <inline-formula><mml:math id="inf427"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula> depends on the stimulus through <inline-formula><mml:math id="inf428"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, and on the properties of the connectivity matrix <inline-formula><mml:math id="inf429"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>, in particular on the relationship between its eigenvectors (<xref ref-type="bibr" rid="bib100">Trefethen and Embree, 2005</xref>).</p><p>Connectivity matrices for which the eigenvectors are orthogonal to each other are called <italic>normal</italic> matrices and they are formally defined as matrices <inline-formula><mml:math id="inf430"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> that satisfy <inline-formula><mml:math id="inf431"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐉𝐉</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐉</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. In networks with normal connectivity, any stimulus <inline-formula><mml:math id="inf432"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> evokes an OFF response for which the distance from baseline decays monotonically to zero. Such networks thus cannot produce amplified OFF responses, as defined by a transiently increasing <inline-formula><mml:math id="inf433"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula>. Note that any symmetric matrix is normal.</p><p>On the other hand, connectivity matrices for which some eigenvectors are not mutually orthogonal are called <italic>non-normal</italic> (<xref ref-type="bibr" rid="bib100">Trefethen and Embree, 2005</xref>), and they consist of all connectivity <inline-formula><mml:math id="inf434"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> for which <inline-formula><mml:math id="inf435"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐉𝐉</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>≠</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐉</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. It is well known that non-normal networks can lead to transiently increasing values of <inline-formula><mml:math id="inf436"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula>, therefore producing amplified OFF responses. However, the non-normality of the network connectivity <inline-formula><mml:math id="inf437"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> constitutes only a necessary, but not a sufficient condition for the generation of amplified responses.</p></sec><sec id="s4-20"><title>Sufficient condition for amplified OFF responses</title><p>In this section we identify the necessary and sufficient condition for the generation of amplified OFF responses in linear recurrent networks. To find the necessary and sufficient condition for amplified responses, we start by writing the differential equation for the dynamics of the distance from baseline as (<xref ref-type="bibr" rid="bib73">Neubert and Caswell, 1997</xref>; <xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>):<disp-formula id="equ34"><label>(33)</label><mml:math id="m34"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>𝐫</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>𝐫</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>𝐫</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mi>𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>𝐫</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>𝐫</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mrow><mml:mo rspace="22.5pt">,</mml:mo><mml:mrow><mml:msub><mml:mi>𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>𝐉</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>𝐉</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf438"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> denotes the symmetric part of the connectivity <inline-formula><mml:math id="inf439"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>. A linear recurrent network exhibits amplified responses when the rate of change of the distance from baseline, <inline-formula><mml:math id="inf440"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>, takes positive values at time <inline-formula><mml:math id="inf441"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. The right-hand side of <xref ref-type="disp-formula" rid="equ34">Equation (33)</xref> takes its largest value when the initial condition <inline-formula><mml:math id="inf442"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is aligned with the eigenvector of <inline-formula><mml:math id="inf443"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> associated with the largest eigenvalue <inline-formula><mml:math id="inf444"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In this case, the rate of change of the distance from baseline at time <inline-formula><mml:math id="inf445"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> takes the value <inline-formula><mml:math id="inf446"><mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. From <xref ref-type="disp-formula" rid="equ34">Equation (33)</xref> it can be shown that the necessary and sufficient condition for the generation of amplified responses in a recurrent networks with connectivity <inline-formula><mml:math id="inf447"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> is given by<disp-formula id="equ35"><label>(34)</label><mml:math id="m35"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>max</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This criterion defines two classes of networks based on the properties of the connectivity matrix: networks in which amplified responses cannot be evoked by any stimulus, and networks able to generate amplified responses to at least one stimulus.</p></sec><sec id="s4-21"><title>Low-rank networks</title><p>In the following section we examine OFF dynamics in networks with low-rank connectivity of the form given by <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref>:<disp-formula id="equ36"><label>(35)</label><mml:math id="m36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We first show that such connectivity directly constraints the network dynamics to a low-dimensional subspace. We then derive the conditions for the stability and amplification of OFF responses. Finally we apply these results to the specific case of low-rank rotational channels as in <xref ref-type="disp-formula" rid="equ5">Equation (5)</xref>.</p></sec><sec id="s4-22"><title>Low-dimensional dynamics</title><p>Here we study the dynamics of the population activity vector for a unit-rank network (<inline-formula><mml:math id="inf448"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) and for a general network with rank-<inline-formula><mml:math id="inf449"><mml:mi>R</mml:mi></mml:math></inline-formula> connectivity structure. We consider low-rank networks in which the initial state is set to <inline-formula><mml:math id="inf450"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and no external input acts on the system at later times <inline-formula><mml:math id="inf451"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. By construction, the autonomous dynamics generated by low-rank networks are constrained by the rank <inline-formula><mml:math id="inf452"><mml:mi>R</mml:mi></mml:math></inline-formula> of the connectivity matrix and are therefore low-dimensional when <inline-formula><mml:math id="inf453"><mml:mrow><mml:mi>R</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>.</p><p>We first illustrate the linear dynamics in the case of a unit-rank connectivity (<inline-formula><mml:math id="inf454"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), given by<disp-formula id="equ37"><label>(36)</label><mml:math id="m37"><mml:mrow><mml:mrow><mml:mi>𝐉</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with <inline-formula><mml:math id="inf455"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> of unit norm. The vectors <inline-formula><mml:math id="inf456"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf457"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> are respectively the right and left eigenvectors of <inline-formula><mml:math id="inf458"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>, and in the following analysis we refer to them respectively as the right and left connectivity vectors. In this case, the dynamics following the initial state <inline-formula><mml:math id="inf459"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> can be explicitly computed as the product between the time-dependent propagator of the dynamics, given by <inline-formula><mml:math id="inf460"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐏</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and the initial condition <inline-formula><mml:math id="inf461"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib3">Arnold, 1973</xref>; <xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>):<disp-formula id="equ38"><label>(37)</label><mml:math id="m38"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>𝐏</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:mi>𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>By expanding the exponential matrix <inline-formula><mml:math id="inf462"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in power series, we can write the propagator for the unit-rank dynamics as:<disp-formula id="equ39"><label>(38)</label><mml:math id="m39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mi>λ</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">(</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>λ</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf463"><mml:mi>λ</mml:mi></mml:math></inline-formula> is the only nonzero eigenvalue of <inline-formula><mml:math id="inf464"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>, given by<disp-formula id="equ40"><label>(39)</label><mml:math id="m40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>As a result, the full dynamics in the case of rank-1 connectivity structure can be written as:<disp-formula id="equ41"><label>(40)</label><mml:math id="m41"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where<disp-formula id="equ42"><label>(41)</label><mml:math id="m42"><mml:mrow><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo rspace="4.2pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Since <inline-formula><mml:math id="inf465"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is the right eigenvector of <inline-formula><mml:math id="inf466"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> corresponding to <inline-formula><mml:math id="inf467"><mml:mi>λ</mml:mi></mml:math></inline-formula>, from <xref ref-type="disp-formula" rid="equ41">Equation (40)</xref> we note that, when <inline-formula><mml:math id="inf468"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is fully aligned with <inline-formula><mml:math id="inf469"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> the dynamics are one-dimensional and exhibit a monotonic decay along the same dimension. Instead, when the initial state is not fully aligned with <inline-formula><mml:math id="inf470"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, the dynamics are confined to the plane defined by <inline-formula><mml:math id="inf471"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf472"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. In this case, while the component of the dynamics along <inline-formula><mml:math id="inf473"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> decays exponentially as a function of time, the component along the direction of <inline-formula><mml:math id="inf474"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> increases initially in proportion to the value of its norm, <inline-formula><mml:math id="inf475"><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow></mml:math></inline-formula> (since at time <inline-formula><mml:math id="inf476"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf477"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). Eventually, the activity decays to its asymptotic value given by <inline-formula><mml:math id="inf478"><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="normal">∞</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn/></mml:mrow></mml:math></inline-formula>. Therefore in a unit-rank network the dynamics draw a neural trajectory that explores at most two-dimensions in the state space.</p><p>These observations can be extended to the general case of rank-<inline-formula><mml:math id="inf479"><mml:mi>R</mml:mi></mml:math></inline-formula> connectivity matrices. For simplicity we rewrite <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> as<disp-formula id="equ43"><label>(42)</label><mml:math id="m43"><mml:mrow><mml:mrow><mml:mi>𝐉</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>𝐔𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the matrices <inline-formula><mml:math id="inf480"><mml:mi mathvariant="bold">𝐔</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf481"><mml:mi mathvariant="bold">𝐕</mml:mi></mml:math></inline-formula> contain respectively the <inline-formula><mml:math id="inf482"><mml:mi>R</mml:mi></mml:math></inline-formula> right and left connectivity vectors as columns. Writing the connectivity matrix in this form is always possible by applying the SVD on <inline-formula><mml:math id="inf483"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>. The SVD allows us to write the connectivity matrix as <inline-formula><mml:math id="inf484"><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐒𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf485"><mml:mrow><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐒</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf486"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">𝐔</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐕</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow></mml:math></inline-formula>. In particular, this implies the norm of each left connectivity vector <inline-formula><mml:math id="inf487"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is unity, while the right connectivity vectors <inline-formula><mml:math id="inf488"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> are not normalized.</p><p>Following steps similar to <xref ref-type="disp-formula" rid="equ39">Equation (38)</xref>, the linear dynamics evoked by the initial state <inline-formula><mml:math id="inf489"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> can be written as<disp-formula id="equ44"><label>(43)</label><mml:math id="m44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">(</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we defined the <inline-formula><mml:math id="inf490"><mml:mi>R</mml:mi></mml:math></inline-formula>-dimensional column vector<disp-formula id="equ45"><label>(44)</label><mml:math id="m45"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝐚</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">[</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mi>𝐈</mml:mi></mml:mrow><mml:mo maxsize="120%" minsize="120%">]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>in analogy with <xref ref-type="disp-formula" rid="equ41">Equation (40)</xref>. Therefore, in the case of rank-<inline-formula><mml:math id="inf491"><mml:mi>R</mml:mi></mml:math></inline-formula> connectivity matrix, the dynamics evolve in a <inline-formula><mml:math id="inf492"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>-dimensional space determined by the initial state <inline-formula><mml:math id="inf493"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and the <inline-formula><mml:math id="inf494"><mml:mi>R</mml:mi></mml:math></inline-formula> right connectivity vectors <inline-formula><mml:math id="inf495"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (columns of <inline-formula><mml:math id="inf496"><mml:mi mathvariant="bold">𝐔</mml:mi></mml:math></inline-formula>). <xref ref-type="disp-formula" rid="equ45">Equation (44)</xref> shows that the dynamics of a rank-<inline-formula><mml:math id="inf497"><mml:mi>R</mml:mi></mml:math></inline-formula> system are determined by the matrix of scalar products between left and right connectivity vectors, which we refer to as the <italic>overlap matrix</italic> (<xref ref-type="bibr" rid="bib89">Schuessler et al., 2020</xref>; <xref ref-type="bibr" rid="bib6">Beiran et al., 2020</xref>)<disp-formula id="equ46"><label>(45)</label><mml:math id="m46"><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We conclude that low-rank connectivity matrices of the form given by <xref ref-type="disp-formula" rid="equ3">Equation (3)</xref> with <inline-formula><mml:math id="inf498"><mml:mrow><mml:mi>R</mml:mi><mml:mo>≪</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> generate low-dimensional dynamics that explore at most <inline-formula><mml:math id="inf499"><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> dimensions.</p></sec><sec id="s4-23"><title>Conditions for stability and amplification of OFF responses in low-rank networks</title><p>In this paragraph we examine the conditions required to generate stable amplified dynamics in networks with low-rank connectivity <inline-formula><mml:math id="inf500"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> and initial state <inline-formula><mml:math id="inf501"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. Specifically, two sets of conditions need to be satisfied. The first set of conditions is directly derived by applying the general criterion for stable amplified dynamics given by <xref ref-type="disp-formula" rid="equ35">Equation (34)</xref> to low-rank networks, which effectively constrains the connectivity <inline-formula><mml:math id="inf502"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> through the relative arrangement of the connectivity vectors <inline-formula><mml:math id="inf503"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf504"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (<inline-formula><mml:math id="inf505"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>). When this criterion is satisfied, amplified dynamics can be generated only if the initial condition <inline-formula><mml:math id="inf506"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is aligned with specific directions in the state-space. We thus examine a second set of conditions on the initial state <inline-formula><mml:math id="inf507"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> for which amplified trajectories can be evoked, and express these conditions in terms of relationship between <inline-formula><mml:math id="inf508"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and the modes <inline-formula><mml:math id="inf509"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>-<inline-formula><mml:math id="inf510"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>. As before, without loss of generality, we assume that the norm of the vectors <inline-formula><mml:math id="inf511"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is equal to one, while the norm of the vectors <inline-formula><mml:math id="inf512"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> can vary.</p></sec><sec id="s4-24"><title>Conditions on the modes <inline-formula><mml:math id="inf513"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>-<inline-formula><mml:math id="inf514"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula></title><p>We first consider a network with unit-rank connectivity <inline-formula><mml:math id="inf515"><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf516"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> of unit norm. In unit-rank networks, the dynamics is stable only if the nonzero eigenvalue <inline-formula><mml:math id="inf517"><mml:mi>λ</mml:mi></mml:math></inline-formula> is smaller than one. From <xref ref-type="disp-formula" rid="equ40">Equation (39)</xref> this yields the stability condition <disp-formula id="equ47"><label>(46)</label><mml:math id="m47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The condition for the generation of amplified responses given by <xref ref-type="disp-formula" rid="equ35">Equation (34)</xref> can be derived in terms of <inline-formula><mml:math id="inf518"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf519"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> by computing the eigenvalues of the symmetric part of the connectivity, <inline-formula><mml:math id="inf520"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. The matrix <inline-formula><mml:math id="inf521"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> is of rank two, and has in general two nonzero eigenvalues, given by:<disp-formula id="equ48"><mml:math id="m48"><mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>max</mml:mi><mml:mo>,</mml:mo><mml:mi>min</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>±</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Therefore the condition for amplified OFF responses <xref ref-type="disp-formula" rid="equ35">Equation (34)</xref> can be written in terms of the length of the vector <inline-formula><mml:math id="inf522"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> as<disp-formula id="equ49"><label>(48)</label><mml:math id="m49"><mml:mrow><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Previous work has shown that amplification in a unit-rank network can take arbitrarily large values only if <inline-formula><mml:math id="inf523"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>). As a result, stable and unbounded amplified dynamics can be generated in a unit-rank network if and only if the norm of <inline-formula><mml:math id="inf524"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is sufficiently large (<xref ref-type="disp-formula" rid="equ49">Equation (48)</xref>) and the correlation between the connectivity vectors is positive and sufficiently small (<xref ref-type="disp-formula" rid="equ47">Equation (46)</xref>).</p><p>The conditions for stability and amplification derived for a rank-1 network can be implicitly generalized to a rank-<inline-formula><mml:math id="inf525"><mml:mi>R</mml:mi></mml:math></inline-formula> network model, using the fact that the nonzero eigenvalues <inline-formula><mml:math id="inf526"><mml:mi>λ</mml:mi></mml:math></inline-formula> of the low-rank connectivity matrix <inline-formula><mml:math id="inf527"><mml:mrow><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐔𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf528"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> is a <inline-formula><mml:math id="inf529"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> matrix) are equal to the nonzero eigenvalues of its overlap matrix <inline-formula><mml:math id="inf530"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐔</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> (where <inline-formula><mml:math id="inf531"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is a <inline-formula><mml:math id="inf532"><mml:mrow><mml:mi>R</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> matrix) (<xref ref-type="bibr" rid="bib71">Nakatsukasa, 2019</xref>):<disp-formula id="equ50"><mml:math id="m50"><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>eig</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>𝐉</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>eig</mml:mi><mml:mrow><mml:mi>λ</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Therefore, the condition for stability can be implicitly written in terms of the nonzero eigenvalues <inline-formula><mml:math id="inf533"><mml:mi>λ</mml:mi></mml:math></inline-formula> of <inline-formula><mml:math id="inf534"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> as:<disp-formula id="equ51"><label>(50)</label><mml:math id="m51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1.</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To derive the conditions for transient amplification, we need that the eigenvalues of the symmetric part of the connectivity be larger than unity, where the symmetric part <inline-formula><mml:math id="inf535"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> is a matrix of rank <inline-formula><mml:math id="inf536"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> given by:<disp-formula id="equ52"><mml:math id="m52"><mml:mrow><mml:msub><mml:mi>𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>𝐔𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>𝐕𝐔</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>𝐔</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐕</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mi>𝐔</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Using <xref ref-type="disp-formula" rid="equ50">Equation (49)</xref> (<xref ref-type="bibr" rid="bib71">Nakatsukasa, 2019</xref>), we can write the nonzero eigenvalues <inline-formula><mml:math id="inf537"><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> of <inline-formula><mml:math id="inf538"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math></inline-formula> as:<disp-formula id="equ53"><label>(52)</label><mml:math id="m53"><mml:mrow><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>eig</mml:mi><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐉</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>eig</mml:mi><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mi>𝐔</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>𝐔</mml:mi><mml:mo>,</mml:mo><mml:mi>𝐕</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>eig</mml:mi><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mi>𝐈</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mi>𝐒</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:msup><mml:mi>𝐔</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐕</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we used the fact that <inline-formula><mml:math id="inf539"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐕</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow></mml:math></inline-formula>, and defined <inline-formula><mml:math id="inf540"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐒</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>diag</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. By definition, the eigenvalues of the symmetric part multiplied by 2, that is, <inline-formula><mml:math id="inf541"><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, should satisfy:<disp-formula id="equ54"><label>(53)</label><mml:math id="m54"><mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mrow><mml:mo movablelimits="false">det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>𝐈</mml:mi></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%" rspace="4.2pt">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo movablelimits="false">det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐔</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐕</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>𝐈</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>𝐒</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐔</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐕</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>𝐈</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we used the expression of the determinant of a <inline-formula><mml:math id="inf542"><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> block matrix (<xref ref-type="bibr" rid="bib45">Horn and Johnson, 2012</xref>). Since for two square matrices <inline-formula><mml:math id="inf543"><mml:mi mathvariant="bold">𝐀</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf544"><mml:mi mathvariant="bold">𝐁</mml:mi></mml:math></inline-formula> we have that <inline-formula><mml:math id="inf545"><mml:mrow><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐀𝐁</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐀</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐁</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf546"><mml:mrow><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐀</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐀</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf547"><mml:mrow><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐀</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>det</mml:mo><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">𝐀</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, we can write:<disp-formula id="equ55"><label>(54)</label><mml:math id="m55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>0</mml:mn></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">{</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Thus, the condition for amplification becomes:<disp-formula id="equ56"><mml:math id="m56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo form="prefix" movablelimits="true">det</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">S</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mtext> where </mml:mtext><mml:mspace width="1em"/><mml:mrow><mml:mi mathvariant="bold">B</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">U</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Thus, in the general case of a rank-<inline-formula><mml:math id="inf548"><mml:mi>R</mml:mi></mml:math></inline-formula> network, the condition for stable and amplified dynamics is given by <xref ref-type="disp-formula" rid="equ51 equ56">Equations (50) and (55)</xref>.</p></sec><sec id="s4-25"><title>Dynamics of a low-rank rotational channel</title><p>In this section we describe the structure of the low-rank connectivity obtained by fitting the network model to the OFF responses to individual stimuli (<xref ref-type="fig" rid="fig5">Figure 5B,C</xref>) and analyze the resulting dynamics. When fitting a low-rank network model to the OFF responses to individual stimuli, we observed a specific structure in the pattern of correlations between right and left connectivity vectors <inline-formula><mml:math id="inf549"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf550"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> of the fitted connectivity <inline-formula><mml:math id="inf551"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula>. This pattern exhibited low values of the correlation for almost all pairs of connectivity vectors, except for pairs of left and right vectors coupled across nearby modes, e.g. <inline-formula><mml:math id="inf552"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>-<inline-formula><mml:math id="inf553"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf554"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>-<inline-formula><mml:math id="inf555"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf556"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>-<inline-formula><mml:math id="inf557"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf558"><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>-<inline-formula><mml:math id="inf559"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, and so forth. This structures gives rise to independent rank-2 channels grouping pairs of modes of the form <inline-formula><mml:math id="inf560"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Within a single channel, the values of the correlation was high, and opposite in sign, for different pairs of vectors, that is, <inline-formula><mml:math id="inf561"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>≈</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf562"><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold">𝐮</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⋅</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. As a result, each of these channels can be cast in the form:<disp-formula id="equ57"><label>(56)</label><mml:math id="m57"><mml:mrow><mml:mrow><mml:msub><mml:mi>𝐉</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we set<disp-formula id="equ58"><label>(57)</label><mml:math id="m58"><mml:mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>𝐮</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>with <inline-formula><mml:math id="inf563"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf564"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> two positive scalars, and the vectors <inline-formula><mml:math id="inf565"><mml:mi mathvariant="bold">𝐯</mml:mi></mml:math></inline-formula>’s are of unit norm. <xref ref-type="fig" rid="C1">Scheme 1</xref> illustrates the structure of the rank-2 channel in terms of the left and right connectivity vectors, and the dynamics evoked by an initial condition along <inline-formula><mml:math id="inf566"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>.</p><fig id="C1" position="float"><label>Scheme 1.</label><caption><title>Schematics of the rank-2 rotational channel.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-53151-fig10-v2.tif"/></fig><p>For a rank-2 connectivity as in <xref ref-type="disp-formula" rid="equ5">Equation (5)</xref>, the 2x2 overlap matrix <inline-formula><mml:math id="inf567"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is therefore given by<disp-formula id="equ59"><label>(58)</label><mml:math id="m59"><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐉</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>𝐕</mml:mi></mml:mrow><mml:mo>≡</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>𝐉</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Note that the overlap matrix also corresponds to the connectivity matrix <inline-formula><mml:math id="inf568"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> projected on the basis of the left connectivity vectors <inline-formula><mml:math id="inf569"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> (third equality in <xref ref-type="disp-formula" rid="equ59">Equation (58)</xref>).</p><p>To derive the necessary and sufficient conditions for the channel to exhibit stable and amplified dynamics in response to at least one initial condition <inline-formula><mml:math id="inf570"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, we need to compute the nonzero eigenvalues of the connectivity matrix and of its symmetric part (equal to the eigenvalues of <inline-formula><mml:math id="inf571"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and of its symmetric part). The eigenvalues of <inline-formula><mml:math id="inf572"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> are purely imaginary for all values of <inline-formula><mml:math id="inf573"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf574"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> and are given by <inline-formula><mml:math id="inf575"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. The dynamics are therefore always stable. Next, we compute the eigenvalues of the symmetric part of the connectivity, which reads:<disp-formula id="equ60"><label>(59)</label><mml:math id="m60"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>𝐉</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>𝐉</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>𝐉</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The eigenvalues of <inline-formula><mml:math id="inf576"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are <inline-formula><mml:math id="inf577"><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, so that the dynamics are amplified when<disp-formula id="equ61"><mml:math id="m61"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></disp-formula></p><p>We next derive the full dynamics of the rank-2 connectivity matrix <inline-formula><mml:math id="inf578"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ57">Equation (56)</xref>. To this end, we use the general expression of the propagator for a rank-R network given by <xref ref-type="disp-formula" rid="equ44 equ45">Equations (43),(44)</xref> in terms of the overlap matrix <inline-formula><mml:math id="inf579"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ59">Equation (58)</xref>). To compute the inverse and the exponential of the overlap matrix, we start by diagonalizing <inline-formula><mml:math id="inf580"><mml:msup><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>. Its eigenvalues are given by <inline-formula><mml:math id="inf581"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>±</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, while the corresponding eigenvectors are specified in the columns of the matrix <inline-formula><mml:math id="inf582"><mml:mi mathvariant="bold">𝐄</mml:mi></mml:math></inline-formula>, where <inline-formula><mml:math id="inf583"><mml:mi mathvariant="bold">𝐄</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf584"><mml:msup><mml:mi mathvariant="bold">𝐄</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> read:<disp-formula id="equ62"><mml:math id="m62"><mml:mrow><mml:mrow><mml:mi>𝐄</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐄</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:msqrt><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="12.5pt">,</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The inverse and exponential of the overlap matrix can be therefore computed as:<disp-formula id="equ63"><label>(62)</label><mml:math id="m63"><mml:mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi>𝐄</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mi>i</mml:mi><mml:mi>ω</mml:mi></mml:mfrac></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mfrac><mml:mi>i</mml:mi><mml:mi>ω</mml:mi></mml:mfrac></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐄</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi>𝐔</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>𝐄</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ω</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐄</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>so that we obtain the term <inline-formula><mml:math id="inf585"><mml:mrow><mml:mi mathvariant="bold">𝐚</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ45">Equation (44)</xref> as:<disp-formula id="equ64"><label>(63)</label><mml:math id="m64"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝐚</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>ω</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>ω</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>𝐕</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>From <xref ref-type="disp-formula" rid="equ44 equ64">Equations (43), (44), (57), and (63)</xref>, we can write the expression for the dynamics of the transient channel <inline-formula><mml:math id="inf586"><mml:msub><mml:mi mathvariant="bold">𝐉</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> with initial condition given by <inline-formula><mml:math id="inf587"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (with <inline-formula><mml:math id="inf588"><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> a vector orthogonal to both <inline-formula><mml:math id="inf589"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf590"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>) as:<disp-formula id="equ65"><label>(64)</label><mml:math id="m65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⊥</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msqrt><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:msqrt><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msqrt><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac></mml:msqrt><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Therefore, the squared distance from baseline of the trajectory reads:<disp-formula id="equ66"><label>(65)</label><mml:math id="m66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>cos</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>cos</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mstyle><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that when <inline-formula><mml:math id="inf591"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, the connectivity matrix is purely anti-symmetric (and therefore normal) and cannot produce amplified dynamics. In fact, in this case, the evolution of the distance from baseline results in an exponential decay <inline-formula><mml:math id="inf592"><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Amplification therefore requires that <inline-formula><mml:math id="inf593"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and specifically that <xref ref-type="disp-formula" rid="equ61">Equation (60)</xref> holds.</p><p>We observe that while an anti-symmetric matrix (therefore normal, and with purely imaginary eigenvalues) cannot produce amplified dynamics, nonetheless a matrix with purely imaginary eigenvalues is not necessarily normal, and can thus produce amplified dynamics. Qualitatively, this is reflected in the dynamics tracing elliptical rotations (as opposed to circular rotations in the case of an anti-symmetric matrix) which determine oscillations (and therefore rising and decaying phases) in the distance from baseline. This analysis can be extended to the case of a superposition of K rank-2 mutually orthogonal channels with connectivity matrix given by:<disp-formula id="equ67"><label>(66)</label><mml:math id="m67"><mml:mrow><mml:mrow><mml:msub><mml:mi>𝐉</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where each channel <inline-formula><mml:math id="inf594"><mml:mi>k</mml:mi></mml:math></inline-formula> is defined by the connectivity vectors <inline-formula><mml:math id="inf595"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf596"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), defining together a rank-2K rotational channel. If we write the initial condition along the connectivity vectors of the different K channels as<disp-formula id="equ68"><label>(67)</label><mml:math id="m68"><mml:mrow><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:mo maxsize="160%" minsize="160%">(</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo maxsize="160%" minsize="160%">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msubsup><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>with <inline-formula><mml:math id="inf597"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, we can write the resulting dynamics as the sum of the dynamics within each channel as:<disp-formula id="equ69"><label>(68)</label><mml:math id="m69"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>𝐫</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mpadded><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msubsup><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where the terms <inline-formula><mml:math id="inf598"><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> have the same form of the second term of the right-hand side of <xref ref-type="disp-formula" rid="equ65">Equation (64)</xref>.</p></sec><sec id="s4-26"><title>Conditions on the initial state <inline-formula><mml:math id="inf599"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula></title><p>In this paragraph we consider the rotational channel examined in Section 'Dynamics of a low-rank rotational channel' and study the conditions on the relationship between the initial condition <inline-formula><mml:math id="inf600"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and the connectivity vectors that ensure that the evoked dynamics be amplified. We first examine the case of a rank-2 rotational channel, and then generalize to a superposition of orthogonal rank-2 channels.</p><p>We consider the equation for the distance from baseline of the dynamics for a rank-2 channel (<xref ref-type="disp-formula" rid="equ66">Equation (65)</xref>) and assume, without loss of generality, that <inline-formula><mml:math id="inf601"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. We observe that when <inline-formula><mml:math id="inf602"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, an initial condition along <inline-formula><mml:math id="inf603"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> does not evoke amplified dynamics. On the other hand, an initial condition along <inline-formula><mml:math id="inf604"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> can evoke amplified dynamics, depending on the values of <inline-formula><mml:math id="inf605"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf606"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. In fact, we have:<disp-formula id="equ70"><mml:math id="m70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mspace width="thinmathspace"/><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>t</mml:mi></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Therefore, when <inline-formula><mml:math id="inf607"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (resp. <inline-formula><mml:math id="inf608"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>), the initial condition <inline-formula><mml:math id="inf609"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> needs to have a substantial component along the vector <inline-formula><mml:math id="inf610"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (resp. <inline-formula><mml:math id="inf611"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>). To formalize this observation, we compute the peak time <inline-formula><mml:math id="inf612"><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> when <inline-formula><mml:math id="inf613"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mo stretchy="false">|</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> takes the largest value. If <xref ref-type="disp-formula" rid="equ61">Equation (60)</xref> holds and <inline-formula><mml:math id="inf614"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≫</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, the peak time can be approximated by <inline-formula><mml:math id="inf615"><mml:mrow><mml:mrow><mml:mi>ω</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>We then examine the value of the distance from baseline <inline-formula><mml:math id="inf616"><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>;</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> when the initial condition <inline-formula><mml:math id="inf617"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> is a linear combination of the vectors <inline-formula><mml:math id="inf618"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf619"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and a vector orthogonal to both <inline-formula><mml:math id="inf620"><mml:mi mathvariant="bold">𝐯</mml:mi></mml:math></inline-formula>’s, that is, <inline-formula><mml:math id="inf621"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>β</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf622"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. At the peak time we can write the distance from baseline as:<disp-formula id="equ71"><label>(70)</label><mml:math id="m71"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>;</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="210%" minsize="210%">[</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo maxsize="210%" minsize="210%">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>By requiring that, at the peak time, the distance from baseline is larger than unity we can derive the following sufficient conditions on the component of the initial conditions along the vectors <inline-formula><mml:math id="inf623"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf624"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf625"><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>:<disp-formula id="equ72"><label>(71)</label><mml:math id="m72"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>&gt;</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>When the component of the initial condition along <inline-formula><mml:math id="inf626"><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is zero (<inline-formula><mml:math id="inf627"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), <xref ref-type="disp-formula" rid="equ72">Equation (71)</xref> is satisfied when<disp-formula id="equ73"><label>(72)</label><mml:math id="m73"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo maxsize="210%" minsize="210%">)</mml:mo></mml:mrow><mml:mo mathsize="210%" stretchy="false">/</mml:mo><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mrow><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo maxsize="210%" minsize="210%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p><xref ref-type="disp-formula" rid="equ72">Equation (71)</xref> shows that in an amplified rotational channel the initial state <inline-formula><mml:math id="inf628"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> may have a significant component orthogonal to the vector <inline-formula><mml:math id="inf629"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and yet be able to generate amplified dynamics. However, from <xref ref-type="disp-formula" rid="equ71">Equation (70)</xref> we observe that, for a fixed value of <inline-formula><mml:math id="inf630"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf631"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> (with <inline-formula><mml:math id="inf632"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>), the amplification decreases when the component along <inline-formula><mml:math id="inf633"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, that is, <inline-formula><mml:math id="inf634"><mml:msub><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, decreases. Therefore, to have amplification the component of <inline-formula><mml:math id="inf635"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> along <inline-formula><mml:math id="inf636"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> should be sufficiently strong.</p><p>The above condition <xref ref-type="disp-formula" rid="equ72">Equation (71)</xref> can be generalized to the case of a superposition of orthogonal rank-2 rotational channels (see <xref ref-type="disp-formula" rid="equ69">Equation (68)</xref>) if we assume that the peak time is approximately the same when considering separately the dynamics within each rank-2 channel. Under these assumptions, the distance from baseline at the peak time can be written as<disp-formula id="equ74"><label>(73)</label><mml:math id="m74"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>;</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:mo maxsize="210%" minsize="210%">[</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo maxsize="210%" minsize="210%">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and the condition for the relationship between initial condition and connectivity vectors in a rank-2K channel becomes:<disp-formula id="equ75"><label>(74)</label><mml:math id="m75"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mpadded><mml:mrow><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>&gt;</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>When the component of the initial condition along <inline-formula><mml:math id="inf637"><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is zero (<inline-formula><mml:math id="inf638"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) and the <inline-formula><mml:math id="inf639"><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> do not depend on the channel <inline-formula><mml:math id="inf640"><mml:mi>k</mml:mi></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ75">Equation (74)</xref> is satisfied when<disp-formula id="equ76"><mml:math id="m76"><mml:mrow><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn> 2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo maxsize="210%" minsize="210%">)</mml:mo></mml:mrow><mml:mo mathsize="210%" stretchy="false">/</mml:mo><mml:mrow><mml:mo maxsize="210%" minsize="210%">(</mml:mo><mml:mrow><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mfrac><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo maxsize="210%" minsize="210%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where the left-hand side represents the component of the initial condition on all the vectors <inline-formula><mml:math id="inf641"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s. From <xref ref-type="disp-formula" rid="equ74">Equation (73)</xref> we note that, for fixed values of the <inline-formula><mml:math id="inf642"><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf643"><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> (assuming <inline-formula><mml:math id="inf644"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>&gt;</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf645"><mml:mi>k</mml:mi></mml:math></inline-formula>), amplification decreases by decreasing the components of the initial condition on the vectors <inline-formula><mml:math id="inf646"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s. Therefore, to generate amplified dynamics, the components of the initial condition <inline-formula><mml:math id="inf647"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> on the vectors <inline-formula><mml:math id="inf648"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s should be sufficiently strong.</p></sec><sec id="s4-27"><title>Correlation between initial and peak state</title><p>In this section we derive the expression for the correlation between the initial state <inline-formula><mml:math id="inf649"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and the state at the peak of the transient dynamics, for a rank-2K rotational channel consisting of K rotational rank-2 channels (see Section 'Dynamics of a low-rank rotational channel'). We set the initial condition to <inline-formula><mml:math id="inf650"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and evaluate the state at the peak at time <inline-formula><mml:math id="inf651"><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> (corresponding to the peak time when <inline-formula><mml:math id="inf652"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> has a strong component on the <inline-formula><mml:math id="inf653"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s and <inline-formula><mml:math id="inf654"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>≫</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>). The initial condition and the peak state are therefore given by:<disp-formula id="equ77"><label>(76)</label><mml:math id="m77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⊥</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msqrt><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac></mml:msqrt><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msqrt><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac></mml:msqrt><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mfrac><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⊥</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>From the mutual orthogonality between <inline-formula><mml:math id="inf655"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf656"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>;</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf657"><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> it follows that<disp-formula id="equ78"><label>(77)</label><mml:math id="m78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mfrac><mml:msup><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Thus, we can write the correlation between the initial condition and the peak state as<disp-formula id="equ79"><label>(78)</label><mml:math id="m79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>⋅</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msqrt><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac></mml:msqrt><mml:mo>−</mml:mo><mml:msqrt><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mfrac></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⊥</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>If the initial condition has a strong component on the vectors <inline-formula><mml:math id="inf658"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s (and the component on <inline-formula><mml:math id="inf659"><mml:msup><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⟂</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> can be neglected, that is, <inline-formula><mml:math id="inf660"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), so that <inline-formula><mml:math id="inf661"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn> 2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf662"><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn> 2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>ϵ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, then the correlation between initial and peak state satisfies<disp-formula id="equ80"><label>(79)</label><mml:math id="m80"><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>𝐫</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>∝</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>⁢</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>and equal to zero when the initial condition is a linear combination of the vectors <inline-formula><mml:math id="inf663"><mml:msup><mml:mi mathvariant="bold">𝐯</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s.</p></sec><sec id="s4-28"><title>Single-trial analysis of population OFF responses</title><p>In this section we focus on the single-trial structure of the dynamics generated by the network and single-cell models. In particular, we consider a setting where dynamics are amplified and examine the amount of single-trial variability along specific directions in the state space: the direction corresponding to the maximum amplification of the dynamics, denoted by <inline-formula><mml:math id="inf664"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub></mml:math></inline-formula>, and a random direction <inline-formula><mml:math id="inf665"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub></mml:math></inline-formula>. Variability along a given direction <inline-formula><mml:math id="inf666"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> at time <inline-formula><mml:math id="inf667"><mml:mi>t</mml:mi></mml:math></inline-formula> can be written as a function of the covariance matrix <inline-formula><mml:math id="inf668"><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the population activity at time <inline-formula><mml:math id="inf669"><mml:mi>t</mml:mi></mml:math></inline-formula> as:<disp-formula id="equ81"><label>(80)</label><mml:math id="m81"><mml:mrow><mml:mrow><mml:mrow><mml:mi>var</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn><mml:mi>T</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In particular, for a given direction <inline-formula><mml:math id="inf670"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>, we examine the ratio between the variability at the time of maximum amplification <inline-formula><mml:math id="inf671"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> and the variability at time <inline-formula><mml:math id="inf672"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (corresponding to the end of stimulus presentation), which we termed variability amplification (VA), defined as:<disp-formula id="equ82"><mml:math id="m82"><mml:mrow><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>var</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>var</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>We show that the network model predicts that the variability should increase from <inline-formula><mml:math id="inf673"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf674"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> along the amplified direction <inline-formula><mml:math id="inf675"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub></mml:math></inline-formula>, but not along a random direction <inline-formula><mml:math id="inf676"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub></mml:math></inline-formula>, resulting in the relationship <inline-formula><mml:math id="inf677"><mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>⁢</mml:mo><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. In contrast, in the single-cell model the presence of VA depends on the shapes of the single-cell responses. Further, we show that changes in VA between the amplified and random directions are due to distinct mechanisms in the network and single-cell models: in the network model they are due to the inter-neuron correlations generated by network recurrency; in the single-cell model they directly stem from changes in the variance of single neurons in the population.</p></sec><sec id="s4-29"><title>Structure of single-trial responses in the network model</title><p>In the following we examine the structure of single-trial population OFF responses generated by a general linear network model. We show that the network model is able to reproduce the experimental observations on VA under the minimal assumption that the variability in the single-trial responses is due to the noise in the initial condition <inline-formula><mml:math id="inf678"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> at stimulus offset. The analysis can nevertheless be extended to the case where external input noise is fed into the network without affecting the key results.</p><p>We consider a linear network model with connectivity <inline-formula><mml:math id="inf679"><mml:mi mathvariant="bold">𝐉</mml:mi></mml:math></inline-formula> and a single stimulus <italic>s</italic> modeled by the trial-averaged initial condition <inline-formula><mml:math id="inf680"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. We assume that the trial-to-trial noise in the initial condition is Gaussian, so that for trial <inline-formula><mml:math id="inf681"><mml:mi>ν</mml:mi></mml:math></inline-formula> the corresponding initial condition <inline-formula><mml:math id="inf682"><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is given by<disp-formula id="equ83"><label>(82)</label><mml:math id="m83"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf683"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf684"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, so that <inline-formula><mml:math id="inf685"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. The solution of the linear system can thus be analytically expressed as:<disp-formula id="equ84"><label>(83)</label><mml:math id="m84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where the time-dependent matrix <inline-formula><mml:math id="inf686"><mml:msub><mml:mi mathvariant="bold">𝐏</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> is the propagator of the system (<xref ref-type="bibr" rid="bib3">Arnold, 1973</xref>).</p><p>We start by computing the covariance matrix of the population activity at an arbitrary time <inline-formula><mml:math id="inf687"><mml:mi>t</mml:mi></mml:math></inline-formula> as defined by:<disp-formula id="equ85"><label>(84)</label><mml:math id="m85"><mml:mrow><mml:mrow><mml:mrow><mml:mi>𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="160%" minsize="160%">⟨</mml:mo><mml:mrow><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msup><mml:mi>𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msup><mml:mi>𝐫</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo maxsize="160%" minsize="160%">⟩</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using <xref ref-type="disp-formula" rid="equ84 equ85">Equations (83) and (84)</xref>, we can write the covariance matrix as (<xref ref-type="bibr" rid="bib26">Farrell and Ioannou, 1996</xref>; <xref ref-type="bibr" rid="bib27">Farrell and Ioannou, 2001</xref>):<disp-formula id="equ86"><label>(85)</label><mml:math id="m86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">⟨</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>so that <inline-formula><mml:math id="inf688"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>At a given time <inline-formula><mml:math id="inf689"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, let the SVD of the propagator is given by<disp-formula id="equ87"><label>(86)</label><mml:math id="m87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">n</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">M</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where the singular values <inline-formula><mml:math id="inf690"><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are positive numbers. If none of the singular values <inline-formula><mml:math id="inf691"><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is larger than unity, no initial condition <inline-formula><mml:math id="inf692"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> can lead to amplified dynamics at time <inline-formula><mml:math id="inf693"><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula>, meaning that for all initial conditions <inline-formula><mml:math id="inf694"><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>(<xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>). Instead, suppose that the first <inline-formula><mml:math id="inf695"><mml:mi>K</mml:mi></mml:math></inline-formula> singular values <inline-formula><mml:math id="inf696"><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup></mml:math></inline-formula> are larger than unity, while the remaining <inline-formula><mml:math id="inf697"><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula> singular values are smaller than one (with arbitrary <inline-formula><mml:math id="inf698"><mml:mi>K</mml:mi></mml:math></inline-formula>). Under this condition, any initial condition <inline-formula><mml:math id="inf699"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> consisting of a linear combination of the first K vectors <inline-formula><mml:math id="inf700"><mml:msup><mml:mi mathvariant="bold">𝐧</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> (i.e. <inline-formula><mml:math id="inf701"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐧</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>) will be amplified, so that the norm of the population vector at time <inline-formula><mml:math id="inf702"><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> is larger than one (<xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>):<disp-formula id="equ88"><mml:math id="m88"><mml:mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>𝐏</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐦</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi>𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>In the following analysis, we explore this last scenario, where the first <inline-formula><mml:math id="inf703"><mml:mi>K</mml:mi></mml:math></inline-formula> singular values are larger than unity. We make the following two assumptions. First, we assume that the initial condition is a linear combination of the first <inline-formula><mml:math id="inf704"><mml:mi>K</mml:mi></mml:math></inline-formula> vectors <inline-formula><mml:math id="inf705"><mml:msup><mml:mi mathvariant="bold">𝐧</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>’s, so that the amplified direction is given by <inline-formula><mml:math id="inf706"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ88">Equation (87)</xref>). Notably, for any specified initial condition <inline-formula><mml:math id="inf707"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> defined in this way, the following analysis holds for all times <inline-formula><mml:math id="inf708"><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> for which <inline-formula><mml:math id="inf709"><mml:mrow><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, including the peak time where the distance from baseline is maximum. Second, we assume that averages of the first or second powers of the singular values are of order (at most) one, that is, <inline-formula><mml:math id="inf710"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for any integer <inline-formula><mml:math id="inf711"><mml:mi>M</mml:mi></mml:math></inline-formula>. This assumption holds for typically studied network topologies (e.g. Gaussian random, low-rank networks), where a few amplified dimensions (corresponding to <inline-formula><mml:math id="inf712"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) coexist with many non-amplified ones (corresponding to <inline-formula><mml:math id="inf713"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) (see <xref ref-type="bibr" rid="bib12">Bondanelli and Ostojic, 2020</xref>).</p><p>Using <xref ref-type="disp-formula" rid="equ85">Equation (84)</xref> and the SVD of the propagator <inline-formula><mml:math id="inf714"><mml:msub><mml:mi mathvariant="bold">𝐏</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:msub></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ87">Equation (86)</xref>), we can write the covariance matrix at time <inline-formula><mml:math id="inf715"><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> as<disp-formula id="equ89"><mml:math id="m89"><mml:mrow><mml:mrow><mml:mi>𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>𝐌</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>𝐌</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Thus, we can compute the amount of variability along the amplified direction <inline-formula><mml:math id="inf716"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ88">Equation (87)</xref>) and a random direction <inline-formula><mml:math id="inf717"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub></mml:math></inline-formula> (with <inline-formula><mml:math id="inf718"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, with <inline-formula><mml:math id="inf719"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">𝒩</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>), using <xref ref-type="disp-formula" rid="equ81">Equation (80)</xref> as:<disp-formula id="equ90"><label>(89)</label><mml:math id="m90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mspace width="thinmathspace"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>4</mml:mn></mml:msubsup><mml:mrow><mml:mo fence="true" maxsize="2.047em" minsize="2.047em" stretchy="true" symmetric="true">/</mml:mo></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msubsup><mml:mi>α</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>≫</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mspace width="thinmathspace"/><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mi>β</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mspace width="thinmathspace"/><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where in the third equation the sum runs only over the singular values larger than one, while in the fourth equation the sum runs over all singular values (both larger and smaller than unity), and brackets denote average over realizations of <inline-formula><mml:math id="inf720"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. <xref ref-type="disp-formula" rid="equ90">Equation (89)</xref> shows that in a linear network model the variability along the amplified direction <inline-formula><mml:math id="inf721"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub></mml:math></inline-formula> increases from the initial time <inline-formula><mml:math id="inf722"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> to the peak time <inline-formula><mml:math id="inf723"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, while the variability along a random direction does not, and instead decreases. We quantified these observations by computing the VA, defined in <xref ref-type="disp-formula" rid="equ82">Equation (81)</xref> (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Using <xref ref-type="disp-formula" rid="equ90">Equation (89)</xref> we obtain:<disp-formula id="equ91"><label>(90)</label><mml:math id="m91"><mml:mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>thus showing that, for a linear network model, VA is larger when computed for the amplified direction than a random direction.</p></sec><sec id="s4-30"><title>Shuffled responses</title><p>In the following we compare the VA of the original responses with the VA obtained from the responses where the trial labels have been shuffled independently for each cell. The covariance matrix of the shuffled responses <inline-formula><mml:math id="inf724"><mml:mrow><mml:msup><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>sh</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is obtained by retaining only the diagonal elements of the real covariance matrix <inline-formula><mml:math id="inf725"><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ92"><label>(91)</label><mml:math id="m92"><mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mi>𝐂</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>sh</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>𝐂</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>𝐦</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>𝐦</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The first two quantities in <xref ref-type="disp-formula" rid="equ90">Equation (89)</xref> computed using <inline-formula><mml:math id="inf726"><mml:msup><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mi>sh</mml:mi></mml:msup></mml:math></inline-formula> instead of <inline-formula><mml:math id="inf727"><mml:mi mathvariant="bold">𝐂</mml:mi></mml:math></inline-formula> do not change, since <inline-formula><mml:math id="inf728"><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is already diagonal. Instead, for shuffled responses the variability along both directions at the peak time <inline-formula><mml:math id="inf729"><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> is of order <inline-formula><mml:math id="inf730"><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, since:<disp-formula id="equ93"><label>(92)</label><mml:math id="m93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Following the same steps it is possible to show that <inline-formula><mml:math id="inf731"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>var</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>;</mml:mo><mml:mi>shuffled</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐦</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. In fact if we set, according to <xref ref-type="disp-formula" rid="equ88">Equation (87)</xref>, <inline-formula><mml:math id="inf732"><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mi mathvariant="bold">𝐦</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>/</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf733"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msubsup><mml:mi>α</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, we have:<disp-formula id="equ94"><label>(93)</label><mml:math id="m94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where in the last equality we assumed that <inline-formula><mml:math id="inf734"><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>α</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> if <inline-formula><mml:math id="inf735"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. To summarize, for shuffled responses we have:<disp-formula id="equ95"><label>(94)</label><mml:math id="m95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo>;</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>so that the VA along both directions is given by:<disp-formula id="equ96"><label>(95)</label><mml:math id="m96"><mml:mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>implying a weaker modulation of the VA between random and amplified direction for shuffled responses with respect to the original responses. These analyses show that in the network model, the difference in the VA between the amplified and random directions is a result of the recurrent interactions within the network, reflected in the off-diagonal elements of the covariance matrix <inline-formula><mml:math id="inf736"><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and it therefore cannot be explained solely by changes in the variability of single units.</p></sec><sec id="s4-31"><title>Structure of single-trial responses in the single-cell model</title><p>Here we examine the structure of the single-trial population responses generated by the single-cell model (<xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>). We consider single-trial responses <inline-formula><mml:math id="inf737"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> to a single stimulus generated by perturbing the initial state of the trial averaged responses <inline-formula><mml:math id="inf738"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, yielding<disp-formula id="equ97"><label>(96)</label><mml:math id="m97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf739"><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> has zero mean and variance equal to <inline-formula><mml:math id="inf740"><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> (<inline-formula><mml:math id="inf741"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf742"><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>). From <xref ref-type="disp-formula" rid="equ97">Equation (96)</xref> we can compute the covariance matrix of the population response for the single-cell model as:<disp-formula id="equ98"><label>(97)</label><mml:math id="m98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mspace width="thinmathspace"/><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>We can obtain the variability along a given direction <inline-formula><mml:math id="inf743"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> as:<disp-formula id="equ99"><label>(98)</label><mml:math id="m99"><mml:mrow><mml:mrow><mml:mrow><mml:mi>var</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover></mml:mpadded><mml:mrow><mml:msubsup><mml:mi>𝐳</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Notably, the term on the right-hand side is proportional to the norm of the dynamics that would be evoked by the initial condition <inline-formula><mml:math id="inf744"><mml:msub><mml:mi mathvariant="bold">𝐳</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>. In the single-cell model, the variability is maximally amplified along the initial condition that leads to largest amplification of the trial averaged dynamics. In contrast, in the network model, the variability is maximally amplified along the amplified direction of the trial-averaged dynamics, which is in general orthogonal to the corresponding initial condition (see Materials and methods, Section 'Conditions on the initial state <inline-formula><mml:math id="inf745"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula>'; <xref ref-type="fig" rid="fig6">Figure 6C,E</xref>). In general, the relationship between the modulation of the variability along the amplified direction and modulation along a random direction depends on the specific shape of the temporal filters <inline-formula><mml:math id="inf746"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and we used simulations of the fitted model to determine it. We can however contrast the single-trial structure generated by the single-cell model with the structure generated by the recurrent model by noting that the covariance matrix given by <xref ref-type="disp-formula" rid="equ98">Equation (97)</xref> is diagonal, and is therefore equal to the covariance matrix of the shuffled responses, <inline-formula><mml:math id="inf747"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>sh</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. This implies that no difference is observed when computing the VA for the amplified and random directions for the real and shuffled responses (i.e. <inline-formula><mml:math id="inf748"><mml:mrow><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>rand</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>shuffled</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf749"><mml:mrow><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>VA</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mi>ampl</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>shuffled</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>), indicating that changes in the trial-to-trial variability can be fully explained in terms of changes in the variability of single units.</p><p>In <xref ref-type="fig" rid="fig8">Figure 8E,G,F,H</xref>, for both network and single-cell models, single-trial population responses were generated by drawing the single-trial initial conditions from a random distribution with mean <inline-formula><mml:math id="inf750"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and covariance matrix computed from the single-trials initial conditions of the original data (across neurons for the single-cell model, across PC dimensions for the network model). The results do not substantially change if we draw the single-trial initial conditions from a random distribution with mean <inline-formula><mml:math id="inf751"><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> and isotropic covariance matrix (<inline-formula><mml:math id="inf752"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:msub><mml:mi mathvariant="bold">𝐫</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf753"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">𝐂</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msup><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">𝐈</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>), as assumed in the analysis above (not shown).</p></sec><sec id="s4-32"><title>Software</title><p>Numerical simulations and data analyses were done using Python 3.6 (using NumPy [<xref ref-type="bibr" rid="bib36">Harris et al., 2020</xref>], SciPy [<xref ref-type="bibr" rid="bib103">Virtanen et al., 2020</xref>], and the scikit-learn package [<xref ref-type="bibr" rid="bib76">Pedregosa et al., 2011</xref>]). Code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/gbondanelli/OffResponses">https://github.com/gbondanelli/OffResponses</ext-link>; <xref ref-type="bibr" rid="bib11">Bondanelli, 2021</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ae6576e399aa359e62f4491b59683fb4d47fc101;origin=https://github.com/gbondanelli/OffResponses;visit=swh:1:snp:adffa57374648ef49c4ac9f4ef744b39c9fd41d5;anchor=swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140/">swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140</ext-link>. Surrogate data sets for model validation (see Materials and methods, Section 'Control data sets', <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>) were generated using the Matlab code provided by <xref ref-type="bibr" rid="bib25">Elsayed and Cunningham, 2017</xref> available at <ext-link ext-link-type="uri" xlink:href="https://github.com/gamaleldin/TME">https://github.com/gamaleldin/TME</ext-link>.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Methodology</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Data curation, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Methodology, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-53151-transrepform-v2.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Python code and data are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/gbondanelli/OffResponses">https://github.com/gbondanelli/OffResponses</ext-link> copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140/">https://archive.softwareheritage.org/swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140/</ext-link>.</p><p>The following datasets were generated:</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alluri</surname> <given-names>RK</given-names></name><name><surname>Rose</surname> <given-names>GJ</given-names></name><name><surname>Hanson</surname> <given-names>JL</given-names></name><name><surname>Leary</surname> <given-names>CJ</given-names></name><name><surname>Vasquez-Opazo</surname> <given-names>GA</given-names></name><name><surname>Graham</surname> <given-names>JA</given-names></name><name><surname>Wilkerson</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Phasic, suprathreshold excitation and sustained inhibition underlie neuronal selectivity for short-duration sounds</article-title><source>PNAS</source><volume>113</volume><fpage>E1927</fpage><lpage>E1935</lpage><pub-id pub-id-type="doi">10.1073/pnas.1520971113</pub-id><pub-id pub-id-type="pmid">26976602</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname> <given-names>LA</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mind the gap: two dissociable mechanisms of temporal processing in the auditory system</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>1977</fpage><lpage>1995</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1652-15.2016</pub-id><pub-id pub-id-type="pmid">26865621</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Arnold</surname> <given-names>VI</given-names></name></person-group><year iso-8601-date="1973">1973</year><source>Ordinary differential equations</source><publisher-name>The MIT Press</publisher-name></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aubie</surname> <given-names>B</given-names></name><name><surname>Becker</surname> <given-names>S</given-names></name><name><surname>Faure</surname> <given-names>PA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Computational models of millisecond level duration tuning in neural circuits</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>9255</fpage><lpage>9270</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1085-09.2009</pub-id><pub-id pub-id-type="pmid">19625516</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbour</surname> <given-names>DL</given-names></name><name><surname>Callaway</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Excitatory local connections of superficial neurons in rat auditory cortex</article-title><source>Journal of Neuroscience</source><volume>28</volume><fpage>11174</fpage><lpage>11185</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2093-08.2008</pub-id><pub-id pub-id-type="pmid">18971460</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Beiran</surname> <given-names>M</given-names></name><name><surname>Dubreuil</surname> <given-names>A</given-names></name><name><surname>Valente</surname> <given-names>A</given-names></name><name><surname>Mastrogiuseppe</surname> <given-names>F</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Shaping dynamics with multiple populations in low-rank recurrent networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2007.02062">https://arxiv.org/abs/2007.02062</ext-link></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beiran</surname> <given-names>M</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Contrasting the effects of adaptation and synaptic filtering on the timescales of dynamics in recurrent networks</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006893</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006893</pub-id><pub-id pub-id-type="pmid">30897092</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern recognition and machine learning</source><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bizley</surname> <given-names>JK</given-names></name><name><surname>Bajo</surname> <given-names>VM</given-names></name><name><surname>Nodal</surname> <given-names>FR</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortico-Cortical connectivity within ferret auditory cortex</article-title><source>Journal of Comparative Neurology</source><volume>523</volume><fpage>2187</fpage><lpage>2210</lpage><pub-id pub-id-type="doi">10.1002/cne.23784</pub-id><pub-id pub-id-type="pmid">25845831</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bjorck</surname> <given-names>A</given-names></name><name><surname>Golub</surname> <given-names>GH</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Numerical methods for computing angles between linear subspaces</article-title><source>Mathematics of Computation</source><volume>27</volume><fpage>579</fpage><lpage>594</lpage><pub-id pub-id-type="doi">10.2307/2005662</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Bondanelli</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>OffResponses</data-title><source>Software Heritage</source><version designator="swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140">swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140</version><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:ae6576e399aa359e62f4491b59683fb4d47fc101;origin=https://github.com/gbondanelli/OffResponses;visit=swh:1:snp:adffa57374648ef49c4ac9f4ef744b39c9fd41d5;anchor=swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140/">https://archive.softwareheritage.org/swh:1:dir:ae6576e399aa359e62f4491b59683fb4d47fc101;origin=https://github.com/gbondanelli/OffResponses;visit=swh:1:snp:adffa57374648ef49c4ac9f4ef744b39c9fd41d5;anchor=swh:1:rev:2438e688ad719eb9870af8c032803a7367fe1140/</ext-link></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bondanelli</surname> <given-names>G</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Coding with transient trajectories in recurrent neural networks</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007655</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007655</pub-id><pub-id pub-id-type="pmid">32053594</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brand</surname> <given-names>A</given-names></name><name><surname>Urban</surname> <given-names>R</given-names></name><name><surname>Grothe</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Duration tuning in the mouse auditory midbrain</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>1790</fpage><lpage>1799</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.84.4.1790</pub-id><pub-id pub-id-type="pmid">11024071</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broome</surname> <given-names>BM</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Encoding and decoding of overlapping odor sequences</article-title><source>Neuron</source><volume>51</volume><fpage>467</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.07.018</pub-id><pub-id pub-id-type="pmid">16908412</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buonomano</surname> <given-names>DV</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>State-dependent computations: spatiotemporal processing in cortical networks</article-title><source>Nature Reviews Neuroscience</source><volume>10</volume><fpage>113</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1038/nrn2558</pub-id><pub-id pub-id-type="pmid">19145235</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calhoun</surname> <given-names>BM</given-names></name><name><surname>Schreiner</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Spectral envelope coding in cat primary auditory cortex: linear and non-linear effects of stimulus characteristics</article-title><source>European Journal of Neuroscience</source><volume>10</volume><fpage>926</fpage><lpage>940</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.1998.00102.x</pub-id><pub-id pub-id-type="pmid">9753160</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Santhanam</surname> <given-names>G</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural variability in premotor cortex provides a signature of motor preparation</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>3697</fpage><lpage>3712</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3762-05.2006</pub-id><pub-id pub-id-type="pmid">16597724</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Cortical preparatory activity: representation of movement or first cog in a dynamical machine?</article-title><source>Neuron</source><volume>68</volume><fpage>387</fpage><lpage>400</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.09.015</pub-id><pub-id pub-id-type="pmid">21040842</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Foster</surname> <given-names>JD</given-names></name><name><surname>Nuyujukian</surname> <given-names>P</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Temporal complexity and heterogeneity of single-neuron activity in premotor and motor cortex</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>4235</fpage><lpage>4257</lpage><pub-id pub-id-type="doi">10.1152/jn.00095.2007</pub-id><pub-id pub-id-type="pmid">17376854</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id><pub-id pub-id-type="pmid">25151264</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davies</surname> <given-names>PT</given-names></name><name><surname>Tso</surname> <given-names>MK-S</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Procedures for Reduced-Rank regression</article-title><source>Applied Statistics</source><volume>31</volume><fpage>244</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.2307/2347998</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneux</surname> <given-names>T</given-names></name><name><surname>Kempf</surname> <given-names>A</given-names></name><name><surname>Daret</surname> <given-names>A</given-names></name><name><surname>Ponsot</surname> <given-names>E</given-names></name><name><surname>Bathellier</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temporal asymmetries in auditory coding and perception reflect multi-layered nonlinearities</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12682</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12682</pub-id><pub-id pub-id-type="pmid">27580932</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duysens</surname> <given-names>J</given-names></name><name><surname>Schaafsma</surname> <given-names>SJ</given-names></name><name><surname>Orban</surname> <given-names>GA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Cortical off response tuning for stimulus duration</article-title><source>Vision Research</source><volume>36</volume><fpage>3243</fpage><lpage>3251</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(96)00040-5</pub-id><pub-id pub-id-type="pmid">8944284</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsayed</surname> <given-names>GF</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Structure in neural population recordings: an expected byproduct of simpler phenomena?</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1310</fpage><lpage>1318</lpage><pub-id pub-id-type="doi">10.1038/nn.4617</pub-id><pub-id pub-id-type="pmid">28783140</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farrell</surname> <given-names>BF</given-names></name><name><surname>Ioannou</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Generalized stability theory. part I: autonomous operators</article-title><source>Journal of the Atmospheric Sciences</source><volume>53</volume><fpage>2025</fpage><lpage>2040</lpage><pub-id pub-id-type="doi">10.1175/1520-0469(1996)053&lt;2025:GSTPIA&gt;2.0.CO;2</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farrell</surname> <given-names>BF</given-names></name><name><surname>Ioannou</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Accurate Low-Dimensional approximation of the linear dynamics of fluid flow</article-title><source>Journal of the Atmospheric Sciences</source><volume>58</volume><fpage>2771</fpage><lpage>2789</lpage><pub-id pub-id-type="doi">10.1175/1520-0469(2001)058&lt;2771:ALDAOT&gt;2.0.CO;2</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedrich</surname> <given-names>RW</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Dynamic optimization of odor representations by slow temporal patterning of mitral cell activity</article-title><source>Science</source><volume>291</volume><fpage>889</fpage><lpage>894</lpage><pub-id pub-id-type="doi">10.1126/science.291.5505.889</pub-id><pub-id pub-id-type="pmid">11157170</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname> <given-names>ZY</given-names></name><name><surname>Tang</surname> <given-names>J</given-names></name><name><surname>Jen</surname> <given-names>PH</given-names></name><name><surname>Chen</surname> <given-names>QC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The auditory response properties of single-on and double-on responders in the inferior colliculus of the leaf-nosed bat, Hipposideros armiger</article-title><source>Brain Research</source><volume>1306</volume><fpage>39</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2009.10.002</pub-id><pub-id pub-id-type="pmid">19835849</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gao</surname> <given-names>P</given-names></name><name><surname>Trautmann</surname> <given-names>E</given-names></name><name><surname>Yu</surname> <given-names>B</given-names></name><name><surname>Santhanam</surname> <given-names>G</given-names></name><name><surname>Ryu</surname> <given-names>S</given-names></name><name><surname>Shenoy</surname> <given-names>K</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A theory of multineuronal dimensionality, dynamics and measurement</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/214262</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Memory without feedback in a neural network</article-title><source>Neuron</source><volume>61</volume><fpage>621</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.012</pub-id><pub-id pub-id-type="pmid">19249281</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Golub</surname> <given-names>GH</given-names></name><name><surname>Zha</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1992">1992</year><chapter-title>The canonical correlations of matrix pairs and their numerical computation</chapter-title><person-group person-group-type="editor"><name><surname>Bojanczyk</surname> <given-names>A</given-names></name><name><surname>Cybenko</surname> <given-names>G</given-names></name></person-group><source>Linear Algebra for Signal Processing</source><publisher-name>Stanford University</publisher-name><fpage>27</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1007/978-1-4612-4228-4_3</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grothe</surname> <given-names>B</given-names></name><name><surname>Vater</surname> <given-names>M</given-names></name><name><surname>Casseday</surname> <given-names>JH</given-names></name><name><surname>Covey</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Monaural interaction of excitation and inhibition in the medial superior olive of the mustached bat: an adaptation for biosonar</article-title><source>PNAS</source><volume>89</volume><fpage>5108</fpage><lpage>5112</lpage><pub-id pub-id-type="doi">10.1073/pnas.89.11.5108</pub-id><pub-id pub-id-type="pmid">1594619</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>Y</given-names></name><name><surname>Burkard</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Onset and offset responses from inferior colliculus and auditory cortex to paired noisebursts: inner hair cell loss</article-title><source>Hearing Research</source><volume>171</volume><fpage>158</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/S0378-5955(02)00496-3</pub-id><pub-id pub-id-type="pmid">12204359</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hancock</surname> <given-names>KE</given-names></name><name><surname>Voigt</surname> <given-names>HF</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Wideband inhibition of dorsal cochlear nucleus type IV units in cat: a computational model</article-title><source>Annals of Biomedical Engineering</source><volume>27</volume><fpage>73</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1114/1.150</pub-id><pub-id pub-id-type="pmid">9916763</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname> <given-names>CR</given-names></name><name><surname>Millman</surname> <given-names>KJ</given-names></name><name><surname>van der Walt</surname> <given-names>SJ</given-names></name><name><surname>Gommers</surname> <given-names>R</given-names></name><name><surname>Virtanen</surname> <given-names>P</given-names></name><name><surname>Cournapeau</surname> <given-names>D</given-names></name><name><surname>Wieser</surname> <given-names>E</given-names></name><name><surname>Taylor</surname> <given-names>J</given-names></name><name><surname>Berg</surname> <given-names>S</given-names></name><name><surname>Smith</surname> <given-names>NJ</given-names></name><name><surname>Kern</surname> <given-names>R</given-names></name><name><surname>Picus</surname> <given-names>M</given-names></name><name><surname>Hoyer</surname> <given-names>S</given-names></name><name><surname>van Kerkwijk</surname> <given-names>MH</given-names></name><name><surname>Brett</surname> <given-names>M</given-names></name><name><surname>Haldane</surname> <given-names>A</given-names></name><name><surname>Del Río</surname> <given-names>JF</given-names></name><name><surname>Wiebe</surname> <given-names>M</given-names></name><name><surname>Peterson</surname> <given-names>P</given-names></name><name><surname>Gérard-Marchant</surname> <given-names>P</given-names></name><name><surname>Sheppard</surname> <given-names>K</given-names></name><name><surname>Reddy</surname> <given-names>T</given-names></name><name><surname>Weckesser</surname> <given-names>W</given-names></name><name><surname>Abbasi</surname> <given-names>H</given-names></name><name><surname>Gohlke</surname> <given-names>C</given-names></name><name><surname>Oliphant</surname> <given-names>TE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Array programming with NumPy</article-title><source>Nature</source><volume>585</volume><fpage>357</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id><pub-id pub-id-type="pmid">32939066</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartley</surname> <given-names>DE</given-names></name><name><surname>Dahmen</surname> <given-names>JC</given-names></name><name><surname>King</surname> <given-names>AJ</given-names></name><name><surname>Schnupp</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Binaural sensitivity changes between cortical on and off responses</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>30</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1152/jn.01070.2010</pub-id><pub-id pub-id-type="pmid">21562191</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>OFF responses in the auditory thalamus of the guinea pig</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>2377</fpage><lpage>2386</lpage><pub-id pub-id-type="doi">10.1152/jn.00083.2002</pub-id><pub-id pub-id-type="pmid">12424279</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Corticofugal modulation on both ON and OFF responses in the nonlemniscal auditory thalamus of the guinea pig</article-title><source>Journal of Neurophysiology</source><volume>89</volume><fpage>367</fpage><lpage>381</lpage><pub-id pub-id-type="doi">10.1152/jn.00593.2002</pub-id><pub-id pub-id-type="pmid">12522186</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heil</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1997">1997a</year><article-title>Auditory cortical onset responses revisited. I. First-spike timing</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>2616</fpage><lpage>2641</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.5.2616</pub-id><pub-id pub-id-type="pmid">9163380</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heil</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1997">1997b</year><article-title>Auditory cortical onset responses revisited. II. response strength</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>2642</fpage><lpage>2660</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.5.2642</pub-id><pub-id pub-id-type="pmid">9163381</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname> <given-names>G</given-names></name><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Non-normal amplification in random balanced neuronal networks</article-title><source>Physical Review E</source><volume>86</volume><elocation-id>011909</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.86.011909</pub-id><pub-id pub-id-type="pmid">23005454</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hennequin</surname> <given-names>G</given-names></name><name><surname>Vogels</surname> <given-names>TP</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Optimal control of transient dynamics in balanced networks supports generation of complex movements</article-title><source>Neuron</source><volume>82</volume><fpage>1394</fpage><lpage>1406</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.045</pub-id><pub-id pub-id-type="pmid">24945778</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henry</surname> <given-names>KR</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Tuning of the auditory brainstem OFF responses is complementary to tuning of the auditory brainstem ON response</article-title><source>Hearing Research</source><volume>19</volume><fpage>115</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(85)90115-7</pub-id><pub-id pub-id-type="pmid">4055531</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Horn</surname> <given-names>RA</given-names></name><name><surname>Johnson</surname> <given-names>CR</given-names></name></person-group><year iso-8601-date="2012">2012</year><source>Matrix Analysis</source><publisher-loc>Cambridge</publisher-loc><publisher-name>University Press</publisher-name></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hotelling</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1936">1936</year><article-title>Relations between two sets of variates</article-title><source>Biometrika</source><volume>28</volume><fpage>321</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1093/biomet/28.3-4.321</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>T</given-names></name><name><surname>Malmierca</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title><italic>Neurons, Connections, and Microcircuits of the Inferior Colliculus</italic></chapter-title><person-group person-group-type="editor"><name><surname>Oliver</surname> <given-names>D. L</given-names></name></person-group><source>Mammalian Auditory Pathways: Synaptic Organization and Microcircuits</source><publisher-name>Springer International Publishing</publisher-name><fpage>127</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-71798-2</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izenman</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Reduced-rank regression for the multivariate linear model</article-title><source>Journal of Multivariate Analysis</source><volume>5</volume><fpage>248</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1016/0047-259X(75)90042-1</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joachimsthaler</surname> <given-names>B</given-names></name><name><surname>Uhlmann</surname> <given-names>M</given-names></name><name><surname>Miller</surname> <given-names>F</given-names></name><name><surname>Ehret</surname> <given-names>G</given-names></name><name><surname>Kurt</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Quantitative analysis of neuronal response properties in primary and higher-order auditory cortical fields of awake house mice (<italic>Mus musculus</italic>)</article-title><source>The European Journal of Neuroscience</source><volume>39</volume><fpage>904</fpage><lpage>918</lpage><pub-id pub-id-type="doi">10.1111/ejn.12478</pub-id><pub-id pub-id-type="pmid">24506843</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasai</surname> <given-names>M</given-names></name><name><surname>Ono</surname> <given-names>M</given-names></name><name><surname>Ohmori</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distinct neural firing mechanisms to tonal stimuli offset in the inferior colliculus of mice in vivo</article-title><source>Neuroscience Research</source><volume>73</volume><fpage>224</fpage><lpage>237</lpage><pub-id pub-id-type="doi">10.1016/j.neures.2012.04.009</pub-id><pub-id pub-id-type="pmid">22579573</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname> <given-names>CH</given-names></name><name><surname>Kaylegian</surname> <given-names>K</given-names></name><name><surname>Wehr</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Gap encoding by parvalbumin-expressing interneurons in auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>120</volume><fpage>105</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1152/jn.00911.2017</pub-id><pub-id pub-id-type="pmid">29589814</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knyazev</surname> <given-names>AV</given-names></name><name><surname>Argentati</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Principal Angles between Subspaces in an <italic>A</italic> -Based Scalar Product: Algorithms and Perturbation Estimates</article-title><source>SIAM Journal on Scientific Computing</source><volume>23</volume><fpage>2008</fpage><lpage>2040</lpage><pub-id pub-id-type="doi">10.1137/S1064827500377332</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopp-Scheinpflug</surname> <given-names>C</given-names></name><name><surname>Tozer</surname> <given-names>AJ</given-names></name><name><surname>Robinson</surname> <given-names>SW</given-names></name><name><surname>Tempel</surname> <given-names>BL</given-names></name><name><surname>Hennig</surname> <given-names>MH</given-names></name><name><surname>Forsythe</surname> <given-names>ID</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The sound of silence: ionic mechanisms encoding sound termination</article-title><source>Neuron</source><volume>71</volume><fpage>911</fpage><lpage>925</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.06.028</pub-id><pub-id pub-id-type="pmid">21903083</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopp-Scheinpflug</surname> <given-names>C</given-names></name><name><surname>Sinclair</surname> <given-names>JL</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>When sound stops: offset responses in the auditory system</article-title><source>Trends in Neurosciences</source><volume>41</volume><fpage>712</fpage><lpage>728</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2018.08.009</pub-id><pub-id pub-id-type="pmid">30274606</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuwada</surname> <given-names>S</given-names></name><name><surname>Batra</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Coding of sound envelopes by inhibitory rebound in neurons of the superior olivary complex in the unanesthetized rabbit</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>2273</fpage><lpage>2287</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-06-02273.1999</pub-id><pub-id pub-id-type="pmid">10066278</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lara</surname> <given-names>AH</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Different population dynamics in the supplementary motor area and motor cortex during reaching</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2754</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05146-z</pub-id><pub-id pub-id-type="pmid">30013188</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>CC</given-names></name><name><surname>Kishan</surname> <given-names>AU</given-names></name><name><surname>Winer</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Wiring of divergent networks in the central auditory system</article-title><source>Frontiers in Neuroanatomy</source><volume>5</volume><elocation-id>46</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2011.00046</pub-id><pub-id pub-id-type="pmid">21847372</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>LY</given-names></name><name><surname>Li</surname> <given-names>YT</given-names></name><name><surname>Zhou</surname> <given-names>M</given-names></name><name><surname>Tao</surname> <given-names>HW</given-names></name><name><surname>Zhang</surname> <given-names>LI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Intracortical multiplication of thalamocortical signals in mouse auditory cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1179</fpage><lpage>1181</lpage><pub-id pub-id-type="doi">10.1038/nn.3493</pub-id><pub-id pub-id-type="pmid">23933752</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname> <given-names>Y</given-names></name><name><surname>Lagoy</surname> <given-names>R</given-names></name><name><surname>Shinn-Cunningham</surname> <given-names>BG</given-names></name><name><surname>Gardner</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Transformation of temporal sequences in the zebra finch auditory system</article-title><source>eLife</source><volume>5</volume><elocation-id>e18205</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18205</pub-id><pub-id pub-id-type="pmid">27897971</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linden</surname> <given-names>JF</given-names></name><name><surname>Schreiner</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Columnar transformations in auditory cortex? A comparison to visual and somatosensory cortices</article-title><source>Cerebral Cortex</source><volume>13</volume><fpage>83</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1093/cercor/13.1.83</pub-id><pub-id pub-id-type="pmid">12466219</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>J</given-names></name><name><surname>Whiteway</surname> <given-names>MR</given-names></name><name><surname>Sheikhattar</surname> <given-names>A</given-names></name><name><surname>Butts</surname> <given-names>DA</given-names></name><name><surname>Babadi</surname> <given-names>B</given-names></name><name><surname>Kanold</surname> <given-names>PO</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>Parallel processing of sound dynamics across mouse auditory cortex via spatially patterned thalamic inputs and distinct areal intracortical circuits</article-title><source>Cell Reports</source><volume>27</volume><fpage>872</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2019.03.069</pub-id><pub-id pub-id-type="pmid">30995483</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>X</given-names></name><name><surname>Zhang</surname> <given-names>O</given-names></name><name><surname>Qi</surname> <given-names>J</given-names></name><name><surname>Chen</surname> <given-names>A</given-names></name><name><surname>Hu</surname> <given-names>K</given-names></name><name><surname>Yan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>The onset and post-onset auditory responses of cochlear nucleus neurons are modulated differently by cortical activation</article-title><source>Hearing Research</source><volume>373</volume><fpage>96</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2018.12.013</pub-id><pub-id pub-id-type="pmid">30640070</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname> <given-names>F</given-names></name><name><surname>Metzner</surname> <given-names>W</given-names></name><name><surname>Wu</surname> <given-names>F</given-names></name><name><surname>Wu</surname> <given-names>FJ</given-names></name><name><surname>Zhang</surname> <given-names>S</given-names></name><name><surname>Zhang</surname> <given-names>SY</given-names></name><name><surname>Chen</surname> <given-names>Q</given-names></name><name><surname>Chen</surname> <given-names>QC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Duration-sensitive neurons in the inferior colliculus of horseshoe bats: adaptations for using CF-FM echolocation pulses</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>284</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1152/jn.00935.2007</pub-id><pub-id pub-id-type="pmid">18003879</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Machens</surname> <given-names>CK</given-names></name><name><surname>Wehr</surname> <given-names>MS</given-names></name><name><surname>Zador</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Linearity of cortical receptive fields measured with natural sounds</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>1089</fpage><lpage>1100</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4445-03.2004</pub-id><pub-id pub-id-type="pmid">14762127</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastrogiuseppe</surname> <given-names>F</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Linking connectivity, dynamics, and computations in Low-Rank recurrent neural networks</article-title><source>Neuron</source><volume>99</volume><fpage>609</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.003</pub-id><pub-id pub-id-type="pmid">30057201</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazor</surname> <given-names>O</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Transient dynamics versus fixed points in odor representations by locust antennal lobe projection neurons</article-title><source>Neuron</source><volume>48</volume><fpage>661</fpage><lpage>673</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.09.032</pub-id><pub-id pub-id-type="pmid">16301181</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>AF</given-names></name><name><surname>Williamson</surname> <given-names>RS</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Models of neuronal Stimulus-Response functions: elaboration, estimation, and evaluation</article-title><source>Frontiers in Systems Neuroscience</source><volume>10</volume><elocation-id>109</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2016.00109</pub-id><pub-id pub-id-type="pmid">28127278</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukherjee</surname> <given-names>A</given-names></name><name><surname>Chen</surname> <given-names>K</given-names></name><name><surname>Wang</surname> <given-names>N</given-names></name><name><surname>Zhu</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>On the degrees of freedom of reduced-rank estimators in multivariate regression</article-title><source>Biometrika</source><volume>102</volume><fpage>457</fpage><lpage>477</lpage><pub-id pub-id-type="doi">10.1093/biomet/asu067</pub-id><pub-id pub-id-type="pmid">26702155</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>BK</given-names></name><name><surname>Miller</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Balanced amplification: a new mechanism of selective amplification of neural activity patterns</article-title><source>Neuron</source><volume>61</volume><fpage>635</fpage><lpage>648</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.005</pub-id><pub-id pub-id-type="pmid">19249282</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muscinelli</surname> <given-names>SP</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name><name><surname>Schwalger</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>How single neuron properties shape chaotic dynamics and signal transmission in random neural networks</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007122</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007122</pub-id><pub-id pub-id-type="pmid">31181063</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nakatsukasa</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The low-rank eigenvalue problem</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1905.11490">https://arxiv.org/abs/1905.11490</ext-link></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelken</surname> <given-names>I</given-names></name><name><surname>Rotman</surname> <given-names>Y</given-names></name><name><surname>Bar Yosef</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Responses of auditory-cortex neurons to structural features of natural sounds</article-title><source>Nature</source><volume>397</volume><fpage>154</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1038/16456</pub-id><pub-id pub-id-type="pmid">9923676</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neubert</surname> <given-names>MG</given-names></name><name><surname>Caswell</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Alternatives to resilience for measuring the responses of ecological systems to perturbations</article-title><source>Ecology</source><volume>78</volume><fpage>653</fpage><lpage>665</lpage><pub-id pub-id-type="doi">10.1890/0012-9658(1997)078[0653:ATRFMT]2.0.CO;2</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oswald</surname> <given-names>AM</given-names></name><name><surname>Doiron</surname> <given-names>B</given-names></name><name><surname>Rinzel</surname> <given-names>J</given-names></name><name><surname>Reyes</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial profile and differential recruitment of GABAB modulate oscillatory activity in auditory cortex</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>10321</fpage><lpage>10334</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1703-09.2009</pub-id><pub-id pub-id-type="pmid">19692606</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oswald</surname> <given-names>AM</given-names></name><name><surname>Reyes</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Maturation of intrinsic and synaptic properties of layer 2/3 pyramidal neurons in mouse auditory cortex</article-title><source>Journal of Neurophysiology</source><volume>99</volume><fpage>2998</fpage><lpage>3008</lpage><pub-id pub-id-type="doi">10.1152/jn.01160.2007</pub-id><pub-id pub-id-type="pmid">18417631</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Michel</surname> <given-names>V</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Grisel</surname> <given-names>O</given-names></name><name><surname>Blondel</surname> <given-names>M</given-names></name><name><surname>Prettenhofer</surname> <given-names>P</given-names></name><name><surname>Weiss</surname> <given-names>R</given-names></name><name><surname>Dubourg</surname> <given-names>V</given-names></name><name><surname>Vanderplas</surname> <given-names>J</given-names></name><name><surname>Passos</surname> <given-names>A</given-names></name><name><surname>Cournapeau</surname> <given-names>D</given-names></name><name><surname>Brucher</surname> <given-names>M</given-names></name><name><surname>Perrot</surname> <given-names>M</given-names></name><name><surname>Duchesnay</surname> <given-names>É</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in Python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phillips</surname> <given-names>DP</given-names></name><name><surname>Hall</surname> <given-names>SE</given-names></name><name><surname>Boehnke</surname> <given-names>SE</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Central auditory onset responses, and temporal asymmetries in auditory perception</article-title><source>Hearing Research</source><volume>167</volume><fpage>192</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/S0378-5955(02)00393-3</pub-id><pub-id pub-id-type="pmid">12117542</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pillow</surname> <given-names>JW</given-names></name><name><surname>Shlens</surname> <given-names>J</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name><name><surname>Sher</surname> <given-names>A</given-names></name><name><surname>Litke</surname> <given-names>AM</given-names></name><name><surname>Chichilnisky</surname> <given-names>EJ</given-names></name><name><surname>Simoncelli</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title><source>Nature</source><volume>454</volume><fpage>995</fpage><lpage>999</lpage><pub-id pub-id-type="doi">10.1038/nature07140</pub-id><pub-id pub-id-type="pmid">18650810</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollak</surname> <given-names>GD</given-names></name><name><surname>Bodenhamer</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Specialized characteristics of single units in inferior colliculus of mustache bat: frequency representation, tuning, and discharge patterns</article-title><source>Journal of Neurophysiology</source><volume>46</volume><fpage>605</fpage><lpage>620</lpage><pub-id pub-id-type="doi">10.1152/jn.1981.46.3.605</pub-id><pub-id pub-id-type="pmid">7299436</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qin</surname> <given-names>L</given-names></name><name><surname>Chimoto</surname> <given-names>S</given-names></name><name><surname>Sakai</surname> <given-names>M</given-names></name><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>Sato</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Comparison between offset and onset responses of primary auditory cortex ON-OFF neurons in awake cats</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>3421</fpage><lpage>3431</lpage><pub-id pub-id-type="doi">10.1152/jn.00184.2007</pub-id><pub-id pub-id-type="pmid">17360820</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remington</surname> <given-names>ED</given-names></name><name><surname>Egger</surname> <given-names>SW</given-names></name><name><surname>Narain</surname> <given-names>D</given-names></name><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>Jazayeri</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A dynamical systems perspective on flexible motor timing</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>938</fpage><lpage>952</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.07.010</pub-id><pub-id pub-id-type="pmid">30266152</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rothschild</surname> <given-names>G</given-names></name><name><surname>Nelken</surname> <given-names>I</given-names></name><name><surname>Mizrahi</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional organization and population dynamics in the mouse primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>353</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1038/nn.2484</pub-id><pub-id pub-id-type="pmid">20118927</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rotman</surname> <given-names>Y</given-names></name><name><surname>Bar-Yosef</surname> <given-names>O</given-names></name><name><surname>Nelken</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Relating cluster and population responses to natural sounds and tonal stimuli in cat primary auditory cortex</article-title><source>Hearing Research</source><volume>152</volume><fpage>110</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1016/S0378-5955(00)00243-4</pub-id><pub-id pub-id-type="pmid">11223286</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saha</surname> <given-names>D</given-names></name><name><surname>Sun</surname> <given-names>W</given-names></name><name><surname>Li</surname> <given-names>C</given-names></name><name><surname>Nizampatnam</surname> <given-names>S</given-names></name><name><surname>Padovano</surname> <given-names>W</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Chen</surname> <given-names>A</given-names></name><name><surname>Altan</surname> <given-names>E</given-names></name><name><surname>Lo</surname> <given-names>R</given-names></name><name><surname>Barbour</surname> <given-names>DL</given-names></name><name><surname>Raman</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Engaging and disengaging recurrent inhibition coincides with sensing and unsensing of a sensory stimulus</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>15413</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms15413</pub-id><pub-id pub-id-type="pmid">28534502</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>How linear are auditory cortical responses?</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>125</fpage><lpage>132</lpage></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savin</surname> <given-names>C</given-names></name><name><surname>Tkačik</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Maximum entropy models as a tool for building precise neural controls</article-title><source>Current Opinion in Neurobiology</source><volume>46</volume><fpage>120</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.08.001</pub-id><pub-id pub-id-type="pmid">28869818</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxena</surname> <given-names>S</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Towards the neural population doctrine</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>103</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.02.002</pub-id><pub-id pub-id-type="pmid">30877963</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scholl</surname> <given-names>B</given-names></name><name><surname>Gao</surname> <given-names>X</given-names></name><name><surname>Wehr</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Nonoverlapping sets of synapses drive on responses and off responses in auditory cortex</article-title><source>Neuron</source><volume>65</volume><fpage>412</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.020</pub-id><pub-id pub-id-type="pmid">20159453</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuessler</surname> <given-names>F</given-names></name><name><surname>Dubreuil</surname> <given-names>A</given-names></name><name><surname>Mastrogiuseppe</surname> <given-names>F</given-names></name><name><surname>Ostojic</surname> <given-names>S</given-names></name><name><surname>Barak</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dynamics of random recurrent networks with correlated low-rank structure</article-title><source>Physical Review Research</source><volume>2</volume><elocation-id>013111</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevResearch.2.013111</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seely</surname> <given-names>JS</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Tensor analysis reveals distinct population structure that parallels the different computational roles of Areas M1 and V1</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005164</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005164</pub-id><pub-id pub-id-type="pmid">27814353</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenoy</surname> <given-names>KV</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A dynamical systems view of motor preparation: implications for neural prosthetic system design</article-title><source>Progress in Brain Research</source><volume>192</volume><fpage>33</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/B978-0-444-53355-5.00003-8</pub-id><pub-id pub-id-type="pmid">21763517</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>RL</given-names></name><name><surname>Brachman</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Operating range and maximum response of single auditory nerve fibers</article-title><source>Brain Research</source><volume>184</volume><fpage>499</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(80)90817-3</pub-id><pub-id pub-id-type="pmid">7353165</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>RL</given-names></name><name><surname>Brachman</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Adaptation in auditory-nerve fibers: a revised model</article-title><source>Biological Cybernetics</source><volume>44</volume><fpage>107</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1007/BF00317970</pub-id><pub-id pub-id-type="pmid">7115787</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sollini</surname> <given-names>J</given-names></name><name><surname>Chapuis</surname> <given-names>GA</given-names></name><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Chadderton</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>ON-OFF receptive fields in auditory cortex diverge during development and contribute to directional sweep selectivity</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2084</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04548-3</pub-id><pub-id pub-id-type="pmid">29802383</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stopfer</surname> <given-names>M</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Laurent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Intensity versus identity coding in an olfactory system</article-title><source>Neuron</source><volume>39</volume><fpage>991</fpage><lpage>1004</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2003.08.011</pub-id><pub-id pub-id-type="pmid">12971898</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname> <given-names>C</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>High-dimensional geometry of population responses in visual cortex</article-title><source>Nature</source><volume>571</volume><fpage>361</fpage><lpage>365</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1346-5</pub-id><pub-id pub-id-type="pmid">31243367</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroud</surname> <given-names>JP</given-names></name><name><surname>Porter</surname> <given-names>MA</given-names></name><name><surname>Hennequin</surname> <given-names>G</given-names></name><name><surname>Vogels</surname> <given-names>TP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Motor primitives in space and time via targeted gain modulation in cortical networks</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1774</fpage><lpage>1783</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0276-0</pub-id><pub-id pub-id-type="pmid">30482949</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suga</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1964">1964</year><article-title>Single unit activity in cochlear nucleus and inferior colliculus of echo-locating bats</article-title><source>The Journal of Physiology</source><volume>172</volume><fpage>449</fpage><lpage>474</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1964.sp007432</pub-id><pub-id pub-id-type="pmid">14201578</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname> <given-names>D</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A neural network that finds a naturalistic solution for the production of muscle activity</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1025</fpage><lpage>1033</lpage><pub-id pub-id-type="doi">10.1038/nn.4042</pub-id><pub-id pub-id-type="pmid">26075643</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Trefethen</surname> <given-names>LN</given-names></name><name><surname>Embree</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><source>Spectra and Pseudospectra: The Behavior of Nonnormal Matrices and Operators</source><publisher-name>Princeton University Press</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-662-03972-4_6</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uurtio</surname> <given-names>V</given-names></name><name><surname>Monteiro</surname> <given-names>JM</given-names></name><name><surname>Kandola</surname> <given-names>J</given-names></name><name><surname>Shawe-Taylor</surname> <given-names>J</given-names></name><name><surname>Fernandez-Reyes</surname> <given-names>D</given-names></name><name><surname>Rousu</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A tutorial on canonical correlation methods</article-title><source>ACM Computing Surveys</source><volume>50</volume><fpage>1</fpage><lpage>33</lpage><pub-id pub-id-type="doi">10.1145/3136624</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vater</surname> <given-names>M</given-names></name><name><surname>Habbicht</surname> <given-names>H</given-names></name><name><surname>Kössl</surname> <given-names>M</given-names></name><name><surname>Grothe</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>The functional role of GABA and glycine in monaural and binaural processing in the inferior colliculus of horseshoe bats</article-title><source>Journal of Comparative Physiology A</source><volume>171</volume><fpage>541</fpage><lpage>553</lpage><pub-id pub-id-type="doi">10.1007/BF00194587</pub-id><pub-id pub-id-type="pmid">1469669</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname> <given-names>P</given-names></name><name><surname>Gommers</surname> <given-names>R</given-names></name><name><surname>Oliphant</surname> <given-names>TE</given-names></name><name><surname>Haberland</surname> <given-names>M</given-names></name><name><surname>Reddy</surname> <given-names>T</given-names></name><name><surname>Cournapeau</surname> <given-names>D</given-names></name><name><surname>Burovski</surname> <given-names>E</given-names></name><name><surname>Peterson</surname> <given-names>P</given-names></name><name><surname>Weckesser</surname> <given-names>W</given-names></name><name><surname>Bright</surname> <given-names>J</given-names></name><name><surname>van der Walt</surname> <given-names>SJ</given-names></name><name><surname>Brett</surname> <given-names>M</given-names></name><name><surname>Wilson</surname> <given-names>J</given-names></name><name><surname>Millman</surname> <given-names>KJ</given-names></name><name><surname>Mayorov</surname> <given-names>N</given-names></name><name><surname>Nelson</surname> <given-names>ARJ</given-names></name><name><surname>Jones</surname> <given-names>E</given-names></name><name><surname>Kern</surname> <given-names>R</given-names></name><name><surname>Larson</surname> <given-names>E</given-names></name><name><surname>Carey</surname> <given-names>CJ</given-names></name><name><surname>Polat</surname> <given-names>İ</given-names></name><name><surname>Feng</surname> <given-names>Y</given-names></name><name><surname>Moore</surname> <given-names>EW</given-names></name><name><surname>VanderPlas</surname> <given-names>J</given-names></name><name><surname>Laxalde</surname> <given-names>D</given-names></name><name><surname>Perktold</surname> <given-names>J</given-names></name><name><surname>Cimrman</surname> <given-names>R</given-names></name><name><surname>Henriksen</surname> <given-names>I</given-names></name><name><surname>Quintero</surname> <given-names>EA</given-names></name><name><surname>Harris</surname> <given-names>CR</given-names></name><name><surname>Archibald</surname> <given-names>AM</given-names></name><name><surname>Ribeiro</surname> <given-names>AH</given-names></name><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>van Mulbregt</surname> <given-names>P</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Lu</surname> <given-names>T</given-names></name><name><surname>Snider</surname> <given-names>RK</given-names></name><name><surname>Liang</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Sustained firing in auditory cortex evoked by preferred stimuli</article-title><source>Nature</source><volume>435</volume><fpage>341</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/nature03565</pub-id><pub-id pub-id-type="pmid">15902257</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural coding strategies in auditory cortex</article-title><source>Hearing Research</source><volume>229</volume><fpage>81</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2007.01.019</pub-id><pub-id pub-id-type="pmid">17346911</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williamson</surname> <given-names>RS</given-names></name><name><surname>Ahrens</surname> <given-names>MB</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Input-Specific gain modulation by local sensory context shapes cortical and thalamic responses to complex sounds</article-title><source>Neuron</source><volume>91</volume><fpage>467</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.041</pub-id><pub-id pub-id-type="pmid">27346532</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winer</surname> <given-names>JA</given-names></name><name><surname>Larue</surname> <given-names>DT</given-names></name><name><surname>Diehl</surname> <given-names>JJ</given-names></name><name><surname>Hefti</surname> <given-names>BJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Auditory cortical projections to the cat inferior colliculus</article-title><source>The Journal of Comparative Neurology</source><volume>400</volume><fpage>147</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19981019)400:2&lt;147::AID-CNE1&gt;3.0.CO;2-9</pub-id><pub-id pub-id-type="pmid">9766397</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname> <given-names>N</given-names></name><name><surname>Fu</surname> <given-names>Z-Y</given-names></name><name><surname>Chen</surname> <given-names>Q-C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The function of offset neurons in auditory information processing</article-title><source>Translational Neuroscience</source><volume>5</volume><fpage>275</fpage><lpage>285</lpage><pub-id pub-id-type="doi">10.2478/s13380-014-0235-5</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>YQ</given-names></name><name><surname>Xiong</surname> <given-names>Y</given-names></name><name><surname>Chan</surname> <given-names>YS</given-names></name><name><surname>He</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title><italic>In vivo</italic> intracellular responses of the medial geniculate neurones to acoustic stimuli in anaesthetized guinea pigs</article-title><source>The Journal of Physiology</source><volume>560</volume><fpage>191</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2004.067678</pub-id><pub-id pub-id-type="pmid">15272038</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.53151.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Hennequin</surname><given-names>Guillaume</given-names> </name><role>Reviewer</role><aff><institution>University of Cambridge</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper explores the hypothesis that OFF responses are single-cell signatures of network dynamics, and shows convincingly that a model based on recurrent interactions does a much better job explaining the data than the de- facto standard model, which is based purely on single cell dynamics. In addition, the proposed recurrent network model generates transient OFF responses very similar to what is seen in experiments.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Population coding and network dynamics during OFF responses in auditory cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Barbara Shinn-Cunningham as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Guillaume Hennequin (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission. Please aim to submit the revised version within two months.</p><p>Summary:</p><p>In this paper, Bondanelli and colleagues study the spatiotemporal structure of OFF responses in A1. They propose that these responses arise from a simple linear mechanism involving a certain form of nonnormal population dynamics. They fit such a network model to A1 data and find that it explains several important aspects of OFF responses, some, but importantly, not all, of which are also captured by a single-neuron mechanism.</p><p>Essential revisions:</p><p>We're very sorry for the long delay. That's in part because at least one of use found the paper very hard to read, and it took a long time to figure out what was going on. And as you'll see, it's not clear if we did that very well. We think the problem is that you're missing quantitative analysis; in many cases it seems that we're supposed to understand why a particular piece of analysis supported your model, but it simply wasn't clear to us why that was true. Explicit examples of this will be given below.</p><p>A major issue for us has been that you begin with a discussion of special cases of Equation (2) (last two paragraphs of page 6) but then go on to test predictions of THE model without telling us which of these special assumptions you are actually making (if any) in the production of your results (Figure 4 specifically). We believe that the first paragraph of &quot;Testing the network mechanisms on the data&quot; should begin with a clear description of the actual model considered (including whether your transient channels are mutually orthogonal, and how initial conditions relate to those planes).</p><p>More specifically, to summarize our current understanding: under the assumption that the v's are orthonormal, the u's are orthogonal, and u<sub>k</sub> dot v<sub>l</sub> = 0 for all k \ne l (not strictly true, but close enough in high dimensions), the most general solution (a generalization of Eq. 34 to an arbitrary number of modes) is</p><p>r(t) = [uperp + sum<sub>k</sub> u<sub>k</sub> (a<sub>k</sub> + v<sub>k</sub> dot u<sub>k</sub> t)] exp(-t)</p><p>where uperp is perpendicular to all the u<sub>k</sub> and the a<sub>k</sub> are arbitrary.</p><p>This appears late in Methods. But it's important, because there seem to be hidden assumptions about uperp and the a<sub>k</sub>. Namely,</p><p>- the a<sub>k</sub> are all set to zero</p><p>- uperp = u<sub>k</sub> for only one k, with k dependent on the stimulus.</p><p>Assuming this is correct, it's a critical part of the model. And it is, in fact, an extra assumption.</p><p>Given that setup, we believe there were several predictions:</p><p>a. Lines 216-228: There's a prediction about the correlational structure that we didn't fully understand. Equations are needed, in the main text, that make the predictions explicit.</p><p>b. Lines 229-238: Correlations between the beginning and the peak of the off response should small. Again, equations are needed; this should be quantified.</p><p>c. Lines 239-253:</p><p>&quot;To further examine to which extent the population dynamics during OFF responses could be accounted for by a non-normal linear dynamical system, we next fitted our network model population OFF responses to all stimuli at once using reduced-rank regression (Figure S1; see Methods). Qualitatively, we found that the fit reproduced well the low-dimensional population trajectories (Figure 4C).&quot;</p><p>As far as we could tell, this just tells us that the fit is good; it doesn't tell us anything about whether the OFF responses could be accounted for by a non-normal linear dynamical system. Is that correct, or did we miss something? If that is correct, it seems like this paragraph is mainly a distractor.</p><p>d. Lines 254-262: The fitted connectivity, J, had eigenvalues less than 1 and the symmetrized version had eigenvalues greater than 1. That's consistent with the low rank, non-normal model. However, couldn't such a J could come from a high rank, non-normal model? If so, it's not strong evidence for your model. This should be clarified.</p><p>e. Lines 263-283: There were several results here, but it's not clear how much they supported the model. For example,</p><p>&quot;We computed the overlap between the subspaces spanned by the transient channels for each pair of stimuli s<sub>1</sub> and s<sub>2</sub> , analogous to the overlap between the vectors u<sup>(s1)</sup> and u<sup>(s2)</sup> in Eq. (2) (see Methods). We found that the overlap between the transient channels matched the overlap between the response dynamics and population states at the end of stimulus presentation (Figure 4F, right panel), consistent with the interpretation that individual OFF responses may be generated through transient coding channels of the form given by Eq. (2).&quot;</p><p>It's not clear what we should expect here. Is this strong or weak evidence for the model? You need to quantify what we should expect, and be clear whether this is only consistent with the model, or provides evidence for it.</p><p>&quot;While the fraction of variance explained when using the matrix J<sub>Sum</sub> was necessarily lower than the one computed using J<sub>Full</sub> , the model with connectivity J<sub>Sum</sub> could still explain a consistent fraction of the total variance, and yielded values of R<sup>2</sup> significantly higher than the ones obtained from the shuffles.&quot;</p><p>Again, it's not clear what we should expect. Is this strong or weak evidence for the model?</p><p>f. Lines 328-331: for the single cell model in Eq. 3, the correlations between the beginning and peak of the off response are high. This seems easily fixable with a very minor tweak. Suppose there are two kinds of neurons, some that peak early,</p><p>r<sub>i</sub>(t) = a<sub>i</sub>(s) f<sub>i</sub>(t)</p><p>and some that peak late,</p><p>r<sub>i</sub>(t) = b<sub>i</sub>(s) g<sub>i</sub>(t)</p><p>(for instance, f<sub>i</sub>(t) = Theta(t) e^{-t} and g<sub>i</sub>(t) = Theta(t) t*e^{-t}). Different stimuli (s) could activate different sets of neurons.</p><p>Alternatively, the single neuron responses could be of the form</p><p>r<sub>i</sub>(t) = a<sub>i</sub>(s) f<sub>i</sub>(t) + b<sub>i</sub>(s) g<sub>i</sub>(t)</p><p>where the a's and b's are anti correlated (either a is large and b is small or vice versa) and f<sub>i</sub> and g<sub>i</sub> are as above.</p><p>Are these model ruled out by the data? If not, that seems to weaken the paper (although maybe there are other things wrong with these models). In either case, models like these should be discussed.</p><p>g. Lines 332-353:</p><p>&quot;A second important difference between the two models is that in the single-cell model the temporal shape of the response of each neuron is the same across all stimuli, while for the recurrent model this is not necessarily the case.&quot;</p><p>Given this opening sentence, why not just show that for the recurrent network model, the temporal shape of the response is not the same across all stimuli? Instead, there's a lot of analysis that we didn't fully understand. In particular, there's a rather sudden switch from specifying the form of L<sub>i</sub>(t) (Eq. 44) and fitting L<sub>i</sub>(t) (Eq. 48). What's missing is a quantitative prediction of what we should expect, followed by a demonstration that the data is consistent with that prediction.</p><p>In addition, we have some specific suggestions.</p><p>1. Lines 174-177,</p><p>&quot;We focus on two outstanding properties identified in the OFF responses to different stimuli. The first one is the strong amplification of OFF responses, as quantified by the transient increase of the distance from baseline ||r(t)||. The second important feature is the low-dimensionality of OFF response trajectories and their global structure across different stimuli.&quot;</p><p>It seems that this is all you're going to focus on, but it's not. It would be nice to know, at some point early in the manuscript, exactly what you're going to do.</p><p>2. What's the difference between Figures 2D and 4A (left panel).</p><p>3. Lines 329-31,</p><p>&quot;The single-cell model predicts that these two states are only weakly decorrelated and essentially lie along a single dimension (Figure 5E and S7), which is inconsistent with experimental observations&quot;</p><p>Which experimental observations?</p><p>4. Throughout the paper we found it unclear how initial conditions were chosen for the model, e.g. in Figure 3. From line 167, we are led to think that they are picked from the actual data, &quot;we model the firing activity at the end of stimulus presentation as the initial condition of the network dynamics&quot; -- since the model doesn't explicitly models the stimulus period as far as we understand (?), we infer this activity is taken from the data? But does the model even have the same number of neurons?</p><p>5. The purpose of Figure 2 is to convey that different stimuli evoke orthogonal OFF responses, and these OFF responses are low dimensional. By my calculation, for each conditional mean (over 20 trials), there are 400ms * 31.5 frame/s ~= 13 samples used to estimate the PCs and variance explained resulting in a maximum dimensionality (PCs to get to 80%) of 13. If this is the case, a more careful comparison to the cross-condition dimensionality is warranted, which accounts for sample size.</p><p>Also, we would expect there to be fewer time points on the traces in Figure 2B. How were the trial-averaged responses interpolated?</p><p>What steps were taken to insure that the same unit wasn't double counted during pooling across sessions. Mistakes in this process can contribute to inflated variance along primary PC's creating the illusion of low dimensionality.</p><p>6. Statements of relative degree of subspace overlap should be verified with a hypothesis test. For data, this can be done by resampling neurons.</p><p>7. You should justify why LDA (naive covariance assumption) is more suitable for assessing linear separability in Figure 1C than an SVM. Absent justification, an SVM should be used to get the clearest assessment of linear separability.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Network dynamics underlying OFF responses in the auditory cortex&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Barbara Shinn-Cunningham (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>The good news is that the paper is much improved. The writing is more clear, and the analysis of dimensions of amplified trial-to-trial variability is compelling. The less good news is that now that we understand it better, additional issues have come up. All can, we believe, be dealt with relatively easily.</p><p>Let's start with the data you're are trying to explain. Basically, after the offset of an auditory stimulus, there is transient amplification, with different stimuli activating nearly orthogonal subspaces.</p><p>To model this, low rank linear dynamics is used, of the form</p><p>dr/dt = sum_{k=1}^R u<sub>k</sub> v<sub>k</sub> r – r,</p><p>where r (=r1, r2,.…, rN) is the trial averaged activity. The network had a few additional properties,</p><p>a. The rank, R, is much less than the number of neurons, N.</p><p>b. The u's and v's are nearly orthogonal.</p><p>c. The symmetric part of the connectivity matrix must have eigenvalues with real part &gt;1.</p><p>d. The model has no external input, so the response to a particular stimulus (after offset) depends only on the value of r immediately after stimulus offset, here denoted r0(s) where s is the stimulus.</p><p>e. For any stimulus, s, r0(s) has appreciable overlap with a small number of v<sub>k</sub> (on the order of 5).</p><p>This model did an OK job explaining the data. In particular, Figure 4H, left (the model), is supposed to match Figure 2D (the data). But the match is not so good: the off-diagonal channel overlap in Figure 2D is near zero, whereas it's around 0.5 in Figure 4H. And the full model explains only about half the variance (Figure 4H, Right).</p><p>In addition, you claim that the dynamics is autonomous. The test for this is described on lines 251-9:</p><p>&quot;We first tested the starting assumption that the OFF response trajectories are consistent with linear, autonomous network dynamics driven only by the initial pattern of activity and network interactions. If that is the case, the OFF response dynamics are fully determined by the initial activity at stimulus offset (<italic>t</italic> = 0). This assumption implies that the geometric structure of the initial activity states r<sub>0</sub><sup>(s)</sup> fully predicts the geometric structure of the dynamics r<sup>(s)</sup>(<italic>t</italic>) during the OFF responses (see Materials and methods). In particular, two stimuli s<sub>1</sub> and s<sub>2</sub> corresponding to correlated initial states r<sub>0</sub><sup>(s1)</sup> and r<sub>0</sub><sup>(s2)</sup> will lead to correlated trajectories r<sup>(s1)</sup>(t) and r<sup>(s2)</sup>(t) in the model. Conversely, if two OFF-response trajectories r<sup>(s1)</sup>(t) and r<sup>(s2)</sup>(t) are orthogonal, the initial states r<sub>0</sub><sup>(s1)</sup> and r<sub>0</sub><sup>(s</sup><sub>2</sub><sup>)</sup> are necessarily orthogonal.&quot;</p><p>We're pretty sure that isn't correct: correlations are preserved only if the dynamics causes pure rotation at constant angular speed, something that doesn't happen in general, even for linear dynamics.</p><p>And finally, Figure 4E, right, shows that many u's and v's are not orthogonal -- judging from that figure, on the order of 10-20%. These terms were of the form</p><p>|u1| v2 v1 – |u2| v1 v2</p><p>where v1 and v2 are nearly orthogonal. You claim that terms like this can't lead to transient amplification. That's true if |u_1|=|u_2|. But if |u_1| and |u_2| are sufficiently different, it's not true. But maybe |u_1| \approx |u_2| in the data? If so, that should be clear. In any case, this seems like a detail -- it's certainly possible to do the analysis with these terms included.</p><p>The lack of orthogonality between the u's and v's doesn't seem so serious. But the lack of agreement between Figures 2D and 4H, combined with no strong evidence for autonomous dynamics, seems potentially problematic. Of course, no model ever fits perfectly. But it's hard to figure out exactly what the take-home message is. If there was strong evidence that the dynamics is autonomous, that would help -- at least we would know that the intrinsic dynamics is responsible for the transient amplification.</p><p>As a potentially important aside: the eigenvalue spectrum of Figure 4D shows one marginally stable, non-oscillatory mode. Based on past experience of one of the reviewers, it may be that the lack of agreement between Figures 2D and 4H is because of this mode. The reasoning is that if this slow mode is present by a small amount in all initial conditions, it will generate the fairly weak overlap in Figure 2D, but because it sticks, it might end up dominating the late off-responses for each stimulus after all the rest has decayed away. If that's the case, then this mode will be part of the principal subspace extracted for each stimulus. The measure of overlap based on &quot;subspace angle&quot; is very sensitive to this, which could explain the large overlaps in Figure 4H. Importantly, that marginally stable eigenvalue may be an artifact of insufficient regularization. There are a lot of &quot;ifs&quot; in the above reasoning, but if this mode can be eliminated, perhaps by different regularization, agreement may improve. We don't know if that's possible, but it's worth thinking about.</p><p>There is a lot of very nice analysis in the paper, and all reviewers agree that it should be published. However, it needs a clear take-home message. Exactly what that is depends, we believe, on how strongly the evidence is for autonomous dynamics. If that's very strong, then at the very least the take-home message is:</p><p>&quot;Off cells show transient amplification that is generated by internal dynamics, not external input. That transient dynamics is mildly consistent with low rank connectivity in which dynamics can mainly be reduced to multiple 2-D systems. However, we can't rule out more complex behavior, with transient amplification fundamentally involving several dimensions.&quot;</p><p>Possibly you can come up with a stronger conclusion, but that's the best we could come up with.</p><p>If the evidence for autonomous dynamics is weak, that seems to be a fundamental problem, since the transient amplification may be caused solely by external input. But presumably that can never be ruled out -- a fact that you should probably mention. It's not a plausible scenario, so we don't think it will weaken the paper..</p><p>Our main comment, then, is to explore more carefully whether or not dynamics is autonomous, and/or be more careful about the conclusions. One possible way to test for autonomous dynamics is to plot the trajectories and look for intersections, or near intersections -- what Mark Churchland calls tangled trajectories, for which quantification is possible. Absence of near intersections would at least be consistent with autonomous dynamics. But there may be better methods. For instance, you might try LFADS: you can fit both an RNN and a linear dynamical model, and see which one fits better. That will, though, be a huge amount of work, and you should do it only if you want to.</p><p>In addition, we suggest exploring a richer single-neuron model. The current model has the form</p><p>r<sub>i</sub>^s(t) = r_{0i}^s L<sub>i</sub>(t).</p><p>If r<sub>i</sub> is non-negative, this can be written</p><p>dr_i/dt = f<sub>i</sub>(t) r<sub>i</sub>,</p><p>with r<sub>i</sub>(t=0) a function of the stimulus. It would be more convincing to consider a model with a nonlinearity; say</p><p>dr<sub>i</sub>/dt = f<sub>i</sub>(t) g<sub>i</sub>(r<sub>i</sub>).</p><p>The nonlinearity g<sub>i</sub> could be parameterized with, probably, only a handful of parameters. For instance, it could be written as a sum of basis functions, much the way L<sub>i</sub> was parameterised. The single-cell model was rejected because it explained only about 20% of the variance, versus 50% for the recurrent network. It would be reassuring if adding a nonlinearity didn't bring this up to 50%. Again, this also is only a suggestion. However, if you stick with the current single cell model, you'll need to frame your comparison less generally than &quot;recurrent versus single cell&quot;.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.53151.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>We're very sorry for the long delay. That's in part because at least one of use found the paper very hard to read, and it took a long time to figure out what was going on. And as you'll see, it's not clear if we did that very well. We think the problem is that you're missing quantitative analysis; in many cases it seems that we're supposed to understand why a particular piece of analysis supported your model, but it simply wasn't clear to us why that was true. Explicit examples of this will be given below.</p></disp-quote><p>We thank the reviewers for a very constructive feedback which has allowed us to significantly improve the manuscript. Following the reviewers’ suggestions we have rewritten large parts of the Results and Methods. Here we first briefly list the main analyses we added. Further below, we explain the new structure of the manuscript, and how the new analyses address the reviewers’ comments.</p><p>List of new analyses:</p><p>– We theoretically derived quantitative predictions on the structure of the network connectivity for a general l ow-rank connectivity matrix and tested these predictions on the AC data (Figure 4E, Methods Section 2.3, 2.7);</p><p>– We derived quantitative predictions for the relationship between the structure of the network connectivity and the population vector at stimulus offset and tested these predictions on AC data (Figure 4F, Methods Section 2.3);</p><p>– We derived quantitative prediction for the value of the correlation between the population activity vectors at stimulus offset and at the time of maximum distance from baseline (Figure 4G, Methods Section 2.5);</p><p>– We added a method section illustrating the prediction for he correlation between the structure of the population vectors at stimulus offset and dynamical trajectories (Figure 4A) f or a general low-rank network model (Methods Section 2.4);</p><p>– We adopted a different approach when comparing the recurrent model with the single-cell model. In the new version of the manuscript, we fit directly the form of the temporal responses of the single units L<sub>i</sub>(t) to the data (we correspondingly updated Figure 5B-C; Methods Section 3.1). We then compare the predictions of the two models on AC data (Figure 5F).</p><p>– We added a new (unrequested) analysis comparing the predictions of the recurrent and single-cell model on the population dynamics across single-trials (Figure 6, Methods Section 3.2, 3.3). We show that the two models yield quantitatively different predictions for the structure of the trial-to-trial response variability, and that the AC data i s consistent with the recurrent model and not with the single-cell model. This adds substantial new evidence i n favor of the recurrent model.</p><p>– We added controls f or the principal component analysis of the OFF responses to individual stimuli and across stimuli (Figure S1, Methods Section 1.4), and for the values of subspace overlap (i.e. Figure 2D) and correlation between i nitial and peak states (i.e. Figure 4G). These controls are described i n detail i n Methods Sections 1.6 and shown i n Figure S7, S8.</p><disp-quote content-type="editor-comment"><p>A major issue for us has been that you begin with a discussion of special cases of Equation (2) (last two paragraphs of page 6) but then go on to test predictions of THE model without telling us which of these special assumptions you are actually making (if any) in the production of your results (Figure 4 specifically). We believe that the first paragraph of &quot;Testing the network mechanisms on the data&quot; should begin with a clear description of the actual model considered (including whether your transient channels are mutually orthogonal, and how initial conditions relate to those planes).</p></disp-quote><p>Following the reviewers’ suggestion, we have totally rewritten the subsection “Recurrent network mechanism” (and the corresponding Methods) and most of the subsections “Testing the network mechanism” and “Comparison with a single-cell model”.</p><p>To help the reviewers navigate the changes, here we provide a summary of the new organization of the manuscript.</p><p>First two subsections of Results: we use population analysis of calcium activity identify three main features of OFF responses in the auditory cortex:</p><p>F1. OFF responses correspond to transiently amplified trajectories;</p><p>F2. responses to individual stimuli lie in low-dimensional subspaces;</p><p>F3. responses to different stimuli lie in largely orthogonal subspaces.</p><p>Subsection “Recurrent network mechanism”: we propose a recurrent network model f or OFF responses based on only two hypotheses:</p><p>H1. dynamics are driven exclusively by recurrent interactions (Eq. 1), and the only effect of each stimulus s is to set the initial state r<sub>0</sub><sup>s</sup> that corresponds to activity at stimulus offset;</p><p>H2. the recurrent connectivity is of l ow-rank type, i.e. characterized by a set of connectivity vectors u<sup>r</sup> and v<sub>r</sub> (Eq. 1).</p><p>We then systematically derive a set of sufficient conditions on vectors u<sup>r</sup>, v<sup>r</sup> and r<sub>0</sub><sup>s</sup> to reproduce the observed features F1-F3. These sufficient conditions provide corresponding predictions P1-P3 that can be tested on the data.</p><p>Subsection “Testing the network mechanism”: we systematically test on the data the hypotheses H1 and H2, as well as the predictions P1-P3. The structure of this subsection now mirrors the structure of “Recurrent network mechanism”.</p><p>Subsection “Comparison with a single-cell model”: we first compare predictions of the fitted models on trial-averaged data; we then compare new predictions f or trial-to-trial variability.</p><disp-quote content-type="editor-comment"><p>More specifically, to summarize our current understanding: under the assumption that the v's are orthonormal, the u's are orthogonal, and u<sub>k</sub> dot v<sub>l</sub> = 0 for all k \ne l (not strictly true, but close enough in high dimensions), the most general solution (a generalization of Eq. 34 to an arbitrary number of modes) is</p><p>r(t) = [uperp + sum<sub>k</sub> u<sub>k</sub> (a<sub>k</sub> + v<sub>k</sub> dot u<sub>k</sub> t)] exp(-t)</p><p>where uperp is perpendicular to all the u<sub>k</sub> and the a<sub>k</sub> are arbitrary.</p><p>This appears late in Methods. But it's important, because there seem to be hidden assumptions about uperp and the a<sub>k</sub>. Namely,</p><p>– the a<sub>k</sub> are all set to zero</p><p>– uperp = u<sub>k</sub> for only one k, with k dependent on the stimulus.</p><p>Assuming this is correct, it's a critical part of the model. And it is, in fact, an extra assumption.</p></disp-quote><p>The new version of the text clarifies i n detail the questions raised by the reviewers. In short, we make no a priori assumptions on vectors u<sup>r</sup>, v<sup>r</sup> and r<sub>0</sub><sup>s</sup> (the initial state) other than that the v's are orthonormal, the u's are orthogonal, but there is no loss of generality there (such u’s and v’s can be uniquely specified by an SVD of the connectivity matrix).</p><p>We then derive sufficient conditions on u+ and v<sup>r</sup> (u<sub>k</sub>, v<sub>k</sub> in the reviewers' notation) and r<sub>0</sub> to reproduce F1-F3, and find i n particular:</p><p>– An upper bound on u<sup>r</sup> dot v<sup>s</sup> (always satisfied if u<sup>r</sup> dot v<sub>s</sub> = 0 for all r,s) to have transient amplification (F1)</p><p>– Conditions on r<sub>0</sub> with respect to u<sup>r</sup>, v<sup>r</sup>, that correspond to conditions on uperp and a<sub>k</sub> in the reviewers’ notation</p><p>We next fit the network model on the data (without specific constraints on u<sup>r</sup>, v<sup>r</sup> and r<sub>0</sub><sup>s</sup>), and check whether the predicted constraints on u<sup>r</sup>, v<sup>r</sup> and r<sub>0</sub><sup>s</sup> hold.</p><p>The methods now start with equations equivalent to the general solution put forward by the reviewers (Eq. 33 i n a unit-rank example, and Eq. 35 for arbitrary rank).</p><disp-quote content-type="editor-comment"><p>Given that setup, we believe there were several predictions:</p><p>a. Lines 216-228: There's a prediction about the correlational structure that we didn't fully understand. Equations are needed, in the main text, that make the predictions explicit.</p></disp-quote><p>The goal was simply to test H1, i.e. that the states of initial activity at stimulus offset determine the ensuing dynamics. We have rewritten that part of the text, and added a detailed section i n the Methods (Section 2.4, &quot;Correlation between structure of initial states and structure of the dynamics&quot;).</p><disp-quote content-type="editor-comment"><p>b. Lines 229-238: Correlations between the beginning and the peak of the off response should small. Again, equations are needed; this should be quantified.</p></disp-quote><p>In the new organization of the text, this prediction now appears later. We have now derived a quantitative prediction for the upper bound of the correlation between initial state and peak response (Methods Section 2.5, &quot;Correlation between initial and peak state&quot;), and added a panel (Figure 4G) demonstrating this prediction is quantitatively satisfied.</p><disp-quote content-type="editor-comment"><p>c. Lines 239-253:</p><p>&quot;To further examine to which extent the population dynamics during OFF responses could be accounted for by a non-normal linear dynamical system, we next fitted our network model population OFF responses to all stimuli at once using reduced-rank regression (Figure S1; see Methods). Qualitatively, we found that the fit reproduced well the low-dimensional population trajectories (Figure 4C).&quot;</p><p>As far as we could tell, this just tells us that the fit is good; it doesn't tell us anything about whether the OFF responses could be accounted for by a non-normal linear dynamical system. Is that correct, or did we miss something? If that is correct, it seems like this paragraph is mainly a distractor.</p></disp-quote><p>The aim of this paragraph is twofold: (i) test H1, i.e. show an autonomous dynamical system is a good model of the data, using the approach introduced in Elsayed and Cunningham (2017) (ii) determine the effective connectivity matrix, and extract vectors u<sup>r</sup> and v<sup>r</sup>, which are then used to test the predictions on the relationship between u<sup>r</sup>, v<sup>r</sup> and r<sub>0</sub><sup>s</sup> (Figure 4 F and F). We have now rephrased that part (and reorganized the whole subsection).</p><disp-quote content-type="editor-comment"><p>d. Lines 254-262: The fitted connectivity, J, had eigenvalues less than 1 and the symmetrized version had eigenvalues greater than 1. That's consistent with the low rank, non-normal model. However, couldn't such a J could come from a high rank, non-normal model? If so, it's not strong evidence for your model. This should be clarified.</p></disp-quote><p>The reviewers are correct, the examination of the eigenvalues tests only the predictions that ensue from H1 (autonomous dynamical system), not H2 (low-rank structure). So this test provides only evidence for H1, not H2, and we have clarified that i n the new version of the text. H2 and the ensuing predictions are tested separately.</p><disp-quote content-type="editor-comment"><p>e. Lines 263-283: There were several results here, but it's not clear how much they supported the model. For example,</p><p>&quot;We computed the overlap between the subspaces spanned by the transient channels for each pair of stimuli s<sub>1</sub> and s<sub>2</sub> , analogous to the overlap between the vectors u<sup>(s1)</sup> and u<sup>(s2)</sup> in Eq. (2) (see Methods). We found that the overlap between the transient channels matched the overlap between the response dynamics and population states at the end of stimulus presentation (Figure 4F, right panel), consistent with the interpretation that individual OFF responses may be generated through transient coding channels of the form given by Eq. (2).&quot;</p><p>It's not clear what we should expect here. Is this strong or weak evidence for the model? You need to quantify what we should expect, and be clear whether this is only consistent with the model, or provides evidence for it.</p></disp-quote><p>Here we test the predictions that result from the requirement that the model reproduces F3 (orthogonal trajectories in response to different stimuli). The corresponding prediction has now been made explicit in the “Recurrent network mechanism” subsection. Specifically, we test Eqs. 3-4.</p><disp-quote content-type="editor-comment"><p>&quot;While the fraction of variance explained when using the matrix J=Sum was necessarily lower than the one computed using J=Full , the model with connectivity J=Sum could still explain a consistent fraction of the total variance, and yielded values of R<sup>2</sup> significantly higher than the ones obtained from the shuffles.&quot;</p><p>Again, it's not clear what we should expect. Is this strong or weak evidence for the model?</p></disp-quote><p>We have now rephrased this part. If the prediction (Eqs.3-4) i s exact, the explained variance should be the same i f the model was f it on the responses to all stimuli at once, or separately on responses to different stimuli. We find that the explained variance i s slightly lower i n the second case, but still much larger than chance (as could be expected, since the responses are orthogonal to many, but not all stimuli). Hence Eq.3 i s not exact, but a reasonable approximation. The strength of the evidence f or the model i s therefore directly quantified by the value of R<sup>2</sup> when fitting the model separately to different stimuli.</p><disp-quote content-type="editor-comment"><p>f. Lines 328-331: for the single cell model in Eq. 3, the correlations between the beginning and peak of the off response are high. This seems easily fixable with a very minor tweak. Suppose there are two kinds of neurons, some that peak early,</p><p>r<sub>i</sub>(t) = a<sub>i</sub>(s) f<sub>i</sub>(t)</p><p>and some that peak late,</p><p>r<sub>i</sub>(t) = b<sub>i</sub>(s) g<sub>i</sub>(t)</p><p>(for instance, f<sub>i</sub>(t) = Theta(t) e^{-t} and g<sub>i</sub>(t) = Theta(t) t*e^{-t}). Different stimuli (s) could activate different sets of neurons.</p><p>Alternatively, the single neuron responses could be of the form</p><p>r<sub>i</sub>(t) = a<sub>i</sub>(s) f<sub>i</sub>(t) + b<sub>i</sub>(s) g<sub>i</sub>(t)</p><p>where the a's and b's are anti correlated (either a is large and b is small or vice versa) and f<sub>i</sub> and g<sub>i</sub> are as above.</p><p>Are these model ruled out by the data? If not, that seems to weaken the paper (although maybe there are other things wrong with these models). In either case, models like these should be discussed.</p></disp-quote><p>In the original manuscript, the correlations between initial and peak activity were assessed by assuming a specific form of the single-neuron response, without constraining i t by the data. Rather than explore this quantity for various assumptions on the single-neuron responses, we decided to first fit the single-neuron responses to data, and then compute the resulting correlations between initial and peak activity. Figure 5F shows that these correlations are much higher than on actual activity trajectories. This clearly demonstrates that the single model does not capture the decorrelation present in the data. (note that the second form suggested by the reviewers, r<sub>i</sub>(t) = a<sub>i</sub>(s) f<sub>i</sub>(t) + b<sub>i</sub>(s) g<sub>i</sub>(t), is not consistent with our hypothesis that a single-cell response depends only on the activity of the cell at stimulus offset; it is instead equivalent to a unit-rank network).</p><p>We moreover added a new analysis and figure (Figure 6) comparing the predictions of the recurrent and single-cell mechanisms for trial-to-trial fluctuations. The results clearly indicate that the single-cell model is inconsistent with the data, and provide significant new evidence in favor of the network model.</p><disp-quote content-type="editor-comment"><p>g. Lines 332-353:</p><p>&quot;A second important difference between the two models is that in the single-cell model the temporal shape of the response of each neuron is the same across all stimuli, while for the recurrent model this is not necessarily the case.&quot;</p><p>Given this opening sentence, why not just show that for the recurrent network model, the temporal shape of the response is not the same across all stimuli? Instead, there's a lot of analysis that we didn't fully understand. In particular, there's a rather sudden switch from specifying the form of L<sub>i</sub>(t) (Eq. 44) and fitting L<sub>i</sub>(t) (Eq. 48). What's missing is a quantitative prediction of what we should expect, followed by a demonstration that the data is consistent with that prediction.</p></disp-quote><p>We thank the reviewers for this important comment. In the new version of the manuscript, we have totally removed the part where we assumed a specific form of single-neuron responses. We now fit i t to the data right away.</p><p>Following the reviewers’ suggestion, we also show that in the network model the temporal shape of the response is not the same across stimuli (Figure 3E).</p><disp-quote content-type="editor-comment"><p>In addition, we have some specific suggestions.</p><p>1. Lines 174-177,</p><p>&quot;We focus on two outstanding properties identified in the OFF responses to different stimuli. The first one is the strong amplification of OFF responses, as quantified by the transient increase of the distance from baseline ||r(t)||. The second important feature is the low-dimensionality of OFF response trajectories and their global structure across different stimuli.&quot;</p><p>It seems that this is all you're going to focus on, but it's not. It would be nice to know, at some point early in the manuscript, exactly what you're going to do.</p></disp-quote><p>As mentioned above, we have now completely reorganized the manuscript to make clear we focus on three features identified i n the data (F1-F3 listed above). These features are now clearly listed in the abstract, introduction and provide the guiding line throughout the results.</p><disp-quote content-type="editor-comment"><p>2. What's the difference between Figures 2D and 4A (left panel).</p></disp-quote><p>Figure 2D displays the correlation matrix between the subspaces explored during the OFF responses to different stimuli. Figure 4A displays the correlation matrix of the initial states (=activity at stimulus offset, not included in the OFF responses). We have now clarified this i n the text and figure legends.</p><disp-quote content-type="editor-comment"><p>3. Lines 329-31,</p><p>&quot;The single-cell model predicts that these two states are only weakly decorrelated and essentially lie along a single dimension (Figure 5E and S7), which is inconsistent with experimental observations&quot;</p><p>Which experimental observations?</p></disp-quote><p>We have rephrased this sentence. As mentioned above, in the new version of the manuscript, we don't fix the shape of the single-cell responses, but instead fit them directly to the data. We compute the correlation between initial state and peak state from the fitted responses when fitting the single-cell model to a progressively increasing number of stimuli. We found that the value of the correlation predicted by the single-cell model deviated from the experimental value as more stimuli were included in the fit, in contrast to the recurrent model, which predicted a value of the correlation consistent with data for any number of fitted stimuli (Figure 5F).</p><disp-quote content-type="editor-comment"><p>4. Throughout the paper we found it unclear how initial conditions were chosen for the model, e.g. in Figure 3. From line 167, we are led to think that they are picked from the actual data, &quot;we model the firing activity at the end of stimulus presentation as the initial condition of the network dynamics&quot; -- since the model doesn't explicitly models the stimulus period as far as we understand (?), we infer this activity is taken from the data? But does the model even have the same number of neurons?</p></disp-quote><p>Figure 3 is only an illustration of the model (with rank=1), where the initial conditions r<sub>0</sub> are picked to satisfy the conditions derived on the relationship between u<sub>r</sub>, v<sub>r</sub> and r<sub>0</sub> to reproduce F1-F3. Once we turn to testing the predictions on the data, the initial conditions are taken from the data: for each stimulus they correspond to the calcium activity recorded at stimulus offset, corresponding to 50ms before the termination of the stimulus. Prior to fitting the model, we applied dimensionality reduction (PCA) to the data to avoid overfitting, so that the dimensionality of the fitted model i s equal to the number of principal components. This has been specified i n Section 1.7 of the Methods &quot;Linear dynamical system fit&quot;.</p><disp-quote content-type="editor-comment"><p>5. The purpose of Figure 2 is to convey that different stimuli evoke orthogonal OFF responses, and these OFF responses are low dimensional. By my calculation, for each conditional mean (over 20 trials), there are 400ms * 31.5 frame/s ~= 13 samples used to estimate the PCs and variance explained resulting in a maximum dimensionality (PCs to get to 80%) of 13. If this is the case, a more careful comparison to the cross-condition dimensionality is warranted, which accounts for sample size.</p></disp-quote><p>We thank the reviewers for pointing this out. We have now added two types of controls for the principal component analysis, which aim at controlling respectively for sample size and trial-to-trial response variability. To control f or sample size we performed PCA on the trial-averaged responses to individual stimuli using the raw data (13 time points). Next we performed PCA on the responses where we shuffled cell labels independently for each time point, thus preserving the firing rate statistics at each time point, but removing temporal correlations i n the response. We found that the dimensionality of the shuffled response was higher than the dimensionality of the real responses, indicating that the value of the dimensionality obtained for individual stimuli is not the direct consequence of sample size. These results are shown in Figure S1 A.</p><p>To account for trial-to-trial variability i n the response we performed a second control which uses cross-validated PCA. This approach (Stringer et al. 2018) provides an unbiased estimate of the signal variance by computing the covariance between a training and a test set of responses (e.g. two different trials) to an identical collection of stimuli. We show that the same number of dimensions obtained with ordinary PCA explains 80% of variance when the trial-to-trial variability of the responses to a fixed stimulus i s taken into account. We describe the details of this procedure in the Methods, Section 1.4 &quot;Cross-validated PCA&quot;, and i n Figure S1 B-C.</p><disp-quote content-type="editor-comment"><p>Also, we would expect there to be fewer time points on the traces in Figure 2B. How were the trial-averaged responses interpolated?</p></disp-quote><p>Indeed, the time points were interpolated using a Gaussian filter with standard deviation equal to 32ms. This is specified in Section 1.1 &quot;Neural recordings&quot;.</p><disp-quote content-type="editor-comment"><p>What steps were taken to insure that the same unit wasn't double counted during pooling across sessions. Mistakes in this process can contribute to inflated variance along primary PC's creating the illusion of low dimensionality.</p></disp-quote><p>Recordings in different sessions were performed at different depths, typically with a 50 micron difference (never less than 20 microns). Since the soma diameter is 15 microns, this ensured different cells were recorded in different sessions. We now specify this in the Methods (Section 1.1).</p><disp-quote content-type="editor-comment"><p>6. Statements of relative degree of subspace overlap should be verified with a hypothesis test. For data, this can be done by resampling neurons.</p></disp-quote><p>We thank the reviewers for pointing this out. We performed two types of statistical tests for assessing the significance of the orthogonality between responses to different stimuli, reflected in l ow values of the subspace overlap (Figure 2D). The two controls correspond to two different null hypotheses.</p><p>The first hypothesis is that low values of the subspace overlap may be due to the high dimensionality of the state-space in which they are embedded (e.g. the correlation between any pair of random vectors in high dimension is likely to be low). To test for this hypothesis we compared the subspace overlap computed f or each pair of stimulis 1 and s2 on the real trial-averaged responses with the subspace overlap computed on the responses where the stimulus labels s1 and s2 had been shuffled across trials, and then averaged over trials. This yielded pairs of responses that are embedded in the same dimensions of the real responses but are otherwise random. We found that f or most of the stimuli the subspace overlap was significantly lower for the real responses than f or the shuffled responses, indicating that l ow values of the subspace overlap were not a direct consequence of the high dimensionality of the state space.</p><p>The second null hypothesis is that l ow values of the subspace overlap might be an artifact of the trial-to-trial variability present in the calcium activity data. To test for this possibility, for each pair of stimuli we computed the values of the subspace overlap by computing the trial-averaged activity on only half of the trials (10 trials), subsampling the set of 10 trials multiple times for each pair of stimuli. We then compared these values with the values of the subspace overlap between the trial-averaged responses to the same stimulus, but averaged over two different sets of 10 trials each, over multiple permutations of the trials (if the trial-to-trial variability was l ow, these values should be close to 1 since we compute it on a single stimulus, but should decrease as a function of the variability). We found that for most of the stimuli the subspace overlap was significantly lower for the real responses than f or the controls, indicating that l ow values of the subspace overlap were not a direct consequence of the trial-to-trial response variability.</p><p>The same type of controls have been applied to test f or the decorrelation between the initial state and peak state (see Figure 4G). We describe the controls in detail in the Methods, Section 1.6 &quot;Controls for subspace overlaps and initial state-peak correlations&quot;, while the results are reported in Figure S7-S8.</p><disp-quote content-type="editor-comment"><p>7. You should justify why LDA (naive covariance assumption) is more suitable for assessing linear separability in Figure 1C than an SVM. Absent justification, an SVM should be used to get the clearest assessment of linear separability.</p></disp-quote><p>We do not make a strong statement on linear separability in Figure 1C. LDA assuming naive covariance was used simply for convenience, and for consistency with previous studies that did not quantify the impact of noise correlations on decoding (Mazor and Laurent 2005, Saha et al. 2014).</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>The good news is that the paper is much improved. The writing is more clear, and the analysis of dimensions of amplified trial-to-trial variability is compelling. The less good news is that now that we understand it better, additional issues have come up. All can, we believe, be dealt with relatively easily.</p></disp-quote><p>We thank the reviewers for detailed and constructive feedback. We have significantly revised the manuscript to address the reviewers’ comments.</p><p>A major comment was that the paper lacked a clear take home message. Our main message is in fact very simple: A1 OFF responses across stimuli are better described by a network mechanism than by a single-cell mechanism. This is an important message, because the whole OFF-response literature is based on single-cell mechanisms (see Kopp-Scheinpflug, Sinclair and Linden, Trends in Neuroscience 2018), and a network model has been lacking.</p><p>The reviewers’ feedback however made us realize that this message was not communicated in a sufficiently clear manner. We have therefore thoroughly reorganized the manuscript to make this message more prominent.</p><p>The new organisation of the paper is the following:</p><p>1. The first part is unchanged: we start with model-free analyses of auditory cortex data.</p><p>2. We now first discuss the single-cell model, and show that it describes well responses to a single stimulus, but not responses across stimuli.</p><p>3. We then introduce the network model, and show that it accounts better for the responses across stimuli than the single-cell model.</p><p>4. We next analyze the structure of the network model, which leads to additional predictions we verify on the data. A subsection of this part has also been substantially revised following the reviewers’ feedback (see below).</p><p>As a consequence of this reorganization, the figures have also been thoroughly rearranged, and several panels have been added:</p><p>– Figure 1: unchanged.</p><p>– Figure 2: panel E (previously in former Figure 4) has been added.</p><p>– Figure 3 contains the fit of the single-cell and network models (previously in former Figure 5 and Figure 4 respectively). We added one more example neuron to panel E. We added panel G (distance from baseline for the fitted network model) and panel I (subspace overlaps for the fitted network model).</p><p>– Figure 4: the spectra of the fitted connectivity matrix J and of its symmetric part J<sub>S</sub> have been re-computed using ridge regression (without low-rank constraints), and extending the temporal window of the OFF response from 350 to 600 ms to get a stable connectivity matrix. To evaluate uncertainty in the connectivity spectra, we now compute the spectra over multiple neuron subsamplings.</p><p>– Figure 5 (former Figure 3) has been updated, and now illustrates the dynamics of orthogonal rank-2 rotational channels.</p><p>– Figure 6 illustrates the structure of the connectivity fitted to individual stimuli, and the predictions ensuing from this structure. We added panel A showing the goodness of fit computed using reduced-rank regression normalized by its value computed when using ordinary least squares regression. We added panel C(left) (condition for amplification for orthogonal rotational channels) and removed former Figure 4F(right). Former Figure 5F has been moved to Figure 6E.</p><p>– Figure 7 contains the results shown in former Figure 4H. Panel B has been added (correlation between subspace overlap and overlap between transient channels).</p><p>– Figure 8 (former Figure 6): the panels have been re-organized: following the structure of the main text, the data panels are now shown before the model panels.</p><p>– Former Figure 4C has been removed and is now shown in Figure 3-Supplementary3.</p><p>– Figure 3-Supplementary1 has been updated to include up to 16 stimuli.</p><p>Below we reply to the details of the reviewers’ comments.</p><disp-quote content-type="editor-comment"><p>Let's start with the data you're are trying to explain. Basically, after the offset of an auditory stimulus, there is transient amplification, with different stimuli activating nearly orthogonal subspaces.</p><p>To model this, low rank linear dynamics is used, of the form</p><p>dr/dt = sum_{k=1}^R u<sub>k</sub> v<sub>k</sub> r – r,</p><p>where r (=r1, r2,.…, rN) is the trial averaged activity. The network had a few additional properties,</p><p>a. The rank, R, is much less than the number of neurons, N.</p><p>b. The u's and v's are nearly orthogonal.</p><p>c. The symmetric part of the connectivity matrix must have eigenvalues with real part &gt;1.</p><p>d. The model has no external input, so the response to a particular stimulus (after offset) depends only on the value of r immediately after stimulus offset, here denoted r0(s) where s is the stimulus.</p><p>e. For any stimulus, s, r0(s) has appreciable overlap with a small number of v<sub>k</sub> (on the order of 5).</p><p>This model did an OK job explaining the data. In particular, Figure 4H, left (the model), is supposed to match Figure 2D (the data). But the match is not so good: the off-diagonal channel overlap in Figure 2D is near zero, whereas it's around 0.5 in Figure 4H.</p></disp-quote><p>We thank the reviewers for pointing out the inconsistency between the former Figure 4H and Figure 2D. We have traced it back to a mismatch between preprocessing parameters, and updated former Figure 4H (now Figure 7A) so that it now matches much better Figure 2D.</p><p>As indicated in the Methods (sections &quot;Fitting​ the network model&quot;​ and &quot;Analysis of the transient channels&quot;), before fitting the network model, we denoise the data using a PCA. In the original Figure 4H, the total number of dimensions (PC dimensionality) after denoising was set to D=50, which was too low compared to the dimensionality of responses to individual stimuli, and introduced correlations between the fitted low-rank components. Increasing this pre-processing parameter to D=100 and setting the rank parameter to R = 5 instead leads to a high match between Figure 2D and Figure 4H (new Figure 7C, coeff. of determination &gt;0.7).</p><disp-quote content-type="editor-comment"><p>And the full model explains only about half the variance (Figure 4H, Right).</p></disp-quote><p>Our main argument for the network model is not based on the absolute value of explained variance, but on the fact that the explained variance does not increase, in contrast to the single-cell model.</p><p>The total variance explained by our model is consistent with previous reports from the literature that used similar methods. Fitting a linear dynamical system to motor cortical population activity yielded R<sup>2</sup> values between 0.6 and 0.8 (see Elsayed et al. 2017, Lara et al. 2018). In our case, for D=100, R=5 and λ=1 for individual stimuli, we found that the cross-validated (10-fold) goodness of fit, as quantified by the coefficient of determination R<sup>2</sup>, was equal to 0.65. Note also that we used calcium recordings, which are significantly more noisy than electrophysiological recordings used in Elsayed et al. 2017, Lara et al. 2018.</p><disp-quote content-type="editor-comment"><p>In addition, you claim that the dynamics is autonomous. The test for this is described on lines 251-9:</p><p>&quot;We first tested the starting assumption that the OFF response trajectories are consistent with linear, autonomous network dynamics driven only by the initial pattern of activity and network interactions. If that is the case, the OFF response dynamics are fully determined by the initial activity at stimulus offset (t = 0). This assumption implies that the geometric structure of the initial activity states r<sub>0</sub><sup>(s)</sup> fully predicts the geometric structure of the dynamics r<sup>(s)</sup>(t) during the OFF responses (see Materials and methods). In particular, two stimuli s<sub>1</sub> and s<sub>2</sub> corresponding to correlated initial states r<sub>0</sub><sup>(s1)</sup> and r<sub>0</sub><sup>(s2)</sup> will lead to correlated trajectories r<sup>(s1)</sup>(t) and r<sup>(s2)</sup>(t) in the model. Conversely, if two OFF-response trajectories r<sup>(s1)</sup>(t) and r<sup>(s2)</sup>(t) are orthogonal, the initial states r<sub>0</sub><sup>(s1)</sup> and r<sub>0</sub><sup>(s</sup><sub>2</sub><sup>)</sup> are necessarily orthogonal.&quot;</p><p>We're pretty sure that isn't correct: correlations are preserved only if the dynamics causes pure rotation at constant angular speed, something that doesn't happen in general, even for linear dynamics.</p></disp-quote><p>We apologize, this paragraph appears to have caused a lot of confusion, and we have now removed it. Our goal was in fact to simply show that the OFF responses depend on the initial state of the network at the end of stimulus presentation. This is consistent with a dynamical mechanism, as has been argued previously in the motor cortex (Churchland et al. 2012), but does not exclude a contribution from external inputs. Since this aspect is consistent with both single-cell and network models, we have now moved the previous Figure 4A to model-free analysis in Figure 2.</p><p>We did not intend to claim to demonstrate that the OFF-response dynamics in the auditory cortex are autonomous. In fact the word “autonomous” was used only twice in the Results (and only in the paragraph copied above), and we have now completely removed it, as technically the single-cell model we use is not an autonomous dynamical system.</p><p>A paragraph in the Discussion (“A major assumption of our model…”) clarifies that we cannot exclude contributions from external inputs during the OFF responses, and do not claim the dynamics are purely autonomous.</p><p>The reviewers are absolutely correct that linear dynamics do not in general preserve correlations – additional constraints are needed. The relationship between initial conditions and subsequent responses found in the data is non-trivial. We have now added a plot showing that the fitted network model accounts for this observation (new Figure 3I).</p><disp-quote content-type="editor-comment"><p>And finally, Figure 4E, right, shows that many u's and v's are not orthogonal -- judging from that figure, on the order of 10-20%. These terms were of the form</p><p>|u1| v2 v1 – |u2| v1 v2</p><p>where v1 and v2 are nearly orthogonal. You claim that terms like this can't lead to transient amplification. That's true if |u_1|=|u_2|. But if |u_1| and |u_2| are sufficiently different, it's not true. But maybe |u_1| \approx |u_2| in the data?If so, that should be clear. In any case, this seems like a detail -- it's certainly possible to do the analysis with these terms included.</p></disp-quote><p>The reviewers are absolutely correct. We have now thoroughly reorganized this part of the results and the corresponding methods. Specifically:</p><p>– We do not assume anymore orthogonality between the u’s and v’s.</p><p>– Instead, based on the properties of the fitted model, we now test the hypothesis that the network can be approximated as a sum of orthogonal rank-2 channels of the form |u1| v2 v1 – |u2| v1 v2</p><p>– We now describe under which conditions such channels lead to amplified dynamics (new Figure 5). In particular, as pointed out by the reviewers, a key condition is | |u1|-|u2| |&gt;2.</p><p>– We then test those conditions in the data, in particular in the new panel Figure 5C.</p><disp-quote content-type="editor-comment"><p>The lack of orthogonality between the u's and v's doesn't seem so serious. But the lack of agreement between Figures 2D and 4H, combined with no strong evidence for autonomous dynamics, seems potentially problematic. Of course, no model ever fits perfectly. But it's hard to figure out exactly what the take-home message is. If there was strong evidence that the dynamics is autonomous, that would help -- at least we would know that the intrinsic dynamics is responsible for the transient amplification.</p></disp-quote><p>As pointed out at the beginning of the reply, our claim is not that the dynamics are autonomous. Our main message is that A1​ OFF responses across stimuli are better described by a network mechanism than by a single-cell mechanism​.</p><p>The manuscript has been thoroughly reorganized to better communicate this message.</p><disp-quote content-type="editor-comment"><p>As a potentially important aside: the eigenvalue spectrum of Figure 4D shows one marginally stable, non-oscillatory mode. Based on past experience of one of the reviewers, it may be that the lack of agreement between Figures 2D and 4H is because of this mode. The reasoning is that if this slow mode is present by a small amount in all initial conditions, it will generate the fairly weak overlap in Figure 2D, but because it sticks, it might end up dominating the late off-responses for each stimulus after all the rest has decayed away. If that's the case, then this mode will be part of the principal subspace extracted for each stimulus. The measure of overlap based on &quot;subspace angle&quot; is very sensitive to this, which could explain the large overlaps in Figure 4H. Importantly, that marginally stable eigenvalue may be an artifact of insufficient regularization. There are a lot of &quot;ifs&quot; in the above reasoning, but if this mode can be eliminated, perhaps by different regularization, agreement may improve. We don't know if that's possible, but it's worth thinking about.</p></disp-quote><p>We thank the reviewer suggesting this possibility. As explained above, the disagreement between former Figure 2D and former Figure 4H (new Figure 7A) was due to an incorrect setting in the preprocessing. Changing the PC dimensionality from 50 (as in the previous version of the manuscript) to 100 (new version) fixed the disagreement.</p><p>As noted by the reviewers, there was indeed a marginally stable eigenvalue in the full spectrum of J. We traced this back to the fact that, for the longest stimuli, the inter-trial interval is too short, and the OFF responses do not have enough time to decay to baseline. Excluding the longest stimuli, and extending the analyzed window eliminates the marginal eigenvalues (updated Figure 4).</p><disp-quote content-type="editor-comment"><p>There is a lot of very nice analysis in the paper, and all reviewers agree that it should be published. However, it needs a clear take-home message. Exactly what that is depends, we believe, on how strongly the evidence is for autonomous dynamics. If that's very strong, then at the very least the take-home message is:</p><p>&quot;Off cells show transient amplification that is generated by internal dynamics, not external input. That transient dynamics is mildly consistent with low rank connectivity in which dynamics can mainly be reduced to multiple 2-D systems. However, we can't rule out more complex behavior, with transient amplification fundamentally involving several dimensions.&quot;</p><p>Possibly you can come up with a stronger conclusion, but that's the best we could come up with.</p><p>If the evidence for autonomous dynamics is weak, that seems to be a fundamental problem, since the transient amplification may be caused solely by external input. But presumably that can never be ruled out -- a fact that you should probably mention. It's not a plausible scenario, so we don't think it will weaken the paper..</p></disp-quote><p>As pointed out at the beginning of the reply, our claim is not that the dynamics are autonomous. While we show evidence that initial conditions play a role in the subsequent dynamics, we cannot exclude that external inputs are present. This is explicitly acknowledged in the Discussion.</p><p>Our main message is instead that A1​ OFF responses across stimuli are better described by a network mechanism than by a single-cell mechanism​. As summarized at the top of the response, we have thoroughly reorganized the manuscript to better communicate this message.</p><disp-quote content-type="editor-comment"><p>Our main comment, then, is to explore more carefully whether or not dynamics is autonomous, and/or be more careful about the conclusions. One possible way to test for autonomous dynamics is to plot the trajectories and look for intersections, or near intersections -- what Mark Churchland calls tangled trajectories, for which quantification is possible. Absence of near intersections would at least be consistent with autonomous dynamics. But there may be better methods. For instance, you might try LFADS: you can fit both an RNN and a linear dynamical model, and see which one fits better. That will, though, be a huge amount of work, and you should do it only if you want to.</p></disp-quote><p>We thank the reviewers for this suggestion. We have however decided not to follow this route, because our main claim is not that the dynamics are purely autonomous, as explained above.</p><disp-quote content-type="editor-comment"><p>In addition, we suggest exploring a richer single-neuron model. The current model has the form</p><p>r<sub>i</sub><sup>s</sup>(t) = r_{0i}^s L<sub>i</sub>(t).</p><p>If r<sub>i</sub> is non-negative, this can be written</p><p>dr<sub>i</sub>/dt = f<sub>i</sub>(t) r<sub>i</sub>,</p><p>with r<sub>i</sub>(t=0) a function of the stimulus. It would be more convincing to consider a model with a nonlinearity; say</p><p>dr<sub>i</sub>/dt = f<sub>i</sub>(t) g<sub>i</sub>(r<sub>i</sub>).</p><p>The nonlinearity g<sub>i</sub> could be parameterized with, probably, only a handful of parameters. For instance, it could be written as a sum of basis functions, much the way L<sub>i</sub> was parameterised. The single-cell model was rejected because it explained only about 20% of the variance, versus 50% for the recurrent network. It would be reassuring if adding a nonlinearity didn't bring this up to 50%. Again, this also is only a suggestion. However, if you stick with the current single cell model, you'll need to frame your comparison less generally than &quot;recurrent versus single cell&quot;.</p></disp-quote><p>We thank the reviewers for this suggestion. We now explicitly frame our results as comparing <italic>linear</italic> ​ single-cell and network models (Abstract).</p><p>Note that the single-cell model captures about 75% of the variance when fitted to responses to a single stimulus. It is therefore clearly expressive enough to capture the dynamics seen in the data. What it does not capture is dynamics across stimuli, and it is not clear to us how a non-linearity could fix this, while linear network interactions do. The effects of a non-linearity would need to be included both in the single-cell and network models, and this goes beyond the scope of the present study.</p></body></sub-article></article>