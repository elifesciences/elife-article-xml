<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">97088</article-id><article-id pub-id-type="doi">10.7554/eLife.97088</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.97088.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Development of a Marmoset Apparatus for Automated Pulling to study cooperative behaviors</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Meisner</surname><given-names>Olivia C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3523-5144</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Shi</surname><given-names>Weikang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4068-1168</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Fagan</surname><given-names>Nicholas A</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Greenwood</surname><given-names>Joel</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Jadi</surname><given-names>Monika P</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1092-5026</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Nandy</surname><given-names>Anirvan S</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4225-5349</contrib-id><email>anirvan.nandy@yale.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Chang</surname><given-names>Steve WC</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4160-7549</contrib-id><email>steve.chang@yale.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Interdepartmental Neuroscience Program, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Psychology, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Neuroscience, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Wu Tsai Institute, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Kavli Institute for Neuroscience, Yale University School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Psychiatry, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>SP</surname><given-names>Arun</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dese585</institution-id><institution>Indian Institute of Science Bangalore</institution></institution-wrap><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Wassum</surname><given-names>Kate M</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>University of California, Los Angeles</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>28</day><month>10</month><year>2024</year></pub-date><volume>13</volume><elocation-id>RP97088</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-03-28"><day>28</day><month>03</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-02-21"><day>21</day><month>02</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.02.16.579531"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-06-13"><day>13</day><month>06</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97088.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-30"><day>30</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97088.2"/></event></pub-history><permissions><copyright-statement>© 2024, Meisner et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Meisner et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-97088-v1.pdf"/><abstract><p>In recent years, the field of neuroscience has increasingly recognized the importance of studying animal behaviors in naturalistic environments to gain deeper insights into ethologically relevant behavioral processes and neural mechanisms. The common marmoset (<italic>Callithrix jacchus</italic>), due to its small size, prosocial nature, and genetic proximity to humans, has emerged as a pivotal model toward this effort. However, traditional research methodologies often fail to fully capture the nuances of marmoset social interactions and cooperative behaviors. To address this critical gap, we developed the Marmoset Apparatus for Automated Pulling (MarmoAAP), a novel behavioral apparatus designed for studying cooperative behaviors in common marmosets. MarmoAAP addresses the limitations of traditional behavioral research methods by enabling high-throughput, detailed behavior outputs that can be integrated with video and audio recordings, allowing for more nuanced and comprehensive analyses even in a naturalistic setting. We also highlight the flexibility of MarmoAAP in task parameter manipulation which accommodates a wide range of behaviors and individual animal capabilities. Furthermore, MarmoAAP provides a platform to perform investigations of neural activity underlying naturalistic social behaviors. MarmoAAP is a versatile and robust tool for advancing our understanding of primate behavior and related cognitive processes. This new apparatus bridges the gap between ethologically relevant animal behavior studies and neural investigations, paving the way for future research in cognitive and social neuroscience using marmosets as a model organism.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>Cooperation is one of the most important and advanced forms of social behaviour, yet studying it in laboratory settings can be particularly challenging. This is partly because animal species typically used in research do not cooperate in a way similar to humans.</p><p>More recently, marmosets have gained recognition as an important model for studying collaboration, as these small primates naturally exhibit cooperative behaviours. However traditional research methods have struggled to capture these dynamics in a reliable and detailed way. A lack of approaches that allow researchers to methodically prompt naturalistic behaviours in freely moving animals under various controlled circumstances has hampered efforts to study the factors that influence cooperation. This limitation has also hindered investigations into the brain processes that underpin this unique social trait.</p><p>To address this gap, Meisner et al. developed MarmoAAP, an apparatus that allows two marmosets in adjacent, transparent enclosures to observe each other and coordinate their actions so they can simultaneously pull levers and both receive a reward. This tool is compatible with advanced tracking technologies to monitor behaviour and brain activity.</p><p>Testing revealed that the marmosets exhibited cooperative behaviour much more consistently and in greater numbers with MarmoAAP than in previous experiments using traditional, non-automated methods, making the apparatus an effective tool for studying this complex social behaviour.</p><p>In addition to studying cooperation, MarmoAAP offers a standardised platform for testing the effects of drugs in marmosets, which could help develop new treatments for further testing in humans. Importantly, performance on the task could be precisely quantified using the detailed metrics provided by the apparatus. This is crucial for better understanding the factors that influence cooperative ability, and how these behaviours can be enhanced or disrupted. Neuroscientists could also use this combination of adaptable design and high-resolution data gathering to better understand brain activity in a wide range of complex primate behaviours.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>cooperation</kwd><kwd>common marmosets</kwd><kwd>social gaze</kwd><kwd>markerless tracking</kwd><kwd>neural recording</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100008982</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>DGE2139841</award-id><principal-award-recipient><name><surname>Meisner</surname><given-names>Olivia C</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R21 MH126072</award-id><principal-award-recipient><name><surname>Jadi</surname><given-names>Monika P</given-names></name><name><surname>Nandy</surname><given-names>Anirvan S</given-names></name><name><surname>Chang</surname><given-names>Steve WC</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100014370</institution-id><institution>Simons Foundation Autism Research Initiative</institution></institution-wrap></funding-source><award-id>SFARI 875855</award-id><principal-award-recipient><name><surname>Jadi</surname><given-names>Monika P</given-names></name><name><surname>Nandy</surname><given-names>Anirvan S</given-names></name><name><surname>Chang</surname><given-names>Steve WC</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>P30 EY026878</award-id><principal-award-recipient><name><surname>Nandy</surname><given-names>Anirvan S</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>Wu Tsai Institute, Yale University</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Shi</surname><given-names>Weikang</given-names></name><name><surname>Jadi</surname><given-names>Monika P</given-names></name><name><surname>Nandy</surname><given-names>Anirvan S</given-names></name><name><surname>Chang</surname><given-names>Steve WC</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The Marmoset Apparatus for Automated Pulling provides a powerful and scalable experimental platform for studying behavioral and neural mechanisms underlying cooperation in freely moving marmosets.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The study of animal behavior is essential for comprehending the intricacies of behavioral dynamics and their underlying cognitive processes. Exploring the neurobiological foundations of animal behavior enables the identification of shared neural mechanisms governing decision-making, learning, memory, and problem-solving throughout the broader spectrum of the animal kingdom. However, investigations of the neurobiology of ecologically valid behaviors can be extremely challenging using traditional approaches. With the rapid advancements in methods for recording and manipulating neural activity from these species, there arises a critical need to modernize our approaches to studying animal behavior to ensure they keep pace with the evolving neural techniques (<xref ref-type="bibr" rid="bib41">Miller et al., 2022</xref>; <xref ref-type="bibr" rid="bib24">Huk et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Scott and Bourne, 2022</xref>).</p><p>There is growing recognition of the common marmoset’s (<italic>Callithrix jacchus</italic>) potential as an invaluable animal model in neuroscience research (<xref ref-type="bibr" rid="bib40">Miller et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Burkart and Finkenwirth, 2015</xref>) as evidenced by efforts to create marmoset brain databases at multiple biological levels (<xref ref-type="bibr" rid="bib34">Lin et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Liu et al., 2020</xref>; <xref ref-type="bibr" rid="bib61">Woodward et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Okano et al., 2016</xref>). Marmosets provide notable advantages as research models, including their immediate relevance to humans given their genetic relatedness and shared dominant sensory modalities (<xref ref-type="bibr" rid="bib40">Miller et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Mitchell and Leopold, 2015</xref>), and their small size which facilitates naturalistic, freely moving studies of primate social behaviors that can be challenging with larger species like macaques. Further, they offer a distinctive platform for the study of social behaviors due to their significant parallels with human social structures. Marmosets are particularly prosocial and socially tolerant primates that, like humans, engage in pair bonding and cooperative breeding (<xref ref-type="bibr" rid="bib14">De la Fuente et al., 2022</xref>; <xref ref-type="bibr" rid="bib54">Schaffner and Caine, 2000</xref>; <xref ref-type="bibr" rid="bib21">French, 1997</xref>; <xref ref-type="bibr" rid="bib22">French et al., 2018</xref>), which has been theorized to have significantly shaped socio-cognitive abilities. Indeed, marmosets consistently show more socio-cognitively advanced behaviors such as social learning, vocal communication, understanding and use of gaze cues, and cooperative problem-solving relative to non-cooperatively breeding primates (<xref ref-type="bibr" rid="bib13">Cronin et al., 2005</xref>; <xref ref-type="bibr" rid="bib6">Burkart and Heschl, 2007</xref>; <xref ref-type="bibr" rid="bib23">Hare et al., 2003</xref>; <xref ref-type="bibr" rid="bib7">Burkart and van Schaik, 2010</xref>; <xref ref-type="bibr" rid="bib58">Snowdon and Cronin, 2007</xref>). As primates, marmosets also share significant similarities to humans in their neural circuits involved in social cognition (<xref ref-type="bibr" rid="bib40">Miller et al., 2016</xref>). For example, both humans and marmosets show similar face-responsive brain regions in the temporal lobe (<xref ref-type="bibr" rid="bib59">Tsao et al., 2008</xref>; <xref ref-type="bibr" rid="bib25">Hung et al., 2015</xref>) and similar brain networks comprising the social brain (<xref ref-type="bibr" rid="bib16">Deen et al., 2023</xref>; <xref ref-type="bibr" rid="bib10">Cléry et al., 2021</xref>). Marmosets provide a unique opportunity to investigate social behavioral dynamics, however, being a relatively new model in the field of neuroscience, they have yet to benefit from the extensive methodological developments available for other model organisms like rodents. Continued innovation in research methods is essential to fully utilize marmosets as a model system to study complex behaviors and their neural correlates.</p><p>Within the realm of animal behavior studies, investigating the dynamics of social interactions and decision-making presents both a challenge and a promising avenue for investigating complex cognitive processes. Advanced social cognition demands constructing and flexibly updating internal models of social agents and computing multiple layers of information across self and others (<xref ref-type="bibr" rid="bib19">Fehr and Fischbacher, 2003</xref>; <xref ref-type="bibr" rid="bib51">Rilling and Sanfey, 2011</xref>). In particular, cooperation, a key behavioral strategy crucial to the evolution of advanced social cognition, involves integrating complex information like social relationships and the goals and intentions of oneself and others (<xref ref-type="bibr" rid="bib4">Brosnan et al., 2010</xref>; <xref ref-type="bibr" rid="bib15">de Waal, 2008</xref>; <xref ref-type="bibr" rid="bib45">Nowak and Sigmund, 2005</xref>; <xref ref-type="bibr" rid="bib36">Lozano et al., 2020</xref>; <xref ref-type="bibr" rid="bib2">Bliege Bird et al., 2018</xref>; <xref ref-type="bibr" rid="bib43">Mustoe et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Fehr and Rockenbach, 2004</xref>; <xref ref-type="bibr" rid="bib1">Axelrod and Hamilton, 1981</xref>; <xref ref-type="bibr" rid="bib3">Boyd and Richerson, 1985</xref>; <xref ref-type="bibr" rid="bib5">Brosnan, 2011</xref>). Given the theorized role of cooperation in the evolution of higher-order cognitive processes involving processing and engaging in social interactions, studying this behavior can have important implications for understanding social dynamics, communication, and cognition in the animal kingdom (<xref ref-type="bibr" rid="bib7">Burkart and van Schaik, 2010</xref>; <xref ref-type="bibr" rid="bib8">Burkart et al., 2014</xref>; <xref ref-type="bibr" rid="bib11">Clutton-Brock, 2009</xref>).</p><p>Traditionally, researchers have studied cooperative behaviors using the cooperative pulling paradigm, a widely employed experimental setup in several animal species that requires animals to collaborate to manipulate a device and retrieve a food reward (<xref ref-type="bibr" rid="bib12">Crawford, 1937</xref>). This paradigm involves two animals working in tandem, each pulling one end of a rope looped through rings attached to a heavy board on the ground. Because the food board is either too heavy for one animal to move alone or rigged so that one animal pulling the rope does not move the board, only coordinated actions can lead to successful food acquisition. This well-established paradigm has greatly contributed to our understanding of cooperative abilities across diverse species, including, but not limited to, chimpanzees, capuchins, hyenas, wolves, dogs, elephants, otters, and rooks (<xref ref-type="bibr" rid="bib13">Cronin et al., 2005</xref>; <xref ref-type="bibr" rid="bib12">Crawford, 1937</xref>; <xref ref-type="bibr" rid="bib37">Martin et al., 2021</xref>; <xref ref-type="bibr" rid="bib39">Mendres, 2000</xref>; <xref ref-type="bibr" rid="bib49">Plotnik et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Range et al., 2019</xref>; <xref ref-type="bibr" rid="bib17">Drea and Carter, 2009</xref>; <xref ref-type="bibr" rid="bib57">Seed et al., 2008</xref>; <xref ref-type="bibr" rid="bib55">Schmelz et al., 2017</xref>).</p><p>While the cooperative pulling paradigm has been invaluable in shedding light on cooperative behaviors across a variety of species, it presents several limitations that hinder its utility for investigating complex behavioral dynamics and preclude studies of underlying neural mechanisms. One notable limitation is the relatively low resolution of behavioral output variables typically measured in the traditional pulling paradigm. Researchers often categorize outcomes in terms of broad categories of successful or unsuccessful cooperation attempts, which may not capture the nuances of behavior with the precision required for advanced analyses. Moreover, manual coding of animal behaviors within the task is constrained to second-by-second measurements and necessitates substantial human labor and expertise.</p><p>Additionally, the traditional cooperative pulling paradigm requires frequent experimenter intervention to reset the apparatus’s position and reload it with food rewards between trials. This time-consuming process not only disrupts the natural behaviors of the animals but also limits the number of trials that can be conducted in each session, often allowing for only a meager sample size. For example, from a sample of five experiments employing a traditional cooperative pulling task across a range of species, animals performed, on average, 10.4 trials per session (<xref ref-type="bibr" rid="bib13">Cronin et al., 2005</xref>; <xref ref-type="bibr" rid="bib37">Martin et al., 2021</xref>; <xref ref-type="bibr" rid="bib39">Mendres, 2000</xref>; <xref ref-type="bibr" rid="bib49">Plotnik et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Range et al., 2019</xref>; <xref ref-type="bibr" rid="bib17">Drea and Carter, 2009</xref>; <xref ref-type="bibr" rid="bib57">Seed et al., 2008</xref>), which poses a significant challenge for neural investigations. Furthermore, the manipulability of task variables is constrained in this manual setup, hampering researchers’ ability to investigate if and how specific factors influence cooperative behaviors in a controlled manner.</p><p>Recent studies have explored alternative cooperative tasks to address some of these limitations, including the work by <xref ref-type="bibr" rid="bib26">Jiang et al., 2021</xref>, which demonstrated the potential of using a nose-poking task to study cooperation in mice, rats, and tree shrews. This study highlighted the comparative abilities of cooperation across different mammalian species and provided a framework for developing more precise and controlled cooperative tasks. Building upon this work, we aimed to develop a task that not only captures the nuances of cooperative behaviors but also allows for high-resolution data collection, making it more suitable for investigating the underlying neural mechanisms in primates.</p><p>Here, we introduce an innovative method for studying cooperative behaviors in common marmosets (<italic>C. jacchus</italic>) using an automated apparatus and task. Our Marmoset Apparatus for Automated Pulling (MarmoAAP) for studying cooperative behaviors comprises response levers controlled by a precision servo motor, integrated with a suite of custom-designed components and sensors. Notably, MarmoAAP offers immense versatility, as it can be seamlessly programmed to accommodate a wide spectrum of behavioral tasks. We demonstrate its utility in the investigation of cooperative behaviors, highlighting its capacity to elicit a large number of trials within a single session while producing exceptionally granular behavioral readouts suitable for sophisticated analytical approaches. This not only surmounts the constraints of traditional methodologies but also aligns with the advanced tools now available for scientific research.</p></sec><sec id="s2" sec-type="materials|methods"><title>Materials and methods</title><sec id="s2-1"><title>Apparatus design and construction</title><p>We developed an apparatus for an automated version of the cooperative pulling paradigm for marmosets (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In this setup, two marmosets are each placed in a separate transparent behavior box set atop the behavioral rig. The marmosets are able to freely move within their individual boxes and have full access to their pull levers in front of them. They can reach out of a slot in the transparent behavior boxes to pull their levers at any time. The levers are controlled by an assembly of components that allow us to program a rotational force to be exerted on the levers. This force can be used to change the position of the levers or adjust the difficulty of pulling the levers. With the incorporated sensors, we can also measure the position of and force exerted on the lever with millisecond precision. Additionally, there are five GoPro cameras and two microphones to capture video and audio recordings, respectively.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Design and Structure of Marmoset Apparatus for Automated Pulling (MarmoAAP).</title><p>(<bold>A</bold>) CAD model of apparatus highlighting general apparatus layout, transparent testing boxes, frame structure, video cameras, and microphones. (<bold>B</bold>) CAD model of lever-motor assembly. Left: Side view of lever-motor assembly. Potentiometer-motor adaptor has been omitted in this view due to its obstruction of view of other components. Right: Front view of lever-motor assembly. (<bold>C</bold>) Photo of actual apparatus. (<bold>D</bold>) Photo of lever-motor assembly.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97088-fig1-v1.tif"/></fig><p>The base frame of this apparatus is constructed of modular T-slotted framing and connectors (<xref ref-type="fig" rid="fig1">Figure 1A and C</xref>). The main structure of the base is a table measuring 18” h × 24” w × 18” l. The table consists of four legs supporting two sets of horizontal rectangular framing. The rectangular frames have T-slotted rails running from front to back, and the lever assembly is attached to these rails. T-slotted framing was also used to provide arms extension to hold the GoPro cameras in the appropriate position (<xref ref-type="fig" rid="fig1">Figure 1A and C</xref>).</p><p>The core of the apparatus is the assembly that controls the marmosets’ pulling levers (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). This assembly is constructed from the materials listed in <xref ref-type="table" rid="table1">Table 1</xref>. The movement of and force required to pull each pull lever is controlled by a servo motor that is programmed via microcontroller development boards (Teensy). With custom code (Arduino), we can exert rotational force on the levers via motor control. This enables us to change the force with which marmosets must pull the levers. It also allows us to reset the levers to the starting positions after the marmosets have pulled the levers. The levers are also connected to two sensors, a strain gauge and a potentiometer. The strain gauge converts the force exerted onto the lever into an electrical signal. The potentiometer measures the position of the lever in a rotary motion and converts it into an electrical signal. These signals can be transmitted to a computer via the Teensy board and used in the task code to evaluate the marmosets’ lever-pulling actions and contingently trigger reward delivery from the syringe pumps (New Era/DUAL-NE-1000X). A successful lever pull is determined by the lever position passing a specified positional threshold as determined by the potentiometer reading. For the Self-Reward condition, a lever pull is considered successful when either lever passes the positional threshold at any time in the session. For the Mutual Cooperation condition, a pair of lever pulls is considered successful when the second lever pull has passed the positional threshold within 1 s of the partner’s lever having passed the positional threshold.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Apparatus parts and information.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Apparatus item</th><th align="left" valign="bottom">Part</th><th align="left" valign="bottom">Manufacturer/part number</th><th align="left" valign="bottom">Function</th></tr></thead><tbody><tr><td align="left" valign="bottom">Pull Lever Head</td><td align="left" valign="bottom">Ball Head</td><td align="left" valign="bottom">Custom</td><td align="left" valign="bottom">Lever grip suitable for marmosets</td></tr><tr><td align="left" valign="bottom">Pull Lever Shaft</td><td align="char" char="." valign="bottom">6-inch rod</td><td align="left" valign="bottom">ThorLabs / ER6-P4</td><td align="left" valign="bottom">Holds lever head at appropriate height</td></tr><tr><td align="left" valign="bottom">Lever Bumpers</td><td align="left" valign="bottom">Load-Rated Threaded Bumper</td><td align="left" valign="bottom">McMaster-Carr/93115K121</td><td align="left" valign="bottom">Bumper for lever to rest on when in starting position</td></tr><tr><td align="left" valign="bottom">Lever Assembly Motor</td><td align="left" valign="bottom">Servo Motor</td><td align="left" valign="bottom">ClearPath Integrated Servo System by Teknic/CPM-MCVC-3411S-RLN</td><td align="left" valign="bottom">Exerts rotational force on the lever</td></tr><tr><td align="left" valign="bottom">Motor Mounting Plate</td><td align="left" valign="bottom">Custom-designed aluminum mounting plate</td><td align="left" valign="bottom">Custom designed. Aluminum cut by water jet</td><td align="left" valign="bottom">Holds servo motor to base frame</td></tr><tr><td align="left" valign="bottom">Potentiometer</td><td align="left" valign="bottom">Rotary Potentiometer—10k Ohm, Linear</td><td align="left" valign="bottom">SparkFun Electronics/COM-09939</td><td align="left" valign="bottom">Delivers real-time positional output of pull lever</td></tr><tr><td align="left" valign="bottom">Strain Gauge</td><td align="left" valign="bottom">Load cell</td><td align="left" valign="bottom">SparkFun Electronics/SEN-14729</td><td align="left" valign="bottom">Delivers real-time force reading of pull lever</td></tr><tr><td align="left" valign="bottom">Potentiometer-Motor Adaptor</td><td align="left" valign="bottom">Custom designed</td><td align="left" valign="bottom">Custom designed. Aluminum cut by water jet</td><td align="left" valign="bottom">Yokes potentiometer shaft and motor shaft</td></tr><tr><td align="left" valign="bottom">Potentiometer Mounting Plate</td><td align="left" valign="bottom">Custom-designed aluminum mounting plate</td><td align="left" valign="bottom">Custom designed. Aluminum cut by water jet</td><td align="left" valign="bottom">Holds the potentiometer in position adjacent to the servo motor</td></tr><tr><td align="left" valign="bottom">Potentiometer Plate Crossbars</td><td align="left" valign="bottom">Ø1/2&quot; Optical Post, SS, 8–32 Setscrew, 1/4&quot;-20 Tap, L=2&quot;</td><td align="left" valign="bottom">ThorLabs / TR2</td><td align="left" valign="bottom">Fixes potentiometer mounting plate to motor mounting plate</td></tr><tr><td align="left" valign="bottom">Counterweight</td><td align="left" valign="bottom">Custom-designed aluminum bar</td><td align="left" valign="bottom">Custom-designed aluminum bar cut by water jet</td><td align="left" valign="bottom">Offsets pull lever weight to balance system</td></tr><tr><td align="left" valign="bottom">Control board</td><td align="left" valign="bottom">Teensy 3.2 USB Development Board</td><td align="left" valign="bottom">SparkFun Electronics/DEV-13736</td><td align="left" valign="bottom">Microcontroller used to integrate motors, potentiometer, and strain gauge</td></tr><tr><td align="left" valign="bottom">Breadboard</td><td align="left" valign="bottom">Solder-able Breadboard</td><td align="left" valign="bottom">SparkFun Electronics/PRT-12070</td><td align="left" valign="bottom">Connects Teensy microcontroller to sensors, facilitating control and computer integration</td></tr><tr><td align="left" valign="bottom">Syringe Pump</td><td align="left" valign="bottom">Syringe Pump</td><td align="left" valign="bottom">New Era/DUAL-NE-1000X</td><td align="left" valign="bottom">Syringe pump controlled by task code to deliver juice reward</td></tr><tr><td align="left" valign="bottom">Frame</td><td align="left" valign="bottom">T-slotted rails</td><td align="left" valign="bottom">McMaster-Carr/47065T553</td><td align="left" valign="bottom">Provide a scaffolding to support lever-motor assembly</td></tr><tr><td align="left" valign="bottom">Cameras</td><td align="left" valign="bottom">Go-Pro Cameras</td><td align="left" valign="bottom">Go-Pro/HERO10</td><td align="left" valign="bottom">Record videos of marmosets performing the task</td></tr><tr><td align="left" valign="bottom">Audio Recorder</td><td align="left" valign="bottom">Voice Recorder, 16 GB</td><td align="left" valign="bottom">QZTELECTRONIC (via Amazon)</td><td align="left" valign="bottom">Record vocalizations from marmosets performing the task</td></tr></tbody></table></table-wrap><p>The lever-motor assembly also consists of structural components that hold each component in the appropriate position. The servo motor is attached to the base frame with a custom-designed mounting plate. A custom-designed clamp sits around the shaft of the motor and serves to yoke the strain gauge and pull lever to the movement of the motor shaft. The top side of the strain gauge connects to the top side of the clamp, and the lever is then connected to the opposite end of the strain gauge. This enables lever force reading by the strain gauge each time the lever is pulled. The bottom side of this clamp is attached to a counterweight (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Positioned directly opposite to the motor shaft is the potentiometer (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The potentiometer is yoked to the motor shaft such that when the lever moves, and therefore the motor shaft rotates, the potentiometer shaft also rotates. This ensures that the potentiometer shaft movement and therefore the potentiometer readings correspond to lever movement. To achieve this, we use a 3D-printed potentiometer-motor adapter. One side of this adapter fits onto the motor shaft and the other side fits onto the potentiometer shaft. Both shafts are held securely in place with set screws.</p><p>Finally, the body of the potentiometer must be held in a stable position so that it does not also move when the potentiometer shaft rotates. To achieve this, we designed a potentiometer mounting plate. This plate has two holes such that crossbars can be attached to connect this potentiometer mounting plate to the motor mounting plate. Additionally, it has a hole that the potentiometer shaft is passed through, and a smaller hole that the tab on the potentiometer body can be placed in. This tab holds the potentiometer in a fixed position to prevent the potentiometer body from rotating when the potentiometer shaft rotates.</p></sec><sec id="s2-2"><title>Animals</title><p>We trained a total of seven adult common marmosets (<italic>C. jacchus</italic>) (3 males, 4 females; 6.0±1.7 years, mean ±s.d.) to perform the MarmoAAP lever-pulling tasks. All marmosets were either pair- or group-housed and lived in the same colony room with a 12 hr light-dark cycle. All pairs tested together were familiar cage-mates. Before testing sessions, water access was temporarily removed, and the AM feed was withheld for 1–3 hr. Water and food were given upon return to the home cage after testing at which point animals had unrestricted access to both. All procedures were approved by the Yale Institutional Animal Care and Use Committee (Yale University IACUC Protocol #2023-20163) and complied with the National Institutes of Health Guide for the Care and Use of Laboratory Animals.</p></sec><sec id="s2-3"><title>Behavioral training</title><p>Marmosets were first trained to voluntarily enter a transport box. At this stage, they were also trained to target touch the metal rod used for the apparatus’ lever from their home cage in exchange for a marshmallow or mealworm reward. Once marmosets were comfortable entering the transport box, they were habituated to transportation to the testing room and sitting inside the transport box in the room. During training, marmosets were always transported and habituated in cage-mate pairs. Once comfortable in the testing room, marmosets were habituated to the transparent behavior boxes (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) and trained to pull the levers (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) on the apparatus in exchange for a liquid reward (marshmallow fluff diluted with water; 6 g marshmallow fluff per 20 ml water).</p><p>Next, marmosets were trained to perform the Self-Reward task. For this task, marmoset pairs were placed in their separate transparent behavior boxes side-by-side, and each was free to pull their lever at any time in exchange for 0.1 ml of liquid reward. The pull-reward contingency was fully independent across the two marmosets. A monitor in front of them depicted a white square cue for this task (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Once they reliably performed the Self-Reward task, we began training them to perform the Mutual Cooperation task. For this task, we introduced a contingency requiring that they pull their levers within a certain time window of one another to receive mutual liquid rewards. A yellow circle cue was depicted on the monitor in front of them for this task. Training advanced through incremental decreases in the cooperative time window including 3 s, 2 s, then 1.5 s, and finally 1 s. A pair of lever pulls in this condition was deemed successful cooperation if the levers were both pulled past their position thresholds within the cooperative time window. After the follower pulled their lever on a successful pull, a tone was played immediately and 0.2 ml of liquid reward was delivered to both animals 1 s later.</p></sec><sec id="s2-4"><title>Multi-animal 3D tracking</title><p>We used DeepLabCut2 (DLC2) (<xref ref-type="bibr" rid="bib38">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Nath et al., 2019</xref>; <xref ref-type="bibr" rid="bib33">Lauer et al., 2022</xref>) to track the head frames of marmosets. We labeled the six facial parts for both animals to define the head frames – two ear tufts, two eyes, central blaze, and mouth. The training dataset contained 270 video frames taken from three cameras in three sessions. We used the multi-animal version of the DLC2 model (<xref ref-type="bibr" rid="bib33">Lauer et al., 2022</xref>), and trained the model with labeled frames from all three cameras for 15,000 iterations until the errors from the loss function reached the plateau (loss &lt;0.001). We applied this trained model to videos taken from all three cameras. This model was also generalizable across sessions and different marmoset individuals. We use Anipose to create the 3D reconstruction of the marmosets’ head frames based on videos taken simultaneously from the three cameras (<xref ref-type="bibr" rid="bib29">Karashchuk et al., 2021</xref>). We first used the checkerboard method to calibrate the three cameras using Anipose, and then provided the DLC2 tracking results from all three cameras at the same time to Anipose to finalize the triangulations.</p></sec><sec id="s2-5"><title>Head chamber implantation and craniotomy</title><p>One animal received a head chamber implant and craniotomy. After the head chamber was surgically implanted, the animal was allowed to recover for 2 weeks. After the recovery, a second procedure was performed to create a craniotomy and mount a screw microdrive (‘nanodrive’; Cambridge Neurotechnologies Inc) holding a 64-channel linear array electrode (NeuroNexus) onto the skull of the marmoset. Craniotomy placement was guided by CT scans and stereotaxic coordinates. The electrode’s electronic interface board was then connected to the White Matter eCube headstage chips (White Matter LLC) which were secured in the marmoset’s head chamber. The implanted electrode was then lowered into the desired cortical site.</p></sec><sec id="s2-6"><title>Neural recordings</title><p>Recordings were logged using White Matter’s eCube headstage system. At the beginning of each recording session, the marmoset was restrained, but not head-fixed, in a chair, and the White Matter’s data logger was connected to the headstage chips in the head chamber. The logger was secured in place with a cap. The marmoset was previously habituated to this restraint process, and the process typically lasted approximately 5 min. The marmoset was then transferred to their transparent behavior box, which was placed on the rig next to their partner’s box, allowing both to engage in the behavioral task. On neural recording days, behavioral sessions consisted of one block of the Mutual Cooperation task and one block of the Self-Reward task, each lasting approximately 10 min. After the behavioral testing, the marmoset was again placed in the chair for removal of the data logger. Electrical signals were collected at 20 kHz from the probe. Action potential waveforms were extracted using Kilosort2 (<xref ref-type="bibr" rid="bib47">Pachitariu et al., 2023</xref>) and manually sorted into single units and multi-units using phy, an open-source Python library for manual clustering of electrophysiology data.</p></sec></sec><sec id="s3" sec-type="results"><title>Results</title><sec id="s3-1"><title>Marmosets perform high number of trials on automated lever-pulling tasks</title><p>The implementation of MarmoAAP yielded significant advancements in the ability to study complex behaviors in marmoset monkeys. In the initial phase of our study, we successfully trained a cohort of seven marmosets to perform the Self-Reward condition in which they could pull their lever at any time to earn a 0.1 ml juice reward for themselves. On average, marmosets pulled 163±56 (mean ± s.e.m.) times per 20 min behavioral session demonstrating high levels of motivated behavior (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). This training phase thus demonstrated the marmosets’ capacity to acquire and consistently execute lever-pulling behavior, providing a dependable means to elicit a high number of motivated and appetitive behaviors.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Quantitative behavioral measurements with Marmoset Apparatus for Automated Pulling (MarmoAAP).</title><p>(<bold>A</bold>) Quantification of average number of lever pulls performed per animal in Self-Reward and 1 s Mutual Cooperation sessions (mean ± s.e.m.; n = 10 Self-Reward sessions, 67 Cooperation sessions). Red dashed line indicates the average number of trials collected per session from a sample of non-automated cooperative pulling paradigm experiments (<xref ref-type="bibr" rid="bib13">Cronin et al., 2005</xref>; <xref ref-type="bibr" rid="bib37">Martin et al., 2021</xref>; <xref ref-type="bibr" rid="bib39">Mendres, 2000</xref>; <xref ref-type="bibr" rid="bib49">Plotnik et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Range et al., 2019</xref>; <xref ref-type="bibr" rid="bib17">Drea and Carter, 2009</xref>; <xref ref-type="bibr" rid="bib57">Seed et al., 2008</xref>). (<bold>B</bold>) Event time series example from a Mutual Cooperation and Self-Reward session. Each bar represents a task-related event (tan: monkey 1 lever pull, brown: monkey 2 lever pull, blue: reward delivery). (<bold>C</bold>) Metrics quantifying performance on MarmoAAP from six example sessions (three Self-Reward, three Mutual Cooperation). Red diamond indicates the mean. Left: Success rate calculated as number of successful lever pulls divided by number of total lever pulls in a session. Middle: Rewards earned per working minute calculated as the average number of rewards earned in 60 s for cumulative time in a session in which a monkey had pulled a lever within 30 s of that time. Right: Inter-pull time calculated as the average amount of time between M1 and M2 lever pulls in a session. (<bold>D</bold>) Example of DLC2 labeled video frame as marmosets perform cooperative pulling task. (<bold>E</bold>) Quantification of gaze targets averaged across three example cooperation sessions (mean ± s.e.m., n = 2 marmosets with 4 sessions each). (<bold>F</bold>) Example vocalizations captured during behavioral sessions. (<bold>G</bold>) Peristimulus time histogram (mean ± s.e.m.; n = 1103 Cooperation lever pulls, 566 Self-Reward lever pulls) of chirp vocalizations from one marmoset across Self-Reward (gray) and Mutual Cooperation (blue) sessions. Red bar indicate time bins with significantly different call counts for Cooperation compared to Self-Reward task conditions (Wilcoxon rank sum test, p &lt; 0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97088-fig2-v1.tif"/></fig><p>Building upon this foundation, we extended our investigations to more complex tasks requiring cooperative pulling behaviors. We trained three unique dyads of familiar marmosets to perform cooperative pulling. For the Mutual Cooperation condition, we introduced a contingency that requires both marmosets to pull their levers within a specified time window of one another to both earn juice rewards. This task is completely unconstrained such that marmosets were free to pull their levers at any time. If the marmosets pulled their levers within the 1 s cooperative time window, a tone was played, and 0.2 ml of juice reward was delivered to both marmosets. However, if they pulled their lever and their partner did not pull within the cooperative time window, they were not rewarded.</p><p>We observed that all three dyads achieved proficiency, defined as 50% success rate (the number of pulls resulting in successful cooperation out of the total number of pulls made by both animals), in this cooperative task within a 2-month period. The choice of a 50% success criterion was based on pilot behavioral testing with marmosets, where this rate was deemed a reasonable target. Additionally, we referred to the findings of <xref ref-type="bibr" rid="bib26">Jiang et al., 2021</xref>, who conducted a similar task with nose-poking behavior in mice, rats, and tree shrews. In their study, rats and tree shrews were observed to achieve and typically plateau around a 50% success rate, leading us to reason that marmosets could reach a similar level of performance. The average number of training days to reach Mutual Cooperation proficiency was 33.7±11.9 days.</p><p>This learning progression was further characterized by quantifiable metrics reflecting their progression in learning the cooperative contingency. Using the precise timestamps of the behavioral events (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), we calculated three metrics across six example sessions (three Self-Reward sessions, three Mutual Cooperation sessions) that differentiated marmosets’ performance on the Self-Reward and Mutual Cooperation tasks (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). These included success rate, calculated as the number of successful lever pulls divided by the total number of lever pulls in a session; rewards earned per working minute, the average number of rewards earned per 60 s of active task engagement; and inter-pull time, the average time interval between lever pulls by the two marmosets (M1 and M2) in a session. We use these metrics here to demonstrate distinct patterns of performance between the Self-Reward and Mutual Cooperation tasks, highlighting specific behavioral markers associated with each task. Future work can utilize these metrics to track learning progress and define or quantify performance on this task under varying conditions.</p><p>Notably, the utilization of the automated behavioral paradigm enabled marmosets to perform an average of 146 trials per 20 min behavioral session across all sessions of learning the task, with an average of 47.9±3.3 trials (mean ± s.e.m.) resulting in successful level pulls (i.e. cooperation in Mutual Cooperation condition) and 98.9±6.6 trials resulting in unsuccessful attempts (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). It’s important to note that these numbers reflect performance across all sessions, including those during the initial learning phase, where success rates were often below the 50% proficiency threshold. This is a substantial improvement compared to the average of 10.4 trials per session observed in studies employing more manual cooperation paradigms. This heightened throughput, coupled with high repeatability, emerges as a critical asset for dissecting the intricacies of behavioral dynamics and the neural computations underlying complex behaviors.</p></sec><sec id="s3-2"><title>Customizable task parameters allow for adaptation to marmosets’ abilities</title><p>Our behavior training also underscored the importance of task parameter adjustability in optimizing marmosets’ performance. We tailored MarmoAAP to individual marmosets by fine-tuning parameters such as the distance required for a lever pull to register as a full pull and the force needed to initiate the lever-pulling action. By initially reducing the force required to pull the lever to 50 g, marmosets were able to smoothly transition into learning the task. Once they became habituated to the lever-pulling paradigm, we increased the lever-pulling force to 100 g and maintained this force level for Self-Reward and Mutual Cooperation tasks.</p><p>Additionally, we customized the reward magnitude offered for task completion to suit the specific requirements of the cooperative pulling task. For example, while marmosets exhibited motivation to work for a 0.1 ml juice reward in the individual pulling task, this was often not sufficient to elicit consistent pulling behaviors from dyads in the more difficult cooperative task. However, increasing the reward amount to 0.2 ml elicited enhanced motivation and more consistent cooperative behaviors from all three dyads. This adaptive parameter manipulation contributed significantly to the success of our marmoset dyads in mastering the cooperative pulling task, highlighting the importance of tailoring task parameters to individual and task-specific requirements.</p><p>Furthermore, MarmoAAP can easily be adapted to a wide variety of behavioral paradigms both in terms of the hardware configuration and parameters set by the task code. Given the modular nature of the apparatus design, the assembly can easily be adjusted to increase or decrease the number of pull levers as well as to change their configuration relative to one another. The task requirements imposed on the animals can also be easily adjusted by changing the task code. For example, the cooperative pull timing contingency, the force required to pull the lever, lever pull distance, and reward timing are just a few examples of task parameters that can be adjusted through the task code. One can imagine a wide variety of experiments that could be achieved with this apparatus to test cognitive processes such as, but not limited to, observational learning, memory, competition, altruism, executive function, and a host of other motivated behaviors.</p></sec><sec id="s3-3"><title>High-resolution behavioral data allows for advanced analyses</title><p>MarmoAAP facilitates comprehensive collection of detailed behavioral data across a variety of modalities. Its design allows for the capture of millisecond level outputs detailing lever positioning (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) and the force applied to the lever. Additionally, it can be built to support cameras to record multiple angles for video data collection and incorporate microphones to record audio. Leveraging this video data, we used automated behavioral marking tools like DeepLabCut2 (DLC2) (<xref ref-type="bibr" rid="bib38">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Nath et al., 2019</xref>) to obtain frame-by-frame annotations of the marmosets’ head frames (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This rich dataset serves as a foundation for subsequent analyses, including the exploration of inferred gaze direction, spatial location within the enclosure, and overall movement trajectories.</p><p>In particular, we would like to highlight our ability to analyze gaze dynamics in this platform. Gaze behaviors are fundamental to social behaviors of primates which are highly visual animals. We were able to analyze complex behavioral dynamics by employing DLC2 to track the head frames of each freely moving marmoset as they engaged in the pulling task. We then used Anipose to create a 3D reconstruction of the marmosets’ head frames based on videos from three cameras (<xref ref-type="bibr" rid="bib29">Karashchuk et al., 2021</xref>). Based upon the constructed head frames, we estimated the marmosets’ gaze direction by creating a virtual cone with an axis perpendicular to the plane defined by markers for the marmosets’ eyes and forehead and a solid angle of 15 degrees. Using this approach, we were able to quantify the number of gazes toward various targets during the sessions. Using data from three example sessions, we can quantify bouts of gazes at targets of interest including their partner (social gaze), lever, and juice tube (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). Such additional information that can be obtained within the automatic pulling paradigm can be used to better understand complex social interactions in marmoset pairs or groups.</p><p>Recognizing the highly vocal nature of marmosets and their extensive repertoire of vocalizations, each with distinct functions, we also collected audio recordings of every behavioral session. We were able to capture a wide variety of marmoset vocalizations during this task. Here, we specifically focused on chirp, trill, and phee calls (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). Using the timestamps from the lever pulls and reward delivery, we further analyzed vocalizations relative to task events. As an example, we examined vocalizations relative to successful and unsuccessful lever pulls from one marmoset across 19 sessions (6 Self-Reward sessions, 13 Mutual Cooperation sessions) (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). This marmoset showed an increase in chirp calls, known to serve as food calls (<xref ref-type="bibr" rid="bib52">Rogers et al., 2018</xref>; <xref ref-type="bibr" rid="bib60">Vitale et al., 2003</xref>), after lever pulls in Mutual Cooperation sessions compared to Self-Reward sessions.</p><p>By incorporating these behavioral metrics from video and audio recordings with the timing of marmosets’ pulling behaviors and reward delivery, one can gain a more comprehensive understanding of the intricate interplay between behavior, vocal communication, and cooperative interactions in this species using an automated pulling task.</p></sec><sec id="s3-4"><title>Precise synchronization with reproducible behavior allows behavior-locked neural data analyses</title><p>In addition to providing rich behavioral data and offering flexibility for various tasks, MarmoAAP and associated behavioral paradigms create an avenue for simultaneous neural recordings while freely moving marmosets are engaged in tasks implemented by MarmoAAP. MarmoAAP significantly increases the number of trials available for analysis and thus ensures ample statistical power when investigating the relationship between neural activity and behaviors. The highly reproducible lever-pulling behavior in marmosets within a naturalistic context strikes a crucial balance between conventional laboratory tests, where monkeys are immobilized and tasks lack natural movement but are tightly controlled, and more naturalistic animal behavior studies, where animals exhibit unrestrained behavior but lack regular behavioral benchmarks for studying the underlying neural dynamics (<xref ref-type="bibr" rid="bib18">Fan et al., 2021</xref>; <xref ref-type="bibr" rid="bib31">Knöll et al., 2018</xref>).</p><p>To validate this application of MarmoAAP, we conducted wireless neural recordings using a silicon-based linear array probe while a marmoset engaged in the cooperative pulling task with its partner (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) and were able to isolate single-unit activity from the prefrontal cortex (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). On each day, marmosets performed a 10 min session of the Mutual Cooperation task and a 10 min session of the Self-Reward task. By synchronizing the behavioral and neural activity timestamps, we were able to investigate spiking activity relative to various behavior events. Here, we present an example single unit recorded from the orbitofrontal cortex (OFC) and an example multi-unit from the dorsolateral prefrontal cortex (dlPFC) that showed increased firing rates around lever pulls in a Mutual Cooperation session (<xref ref-type="fig" rid="fig3">Figure 3C and D</xref>). Investigating neural activity with specific yet naturalistic behavioral events provides a valuable dataset for investigating the neural dynamics associated with cooperative interactions. By using wireless electrophysiology recording techniques in conjunction with this cooperative behavior paradigm with markerless behavioral tracking, one can obtain a more comprehensive understanding of the neural underpinnings of complex social behaviors, such as cooperation.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Wireless neural data recordings with Marmoset Apparatus for Automated Pulling (MarmoAAP).</title><p>(<bold>A</bold>) Photo of marmosets performing Mutual Cooperation task with one marmoset performing the task with a head-mounted wireless recording system. (<bold>B</bold>) Example single-unit waveforms from one recording session of the orbitofrontal cortex (OFC). (<bold>C</bold>) Top: Peristimulus time histogram of an example single OFC neuron averaged across all self lever pulls in one session aligned to the time of lever pull registration (dashed line) (n = 49 lever pulls, bin size = 150 ms with 50 ms sliding window). Bottom: Raster plot of the same example OFC neuron relative to all self lever pulls (red line = lever pull registration) in one example session. (<bold>D</bold>) Top: Peristimulus time histogram of an example dorsolateral prefrontal cortex (dlPFC) multi-unit averaged across all self lever pulls in one session aligned to the time of lever pull registration (dashed line) (n = 49 lever pulls, bin size = 150 ms with 50 ms sliding window). Bottom: Raster plot of example dlPFC multi-unit relative to all self lever pulls (red line = lever pull registration) in one example session.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97088-fig3-v1.tif"/></fig></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>The Marmoset Automated Apparatus for Pulling (MarmoAAP) bridges the gap between traditional animal behavior methodologies and the demand for increased precision and adaptability in behavioral research. To advance our understanding of the complex behavioral and neural dynamics underlying cooperative behaviors, it is imperative that we transition toward a modernized approach to examining animal behaviors. In our current work, we introduced a novel automated cooperative pulling apparatus designed to address these limitations and advance the study of cooperative behaviors by providing a more refined and manipulable platform for experimentation. MarmoAAP offers the ability to enhance behavioral resolution in data collection, increase data output, streamline experimental procedures, and provide the flexibility to systematically manipulate task variables. With this scalable tool, researchers can gain insights into the behavioral dynamics governing cooperative behaviors and the neural mechanisms that underlie these complex social interactions. This methodology not only holds exceptional promise for enriching our understanding of primate behavior but also provides a unique opportunity to explore the intricate connections between neural processes and actions in a manner that bridges controlled and naturalistic experimental conditions.</p><p>The development of MarmoAAP arrives at a critical time, coinciding with burgeoning efforts to engineer genetically modified marmosets (<xref ref-type="bibr" rid="bib28">Kaiser and Feng, 2015</xref>; <xref ref-type="bibr" rid="bib30">Kishi et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Kumita et al., 2019</xref>; <xref ref-type="bibr" rid="bib53">Sato et al., 2016</xref>). As such models progress, it is essential to have robust methodologies that can accurately measure the features of marmoset social interactions. Precise behavioral assays are indispensable for future investigations aiming to elucidate the effects of genetic modifications on social behavior and test potential therapeutic approaches. Just as neurological abilities such as locomotion can be quantitatively assessed (<xref ref-type="bibr" rid="bib48">Pickett et al., 2020</xref>), it is critical to establish equivalent metrics for evaluating complex behavioral patterns in marmosets.</p><sec id="s4-1"><title>Automated task paradigm for naturalistic social exploration</title><p>Using MarmoAAP, we were able to elicit consistent and highly repeatable motivated behaviors in freely moving marmoset monkeys. This task design strikes a pivotal balance between traditional naturalistic animal behavior studies, which benefit from a high degree of naturalism but often suffer from low behavioral resolution and limited trial counts, and conventional lab studies, which are highly controlled but lack natural ethological relevance (<xref ref-type="bibr" rid="bib18">Fan et al., 2021</xref>). Previous research has underscored the substantial impact of behavioral context, specifically the distinction between constrained and freely moving conditions, on prefrontal cortical representations of social information (<xref ref-type="bibr" rid="bib27">Jovanovic et al., 2022</xref>). Our shift toward a paradigm that integrates naturalistic, yet highly repeatable, decisions and actions is imperative for the comprehensive exploration of natural social behaviors and the elucidation of their underlying neural mechanisms. This approach addresses the limitations of paradigms that fall short of faithfully capturing the intricacies of social interactions, emphasizing the importance of a more ecologically valid framework for advancing our understanding of the neural dynamics that underpin fundamental aspects of primate social brain functions.</p></sec><sec id="s4-2"><title>Quantification of high-throughput cooperative behaviors</title><p>We show that marmosets exhibit a rapid acquisition of proficiency in the lever-pulling action and demonstrate their capacity to grasp more complex task contingencies, such as the cooperative pulling task highlighted in this study. Our findings also showcase that the detailed behavioral data outputs from the apparatus, including millisecond-level timestamps for lever pulls and reward deliveries, enable us to quantitatively assess marmosets’ learning and performance on this task. Significantly, our study demonstrates that the automated apparatus facilitates a substantial 15-fold increase in the number of trials conducted per session compared to conventional pulling paradigms. This increased trial throughput is of critical importance for investigations of the neural mechanisms underlying these social behaviors, ensuring the acquisition of a robust dataset for comprehensive analyses of neural activity during naturalistic behavioral settings. Moreover, the ability to examine complex social interactions with high-throughput data might be particularly important for characterizing transgenic marmoset models.</p><p>While our study demonstrates a considerable increase in trial throughput using the automated apparatus, with marmosets completing an average of 146 trials per 20 min session, it is important to note that not all of these trials result in successful outcomes. On average, 47.9 of the 146 trials were successful. Additionally, there are challenges associated with sustaining motivation over longer periods, particularly in the context of the Mutual Cooperation task which requires not just one, but two animals to be simultaneously motivated and engaged for the same duration. Coordinating motivation between two animals is inherently more challenging than motivating a single subject, as both must be willing to work at the same time and for the same length of time to achieve successful cooperation.</p><p>We experimented with several liquid rewards and ultimately selected diluted marshmallow water, as it was consistently consumed by all marmosets. However, further optimization tailored to individual marmosets’ preferences could potentially enhance motivation and extend the duration of task engagement, thereby increasing the number of trials per session. Additionally, our approach to food and water restriction was minimal, involving only the removal of food and water for 1–3 hr each morning without limiting the overall daily intake. For future studies, researchers might consider implementing more controlled and stringent food and water restrictions, in line with established protocols, to increase the marmosets’ motivation by ensuring they are sufficiently hungry or thirsty during task sessions. While our primary focus was on the design, development, and validation of the apparatus and methods, we recognize the potential for further optimization in these areas to maximize the efficacy of the paradigm for neurophysiological and cognitive experiments.</p></sec><sec id="s4-3"><title>Manipulability and adaptability of task parameters and apparatus</title><p>Importantly, the configuration of MarmoAAP allows for precise adjustment of task parameters, a key feature for optimizing marmoset performance and facilitating investigations into a diverse array of complex behaviors. Experimenters can easily fine-tune parameters in the task code to customize apparatus functionality for various behavioral tasks or to accommodate the specific needs and capabilities of individual animals. This adaptability not only expedites the animal training process but also allows for a nuanced exploration of the intricate dimensions of cooperative behaviors, ensuring that experimental conditions closely align with research objectives. Additionally, the design of MarmoAAP is modular, enabling it to be built in different configurations, such as varying the positioning or number of motors and levers. This modularity allows the apparatus to be adapted not only for different types of social tasks but also for non-social tasks, further expanding its utility. Such flexibility is indispensable not only for cooperative tasks but also positions our paradigm as a versatile tool for delving into cognitive processes beyond cooperation.</p><p>Although this paradigm was developed specifically for marmosets, its adaptable design suggests it could be readily modified for use in other species. One key modification would involve adjusting the size of the servo motor and the lever, as the current setup is tailored to small animals like marmosets, which can be trained to exert a pulling force of approximately 500–600 g. For larger animals, incorporating a larger motor capable of exerting greater force, along with more durable parts, would be recommended. By making these adjustments, researchers could tailor the paradigm to suit the physical and cognitive characteristics of different animals, enabling comparative studies across species. This is particularly valuable, as it allows for the examination of how various species approach the same social challenges, providing deeper insights into the nuances of their socio-cognitive abilities.</p></sec><sec id="s4-4"><title>High-resolution behavioral data and multimodal analyses</title><p>In tandem with the intricate behavioral outputs derived from the apparatus, MarmoAAP incorporates the integration of information from many sources and modalities. Utilizing video recordings obtained during the task, we showcased the application of automated behavioral marking tools, such as DLC2 (<xref ref-type="bibr" rid="bib38">Mathis et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Nath et al., 2019</xref>), to probe the interplay between behavioral dynamics—particularly gaze behaviors—and performance on the cooperative task. Complementarily, the inclusion of audio recordings enriches this dataset, allowing for a comprehensive examination of marmosets’ vocal communication patterns and their correlation with task events. This multimodal approach establishes a robust foundation for nuanced investigations into the cognitive processes and social dynamics of marmosets, aligning with a goal toward a comprehensive understanding of primate social behaviors.</p></sec><sec id="s4-5"><title>Integration with neural recordings</title><p>A key attribute of the MarmoAAP design is its capacity to seamlessly integrate with wireless electrophysiology recordings, providing an avenue to explore the neural underpinnings of behavioral processes. The apparatus allows for precise time-locking of task and behavioral events with neural activity as demonstrated in the dlPFC and the OFC. With a substantially increased number of trials amassed through MarmoAAP, this demonstration supports the possibility of examining the neural dynamics underlying cooperative behaviors in marmosets. Our apparatus and paradigm represent a noteworthy advancement, bridging the gap between traditional animal behavior studies that address ethologically relevant behaviors of animals and precise, highly controlled investigations of neural activity.</p></sec><sec id="s4-6"><title>Conclusion and future directions</title><p>In conclusion, we hope that MarmoAAP and the associated automated cooperative pulling paradigm will make a significant contribution to the study of marmoset social behaviors in the field. The combination of a highly modular and adaptable design, high-resolution behavioral data, and integration with neural recordings positions our paradigm as a robust and versatile tool for unraveling the complexities of primate behavior. As we move forward, this paradigm not only serves as a platform for in-depth investigations into marmoset social dynamics but also holds the promise of extending our understanding of cognitive processes and neural mechanisms across a variety of complex behaviors. The scientific community can leverage this paradigm to explore a myriad of cognitive processes, from observational learning to executive function, laying the groundwork for comprehensive insights into the neural mechanisms of complex behaviors in nonhuman primates.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Methodology</p></fn><fn fn-type="con" id="con4"><p>Software, Methodology</p></fn><fn fn-type="con" id="con5"><p>Resources, Data curation, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Data curation, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All procedures were approved by the Yale Institutional Animal Care and Use Committee and complied with the National Institutes of Health Guide for the Care and Use of Laboratory Animals. (Yale University IACUC Protocol #2023-20163).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-97088-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Code for the automated pulling tasks and the SolidWorks CAD file for the apparatus can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/changlabneuro/cooperative-pulling-task/">GitHub</ext-link>.</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Science Foundation Graduate Research Fellowship (DGE2139841, OCM), the National Institute of Mental Health (R21 MH126072, SWCC, ASN, MPJ), the Simons Foundation Autism Research Initiative (SFARI 875855, SWCC, ASN, MPJ), Wu Tsai Institute at Yale University (SWCC, ASN, MPJ, WS), and a National Eye Institute core grant for vision research (P30 EY026878 to Yale University). We thank Paul Shamble and the Neurotechnology Core of the Kavli Institute for Neuroscience at Yale University for providing technical support. We also like to thank Feng Xing, Amrita Nair, and Nyomi Hudson for their support in this research project.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Axelrod</surname><given-names>R</given-names></name><name><surname>Hamilton</surname><given-names>WD</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>The evolution of cooperation</article-title><source>Science</source><volume>211</volume><fpage>1390</fpage><lpage>1396</lpage><pub-id pub-id-type="doi">10.1126/science.7466396</pub-id><pub-id pub-id-type="pmid">7466396</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bliege Bird</surname><given-names>R</given-names></name><name><surname>Ready</surname><given-names>E</given-names></name><name><surname>Power</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The social significance of subtle signals</article-title><source>Nature Human Behaviour</source><volume>2</volume><fpage>452</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1038/s41562-018-0298-3</pub-id><pub-id pub-id-type="pmid">31097793</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Boyd</surname><given-names>R</given-names></name><name><surname>Richerson</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="1985">1985</year><source>Culture and the Evolutionary Process</source><publisher-name>University of Chicago Press</publisher-name></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brosnan</surname><given-names>SF</given-names></name><name><surname>Salwiczek</surname><given-names>L</given-names></name><name><surname>Bshary</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The interplay of cognition and cooperation</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>365</volume><fpage>2699</fpage><lpage>2710</lpage><pub-id pub-id-type="doi">10.1098/rstb.2010.0154</pub-id><pub-id pub-id-type="pmid">20679113</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brosnan</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A hypothesis of the co-evolution of cooperation and responses to inequity</article-title><source>Frontiers in Neuroscience</source><volume>5</volume><elocation-id>43</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2011.00043</pub-id><pub-id pub-id-type="pmid">21519380</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burkart</surname><given-names>JM</given-names></name><name><surname>Heschl</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Understanding visual access in common marmosets, Callithrix jacchus: perspective taking or behaviour reading?</article-title><source>Animal Behaviour</source><volume>73</volume><fpage>457</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1016/j.anbehav.2006.05.019</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burkart</surname><given-names>JM</given-names></name><name><surname>van Schaik</surname><given-names>CP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Cognitive consequences of cooperative breeding in primates?</article-title><source>Animal Cognition</source><volume>13</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1007/s10071-009-0263-7</pub-id><pub-id pub-id-type="pmid">19629551</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burkart</surname><given-names>JM</given-names></name><name><surname>Allon</surname><given-names>O</given-names></name><name><surname>Amici</surname><given-names>F</given-names></name><name><surname>Fichtel</surname><given-names>C</given-names></name><name><surname>Finkenwirth</surname><given-names>C</given-names></name><name><surname>Heschl</surname><given-names>A</given-names></name><name><surname>Huber</surname><given-names>J</given-names></name><name><surname>Isler</surname><given-names>K</given-names></name><name><surname>Kosonen</surname><given-names>ZK</given-names></name><name><surname>Martins</surname><given-names>E</given-names></name><name><surname>Meulman</surname><given-names>EJ</given-names></name><name><surname>Richiger</surname><given-names>R</given-names></name><name><surname>Rueth</surname><given-names>K</given-names></name><name><surname>Spillmann</surname><given-names>B</given-names></name><name><surname>Wiesendanger</surname><given-names>S</given-names></name><name><surname>van Schaik</surname><given-names>CP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The evolutionary origin of human hyper-cooperation</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>4747</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms5747</pub-id><pub-id pub-id-type="pmid">25158760</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burkart</surname><given-names>JM</given-names></name><name><surname>Finkenwirth</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Marmosets as model species in neuroscience and evolutionary anthropology</article-title><source>Neuroscience Research</source><volume>93</volume><fpage>8</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.neures.2014.09.003</pub-id><pub-id pub-id-type="pmid">25242577</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cléry</surname><given-names>JC</given-names></name><name><surname>Hori</surname><given-names>Y</given-names></name><name><surname>Schaeffer</surname><given-names>DJ</given-names></name><name><surname>Menon</surname><given-names>RS</given-names></name><name><surname>Everling</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural network of social interaction observation in marmosets</article-title><source>eLife</source><volume>10</volume><elocation-id>e65012</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.65012</pub-id><pub-id pub-id-type="pmid">33787492</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clutton-Brock</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Cooperation between non-kin in animal societies</article-title><source>Nature</source><volume>462</volume><fpage>51</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1038/nature08366</pub-id><pub-id pub-id-type="pmid">19890322</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crawford</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="1937">1937</year><article-title>The cooperative solving of problems by young chimpanzees</article-title><source>Comparative Psychology Monographs</source><volume>14</volume><fpage>1</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1080/00224545.1941.9714077</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cronin</surname><given-names>KA</given-names></name><name><surname>Kurian</surname><given-names>AV</given-names></name><name><surname>Snowdon</surname><given-names>CT</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cooperative problem solving in a cooperatively breeding primate (Saguinus oedipus)</article-title><source>Animal Behaviour</source><volume>69</volume><fpage>133</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.anbehav.2004.02.024</pub-id><pub-id pub-id-type="pmid">16804561</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De la Fuente</surname><given-names>MF</given-names></name><name><surname>Sueur</surname><given-names>C</given-names></name><name><surname>Garber</surname><given-names>PA</given-names></name><name><surname>Bicca-Marques</surname><given-names>JC</given-names></name><name><surname>Souto</surname><given-names>A</given-names></name><name><surname>Schiel</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Foraging networks and social tolerance in a cooperatively breeding primate (Callithrix jacchus)</article-title><source>The Journal of Animal Ecology</source><volume>91</volume><fpage>138</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1111/1365-2656.13609</pub-id><pub-id pub-id-type="pmid">34655252</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Waal</surname><given-names>FBM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Putting the altruism back into altruism: the evolution of empathy</article-title><source>Annual Review of Psychology</source><volume>59</volume><fpage>279</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.59.103006.093625</pub-id><pub-id pub-id-type="pmid">17550343</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deen</surname><given-names>B</given-names></name><name><surname>Schwiedrzik</surname><given-names>CM</given-names></name><name><surname>Sliwa</surname><given-names>J</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Specialized networks for social cognition in the primate brain</article-title><source>Annual Review of Neuroscience</source><volume>46</volume><fpage>381</fpage><lpage>401</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-102522-121410</pub-id><pub-id pub-id-type="pmid">37428602</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drea</surname><given-names>CM</given-names></name><name><surname>Carter</surname><given-names>AN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Cooperative problem solving in a social carnivore</article-title><source>Animal Behaviour</source><volume>78</volume><fpage>967</fpage><lpage>977</lpage><pub-id pub-id-type="doi">10.1016/j.anbehav.2009.06.030</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>S</given-names></name><name><surname>Dal Monte</surname><given-names>O</given-names></name><name><surname>Chang</surname><given-names>SWC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Levels of naturalism in social neuroscience research</article-title><source>iScience</source><volume>24</volume><elocation-id>102702</elocation-id><pub-id pub-id-type="doi">10.1016/j.isci.2021.102702</pub-id><pub-id pub-id-type="pmid">34258547</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fehr</surname><given-names>E</given-names></name><name><surname>Fischbacher</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The nature of human altruism</article-title><source>Nature</source><volume>425</volume><fpage>785</fpage><lpage>791</lpage><pub-id pub-id-type="doi">10.1038/nature02043</pub-id><pub-id pub-id-type="pmid">14574401</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fehr</surname><given-names>E</given-names></name><name><surname>Rockenbach</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Human altruism: economic, neural, and evolutionary perspectives</article-title><source>Current Opinion in Neurobiology</source><volume>14</volume><fpage>784</fpage><lpage>790</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2004.10.007</pub-id><pub-id pub-id-type="pmid">15582384</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>French</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1997">1997</year><source>Cooperative Breeding in Mammals</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511574634.004</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>French</surname><given-names>JA</given-names></name><name><surname>Cavanaugh</surname><given-names>J</given-names></name><name><surname>Mustoe</surname><given-names>AC</given-names></name><name><surname>Carp</surname><given-names>SB</given-names></name><name><surname>Womack</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Social monogamy in nonhuman primates: Phylogeny, phenotype, and physiology</article-title><source>Journal of Sex Research</source><volume>55</volume><fpage>410</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1080/00224499.2017.1339774</pub-id><pub-id pub-id-type="pmid">28704071</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hare</surname><given-names>B</given-names></name><name><surname>Addessi</surname><given-names>E</given-names></name><name><surname>Call</surname><given-names>J</given-names></name><name><surname>Tomasello</surname><given-names>M</given-names></name><name><surname>Visalberghi</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Do capuchin monkeys, Cebus apella, know what conspecifics do and do not see?</article-title><source>Animal Behaviour</source><volume>65</volume><fpage>131</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1006/anbe.2002.2017</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huk</surname><given-names>A</given-names></name><name><surname>Bonnen</surname><given-names>K</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Beyond trial-based paradigms: Continuous behavior, ongoing neural activity, and natural stimuli</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>7551</fpage><lpage>7558</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1920-17.2018</pub-id><pub-id pub-id-type="pmid">30037835</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hung</surname><given-names>C-C</given-names></name><name><surname>Yen</surname><given-names>CC</given-names></name><name><surname>Ciuchta</surname><given-names>JL</given-names></name><name><surname>Papoti</surname><given-names>D</given-names></name><name><surname>Bock</surname><given-names>NA</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Silva</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional mapping of face-selective regions in the extrastriate visual cortex of the marmoset</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>1160</fpage><lpage>1172</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2659-14.2015</pub-id><pub-id pub-id-type="pmid">25609630</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Shi</surname><given-names>Q</given-names></name><name><surname>Wei</surname><given-names>L</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>D</given-names></name><name><surname>Liu</surname><given-names>B</given-names></name><name><surname>Nie</surname><given-names>X</given-names></name><name><surname>Qiao</surname><given-names>H</given-names></name><name><surname>Xu</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Evolution and neural representation of mammalian cooperative behavior</article-title><source>Cell Reports</source><volume>37</volume><elocation-id>110029</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.110029</pub-id><pub-id pub-id-type="pmid">34788618</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jovanovic</surname><given-names>V</given-names></name><name><surname>Fishbein</surname><given-names>AR</given-names></name><name><surname>de la Mothe</surname><given-names>L</given-names></name><name><surname>Lee</surname><given-names>K-F</given-names></name><name><surname>Miller</surname><given-names>CT</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Behavioral context affects social signal representations within single primate prefrontal cortex neurons</article-title><source>Neuron</source><volume>110</volume><fpage>1318</fpage><lpage>1326</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.020</pub-id><pub-id pub-id-type="pmid">35108498</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaiser</surname><given-names>T</given-names></name><name><surname>Feng</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Modeling psychiatric disorders for developing effective treatments</article-title><source>Nature Medicine</source><volume>21</volume><fpage>979</fpage><lpage>988</lpage><pub-id pub-id-type="doi">10.1038/nm.3935</pub-id><pub-id pub-id-type="pmid">26340119</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karashchuk</surname><given-names>P</given-names></name><name><surname>Rupp</surname><given-names>KL</given-names></name><name><surname>Dickinson</surname><given-names>ES</given-names></name><name><surname>Walling-Bell</surname><given-names>S</given-names></name><name><surname>Sanders</surname><given-names>E</given-names></name><name><surname>Azim</surname><given-names>E</given-names></name><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Tuthill</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Anipose: A toolkit for robust markerless 3D pose estimation</article-title><source>Cell Reports</source><volume>36</volume><elocation-id>109730</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.109730</pub-id><pub-id pub-id-type="pmid">34592148</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kishi</surname><given-names>N</given-names></name><name><surname>Sato</surname><given-names>K</given-names></name><name><surname>Sasaki</surname><given-names>E</given-names></name><name><surname>Okano</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Common marmoset as a new model animal for neuroscience research and genome editing technology</article-title><source>Development, Growth &amp; Differentiation</source><volume>56</volume><fpage>53</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1111/dgd.12109</pub-id><pub-id pub-id-type="pmid">24387631</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knöll</surname><given-names>J</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Lawful tracking of visual motion in humans, macaques, and marmosets in a naturalistic, continuous, and untrained behavioral context</article-title><source>PNAS</source><volume>115</volume><fpage>E10486</fpage><lpage>E10494</lpage><pub-id pub-id-type="doi">10.1073/pnas.1807192115</pub-id><pub-id pub-id-type="pmid">30322919</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumita</surname><given-names>W</given-names></name><name><surname>Sato</surname><given-names>K</given-names></name><name><surname>Suzuki</surname><given-names>Y</given-names></name><name><surname>Kurotaki</surname><given-names>Y</given-names></name><name><surname>Harada</surname><given-names>T</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Kishi</surname><given-names>N</given-names></name><name><surname>Sato</surname><given-names>K</given-names></name><name><surname>Aiba</surname><given-names>A</given-names></name><name><surname>Sakakibara</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>G</given-names></name><name><surname>Okano</surname><given-names>H</given-names></name><name><surname>Sasaki</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Efficient generation of Knock-in/Knock-out marmoset embryo via CRISPR/Cas9 gene editing</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>12719</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-49110-3</pub-id><pub-id pub-id-type="pmid">31481684</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lauer</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>M</given-names></name><name><surname>Ye</surname><given-names>S</given-names></name><name><surname>Menegas</surname><given-names>W</given-names></name><name><surname>Schneider</surname><given-names>S</given-names></name><name><surname>Nath</surname><given-names>T</given-names></name><name><surname>Rahman</surname><given-names>MM</given-names></name><name><surname>Di Santo</surname><given-names>V</given-names></name><name><surname>Soberanes</surname><given-names>D</given-names></name><name><surname>Feng</surname><given-names>G</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Lauder</surname><given-names>G</given-names></name><name><surname>Dulac</surname><given-names>C</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Multi-animal pose estimation, identification and tracking with DeepLabCut</article-title><source>Nature Methods</source><volume>19</volume><fpage>496</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1038/s41592-022-01443-0</pub-id><pub-id pub-id-type="pmid">35414125</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>MK</given-names></name><name><surname>Takahashi</surname><given-names>YS</given-names></name><name><surname>Huo</surname><given-names>B-X</given-names></name><name><surname>Hanada</surname><given-names>M</given-names></name><name><surname>Nagashima</surname><given-names>J</given-names></name><name><surname>Hata</surname><given-names>J</given-names></name><name><surname>Tolpygo</surname><given-names>AS</given-names></name><name><surname>Ram</surname><given-names>K</given-names></name><name><surname>Lee</surname><given-names>BC</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name><name><surname>Rosa</surname><given-names>MG</given-names></name><name><surname>Sasaki</surname><given-names>E</given-names></name><name><surname>Iriki</surname><given-names>A</given-names></name><name><surname>Okano</surname><given-names>H</given-names></name><name><surname>Mitra</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A high-throughput neurohistological pipeline for brain-wide mesoscale connectivity mapping of the common marmoset</article-title><source>eLife</source><volume>8</volume><elocation-id>e40042</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.40042</pub-id><pub-id pub-id-type="pmid">30720427</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Newman</surname><given-names>JD</given-names></name><name><surname>Szczupak</surname><given-names>D</given-names></name><name><surname>Tian</surname><given-names>X</given-names></name><name><surname>Yen</surname><given-names>CC-C</given-names></name><name><surname>Majka</surname><given-names>P</given-names></name><name><surname>Glen</surname><given-names>D</given-names></name><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Silva</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A resource for the detailed 3D mapping of white matter pathways in the marmoset brain</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>271</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0575-0</pub-id><pub-id pub-id-type="pmid">31932765</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lozano</surname><given-names>P</given-names></name><name><surname>Gavrilets</surname><given-names>S</given-names></name><name><surname>Sánchez</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cooperation, social norm internalization, and hierarchical societies</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>15359</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-71664-w</pub-id><pub-id pub-id-type="pmid">32958841</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>JS</given-names></name><name><surname>Koski</surname><given-names>SE</given-names></name><name><surname>Bugnyar</surname><given-names>T</given-names></name><name><surname>Jaeggi</surname><given-names>AV</given-names></name><name><surname>Massen</surname><given-names>JJM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Prosociality, social tolerance and partner choice facilitate mutually beneficial cooperation in common marmosets, Callithrix jacchus</article-title><source>Animal Behaviour</source><volume>173</volume><fpage>115</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/j.anbehav.2020.12.016</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mendres</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Capuchins do cooperate: the advantage of an intuitive task</article-title><source>Animal Behaviour</source><volume>60</volume><fpage>523</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1006/anbe.2000.1512</pub-id><pub-id pub-id-type="pmid">11032655</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>CT</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Mitchell</surname><given-names>JF</given-names></name><name><surname>Silva</surname><given-names>AC</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Marmosets: a neuroscientific model of human social behavior</article-title><source>Neuron</source><volume>90</volume><fpage>219</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.018</pub-id><pub-id pub-id-type="pmid">27100195</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>CT</given-names></name><name><surname>Gire</surname><given-names>D</given-names></name><name><surname>Hoke</surname><given-names>K</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Kelley</surname><given-names>D</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Smear</surname><given-names>MC</given-names></name><name><surname>Theunissen</surname><given-names>F</given-names></name><name><surname>Yartsev</surname><given-names>M</given-names></name><name><surname>Niell</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Natural behavior is the language of the brain</article-title><source>Current Biology</source><volume>32</volume><fpage>R482</fpage><lpage>R493</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.03.031</pub-id><pub-id pub-id-type="pmid">35609550</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>JF</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The marmoset monkey as a model for visual neuroscience</article-title><source>Neuroscience Research</source><volume>93</volume><fpage>20</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1016/j.neures.2015.01.008</pub-id><pub-id pub-id-type="pmid">25683292</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mustoe</surname><given-names>AC</given-names></name><name><surname>Harnisch</surname><given-names>AM</given-names></name><name><surname>Hochfelder</surname><given-names>B</given-names></name><name><surname>Cavanaugh</surname><given-names>J</given-names></name><name><surname>French</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Inequity aversion strategies between marmosets are influenced by partner familiarity and sex but not oxytocin</article-title><source>Animal Behaviour</source><volume>114</volume><fpage>69</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.anbehav.2016.01.025</pub-id><pub-id pub-id-type="pmid">27019514</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nath</surname><given-names>T</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>AC</given-names></name><name><surname>Patel</surname><given-names>A</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title><source>Nature Protocols</source><volume>14</volume><fpage>2152</fpage><lpage>2176</lpage><pub-id pub-id-type="doi">10.1038/s41596-019-0176-0</pub-id><pub-id pub-id-type="pmid">31227823</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nowak</surname><given-names>MA</given-names></name><name><surname>Sigmund</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Evolution of indirect reciprocity</article-title><source>Nature</source><volume>437</volume><fpage>1291</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1038/nature04131</pub-id><pub-id pub-id-type="pmid">16251955</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okano</surname><given-names>H</given-names></name><name><surname>Sasaki</surname><given-names>E</given-names></name><name><surname>Yamamori</surname><given-names>T</given-names></name><name><surname>Iriki</surname><given-names>A</given-names></name><name><surname>Shimogori</surname><given-names>T</given-names></name><name><surname>Yamaguchi</surname><given-names>Y</given-names></name><name><surname>Kasai</surname><given-names>K</given-names></name><name><surname>Miyawaki</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Brain/MINDS: a Japanese national brain project for marmoset neuroscience</article-title><source>Neuron</source><volume>92</volume><fpage>582</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.018</pub-id><pub-id pub-id-type="pmid">27809998</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Sridhar</surname><given-names>S</given-names></name><name><surname>Stringer</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Solving the Spike Sorting Problem with Kilosort</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.01.07.523036</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pickett</surname><given-names>KA</given-names></name><name><surname>Schultz-Darken</surname><given-names>N</given-names></name><name><surname>Bradfield</surname><given-names>AF</given-names></name><name><surname>Malicki</surname><given-names>K</given-names></name><name><surname>Pape</surname><given-names>B</given-names></name><name><surname>Ausderau</surname><given-names>KK</given-names></name><name><surname>Emborg</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Spatiotemporal quantification of gait in common marmosets</article-title><source>Journal of Neuroscience Methods</source><volume>330</volume><elocation-id>108517</elocation-id><pub-id pub-id-type="doi">10.1016/j.jneumeth.2019.108517</pub-id><pub-id pub-id-type="pmid">31730871</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plotnik</surname><given-names>JM</given-names></name><name><surname>Lair</surname><given-names>R</given-names></name><name><surname>Suphachoksahakun</surname><given-names>W</given-names></name><name><surname>de Waal</surname><given-names>FBM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Elephants know when they need a helping trunk in a cooperative task</article-title><source>PNAS</source><volume>108</volume><fpage>5116</fpage><lpage>5121</lpage><pub-id pub-id-type="doi">10.1073/pnas.1101765108</pub-id><pub-id pub-id-type="pmid">21383191</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Range</surname><given-names>F</given-names></name><name><surname>Kassis</surname><given-names>A</given-names></name><name><surname>Taborsky</surname><given-names>M</given-names></name><name><surname>Boada</surname><given-names>M</given-names></name><name><surname>Marshall-Pescini</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Wolves and dogs recruit human partners in the cooperative string-pulling task</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>17591</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-53632-1</pub-id><pub-id pub-id-type="pmid">31772201</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rilling</surname><given-names>JK</given-names></name><name><surname>Sanfey</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neuroscience of social decision-making</article-title><source>Annual Review of Psychology</source><volume>62</volume><fpage>23</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.121208.131647</pub-id><pub-id pub-id-type="pmid">20822437</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>LJ</given-names></name><name><surname>Stewart</surname><given-names>L</given-names></name><name><surname>Kaplan</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Food calls in common marmosets, <italic>Callithrix jacchus</italic>, and evidence that one is functionally referential</article-title><source>Animals</source><volume>8</volume><elocation-id>99</elocation-id><pub-id pub-id-type="doi">10.3390/ani8070099</pub-id><pub-id pub-id-type="pmid">29933611</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>K</given-names></name><name><surname>Oiwa</surname><given-names>R</given-names></name><name><surname>Kumita</surname><given-names>W</given-names></name><name><surname>Henry</surname><given-names>R</given-names></name><name><surname>Sakuma</surname><given-names>T</given-names></name><name><surname>Ito</surname><given-names>R</given-names></name><name><surname>Nozu</surname><given-names>R</given-names></name><name><surname>Inoue</surname><given-names>T</given-names></name><name><surname>Katano</surname><given-names>I</given-names></name><name><surname>Sato</surname><given-names>K</given-names></name><name><surname>Okahara</surname><given-names>N</given-names></name><name><surname>Okahara</surname><given-names>J</given-names></name><name><surname>Shimizu</surname><given-names>Y</given-names></name><name><surname>Yamamoto</surname><given-names>M</given-names></name><name><surname>Hanazawa</surname><given-names>K</given-names></name><name><surname>Kawakami</surname><given-names>T</given-names></name><name><surname>Kametani</surname><given-names>Y</given-names></name><name><surname>Suzuki</surname><given-names>R</given-names></name><name><surname>Takahashi</surname><given-names>T</given-names></name><name><surname>Weinstein</surname><given-names>EJ</given-names></name><name><surname>Yamamoto</surname><given-names>T</given-names></name><name><surname>Sakakibara</surname><given-names>Y</given-names></name><name><surname>Habu</surname><given-names>S</given-names></name><name><surname>Hata</surname><given-names>J-I</given-names></name><name><surname>Okano</surname><given-names>H</given-names></name><name><surname>Sasaki</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Generation of a nonhuman primate model of severe combined immunodeficiency using highly efficient genome editing</article-title><source>Cell Stem Cell</source><volume>19</volume><fpage>127</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1016/j.stem.2016.06.003</pub-id><pub-id pub-id-type="pmid">27374787</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schaffner</surname><given-names>CM</given-names></name><name><surname>Caine</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Natural Conflict Resolution</source><publisher-name>University of California Press</publisher-name></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmelz</surname><given-names>M</given-names></name><name><surname>Duguid</surname><given-names>S</given-names></name><name><surname>Bohn</surname><given-names>M</given-names></name><name><surname>Völter</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cooperative problem solving in giant otters (Pteronura brasiliensis) and Asian small-clawed otters (Aonyx cinerea)</article-title><source>Animal Cognition</source><volume>20</volume><fpage>1107</fpage><lpage>1114</lpage><pub-id pub-id-type="doi">10.1007/s10071-017-1126-2</pub-id><pub-id pub-id-type="pmid">28840405</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>JT</given-names></name><name><surname>Bourne</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Modelling behaviors relevant to brain disorders in the nonhuman primate: Are we there yet?</article-title><source>Progress in Neurobiology</source><volume>208</volume><elocation-id>102183</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2021.102183</pub-id><pub-id pub-id-type="pmid">34728308</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seed</surname><given-names>AM</given-names></name><name><surname>Clayton</surname><given-names>NS</given-names></name><name><surname>Emery</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Cooperative problem solving in rooks (Corvus frugilegus)</article-title><source>Proceedings. Biological Sciences</source><volume>275</volume><fpage>1421</fpage><lpage>1429</lpage><pub-id pub-id-type="doi">10.1098/rspb.2008.0111</pub-id><pub-id pub-id-type="pmid">18364318</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snowdon</surname><given-names>CT</given-names></name><name><surname>Cronin</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Cooperative breeders do cooperate</article-title><source>Behavioural Processes</source><volume>76</volume><fpage>138</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/j.beproc.2007.01.016</pub-id><pub-id pub-id-type="pmid">17703900</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname><given-names>DY</given-names></name><name><surname>Moeller</surname><given-names>S</given-names></name><name><surname>Freiwald</surname><given-names>WA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Comparing face patch systems in macaques and humans</article-title><source>PNAS</source><volume>105</volume><fpage>19514</fpage><lpage>19519</lpage><pub-id pub-id-type="doi">10.1073/pnas.0809662105</pub-id><pub-id pub-id-type="pmid">19033466</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vitale</surname><given-names>A</given-names></name><name><surname>Zanzoni</surname><given-names>M</given-names></name><name><surname>Queyras</surname><given-names>A</given-names></name><name><surname>Chiarotti</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Degree of social contact affects the emission of food calls in the common marmoset (Callithrix jacchus)</article-title><source>American Journal of Primatology</source><volume>59</volume><fpage>21</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1002/ajp.10060</pub-id><pub-id pub-id-type="pmid">12526036</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woodward</surname><given-names>A</given-names></name><name><surname>Hashikawa</surname><given-names>T</given-names></name><name><surname>Maeda</surname><given-names>M</given-names></name><name><surname>Kaneko</surname><given-names>T</given-names></name><name><surname>Hikishima</surname><given-names>K</given-names></name><name><surname>Iriki</surname><given-names>A</given-names></name><name><surname>Okano</surname><given-names>H</given-names></name><name><surname>Yamaguchi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Brain/MINDS 3D digital marmoset brain atlas</article-title><source>Scientific Data</source><volume>5</volume><elocation-id>180009</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2018.9</pub-id><pub-id pub-id-type="pmid">29437168</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97088.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>SP</surname><given-names>Arun</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Indian Institute of Science Bangalore</institution><country>India</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study describes an apparatus, workflow, and proof-of-concept data for a system to study social cooperation in marmosets, an increasingly popular primate model for neuroscience. The apparatus and methodology have clear and <bold>convincing</bold> advantages over conventional methods based on manual approaches. However, claims of faster social learning or of finer-grained behavioural analysis in this setup will require further corroboration.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97088.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This manuscript by Meissner and colleagues described a novel take on a classic social cognition paradigm developed for marmosets. The classic pull task is a powerful paradigm that has been used for many years across numerous species, but its analog approach has several key limitations. As such, it has not been feasible to adopt the task for neuroscience experiments. Here the authors capture the spirit of the classic task but provide several fundamental innovations that modernize the paradigm - technically and conceptually. By developing the paradigm for marmosets, the authors leverage the many advantages of this primate model for studies of social brain functions and their particular amenability to freely-moving naturalistic approaches.</p><p>Strengths:</p><p>The current manuscript describes one of the most exciting paradigms in primate social cognition to be developed in many years. By allowing for freely-moving marmosets to engage in high numbers of trials, while precisely quantifying their visual behavior (e.g. gaze) and recording neural activity this paradigm has the potential to usher in a new wave of research on the cognitive and neural mechanisms underlying primate social cognition and decision-making. This paradigm is an elegant illustration of how naturalistic questions can be adapted to more rigorous experimental paradigms. Overall, I thought the manuscript was well written and provided sufficient details for others to adopt this paradigm.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97088.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This important work by Meisner et al., developed an automated apparatus (MarmoAPP) to collect a wide array of behavioral data (lever pulling, gaze direction, vocalizations) in marmoset monkeys, with the goal of modernizing collection of behavioral data to coincide with the investigation of neurological mechanisms governing behavioral decision making in an important primate neuroscience model. The authors show a variety of &quot;proof-of-principle&quot; concepts that this apparatus can collect a wide range of behavioral data, with higher behavioral resolution than traditional methods. For example, the authors highlight that typical behavioral experiments on primate cooperation provide around 10 trials per session, while using their approach the authors were able to collect over 100 trials per 20-minute session with the MarmoAAP.</p><p>Overall the authors argue that this approach has a few notable advantages:</p><p>(1) It enhances behavioral output which is important for measuring small or nuanced effects/changes in behavior;</p><p>(2) Allows for more advanced analyses given the higher number of trials per session;</p><p>(3) Significantly reduces the human labor of manually coding behavioral outcomes and experimenter interventions such as reloading apparatuses for food or position;</p><p>(4) Allows for more flexibility and experimental rigor in measuring behavior and neural activity simultaneously.</p><p>Strengths:</p><p>The paper is well-written and the MarmoAPP appears to be highly successful at integrating behavioral data across many important contexts (cooperation, gaze, vocalizations), with the ability to measure significantly many more behavioral contexts (many of which the authors make suggestions for).</p><p>The authors provide substantive information about the design of the apparatus, how the apparatus can be obtained via a long list of information Apparatus parts and information, and provide data outcomes from a wide number of behavioral and neurological outcomes. The significance of the findings is important for the field of social neuroscience and the strength of evidence is solid in terms of the ability of the apparatus to perform as described, at least in marmoset monkeys. The advantage of collecting neural and freely-behaving behavioral data concurrently is a significant advantage.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97088.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors set out to devise a system for the neural and behavioral study of socially cooperative behaviors in nonhuman primates (common marmosets). They describe instrumentation to allow for a &quot;cooperative pulling&quot; paradigm, the training process, and how both behavioral and neural data can be collected and analyzed. This is a valuable approach to an important topic, as the marmoset stands as a great platform to study primate social cognition. Given that the goals of such a methods paper are to (a) describe the approach and instrumentation, (b) show the feasibility of use, and (c) quantitatively compare to related approaches, the work is easily able to meet those criteria. My specific feedback on both strengths and weaknesses is therefore relatively limited in scope and depth.</p><p>Strengths:</p><p>The device is well-described, and the authors should be commended for their efforts in both designing this system but also in &quot;writing it up&quot; so that others can benefit from their R&amp;D.</p><p>The device appears to generate more repetitions of key behavior than other approaches used in prior work (with other species).</p><p>The device allows for quantitative control and adjustment to control behaviour.</p><p>The approach also supports the integration of markerless behavioral analysis as well as neurophysiological data.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97088.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Meisner</surname><given-names>Olivia C</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Shi</surname><given-names>Weikang</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Fagan</surname><given-names>Nicholas</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Greenwood</surname><given-names>Joel</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Jadi</surname><given-names>Monika P</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Nandy</surname><given-names>Anirvan S</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Chang</surname><given-names>Steve WC</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>This manuscript by Meissner and colleagues described a novel take on a classic social cognition paradigm developed for marmosets. The classic pull task is a powerful paradigm that has been used for many years across numerous species, but its analog approach has several key limitations. As such, it has not been feasible to adopt the task for neuroscience experiments. Here the authors capture the spirit of the classic task but provide several fundamental innovations that modernize the paradigm - technically and conceptually. By developing the paradigm for marmosets, the authors leverage the many advantages of this primate model for studies of social brain functions and their particular amenability to freely-moving naturalistic approaches.</p><p>Strengths:</p><p>The current manuscript describes one of the most exciting paradigms in primate social cognition to be developed in many years. By allowing for freely-moving marmosets to engage in high numbers of trials, while precisely quantifying their visual behavior (e.g. gaze) and recording neural activity this paradigm has the potential to usher in a new wave of research on the cognitive and neural mechanisms underlying primate social cognition and decision-making. This paradigm is an elegant illustration of how naturalistic questions can be adapted to more rigorous experimental paradigms. Overall, I thought the manuscript was well written and provided sufficient details for others to adopt this paradigm. I did have a handful of questions and requests about topics and information that could help to further accelerate its adoption across the field.</p><p>Weaknesses:</p><p>LN 107 - Otters have also been successful at the classic pull task (<ext-link ext-link-type="uri" xlink:href="https://link.springer.com/article/10.1007/s10071-017-1126-2">https://link.springer.com/article/10.1007/s10071-017-1126-2</ext-link>)</p></disp-quote><p>We have added this reference to the manuscript.</p><disp-quote content-type="editor-comment"><p>LN 151 - Can you provide a more precise quantification of timing accuracy than the 'sub-second level'. This helps determine synchronization with other devices.</p></disp-quote><p>We have included more precise timing details, noting that data is stored at the millisecond level.</p><disp-quote content-type="editor-comment"><p>Using this paradigm, the marmosets achieved more trials than in the conventional task (146 vs 10). While this is impressive, given that only ~50 are successful Mutual Cooperation trials it does present some challenges for potential neurophysiology experiments and particular cognitive questions. The marmosets are only performing the task for 20 minutes, presumably because they become sated and are no longer motivated. This seems a limitation of the task and is something worth discussing in the manuscript. Did the authors try other food rewards, reduce the amount of reward, food/water restrict the animals for more than the stated 1-3 hours? How might this paradigm be incorporated into in-cage approaches that have been successful in marmosets? Any details on this would help guide others seeking to extend the number of trials performed each day.</p></disp-quote><p>We have added a discussion addressing the use of liquid rewards, minimal food and water restriction, and the potential for further optimization to increase task engagement and trial numbers. This is now reflected in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Can you provide more details on the DLC/Anipose procedure? How were the cameras synchronized? What percentage of trials needed to be annotated before the model could be generalized? Did each monkey require its own model, or was a single one applied to all animals?</p></disp-quote><p>We have added more detailed information on the DLC and Anipose tracking which can be found in the <italic>Multi-animal 3D tracking</italic> section under Materials &amp; Methods.</p><disp-quote content-type="editor-comment"><p>Will the schematics and more instructions on building this system be made publicly available? A number of the components listed in Table 1 are custom-designed. Although it is stated that CAD files will be made available upon request, sharing a link to these files in an accessible folder would significantly add to the potential impact of this paradigm by making it easier for others to adopt.</p></disp-quote><p>We have made the SolidWorks CAD files publicly available. They can now be found in the Github repository alongside the apparatus and task code.</p><disp-quote content-type="editor-comment"><p>In the Discussion, it would be helpful to have some discussion of how this paradigm might be used more broadly. The classic pulling paradigm typically allows one to ask a specific question about social cognition, but this task has the potential to be more widely applied to other social decision-making questions. For example, how might this task be adopted to ask some of the game-theory-type approaches common in this literature? Given the authors' expertise in this area, this discussion could serve to provide a roadmap for the broader field to adopt.</p><p>Although this paradigm was developed specifically for marmosets, it seems to me that it could readily be adopted in other species with some modifications. Could the authors speak to this and their thoughts on what may need to be changed to be used in other species? This is particularly important because one of the advantages of the classic paradigm is that it has been used in so many species, providing the opportunity to compare how different species approach the same challenge. For example, though both chimps and bonobos are successful, their differences are notably illuminating about the nuances of their respective social cognitive faculties.</p></disp-quote><p>We have expanded the discussion for the broader applications of this apparatus both for other decision-making research questions as well as its adaptability for use in other species.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>This important work by Meisner et al., developed an automated apparatus (MarmoAPP) to collect a wide array of behavioral data (lever pulling, gaze direction, vocalizations) in marmoset monkeys, with the goal of modernizing collection of behavioral data to coincide with the investigation of neurological mechanisms governing behavioral decision making in an important primate neuroscience model. The authors show a variety of &quot;proof-of-principle&quot; concepts that this apparatus can collect a wide range of behavioral data, with higher behavioral resolution than traditional methods. For example, the authors highlight that typical behavioral experiments on primate cooperation provide around 10 trials per session, while using their approach the authors were able to collect over 100 trials per 20-minute session with the MarmoAAP.</p><p>Overall the authors argue that this approach has a few notable advantages:</p><p>(1) it enhances behavioral output which is important for measuring small or nuanced effects/changes in behavior;</p><p>(2) allows for more advanced analyses given the higher number of trials per session;</p><p>(3) significantly reduces the human labor of manually coding behavioral outcomes and experimenter interventions such as reloading apparatuses for food or position;</p><p>(4) allows for more flexibility and experimental rigor in measuring behavior and neural activity simultaneously.</p><p>Strengths:</p><p>The paper is well-written and the MarmoAPP appears to be highly successful at integrating behavioral data across many important contexts (cooperation, gaze, vocalizations), with the ability to measure significantly many more behavioral contexts (many of which the authors make suggestions for).</p><p>The authors provide substantive information about the design of the apparatus, how the apparatus can be obtained via a long list of information Apparatus parts and information, and provide data outcomes from a wide number of behavioral and neurological outcomes. The significance of the findings is important for the field of social neuroscience and the strength of evidence is solid in terms of the ability of the apparatus to perform as described, at least in marmoset monkeys. The advantage of collecting neural and freely-behaving behavioral data concurrently is a significant advantage.</p><p>Weaknesses:</p><p>While this paper has many significant strengths, there are a few notable weaknesses in that many of the advantages are not explicitly demonstrated within the evidence presented in the paper. There are data reported (as shown in Figures 2 and 3), but in many cases, it is unclear if the data is referenced in other published work, as the data analysis is not described and/or self-contained within the manuscript, which it should be for readers to understand the nature of the data shown in Figures 2 and 3.</p><p>(1) There is no data in the paper or reference demonstrating training performance in the marmosets. For example, how many sessions are required to reach a pre-determined criterion of acceptable demonstration of task competence? The authors reference reliably performing the self-reward task, but this was not objectively stated in terms of what level of reliability was used. Moreover, in the Mutual Cooperation paradigm, while there is data reported on performance between self-reward vs mutual cooperation tasks, it is unclear how the authors measured individual understanding of mutual cooperation in this paradigm (cooperation performance in the mutual cooperation paradigm in the presence or absence of a partner; and how, if at all, this performance varied across social context). What positive or negative control is used to discern gained advantages between deliberate cooperation vs two individuals succeeding at self-reward simultaneously?</p></disp-quote><p>Thank you for your comment. This Tools &amp; Resources paper is focused solely on the development of the apparatus and methods. Future publications will provide more details on training performance, learning behaviors, and include appropriate controls to distinguish deliberate cooperation from simultaneous success in self-reward tasks.</p><disp-quote content-type="editor-comment"><p>(2) One of the notable strengths of this approach argued by the authors is the improved ability to utilize trials for data analysis, but this is not presented or supported in the manuscript. For example, the paper would be improved by explicitly showing a significant improvement in the analytical outcome associated with a comparison of cooperation performance in the context of ~150 trials using MarmoAAP vs 10-12 trials using conventional behavioral approaches beyond the general principle of sample size. The authors highlight the dissection of intricacies of behavioral dynamics, but more could be demonstrated to specifically show these intricacies compared to conventional approaches. Given the cost and expertise required to build and operate the MarmoAAP, it is critical to provide an important advantage gained on this front. The addition of data analysis and explicit description(s) of other analytical advantages would likely strengthen this paper and the advantages of MarmoAAP over other behavioral techniques.</p></disp-quote><p>Thank you for the suggestion. While this manuscript focuses on the apparatus and methods, the increase in trial numbers itself provides clear advantages, including greater statistical power and more robust analyses of behavioral dynamics. Future publications will offer more in-depth analyses comparing the performance and cooperation behavior observed with MarmoAAP, further demonstrating these analytical benefits.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Summary:</p><p>The authors set out to devise a system for the neural and behavioral study of socially cooperative behaviors in nonhuman primates (common marmosets). They describe instrumentation to allow for a &quot;cooperative pulling&quot; paradigm, the training process, and how both behavioral and neural data can be collected and analyzed. This is a valuable approach to an important topic, as the marmoset stands as a great platform to study primate social cognition. Given that the goals of such a methods paper are to (a) describe the approach and instrumentation, (b) show the feasibility of use, and (c) quantitatively compare to related approaches, the work is easily able to meet those criteria. My specific feedback on both strengths and weaknesses is therefore relatively limited in scope and depth.</p><p>Strengths:</p><p>The device is well-described, and the authors should be commended for their efforts in both designing this system but also in &quot;writing it up&quot; so that others can benefit from their R&amp;D.</p><p>The device appears to generate more repetitions of key behavior than other approaches used in prior work (with other species).</p><p>The device allows for quantitative control and adjustment to control behavior.</p><p>The approach also supports the integration of markerless behavioral analysis as well as neurophysiological data.</p><p>Weaknesses:</p><p>A few ambiguities in the descriptions are flagged below in the &quot;Recommendations for authors&quot;.</p><p>The system is well-suited to marmosets, but it is less clear whether it could be generalized for use in other species (in which similar behaviors have been studied with far less elegant approaches). If the system could impact work in other species, the scope of impact would be significantly increased, and would also allow for more direct cross-species comparisons. Regardless, the future work that this system will allow in the marmoset will itself be novel, unique, and likely to support major insights into primate social cognition.</p></disp-quote><p>Thank you for this feedback. We have expanded the discussion to include how the apparatus could be adapted for use in other species, highlighting the potential modifications required, such as adjusting the size and strength of the servo motor and components. These changes would enable broader applications and facilitate cross-species comparisons.</p></body></sub-article></article>