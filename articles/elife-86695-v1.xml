<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">86695</article-id><article-id pub-id-type="doi">10.7554/eLife.86695</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.86695.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A reductionist paradigm for high-throughput behavioural fingerprinting in <italic>Drosophila melanogaster</italic></article-title></title-group><contrib-group><contrib contrib-type="author" id="author-305618"><name><surname>Jones</surname><given-names>Hannah</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9481-8094</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-305619"><name><surname>Willis</surname><given-names>Jenny A</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-256673"><name><surname>Firth</surname><given-names>Lucy C</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-256668"><name><surname>Giachello</surname><given-names>Carlo NG</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4186-1571</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-73720"><name><surname>Gilestro</surname><given-names>Giorgio F</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7512-8541</contrib-id><email>giorgio@gilest.ro</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Department of Life Sciences, Imperial College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/000bdn450</institution-id><institution>Syngenta, Jealott’s Hill International Research Centre</institution></institution-wrap><addr-line><named-content content-type="city">Bracknell</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ewer</surname><given-names>John</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00h9jrb69</institution-id><institution>Universidad de Valparaiso</institution></institution-wrap><country>Chile</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Desplan</surname><given-names>Claude</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>New York University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>08</day><month>11</month><year>2023</year></pub-date><volume>12</volume><elocation-id>RP86695</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-02-20"><day>20</day><month>02</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2022-12-15"><day>15</day><month>12</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.12.15.519769"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-05-11"><day>11</day><month>05</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.86695.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-10-31"><day>31</day><month>10</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.86695.2"/></event></pub-history><permissions><copyright-statement>© 2023, Jones et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Jones et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-86695-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-86695-figures-v1.pdf"/><abstract><p>Understanding how the brain encodes behaviour is the ultimate goal of neuroscience and the ability to objectively and reproducibly describe and quantify behaviour is a necessary milestone on this path. Recent technological progresses in machine learning and computational power have boosted the development and adoption of systems leveraging on high-resolution video recording to track an animal pose and describe behaviour in all four dimensions. However, the high temporal and spatial resolution that these systems offer must come as a compromise with their throughput and accessibility. Here, we describe <italic>coccinella</italic>, an open-source reductionist framework combining high-throughput analysis of behaviour using real-time tracking on a distributed mesh of microcomputers (ethoscopes) with resource-lean statistical learning (HCTSA/Catch22). Coccinella is a reductionist system, yet outperforms state-of-the-art alternatives when exploring the pharmacobehaviour in <italic>Drosophila melanogaster</italic>.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>behaviour</kwd><kwd>fingerprinting</kwd><kwd>ethomics</kwd><kwd>open source</kwd><kwd>pharmacology</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>D. melanogaster</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000268</institution-id><institution>Biotechnology and Biological Sciences Research Council</institution></institution-wrap></funding-source><award-id>BB/M011178/1</award-id><principal-award-recipient><name><surname>Jones</surname><given-names>Hannah</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Coccinella, an open-source framework, combines real-time tracking on microcomputers with statistical learning, optimising behaviour analysis in <italic>Drosophila melanogaster</italic> while surpassing other advanced systems in throughput and performance.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The nervous system integrates stimuli, internal states, expectations, and previous experience to regulate behavioural output. Describing, quantifying, and modulating behaviour are critical aspects of modern neuroscience and, ever since its inception, the field has spent considerable effort into building and sharing paradigms or tools aimed at objectively and reproducibly quantify behaviours in the most disparate animal models, to the point that this exercise is now recognised as an exciting subfield of neuroscience in its own right: ethomics (<xref ref-type="bibr" rid="bib7">Brown and de Bivort, 2018</xref>; <xref ref-type="bibr" rid="bib9">Datta et al., 2019</xref>). As the portmanteau name itself suggests, ethomics is not just about describing behaviour (<italic>etho-</italic>) but also about doing so in a high-throughput fashion (<italic>-omics</italic>), collecting data simultaneously from a large number of individuals, which can remain undisturbed throughout recording. Irrespective of the behaviour or the animal model to be analysed, the first compromise a researcher will face when choosing a tool for behavioural quantification will always be between throughput and resolution: a high-throughput analysis will allow for powerful experimental manipulations – such as genetics or pharmacological screens – offering unbiased approaches in identifying neuronal circuits, genes, molecules underpinning behaviour; high-resolution analysis, on the other hand, promises to identify and discriminate even minuscule differences that may not be immediately visible to the human eye, and to label behaviours into identifiable classes (e.g. ‘grooming’, ‘courting’, and ‘shaking’) that may be more relevant to researchers interested in modelling disease or in anthropomorphic descriptions. In the past years, the field has generally converged towards the adoption of high-resolution video recording of activity, in some cases adopting cameras that have milliseconds temporal resolution or developing setups that provide depth information for three-dimensional reconstruction of motion or posture (<xref ref-type="bibr" rid="bib34">Wiltschko et al., 2015</xref>; <xref ref-type="bibr" rid="bib20">Hsu and Yttri, 2021</xref>; <xref ref-type="bibr" rid="bib27">Nath et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">Pereira et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Gosztolai et al., 2021</xref>). Given the recent evolution in machine learning and progresses in computational power, even these high-resolution analyses can be at least in part compatible with high-throughput approaches (<xref ref-type="bibr" rid="bib35">Wiltschko et al., 2020</xref>), especially when employed on small invertebrate animal models (<xref ref-type="bibr" rid="bib26">McDermott-Rouse et al., 2021</xref>; <xref ref-type="bibr" rid="bib3">Ayroles et al., 2015</xref>; <xref ref-type="bibr" rid="bib6">Branson et al., 2009</xref>; <xref ref-type="bibr" rid="bib22">Kabra et al., 2013</xref>) or when aided by robotic handling (<xref ref-type="bibr" rid="bib1">Alisch et al., 2018</xref>). These systems, however, can still be prohibitively expensive for most laboratories, and not easily compatible with throughput in the ‘<italic>omics</italic> scale. Moreover, besides the technical urge of removing entry barrier and make ethomics an accessible tool, an equally important underlying question concerns what is the minimal amount of information that needs to be extracted to identify and classify behaviour. Do we always necessarily gain information from extracting micro-postural features or by analysing activity in three dimensions? To what extent this may actually add counterproductive biological noise to some assays?</p><p>Here, we introduce <italic>coccinella</italic>: a new experimental framework that combines high-throughput, inexpensive, real-time ethomics (<xref ref-type="bibr" rid="bib14">Geissmann et al., 2017</xref>) with state-of-the-art statistical analysis (<xref ref-type="bibr" rid="bib13">Fulcher and Jones, 2017</xref>; <xref ref-type="bibr" rid="bib24">Lubba et al., 2019</xref>) to characterise and discriminate complex behaviours using a reductionist approach based solely on one simple feature (<ext-link ext-link-type="uri" xlink:href="https://lab.gilest.ro/coccinella">https://lab.gilest.ro/coccinella</ext-link>). <italic>Coccinella</italic> builds on ethoscopes (<xref ref-type="bibr" rid="bib14">Geissmann et al., 2017</xref>), an accessible open-source platform, to extract, in real-time, activity information from flies. Despite its minimalist nature, <italic>coccinella</italic> outperforms state-of-the-art alternatives in recognising the pharmacobehavioural space, providing better discernibility at a fraction of the cost, thus opening a new path to high-throughput ethomics.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p><italic>Drosophila</italic> ethomics studies generally rely on image acquisition through so-called industrial cameras, able to collect videos with high temporal and spatial resolution and featuring mounts for a large selection of lenses. Some of the cameras commonly used for these purposes (e.g. FLIR, Point Grey, Basler) (<xref ref-type="bibr" rid="bib25">Mathis et al., 2018</xref>) are expensive and normally employed in close-up imaging that microscopically highlights the smallest anatomical features of the animal but at the same time greatly limits the number of experimental subjects that can be recorded by a single device. Normally, one or few more camera would be connected to a dedicated powerful computer for acquisition and storage of videos. The cost and physical footprint of these setups makes them incompatible, at least for most laboratories, with high-throughput simultaneous acquisition. To lower this barrier, we created a framework that employs the distributing computing power of ethoscopes (<xref ref-type="bibr" rid="bib14">Geissmann et al., 2017</xref>), thus allowing for inexpensive analysis of activity in hundreds or thousands of flies at once. Ethoscopes are open source and can be manufactured by a skilled end-user at a cost of about £75 per machine, mostly building on two off-the-shelf component: a Raspberry Pi microcomputer and a Raspberry Pi NoIR camera overlooking a bespoke 3D-printed arena hosting freely moving flies. The temporal and spatial resolution of the collected images depends on the working modality the user chooses. When operating in offline mode, ethoscopes are capable to acquire 720p videos at 60 fps, which is a convenient option with fast moving animals. In this study, we instead opted for the default ethoscope working settings, providing online tracking and real-time parametric extraction, meaning that images are analysed by each Raspberry Pi at the very moment they are acquired (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). This latter modality limits the temporal resolution of information being processed (one frame every 444 ± 127 ms, equivalent to 2.2 fps on a Raspberry Pi3 at a resolution of 1280 × 960 pixels with each animal being constricted in an ellipse measuring 25.8 ± 1.4 × 9.85 ± 1.4 pixels – <xref ref-type="fig" rid="fig1">Figure 1a</xref>) but provides the most affordable and high-throughput solution, dispensing the researcher from organising video storage or asynchronous video processing for tracking the animals. In the work here described, flies moved freely in a circular two-dimensional space with a diameter of 11.5 mm designed to maintain the animal in the walking position (<xref ref-type="bibr" rid="bib32">Simon and Dickinson, 2010</xref>) while venturing on solidified agar providing nutrients alone or nutrients and drugs. In previous analysis of activity and sleep (<xref ref-type="bibr" rid="bib14">Geissmann et al., 2017</xref>; <xref ref-type="bibr" rid="bib15">Geissmann, 2018</xref>), we found that the maximal velocity of the fly over a period of 10 s best described the basic motion features of the animal, allowing us to accurately differentiate between different activity patterns, such as walking, grooming, and feeding (<xref ref-type="bibr" rid="bib14">Geissmann et al., 2017</xref>). We therefore adopted this measure for <italic>coccinella</italic> too, ultimately producing monodimensional time series of a behavioural correlate, which were then digested using highly comparative time-series analysis (HCTSA) (<xref ref-type="bibr" rid="bib13">Fulcher and Jones, 2017</xref>), a computational framework that effortlessly subjects time series to more than 7700 literature-relevant statistical tests, looking for meaningful discriminative features. Features successfully extracted through HCTSA were then used to classify behaviour using a linear support vector machine (SVM<sub>linear</sub>) (<xref ref-type="bibr" rid="bib8">Chatterjee et al., 2022</xref>; <xref ref-type="fig" rid="fig1">Figure 1b</xref>) and here presented and compared using confusion matrices (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a</xref>). To test the ability of this system to discriminate behaviour, we started by exploring the pharmacobehavioural space of flies fed with a panel of known or putative neurotropic chemicals, comprising molecules previously described in the literature along with uncharacterised ones being considered as potential insecticides (<xref ref-type="fig" rid="fig1">Figure 1c, d</xref> and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Using an initial panel of 17 treatments (16 drugs and 1 solvent control) we were able to discern compounds with an accuracy of 71.4% (vs. 5.8% of a random classifier – <xref ref-type="fig" rid="fig1">Figure 1c</xref>). Some compounds induced behaviours with a particularly high predictive fingerprint: dieldrin, for instance, was predicted with an accuracy of 94% and flonicamid with an accuracy of 87%. For others, our system fared more poorly (e.g. tetramethrin showed 41% accuracy). In all cases, however, the relative confusion was negligible, with all compounds being correctly identified as the first choice and with the first predicted compounds having, on average, a score that was 15 times greater compared to the second-best choices (<xref ref-type="fig" rid="fig1">Figure 1c</xref> – min.: 3.3×; max.: 65×). To validate our framework and exclude artefacts operated by overfitting biologically irrelevant information we followed two lines of control. Firstly, we fed flies with lower concentrations of the same compounds (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). Feeding flies with different concentrations of drugs unsurprisingly showed a different effect on short-term lethality (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1b</xref>), with several compounds hitting a 25% lethality rate before the end of the experiment when fed at the highest concentration (1000 ppm – <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1b</xref>). Lowering the compound concentration, the predictive accuracy of the system decreased from 71.4% (1000 ppm) to 61.8% (100 ppm), falling to 36.1% with the lowest concentrations (1 ppm), indicating that the system does operate on pharmacologically induced, biologically meaningful behavioural correlates (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). A similar drop in accuracy was observed using a smaller panel of 12 treatments (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c</xref>). As a second line of work to test specificity, we obtained genetic mutants known to be resistant to specific pharmacological treatments: the <italic>para<sup>L1029F</sup></italic> allele encodes for a version of the α-subunit of voltage-gated sodium channel conferring resistance to dichlorodiphenyltrichloroethane (DDT) and pyrethroids (<xref ref-type="bibr" rid="bib23">Kaduskar et al., 2022</xref>); the <italic>Rdl<sup>A301S</sup></italic> allele encodes for a version of the ligand-gated chloride channel conferring resistance to dieldrin and fiproles (<xref ref-type="bibr" rid="bib29">Remnant et al., 2014</xref>). Challenging these mutants with their respective compounds created confusion in the clustering algorithm for which discerning between drug treatment and solvent control became a harder task, especially in the case of DDT and <italic>para<sup>L1029F</sup></italic> (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2a</xref>). The observed drop in accuracy suggests again that <italic>coccinella</italic> is working on biologically relevant behavioural signatures and the fact that some discrimination can still be observed with targets harbouring point mutations – which should severely affect compound efficacy – is indicative of high sensitivity.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title><italic>Coccinella</italic> successfully classifies pharmacobehaviours.</title><p>(<bold>a</bold>) Bespoke 3D-printed arena can house 24 individual flies in a two-dimensional circular space. Each arena measures 11.5 mm in diameter and allows for back illumination either by visible or infrared light sources embedded in the ethoscope base. The red ellipse shows the data being extracted by the ethoscope in real time. <italic>w</italic>, <italic>h</italic>: width and height of the ellipse inscribing the animal. <italic>φ</italic>: the angle of the ellipse in reference to the region of interest. <italic>max. vel</italic>.: maximal velocity over the last 10 s. (<bold>b</bold>) Flowchart describing the analytical pipeline and the tools that compose <italic>coccinella</italic>. (<bold>c</bold>) Confusion matrices for treatments with 16 compounds and a solvent control, with drugs used at concentrations of 1000 ppm (left), 100 ppm (centre), and 1 ppm (right). The target icon indicates calculated accuracy while the rolling die indicate the accuracy of a random classifier. (<bold>d</bold>) Confusion matrix for the largest panel of 40 treatments at 100 ppm.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86695-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Successful classification of a smaller group of 11 compounds.</title><p>(<bold>a</bold>) Explanatory drawing of how confusion matrices present the data. The blue diagonal boxes indicate the number of flies correctly classified (true positives). The vertical cells indicate the number of flies wrongly classified (false positives). The horizontal cells indicate the number of flies that should have been classified (false negatives). (<bold>b</bold>) Survival curves upon treatment with a panel of 12 drugs administered at different concentrations, indicated above each figure (1, 100, and 1000 ppm). (<bold>c</bold>) Confusion matrices for treatments with 11 compounds and a solvent control, with drugs used at concentrations of 1000 ppm (left), 100 ppm (middle), and 1 ppm (right). The target icon indicates calculated accuracy. Accuracy of a random classifier would be 8.3%.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86695-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Effect of drug resistance conferring mutations on Coccinella's performance.</title><p>(<bold>a</bold>) Confusion matrix classifying the action of two selected drugs (Dichlorodiphenyltrichloroethane (DDT) 100 ppm and dieldrin 100 ppm) or solvent on wild-type flies (WT) or mutants with known resistance to those drugs. The LD100 of dieldrin is 0.1–1 ppm and the LD100 of DDT is 10–100 ppm. The three purple dotted boxes highlight the three experimental clusters (wild-type flies, <italic>para</italic> mutants, <italic>Rdl</italic> mutants).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86695-fig1-figsupp2-v1.tif"/></fig></fig-group><p>Having established the accuracy and sensitivity of the system, we next wanted to test its usefulness in a genuine high-throughput scenario. We subjected a total of 2192 flies to a panel of 40 treatments (<xref ref-type="fig" rid="fig1">Figure 1d</xref>), mostly featuring known compounds but also two unexplored molecules (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). Given that the 100 ppm intermediate concentrations showed the best compromise between accuracy and lethality in the previous pilot experiment (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1b</xref>), we performed this larger screen using compounds diluted at 100 ppm only. Even with such a large panel, the system was able to first-guess 39 out of 40 of the tested treatments (the only exception being the Syngenta Compound #5) with an overall accuracy of 44.5% vs. 2.5% of the random classifier.</p><p>A reductionist approach served us well so far, identifying with remarkable accuracy even subtle changes when we explored the pharmacobehavioural space of a large number of neuroactive compounds in wild-type and mutant flies. But how does it compare to other more established paradigms? <italic>Coccinella</italic> is arguably to be preferred in terms of accessibility and throughput, but what is the amount of useful information that we are sacrificing by adopting a reductionist approach? To quantify any possible loss in information content, we ran a series of parallel experiments in which flies were fed with a selected panel of 12 treatments (11 drugs and a solvent control, <xref ref-type="fig" rid="fig2">Figure 2</xref>) and their behaviour analysed either using <italic>coccinella</italic> or using other widely adopted state-of-the-art methods, which started with high-resolution imaging and employed supervised machine learning for pose-estimation DeepLabCut; <xref ref-type="bibr" rid="bib25">Mathis et al., 2018</xref> followed by unsupervised identification of behavioural grammar (B-SOiD; <xref ref-type="bibr" rid="bib20">Hsu and Yttri, 2021</xref>). To widen the range of comparisons, data were then either immediately clustered using different common clustering algorithms (<italic>K</italic>-nearest neighbours, random forest) or first processed through a smaller, selected subsample of the HCTSA array (Catch22; <xref ref-type="bibr" rid="bib24">Lubba et al., 2019</xref>) before being clustered using SVM<sub>linear</sub> (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). In this challenge, <italic>coccinella</italic> unambiguously identified 10 out of 12 compounds, with poor performance only for two of them (flubendiamide and tetramethrin) and an overall accuracy of 42.4% vs. 8.3% of the random classifier (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). Surprisingly, none of the state-of-the-art high-resolution paths did better than this. The combination of pose-estimation → grammar extraction → random forest classification scored as the second best, with an accuracy of 25.4% but with only three compounds being unambiguously identified (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). The same experimental dataset clustered with even poorer performance when using <italic>K</italic>-nearest neighbours (<xref ref-type="fig" rid="fig2">Figure 2e</xref>) and even the application of HCTSA features extraction to the B-SoID output still could not match the accuracy observed with <italic>coccinella</italic>’s reductionist approach (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). This analysis is not meant to be conclusive. We expect that some alternative combination of state-of-the-art approaches will probably manage to match or likely improve over <italic>coccinella</italic>’s performance, yet the fact we could obtain such an impressive result with a system that is arguably unmatched in terms of throughput and economic cost is, alone, an argument that gives new weight to this (and future) reductionist approaches.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Comparison between <italic>coccinella</italic> and the state-of-the-art.</title><p>(<bold>a</bold>) Experimental pipeline illustrating the four experimental analyses. (<bold>b</bold>) Confusion matrix for 12 treatments (11 drugs at 1000 ppm and 1 solvent control) analysed using <italic>coccinella</italic>. (<bold>c</bold>) Same experimental treatments as in b, analysed using the DeepLabCut → B-SoID → random forest pipeline starting from high-resolution images. The random forest classifier was trained on a 4:1 training:testing ratio. (<bold>d</bold>) Same as c but with Catch22 identification and support vector machine (SVM) clustering after B-SoID grammar dissection. This is a hybrid treatment combining highly comparative time-series analysis (HCTSA) feature extraction to the high-resolution pipeline. (<bold>e</bold>) Same as c but using <italic>K</italic>-nearest neighbours (KNN) as cluster algorithm. KNN required a much higher training:testing ratio of 9:1, dramatically reducing the size of the testing dataset. The accuracy of a random classifier for all matrices on this figure would be 8.3% (not shown on figures for lack of space).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86695-fig2-v1.tif"/></fig><p>Finally, to push the system to its limit, we asked <italic>coccinella</italic> to find qualitative differences not in pharmacologically induced changes in activity, but in a type of spontaneous behaviour mostly characterised by lack of movement: sleep. In particular, we wondered whether <italic>coccinella</italic> could provide biological insights comparing conditions of sleep rebound observed after different regimes of sleep deprivation. <italic>Drosophila melanogaster</italic> is known to show a strong, conserved homeostatic regulation of sleep that forces flies to recover at least in part lost sleep, for instance after a night of forceful sleep deprivation (<xref ref-type="bibr" rid="bib31">Shaw et al., 2000</xref>; <xref ref-type="bibr" rid="bib19">Hendricks et al., 2000</xref>). We previously showed that the extent of sleep rebound observed after sleep deprivation only loosely correlates with the amount of lost sleep (<xref ref-type="bibr" rid="bib16">Geissmann et al., 2019a</xref>) and it remains an open question whether similar amounts of sleep rebound may in fact differ from each other in some inscrutable feature that would underpin a different ‘sleep depth’ (<xref ref-type="bibr" rid="bib33">Wiggin et al., 2020</xref>; <xref ref-type="bibr" rid="bib12">French et al., 2021</xref>), similar to what it is believed to happen in mammals. Here, we analysed a dataset of 727 flies that experienced different regimes of mechanically enforced sleep deprivation during the 12 hr of the night (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Flies were housed in tubes that would rotate after a set time of inactivity ranging from 20 to 1000 s leading to different degrees of sleep restriction (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, dataset from <xref ref-type="bibr" rid="bib16">Geissmann et al., 2019a</xref>). In this experimental paradigm, all treatments led to a statistically significant rebound compared to the undisturbed control animals (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). We then ran <italic>coccinella</italic> on the two subsets of the panel: the baseline data, acquired the morning before the sleep deprivation (<xref ref-type="fig" rid="fig3">Figure 3c</xref>), and the rebound data, on the morning after (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). Unsurprisingly, we could not detect any internal biological difference in the pre sleep deprivation control set, featuring flies of identical genotype and age housed in different tubes before the sleep deprivation treatment. In these conditions, <italic>coccinella</italic> could not discern, and performed exactly as a random classifier would (9% vs. 9% – <xref ref-type="fig" rid="fig3">Figure 3c</xref>). However, analysis of those same animals during rebound after sleep deprivation showed a clear clustering, segregating the samples in two subsets with separation around the 300 s inactivity trigger (<xref ref-type="fig" rid="fig3">Figure 3d</xref>). This result is important for two reasons: on one hand, it provides, for the third time, strong evidence that the system is not simply overfitting data of nought biological significance, given that it could not perform any better than a random classifier on the baseline control. On the other hand, <italic>coccinella</italic> could find biologically relevant differences on rebound data after different regimes of sleep deprivation. Interestingly enough, the 300 s threshold that <italic>coccinella</italic> independently identified has a deep intrinsic significance for the field, for it is considered to be the threshold beyond which flies lose arousal response to external stimuli, defining a ‘sleep quantum’ (i.e. the minimum amount of time required for transforming inactivity bouts into sleep bouts; <xref ref-type="bibr" rid="bib31">Shaw et al., 2000</xref>; <xref ref-type="bibr" rid="bib19">Hendricks et al., 2000</xref>; <xref ref-type="bibr" rid="bib21">Joyce et al., 2023</xref>). Coccinella’s analysis ran agnostic of the arbitrary 5 min threshold and yet identified the same value as the one able to segregate the two clusters, thus providing an independent confirmation of the 5-min rule in <italic>D. melanogaster</italic>.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title><italic>Coccinella</italic> finds differences in type of sleep rebound after sleep deprivation.</title><p>(<bold>a</bold>) Sleep profile of flies over the period of 3 days. A 12-hr sleep deprivation regime starts at the beginning of the dark phase of day 0 (purple bar). The 3-hr windows labelled with green boxes were analysed by <italic>coccinella</italic> in search of meaningful differences. The letters above refer to the panels using data in those time windows. (<bold>b</bold>) Extent of rebound as observed following sleep deprivation as performed in a. Panels a and b reproduce data from <xref ref-type="bibr" rid="bib16">Geissmann et al., 2019a</xref>. (<bold>c</bold>) Confusion matrix showing the classification using <italic>coccinella</italic> of the baseline time series. No accuracy gain compared to the random classifier. (<bold>d</bold>) Confusion matrix of the rebound data. The classification finds two clusters, separated by the 300 s threshold (thick black lines).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-86695-fig3-v1.tif"/></fig></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>System neuroscience is living a period of renaissance, and <italic>Drosophila</italic> is driving this revolution strong of the first full-brain connectome, a plethora of new genetic reagents that allow thermo- and opto-genetic manipulations, a galore of genetic transformants for circuit tracking and manipulation, and multiple tools for large-scale quantification of behaviour. Progresses in machine learning and computer power have had a massive impact on the field of ethomics, especially in achieving levels of anatomical tracking that allow mapping of the tiniest movements on an experimental animal model with the highest temporal resolution and with little human supervision (<xref ref-type="bibr" rid="bib28">Pereira et al., 2019</xref>; <xref ref-type="bibr" rid="bib25">Mathis et al., 2018</xref>). Most of these systems, however, rely on relatively expensive setups and do not scale easily to high-throughput experimental paradigms. They are ideal – and irreplaceable – to identify behavioural patterns and study fine motor control but may be undue for other uses. Here, we introduce a new framework, <italic>coccinella</italic>, that merges an open-source, economically accessible hardware platform (ethoscopes; <xref ref-type="bibr" rid="bib14">Geissmann et al., 2017</xref>; <xref ref-type="bibr" rid="bib17">Geissmann et al., 2019b</xref>) with a powerful toolbox for statistical analysis and clustering (HCTSA, <xref ref-type="bibr" rid="bib13">Fulcher and Jones, 2017</xref>/Catch22, <xref ref-type="bibr" rid="bib24">Lubba et al., 2019</xref>). <italic>Coccinella</italic> is a reductionist tool, not meant to replace the behavioural categorisation that other tools can offer but to complement it. It relies on Raspberry PIs as main acquisition devices, with associated advantages and limitations. Ethoscopes are inexpensive and versatile but are limited in terms of computing power and acquisition rates. Their online acquisition speed is fast enough to successfully capture the motor activity of different species of <italic>Drosophilae</italic> (<xref ref-type="bibr" rid="bib21">Joyce et al., 2023</xref>), but may not be sufficient for other animals moving more swiftly, such as zebrafish larvae. Moreover, <italic>coccinella</italic> cannot – and is not meant to – apply labels to behaviour (‘courting’, ‘lounging’, ‘sipping’, ‘jumping’, etc.) but it can successfully identify large behavioural phenotypes and generate unbiased hypothesis on how behaviour, and a nervous system at large, can be influenced by chemicals, genetics, artificial manipulations in general. Here, we provided evidence that <italic>coccinella</italic> can be used to successfully explore and compartmentalise the pharmacobehavioural space and also showed that a reductionist approach can be employed to discern otherwise invisible shades of a very subtle naturally occurring behaviour: sleep. The success of <italic>Drosophila</italic> as experimental model was built on the many genetic screens of the 1900s. We propose <italic>coccinella</italic> as an accessible, pivotal tool to boost again this important line of work in any laboratory, without funding or access to technology being a discriminative factor.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title><italic>Drosophila</italic> rearing</title><p>Fly lines were maintained on a 12-hr light:12-hr dark (LD) cycle and raised on polenta and yeast-based fly media (agar 96 g, polenta 240 g, fructose 960 g, and Brewer’s yeast 1200 g in 12 l of water). Canton-Special (CS) <italic>D. melanogaster</italic> were used as the wild-type line for all experiments.</p></sec><sec id="s4-2"><title>Drug-resistant mutants</title><p><italic>Rdl<sup>A301S</sup></italic> is derived from <italic>Rdl<sup>MDRR</sup></italic> (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_1675">BDSC_1675</ext-link>), an <italic>Rdl</italic> allele isolated from a natural population in Maryland (<xref ref-type="bibr" rid="bib11">Ffrench-Constant et al., 1990</xref>), and underwent isogenisation and selection on dieldrin to eliminate the metabolic resistance and maintain the dieldrin target site resistance (<xref ref-type="bibr" rid="bib5">Blythe et al., 2022</xref>). The <italic>Rdl</italic><sup>MDRR</sup> was obtained from the Bloomington <italic>Drosophila</italic> Stock Center. For <italic>para</italic>: the L1029F mutation, located in the voltage-gated sodium channel paralytic, has been extensively reported to confer resistance to DDT and pyrethroids in many other insect species (called kdr, knockdown resistance, reviewed in <xref ref-type="bibr" rid="bib2">Arena et al., 1992</xref>). In the <italic>Drosophila</italic> gene, kdr maps to L1029F and is equivalent to the often cited L1014F in other insects (e.g. <italic>Musca domestica</italic>; <xref ref-type="bibr" rid="bib10">Dong, 2007</xref>). The kdr L1029F mutation in <italic>Drosophila</italic> Para was introduced via CRISPR/Cas9-mediated genome editing (see below). This genome edited generated mutation resulted in a similar resistance to DDT as previously reported (<xref ref-type="bibr" rid="bib30">Samantsidis et al., 2020</xref>).</p></sec><sec id="s4-3"><title>Generation of Para<sup>L1029F</sup> via CRISPR-CAS9-based genome editing</title><p>CRISPR/Cas9-mediated genome editing was used to introduce a point mutation L1029F in para-PBG isoform, CTT to TTT, L to F by homology-dependent repair using one guide RNA and a dsDNA plasmid donor. The strategy design, molecular biology, and screening were completed by Well Genetics Inc, Taiwan (R.O.C.). The cassette PBacDsRed contains Piggy Bac 3′ terminal repeats, the selection marker 3xP3-DsRed, and Piggy Bac 5′ terminal repeats. The selection marker 3xP3-DsRed contains Piggy Bac 3′ terminal repeats, 3x Pax3 and hsp70 promoter, DsRed2, SV40 3′UTR, and Piggy Bac 5′ terminal repeats. The dsRed marker facilitates the genetic screening and was excised by Piggy Bac transposase. Only one TTAA motif was left after transposition embedded in mutated intron sequence, and create a mutation G to A on X:16,486,649; X:16,486,649–X:16,486,646, CTAA to T TAA in intron. The CRISPR Target Site [PAM]: <named-content content-type="sequence">CACAAGATTGCCGATGACAA</named-content>[CGG]. Guide RNA Primers: Sense oligo5′-<named-content content-type="sequence">CTTCGCACAAGATTGCCGATGACAA</named-content> and Antisense oligo5′-<named-content content-type="sequence">AAACTTGTCATCGGCAATCTTGTGC</named-content>. Upstream Homology Arm: 1027 bp, the +34,097 nt to +35,123 nt from ATG of para. Forward Oligo5′-<named-content content-type="sequence">GTTCACCAAACTCGGAATCG</named-content>; Reverse Oligo5′-<named-content content-type="sequence">GTGGCCAAGAAGAAGGGAAT</named-content>. Downstream Homology Arm: 1022 bp, the +35,128 nt to +36,149 nt from ATG of para Forward Oligo: 5′-<named-content content-type="sequence">CCATGGCTTTAAGCATCGCA</named-content>; Reverse Oligo: 5′-<named-content content-type="sequence">TTATGACGGATACGGTTACGG</named-content>. Synthesis fragment: 5′- <named-content content-type="sequence">GGTTGTCATCGGCAATTTTGTGgtgagtactcttatcgaactgctgacttgtaaacgatgtttactggctataatgctgacttatcgcct</named-content>.</p><p>The <italic>Drosophila</italic> injection strain was <italic>white</italic><sup>1118</sup>. 206 embryos were injected. 36 G0 crosses were established. Of the 78 positive lines crosses, in the F1 screen 25 positive lines were identified. Seven lines were positively validated by PCR and 1 line was sequenced confirming no unexpected changes in <italic>para</italic>. Lines were isogenised and balanced. DsRed was excised using PiggyBac (PBac) Transposase Bloomington Stock RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:BDSC_8285">BDSC_8285</ext-link>. Excision was validated by genomic PCR and sequencing. Resulting lines were hemizygous viable. The line used in study had internal identifier: 20256ex1.</p></sec><sec id="s4-4"><title>Choice, handling, and preparation of drugs</title><p>The initial preliminary analysis was conducted using a group of 12 compounds ‘proof of principle’ compounds and a solvent control. These compounds were initially used to compare both the video method and ethoscope method. After testing these initial compounds, it was found that the ethoscope methodology was more successful, and then the compound list was expanded to 17 (including the control) only using the ethoscope method. As a final test, we included additional compounds for a single concentration, bringing up the total to 40 (including control), also for the ethoscope method. All insecticide compounds were supplied by Syngenta Ltd from their in-house stock (see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for a full list of compounds used). Compounds were received in solid form and diluted in solvent containing 5% ethanol (VWR, 20821), 5% acetone (Sigma, 179124), and 10% dimethylsulfoxide (D2650, Sigma) in distilled water to 1000 ppm initially, then further diluted in the solvent mixture to 100 and 1 ppm (where 1 ml/l = 1000 ppm). For insecticide assays, 0.5 ml of 5% sucrose (Sigma, S0389), 1% agarose (Sigma, A6236) solution was pipetted into each well and allowed to set. Following this, 2 µl of compound solution were placed on the surface and allowed to dry for 30 min or more. Male flies were then placed on the surface with a small glass cover slip placed on top (13 mm circular cover slip, VWR631-0150). Flies were briefly anaesthetised (&gt;1 min) before being placed onto the surface of the plate. Once each well had been filled with a single male fly, arenas were placed into the ethoscope and recorded for a minimum of 2 days. All experiments were started between ZT0 and ZT1 and within 30 min of the flies being placed in the wells. For each compound in <xref ref-type="fig" rid="fig1">Figure 1c</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c</xref>, three repeats were done at different time points. For <xref ref-type="fig" rid="fig1">Figure 1d</xref>, two repeats to three biological repeats per compound.</p></sec><sec id="s4-5"><title>Data acquisition and processing</title><p>Ethoscope data were first processed in R using rethomics (<xref ref-type="bibr" rid="bib17">Geissmann et al., 2019b</xref>). Each time series was exported (.csv) and converted using Python to individual time series in a file format (.dat) compatible with MatLab. A metadata (.txt) file served as a reference file of each individual time series with keywords outlining compound groups and concentrations for processing data using HCTSA.</p></sec><sec id="s4-6"><title>HCTSA/Catch22</title><p>Following this process, HCTSA feature extraction was performed on the time-series data (for <xref ref-type="fig" rid="fig1">Figure 1c, d</xref> and <xref ref-type="fig" rid="fig3">Figure 3c, d</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplements 1</xref> and <xref ref-type="fig" rid="fig1s2">2a</xref>). After the features were extracted, outputs of error-producing operations were removed through a normalisation process using a sigmoidal transformation. HCTSA inbuilt functions were then used to classify data using a linear SVM classifier and a confusion matrix comparing the time series was generated. For some of the time-series data (that in <xref ref-type="fig" rid="fig2">Figure 2b, d</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2b</xref>), a smaller feature set of HCTSA, Catch-22 was used for feature extraction. Due to the smaller number of features used with this method, normalisation was not required before using a linear SVM classifier to generate a confusion matrix comparing the results. A time series of 12 hr was used for the HCTSA analysis in <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplements 1</xref> and <xref ref-type="fig" rid="fig1s2">2</xref>. A length of 3 hr was used for the HCTSA analysis in <xref ref-type="fig" rid="fig3">Figure 3</xref>. All video data in <xref ref-type="fig" rid="fig2">Figure 2</xref> are from time series of 15 min. By always running the full set of features on aggregate to train a classifier (e.g. TS_Classify in HCTSA), no post hoc correction is necessary because the trained classifier only ever makes a single prediction (only one test is performed).</p></sec><sec id="s4-7"><title>Video generation for flies on insecticides</title><p>Custom 3D-printed squares were designed using the online CAD software Onshape and printed using Ultimaker 2+ 3D printers using PLA plastic. For insecticide assays, 0.5 ml of 5% sucrose (Sigma, S0389), 1% agarose (Sigma, A6236) solution was pipetted into each well and allowed to set. Following this, 2 µl of compound solution were placed on the surface and allowed to dry for 30 min or more before male flies were placed on the surface with a small glass cover slip placed on top (13 mm circular cover slip, VWR631-0150). Flies were briefly anaesthetised (&gt;1 min) before being placed onto the surface of the square. Once each well had been filled with a single male fly, squares were placed in the arena and a video was recorded for a minimum of 12 hr using an ELP 8 megapixel camera with an IMX179 Sensor and 2.8–12 mm variable focus manual lens. All video recordings were started between ZT0 and ZT1. Recordings of flies exposed to compounds were done in a randomised manner. Video data were then broken down into shorter segments of 15 min videos for processing. The first 15 min following 1 hr of fly exposure to compound or control was used for pose-extraction.</p></sec><sec id="s4-8"><title>DeepLabCut/B-SoID</title><p>The use of DeepLabCut (version 2.1) followed the detailed protocol outlined by <xref ref-type="bibr" rid="bib27">Nath et al., 2019</xref>. Briefly, frames for labelling were extracted from 3 representative videos using a <italic>K</italic>-means algorithm and frames were labelled with 22 unique body parts (head, left eye, right eye, thorax top, thorax bottom, abdomen top, abdomen middle, abdomen bottom, left wing tip, right wing tip, left foreleg tip, left foreleg middle, right foreleg tip, right foreleg middle, left middle leg tip, left middle leg middle, right middle leg tip, right middle leg middle, left back leg tip, left back leg middle, right back leg tip, and right back leg middle). These frames were labelled locally with a DeepLabCut graphical user interface before the project file was uploaded to Google Drive for training and video analysis to be done using Google Colab. The data were split into a 9:1 test:train dataset and training was run for more than 150,000 iterations before the average Euclidean error was computed between labels and predictions. The model at the best performing checkpoint was used to predict pose in novel videos. Following this, B-SoID was used to de-structure behaviour using the output of DeepLabCut and generate fly-specific time series of behavioural grammar as in <xref ref-type="bibr" rid="bib20">Hsu and Yttri, 2021</xref>.</p></sec><sec id="s4-9"><title>Sleep deprivation</title><p>Maximal velocity time-series data generated from recording flies exposed to either control conditions (no SD) or incrementally increasing immobility-triggered SD conditions were taken from the dataset generated by <xref ref-type="bibr" rid="bib16">Geissmann et al., 2019a</xref> and analysed as above. Only data for female flies were included in this study, limiting to a sample of 60 individuals per experimental group. Wherever experimental groups consisted of more than 60 individuals, 60 individual flies were randomly chosen.</p></sec><sec id="s4-10"><title>Survival</title><p>Flies were fed with the specified compounds at the desired concentrations and concomitantly analysed in ethoscopes for 24 hr. Time of death was calculated as the last moment of detected motion.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Investigation, Methodology, Project administration</p></fn><fn fn-type="con" id="con2"><p>Resources, Validation</p></fn><fn fn-type="con" id="con3"><p>Resources, Validation</p></fn><fn fn-type="con" id="con4"><p>Methodology</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Table listing of all the compounds used in this study, each with its relative bibliographic reference.</title></caption><media xlink:href="elife-86695-supp1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Two Jupyter notebooks guiding the user through the integration of ethoscope data with highly comparative time-series analysis (HCTSA; notebook 1) and Catch22 (notebook 2).</title></caption><media xlink:href="elife-86695-supp2-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-86695-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>A notebook version of the source code used to generate all figures is available on the Zenodo public repository, along with all the metadata and the raw data collected in this study (DOIs: 10.5281/zenodo.7335575 and 10.5281/zenodo.7393689). Data were analysed using rethomics (<xref ref-type="bibr" rid="bib17">Geissmann et al., 2019b</xref>) and ethoscopy (<xref ref-type="bibr" rid="bib4">Blackhurst et al., 2023</xref>). Two notebooks showing how to use the system for multiple uses are provided in <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>.</p><p>The following datasets were generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>H</given-names></name><name><surname>Gilestro</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>A reductionist paradigm for high-throughput behavioural fingerprinting in <italic>Drosophila melanogaster</italic> - DATASET 1 of 2</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.7335575</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset2"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>H</given-names></name><name><surname>Gilestro</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>A reductionist paradigm for high-throughput behavioural fingerprinting in <italic>Drosophila melanogaster</italic> - DATASET 2 of 2</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.7393689</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank the Gilestro lab at Imperial College London and Robert Lind at Syngenta for useful discussions. Special thanks to Laurence Blackhurst for compiling the catch22 notebooks. HJ was supported by a BBSRC/CASE studentship in partnership with Syngenta (project reference BB/M011178/1/1958700). Stocks obtained from the Bloomington <italic>Drosophila</italic> Stock Center (NIH P40OD018537) were used in this study.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alisch</surname><given-names>T</given-names></name><name><surname>Crall</surname><given-names>JD</given-names></name><name><surname>Kao</surname><given-names>AB</given-names></name><name><surname>Zucker</surname><given-names>D</given-names></name><name><surname>de Bivort</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>MAPLE (modular automated platform for large-scale experiments), a robot for integrated organism-handling and phenotyping</article-title><source>eLife</source><volume>7</volume><elocation-id>e37166</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.37166</pub-id><pub-id pub-id-type="pmid">30117804</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arena</surname><given-names>JP</given-names></name><name><surname>Liu</surname><given-names>KK</given-names></name><name><surname>Paress</surname><given-names>PS</given-names></name><name><surname>Schaeffer</surname><given-names>JM</given-names></name><name><surname>Cully</surname><given-names>DF</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Expression of a glutamate-activated chloride current in <italic>Xenopus</italic> oocytes injected with <italic>Caenorhabditis elegans</italic> RNA: evidence for modulation by avermectin</article-title><source>Brain Research. Molecular Brain Research</source><volume>15</volume><fpage>339</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/0169-328x(92)90127-w</pub-id><pub-id pub-id-type="pmid">1279355</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayroles</surname><given-names>JF</given-names></name><name><surname>Buchanan</surname><given-names>SM</given-names></name><name><surname>O’Leary</surname><given-names>C</given-names></name><name><surname>Skutt-Kakaria</surname><given-names>K</given-names></name><name><surname>Grenier</surname><given-names>JK</given-names></name><name><surname>Clark</surname><given-names>AG</given-names></name><name><surname>Hartl</surname><given-names>DL</given-names></name><name><surname>de Bivort</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Behavioral idiosyncrasy reveals genetic control of phenotypic variability</article-title><source>PNAS</source><volume>112</volume><fpage>6706</fpage><lpage>6711</lpage><pub-id pub-id-type="doi">10.1073/pnas.1503830112</pub-id><pub-id pub-id-type="pmid">25953335</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackhurst</surname><given-names>L</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name><name><surname>Yu</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Ethoscopy and ethoscope-lab: a framework for behavioural analysis to lower entrance barrier and aid reproducibility</article-title><source>Bioinformatics Advances</source><volume>3</volume><elocation-id>vbad132</elocation-id><pub-id pub-id-type="doi">10.1093/bioadv/vbad132</pub-id><pub-id pub-id-type="pmid">37818176</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blythe</surname><given-names>J</given-names></name><name><surname>Earley</surname><given-names>FGP</given-names></name><name><surname>Piekarska-Hack</surname><given-names>K</given-names></name><name><surname>Firth</surname><given-names>L</given-names></name><name><surname>Bristow</surname><given-names>J</given-names></name><name><surname>Hirst</surname><given-names>EA</given-names></name><name><surname>Goodchild</surname><given-names>JA</given-names></name><name><surname>Hillesheim</surname><given-names>E</given-names></name><name><surname>Crossthwaite</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The mode of action of isocycloseram: A novel isoxazoline insecticide</article-title><source>Pesticide Biochemistry and Physiology</source><volume>187</volume><elocation-id>105217</elocation-id><pub-id pub-id-type="doi">10.1016/j.pestbp.2022.105217</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Bender</surname><given-names>J</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>High-throughput ethomics in large groups of <italic>Drosophila</italic></article-title><source>Nature Methods</source><volume>6</volume><fpage>451</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1328</pub-id><pub-id pub-id-type="pmid">19412169</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>AEX</given-names></name><name><surname>de Bivort</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Ethology as a physical science</article-title><source>Nature Physics</source><volume>14</volume><fpage>653</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1038/s41567-018-0093-0</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chatterjee</surname><given-names>S</given-names></name><name><surname>Dey</surname><given-names>D</given-names></name><name><surname>Munshi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><chapter-title>Chapter 4 - feature selection and classification</chapter-title><person-group person-group-type="editor"><name><surname>Chatterjee</surname><given-names>S</given-names></name><name><surname>Dey</surname><given-names>D</given-names></name><name><surname>Munshi</surname><given-names>S</given-names></name></person-group><source>Recent Trends in Computer-Aided Diagnostic Systems for Skin Diseases</source><publisher-name>Academic Press</publisher-name><fpage>95</fpage><lpage>135</lpage><pub-id pub-id-type="doi">10.1016/B978-0-323-91211-2.00001-9</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname><given-names>SR</given-names></name><name><surname>Anderson</surname><given-names>DJ</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Leifer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Computational neuroethology: A call to action</article-title><source>Neuron</source><volume>104</volume><fpage>11</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.038</pub-id><pub-id pub-id-type="pmid">31600508</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Insect sodium channels and insecticide resistance</article-title><source>Invertebrate Neuroscience</source><volume>7</volume><fpage>17</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1007/s10158-006-0036-9</pub-id><pub-id pub-id-type="pmid">17206406</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ffrench-Constant</surname><given-names>RH</given-names></name><name><surname>Roush</surname><given-names>RT</given-names></name><name><surname>Mortlock</surname><given-names>D</given-names></name><name><surname>Dively</surname><given-names>GP</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Isolation of dieldrin resistance from field populations of <italic>Drosophila melanogaster</italic> (Diptera: Drosophilidae)</article-title><source>Journal of Economic Entomology</source><volume>83</volume><fpage>1733</fpage><lpage>1737</lpage><pub-id pub-id-type="doi">10.1093/jee/83.5.1733</pub-id><pub-id pub-id-type="pmid">2124226</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>French</surname><given-names>AS</given-names></name><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Sensory processing during sleep in <italic>Drosophila melanogaster</italic></article-title><source>Nature</source><volume>598</volume><fpage>479</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03954-w</pub-id><pub-id pub-id-type="pmid">34588694</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Jones</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>hctsa: A computational framework for automated time-series phenotyping using massive feature extraction</article-title><source>Cell Systems</source><volume>5</volume><fpage>527</fpage><lpage>531</lpage><pub-id pub-id-type="doi">10.1016/j.cels.2017.10.001</pub-id><pub-id pub-id-type="pmid">29102608</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Garcia Rodriguez</surname><given-names>L</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>French</surname><given-names>AS</given-names></name><name><surname>Jamasb</surname><given-names>AR</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ethoscopes: An open platform for high-throughput ethomics</article-title><source>PLOS Biology</source><volume>15</volume><elocation-id>e2003026</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.2003026</pub-id><pub-id pub-id-type="pmid">29049280</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>High-Throughput Recording, Analysis and Manipulation of Sleep in Drosophila</source><publisher-name>Imperial College London Press</publisher-name><pub-id pub-id-type="doi">10.25560/69514</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>Most sleep does not serve a vital function: Evidence from <italic>Drosophila melanogaster</italic></article-title><source>Science Advances</source><volume>5</volume><elocation-id>eaau9253</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aau9253</pub-id><pub-id pub-id-type="pmid">30801012</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geissmann</surname><given-names>Q</given-names></name><name><surname>Garcia Rodriguez</surname><given-names>L</given-names></name><name><surname>Beckwith</surname><given-names>EJ</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>Rethomics: An R framework to analyse high-throughput behavioural data</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0209331</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0209331</pub-id><pub-id pub-id-type="pmid">30650089</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gosztolai</surname><given-names>A</given-names></name><name><surname>Günel</surname><given-names>S</given-names></name><name><surname>Lobato-Ríos</surname><given-names>V</given-names></name><name><surname>Pietro Abrate</surname><given-names>M</given-names></name><name><surname>Morales</surname><given-names>D</given-names></name><name><surname>Rhodin</surname><given-names>H</given-names></name><name><surname>Fua</surname><given-names>P</given-names></name><name><surname>Ramdya</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>LiftPose3D, a deep learning-based approach for transforming two-dimensional to three-dimensional poses in laboratory animals</article-title><source>Nature Methods</source><volume>18</volume><fpage>975</fpage><lpage>981</lpage><pub-id pub-id-type="doi">10.1038/s41592-021-01226-z</pub-id><pub-id pub-id-type="pmid">34354294</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hendricks</surname><given-names>JC</given-names></name><name><surname>Finn</surname><given-names>SM</given-names></name><name><surname>Panckeri</surname><given-names>KA</given-names></name><name><surname>Chavkin</surname><given-names>J</given-names></name><name><surname>Williams</surname><given-names>JA</given-names></name><name><surname>Sehgal</surname><given-names>A</given-names></name><name><surname>Pack</surname><given-names>AI</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Rest in <italic>Drosophila</italic> is a sleep-like state</article-title><source>Neuron</source><volume>25</volume><fpage>129</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)80877-6</pub-id><pub-id pub-id-type="pmid">10707978</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>AI</given-names></name><name><surname>Yttri</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>B-SOiD, an open-source unsupervised algorithm for identification and fast prediction of behaviors</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>5188</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-25420-x</pub-id><pub-id pub-id-type="pmid">34465784</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Joyce</surname><given-names>M</given-names></name><name><surname>Falconio</surname><given-names>FA</given-names></name><name><surname>Blackhurst</surname><given-names>L</given-names></name><name><surname>Prieto-Godino</surname><given-names>L</given-names></name><name><surname>French</surname><given-names>AS</given-names></name><name><surname>Gilestro</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Divergent Evolution of Sleep Functions</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.05.27.541573</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kabra</surname><given-names>M</given-names></name><name><surname>Robie</surname><given-names>AA</given-names></name><name><surname>Rivera-Alba</surname><given-names>M</given-names></name><name><surname>Branson</surname><given-names>S</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>JAABA: interactive machine learning for automatic annotation of animal behavior</article-title><source>Nature Methods</source><volume>10</volume><fpage>64</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2281</pub-id><pub-id pub-id-type="pmid">23202433</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaduskar</surname><given-names>B</given-names></name><name><surname>Kushwah</surname><given-names>RBS</given-names></name><name><surname>Auradkar</surname><given-names>A</given-names></name><name><surname>Guichard</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Bennett</surname><given-names>JB</given-names></name><name><surname>Julio</surname><given-names>AHF</given-names></name><name><surname>Marshall</surname><given-names>JM</given-names></name><name><surname>Montell</surname><given-names>C</given-names></name><name><surname>Bier</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Reversing insecticide resistance with allelic-drive in <italic>Drosophila melanogaster</italic></article-title><source>Nature Communications</source><volume>13</volume><elocation-id>291</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-27654-1</pub-id><pub-id pub-id-type="pmid">35022402</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lubba</surname><given-names>CH</given-names></name><name><surname>Sethi</surname><given-names>SS</given-names></name><name><surname>Knaute</surname><given-names>P</given-names></name><name><surname>Schultz</surname><given-names>SR</given-names></name><name><surname>Fulcher</surname><given-names>BD</given-names></name><name><surname>Jones</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>catch22: CAnonical Time-series CHaracteristics</article-title><source>Data Mining and Knowledge Discovery</source><volume>33</volume><fpage>1821</fpage><lpage>1852</lpage><pub-id pub-id-type="doi">10.1007/s10618-019-00647-x</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott-Rouse</surname><given-names>A</given-names></name><name><surname>Minga</surname><given-names>E</given-names></name><name><surname>Barlow</surname><given-names>I</given-names></name><name><surname>Feriani</surname><given-names>L</given-names></name><name><surname>Harlow</surname><given-names>PH</given-names></name><name><surname>Flemming</surname><given-names>AJ</given-names></name><name><surname>Brown</surname><given-names>AEX</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Behavioral fingerprints predict insecticide and anthelmintic mode of action</article-title><source>Molecular Systems Biology</source><volume>17</volume><elocation-id>e10267</elocation-id><pub-id pub-id-type="doi">10.15252/msb.202110267</pub-id><pub-id pub-id-type="pmid">34031985</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nath</surname><given-names>T</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>AC</given-names></name><name><surname>Patel</surname><given-names>A</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title><source>Nature Protocols</source><volume>14</volume><fpage>2152</fpage><lpage>2176</lpage><pub-id pub-id-type="doi">10.1038/s41596-019-0176-0</pub-id><pub-id pub-id-type="pmid">31227823</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pereira</surname><given-names>TD</given-names></name><name><surname>Aldarondo</surname><given-names>DE</given-names></name><name><surname>Willmore</surname><given-names>L</given-names></name><name><surname>Kislin</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>SS-H</given-names></name><name><surname>Murthy</surname><given-names>M</given-names></name><name><surname>Shaevitz</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fast animal pose estimation using deep neural networks</article-title><source>Nature Methods</source><volume>16</volume><fpage>117</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0234-5</pub-id><pub-id pub-id-type="pmid">30573820</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remnant</surname><given-names>EJ</given-names></name><name><surname>Morton</surname><given-names>CJ</given-names></name><name><surname>Daborn</surname><given-names>PJ</given-names></name><name><surname>Lumb</surname><given-names>C</given-names></name><name><surname>Yang</surname><given-names>YT</given-names></name><name><surname>Ng</surname><given-names>HL</given-names></name><name><surname>Parker</surname><given-names>MW</given-names></name><name><surname>Batterham</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The role of Rdl in resistance to phenylpyrazoles in <italic>Drosophila melanogaster</italic></article-title><source>Insect Biochemistry and Molecular Biology</source><volume>54</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.ibmb.2014.08.008</pub-id><pub-id pub-id-type="pmid">25193377</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samantsidis</surname><given-names>G-R</given-names></name><name><surname>Panteleri</surname><given-names>R</given-names></name><name><surname>Denecke</surname><given-names>S</given-names></name><name><surname>Kounadi</surname><given-names>S</given-names></name><name><surname>Christou</surname><given-names>I</given-names></name><name><surname>Nauen</surname><given-names>R</given-names></name><name><surname>Douris</surname><given-names>V</given-names></name><name><surname>Vontas</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>What I cannot create, I do not understand’: functionally validated synergism of metabolic and target site insecticide resistance</article-title><source>Proceedings of the Royal Society B</source><volume>287</volume><elocation-id>20200838</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2020.0838</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaw</surname><given-names>PJ</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name><name><surname>Greenspan</surname><given-names>RJ</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Correlates of sleep and waking in <italic>Drosophila melanogaster</italic></article-title><source>Science</source><volume>287</volume><fpage>1834</fpage><lpage>1837</lpage><pub-id pub-id-type="doi">10.1126/science.287.5459.1834</pub-id><pub-id pub-id-type="pmid">10710313</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simon</surname><given-names>JC</given-names></name><name><surname>Dickinson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A new chamber for studying the behavior of <italic>Drosophila</italic></article-title><source>PLOS ONE</source><volume>5</volume><elocation-id>e8793</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0008793</pub-id><pub-id pub-id-type="pmid">20111707</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiggin</surname><given-names>TD</given-names></name><name><surname>Goodwin</surname><given-names>PR</given-names></name><name><surname>Donelson</surname><given-names>NC</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Trinh</surname><given-names>K</given-names></name><name><surname>Sanyal</surname><given-names>S</given-names></name><name><surname>Griffith</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Covert sleep-related biological processes are revealed by probabilistic analysis in <italic>Drosophila</italic></article-title><source>PNAS</source><volume>117</volume><fpage>10024</fpage><lpage>10034</lpage><pub-id pub-id-type="doi">10.1073/pnas.1917573117</pub-id><pub-id pub-id-type="pmid">32303656</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname><given-names>AB</given-names></name><name><surname>Johnson</surname><given-names>MJ</given-names></name><name><surname>Iurilli</surname><given-names>G</given-names></name><name><surname>Peterson</surname><given-names>RE</given-names></name><name><surname>Katon</surname><given-names>JM</given-names></name><name><surname>Pashkovski</surname><given-names>SL</given-names></name><name><surname>Abraira</surname><given-names>VE</given-names></name><name><surname>Adams</surname><given-names>RP</given-names></name><name><surname>Datta</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mapping sub-second structure in mouse behavior</article-title><source>Neuron</source><volume>88</volume><fpage>1121</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.031</pub-id><pub-id pub-id-type="pmid">26687221</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiltschko</surname><given-names>AB</given-names></name><name><surname>Tsukahara</surname><given-names>T</given-names></name><name><surname>Zeine</surname><given-names>A</given-names></name><name><surname>Anyoha</surname><given-names>R</given-names></name><name><surname>Gillis</surname><given-names>WF</given-names></name><name><surname>Markowitz</surname><given-names>JE</given-names></name><name><surname>Peterson</surname><given-names>RE</given-names></name><name><surname>Katon</surname><given-names>J</given-names></name><name><surname>Johnson</surname><given-names>MJ</given-names></name><name><surname>Datta</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Revealing the structure of pharmacobehavioral space through motion sequencing</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1433</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00706-3</pub-id><pub-id pub-id-type="pmid">32958923</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86695.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ewer</surname><given-names>John</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Universidad de Valparaiso</institution><country>Chile</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>This study presents an <bold>important</bold> open-source resource for high-throughput behavioral screening. The protocols employ inexpensive, off the shelf hardware, and allow real-time analysis of hundreds of behaving flies. Although these protocols were developed using <italic>Drosophila melanogaster</italic>, they could easily be applied to other models. The evidence in support of the conclusions is <bold>solid</bold> and the revisions carried out by the authors go a long way towards providing the user with an integrated system that is also more user-friendly.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86695.3.sa1</article-id><title-group><article-title>Joint Public Review:</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In the current paper, Jones et al. describe a new framework, named &quot;coccinella&quot;, for real-time high-throughput behavioral analysis aimed at reducing the cost of analyzing behavior. In the setup used here each fly is confined to a small circular arena and able to walk around on an agar bed spiked with nutrients or pharmacological agents. The new framework, built on the researchers' previously developed platform Ethoscope, relies on relatively low-cost Raspberry Pi video cameras to acquire images at ~0.5 Hz and pull out, in real time, the maximal velocity (parameter extraction) during 10 second windows from each video. Thus, the program produces a text file, and not voluminous videos requiring storage facilities for large amounts of video data, a prohibitive step in many behavioral analyses. The maximal velocity time-series is then fed to an algorithm called Highly Comparative Time-Series Classification (HCTSA)(which itself is based on a large number of feature extraction algorithms) developed by other researchers. HCTSA identifies statistically salient features in the time-series which are then passed on to a type of linear classifier algorithm called support vector machines (SVM). In cases where such analyses are sufficient for characterizing the behaviors of interest this system performs as well as other state-of-the-art systems used in behavioral analysis (e.g., DeepLabCut)</p><p>In a pharmacobehavior paradigm testing different chemicals, the authors show that coccinella can identify specific compounds as effectively as other more time-consuming and resource-consuming systems.</p><p>The new paradigm should be of interest to researchers involved in drug screens, and more generally, in high-throughput analysis focused on gross locomotor defects in fruit flies such as identification of sleep phenotypes. By extracting/saving only the maximal velocity from video clips, the method is fast. However, the rapidity of the platform comes at a cost--loss of information on subtle but important behavioral alterations. When seeking subtle modifications in animal behavior, solutions like DeepLabCut, which are admittedly slower but far superior in terms of the level of details they yield, would be more appropriate.</p><p>The manuscript reads well, and it is scientifically solid. The comments listed below were directed to the original submission and were satisfactorily addressed in the revised version.</p><p>1- The fact that Coccinella runs on Ethoscopes, an open source hardware platform described by the same group, is very useful because the relevant publication describes Ethoscope in detail. However, the current version of the paper does not offer details or alternatives for users that would like to test the framework, but do not have an Ethoscope. Would it be possible to overcome this barrier and have coccinella run with any video data (and, thus, potentially be used to analyze data obtained from other animal models)?</p><p>2- Readers who want background on the analytical approaches that the platform relies on following maximal velocity extraction, will have to consult the original publications. In particular, the current manuscript does not provide much explanation on Highly Comparative Time-Series Classification (HCTSA) or SVM; this may be reasonable because the methods were developed earlier by others. While some readers may find that the lack of details increases the manuscript's readability, others may be left wanting to see more discussion on these not-so-trivial approaches. In addition, it is worth noting that the same authors that published the HCTSA method, also described a shorter version named catch22, that runs faster with a similar output. Thus, explaining in more detail how HCTSA operates, considering is a relatively new method, will make the method more convincing.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.86695.3.sa2</article-id><title-group><article-title>Author Response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Jones</surname><given-names>Hannah</given-names></name><role specific-use="author">Author</role><aff><institution>Imperial College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Willis</surname><given-names>Jenny A</given-names></name><role specific-use="author">Author</role><aff><institution>Syngenta</institution><addr-line><named-content content-type="city">Bracknell</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Firth</surname><given-names>Lucy C</given-names></name><role specific-use="author">Author</role><aff><institution>Syngenta</institution><addr-line><named-content content-type="city">Bracknell</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Giachello</surname><given-names>Carlo NG</given-names></name><role specific-use="author">Author</role><aff><institution>Syngenta</institution><addr-line><named-content content-type="city">Bracknell</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Gilestro</surname><given-names>Giorgio F</given-names></name><role specific-use="author">Author</role><aff><institution>Imperial College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><p>We thank the editor and the reviewers for their very useful and constructive comments. We went through the list and gladly received all their suggestions. The reviewers mostly pointed to minor revisions in the text, and we acted on all of those. The one suggestion that required major work was the one raised in point 13, about the processing pipeline being unconvincingly scattered between different tools (R → Python → Matlab). I agree that this was a major annoyance, and I am happy to say we have solved it integrating everything in a recent version of the ethoscopy software (available on biorxiv with DOI <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.11.28.517675v2">https://www.biorxiv.org/content/10.1101/2022.11.28.517675v2</ext-link> and in press with Bioinformatics Advances). End users will now be able to perform coccinella analysis using ethoscopy only, thus relying on nothing else but Python as their data analysis tool. This revised version of the manuscript now includes two Jupyter Notebooks as supplementary material with a “pre-cooked” sample recipe of how to do that. This should really simplify adoption and provides more details on the pipeline used for phenotyping.</p><p>Please find below a point-by-point description of how we incorporated all the reviewers’ excellent suggestions.</p><p>Recommendations for the authors: please note that you control which, if any, revisions, to undertake</p><disp-quote content-type="editor-comment"><p>1. Line 38: &quot;collecting data simultaneously from a large number of individuals with no or limited human intervention&quot; is a bit misleading, as the entire condition the individuals are put in are highly modified by humans and most times &quot;unnatural&quot;. I understand the point that once the animals are placed in these environments, then recording takes place without intervention, but it would be nice to rephrase this so that it reflects more accurately what is happening.</p></disp-quote><p>We have now rephrased this into the following (L39):</p><p>Collecting data simultaneously from a large number of individuals, which can remain undisturbed throughout recording.</p><disp-quote content-type="editor-comment"><p>1. Line 63: please add a reference to the Ethoscopes so that readers can easily find it.</p></disp-quote><p>Done.</p><disp-quote content-type="editor-comment"><p>(2b) And also add how much they cost and the time needed to build them, as this will allow readers to better compare the proposed system against other commercially available ones.</p></disp-quote><p>This information is available on the ethoscope manual website (<ext-link ext-link-type="uri" xlink:href="http://lab.gilest.ro/ethoscope">http://lab.gilest.ro/ethoscope</ext-link>). The price of one ethoscope, provided all necessary tools are available, is around ~£75 and the building time very much depends on the skillset of the builder and whether they are building their first ethoscope or subsequent ones. In our experience, building and adopting ethoscopes for the first time is not any more time-expensive than building a (e.g.) deeplabcut setup for the first time. We have added this information to L81</p><p>Ethoscopes are open source and can be manufactured by a skilled end-user at a cost of about £75 per machine, mostly building on two off-the-shelf component: a Raspberry Pi microcomputer and a Raspberry Pi NoIR camera overlooking a bespoke 3D printed arena hosting freely moving flies.</p><disp-quote content-type="editor-comment"><p>1. Line 88: The authors describe that in the current setting, their system is capable of an acquisition rate of 2.2 frames per second (FPS). Would reducing the resolution of the PiCamera allow for higher FPS? I raise this point because the authors state that max velocity over a ten second window is a good feature for classifying behaviors. However, if animals move much faster than the current acquisition rate, they could, for instance, be in position X, move about and be close to the initial position when the next data point is acquired, leading to a measured low max velocity, when in fact the opposite happened. I think it would be good to add a statement addressing this (either data from the literature showing that the low FPS does not compromise data acquisition, or a test where increasing greatly FPS leads to the same results).</p></disp-quote><p>We have previously performed a comparison of data analysed using videos captured at different FPSs, which is published in Quentin Geissman’s doctoral Thesis (2018, DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.25560/69514">https://doi.org/10.25560/69514</ext-link> in chapter 2, section 2.8.3, figure 2.9 ). We have now added this work as one of the references at L95 (reference 19).</p><disp-quote content-type="editor-comment"><p>1. Still on the low FPS, would a Raspberry Pi 4 help with the sampling rate? Given that they are more powerful than the RPi3 used in the paper?</p></disp-quote><p>It would, but it would be a minor increase, leading from 2.2 to probably 3-5 FPS. A significantly higher number of FPSs would be best achieved by lowering the camera’s resolution, as the reviewer’s suggested, or by operating offline. I think the interesting point being implied by the reviewers is that, for <italic>Drosophila</italic>, the current limits of resolution are more than sufficient. For other animals, perhaps moving more abruptly, they may not. The reviewer is right that we should add a line of caveat about this. We now do so in the discussion, lines 215-224.</p><p>Coccinella is a reductionist tool, not meant to replace the behavioural categorization that other tools can offer but to complement it. It relies on raspberry PIs as main acquisition devices, with associated advantages and limitations. Ethoscopes are inexpensive and versatile but have limitations in terms of computing power and acquisition rates. Their online acquisition speed is fast enough to successfully capture the motor activity of different species of <italic>Drosophilae28</italic>, but may not be sufficient for other animals moving more swiftly, such as zebrafish larvae. Moreover, coccinella cannot apply labels to behaviour (“courting”, “lounging”, “sipping”, “jumping” etc.) but it can successfully identify large behavioural phenotypes and generate unbiased hypothesis on how behaviour – and a nervous system at large – can be influenced by chemicals, genetics, artificial manipulations in general.</p><disp-quote content-type="editor-comment"><p>1. Along the same line of thought, would using a simple webcam (with similar specs to the PiCamera - ELP has cameras that operate on infrared and are quite affordable too) connected to a more powerful computer lead to higher FPS? - The reason for the question about using a simple webcam is that this would make your system more flexible (especially useful in the current shortage of RPi boards on the market) lowering the barrier for others to use it, increasing the chances for adoption.</p></disp-quote><p>Completely bypassing ethoscopes would require the users to setup their own tracking solution, with a final result that may or may not match what we describe here. If a greater temporal resolution is necessary, the easiest way to achieve more FPSs would be to either decrease camera resolution or use the Pis to take videos offline and then process those videos at a later stage. The combination of these two would give FPS acquisition of 60 fps at 720p, which is the maximum the camera can achieve. We now made this clear at lines 83-92.</p><p>The temporal and spatial resolution of the collected images depends on the working modality the user chooses. When operating in offline mode, ethoscopes are capable to acquire 720p videos at 60 fps, which is a convenient option with fast moving animals. In this study, we instead opted for the default ethoscope working settings, providing online tracking and realtime parametric extraction, meaning that images are analysed by each raspberry Pi at the very moment they were acquired (Figure 1b). This latter modality limits the temporal resolution of information being processed (one frame every 444 ms ± 127 ms, equivalent to 2.2 fps on a Raspberry Pi3 at a resolution of 1280x960 pixels with each animal being constricted in an ellipse measuring 25.8 ± 1.4 x 9.85 ±1.4 pixels - Figure 1a) but provides the most affordable and high-throughput solution, dispensing the researcher from organising video storage or asynchronous video processing for animals tracking.</p><disp-quote content-type="editor-comment"><p>1. One last point about decreasing use barrier and increasing adoption: Would it be possible to use DeepLabCut (DLC) to simply annotate each animal (instead of each body part) and feed the extracted data into your current analysis with coccinella? This way different labs that already have pipelines in place that use DLC would have a much easier time in testing and eventually switching to coccinella? I understand that extracting simple maximal velocity this way would be an overkill, but the trade-off would again be a lowering of the adoption barrier.</p></disp-quote><p>It would certainly be possible to calculate velocity from the whole animal pose measurement and then use this with HCTSA or Catch22, thus mimicking the coccinella pipeline, but it would be definitely overkilled, as the reviewers correctly points out. Given that we are trying to make an argument about high-throughput data acquisition I would rather not suggest this option in the manuscript.</p><disp-quote content-type="editor-comment"><p>1. Line 96: The authors state that once data is collected, it is put through a computational frameworkthat uses 7700 tests described in the literature so that meaningful discriminative features are found. I think it would be interesting to expand a bit on the explanation of how this framework deals multiple comparison/multiple testing issues.</p></disp-quote><p>We always use the full set of features on aggregate to train a classifier (e.g., TS_Classify in HCTSA) and that means no correction is necessary because the trained classifier only ever makes a single prediction (only one test is performed), so as long as it is done correctly (e.g., proper separation of training and test sets, etc.) then multiple hypothesis correction is not appropriate. This has been confirmed with the HCTSA/Catch22 author (Dr Ben Fulcher, personal communication). We have added a clarifying sentence about this to the methods (L315-318)</p><disp-quote content-type="editor-comment"><p>1. It would be nice to have a couple of lines explaining the choice of compounds used for testing and also why in some tests, 17 compounds were used, while in others 40, and then 12? I understand how much work it must be in terms of experiment preparation and data collection for these many flies and compounds, but these changes in the compounds used for testing without a more detailed explanation is suboptimal.</p></disp-quote><p>This is another good point. We have now added this information to the methods, in a section renamed “choice, handling and preparation of drugs” L280-285, which now reads like this:</p><p>The initial preliminary analysis was conducted using a group of 12 compounds “proof of principle” compounds and a solvent control. These compounds were initially used to compare both the video method and ethoscope method. After testing these initial compounds, it was found that the ethoscope methodology was more successful, and then the compound list was expanded to 17 (including the control) only using the ethoscope method. As a final test, we included additional compounds for a single concentration, bringing up the total to 40 (including control), also for the ethoscope method.</p><disp-quote content-type="editor-comment"><p>1. Line 119 states: &quot;A similar drop in accuracy was observed using a smaller panel of 12 treatments (Supplementary Figure 2a)&quot;. It is actually Supplementary Figure 1c.</p></disp-quote><p>Thank you for noticing that! Now corrected. The Supplementary figures have also been renamed to obey eLife’s expected nomenclature (both Figure 1 – Figure supplements)</p><disp-quote content-type="editor-comment"><p>1. In some places the language seems a little outlandish and should either be removed or appropriately qualified. a- Lines 56-59 pose three questions that are either rhetorical or ill-posed. For example, &quot;...minimal amount of information...behavior&quot; implies there is a singular response but the response depends on many details such as to what degree do the authors want to &quot;classify behavior&quot;.</p></disp-quote><p>Yes, those were meant as rhetorical questions indeed, but we prefer to keep them in, because we are hoping to generate this type of thoughts with the readers. These are concepts that may not be so obvious to someone who is just looking to apply an existing tool and may spring some reflection about what kind of data do they really want/need to acquire.</p><disp-quote content-type="editor-comment"><p>b) Some of the criticisms leveled at the state-of-the-art methods are probably unwarranted because the goals of the different approaches are different. The current method does not yield the type of rich information that DeepLabCut yields. So, depending on the application DeepLabCut may be the method of choice. The authors of the current manuscript should more clearly state that.</p></disp-quote><p>In the introduction and discussion we do try to stress that coccinella is not meant to replace tools like DLC. We have now added more emphasis to this concept, for instance to L212:</p><p>[tools like deeplabcut] are ideal – and irreplaceable – to identify behavioural patterns and study fine motor control but may be undue for many other uses.</p><p>And L215:</p><p>Coccinella is a reductionist tool not meant to replace the behavioural categorization that other tools can offer but to complement it</p><disp-quote content-type="editor-comment"><p>1. The application to sleep data appears suddenly in the manuscript. The authors should attempt to make with text change a smoother transition from drug screen to investigation into sleep.</p></disp-quote><p>I agree with this observation. We have now tried to add a couple of sentences to contextualise this experiment and hopefully make the connection appear more natural. Ultimately, this is a proof-ofprinciple example anyway so hopefully the reader will take it for what it is (L169).</p><p>Finally, to push the system to its limit, we asked coccinella to find qualitative differences not in pharmacologically induced changes in activity, but in a type of spontaneous behaviour mostly characterised by lack of movement: sleep. In particular, we wondered whether coccinella could provide biological insights comparing conditions of sleep rebound observed after different regimes of sleep deprivation. <italic>Drosophila melanogaster</italic> is known to show a strong, conserved homeostatic regulation of sleep that forces flies to recover at least in part lost sleep, for instance after a night of forceful sleep deprivation.</p><disp-quote content-type="editor-comment"><p>(11b) Additionally, the beginning section of sleep experiments talks about sleep depth yet the conclusion drawn from sleep rebound says more about the validity of the current 5 min definition of sleep than about sleep depth. If this conclusion was misunderstood, it should be clarified. If it was not, the beginning text of the sleep section should be tailored to better fit the conclusion.</p></disp-quote><p>I am afraid we did not a good job at explaining a critical aspect here: the data fed to coccinella are the “raw” activity data, in which we are not making any assumption on the state of the animal. In other words, we do not use the 5-minutes at this or any other point to classify sleep and wakening. Nevertheless, coccinella picks the 300 seconds threshold as the critical one for discerning the two groups. This is interesting because it provides a full agnostic confirmation of the five minutes rule in <italic>D. melanogaster</italic>. We recognise this was not necessarily obvious from the text and now added a clarification at L189-201:</p><p>However, analysis of those same animals during rebound after sleep deprivation showed a clear clustering, segregating the samples in two subsets with separation around the 300 seconds inactivity trigger (Figure 3d). This result is important for two reasons: on one hand, it provides, for the third time, strong evidence that the system is not simply overfitting data of nought biological significance, given that it could not perform any better than a random classifier on the baseline control. On the other hand, coccinella could find biologically relevant differences on rebound data after different regimes of sleep deprivation. Interestingly enough, the 300 seconds threshold that coccinella independently identified has a deep intrinsic significance for the field, for it is considered to be the threshold beyond which flies lose arousal response to external stimuli, defining a “sleep quantum” (i.e.: the minimum amount of time required for transforming inactivity bouts into sleep bouts23,24,28). Coccinella’s analysis ran agnostic of the arbitrary 5-minutes threshold and yet identified the same value as the one able to segregate the two clusters, thus providing an independent confirmation of the fiveminutes rule in <italic>D. melanogaster</italic>.</p><disp-quote content-type="editor-comment"><p>1. Line 227: (standard food) - please add a link to a protocol or a detailed description on what is &quot;standard food&quot;. This way others can precisely replicate what you are using. This is not my field, but I have the impression that food content/composition for these animals makes big changes in behaviour?</p></disp-quote><p>Yes, good point. We have now added the actual recipe to the methods L240:</p><p>Fly lines were maintained on a 12-hour light: 12-hour dark (LD) cycle and raised on polenta and yeast-based fly media (agar 96 g, polenta 240 g, fructose 960 g and Brewer’s yeast 1,200 g in 12 litres of water).</p><disp-quote content-type="editor-comment"><p>1. Data acquisition and processing: please add links to the code used.</p></disp-quote><p>Both the code and the raw data used to generate all the figures have been uploaded on Zenodo and available through their repository. Zenodo has a limit of 50GB per uploaded dataset so we had to split everything into two files, with two DOIs, given in the methods (L356, section “code and availability” - DOIs: 10.5281/zenodo.7335575 and 10.5281/zenodo.7393689). We have now also created a landing page for the entire project at <ext-link ext-link-type="uri" xlink:href="http://lab.gilest.ro/coccinella">http://lab.gilest.ro/coccinella</ext-link> and linked that landing page in the introduction (L64).</p><disp-quote content-type="editor-comment"><p>13b) Also your pipeline seems to use three different programming languages/environments... Any chance this could be reduced? Maybe there are R packages that can convert csv to matlab compatible formats, so you can avoid the Python step? (nothing against using the current pipeline per se, I am just thinking that for usability and adoption by other labs, the smaller amount of languages, the better?</p></disp-quote><p>This is a very important suggestion that highlights a clear limitation of the pipeline. I am happy to say that we worked on this and solved the problem integrating the Python version of Catch22 into the ethoscopy software. This means the two now integrate, and the entire analysis can be run within the Python ecosystem. HCTSA does not have a Python package unfortunately but we still streamlined the process so that one only has to go from Python to Matlab without passing through R. To be honest, Catch22 is the evolution of HCTSA and performs really well so I think that is what most users will want to use. We provide two supplementary notebooks to guide the reader through the process. One explains how to go from ethoscope data to an HCTSA compatible mat file. The other explains how ethoscope data integrate with Catch22 and provides many more examples than the ones found in the paper figures.</p><disp-quote content-type="editor-comment"><p>1. There are two sections named &quot;References&quot; (which are different from each other) on the manuscript I received and also on BioRxiv. Should one of them be a supplementary reference? Please correct it. I spent a bit of time trying to figure out why cited references in the paper had nothing to do with what was being described...</p></disp-quote><p>The second list of references actually applied only to the list of compounds in the supplementary table 1. When generating a collated PDF this appeared at the end of the document and created confusion. We have now amended the heading of that list in the following way, to read more appropriately:</p></body></sub-article></article>