<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">103734</article-id><article-id pub-id-type="doi">10.7554/eLife.103734</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.103734.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Advance</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Humans adapt rationally to approximate estimates of uncertainty</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Pulcu</surname><given-names>Erdem</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2170-0677</contrib-id><email>pulerd@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Browning</surname><given-names>Michael</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9108-3144</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Psychiatry, University of Oxford</institution></institution-wrap><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04c8bjx39</institution-id><institution>Oxford Health NHS Trust</institution></institution-wrap><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Diaconescu</surname><given-names>Andreea Oliviana</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>08</day><month>07</month><year>2025</year></pub-date><volume>14</volume><elocation-id>RP103734</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-10-03"><day>03</day><month>10</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-09-19"><day>19</day><month>09</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.11.26.568699"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-01-13"><day>13</day><month>01</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.103734.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-06-27"><day>27</day><month>06</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.103734.2"/></event></pub-history><permissions><copyright-statement>© 2025, Pulcu and Browning</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Pulcu and Browning</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-103734-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-103734-figures-v1.pdf"/><related-article related-article-type="article-reference" ext-link-type="doi" xlink:href="10.7554/elife.27879" id="ra1"/><abstract><p>Efficient learning requires estimation of, and adaptation to, different forms of uncertainty. If uncertainty is caused by randomness in outcomes (noise), observed events should have less influence on beliefs, whereas if uncertainty is caused by a change in the process being estimated (volatility) the influence of events should increase. Previously, we showed that humans respond appropriately to changes in volatility irrespective of outcome valence (Pulcu and Browning, 2017), but there is less evidence of a rational response to noise. Here, we test adaptation to variable levels of volatility and noise in human participants, using choice behaviour and pupillometry as a measure of the central arousal system. We find that participants adapt as expected to changes in volatility, but not to changes in noise. Using a Bayesian observer model, we demonstrate that participants are, in fact, adapting to estimated noise, but that their estimates are imprecise, leading them to misattribute it as volatility and thus to respond inappropriately.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>reinforcement learning</kwd><kwd>pupillometry</kwd><kwd>behavioural modelling</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>MR/N008103/1</award-id><principal-award-recipient><name><surname>Browning</surname><given-names>Michael</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Humans estimate different forms of uncertainty during learning, but do so imprecisely, leading to the misattribution of random fluctuations as fundamental shifts.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>It is much easier to respond appropriately to an event if we know what has caused it. For example, if heavy traffic means that our drive into work takes longer than normal, the best course of action the next time we have to make the journey depends on what caused the traffic to be heavier (<xref ref-type="bibr" rid="bib27">Yu and Dayan, 2005</xref>). If it was caused by a one-off or random event, such as a broken-down lorry, then we should continue using the same route as before, whereas if it was caused by some longer-term change, perhaps there are new road works nearby disrupting the traffic, we should consider a different route. Frequently, however, the causes of events are not obvious. We experience the heavy traffic but aren’t sure why it has occurred. In these situations, the best we can do is make an educated guess, based on our experience, about what broad type of causal process has led to recent events. In the case of the drive into work, if the traffic has been heavier for a number of days in a row it is likely that some prolonged shift has occurred, and we should change routes, whereas if the traffic changes noisily from day to day, then we should probably stick with our usual route. In the learning literature, this problem is often framed as a competitive attribution of uncertainty to one of two types; expected uncertainty, which is caused by the variability of noisy associations, and unexpected uncertainty, which is caused by longer-lasting changes (sometimes called volatility) in an association (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Pulcu and Browning, 2017</xref>; <xref ref-type="bibr" rid="bib27">Yu and Dayan, 2005</xref>). The behavioural importance of this attribution process can be seen in the driving example given above; an event caused by noise requires the opposite behavioural response (continuing to use the same route) than the same event caused by volatility (switching routes). Consequently, effective decision making often depends on the accurate attribution of uncertainty, with misattribution having a substantial detrimental effect on choice (<xref ref-type="bibr" rid="bib22">Pulcu and Browning, 2019</xref>).</p><p>The influence of events on subsequent choice can be estimated within a reinforcement learning framework as the learning rate parameter (<xref ref-type="bibr" rid="bib24">Sutton and Barto, 2018</xref>), with a higher learning rate indicating a greater influence of the event on behaviour. As described above, the normative response to changes in volatility and noise is to use a higher learning rate when volatility is high and/or noise is low (<xref ref-type="bibr" rid="bib22">Pulcu and Browning, 2019</xref>; <xref ref-type="bibr" rid="bib27">Yu and Dayan, 2005</xref>). A large number of studies have found the predicted increase in learning rates in response to higher outcome volatility in human learners (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib3">Behrens et al., 2008</xref>; <xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Gagne et al., 2020</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Pulcu and Browning, 2017</xref>). In contrast, the evidence for adaptation of learning in response to changes in outcome noise is less complete. Previous studies have described the expected reduction of learning rates when outcome noise is high, but only when the level of noise is explicitly signalled in a task (<xref ref-type="bibr" rid="bib7">Diederen and Schultz, 2015</xref>), or when it is made unambiguous by virtue of being very much smaller than changes in outcome caused by volatility (<xref ref-type="bibr" rid="bib16">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>). As illustrated in the driving example above, we are often faced with situations in which there exists significant uncertainty about whether an event has been caused by volatility or noise. To date, however, the degree to which human learners are able to discriminate between these types of uncertainty, when they are not explicitly labelled, has not been closely examined.</p><p>From a neurobiological perspective, activity of central modulatory neurotransmitter systems have been argued to represent distinct sources of uncertainty during learning, with central norepinepheric (NE)/locus coeruleus (LC) activity described as signalling changes in the associations (i.e. volatility) and central cholinergic activity representing noise (<xref ref-type="bibr" rid="bib27">Yu and Dayan, 2005</xref>). Electrophysiological measures of LC activity in non-human primates have been shown to correlate with pupil dilation (<xref ref-type="bibr" rid="bib10">Joshi et al., 2016</xref>), suggesting it may be possible to estimate activity in this system in humans using pupilometry. Taking this approach, indirect support for this role of the NE system has been provided by studies of human participants that report greater pupillary size in volatile relative to stable contexts (<xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib21">Pulcu and Browning, 2017</xref>). However, the pupil also responds to other learning signals, such as surprise (<xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">O’Reilly et al., 2013</xref>; <xref ref-type="bibr" rid="bib20">Preuschoff et al., 2011</xref>) and has been reported as being smaller when outcome noise is high (<xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>). Neuroimaging evidence suggests an association between activity in other central neurotransmitter nuclei, including the cholinergic basal forebrain, and pupil dilation (<xref ref-type="bibr" rid="bib6">de Gee et al., 2017</xref>). Overall, this suggests that the pupillary signal may reflect a more general belief updating process (<xref ref-type="bibr" rid="bib18">O’Reilly et al., 2013</xref>) rather than a specific volatility signal and thus that, like learning rates, pupil size should increase when noise is reduced as well as when volatility is increased.</p><p>In this paper, we test whether human participants modify their learning in situations in which the attribution of uncertainty as volatility or noise is challenging (<xref ref-type="fig" rid="fig1">Figure 1a–c</xref>). We report the results of a study in which participants completed a learning task during which the noise and volatility of both win and loss outcomes were independently manipulated. Participant behaviour was characterised using learning rate parameters derived from reinforcement learning models of choice, while interpretation of the results was facilitated by a Bayesian Ideal Observer model that was developed to provide a benchmark comparator to participant behaviour (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib19">Piray and Daw, 2021</xref>; <xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref>) and by the collection of pupillometry data as a physiological marker of central neurotransmitter function (<xref ref-type="bibr" rid="bib6">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="bib10">Joshi et al., 2016</xref>). It was predicted that human participants would be able to adapt appropriately to the cause of the events they encountered—using a higher learning rate, and displaying increased pupil size, when volatility was high and when noise was low for both win and loss outcomes (<xref ref-type="fig" rid="fig1">Figure 1d</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The magnitude learning task (<bold>a</bold>) Timeline of one trial from the learning task.</title><p>On each trial, participants were presented with two abstract shapes and were asked to choose one of them. The empty bars above and below the fixation cross represented the total available wins and losses for the trial, the full length of each bar was equivalent to £1. Participants chose a shape and then were shown the proportion of each outcome that was associated with their chosen shape as coloured regions of the bars (green for wins and red for losses). The empty portions of the bars indicated the win and loss magnitudes associated with the unchosen option, allowing participants to infer which shape would have been the better option on every trial. The task consisted of six blocks of sixty trials each. The volatility and noise of the two outcomes varied independently between blocks with different shapes used in each block. Panel (<bold>b</bold>) illustrates outcomes from the four block types. As can be seen, blocks with high volatility and low noise (top left), and those with low volatility and high noise (bottom right), present participants with a similar range of magnitudes. Participants, therefore, have to distinguish whether variability in the outcomes is caused by volatility or noise from the temporal structure of the outcomes rather than the size of changes in magnitude (cf. <xref ref-type="bibr" rid="bib7">Diederen and Schultz, 2015</xref>; <xref ref-type="bibr" rid="bib13">Krishnamurthy et al., 2017</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>). Panel (<bold>c</bold>) shows two example blocks (one block in grey, the other in white) with both win (green) and loss outcomes (red) displayed. Panel (<bold>d</bold>) shows the expected adaptation of learning rates in response to the manipulation of volatility and noise; for both win and loss outcomes, learning rates should be increased when volatility is high and when noise is low.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig1-v1.tif"/></fig></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Participant demographics</title><p>70 participants (see <xref ref-type="table" rid="table1">Table 1</xref> for demographic information) completed a learning task in which they had to choose one of two stimuli based on the separately estimated magnitudes of win and loss outcomes associated with the stimuli (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Participants were able to learn the best option to choose in the task, selecting the most highly rewarded option on an average of 71% of trials (range 65–74%).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Demographic details of participants.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Measure</th><th align="left" valign="top">Mean (SD)</th></tr></thead><tbody><tr><td align="left" valign="top"><bold>Age</bold></td><td align="left" valign="top">29.07 (10.86)</td></tr><tr><td align="left" valign="top"><bold>Gender</bold></td><td align="left" valign="top">69% Female</td></tr><tr><td align="left" valign="top"><bold>QIDS-16</bold></td><td align="left" valign="top">5.26 (4.25)</td></tr><tr><td align="left" valign="top"><bold>Trait-STAI</bold></td><td align="left" valign="top">36.21 (10.42)</td></tr><tr><td align="left" valign="top"><bold>State-STAI</bold></td><td align="left" valign="top">30.29 (8.57)</td></tr></tbody></table><table-wrap-foot><fn><p>QIDS-16; Quick Inventory of Depressive Symptoms, 16-item self-report version. Trait/State-STAI; Spielberger State-Trait Anxiety Inventory.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-2"><title>Experimental manipulation of volatility and noise influences participant choice behaviour</title><p>As explained above, high levels of volatility and low levels of noise should increase the degree to which outcomes influence choice behaviour. A crude metric of this effect is provided by examining participant choice as a function of the previous outcome. In the task, a win outcome of &gt;50 p or a loss outcome of &lt;50 p associated with Shape A prompts participants to select Shape A in the subsequent trial, with the other outcomes (i.e. win &lt;50 p and loss &gt;50 p) prompting choice of Shape B. The influence of the outcomes on choice can, therefore, be roughly estimated as the relative proportion of trials in which Shape A was chosen when it was prompted by a previous outcome of a given magnitude, compared to when Shape B was prompted. Analysis of this choice metric (<xref ref-type="fig" rid="fig2">Figure 2a–b</xref>) found the expected effect of volatility, with participant choice being more influenced by previous outcomes when volatility was higher (F(1,696)=99.8, pParticipants adjust normatively to changes in volatility but not noise&lt;0.001). An effect of noise was observed, but in the opposite direction to expected, with outcomes influencing choice more when noise was increased (F(1,696)=4.79, p=0.03). No significant difference between the influence of win and loss outcomes was found (F(1,696)=1, p=0.32), and there was no interaction between volatility and noise (F(1,693)=0.61, p=0.4). Having found some evidence of an impact of the uncertainty manipulations on a crude measure of subject choice, we next sought to characterise this effect using reinforcement learning models fitted to participant choices.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The impact of uncertainty manipulations on participant choice.</title><p>Panels a and b report a summary metric for the effect of win and loss outcomes on subsequent choice. The metric was calculated as the proportion of trials in which an outcome of magnitude 51–65 associated with Shape A was followed by choice of the shape prompted by the outcome (i.e. Shape A for win outcomes, Shape B for loss outcomes) relative to when the outcome magnitude was 49–35 (see Methods and materials for more details). We focused on this outcome range as these range of magnitudes were covered by all volatility × noise conditions and it was dictated by the relatively smaller range coverage in the low volatility low noise condition (also see <xref ref-type="fig" rid="fig1">Figure 1C</xref>, loss outcomes shown in red between trials 60–120). The higher this number, the greater the tendency for a participant to choose the shape prompted by an outcome. As can be seen, the outcome of previous trials had a greater influence on participant choice when volatility was high, with a small effect of noise, in the opposite direction to that predicted. Panels c and d report the win and loss learning rates estimated from the same data. Again, the expected effect of volatility is observed, this time with no consistent effect of noise. Bars represent the mean (± SEM) of the data, with individual data points superimposed.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Comparison of estimated win and loss learning rates from the two estimation reinforcement learning (RL) models.</title><p>Panels (<bold>a</bold>) and (<bold>b</bold>) are the same as panels (<bold>c </bold>and <bold>d</bold>) from main <xref ref-type="fig" rid="fig2">Figure 2</xref> and report the estimated win and loss learning rates using the two learning rate one beta model described in the main paper. Panels c and d report the same parameters from the tw0 learning rate two beta model described above. As can be seen, the results are similar regardless of the form of the measurement model used.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Results of the generate-recover procedure for the reinforcement learning (RL) measurement model.</title><p>The two learning rate parameters were varied from 0.01 to 0.99 and the inverse temperature parameter from 1 to 36. Synthetic choices from one task block were generated using the RL model described in the main paper, which were then passed through the model fitting procedure. The recovered parameter values are reported on the z-axis of the plots (the top row reports recovered win learning rates, middle row recovered loss learning rates, bottom row recovered beta values) as a function of different pairs of input parameters (as described on the x and y axes). As can be seen, all three parameters are well recovered, whenever the beta value is above 1.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Behaviour of a simple reinforcement learning (RL) model fit across all task blocks.</title><p>A three-parameter (win learning rate, loss learning rate, inverse temperature) model was fit to participant’s choices across all blocks. The effective learning rates of the model’s choices are illustrated, demonstrating that it does not replicate the pattern of behaviour seen in participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig2-figsupp3-v1.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Participants adjust normatively to changes in volatility but not noise</title><p>We aimed to capture the computational process that underlies participant choice behaviour by fitting different reinforcement learning models to choice data separately for each block of the task and each participant. The best fitting RL model included separate learning rates for win and loss outcomes allowing estimation of the degree to which participants adjusted these learning rates in response to the block-wise changes in outcome volatility and noise (see Supplementary materials and methods for model comparison and selection analyses).</p><p>Consistent with the analysis of choice data reported above, there was a significant main effect of volatility (<xref ref-type="fig" rid="fig2">Figure 2c–d</xref>; F(1,696)=22.2, p&lt;0.001), with a higher learning rate used when volatility was high. There was no main effect of noise (F(1,696)=0.63, p=0.43) on learning rate or outcome valence (F(1,696)=0.15, p=0.7). An interaction between volatility and noise (F(1,693)=7.74, p=0.006) was also significant. A higher volatility led to a significantly raised learning rate when noise was low (F(1,383)=27.1, p&lt;0.01), with a non-significant increase when noise was high (F(1,311)=1.13, p=0.29). Higher noise was associated with a non-significant reduction in learning rates when volatility was high (F(1,347)=2.57, p=0.11) but to a significant increase in learning rate when volatility was low (F(1,347)=4.7, p=0.031).</p><p>In summary, analysis of both crude choice data and learning rates indicates that participants adapted appropriately to changes in the volatility of learned associations but did not show a consistent response to changes in noise. In the next section,, we utilise a Bayesian observer model (BOM) to investigate potential causes for this relative insensitivity to noise.</p></sec><sec id="s2-4"><title>Using a Bayesian observer model to characterise noise insensitivity</title><p>Bayesian observer models (BOM) can be used as normative benchmarks against which human behaviour may be compared (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib19">Piray and Daw, 2021</xref>; <xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref>). BOMs are generally not fit to participant choice, rather these models invert a generative process assumed to underlie observed events and provide an estimate of the belief of an idealised agent exposed to the same outcomes as participants. We developed a BOM (<xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref>) based on the generative process underlying the outcome magnitudes of our task (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). The BOM explicitly estimates the volatility and noise of the outcomes and uses these estimates to influence its belief about the likely magnitude of upcoming outcomes (see methods for more details). We first tested whether the BOM reproduced the normative learning rate adaptation to changes in volatility and noise described in the introduction, by exposing the model to the same outcomes as participants and using the model’s belief about the likely magnitude of the win and loss outcome on each trial to generate choices. We then estimated the effective learning rate of the model by fitting the same RL model used to analyse participants’ choices to the model’s choices. These learning rates are presented in <xref ref-type="fig" rid="fig3">Figure 3f</xref> (<xref ref-type="fig" rid="fig3">Figure 3e</xref> reproduces the learning rates of participants, averaged across wins and losses, for comparison). As can be seen, the BOM adapts as expected, using a higher learning rate both when volatility increases (F(1,696)=422, p&lt;0.001) and when noise decreases (F(1,696)=21.2, p&lt;0.001). No effect of outcome valence or interaction between volatility and noise (all p&gt;0.09) was observed.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The behaviour of Bayesian observer models.</title><p>Bayesian Observer Models (BOM) invert generative descriptions of a process, indicating how an idealised observer may learn. We developed a BOM based on the generative model of the task we used (<bold>a</bold>) Details of the BOM are provided in the methods, briefly, it assumes that observations (<inline-formula><alternatives><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft1">\begin{document}$y_{i}$\end{document}</tex-math></alternatives></inline-formula>) are generated from a Gaussian distribution with a mean (<inline-formula><alternatives><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft2">\begin{document}$mu_{i}$\end{document}</tex-math></alternatives></inline-formula>) and standard deviation (<inline-formula><alternatives><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft3">\begin{document}$SD_{i}$\end{document}</tex-math></alternatives></inline-formula>). Between observations, the mean changes with the rate of change controlled by the volatility parameter (<inline-formula><alternatives><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft4">\begin{document}$vmu_{i}$\end{document}</tex-math></alternatives></inline-formula>). The standard deviation and volatility of this model estimate the noise and volatility described for the task. The last parameters control the change in volatility (<inline-formula><alternatives><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$kmu$\end{document}</tex-math></alternatives></inline-formula>) and standard deviation (<inline-formula><alternatives><mml:math id="inf6"><mml:mi>v</mml:mi><mml:mi>s</mml:mi></mml:math><tex-math id="inft6">\begin{document}$vs$\end{document}</tex-math></alternatives></inline-formula>) between observations, allowing the model to account for different periods when these types of uncertainty are high and others when they are low. The BOM adjusts its learning rate in a normative fashion (<bold>f</bold>), increasing it when volatility is higher, or noise is lower. The BOM was lesioned in a number of different ways in an attempt to recapitulate the learning rate adaptation observed in participants (shown in panel <bold>e</bold>). Removing the ability of the BOM to adapt to changes in volatility (<bold>b</bold>) or noise (<bold>c</bold>) did not achieve this goal (<bold>g, h</bold>). However, degrading the BOMs representation of uncertainty (<bold>d</bold>) was able to recapitulate the behavioural pattern of participants (<bold>i</bold>) Bars represent the mean (± SEM) of participant learning rates, with raw data points presented as circles behind each bar.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Analysis of the behaviour of the latent-state model.</title><p>The latent-state model described by <xref ref-type="bibr" rid="bib5">Cochran and Cisler, 2019</xref> was fit to participant data. Panel a illustrates the behaviour of the fitted model analysed using the reinforcement learning measurement model (main paper <xref ref-type="fig" rid="fig3">Figure 3e–i</xref>). As can be seen the model captures the increase in learning rate in high-volatile blocks seen in participants (main paper <xref ref-type="fig" rid="fig3">Figure 3e</xref>), but unlike participants increases its learning rate when noise is high. Panel b illustrates the analysis of participant choice data, using model-defined labels of high/low volatility/noise (cf main paper <xref ref-type="fig" rid="fig4">Figure 4d–f</xref>). Where the degraded Bayesian observer model (BOM) rescued the normative behaviour of participants (main paper <xref ref-type="fig" rid="fig4">Figure 4f</xref>), the latent-state model does not.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig3-figsupp1-v1.tif"/></fig></fig-group><p>Having shown that an optimal learner adjusts its learning rate to changes in volatility and noise as expected, we next sought to understand the relative noise insensitivity of participants. In these analyses, we ‘lesion’ the BOM, to reduce its performance in some way, and then assess whether doing so recapitulates the pattern of learning rate adaptation observed for participants (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). In other words, we damage the model so it performs less well and then assess whether this damage makes the behaviour of the BOM (shown in <xref ref-type="fig" rid="fig3">Figure 3f</xref>) more closely resemble that seen in participants (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). First, we tested the impact of completely removing the ability of the BOM to adjust to changes in either volatility (<xref ref-type="fig" rid="fig3">Figure 3b</xref>) or noise (<xref ref-type="fig" rid="fig3">Figure 3c</xref>) by removing the top nodes of the model (i.e. <inline-formula><alternatives><mml:math id="inf7"><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:math><tex-math id="inft7">\begin{document}$kmu$\end{document}</tex-math></alternatives></inline-formula> or <inline-formula><alternatives><mml:math id="inf8"><mml:mi>v</mml:mi><mml:mi>s</mml:mi></mml:math><tex-math id="inft8">\begin{document}$vs$\end{document}</tex-math></alternatives></inline-formula> respectively). Removing these nodes forces the BOM to estimate the mean volatility or noise across all task blocks rather than estimating local periods where they are higher or lower (see <xref ref-type="video" rid="video1">Animation 1</xref>). As illustrated in <xref ref-type="fig" rid="fig3">Figure 3g–h</xref>, neither of these lesions recapitulates the pattern of learning rates observed in participants, with the volatility lesioned model attributing increased volatility to noise and thus decreasing its learning rate during periods of higher volatility (main effect of volatility; F(1,696)=11.9, p&lt;0.001) and the SD-lesioned model treating any form of uncertainty as volatility and thus increasing its learning rate in response to increased noise (main effect of noise; F(1,696)=227, p&lt;0.001). This suggests that human participants are able to adapt to changes in outcome volatility and noise to some degree, but are less sensitive to these changes than the intact BOM.</p><media mimetype="video" mime-subtype="gif" id="video1" xlink:href="elife-103734-animation1-v1.gif"><label>Animation 1.</label><caption><title>Estimation of the causes of uncertainty by the Bayesian Observer Model.</title><p>Lower right panel: Synthetic data with periods of high (trial number: 0-60; 120-180; 240-360) and low (trial number: 60-120; 180-240) volatility and high (trial number: 180-240) and low (trial number: 1-180; 240-360) noise was provided to the Bayesian Observer Models. The models trial-by-trial estimate of volatility and noise is illustrated by marginalising over all but the <italic>vmu</italic> and <italic>SD</italic> dimensions of the joint probability distribution (see description of the Bayesian Observer Model in the methods). This produces a two-dimensional probability density of the model’s estimate of volatility (y-axes) and noise (x-axes). The current data being fed to the model is illustrated by the solid line moving through the data. Top left panel: The estimated uncertainty of the full (unlesioned) model. The model adapts to different periods of high and low volatility reasonably well (e.g. see the period around trial 180 when the data moves from high volatility/low noise to high noise/low volatility). The fully lesioned models are provided for comparison (see methods section for a description of these models). Top right panel: The noise blind model (<italic>vSD</italic> has been removed) cannot account for changes in noise and so any change in either volatility or noise is captured as a change in volatility. Lower left panel: The volatility blind model (<italic>kmu</italic> has been removed) cannot account for changes in volatility and so any change in either volatility or noise is captured as a change in noise.</p></caption></media><p>We next assessed whether a relative degrading of the model’s representation of volatility and noise (<xref ref-type="fig" rid="fig3">Figure 3d</xref>) altered its behaviour in a manner similar to participants. This was achieved by independently coarsening the model’s representation of volatility and noise, with the degree of coarsening selected to make the model’s choices as similar as possible to those of a given participant. Details of this coarsening process are provided in the methods section, but in simple terms, at one extreme, the intact model’s beliefs about current volatility and noise are represented as probability distributions over many possible values, with the number of values used gradually reduced during coarsening, until the coarsest model treats each form of uncertainty as being either ‘high’ or ‘low.’ As can be seen from <xref ref-type="fig" rid="fig3">Figure 3i</xref>, this relative degrading of the model’s representation of uncertainty more closely recapitulated the learning rates observed in participants, with a significant increase in learning rate in response to increased volatility (F(1,696)=59, p&lt;0.001) and no effect of noise (F(1,696)=2.3, p=0.13). In total, the BOM fitted to participant choices had five parameters (i.e. volatility and SD acuity for rewards and losses and a single inverse temperature term). This was compared with two reinforcement learning models: the measurement model described previously, which was fitted to individual blocks and, therefore, had many more parameters (18 in total; learning rates for wins and losses for each block, one inverse temperature term per block), and a simple version of the same model which was fitted across all blocks and had three parameters in total (win and loss LR and one inverse temperature parameter). Model comparison between the BOM and the RW models based on BIC scores favoured the BOM (mean (SD) for BOM; 235 (54), for complex RL measurement model; 281 (57), for simple RL model; 246 (58)).</p><p>In the next sections, we characterise how coarsening the BOM changes its behaviour and assess whether it provides an accurate account of participants’ noise insensitivity.</p></sec><sec id="s2-5"><title>The degraded BOM misattributes noise as volatility</title><p>The BOM was degraded by reducing the number of bins it used to represent volatility and/or noise, until its behaviour most closely matched that of participants. This process led to a greater coarsening of the noise than the volatility dimension (<xref ref-type="fig" rid="fig4">Figure 4a</xref>; F(1,69)=49, p&lt;0.001), with no effect of outcome valence (F(1,69)=0.73, p=0.4), suggesting that the degraded model maintained a generally less precise representation of noise than volatility. In order to investigate the impact of this coarsening on the model’s beliefs, we used the degraded BOM’s estimates of volatility and noise to categorise task trials as either high or low volatility/noise (i.e. trials in which the model’s estimates of these variables were higher/lower than the mean) and compared these to the same trial labels generated by the intact BOM. Consistent with the greater degradation of the noise dimension, coarsening the model caused it to miscategorise more trials which the intact BOM had labelled as having high than low noise (<xref ref-type="fig" rid="fig4">Figure 4b</xref>; F(1,69)=30.7, p&lt;0.01) with no effect of volatility (F(1,69)=1.9, p=0.17) or outcome valence (F(1,69)=0.004, p=0.95). As illustrated in <xref ref-type="fig" rid="fig4">Figure 4c</xref>, when the degraded BOM miscategorised high noise trials, it tended to label them as having high, rather than low, volatility. Overall, these results indicate that coarsening the BOM caused it, relative to the intact BOM, to misattribute high noise trials as high volatility trials.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Analysis of the behaviour of the degraded Bayesian observer model (BOM).</title><p>The process of degrading the BOM involved reducing the number of bins used to represent the volatility and noise dimensions independently until the choice of the model matched that of participants. Panel (<bold>a</bold>) illustrates the number of bins selected by this process for the volatility and noise dimensions (averaged across win and loss outcomes). As can be seen, the degraded BOM maintained a less precise representation of noise than volatility. In order to understand the behaviour of the degraded model, the model’s estimated <inline-formula><alternatives><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft9">\begin{document}$vmu_{i}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft10">\begin{document}$SD_{i}$\end{document}</tex-math></alternatives></inline-formula> were used to label individual trials as high/low volatility and noise (NB greater than or less than the mean value of the estimates). These trial labels were compared with the same labels from the intact model, which were used as an ideal comparator (panels <bold>b</bold> and <bold>c</bold>). Panel <bold>b</bold> illustrates the proportion of trials in which the labels of the two models agreed, arranged by the ground truth labels of the full model and averaged across win and loss outcomes. The dotted line indicates the agreement expected by chance. The degraded model trial labels differed from those of the full model particularly for high noise trials, with no impact of trial volatility. Panel <bold>c</bold> provides more details on how the degraded model misattributes trials. In this figure, the labels assigned by the full model are arranged along the x-axis. The colour of each square represents the proportion of trials with a specific full model label that received the indicated label of the degraded model (arranged along the y-axis). The diagonal squares illustrate agreement between models as reported in panel (<bold>b</bold>). As highlighted by the red outlines, trials which the full model labelled as having high noise were generally mislabelled by the degraded model as having high volatility. Reanalysis of participant choices using the trial labels provided by the full (panel <bold>e</bold>) and degraded (panel <bold>f</bold>) models indicates that participants adapt their learning rates in a normative fashion when the degraded model trial labels are used (panel <bold>f</bold>), but not when the full model labels are used (panel <bold>e</bold>). Panel (<bold>d</bold>) illustrates the same analysis using the original task block labels for comparison. Bars represent the mean (± SEM) of participant learning rates, with raw data points presented as circles behind each bar. See <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for a comparison of the behaviour of the degraded BOM with an alternative fitted model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Comparison of the degraded volatility/noise Bayesian observer model (BOM) and a control model (‘mu model’) in which the representation of the mean of the generative process, rather than the volatility/noise are degraded.</title><p>Panel a illustrates the behaviour of participants in the task (as reported in main text <xref ref-type="fig" rid="fig2">Figure 2</xref>). Panel b illustrates the behaviour of the degraded volatility/noise model (as reported in main text <xref ref-type="fig" rid="fig3">Figure 3</xref>) and panel d illustrates that participants are behaving normatively if we assume that they are using a similar estimate of volatility and noise as the degraded volatility/noise model (as reported in main text <xref ref-type="fig" rid="fig4">Figure 4</xref>). Panel <bold>c</bold> illustrates that the mu model does not recapitulate participant behaviour and panel e shows that, assuming participants use similar estimates of volatility/noise as the mu model does not rescue normative behaviour.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Performance of the degraded Bayesian observer model (BOM) on schedules derived from <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>.</title><p>Example high and low noise schedules used (panel a, blue line low noise schedule, red line high noise schedule). Volatility is generated by jumps in the mean of the generative process that occur with a probability of 0.1 on each trial, after at least three trials have passed since the last jump. Noise is added by drawing samples from a Gaussian distribution centred on this mean, using an SD of either 10 (high SD) or 5 (low SD). As can be seen, changes in the magnitude of the outcome produced by volatility are substantially larger than those caused by noise. The performance of the degraded BOM on this task was estimated by passing generated schedules from this task to the BOM (using the noise/volatility bins estimated for participants in the current study, 20 schedules were used per participant). Estimating learning rate from the task for a specific individual and schedule (panel <bold>b</bold>). Unlike the task reported in the current paper, the outcome of the Nassar et al. paper was continuous (the subsequent value was predicted). This allows the effective learning rate used in high and low SD blocks to be estimated as the slope of the line linking trialwise belief update (i.e. change in prediction of the model) and prediction error. The degraded model uses a higher learning rate when noise is low than when it is high in the Nassar task (panel <bold>c</bold>). The estimated learning rates for high and low SD blocks illustrated for all participants and all schedules. As can be seen, and as reported by Nassar et al., the degraded model uses a higher learning rate when SD is small (t(69)=3.6, p=0.0006). The degree to which the degraded BOM increased its learning rate in low relative to high SD blocks was significantly associated with the precision with which it represented noise (panel <bold>d</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig4-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-6"><title>The degraded BOM rescues optimal behaviour</title><p>The process of fitting the degraded BOM to participant behaviour can be understood as searching for a configuration of the model (akin to a grid-based maximum likelihood estimation) in which participant choice conforms to the normative response to volatility and noise coded in the model’s structure. In other words, participants’ learning rates should increase when the degraded BOM’s estimate of volatility is high and, critically, when it estimates that noise is low. We demonstrate this by reanalysing participant behaviour, using the trial labels of the degraded BOM to indicate periods of low/high volatility and noise in place of the task block labels used in the original analysis. In effect, this approach allows us to test whether participants make internally consistent errors during learning, i.e., reducing their learning rates for outcomes that they thought — instead of the actual task structure — were associated with high volatility and/or low noise. As can be seen (<xref ref-type="fig" rid="fig4">Figure 4f</xref>), participants significantly increased their learning rate when the degraded BOM estimated volatility to be high (F(1,566)=86, p&lt;0.001) and noise to be low (F(1,566)=81, p&lt;0.001). In control analyses, this normative response to uncertainty was not seen when the labels from the intact rather than the degraded BOM were used (<xref ref-type="fig" rid="fig4">Figure 4e</xref>), or when the BOM’s representation of outcome mean was degraded, rather than its estimates of volatility and noise (supplementary materials).</p></sec><sec id="s2-7"><title>Assuming human participants use the degraded BOM’s estimates of volatility and noise also rescues normative pupillary response</title><p>If the degraded BOM is a fair representation of how participants are performing the learning task, then we would expect it to be better able to explain physiological markers of uncertainty estimation than the simple task block structure or the intact BOM. Specifically, participants’ pupils should be larger when the degraded BOM thinks that volatility is high and when it thinks noise is low. We first show (<xref ref-type="fig" rid="fig5">Figure 5a–c</xref>) that participants’ pupils do not adapt normatively to the task block structure, with no main effect of block volatility (F(1,1723)=0.002, p=0.9) and an increase of pupil size in response to higher noise (F(1,1723)=13.8 p&lt;0.001). In contrast, analysis using the trial labels derived from the degraded model (<xref ref-type="fig" rid="fig5">Figure 5d–f</xref>) recovered the expected increase in pupil size in response to both raised volatility (F(1,2067)=105, p&lt;0.001) and reduced noise (F(1,2067)=42.3, p&lt;0.001) suggesting that the model provides a reasonable measure of participants’ estimates of these parameters. Finally, we tested whether the degraded BOM was able to explain more variance in the pupil data than the intact BOM. In order to do this, we first regressed participants’ pupil data against the estimated volatility and noise of the intact BOM, as well as a range of other task- related factors (<xref ref-type="fig" rid="fig5">Figure 5g</xref>; see methods for more details of analysis). Having removed the variance accounted for by these factors, we then regressed the residuals of this first level analysis against the degraded model’s estimates of volatility and noise. This second level analysis (<xref ref-type="fig" rid="fig5">Figure 5h–i</xref>) indicated that the degraded model was able to account for variance associated with outcome noise that was not explained by the full model (F(1,286)=4.1, p=0.04), but did not explain additional variance associated with outcome volatility (F(1,286)=0.1, p=0.75). In summary, assuming that participants used the degraded BOM’s estimates of outcome volatility and noise rescued the normative pattern of physiological adaptation during the task.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Analysis of pupillometry data.</title><p>Z-scored pupil area from 2 s before to 6 s after win (panel <bold>a</bold>) and loss (panel <bold>b</bold>) outcomes, split by task block. Lines illustrate average size, with shaded area illustrating SEM. Panel <bold>c</bold> Pupil size averaged across whole outcome period and both win and loss outcomes. Pupil size did not systematically vary by task block. Panels (<bold>d-f</bold>) as above but using the trial labels derived from the degraded model. Pupil size was significantly larger for trials labelled as having high vs. low volatility and low vs. high noise. Panel (<bold>g</bold>) displays the mean (SEM) effect of volatility and noise as estimated by the full BOM derived from a regression analysis of pupil data. The residuals from this analysis were then regressed against the estimated volatility and noise from the degraded model. A time course of the regression weights from this analysis is shown in panel <bold>h</bold>, with the mean coefficients across the whole period shown in panel <bold>i</bold>. The degraded model’s estimated noise accounted for a significant amount of variance not captured by the full model (pink line in <bold>h</bold> is below 0, the mean effect across the period is represented by dashed lines and arrows in panel <bold>i</bold>). See <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for comparison of the degraded BOM with an alternative fitted model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Comparison of the degraded volatility/noise Bayesian observer model (BOM) and the mu BOM on analysis of the pupillometry data.</title><p>As reported in main <xref ref-type="fig" rid="fig5">Figure 5</xref>, the intact BOM explains variance in pupil signal attributable to both volatility and noise (panel a), with the degraded BOM explaining additional variance over and above this, attributable to noise (panels b and d). In contrast, the mu model does not explain additional variance over and above the full model (panels c and e).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-103734-fig5-figsupp1-v1.tif"/></fig></fig-group></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Humans respond in a rational, if approximate, manner to the causal statistics of dynamic environments. We found that participants adapted as expected to changes in outcome volatility, but were relatively insensitive to changes in noise. Using a degraded BOM to characterise participants’ behaviour suggested that they responded appropriately to a relatively coarse estimation of the level of noise, that led to its misattribution as volatility. Analysis of pupillometry data using the degraded model again suggested that participants were responding normatively to changes in estimated noise, but that these estimates diverged from the true noise of experienced outcomes. These results illustrate that human learners are able to adapt to the statistical properties of their environment, but during this process, they make internally consistent errors, utilising higher learning rates as a result of misattributing environmental noise as volatility which also leads to suboptimal choice.</p><p>Using a task in which volatility and noise varied independently between blocks, we found that human learners adapted as expected (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib22">Pulcu and Browning, 2019</xref>) to blockwise changes in the volatility of both win and loss outcomes, increasing the learning rate used when volatility was high vs. low. In contrast, the expected reduction of learning rates in response to increased outcome noise was not apparent, with participants employing a significantly higher learning rate in response to increased noise when volatility was low and a numerically lower learning rate when volatility was high. The absence of a normative response to blockwise changes in noise is at odds with previous work which has described a reduction in learning rates during periods of high noise (<xref ref-type="bibr" rid="bib7">Diederen and Schultz, 2015</xref>; <xref ref-type="bibr" rid="bib16">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>). However, in this previous work the level of noise was either explicitly presented to participants (as a bar on screen representing the standard deviation of the generative process in Diederen &amp; Schultz) or was made unambiguous by being very different from changes caused by volatility (in Nassar et al, noise was generated using an SD of 5 or 10, while the average change due to volatility was 100). By design, in the current task, high noise and volatility resulted in a similar range of magnitudes (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) forcing participants to use the temporal sequence of outcomes to discriminate between the different forms of uncertainty. Our behavioural results suggest that, in the absence of unambiguous differences between outcomes caused by volatility and those caused by noise, participants’ ability to estimate and/or adapt to changes in noise is reduced. Interestingly, a recent study reported that participants do not adjust their choice or estimated confidence in response to variability in the orientation of arrays of visual gratings (<xref ref-type="bibr" rid="bib9">Herce Castañón et al., 2019</xref>), suggesting that an insensitivity to outcome noise may be a general feature of human decision making, rather than a specific component of learning.</p><p>Noise fundamentally limits the reliability of information (<xref ref-type="bibr" rid="bib14">MacKay, 2003</xref>) and ignoring it has a clear detrimental impact on inference (<xref ref-type="fig" rid="fig3">Figure 3h</xref>), causing agents to be unnecessarily influenced by chance events (<xref ref-type="bibr" rid="bib22">Pulcu and Browning, 2019</xref>). It would, therefore, be surprising if human learners were completely insensitive to this process, particularly given evidence that they can respond normatively when the level of noise is unambiguous (<xref ref-type="bibr" rid="bib7">Diederen and Schultz, 2015</xref>; <xref ref-type="bibr" rid="bib16">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>). We developed an ideal (BOM; <xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib16">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib19">Piray and Daw, 2021</xref>; <xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref>) to investigate the degree to which participants were adapting to noise. The intact BOM displayed the expected behavioural response to changes in both volatility and noise (<xref ref-type="fig" rid="fig3">Figure 3f</xref>) and, as a result, did not accurately capture the behaviour of participants (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). Completely removing the BOM’s ability to adapt to noise (or volatility) did not recapitulate participant choice behaviour (<xref ref-type="fig" rid="fig3">Figure 3g–h</xref>), whereas coarsening its representation of volatility and noise, produced a much closer match (<xref ref-type="fig" rid="fig3">Figure 3i</xref>). This suggests that participants were relatively, rather than completely insensitive to noise and that they tended to misattribute high noise as volatility (<xref ref-type="fig" rid="fig4">Figure 4</xref>). However, an important caveat to this interpretation is that the degree of coarsening was selected using participants’ choices. The better behavioural match of the coarsened BOM to participant learning rates may, therefore, be simply because this model was fitted to the same choices used to calculate the learning rates, whereas the intact and fully lesioned models were not. We, therefore, sought to validate the coarsened BOM by assessing its ability to account for participants’ pupillary data, and by comparing it with an alternative fitted BOM which coarsened the representation of the generative mean, rather than the estimated uncertainty (see Supplementary materials). Participants’ pupil size did not vary systematically between different block types, whereas they were significantly larger when the degraded BOM estimated volatility to be high and noise to be low (<xref ref-type="fig" rid="fig5">Figure 5a–f</xref>). Similarly, the estimated noise of the degraded BOM accounted for additional variance in pupil size, over and above the intact BOM (<xref ref-type="fig" rid="fig5">Figure 5g–i</xref>). In contrast, the alternative mean-degraded BOM did not recapitulate participants’ learning rates (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) and was not able to account for changes in participant pupil size (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). The finding that participants’ pupil size covaries in the expected direction with the degraded BOM’s estimated levels of both volatility and noise provides some reassurance that the model is capturing the dynamics of participants’ uncertainty estimates. More generally, the presence of both volatility and noise signals in this data, indicate that, as suggested previously (<xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="bib18">O’Reilly et al., 2013</xref>), the pupillometry signal reflects general belief updating rather than specifically volatility.</p><p>An outstanding question is why participants might be particularly insensitive to changes in outcome noise. It is tempting to try to answer this question by reference to the processes by which the BOM was coarsened (i.e. the insensitivity was caused by a reduction in the precision by which noise was represented in a multi-dimensional probability distribution). However, the BOM described here was developed as an algorithmic description of how the learning task may be solved. As far as we are aware, there is little evidence that it accurately describes the cognitive or neural implementation of uncertainty estimation. Alternative algorithmic approaches to the general problem of uncertainty estimation have been described (<xref ref-type="bibr" rid="bib11">Kalman, 1960</xref>; <xref ref-type="bibr" rid="bib16">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="bib19">Piray and Daw, 2021</xref>; <xref ref-type="bibr" rid="bib22">Pulcu and Browning, 2019</xref>), including simpler approaches that avoid computationally expensive representations of multi-dimensional distributions (<xref ref-type="bibr" rid="bib11">Kalman, 1960</xref>; <xref ref-type="bibr" rid="bib16">Nassar et al., 2010</xref>) and which, therefore, may be more likely implementational candidates. In other words, the current results indicate that human learners are relatively insensitive to changes in outcome noise, but do not specify the lower level mechanisms that determine this effect.</p><p>Previous work examining the neural representations of uncertainty has tended to report correlations between brain activity and some task-based estimate of one form of uncertainty at a time (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib25">Walker et al., 2020</xref>; <xref ref-type="bibr" rid="bib26">Walker et al., 2023</xref>). We are not aware of work that has, for example, systematically varied volatility and noise and reported distinct correlations for each. An interesting possibility as to how different forms of uncertainty may be encoded is suggested by parallels with the neuronal decoding literature. One question addressed by this literature is how the brain decodes changes in the world from the distributed, noisy neural responses to those changes, with a particular focus on the influence of different forms of between-neuron correlation (<xref ref-type="bibr" rid="bib1">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="bib12">Kohn et al., 2016</xref>). Specifically, signal-correlation, the degree to which different neurons represent similar external quantities (required to track volatility) is distinguished from, and often limited by, noise-correlation, the degree to which the activity of different neurons covaries independently of these external quantities. One possibility relevant to the current study, which resembles the underlying logic of the BOM, is that a population of neurons represents the estimated mean of the generative process that produces task outcomes. In this case, volatility would be tracked as the signal-correlation across this population, whereas noise would be analogous to the noise-correlation and, crucially, misestimation of noise as volatility might arise as misestimation of these two forms of correlation. While the current study clearly cannot adjudicate on the neural representation of these processes, our finding of distinct behavioural and physiological responses to the two forms of uncertainty, does suggest that separable neural representations of uncertainty are maintained.</p><p>A related question is whether other, non-Bayesian model formulations may be able to account for participants’ learning adaptation in response to volatility and noise. Of note, the reinforcement learning model used to measure learning rates in separate blocks does not achieve this goal—as this model is fitted separately to each block rather than adapting between blocks (NB the simple reinforcement learning model that is fitted across all blocks does not capture participant behaviour, see supplementary information). One candidate class of model that has potential here is latent-state models (<xref ref-type="bibr" rid="bib5">Cochran and Cisler, 2019</xref>), in which the variance and unexpected changes in the process being learned (which have a degree of similarity with noise and volatility, respectively) is estimated and used to alter the model’s rates of updating as well as the estimated number of states being considered. Using the model described by Cochran and Cisler, we were unable to replicate the learning rate adaptation demonstrated by participants in the current study (see Supplementary information), although it remains possible that other latent state formulations may be more successful.</p><p>In conclusion, human learners adapt rationally to estimates of the volatility and noise of experienced outcomes. However, these estimates are approximate leading to a relative insensitivity to outcome noise.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Experimental model and subject details</title><sec id="s4-1-1"><title>Participants</title><p>70 English-speaking participants aged between 18 and 65 were recruited from the general public using print and online advertisements. A previous study (<xref ref-type="bibr" rid="bib21">Pulcu and Browning, 2017</xref>) on behavioural response to changes in volatility reported an effect size of <italic>d</italic>=0.7. As the effect size of a noise manipulation was not clear, we recruited a sample size sufficient to detect an effect size of half this value (<italic>d</italic>=0.35) with 80% power. Participants were excluded from the study if they had any psychological or neurological disorders or were currently on psychotropic medication. No exclusion criteria related to task performance were used.</p></sec></sec><sec id="s4-2"><title>Method details</title><sec id="s4-2-1"><title>General procedure</title><p>Participants attended a single study visit during which they completed the learning task. The study was approved by the University of Oxford Central Research Ethics Committee (R49753/RE001). All participants provided written informed consent to take part in the study, in accordance with the Declaration of Helsinki.</p></sec><sec id="s4-2-2"><title>Behavioural paradigm</title><p>The reinforcement learning (RL) task consisted of six blocks, each comprising 60 trials. In each trial, participants were presented with two abstract shapes taken from the Agathodaimon font (i.e. shape A and shape B). Two different shapes were used in each block, with rest sessions between blocks. The shapes were presented randomly on either side of the screen. Participants were explicitly instructed that this randomised location did not influence the outcome magnitudes. Participants attempted to accumulate as much money as possible by learning the likely magnitude of the wins and losses associated with each shape and using this information to guide their choice. On each trial, participants chose one of two shapes, with their choice highlighted by a black frame (see <xref ref-type="fig" rid="fig1">Figure 1a</xref>). Following the choice, the win and loss amounts associated with the chosen shape were presented, in randomised order, for a jittered period (2–6 s, mean: 4 s) inside two empty bars, above and below the fixation cross. The win amount was shown as a green area in the upper bar, and the loss amount was represented as a red area in the lower bar. The total length of each bar represented £1 (i.e. of wins or losses) and thus the amount associated with the chosen shape was the proportion of the bar filled by the green/red areas (e.g. three quarters of the upper bar being green, would mean that the chosen option was associated with a win of 75 p). Participants were informed that the unshaded area of each bar was the amount associated with the unchosen option. Thus, on each trial, participants knew how much they had won/lost and how much they would have won/lost if they had chosen the other option. This feature simplified the task; rather than having to separately estimate the wins and losses associated with each shape, participants only had to estimate these values for one shape (with the other shape being £1 minus this value). For each trial, participants received the difference between the win and loss amounts associated with their choice. A running total amount of money was displayed in the centre of the screen, under the bars, and was updated at the beginning of the subsequent trial with the recent winnings. Participants were informed that the task would be split into six blocks, that they had to learn which was the best option to choose, and that this option may change over time. They were not informed about the different forms of uncertainty we were investigating or of the underlying structure of the task (that uncertainty varied between blocks).</p><p>The wins and the losses associated with each shape followed independent outcome schedules (<xref ref-type="fig" rid="fig1">Figure 1b</xref>), generated from a Gaussian distribution. In each block, the win and loss outcomes had either high or low volatility and high or low noise. When volatility was low, the mean of the Gaussian distribution remained constant, when volatility was high, the mean changed between 25–40, and 60–75 every 9–15 trials. When noise was low, the standard deviation of the Gaussian was set to 5, whereas when noise was high, the standard deviation was 35. As can be seen from <xref ref-type="fig" rid="fig1">Figure 1b</xref>, these schedules resulted in similar ranges of outcome magnitudes for periods of high noise and high volatility. The first block for every participant had high volatility and low noise for both win and loss outcomes and was used to familiarise participants with the task. Choices from this block were not used in the analyses presented (although including them does not alter the reported pattern of results). The schedules in the remaining five blocks were presented in a randomised order with the constraint that, across both win and loss outcomes, each of the four combinations of volatility and noise level (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) was presented either 2 or 3 times. Thus, while each participant completed at least two blocks with each of the four combinations of high/low volatility/noise, the specific pairings of win and loss volatility/noise levels, differed across participants. This approach was used in preference to a fully factorial design in order to keep the total task duration to a manageable level. At the end of the experiment, participants were paid one-fifth of their total winnings, plus a £15 baseline rate for turning up to take part.</p><p>Pupillometry data was collected for 36 of the 70 participants. During the collection of pupillary data, the task was presented on a VGA monitor connected to a laptop computer running Presentation software version 18.3 (Neurobehavioural Systems). An identical behavioural version of the task, presented using Psychtoolbox 3.0 on MATLAB (MathWorks Inc), was used to collect behavioural data from the remaining 34 participants. In the pupillometry version, participants’ heads were stabilised using a head-and-chin rest placed 70 cm from the screen on which the eye tracking system was mounted (Eyelink 1000 Plus; SR Research). The eye tracking device was configured to record the coordinates of both of the eyes and the pupil area at a rate of 500 Hz. The task stimuli were drawn on either side of a fixation cross which marked the middle of the screen and were offset by 7° visual angle. The testing session lasted approximately 70 min per participant.</p></sec></sec><sec id="s4-3"><title>Analysis of choice data</title><sec id="s4-3-1"><title>Non-model-based measure of the influence of outcomes</title><p>The manipulation of uncertainty in the reinforcement learning task is expected to alter the degree to which participants’ choices are influenced by the outcomes they experience. A simple, if somewhat crude, measure of this influence can be calculated as the proportion of trials in a block in which participants select the choice prompted by the win or loss outcomes on the previous trial. Generally, win outcomes of &gt;50 p and loss outcomes of &lt;50 p associated with a shape will prompt selection of the same shape on the next trial, whereas other outcomes will prompt selection of the alternative shape. The overall effect of win outcomes on choice can, therefore, be estimated as:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>==</mml:mo><mml:mi>A</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>A</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>50</mml:mn><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>==</mml:mo><mml:mi>A</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>A</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>50</mml:mn><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  P_{\left (choice==A\ |\ previous\ win\ outcome\ for\ A\gt 50p\right)}-P_{\left (choice==A\ |previous\ win\ outcome\ for\ A\lt 50p\right)}$$\end{document}</tex-math></alternatives></disp-formula></p><p>That is, the probability of choosing shape A, given that, on the previous trial, a win of &gt;50 p was associated with shape A – the probability of choosing Shape A, given that, on the previous trial a win of &lt;50 p was associated with Shape A. Similarly, the effect of loss outcomes is estimated as:<disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>==</mml:mo><mml:mi>A</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>A</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>50</mml:mn><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>==</mml:mo><mml:mi>A</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mtext> </mml:mtext><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>A</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>50</mml:mn><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  P_{\left (choice==A\ |\ previous\ loss\ outcome\ for\ A\lt 50p\right)}-P_{\left (choice==A\ |previous\ loss\ outcome\ for\ A\gt 50p\right)}$$\end{document}</tex-math></alternatives></disp-formula></p><p>However, choice is also influenced by the magnitude of the outcome; a win of 90 p will have a greater effect on subsequent choice than a win of 55 p. Blocks with high levels of either volatility or noise have more extreme magnitudes than blocks with low levels of both (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) which will bias any comparison of this metric between blocks. In order to limit the effect of this bias, we estimated the simple choice metric only for trials in which the previous outcome lay in the range of magnitudes common to all four blocks, 35–65.</p></sec><sec id="s4-3-2"><title>Reinforcement learning model</title><p>While the choice metric described above provides a relatively transparent measure of the influence of task outcomes on choice, it does not account for differences in outcome magnitude making it liable to bias. We, therefore fitted a simple reinforcement learning model to measure block-wise learning rates, which provide a more principled estimate of the degree to which choices are influenced by outcomes. The model combines a learning phase in which the magnitude of wins and losses associated with a shape are estimated (note that it is not necessary to learn the magnitudes associated with the other shape, as these are simply 1- those described below)<disp-formula id="equ3"><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>Q</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  Qwin\_ a_{\left (t+1\right)}=Qwin\_ a_{\left (t\right)}+\alpha _{win}\left (win_{\left (t\right)}-Q_{win\_ a\left (t\right)}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ4"><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>Q</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  Qloss\_ a_{\left (t+1\right)}=Qloss\_ a_{\left (t\right)}+\alpha _{loss}\left (loss_{\left (t\right)}-Q_{loss\_ a\left (t\right)}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>In these equations,<inline-formula><alternatives><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="normal">_</mml:mi></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft11">\begin{document}$Qwin\mathrm{\_} a_{\left (t\right)}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">_</mml:mi></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft12">\begin{document}$Qloss\mathrm{\_} a_{\left (t\right)}$\end{document}</tex-math></alternatives></inline-formula> are the estimated win and loss magnitudes associated with Shape A on trial <italic>t,</italic> <inline-formula><alternatives><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math><tex-math id="inft13">\begin{document}$win_{\left (t\right)}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math><tex-math id="inft14">\begin{document}$loss_{\left (t\right)}$\end{document}</tex-math></alternatives></inline-formula> are the observed win and loss outcome magnitudes and <inline-formula><alternatives><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft15">\begin{document}$\alpha _{win}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft16">\begin{document}$\alpha _{loss}$\end{document}</tex-math></alternatives></inline-formula> are the win and loss learning rates. These values are then combined in a decision phase such that:<disp-formula id="equ5"><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  Pchoice\_ a_{\left (t\right)}=\frac{1}{1+e^{-\beta \left (Q_{win\_ a\left (t\right)}-Q_{loss\_ a\left (t\right)}\right)}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mi mathvariant="normal">_</mml:mi></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft17">\begin{document}$Pchoice\mathrm{\_} a_{\left (t\right)}$\end{document}</tex-math></alternatives></inline-formula> is the probability that Shape A will be chosen on trial <italic>t</italic> and <inline-formula><alternatives><mml:math id="inf18"><mml:mi>β</mml:mi></mml:math><tex-math id="inft18">\begin{document}$\beta $\end{document}</tex-math></alternatives></inline-formula> is a single inverse decision temperature. This model was initiated with <inline-formula><alternatives><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="normal">_</mml:mi></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}$Qwin\mathrm{\_} a_{\left (0\right)}$\end{document}</tex-math></alternatives></inline-formula> = <inline-formula><alternatives><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Q</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mi mathvariant="normal">_</mml:mi></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}$Qloss\mathrm{\_} a_{\left (0\right)}$\end{document}</tex-math></alternatives></inline-formula>=0.5 and the three free parameters (<inline-formula><alternatives><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math><tex-math id="inft21">\begin{document}$win_{\left (t\right)}$\end{document}</tex-math></alternatives></inline-formula><italic>,</italic><inline-formula><alternatives><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub></mml:math><tex-math id="inft22">\begin{document}$loss_{\left (t\right)}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf23"><mml:mi>β</mml:mi></mml:math><tex-math id="inft23">\begin{document}$\beta $\end{document}</tex-math></alternatives></inline-formula>) were estimated for each block and each participant by calculating the joint posterior probability given participant choice, marginalising each parameter, and deriving the parameters’ expected values (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>). See supplementary materials for model selection data.</p><p>Some analyses reported in the paper (i.e. where trials are labelled as high/low volatility and high/low noise by the Bayesian Observer Model rather than by task block) cannot be modelled using this block-wise approach (as different types of trials are interleaved throughout the task, rather than blocked). In these analyses, a similar single model was fit across all trials in the task. This model had eight different learning rates (separate win and loss learning rates, for each combination of high/low volatility and high/low noise labelled trials) and a single inverse temperature parameter. Although this model is somewhat less flexible than the blockwise modelling approach (i.e. it has 8, rather than 10 learning rates, and 1 rather than 5 inverse temperatures), it produces the same pattern of results when applied to participant choices split by task block (all estimated learning rates correlate at <italic>r</italic>&gt;0.8, <xref ref-type="fig" rid="fig2">Figure 2c–d</xref> show results from blockwise fitting, <xref ref-type="fig" rid="fig3">Figure 3e</xref> from the simpler model). This simpler model was fit using stan, with 5000 burn in and 5000 estimation trials, with posterior convergence visually checked and rhat values of less than 1.1 accepted.</p><p>Note that neither of these models describe how participants adjust to different levels of volatility and noise, they simply estimate the learning rates used in each block/type of trial, which are expected to vary in response to differences in levels of uncertainty (in contrast, the Bayesian Observer Model described below does estimate uncertainty and adjust to levels of uncertainty).</p></sec><sec id="s4-3-3"><title>Bayesian observer model</title><p>A recursive, grid-based BOM was developed, similar to that described by Behrens and colleagues (<xref ref-type="bibr" rid="bib2">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref>). The BOM is based on a generative process (see <xref ref-type="fig" rid="fig3">Figure 3</xref>), and described fully in <xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref>. Below, we summarise the key aspects of the model.</p><p>The BOM assumes that the observed outcomes at a given time point <inline-formula><alternatives><mml:math id="inf24"><mml:mi>t</mml:mi></mml:math><tex-math id="inft24">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft25">\begin{document}$y_{t}$\end{document}</tex-math></alternatives></inline-formula>, are generated from a Gaussian distribution with an unknown mean, <inline-formula><alternatives><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft26">\begin{document}$\mu _{t}$\end{document}</tex-math></alternatives></inline-formula>, and standard deviation, <inline-formula><alternatives><mml:math id="inf27"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><tex-math id="inft27">\begin{document}$e^{SD_{t}}$\end{document}</tex-math></alternatives></inline-formula>, with the later producing noise in the observed outcomes (<xref ref-type="fig" rid="fig1">Figure 1b–c</xref>).<disp-formula id="equ6"><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  y_{t}\sim N\left (\mu _{t},e^{SD_{t}}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>As illustrated in <xref ref-type="fig" rid="fig1">Figure 1b–c</xref>, the mean of this distribution may change between time points, leading to volatility in the task environment, with this change described by a second level Gaussian distribution, centered on the current mean and with a standard deviation of <inline-formula><alternatives><mml:math id="inf28"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><tex-math id="inft28">\begin{document}$e^{vmu_{t}}$\end{document}</tex-math></alternatives></inline-formula>. The mean of the generative Gaussian distribution in the following trial is drawn from:<disp-formula id="equ7"><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  P\left (\mu _{t+1}\right)\sim N\left (\mu _{t},e^{vmu_{t}}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Both the noise (<inline-formula><alternatives><mml:math id="inf29"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft29">\begin{document}$SD_{t}$\end{document}</tex-math></alternatives></inline-formula>) and volatility (<inline-formula><alternatives><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft30">\begin{document}$vmu_{t}$\end{document}</tex-math></alternatives></inline-formula>) parameters can also change between time points with their change governed by Gaussian distributions centered on their current value with standard deviations of <inline-formula><alternatives><mml:math id="inf31"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft31">\begin{document}$e^{vSD}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf32"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft32">\begin{document}$e^{kmu}$\end{document}</tex-math></alternatives></inline-formula>, respectively. These higher-level parameters allow the model to account for periods in which noise and volatility are high and other periods in which they are low (for example, as caused by the uncertainty changes between task blocks).<disp-formula id="equ8"><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  P\left (vmu_{t+1}\right)\sim N\left (vmu_{t},\ e^{kmu}\right)$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ9"><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle  P\left(SD_{t+1}\right)\sim N\left (SD_{t},e^{vSD}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>The BOM estimates the joint posterior probability of the five causal parameters, given the choice outcome it has observed. The joint probability distribution at time point <inline-formula><alternatives><mml:math id="inf33"><mml:mi>t</mml:mi></mml:math><tex-math id="inft33">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> is defined as:<disp-formula id="equ10"><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle  P\left (joint_{t}\right)=P\left (mu,vmu,kmu,SD,vSD|\ y_{t-1},y_{t-2},\ \ldots ,y_{1}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>This joint probability distribution can be thought of as the BOM’s belief about the values of each parameter in the generative model. A Markovian assumption (i.e. that nodes of the model are sufficient to describe the generative process) simplifies this process and illustrates the recursive update performed by the BOM:<disp-formula id="equ11"><alternatives><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:mi>j</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mtext> </mml:mtext></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle  P\left (joint_{t}\right)=P\left (mu_{t},vmu_{t},kmu_{t},SD_{t},vSD_{t}\mathrm{\ }|\mathrm{\ }joint_{t-1},\mathrm{\ }y_{t-1}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>We initialized the joint posterior, before observation of any task outcomes as a uniform distribution. The BOM performs the update, first using Bayes’ rule to incorporate the effect of the most recently observed outcome, and then accounts for the drifting parameters by using the conditional probability of the new value of the drifting parameter, given the initial value and drift rate (See; <xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref> for a detailed account of this updating process):<disp-formula id="equ12"><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>j</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∭</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>S</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>…</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>m</mml:mi><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle   \left (joint_{t}\ |\ joint_{t-1},y_{t-1}\right)= &amp;  \iiint p\left (joint_{t-1}\ |\ y_{t-1}\right)p\left (SD_{t}\ |\ SD_{t-1},vSD\right)p\left (vmu_{t}\ |\ vmu_{t-1},kmu\right)\ldots \\ &amp;  p\left (mu_{t}\ |\ mu_{t-1},vmu_{t}\right),\ dSD_{t-1},\ dvmu_{t-1},\ dmu_{t-1}$$\end{document}</tex-math></alternatives></disp-formula></p><p>The value of each node is derived at every time point by marginalizing over all but the relevant dimension of the joint probability distribution and calculating the expected value of that dimension.</p><p>During the task, the shapes presented to participants change between each task block, which means that, at the start of each block, participants have to relearn the mean associated with each shape. This was dealt with in the BOM by flattening the mu dimension of the joint probability distribution at the start of each trial (i.e. replacing the values of the mean dimension, with the average of the joint distribution across this dimension). The effect of this is to reset the model’s belief about the actual magnitude associated with the two new shapes, while maintaining its belief about the overall volatility and noise of the outcomes.</p><p>The BOM was provided with the win and loss outcomes (as values between 0 and 1) for each trial, across all trials in the task (excluding the first practice block, although including this did not alter the pattern of results). It treated the two outcomes as independent (i.e. the win outcome did not influence estimates for the loss outcome and vice versa) and transformed the outcomes to the infinite real line using the logistic transform before estimating the posterior probability (<xref ref-type="bibr" rid="bib23">Pulcu et al., 2022</xref>).</p></sec><sec id="s4-3-4"><title>Lesioning the Bayesian observer model</title><p>A number of different lesions were applied to the BOM. First, its ability to estimate changes in either volatility or noise was removed. This was achieved simply by removing the kmu or vSD nodes from the BOM (reducing the dimensionality of the joint distribution by one in each case). The effect of this is to force the BOM to estimate the mean volatility and noise (respectively) across the whole task, rather than to modify its estimates of these parameters between trials.</p><p>The second approach induced a graded, rather than absolute, lesion. This was achieved by reducing the precision with which the BOM represented the volatility-related nodes (vmu and kmu) and/or the noise- related nodes (SD and vSD). More specifically, the BOM’s estimates of the values of each of the five nodes are encoded on a five-dimensional grid, with each dimension on the grid representing the possible range of values of a particular node, from low to high, using a fixed number of points. The probability ascribed by the model to a specific point on this dimension is the relative probability that the value of the node lies within the bin of values that is closer to the point, than to adjacent points. For example, say the value of volatility (vmu) ranged from 0 to 10 and was represented by 10 bins. In this case, volatility would be represented by a probability mass function over the 10 bins (&lt;0.5, 0.5–1.5, 1.5–2.5, …,&gt;9.5). Lesioning occurred by independently varying the number of bins used in the volatility-related and/or noise-related dimensions, from a maximum of 20, to a minimum of 2 (i.e. with only two bins, volatility/noise would be represented as simply ‘high’ or ‘low’). The degree of lesioning selected for each individual participant was determined as the number of bins for the volatility and noise dimensions that, after passing the model estimates through a softmax action selector with a single inverse temperature parameter (i.e. as described for the RL model), maximized the likelihood that the model would make the same choices as the participant, across all task blocks. This process of lesioning, therefore, progressively coarsens the BOM’s representation of the two types of uncertainty and selects the degree of coarsening that results in choices as similar as possible to participants (see supplementary materials for an alternative model that coarsens the representation of the mean values).</p></sec><sec id="s4-3-5"><title>Alternative measurement model</title><p>A reinforcement learning model with separate learning rates for win and loss outcomes and a single beta term was used to estimate the learning rates employed by participants and the BOMs in the paper. An alternative, slightly more complex version of this model, uses separate learning rates and separate beta terms for the two outcomes. This model estimates Q values in a similar manner, but uses the following approach during action selection:<disp-formula id="equ13"><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle  Pchoice\_ a_{\left (t\right)}=\frac{1}{1+e^{-\left (\beta _{win}*\left (Q_{win_{a\left (t\right)}}-0.5\right)-\beta _{loss}*\left (Q_{loss_{a\left (t\right)}}-0.5\right)\right)}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>As can be seen, two separate beta terms are used to separately weight the win and loss Q values when selecting an action.</p><p>This more complex model provided a poorer fit to participant choice data (mean AIC/BIC: 40.9/41.9) compared to the simpler model with a single beta term (mean AIC/BIC: 39.6/40.4). Furthermore, as illustrated in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, the learning rates recovered from the more complex model show the same pattern of effects when analysing participant behaviour as those demonstrated by the simpler model (main effect of volatility: <italic>F</italic>(1,696)=47.4, p&lt;0.001, main effect of noise: <italic>F</italic>(1,696)=0.37, p=0.54, interaction between volatility and noise <italic>F</italic>(1,693)=5.24, p=0.02). In summary, the simpler model provides a better fit to choice data and provides similar estimates of participant learning rates than the more complex model, therefore, the simpler model was used in the paper.</p></sec><sec id="s4-3-6"><title>Generate-recover performance of the measurement model</title><p>The ability of the measurement model to recover the three parameters it encodes (win learning rate, loss learning rate and inverse temperature) was assessed by generating synthetic choices across a range of learning rates (0.01–0.99) and inverse temperatures (1-36; NB the mean recovered beta value was 18) from a single task block and then comparing the recovered values to those used to generate the choices. These results are summarised in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> . As can be seen, all model parameters are recovered well unless the inverse temperature parameter was very low (i.e. when the choice is made relatively randomly).</p></sec><sec id="s4-3-7"><title>Effect of uncertainty manipulation on inverse temperature</title><p>The effects of uncertainty on estimated learning rates are reported in the Results section. Here, we describe the effects of the uncertainty manipulation on estimated inverse temperature (the beta parameter from the estimation model). This analysis was run as for the learning rate analysis: log- transformed beta parameters were entered into a linear mixed model with fixed factors of win volatility, win noise, loss volatility and loss noise, and random intercepts for subjects. The estimated choice inverse temperature was lower when the noise of either outcome was higher (win: F(1,345)=25.3, p&lt;0.001; loss: F(1,345)=55.7, p&lt;0.001) and was not affected by outcome volatility (p&gt;0.05). Including inverse temperature as a covariate in the analysis of participant learning rates did not influence the reported pattern of results.</p></sec><sec id="s4-3-8"><title>Analysis of a control, fitted Bayesian observer model</title><p>The degraded BOM was fit to participant choice, with the number of bins used to represent volatility and noise selected to maximise the degree to which model choice matched participant choice. We report that (a) the degraded model adjusts its learning rate in response to changes in uncertainty in a similar manner to participants, (b) that if we label trials as being high/low volatility/noise based on the internal estimates of the degraded model we are able to recover both a normative pattern of behaviour and pupil response from participant data. We use these results to argue that the degraded model provides useful information about how participants estimate and adjust to changes in uncertainty.</p><p>In the following section we test whether the ability of the degraded model to produce these results depends on how it represents uncertainty (i.e. changes to the volatility/noise nodes) or whether a similar effect is produced by degrading its estimation of the other node which influences its behaviour, the mean of the generative process (i.e. <italic>mu</italic>). The degrading of the <italic>mu</italic> node was achieved as described in the main text for the volatility/noise, the number of bins used to represent the node were varied, to maximise the likelihood of the model producing the same choice as participants. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> summarises the analysis of the behavioural data, comparing it to the behaviour of participants (panel a) and the volatility/noise model described in the main paper (panels b &amp; d). As can be seen, whereas the volatility/noise degraded model (panel b) replicates participants’ response to changes in uncertainty (panel a), the fitted mu model does not. After fitting to participant behaviour, the mu model uses generally lower learning rates than participants, and specifically shows a higher learning rate when volatility increases (<italic>F</italic>(1,696)=84.5, p&lt;0.001), but also a lower learning rate when noise is increased (<italic>F</italic>(1,696)=3.9, p=0.049). As described in the main paper, participants do not show this expected reduction in learning rates when noise is raised.</p><p>Similarly, unlike the degraded volatility/noise model, using the mu model’s estimates of volatility and noise to label trials and then reanalysing participant data did not produce normative behaviour, with an interaction found between volatility and noise (<italic>F</italic>(1,537)=7.2, p=0.008) arising from a significantly lower learning rate with higher noise when volatility was high (<italic>F</italic>(1,277)=11.4, p&lt;0.001) and a non-significant increase in learning rates with higher noise when volatility was low (<italic>F</italic>(1,277)=0.007, p=0.93; Figure panel e).</p><p>Next, we assessed the performance of the mu model on the analysis of the pupillometry data, and specifically, whether it explained variance in this data over and above the unfitted, full model. As illustrated in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, whereas the degraded volatility/noise model explained extra variance associated with its estimate of noise (see main <xref ref-type="fig" rid="fig5">Figure 5</xref>), the mu model did not explain additional variance in this data at all (additional effect explained by volatility <italic>F</italic>(1,286)=0.01, p=0.9; additional effect explained by noise <italic>F</italic>(1,286)=0.38, p=0.54).</p><p>Overall, the ability of the degraded model in the main paper to account for participant choice behaviour and changes in pupil size are not replicated when the fitting process influences a non-uncertainty related node (<italic>mu</italic>).</p></sec><sec id="s4-3-9"><title>Does the degraded BOM replicate the effect of noise reported in <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>?</title><p>In the main text, we suggest that <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref> observed an increase in learning rate during low relative to high noise trials because in their schedule, noise produced a significantly smaller effect on outcomes than volatility (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). If this is the case, then we might expect the degraded BOM used in the current study to also show the appropriate learning rate adaptation to changes in noise, if presented with the schedules used in Nassar. <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> illustrates the results of this analysis, which indicated that the degraded BOM did indeed show an increase in learning rate in low relative to high SD blocks (<italic>t</italic>(69)=3.6, p=0.0006). Consistent with the effects reported in the main paper we found that the number of bins used by the degraded model to represent noise was positively associated with the degree to which the model adapted it learning rate in the expected direction (controlling for the bins used to represent volatility), rparital<sub>parital</sub> = 4.1, p&lt;0.001, while the number of bins used to represent volatility was not significant, rparital<sub>parital</sub> = −0.04, p=0.16.</p></sec><sec id="s4-3-10"><title>Performance of an alternative, latent state model</title><p>An alternative approach to the estimation of volatility and noise is provided by latent state models (<xref ref-type="bibr" rid="bib5">Cochran and Cisler, 2019</xref>). We assessed the degree to which the online general latent-state model described by <xref ref-type="bibr" rid="bib5">Cochran and Cisler, 2019</xref> was able to account for participant behaviour. Specifically, we assessed (a) the degree to which it captured participant choice, parameterised as blockwise learning rate in the task (see <xref ref-type="fig" rid="fig3">Figure 3</xref>, main text) and (b) whether internal model estimates of volatility and noise from the latent-state model were able to rescue normative behaviour, as described for the Bayesian Observer Model in the main paper (main paper <xref ref-type="fig" rid="fig4">Figure 4f</xref>). The latent state model assumes that observations are generated from one of a series of latent states. The model estimates expected uncertainty, qualitatively similar to noise, at each time point as the expected value of the square of the prediction error. It also estimates unexpected uncertainty, which is similar to volatility, as a function of the likelihood ratio between a one-state model and its current prediction. When this likelihood ratio exceeds a threshold (i.e. the unexpected uncertainty is judged to be high), the model creates an additional latent state. The model is described in detail in <xref ref-type="bibr" rid="bib5">Cochran and Cisler, 2019</xref>. 11 model parameters were allowed to vary when fitting the model to participant choice (<xref ref-type="table" rid="table2">Table 2</xref>):</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Summary of free parameters in latent state model (see <xref ref-type="bibr" rid="bib5">Cochran and Cisler, 2019</xref> for detailed description).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Parameter</th><th align="left" valign="top">Description</th><th align="left" valign="top">Separate for win and loss outcomes</th><th align="left" valign="top">Number of parameters</th></tr></thead><tbody><tr><td align="left" valign="top">Alpha0</td><td align="left" valign="top">Learning rate for the association</td><td align="left" valign="top">yes</td><td align="char" char="." valign="top">2</td></tr><tr><td align="left" valign="top">Alpha1</td><td align="left" valign="top">Learning rate for variance</td><td align="left" valign="top">yes</td><td align="char" char="." valign="top">2</td></tr><tr><td align="left" valign="top">Alpha2</td><td align="left" valign="top">Learning rate for covariance</td><td align="left" valign="top">yes</td><td align="char" char="." valign="top">2</td></tr><tr><td align="left" valign="top">Gamma</td><td align="left" valign="top">Transition probability between states</td><td align="left" valign="top">yes</td><td align="char" char="." valign="top">2</td></tr><tr><td align="left" valign="top">Eta</td><td align="left" valign="top">Threshold for creating new state</td><td align="left" valign="top">yes</td><td align="char" char="." valign="top">2</td></tr><tr><td align="left" valign="top">Beta</td><td align="left" valign="top">Inverse choice temperature</td><td align="left" valign="top">No</td><td align="char" char="." valign="top">1</td></tr></tbody></table></table-wrap><p>The model’s value estimates were reset at the start of each task block, with the number of latent states at the start of each block being set to 1. The number of active latent states was used as an estimate of volatility, the log of the model’s expected value for the square of the prediction error was used as an estimate of noise. Model-derived trial labels (i.e. high/low volatility and noise) were calculated as for the analyses in <xref ref-type="fig" rid="fig4">Figure 4</xref> of the main paper-- those trials with values above/below the mean value for that participant.</p><p><xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> illustrates the estimated learning rates of the latent-state model in the task blocks. As can be seen, it replicates the increased learning rate in high volatility blocks demonstrated by participants (F(1,696)=9.98, p=0.001), however, unlike participants, it significantly increases its learning rate in response to noise (F(1,696)=100, p&lt;0.001). Using the labels for high/low volatility and noise derived from the latent-state model (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) does not rescue normative behaviour in participants. Participants employ a higher learning rate in trials the model considers to have low relative to high volatility (F(1,556)=7, p=0.008), with no effect of noise (F(1,556)=3.1, p=0.08). These results suggest that, while the current latent-state model is able to capture some aspects of participant behaviour, the internal model estimates of unexpected and expected uncertainty (as markers of volatility and noise, respectively) do not explain the response to uncertainty accounted for by the Bayesian Observer Model. It should be noted that, while the latent state model was constructed to respond to levels of uncertainty (<xref ref-type="bibr" rid="bib5">Cochran and Cisler, 2019</xref>) the formulation of these, and particularly of unexpected uncertainty is somewhat different to that used in the BOM (e.g. the estimate of unexpected uncertainty is a measure of the degree to which existing latent states are unable to account for experienced outcomes, and it can only increase across a block). It, therefore, remains possible that alternative latent state formulations would be more sensitive to the behaviour examined here.</p></sec><sec id="s4-3-11"><title>Performance of a simple RL model</title><p>A final possibility considered is that some of the behaviour of the fitted BOM might be captured by a radically simpler model that does not represent levels of uncertainty. To assess this, we fitted the simple reinforcement learning model to all of a participant’s choices across all task blocks (i.e. as compared to the measurement RL model used in the main paper which was fit to individual blocks). We then estimated the effective learning rate per block using choices derived from this model and the same analysis pipeline as the main paper. As can be seen in <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>, this very simple model does not replicate the learning adaptation apparent in participant behaviour.</p></sec></sec><sec id="s4-4"><title>Pupilometry data preprocessing</title><p>Pupilometry data were collected using the Eyelink II system (SRresearch) from both eyes, sampled at 500 Hz. Preprocessing involved the following steps: Eye blinks were identified using the built-in filter of the Eyelink system and were removed from the data. A linear interpolation was implemented for all missing data points (including blinks). The resulting trace was subjected to a low pass Butterworth filter (cut-off of 3.75 Hz), z-transformed across the session (<xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>), and then averaged across the two eyes. The pupil response to the win and the loss outcomes were extracted separately from each trial, using a time window based on the presentation of the outcomes. This included a 2 s pre-outcome period, and a 6 s period following outcome presentation. Individual trials were excluded from the pupilometry analysis if more than 50% of the data from the outcome period had been interpolated (mean = 6.7% of trials) (<xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>). The first five trials from each block were not used in the analysis as initial pupil adaptation can occur in response to luminance changes in this period (<xref ref-type="bibr" rid="bib4">Browning et al., 2015</xref>; <xref ref-type="bibr" rid="bib17">Nassar et al., 2012</xref>). The preprocessing resulted in two sets of timeseries per participant, one set containing pupil size data for each included trial when the win outcomes were displayed and the other when the loss outcomes were displayed. These pupil area data were binned into 1 s bins across the outcome period for analysis (NB <xref ref-type="fig" rid="fig5">Figure 5a–f</xref>). This analysis was supplemented by an individual regression approach (<xref ref-type="fig" rid="fig5">Figure 5g–i</xref>) in which individual participants’ pupil area timeseries was first regressed against estimated trialwise volatility and noise from the intact BOM (<xref ref-type="fig" rid="fig5">Figure 5g</xref>), as well as a number of control variables (constant term, amount won/lost on trial (i.e. magnitude of outcome), valence of outcome (win or loss), order in which outcomes were presented (win first/loss first), trial number (1:360), whether shape chosen switched on next trial or not (1:0)). The residuals from this regression were then regressed against estimated trial-wise volatility and noise from the degraded BOM (<xref ref-type="fig" rid="fig5">Figure 5h and i</xref>). These regression analyses resulted in timeseries of beta-weights that were analysed in the same manner as raw pupil size data.</p></sec><sec id="s4-5"><title>Quantification and statistical analysis</title><p>Behavioural data were analysed using linear mixed effect models (<italic>fitlme</italic> function of Matlab (2022a)) with participant ID included as a random factor and volatility, noise, and valence added as fixed factors. Two-way interactions between fixed effects were also tested (main effects are reported from models without interaction terms). Addition of random slopes for any of the fixed factors decreased LME model fit statistics and so were not included (<xref ref-type="bibr" rid="bib15">Matuschek et al., 2017</xref>). Analysis of timeseries pupillometry data included the additional fixed effect factor of time across the outcome period. Learning rates were transformed to the infinite real line using a logistic transform before analyses (untransformed data are displayed in figures for ease of interpretation). The normality of the distribution of the residuals of the LME analyses was checked both visually and with a one-sample Kolmogorov-Smirnov test. Changes in the classification of trials between the full and degraded BOM (<xref ref-type="fig" rid="fig4">Figure 4b</xref>) were analysed using a repeated measures ANOVA with within-subject factors of volatility, noise, and valence. Raw data are superimposed on all summary figures.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Has received travel expenses from Lundbeck for attending conferences and consultancy fromJansen, CHDR and Novartis</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Formal analysis, Investigation, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Formal analysis, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing – original draft</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>The studywas approved by the University of Oxford Central Research Ethics Committee (R49753/RE001).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-103734-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Study data and analysis scripts, including code for the various models used are available at: <ext-link ext-link-type="uri" xlink:href="https://osf.io/j7md3/">https://osf.io/j7md3/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Browning</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Affective Variability</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/j7md3/">j7md3</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to thank James Gunnell for his help in collecting the data. This study was funded by a MRC Clinician Scientist Fellowship awarded to MB (MR/N008103/1). MB was supported by the Oxford Health NIHR Biomedical Research Centre. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, or the Department of Health.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural correlations, population coding and computation</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1038/nrn1888</pub-id><pub-id pub-id-type="pmid">16760916</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Hunt</surname><given-names>LT</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Associative learning of social value</article-title><source>Nature</source><volume>456</volume><fpage>245</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1038/nature07538</pub-id><pub-id pub-id-type="pmid">19005555</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Browning</surname><given-names>M</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name><name><surname>Jocham</surname><given-names>G</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Bishop</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Anxious individuals have difficulty learning the causal statistics of aversive environments</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>590</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1038/nn.3961</pub-id><pub-id pub-id-type="pmid">25730669</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cochran</surname><given-names>AL</given-names></name><name><surname>Cisler</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A flexible and generalizable model of online latent-state learning</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1007331</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007331</pub-id><pub-id pub-id-type="pmid">31525176</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Colizoli</surname><given-names>O</given-names></name><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic modulation of decision biases by brainstem arousal systems</article-title><source>eLife</source><volume>6</volume><elocation-id>e23232</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.23232</pub-id><pub-id pub-id-type="pmid">28383284</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diederen</surname><given-names>KMJ</given-names></name><name><surname>Schultz</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Scaling prediction errors to reward variability benefits error-driven learning in humans</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>1628</fpage><lpage>1640</lpage><pub-id pub-id-type="doi">10.1152/jn.00483.2015</pub-id><pub-id pub-id-type="pmid">26180123</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gagne</surname><given-names>C</given-names></name><name><surname>Zika</surname><given-names>O</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Bishop</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Impaired adaptation of learning to contingency volatility in internalizing psychopathology</article-title><source>eLife</source><volume>9</volume><elocation-id>e61387</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.61387</pub-id><pub-id pub-id-type="pmid">33350387</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herce Castañón</surname><given-names>S</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Egner</surname><given-names>T</given-names></name><name><surname>Bang</surname><given-names>D</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Human noise blindness drives suboptimal cognitive inference</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>1719</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-09330-7</pub-id><pub-id pub-id-type="pmid">30979880</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalman</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>A new approach to linear filtering and prediction problems</article-title><source>Journal of Basic Engineering</source><volume>82</volume><fpage>35</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1115/1.3662552</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Correlations and neuronal population information</article-title><source>Annual Review of Neuroscience</source><volume>39</volume><fpage>237</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id><pub-id pub-id-type="pmid">27145916</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishnamurthy</surname><given-names>K</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Sarode</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</article-title><source>Nature Human Behaviour</source><volume>1</volume><elocation-id>0107</elocation-id><pub-id pub-id-type="doi">10.1038/s41562-017-0107</pub-id><pub-id pub-id-type="pmid">29034334</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>MacKay</surname><given-names>DJC</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Information Theory, Inference, and Learning Algorithms</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matuschek</surname><given-names>H</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name><name><surname>Vasishth</surname><given-names>S</given-names></name><name><surname>Baayen</surname><given-names>H</given-names></name><name><surname>Bates</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Balancing Type I error and power in linear mixed models</article-title><source>Journal of Memory and Language</source><volume>94</volume><fpage>305</fpage><lpage>315</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2017.01.001</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id><pub-id pub-id-type="pmid">20844132</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rumsey</surname><given-names>KM</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Parikh</surname><given-names>K</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><pub-id pub-id-type="doi">10.1038/nn.3130</pub-id><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Schüffelgen</surname><given-names>U</given-names></name><name><surname>Cuell</surname><given-names>SF</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dissociable effects of surprise and model update in parietal and anterior cingulate cortex</article-title><source>PNAS</source><volume>110</volume><fpage>E3660</fpage><lpage>E9</lpage><pub-id pub-id-type="doi">10.1073/pnas.1305373110</pub-id><pub-id pub-id-type="pmid">23986499</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piray</surname><given-names>P</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A model for learning based on the joint estimation of stochasticity and volatility</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>6587</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26731-9</pub-id><pub-id pub-id-type="pmid">34782597</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname><given-names>K</given-names></name><name><surname>’t Hart</surname><given-names>BM</given-names></name><name><surname>Einhäuser</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Pupil dilation signals surprise: evidence for noradrenaline’s role in decision making</article-title><source>Frontiers in Neuroscience</source><volume>5</volume><elocation-id>115</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2011.00115</pub-id><pub-id pub-id-type="pmid">21994487</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulcu</surname><given-names>E</given-names></name><name><surname>Browning</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Affective bias as a rational response to the statistics of rewards and punishments</article-title><source>eLife</source><volume>6</volume><elocation-id>e27879</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.27879</pub-id><pub-id pub-id-type="pmid">28976304</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulcu</surname><given-names>E</given-names></name><name><surname>Browning</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The misestimation of uncertainty in affective disorders</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>865</fpage><lpage>875</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.07.007</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulcu</surname><given-names>E</given-names></name><name><surname>Saunders</surname><given-names>KEA</given-names></name><name><surname>Harmer</surname><given-names>CJ</given-names></name><name><surname>Harrison</surname><given-names>PJ</given-names></name><name><surname>Goodwin</surname><given-names>GM</given-names></name><name><surname>Geddes</surname><given-names>JR</given-names></name><name><surname>Browning</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Using a generative model of affect to characterize affective variability and its response to treatment in bipolar disorder</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2202983119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2202983119</pub-id><pub-id pub-id-type="pmid">35787043</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introdcution</source><edition>Second</edition><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>EY</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A neural basis of probabilistic computation in visual cortex</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>122</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0554-5</pub-id><pub-id pub-id-type="pmid">31873286</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>EY</given-names></name><name><surname>Pohl</surname><given-names>S</given-names></name><name><surname>Denison</surname><given-names>RN</given-names></name><name><surname>Barack</surname><given-names>DL</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Block</surname><given-names>N</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Studying the neural representations of uncertainty</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>1857</fpage><lpage>1867</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01444-y</pub-id><pub-id pub-id-type="pmid">37814025</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103734.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Diaconescu</surname><given-names>Andreea Oliviana</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Toronto</institution><country>Canada</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This study makes an <bold>important</bold> contribution by showing that humans adapt learning rates rationally to environmental volatility yet systematically misattribute noise as volatility, demonstrating approximate rationality with simplified internal models. The evidence is <bold>compelling</bold>, encompassing a cleverly designed volatility-versus-noise paradigm, innovative lesion-based comparisons between reinforcement-learning and degraded Bayesian Observer Models, and convergent behavioural and pupillometric data. Expanding formal model comparisons (e.g., BIC/AIC) and directly contrasting RL and Bayesian fits to physiological markers would further enhance the work, but these are minor limitations that do not detract from the core findings.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103734.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors present an interesting study using RL and Bayesian modelling to examine differences in learning rate adaptation in conditions of high and low volatility and noise respectively. Through &quot;lesioning&quot; an optimal Bayesian model, they reveal that apparently suboptimal adaptation of learning rates results from incorrectly detecting volatility in the environment when it is not in fact present.</p><p>Strengths:</p><p>The experimental task used is cleverly designed and does a good job of manipulating both volatility and noise. The modelling approach takes an interesting and creative approach to understand the source of apparently suboptimal adaptation of learning rates to noise, through carefully &quot;lesioning&quot; and optimal Bayesian model to determine which components are responsible for this behaviour.</p><p>Weaknesses:</p><p>The model space could be more extensive, although the authors have covered the most relevant models for the question at hand.</p><p>Comments on revisions: I have no further recommendations for the authors, they have addressed my previous comments very well.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103734.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this study, the authors aimed to investigate how humans learn and adapt their behavior in dynamic environments characterized by two distinct types of uncertainty: volatility (systematic changes in outcomes) and noise (random variability in outcomes). Specifically, they sought to understand how participants adjust their learning rates in response to changes in these forms of uncertainty.</p><p>To achieve this, the authors employed a two-step approach:</p><p>Reinforcement Learning (RL) Model:</p><p>They first used an RL model to fit participants' behavior, revealing that the learning rate was context-dependent-it varied based on the levels of volatility and noise. However, the RL model showed that participants misattributed noise as volatility, leading to higher learning rates in noisy conditions, where the optimal strategy would be to be less sensitive to random fluctuations.</p><p>Bayesian Observer Model (BOM):</p><p>To better account for this context dependency, they introduced a Bayesian Observer Model (BOM), which models how an ideal Bayesian learner would update their beliefs about environmental uncertainty. They found that a degraded version of the BOM, where the agent had a coarser representation of noise compared to volatility, best fit the participants' behavior. This suggested that participants were not fully distinguishing between noise and volatility, instead treating noise as volatility and adjusting their learning rates accordingly.</p><p>The authors also aimed to use pupillometry data (measuring pupil dilation) as a physiological marker to arbitrate between models and understand how participants' internal representations of uncertainty influenced both their behavior and physiological responses. Their objective was to explore whether the BOM could explain not just behavioral choices but also these physiological responses, thereby providing stronger evidence for the model's validity.</p><p>Overall, the study sought to reconcile approximate rationality in human learning by showing that participants still follow a Bayesian-like learning process, but with simplified internal models that lead to suboptimal decisions in noisy environments.</p><p>Strengths:</p><p>The generative model presented in the study is both innovative and insightful. The authors first employ a Reinforcement Learning (RL) model to fit participants' behavior, revealing that the learning rate is context-dependent-specifically, it varies based on the levels of volatility and noise in the task. They then introduce a Bayesian Observer Model (BOM) to account for this context dependency, ultimately finding that a degraded BOM-in which the agent has a coarser representation of noise compared to volatility-provides the best fit to the participants' behavior. This suggests that participants are not fully distinguishing between noise and volatility, leading to misattribution of noise as volatility. Consequently, participants adopt higher learning rates even in noisy contexts, where an optimal strategy would involve being less sensitive to new information (i.e., using lower learning rates). This finding highlights a rational but approximate learning process, as described in the paper.</p><p>Weaknesses:</p><p>While the RL and Bayesian models both successfully predict behavior, it remains unclear how to fully reconcile the two approaches. The RL model captures behavior in terms of a fixed or context-dependent learning rate, while the BOM provides a more nuanced account with dynamic updates based on volatility and noise. Both models can predict actions when fit appropriately, but the pupillometry data offers a promising avenue to arbitrate between the models. However, the current study does not provide a direct comparison between the RL framework and the Bayesian model in terms of how well they explain the pupillometry data. It would be valuable to see whether the RL model can also account for physiological markers of learning, such as pupil responses, or if the BOM offers a unique advantage in this regard. A comparison of the two models using pupillometry data could strengthen the argument for the BOM's superiority, as currently, the possibility that RL models could explain the physiological data remains unexplored.</p><p>The model comparison between the Bayesian Observer Model and the self-defined degraded internal model could be further enhanced. Since different assumptions about the internal model's structure lead to varying levels of model complexity, using a formal criterion such as Bayesian Information Criterion (BIC) or Akaike Information Criterion (AIC) would allow for a more rigorous comparison of model fit. Including such comparisons would ensure that the degraded BOM is not simply favored due to its flexibility or higher complexity, but rather because it genuinely captures the participants' behavioral and physiological data better than alternative models. This would also help address concerns about overfitting and provide a clearer justification for using the degraded BOM over other potential models.</p><p>Comments on revisions:</p><p>The authors have addressed all my questions. Congratulations on the impressive work accomplished by the authors!</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.103734.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Pulcu</surname><given-names>Erdem</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Browning</surname><given-names>Michael</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oxford</institution><addr-line><named-content content-type="city">Oxford</named-content></addr-line><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>The authors present an interesting study using RL and Bayesian modelling to examine differences in learning rate adaptation in conditions of high and low volatility and noise respectively. Through &quot;lesioning&quot; an optimal Bayesian model, they reveal that apparently a suboptimal adaptation of learning rates results from incorrectly detecting volatility in the environment when it is not in fact present.</p><p>Strengths:</p><p>The experimental task used is cleverly designed and does a good job of manipulating both volatility and noise. The modelling approach takes an interesting and creative approach to understanding the source of apparently suboptimal adaptation of learning rates to noise, through carefully &quot;lesioning&quot; and optimal Bayesian model to determine which components are responsible for this behaviour.</p><p>We thank the reviewer for this assessment.</p><p>Weaknesses:</p><p>The study has a few substantial weaknesses; the data and modelling both appear robust and informative, and it tackles an interesting question. The model space could potentially have been expanded, particularly with regard to the inclusion of alternative strategies such as those that estimate latent states and adapt learning accordingly.</p></disp-quote><p>We thank the reviewer for this suggestion. We agree that it would be interesting to assess the ability of alternative models to reproduce the sub-optimal choices of participants in this study. The Bayesian Observer Model described in the paper is a form of Hierarchical Gaussian Filter, so we will assess the performance of a different class of models that are able to track uncertainty-- RL based models that are able to capture changes of uncertainty (the Kalman filter, and the model described by Cochran and Cisler, Plos Comp Biol 2019). We will assess the ability of the models to recapitulate the core behaviour of participants (in terms of learning rate adaption) and, if possible, assess their ability to account for the pupillometry response.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>In this study, the authors aimed to investigate how humans learn and adapt their behavior in dynamic environments characterized by two distinct types of uncertainty: volatility (systematic changes in outcomes) and noise (random variability in outcomes). Specifically, they sought to understand how participants adjust their learning rates in response to changes in these forms of uncertainty.</p><p>To achieve this, the authors employed a two-step approach:</p><p>(1) Reinforcement Learning (RL) Model: They first used an RL model to fit participants' behavior, revealing that the learning rate was context-dependent. In other words, it varied based on the levels of volatility and noise. However, the RL model showed that participants misattributed noise as volatility, leading to higher learning rates in noisy conditions, where the optimal strategy would be to be less sensitive to random fluctuations.</p><p>(2) Bayesian Observer Model (BOM): To better account for this context dependency, they introduced a Bayesian Observer Model (BOM), which models how an ideal Bayesian learner would update their beliefs about environmental uncertainty. They found that a degraded version of the BOM, where the agent had a coarser representation of noise compared to volatility, best fit the participants' behavior. This suggested that participants were not fully distinguishing between noise and volatility, instead treating noise as volatility and adjusting their learning rates accordingly.</p><p>The authors also aimed to use pupillometry data (measuring pupil dilation) as a physiological marker to arbitrate between models and understand how participants' internal representations of uncertainty influenced both their behavior and physiological responses. Their objective was to explore whether the BOM could explain not just behavioral choices but also these physiological responses, thereby providing stronger evidence for the model's validity.</p><p>Overall, the study sought to reconcile approximate rationality in human learning by showing that participants still follow a Bayesian-like learning process, but with simplified internal models that lead to suboptimal decisions in noisy environments.</p><p>Strengths:</p><p>The generative model presented in the study is both innovative and insightful. The authors first employ a Reinforcement Learning (RL) model to fit participants' behavior, revealing that the learning rate is context-dependent-specifically, it varies based on the levels of volatility and noise in the task. They then introduce a Bayesian Observer Model (BOM) to account for this context dependency, ultimately finding that a degraded BOM - in which the agent has a coarser representation of noise compared to volatility - provides the best fit for the participants' behavior. This suggests that participants do not fully distinguish between noise and volatility, leading to the misattribution of noise as volatility. Consequently, participants adopt higher learning rates even in noisy contexts, where an optimal strategy would involve being less sensitive to new information (i.e., using lower learning rates). This finding highlights a rational but approximate learning process, as described in the paper.</p></disp-quote><p>We thank the reviewer for their assessment of the paper.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>While the RL and Bayesian models both successfully predict behavior, it remains unclear how to fully reconcile the two approaches. The RL model captures behavior in terms of a fixed or context-dependent learning rate, while the BOM provides a more nuanced account with dynamic updates based on volatility and noise. Both models can predict actions when fit appropriately, but the pupillometry data offers a promising avenue to arbitrate between the models. However, the current study does not provide a direct comparison between the RL framework and the Bayesian model in terms of how well they explain the pupillometry data. It would be valuable to see whether the RL model can also account for physiological markers of learning, such as pupil responses, or if the BOM offers a unique advantage in this regard. A comparison of the two models using pupillometry data could strengthen the argument for the BOM's superiority, as currently, the possibility that RL models could explain the physiological data remains unexplored.</p></disp-quote><p>We thank the reviewer for this suggestion. In the current version of the paper, we use an extremely simple reinforcement learning model to simply measure the learning rate in each task block (as this is the key behavioural metric we are interested in). As the reviewer highlights, this simple model doesn’t estimate uncertainty or adapt to it. Given this, we don’t think we can directly compare this model to the Bayesian Observer Model—for example, in the current analysis of the pupillometry data we classify individual trials based on the BOM’s estimate of uncertainty and show that participants adapt their learning rate as expected to the reclassified trials, this analysis would not be possible with our current RL model. However, there are more complex RL based models that do estimate uncertainty (as discussed above in response to Reviewer #1) and so may more directly be compared to the BOM. We will attempt to apply these models to our task data and describe their ability to account for participant behaviour and physiological response as suggested by the Reviewer.</p><disp-quote content-type="editor-comment"><p>The model comparison between the Bayesian Observer Model and the self-defined degraded internal model could be further enhanced. Since different assumptions about the internal model's structure lead to varying levels of model complexity, using a formal criterion such as Bayesian Information Criterion (BIC) or Akaike Information Criterion (AIC) would allow for a more rigorous comparison of model fit. Including such comparisons would ensure that the degraded BOM is not simply favored due to its flexibility or higher complexity, but rather because it genuinely captures the participants' behavioral and physiological data better than alternative models. This would also help address concerns about overfitting and provide a clearer justification for using the degraded BOM over other potential models.</p></disp-quote><p>Thank you, we will add this.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>For clarity, the methods would benefit from further detail of task framing to participants. I.e. were there explicit instructions regarding volatility/task contingencies? Or were participants told nothing?</p></disp-quote><p>We have added in the following explanatory text to the methods section (page 20), clarifying the limited instructions provided to participants:</p><p>“Participants were informed that the task would be split into 6 blocks, that they had to learn which was the best option to choose, and that this option may change over time. They were not informed about the different forms of uncertainty we were investigating or of the underlying structure of the task (that uncertainty varied between blocks).”</p><p>In the results, it would be useful to report the general task behavior of participants to get a sense of how they performed across different parts of the task. Also, were participants excluded if they didn't show evidence of learning adaptation to volatility?</p><p>We have added the following text reporting overall performance to the results (page 6):</p><p>“Participants were able to learn the best option to choose in the task, selecting the most highly rewarded option on an average of 71% of trials (range 65% - 74%).”</p><p>And the following text to the methods, confirming that participants were not excluded if they didn’t respond to volatility/noise (the failure in this adaptation is the focus of the current study) (page 19):</p><p>“No exclusion criteria related to task performance were used.”</p><disp-quote content-type="editor-comment"><p>The results would benefit from a more intuitive explanation of what the lesioning is trying to recapitulate; this can get quite technical and the objective is not necessarily clear, especially for the less computationally-minded reader.</p></disp-quote><p>We have amended the relevant section of the results to clarify this point (page 9):</p><p>“Having shown that an optimal learner adjusts its learning rate to changes in volatility and noise as expected, we next sought to understand the relative noise insensitivity of participants. In these analyses we “lesion” the BOM, to reduce its performance in some way, and then assess whether doing so recapitulates the pattern of learning rate adaptation observed for participants (Fig 3e). In other words, we damage the model so it performs less well and then assess whether this damage makes the behaviour of the BOM (shown in Fig 3f) more closely resemble that seen in participants (Fig 3e).”</p><disp-quote content-type="editor-comment"><p>The modelling might be improved by the inclusion of another class of model. Specifically, models that adapt learning rates in response to the estimation of latent states underlying the current task outcomes would be very interesting to see. In a sense, these are also estimating volatility through changeability of latent states, and it would be interesting to explore whether the findings could also be explained by an incorrect assumption that the latent state has changed when outcomes are noisy.</p></disp-quote><p>Thank you for this suggestion. We have added additional sections to the supplementary materials in which we use a general latent state model and a simple RL model to try to recapitulate the behaviour of participants (and to compare with the BOM). These additional sections are extensive, so are not reproduced here. We have also added in a section to the discussion in the main paper covering this interesting question in which we confirm that we were unable to reproduce participant behaviour (or the normative effect of the lesioned BOMs) using these models but suggest that alternative latent state formulations would be interesting to explore in future work (page 18):</p><p>“A related question is whether other, non-Bayesian model formulations may be able to account for participants’ learning adaptation in response to volatility and noise. Of note, the reinforcement learning model used to measure learning rates in separate blocks does not achieve this goal—as this model is fitted separately to each block rather than adapting between blocks (NB the simple reinforcement learning model that is fitted across all blocks does not capture participant behaviour, see supplementary information). One candidate class of model that has potential here is latent-state models (Cochran &amp; Cisler, 2019), in which the variance and unexpected changes in the process being learned (which have a degree of similarity with noise and volatility respectively) is estimated and used to alter the model’s rates of updating as well as the estimated number of states being considered. Using the model described by Cochran and Cisler, we were unable to replicate the learning rate adaptation demonstrated by participants in the current study (see supplementary information) although it remains possible that other latent state formulations may be more successful.”</p><disp-quote content-type="editor-comment"><p>The discussion may benefit from a little more discussion of where this work leads us - what is the next step?</p></disp-quote><p>As above, we have added in a suggestion about future modelling work. We have also added in a section about the outstanding interesting questions concerning the neural representation of these quantities, reproduced in response to the suggestion by reviewer #2 below.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>The study presents an opportunity to explore potential neural coding models that could account for the cognitive processes underlying the task. In the field of neural coding, noise correlation is often measured to understand how a population of neurons responds to the same stimulus, which could be related to the noise signal in this task. Since the brain likely treats the stimulus as the same, with noise representing minor changes, this aspect could be linked to the participants' difficulty distinguishing noise from volatility. On the other hand, signal correlation is used to understand how neurons respond to different stimuli, which can be mapped to the volatility signal in the task. It would be highly beneficial if the authors could discuss how these established concepts from neural population coding might relate to the Bayesian behavior model used in the study. For instance, how might neurons encode the distinction between noise and volatility at a population level? Could noise correlation lead to the misattribution of noise as volatility at a neural level, mirroring the behavioral findings? Discussing possible neural models that could explain the observed behavior and relating it to the existing literature on neural population coding would significantly enrich the discussion. It would also open up avenues for future research, linking these behavioral findings to potential neural mechanisms.</p></disp-quote><p>We thank the reviewer for this interesting suggestion. We have added in the following paragraph to the discussion section which we hope does justice to this interesting questions (page 18):</p><p>“Previous work examining the neural representations of uncertainty have tended to report correlations between brain activity and some task-based estimate of one form of uncertainty at a time (Behrens et al., 2007; Walker et al., 2020, 2023). We are not aware of work that has, for example, systematically varied volatility and noise and reported distinct correlations for each. An interesting possibility as to how different forms of uncertainty may be encoded is suggested by parallels with the neuronal decoding literature. One question addressed by this literature is how the brain decodes changes in the world from the distributed, noisy neural responses to those changes, with a particular focus on the influence of different forms of between-neuron correlation (Averbeck et al., 2006; Kohn et al., 2016). Specifically, signal-correlation, the degree to which different neurons represent similar external quantities (required to track volatility) is distinguished from, and often limited by, noise-correlation, the degree to which the activity of different neurons covaries independently of these external quantities. One possibility relevant to the current study, which resembles the underlying logic of the BOM, is that a population of neurons represents the estimated mean of the generative process that produces task outcomes. In this case, volatility would be tracked as the signal-correlation across this population, whereas noise would be analogous to the noise-correlation and, crucially, misestimation of noise as volatility might arise as misestimation of these two forms of correlation. While the current study clearly cannot adjudicate on the neural representation of these processes, our finding of distinct behavioural and physiological responses to the two forms of uncertainty, does suggest that separable neural representations of uncertainty are maintained.”</p></body></sub-article></article>