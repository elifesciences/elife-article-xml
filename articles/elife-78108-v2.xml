<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">78108</article-id><article-id pub-id-type="doi">10.7554/eLife.78108</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Frequency-specific neural signatures of perceptual content and perceptual stability</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-164556"><name><surname>Hardstone</surname><given-names>Richard</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7502-9145</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-108333"><name><surname>Flounders</surname><given-names>Matthew W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7014-4665</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-273821"><name><surname>Zhu</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-71932"><name><surname>He</surname><given-names>Biyu J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1549-1351</contrib-id><email>biyu.he@nyulangone.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Neuroscience Institute, New York University Grossman School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Department of Neurology, New York University Grossman School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Department of Neuroscience and Physiology, New York University Grossman School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Department of Radiology, New York University Grossman School of Medicine</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Luo</surname><given-names>Huan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Baker</surname><given-names>Chris I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>National Institute of Mental Health, National Institutes of Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>20</day><month>09</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e78108</elocation-id><history><date date-type="received" iso-8601-date="2022-02-23"><day>23</day><month>02</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-09-18"><day>18</day><month>09</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-03-20"><day>20</day><month>03</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.03.18.484861"/></event></pub-history><permissions><copyright-statement>© 2022, Hardstone et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Hardstone et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-78108-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-78108-figures-v2.pdf"/><abstract><p>In the natural environment, we often form stable perceptual experiences from ambiguous and fleeting sensory inputs. Which neural activity underlies the content of perception and which neural activity supports perceptual stability remains an open question. We used a bistable perception paradigm involving ambiguous images to behaviorally dissociate perceptual content from perceptual stability, and magnetoencephalography to measure whole-brain neural dynamics in humans. Combining multivariate decoding and neural state-space analyses, we found frequency-band-specific neural signatures that underlie the content of perception and promote perceptual stability, respectively. Across different types of images, non-oscillatory neural activity in the slow cortical potential (&lt;5 Hz) range supported the content of perception. Perceptual stability was additionally influenced by the amplitude of alpha and beta oscillations. In addition, neural activity underlying perceptual memory, which supports perceptual stability when sensory input is temporally removed from view, also encodes elapsed time. Together, these results reveal distinct neural mechanisms that support the content versus stability of visual perception.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>bistable perception</kwd><kwd>magnetoencephalography</kwd><kwd>slow cortical potential</kwd><kwd>brain oscillations</kwd><kwd>multivariate analysis</kwd><kwd>perceptual stability</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>BCS-1753218</award-id><principal-award-recipient><name><surname>He</surname><given-names>Biyu J</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006984</institution-id><institution>Irma T. Hirschl Trust</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>He</surname><given-names>Biyu J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01EY032085</award-id><principal-award-recipient><name><surname>He</surname><given-names>Biyu J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>While perceptual content is encoded in non-oscillatory activity in the slow cortical potential (&lt;5 Hz) range, perceptual stability is predominantly influenced by the amplitude fluctuations of alpha (~10 Hz) and beta (~20 Hz) brain oscillations.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>How vivid visual perceptual experiences are generated by the brain remains a central question in neuroscience. There are two critical functions that the visual perceptual system is able to accomplish: the first is to generate the specific content of perceptual experience (such as seeing a predator); the second is to maintain a stable perceptual experience despite noisy and unstable retinal input due to constant head and eye movements and complexities of the natural environment involving occlusion, shading, and dynamic changes of sensory input (e.g., the predator is camouflaged and hidden in the bush). Here, we investigate neural mechanisms giving rise to specific perceptual content and supporting perceptual stability in the human brain.</p><p>Motivated by several strands of previous work, we hypothesized that there might be different components of electrophysiological neural activities that support perceptual content and perceptual stability, respectively. First, previous studies using multivariate analysis to decode perceptual content based on electroencephalography/magnetoencephalography (EEG/MEG) activity have typically reported greater successes when the decoder’s input was raw filtered field potentials in the relatively low (&lt;30 Hz) frequency range (e.g., <xref ref-type="bibr" rid="bib7">Carlson et al., 2013</xref>; <xref ref-type="bibr" rid="bib45">Salti et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">King et al., 2016</xref>). Further, studies using frequency-band-specific analysis have shown that the ability to decode perceptual content is contributed most by the slow cortical potential (SCP, &lt;5 Hz) frequency range (<xref ref-type="bibr" rid="bib1">Baria et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Flounders et al., 2019</xref>). This is consistent with the 1/<italic>f</italic> distribution of EEG/MEG power spectrum suggesting that the SCP band contributes most to the power in the event-related potential/field (ERP/ERF) frequency range (<xref ref-type="bibr" rid="bib21">He et al., 2010</xref>; <xref ref-type="bibr" rid="bib22">He, 2014</xref>; <xref ref-type="bibr" rid="bib13">Donoghue et al., 2020</xref>).</p><p>Second, a line of work focused on brain oscillations has shown that moment-to-moment fluctuations of alpha oscillation amplitude in sensory cortices modulate local cortical excitability in a manner that transcends specific stimulus/perceptual contents (<xref ref-type="bibr" rid="bib46">Samaha et al., 2020</xref>). In addition, alpha and beta oscillations can carry top-down feedback influences (<xref ref-type="bibr" rid="bib59">van Kerkoerle et al., 2014</xref>; <xref ref-type="bibr" rid="bib34">Michalareas et al., 2016</xref>), and top-down feedback may facilitate resolving perceptual ambiguity by carrying information consistent with prior knowledge (<xref ref-type="bibr" rid="bib8">Cavanagh, 1991</xref>; <xref ref-type="bibr" rid="bib63">Yuille and Kersten, 2006</xref>). We therefore hypothesized that there might exist a frequency-band separation between neural activity supporting perceptual content and neural activity supporting perceptual stability, with the former residing in the non-oscillatory activity in the SCP range, and the latter predominantly residing in oscillatory activity in the alpha/beta range.</p><p>To test this hypothesis, we recorded whole-head MEG while participants performed a bistable visual perception task involving two different ambiguous figures (Necker cube and Rubin face–vase illusion). Data from these two images were separately analyzed, providing a within-study reproducibility and generalizability check. In two different conditions, the images were either continuously presented (<italic>Ambiguous</italic> condition, <xref ref-type="fig" rid="fig1">Figure 1A</xref>) or intermittently presented (<italic>Discontinuous</italic> condition, <xref ref-type="fig" rid="fig1">Figure 1E</xref>). The <italic>Ambiguous</italic> condition allowed us to dissociate perceptual content (perceiving one or the other interpretation) from perceptual stability (how long a percept lasts). The <italic>Discontinuous</italic> condition allowed us to investigate the neural underpinnings of perceptual memory: previous research has shown that perceptual alternations slow down during intermittent presentation and that a perceptual memory trace exists in the intervening blank periods such that the recently experienced percept is likely reinstated when the image reappears (<xref ref-type="bibr" rid="bib38">Orbach et al., 1966</xref>; <xref ref-type="bibr" rid="bib29">Leopold et al., 2002</xref>; <xref ref-type="bibr" rid="bib40">Pearson and Brascamp, 2008</xref>). This phenomenon provides a window into neural mechanisms supporting perceptual stability when sensory input is both ambiguous and fleeting, as often is the case in natural vision. Finally, to test the generalizability of the identified neural correlate of perceptual content, participants additionally performed a task in which modified versions of the Necker cube and Rubin face–vase images with ambiguity removed (<xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>) were presented and perceptual content varied with the actual physical stimulus (<italic>Unambiguous</italic> condition, <xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Paradigm and behavioral results.</title><p>(<bold>A</bold>) In the <italic>Ambiguous</italic> condition, bistable images were presented for 60 s each, and subjects pressed buttons to indicate their current percept. (<bold>B</bold>) Percentage of time spent in each perceptual state during the <italic>Ambiguous</italic> condition. (<bold>C</bold>) In the <italic>Unambiguous</italic> condition, bistable images which were modified to reduce their ambiguity were presented. (<bold>D</bold>) Percentage of valid trials for each image type during the Unambiguous condition. Valid trials consisted of the subject pressing the button only once for the intended percept. (<bold>E</bold>) In the <italic>Discontinuous</italic> condition, ambiguous images were shown nine times with interleaving blank periods. (<bold>F</bold>) Percentage of blank periods that were classified as Stable, Unstable, or Missing. ‘Stable’ indicates that perception was the same before and after the blank period, ‘Unstable’ that it was different, and ‘missing’ indicates that no button press was recorded during the pre or post image presentation period. (<bold>B, D, F</bold>) Dots indicate individual subjects; bars and error bars indicate group mean and standard error of the mean (SEM).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Individual-level power spectra and group-level duration histograms.</title><p>(<bold>A, B</bold>) Each line corresponds to a subject’s power spectrum averaged over all 272 MEG sensors. Shaded boxes correspond to the three frequency bands analyzed, slow cortical potential (SCP) (0.05–5 Hz), alpha (8–13 Hz) amplitude, and beta (13–30 Hz) amplitude. For the discontinuous condition, peaks can be seen in low frequencies corresponding to the task structure (8 s between consecutive image onsets gives rise to 0.125 Hz and its harmonics). Frequencies at line noise (60 Hz) and its harmonics are not plotted. (<bold>C, D</bold>) Histograms showing the distribution of percept durations, including data pooled across 19 subjects.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig1-figsupp1-v2.tif"/></fig></fig-group><p>To test our hypothesis, we combined multivariate decoding with an innovative multivariate regression approach which allowed us to identify separate neural subspaces relevant to the encoding of different types of behavioral information that are simultaneously present in the same task (<xref ref-type="bibr" rid="bib32">Mante et al., 2013</xref>)—specifically, perceptual content and perceptual switching dynamics in the present task. Across two different task conditions with different levels of stimulus ambiguity (<italic>Ambiguous</italic> and <italic>Unambiguous</italic>), we found that non-oscillatory neural activity in the SCP range, but not alpha or beta oscillations, encoded perceptual content. Furthermore, across both <italic>Ambiguous</italic> and <italic>Discontinuous</italic> conditions, we found that the fluctuations of alpha and beta amplitudes modulated perceptual stability and perceptual memory. Interestingly, we also found that SCP modulated perceptual stability, although with less spatial consistency across subjects than alpha and beta oscillations. These results reveal an intriguing frequency-domain separation of neural activity encoding perceptual content and that supporting perceptual stability.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Task paradigm and behavioral results</title><p>We recorded 18 subjects with whole-head MEG (CTF, 272 functional axial gradiometers) performing 3 conditions of a visual perception task involving 2 commonly studied ambiguous figures (Necker cube and Rubin face–vase illusion). The first condition consists of the classic bistable perception task (<italic>Ambiguous</italic>, <xref ref-type="fig" rid="fig1">Figure 1A</xref>), in which subjects viewed ambiguous images for 60 s at a time and used button presses to indicate their spontaneous perceptual switches (with three buttons corresponding to two of the possible percepts and an ‘unsure’ option). In the second condition (<italic>Unambiguous</italic>, <xref ref-type="fig" rid="fig1">Figure 1C</xref>), subjects viewed modified versions of these images for 5 s at a time, which enhance one of the possible interpretations and largely abolish perceptual switching (<xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>); subjects indicated their percepts in a similar fashion as before. In the final condition (<italic>Discontinuous</italic>, <xref ref-type="fig" rid="fig1">Figure 1E</xref>), each ambiguous figure was presented repeatedly with interleaving blank periods, allowing us to investigate neural underpinnings of perceptual memory during the blank periods (<xref ref-type="bibr" rid="bib29">Leopold et al., 2002</xref>; <xref ref-type="bibr" rid="bib40">Pearson and Brascamp, 2008</xref>); subjects indicated their percepts whenever the image was in view.</p><p>During the <italic>Ambiguous</italic> condition (<xref ref-type="fig" rid="fig1">Figure 1A, B</xref>) perceptual switching occurred, with group-level results showing that each of the possible percepts was perceived (on average &gt;25% of the time), and that subjects were rarely unsure of which percept they were experiencing (&lt;10% occurrence, these time periods were removed from further analyses). Modifying the images to be unambiguous (<xref ref-type="fig" rid="fig1">Figure 1C, D</xref>) was successful, as evidenced by subjects having on average &gt;80% valid trials (defined as trials with only one button press indicating the intended percept). In the <italic>Discontinuous</italic> condition, we found an increased likelihood that perception remained stable across the blank period for the Necker cube (one-tailed Wilcoxon sign-rank (17) = 116.5, p = 0.031) but not for the Rubin face–vase image (one-tailed Wilcoxon sign-rank (17) = 71.5, p = 0.736).</p><p>Together, these behavioral results demonstrate the classic bistable perception phenomenon in the <italic>Ambiguous</italic> condition, successful disambiguation of the images in the <italic>Unambiguous</italic> condition, and a means to investigate perceptual memory by contrasting stable- and unstable-blank periods in the <italic>Discontinuous</italic> condition. Importantly, the use of two different ambiguous figures in all three conditions allowed us to test whether the neural findings are reproducible and generalizable across the specific stimulus characteristics. Here, taking advantage of the large-scale neural dynamics recorded by whole-head MEG, we aimed to dissociate dynamical neural activity underlying perceptual content and supporting perceptual stability, respectively.</p></sec><sec id="s2-2"><title>Perceptual content can be decoded from SCP but not amplitude of band-limited oscillations</title><p>In the classic bistable perception task, perceptual content experienced by the subject continuously alternates between two possible outcomes while the sensory input stays constant. This allows the investigation of the neural correlates of the content of conscious perception while controlling for low-level sensory processing. To this end, we applied time-resolved multivariate decoding to whole-brain MEG data (for details, see <italic>Methods</italic>). We tested three components of neural field potentials—SCP (&lt;5 Hz), alpha-band amplitude (amplitude envelope of 8–13 Hz filtered data) and beta-band amplitude (amplitude envelope of 13–30 Hz filtered data)—in their ability to distinguish between the two percepts that are alternatively experienced for each ambiguous figure. The SCP activity corresponds to the low-frequency component of the broadband, non-oscillatory (i.e., aperiodic) activity (<xref ref-type="bibr" rid="bib21">He et al., 2010</xref>; <xref ref-type="bibr" rid="bib22">He, 2014</xref>), while the alpha and beta bands have prominent oscillatory activity (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A, B</xref>). After extracting the relevant neural feature, perceptual content decoding was performed using a fourfold cross-validated linear support vector machine (SVM), with significance determined using cluster-based permutation testing that corrects for multiple comparisons across time.</p><p>To investigate neural activity underlying specific perceptual content, we selected time periods (‘subtrials’) that were preceded and followed by button presses for two different percepts (i.e., excluding periods preceded or followed by unsure presses, or at the beginning or end of the image presentation) and sorted them into two groups. Thus, each subtrial begins with a button press indicating the relevant percept and ends with a button press that indicates a switch to the opposite percept. These subtrials were of different lengths (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C, D</xref>), as percept duration is highly variable during spontaneous bistable perception—a topic we will address in the following section. To decode perceptual content, we then subsampled each subtrial by taking 100 equally spaced time points from the beginning to the end of that subtrial (henceforth referred to as percentile of a percept). This way, we tested whether a decoder trained using neural features recorded at the beginning (/middle/end) of a subtrial generalized to the beginning (/middle/end) of other subtrials, even if they were of different lengths (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The content of subjective perception is encoded in slow cortical potential (SCP) activity.</title><p>(<bold>A</bold>) In the <italic>Ambiguous</italic> condition, subjects continuously reported their current perception using button presses. Neural activity during each percept was split into 100 percentiles according to time elapsed, and percept was then decoded at each temporal percentile. (<bold>B</bold>) In the <italic>Unambiguous</italic> condition, different disambiguated images were shown that emphasized one of the two percepts. For valid trials in which subjects’ reported percept matched the intended percept (see <xref ref-type="fig" rid="fig1">Figure 1D</xref>), image content was decoded separately at each time point during image presentation. (<bold>C</bold>) (<italic>Left</italic>) Decoding accuracy for perceptual content during the time course of a percept. Significant temporal clusters of percept decoding exist for both images using SCP as the decoder input, but not when alpha or beta amplitude was used as decoder input. (<italic>Right</italic>) Temporal generalization matrices. Significant clusters are outlined, showing generalization across a large proportion of the percept duration. (<bold>D</bold>) (<italic>Left</italic>) Decoding accuracy for unambiguous images during their presentation. Significant temporal clusters of image/percept decoding exist in the SCP range throughout image presentation, but not for alpha/beta amplitude. (<italic>Right</italic>) Temporal generalization matrices showing significant generalization across a large proportion of the image presentation duration.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Slow cortical potential (SCP) has significantly higher decoding than alpha or beta oscillations in both the ambiguous (top) and unambiguous (bottom) conditions.</title><p>(<italic>Left</italic>) Difference in decoding accuracy between SCP and alpha/beta amplitude for perceptual content across the time course of a percept. Significant temporal clusters of percept decoding exist for both images. (<italic>Right</italic>) Difference in temporal generalization matrices (SCP – alpha or beta amplitude). Significant clusters are outlined, showing the temporal generalization locations where SCP has significantly greater decoding accuracy. Significance for all plots is established by cluster-based permutation test and presented at a p &lt; 0.05, corrected level.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig2-figsupp1-v2.tif"/></fig></fig-group><p>Decoding accuracies over the course of a percept for the three different neural features are shown in <xref ref-type="fig" rid="fig2">Figure 2C</xref>, left column. Significant decoding of perceptual content is found for SCP, but not alpha or beta amplitude (except for a very small temporal cluster for the face–vase image), and SCP shows significantly stronger decoding than alpha or beta amplitude (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) suggesting that the currently experienced percept is most strongly encoded in SCP activity. These findings are consistent with previous results using other visual perceptual tasks (<xref ref-type="bibr" rid="bib1">Baria et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Flounders et al., 2019</xref>). To shed light on whether the neural representation of the percept stays stable over the duration of the percept or changes constantly over time, we tested the temporal generalization of the decoder, whereby decoders trained at each time point are tested at all other time points (<xref ref-type="bibr" rid="bib25">King and Dehaene, 2014</xref>). We observed broad decoder temporal generalization in the SCP band for both the Necker cube and Rubin face–vase illusion (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, right column), especially from 20th to 80th percentile of the percept duration. This suggests that neural representation underlying perceptual content, except at the very beginning and end of a percept, is relatively stable over time regardless of percept duration, and localizes to the SCP band in the frequency domain.</p><p>We next tested whether a similar pattern of findings exists when stimulus ambiguity is removed, by decoding perceptual content using data from the <italic>Unambiguous</italic> condition. To this end, we selected valid trials (wherein the subject only had one button press indicating the intended percept), which account for the vast majority of all trials (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), and constructed decoders to distinguish between the two different perceptual contents which coincided with different image inputs (i.e., decoding between the two versions of face–vase image, and between the two versions of cube image, <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Similar to the <italic>Ambiguous</italic> condition, significant perceptual content decoding was obtained using SCP activity, but not alpha or beta amplitude (except for one small temporal cluster at image onset for alpha amplitude, face–vase image) (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, left column) and decoding was stronger in the SCP band (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Decoding accuracy in the SCP band was highest in the first second after image onset and then drops to a lower level (likely due to neural adaptation). The higher decoding accuracy in the <italic>Unambiguous</italic> condition as compared to the <italic>Ambiguous</italic> condition is likely due to the differences in sensory input that coincides with different perceptual contents, as well as consistent timing across all trials (all image presentations last 5 s, as opposed to variable percept durations in the <italic>Ambiguous</italic> condition). Lastly, as in the <italic>Ambiguous</italic> condition, the SCP decoder of perceptual content generalized well across time in the <italic>Unambiguous</italic> condition (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, right column), suggesting that the underlying neural code is stable over time after the very initial image onset-related activity.</p><p>Together, these results show that perceptual content information is decodable from SCP activity, but not from the amplitude of alpha or beta oscillations, regardless of whether sensory input is ambiguous or not. In the next section, we investigate neural processes controlling the stability of a percept as compared to the neural processes underlying the content of that percept.</p></sec><sec id="s2-3"><title>Defining a behaviorally relevant neural subspace</title><p>To simultaneously extract neural activity relevant to different behavioral metrics—here, the content of perception and the dynamics of perceptual switching—we adapted a multivariate analysis approach recently developed in animal neurophysiology (‘state-space analysis’) (<xref ref-type="bibr" rid="bib54">Sussillo, 2014</xref>). In this framework, multivariate neural activity (across neurons or sensors) at each time point corresponds to a specific location in the neural state space, where each dimension is a neuron/sensor. Because different neurons/sensors are highly correlated and not all are informative for the behavior of interest, dimensionality reduction methods (such as principal component analysis, PCA) are typically applied to identify a low-dimensional subspace capturing the majority of the variance in the data and/or most relevant to the behavior in question (<xref ref-type="bibr" rid="bib4">Briggman et al., 2005</xref>; <xref ref-type="bibr" rid="bib10">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib53">Stokes et al., 2013</xref>; <xref ref-type="bibr" rid="bib1">Baria et al., 2017</xref>). Here, following earlier studies (<xref ref-type="bibr" rid="bib32">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Kayser et al., 2016</xref>), we identify the neural subspace most relevant to a particular behavioral metric by conducting a multilinear regression using orthogonal, task-related axes that capture perceptual content and perceptual switching dynamics, as described in detail below. Importantly, unlike the decoding approach employed in the earlier analysis, where a different decoder is trained for each time point within a trial and decoder weights are sometimes difficult to interpret (<xref ref-type="bibr" rid="bib18">Haufe et al., 2014</xref>), the state-space analysis aims to identify a neural subspace that is unchanging across time, wherein the trajectory of neural activity informs about changes in behavior across time.</p><p>For both the <italic>Ambiguous</italic> and <italic>Discontinuous</italic> conditions, we defined a set of behavioral axes capturing both perceptual content and perceptual switching dynamics (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). For the <italic>Ambiguous</italic> condition, these consisted of a <italic>Type</italic> Axis, which was a binary (0 or 1) variable indicating the current perceptual content; a <italic>Duration</italic> Axis, indicating the overall duration of the current percept; a <italic>Switch</italic> Axis, indicating the temporal distance to a reported perceptual switch (i.e., button press); and, finally, a <italic>Direction</italic> Axis, a binary variable indicating whether the current percept is stabilizing or destabilizing (operationalized as the first half vs. second half of a percept). Both the Switch and Duration axes had values normalized to the range of [0, 1], such that for the <italic>Switch</italic> axis, time points corresponding to button presses are 0 and time points furthest away from button presses within each percept are 1; for the <italic>Duration</italic> axis, the shorted and longest percept durations for a particular subject are coded as 0 and 1, respectively. Thus, the <italic>Switch</italic>, <italic>Duration</italic>, and <italic>Direction</italic> axes together capture different aspects of the perceptual switching dynamic, while the <italic>Type</italic> axis captures the specific perceptual content.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Method to define behaviorally relevant neural subspace.</title><p>(<bold>A</bold>) For the <italic>Ambiguous</italic> and <italic>Discontinuous</italic> conditions, a set of behavioral metrics was defined, which incorporated information about both the perceptual content and the perceptual switching dynamics. (<bold>B</bold>) Using a training set of MEG data, neural subspaces were defined by apply multilinear regression to activity from each sensor using the four behavioral metrics as predictors. The weights across sensors for each behavioral metric define the neural subspace relevant to that metric. (<bold>C</bold>) The test MEG dataset can then be projected into the subspace corresponding to a particular behavioral metric to provide a prediction of the metric value at each time point. (<bold>D</bold>) Accuracy of the prediction can then be tested by comparison to the actual behavioral data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig3-v2.tif"/></fig><p>For the <italic>Discontinuous</italic> condition, because we are interested in neural activity underlying the perceptual memory trace, only blank periods were analyzed. Two behavioral axes were defined to capture the content of perception: <italic>Pre</italic> and <italic>Post</italic>, which are binary variables indicating the perceptual content before and after the blank period, respectively. Two behavioral axes were defined to capture the dynamics of perceptual memory: a <italic>Memory</italic> axis, which is a binary variable indicating whether a perceptual memory trace is present or absent (defined by whether the reported perceptual content before and after the blank period is the same); and a <italic>Blank</italic> axis, which is a linearly ramping variable between 0 and 1 from the beginning to the end of each blank period, indicating how long the perceptual memory trace, if present, has last since image offset.</p><p>To extract the neural subspace most relevant to each behavioral metric, half of the data were used as a training set and a multilinear regression model was fit for each sensor (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). The <italic>β</italic> weights from the regression model provide an estimate of the relative contributions of the activity of that sensor to each of the different behavioral metrics. The set of weights across sensors for a particular behavioral metric thus defines the identified neural subspace. The held-out test data are then projected into that subspace (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), which provides a prediction of the value of that behavioral metric at each time point, solely based on the MEG activity. Comparing the actual and predicted behavior (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) yields a cross-validated estimate of how much information the identified neural subspace has about that aspect of behavior.</p><p>Lastly, the set of <italic>β</italic> weights (with size equal to the number of MEG sensors) for each behavioral metric can also be inspected for consistency at the group level (topography in <xref ref-type="fig" rid="fig3">Figure 3B</xref>) to determine whether neural activity from a particular sensor significantly contributes to a particular behavioral metric. In sum, this state-space analysis allows us to simultaneously identify neural underpinnings of multiple aspects of behavior at once.</p></sec><sec id="s2-4"><title>Role of neural oscillations in perceptual switching dynamics during bistable perception</title><p>We first applied the state-space analysis to data from the <italic>Ambiguous</italic> condition. For perceptual content (‘Type’ axis), we found that the neural subspace identified using the SCP activity allows robust prediction of moment-to-moment perceptual content experienced by the subject for the face–vase image (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>, ‘Type’ column), with highly consistent sensor-level weights across subjects (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>, ‘Type’ column). Interestingly, the results did not reach significance for the cube image, consistent with weaker perceptual content decoding for the cube than face–vase image (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) and potentially due to the decoder being retrained at each time point whereas the subspace is fixed across time points. Using amplitude of alpha or beta oscillations, we could not achieve significant prediction of perceptual content (except for a small temporal cluster for beta amplitude, cube image) (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>, ‘Type’ column) and there were no consistent weights across subjects (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>, ‘Type’ column). Together, these results reinforce the impression from the decoding results showing that perceptual content information largely localizes to the SCP band, manifesting as moment-to-moment changes in large-scale SCP activity.</p><p>Focusing on the ‘Duration’ axis, which captures variability in the percept durations, we found consistent group-level <italic>β</italic> weights in occipital cortex for alpha and beta amplitudes, whereby stronger neural oscillations were associated with longer-lasting percepts (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, left; reproduced in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>, ‘Duration’ column). The ‘Duration’ neural subspace extracted from alpha and beta amplitudes contained significant predictive information for percept durations in the left-out test dataset, as evidenced by highly significant correlations between the actual percept duration and predicted percept duration according to neural data collected at different time points during a percept (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, right, showing trial-by-trial correlation; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>, ‘Duration’ column, showing predicted percept durations for trials with long vs. short actual percept durations). These results also show that neural activity related to perceptual stability is relatively persistent across time, evident from the beginning to the end of a percept. For SCP activity, significant predictive information over time was found for both images (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>, ‘Duration’ column); however, there was little consistency between <italic>β</italic> weights across subjects (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>, ‘Duration’ column), or between the group-level <italic>β</italic> weight maps for the two images (cosine similarity, <italic>N</italic> = 272 sensors, cos <italic>θ</italic> = 0.08, p = 0.37 assessed by a permutation test). By contrast, the group-level <italic>β</italic> weight maps for the ‘Duration’ axis are highly correlated between the two images for alpha amplitude (cos <italic>θ</italic> = 0.83, p = 0.02) and beta amplitude (cos <italic>θ</italic> = 0.82, p = 0.02). Therefore, we conclude that information about perceptual stability, as captured by percept duration, is primarily carried by the amplitude of alpha- and beta-band activity. Although this information also exists in the SCP band, it is encoded in a less consistent manner across subjects and across different image inputs.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Alpha and beta amplitudes are involved in the switching process and perceptual memory trace.</title><p>(<bold>A</bold>) (<italic>Left</italic>) Group-average <italic>β</italic> weights for Duration axis in the ambiguous condition. Sensors whose <italic>β</italic> weights are significantly different from zero (Wilcoxon signed-rank test, cluster-corrected, p &lt; 0.05) are marked with <italic>x</italic>. (<italic>Right</italic>) Mean Fisher <italic>z</italic>-transformed Spearman rho values, obtained by correlating predicted and actual behavioral values across trials for each subject. Shaded areas show group-level standard error of mean (SEM). Significant time points (p &lt; 0.05, cluster-based permutation test) are indicated by the horizontal red bars. (<bold>B</bold>) (<italic>Left</italic>) Group-average <italic>β</italic> weights for Memory axis in the discontinuous condition. Sensors whose group-level <italic>β</italic> weights are significantly different from zero (Wilcoxon signed-rank test, cluster-corrected, p &lt; 0.05) are marked with <italic>x</italic>. (<italic>Right</italic>) Difference in neural activity projected onto the Memory axis between the Stable and Unstable trials (i.e., blank periods sandwiched by the same percept or different percepts). Significant differences (p &lt; 0.05, cluster-based permutation test) between them are indicated by red horizontal bars.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Complete neural subspace results for the <italic>Ambiguous</italic> condition.</title><p>(<bold>A</bold>) Group-average <italic>β</italic> weights. Sensors whose <italic>β</italic> weights are significantly different from zero (Wilcoxon signed-rank test, cluster-corrected, p &lt; 0.05) are marked with <italic>x</italic>. (<bold>B</bold>) Test dataset projected onto each behavioral axis; shaded areas indicate SEM across subjects. For the Type axis, trials for the different percepts are projected and averaged separately, and difference between the trial-averaged projections are tested by a paired <italic>t</italic>-test across subjects (one-sided). For the Duration axis, the longest and shortest 50% of trials are averaged and compared by a paired <italic>t</italic>-test across subjects (one-sided). Significant temporal clusters (p &lt; 0.05, cluster-based permutation test) are indicated by black horizontal bars at the top. For the Switch and Direction axes, all trials are projected and averaged, and compared to the actual behavioral metric (shown as dashed black lines here, also see <xref ref-type="fig" rid="fig3">Figure 3A</xref>) using a Spearman correlation for the Switch axis and a two-sample <italic>t</italic>-test (between the first and second half of the trial) for the Direction axis. Subsequently, the rho and <italic>t</italic>-stats are tested at the group level by a Wilcoxon sign-rank test against zero (one-sided).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Complete neural subspace results for the <italic>Discontinuous</italic> condition.</title><p>(<bold>A</bold>) Group-average <italic>β</italic> weights. Sensors whose <italic>β</italic> weights are significantly different from zero (Wilcoxon signed-rank test, cluster-corrected, p &lt; 0.05) are marked with <italic>x</italic>. (<bold>B</bold>) Test dataset, including data from the blank periods only, projected onto each behavioral axis; shaded areas indicate SEM across subjects. For Pre and Post axes, trials for the different percepts are projected separately, and difference between them tested by a paired <italic>t</italic>-test (one-sided) across subjects. For the Blank axis, all trials are projected and averaged and compared to the actual behavior (shown as black dashed line here; also see <xref ref-type="fig" rid="fig3">Figure 3A</xref>) using a Spearman correlation; subsequently, the <italic>rho</italic> values were tested at the group level by a Wilcoxon sign-rank test against zero (one-sided). For the Memory axis, stable and unstable trials are projected separately, and the difference between them is plotted and tested by a one-sample <italic>t</italic>-test across subjects (one-sided).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-fig4-figsupp2-v2.tif"/></fig></fig-group><p>For the ‘Switch’ and ‘Direction’ axes, we found that all three neural features were significantly predictive of behavior (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>, ‘Switch’ and ‘Direction’ columns), suggesting that the neural representation of these processes is distributed across multiple frequency bands. For the ‘Direction’ axis, group-level <italic>β</italic> weight maps for SCP and beta amplitude show significant sensors lateralized over the left hemisphere whose spatial distribution could be related to the button press response (carried out using the right hand). For the ‘Switch’ axis, the SCP-band <italic>β</italic> weight maps are consistent with a dipole in the midline region corresponding to a potential source in the supplementary motor area; alpha/beta amplitudes have positive <italic>β</italic> weights suggesting that the amplitudes decrease around the time of the perceptual switch, consistent with earlier findings (<xref ref-type="bibr" rid="bib12">de Jong et al., 2016</xref>). Together, these findings provide a methodological validation of the present analysis approach; however, given the potential motor contribution to the results obtained from the ‘Switch’ and ‘Direction’ behavioral axes, we do not emphasize these findings henceforth.</p></sec><sec id="s2-5"><title>Role of neural oscillations in maintaining perceptual memory</title><p>Finally, we applied the state-space analysis to data from the <italic>Discontinuous</italic> condition, focusing on the blank periods (6 s each) between repeated image presentations (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). For perceptual content reported before and after each blank period (‘Pre’ and ‘Post’ axes), we only found small temporal clusters of significant prediction in the test dataset for beta amplitude-defined neural subspace in the case of cube image (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>, ‘Pre’ and ‘Post’ columns). Overall, the information contained in neural activity during blank periods about perceptual content experienced earlier or later is weak, which is not surprising, given that there is no active perception related to the cube or face–vase image per se during this period.</p><p>However, all three neural features carried significant information about how far into the blank period the time point was (i.e., the temporal distance to previous image offset), suggesting a strong timing mechanism distributed across frequency bands. This is evident in the ability of the neural subspaces to predict timing information in the left-out test dataset (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>, ‘Blank’ column), as well as consistent sensor-level <italic>β</italic> weight topography across subjects (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref>, ‘Blank’ column). The SCP topography shows a midline dipole, and the alpha/beta topographies show widespread sensors whose oscillatory amplitudes decrease as time passes. Because the blank periods have a constant duration (6 s) before the next image onset, these results are consistent with previous reports of a contingent negative variation potential (CNV, an SCP activity with generators in the anterior cingulate cortex) and alpha amplitude decreases being neural correlates of temporal anticipation (<xref ref-type="bibr" rid="bib36">Nobre and van Ede, 2018</xref>).</p><p>The most informative behavioral metric for the <italic>Discontinuous</italic> condition is the ‘Memory’ axis as it indicates the presence or absence of a perceptual memory trace (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Here, we found significant temporal clusters of prediction in the test dataset using alpha and beta amplitudes, but not SCP activity (which only showed small temporal clusters for the Cube image) (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>, ‘Memory’ column; alpha and beta results reproduced in <xref ref-type="fig" rid="fig4">Figure 4B</xref>). The consistency of the group-level <italic>β</italic> weights across images was also stronger for alpha (cos <italic>θ</italic> = 0.65, p = 0.08) and beta amplitudes (cos <italic>θ</italic> = 0.75, p = 0.10) than for SCP activity (cos <italic>θ</italic> = −0.11, p = 0.71), although the consistency did not reach significance in any of the neural features. Interestingly, the group-level <italic>β</italic> weight vectors are highly correlated between the Memory axis and the Blank axis for alpha and beta amplitudes (alpha amplitude: face–vase, cos <italic>θ</italic> = 0.84, p &lt; 0.01; cube: cos <italic>θ</italic> = 0.82, p = 0.01; beta amplitude: face–vase, cos <italic>θ</italic> = 0.83, p = 0.02, cube: cos <italic>θ</italic> = 0.86, p &lt; 0.01), suggesting a strong timing component to the memory trace. The negative <italic>β</italic> weights for the oscillation amplitudes (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, left) show that alpha and beta oscillations are weaker when there is a perceptual memory trace.</p><p>Interestingly, the encoding of perceptual memory during the blank periods occurs first in beta activity (at ~0.5–1.5 s after blank onset), followed by alpha activity (at ~1.5–3 s), and is not significant in either frequency band during the latter half of the blank period (3–6 s) (<xref ref-type="fig" rid="fig4">Figure 4B</xref> and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). This transient encoding of perceptual memory in neural dynamics is consistent with a recent EEG study using a similar paradigm (<xref ref-type="bibr" rid="bib64">Zhu et al., 2022</xref>). Speculatively, after the transient encoding in beta and alpha activities, perceptual memory trace might be maintained in short-term synaptic plasticity within the network in an ‘activity-silent’ state without measurable signatures in active neural dynamics (<xref ref-type="bibr" rid="bib35">Mongillo et al., 2008</xref>; <xref ref-type="bibr" rid="bib53">Stokes et al., 2013</xref>; <xref ref-type="bibr" rid="bib44">Rose et al., 2016</xref>).</p><p>Together with the earlier results showing that stronger alpha/beta amplitudes promote perceptual stability (i.e., longer-lasting percepts) during continuous bistable perception (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), these results show that the neural mechanisms supporting perceptual memory localize to the same frequency bands, but have different circuit-level mechanisms. In addition, sensors supporting perceptual memory (when the stimulus is temporarily removed from view) reside in more anterior regions than those supporting perceptual stability (when the stimulus is in view) (compare topoplots between <xref ref-type="fig" rid="fig4">Figure 4A, B</xref>), suggesting that higher-order brain circuits are recruited to maintain a perceptual memory trace when sensory input is absent, consistent with previous fMRI findings (<xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we dissected the roles that different types of neural activity play in perception. We found evidence that perceptual content is predominantly encoded in the SCP (&lt;5 Hz) range, and no evidence of perceptual content encoding in the amplitude of alpha and beta oscillations. This was the case regardless of whether the sensory input is ambiguous or unambiguous. We additionally found that SCP activity along with the amplitude of alpha and beta oscillations encoded aspects of perceptual switching, including the distance to a switch and whether the current percept is stabilizing or destabilizing. However, information about how long the current percept would last and whether a perceptual memory trace would occur if the stimulus is temporally removed from view was primarily encoded in alpha and beta amplitudes. Together, these results show a frequency-band separation of information related to perceptual content and perceptual stability, with the former encoded in raw fluctuations of low-frequency SCP activity, and the latter primarily influenced by the amplitude fluctuations of alpha and beta oscillations.</p><p>Previous studies on bistable perception have typically focused on one aspect of perceptual behavior at a time, such as perceptual content or perceptual switching. By using a novel neural state-space analysis approach, we were able to simultaneously extract components of neural activity relevant to different aspects of perceptual behavior that all vary across time/trials and are mutually independent. Additionally, this approach can uncover important relationships between neural activity underlying different aspects of behavior. For example, for alpha and beta amplitudes, the state space extracted for ‘Blank’ and ‘Memory’ axes in the <italic>Discontinuous</italic> condition are strongly correlated, suggesting a strong timing mechanism to how perceptual memory is encoded during the blank period (i.e., the neural activity pattern associated with the presence of a perceptual memory trace is similar to the activity pattern that increases over time during the blank period). Compared to other multivariate analysis methods, the neural state-space method has specific advantages and is well suited to addressing the questions investigated herein. First, compared to multivariate decoding, the state-space method extracts multivariate neural activity patterns relevant to multiple behavioral metrics simultaneously, as opposed to investigating neural correlate of one behavioral metric at a time. Second, compared to automatic dimensionality reduction, such as PCA and similar techniques (<xref ref-type="bibr" rid="bib10">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Cunningham and Yu, 2014</xref>; <xref ref-type="bibr" rid="bib1">Baria et al., 2017</xref>), the state-space approach directly identifies the neural activity pattern (i.e., neural subspace) relevant to a particular behavioral metric, as opposed to being behavior agnostic.</p><p>Our finding of perceptual content encoding in the SCP band provides further evidence of the role of SCP in conscious perception, consistent with earlier studies (<xref ref-type="bibr" rid="bib30">Li et al., 2014</xref>; <xref ref-type="bibr" rid="bib1">Baria et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Flounders et al., 2019</xref>). A general role of SCP in supporting conscious awareness (<xref ref-type="bibr" rid="bib20">He and Raichle, 2009</xref>) is also corroborated by recent findings comparing different states of consciousness (<xref ref-type="bibr" rid="bib3">Bourdillon et al., 2020</xref>; <xref ref-type="bibr" rid="bib55">Toker et al., 2022</xref>). In the domain of bistable perception, most studies probing neural correlates of perceptual content have employed fMRI (e.g., <xref ref-type="bibr" rid="bib56">Tong et al., 1998</xref>; <xref ref-type="bibr" rid="bib19">Haynes and Rees, 2005</xref>; <xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>), and most electrophysiological studies have focused on changes in ERPs (e.g., <xref ref-type="bibr" rid="bib5">Britz et al., 2009</xref>; <xref ref-type="bibr" rid="bib42">Pitts et al., 2009</xref>), oscillatory power (e.g., <xref ref-type="bibr" rid="bib12">de Jong et al., 2016</xref>), or neuronal firing rates (<xref ref-type="bibr" rid="bib16">Gelbard-Sagiv et al., 2018</xref>) around perceptual switches. Previous electrophysiological studies probing neural correlates of perceptual content have typically used specialized stimulus design, such as frequency tagging (<xref ref-type="bibr" rid="bib57">Tononi et al., 1998</xref>; <xref ref-type="bibr" rid="bib52">Srinivasan et al., 1999</xref>), binocular rivalry involving face and oriented grating (where face-elicited ERFs, the M170, correlates with perceiving faces) (<xref ref-type="bibr" rid="bib47">Sandberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Sandberg et al., 2014</xref>), or auditory bistable stimuli where neural information integration correlates with perceiving an integrated auditory stream (<xref ref-type="bibr" rid="bib6">Canales-Johnson et al., 2020</xref>). Here, by using classic ambiguous figures where the two percepts are symmetrical in salience and level of cortical processing, and showing results consistent across different images, our findings provide a more generalizable electrophysiological correlate of perceptual content. Our results also complement a recent intracranial electrophysiology study using the same ambiguous figures which revealed changes in corticocortical information flow depending on the specific perceptual content experienced (<xref ref-type="bibr" rid="bib17">Hardstone et al., 2021</xref>). Finally, the potential role of gamma frequency band in encoding perceptual content should be further investigated in future studies using intracranial recordings which are more sensitive to gamma-band activity than MEG (e.g., <xref ref-type="bibr" rid="bib39">Panagiotaropoulos et al., 2012</xref>).</p><p>A relationship between alpha and beta amplitudes and the stability of percepts has been reported in several previous studies of bistable perception (<xref ref-type="bibr" rid="bib27">Kloosterman et al., 2015</xref>; <xref ref-type="bibr" rid="bib41">Piantoni et al., 2017</xref>; <xref ref-type="bibr" rid="bib64">Zhu et al., 2022</xref>). Although the detailed mechanisms involved remain unclear, two non-mutually exclusive mechanisms have been proposed: lateral inhibition and the resulting dynamical attractor at a local scale (<xref ref-type="bibr" rid="bib41">Piantoni et al., 2017</xref>) and top-down feedback from higher-order regions (<xref ref-type="bibr" rid="bib27">Kloosterman et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Zhu et al., 2022</xref>). While both local inhibition and top-down processing roles have been ascribed to alpha and beta oscillations (<xref ref-type="bibr" rid="bib23">Jensen and Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="bib34">Michalareas et al., 2016</xref>; <xref ref-type="bibr" rid="bib51">Spitzer and Haegens, 2017</xref>), we believe that our finding of higher alpha/beta amplitude being associated with stronger perceptual stability (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) is more compatible with a top-down interpretation. While lateral inhibition between competing neuronal groups is a key ingredient of biophysical models of bistable perception (e.g., <xref ref-type="bibr" rid="bib49">Shpiro et al., 2009</xref>), and enhancing cortical inhibition by administering lorazepam, a GABA<sub>A</sub> receptor agonist, enhances perceptual stability (<xref ref-type="bibr" rid="bib60">van Loon et al., 2013</xref>), lorazepam also has the effect of reducing alpha power (<xref ref-type="bibr" rid="bib31">Lozano-Soldevilla, 2018</xref>)—opposite to the present finding of a positive correlation between perceptual stability and alpha power. By contrast, recent intracranial electrophysiological evidence suggests that top-down feedback can carry perceptual templates congruent with long-term priors that act to stabilize a particular percept (<xref ref-type="bibr" rid="bib17">Hardstone et al., 2021</xref>). Given the well-documented role of alpha and beta oscillations in carrying top-down feedback (<xref ref-type="bibr" rid="bib59">van Kerkoerle et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Bastos et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">Michalareas et al., 2016</xref>), a plausible mechanism for the present finding of higher alpha/beta amplitudes being associated with longer percept durations is then a top-down modulatory influence carried in the alpha and beta bands.</p><p>Similarly, we interpret our finding of alpha and beta amplitudes being associated with perceptual memory as reflecting a top-down modulatory influence. Consistent with this interpretation, a previous fMRI study showed that the content of perception and perceptual memory during intermittent presentation of ambiguous images is especially decodable in higher-order frontoparietal regions, and that intermittent presentation elicits strong top-down influences as compared to continuous presentation (<xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>). The locations of sensors involved in perceptual memory (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) are more anterior than those involved in perceptual stability (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), which may reflect the source and target of top-down modulation, respectively.</p><p>Our finding of alpha and beta amplitudes being related to perceptual memory is concordant with a recent EEG study (<xref ref-type="bibr" rid="bib64">Zhu et al., 2022</xref>), but, superficially, the two studies appear to report opposite directions of this relationship: a negative correlation (manifested as negative <italic>β</italic> weights) in the present study versus a positive correlation in the earlier EEG study. However, a closer inspection suggests that the two studies are in fact consistent: Zhu et al. used short blank durations (~0.5–1.5 s), and alpha/beta amplitudes are higher in stable-blank trials than unstable-blank trials early (within 500 ms of blank-onset) during the blank period, but lower in stable-blank trials (after 800 ms) late in the blank periods (<xref ref-type="fig" rid="fig4">Figure 4B</xref> therein). The present study used long blank durations (6 s), and the lower alpha/beta amplitude in stable-blank trials is mostly evident at 500 ms following blank onset or later (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, right, note ‘projected average’ is amplitude multiplied by <italic>β</italic> weights, which are negative). The exact neurophysiological mechanisms contributing to these time courses remain to be investigated, but both studies converge to suggest that alpha and beta amplitudes influence not only perceptual stability when sensory input is in view but also perceptual memory when sensory input is temporarily removed from view. Importantly, the present results differ from previous studies showing beta power increases during working memory maintenance (<xref ref-type="bibr" rid="bib51">Spitzer and Haegens, 2017</xref>), reinforcing the notion that perceptual memory differs from working memory: the former is unconscious and automatic (<xref ref-type="bibr" rid="bib40">Pearson and Brascamp, 2008</xref>), while the latter is largely conscious and deliberate (<xref ref-type="bibr" rid="bib58">Trübutschek et al., 2019</xref>). Furthermore, we found that neural activity (in the alpha and beta bands) underlying perceptual memory has significant overlap with neural activity encoding elapsed time (as evidenced by a significant positive correlation of <italic>β</italic> weight vectors for the ‘Blank’ and ‘Memory’ axes), which also fits better with an automatic process as opposed to an working memory account (<xref ref-type="bibr" rid="bib50">Souza and Oberauer, 2015</xref>; <xref ref-type="bibr" rid="bib15">Fulvio and Postle, 2020</xref>).</p><p>In sum, across multiple perceptual conditions (unambiguous vs. ambiguous sensory input; continuous vs. intermittent presentation), we found that distinct components of dynamical neural activity contribute to the content vs. stability of perception. While perceptual content is encoded in the activity pattern of low-frequency neural activity in the SCP band, perceptual stability and perceptual memory are influenced by the fluctuations of alpha and beta oscillation amplitudes. These results provide clues to the neural mechanisms underlying stable visual experiences in the natural environment, wherein the ever-present noise and instability in the retinal images must be overcome to reconstruct the cause of sensory input in order to guide adaptive behavior. Finally, these results also inform future computational models of bistable visual perception and efforts to understand pathological processes underlying perceptual disorders in mental illnesses, including abnormal bistable perceptual dynamics in autism and schizophrenia (<xref ref-type="bibr" rid="bib43">Robertson et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Kornmeier et al., 2017</xref>; <xref ref-type="bibr" rid="bib62">Weilnhammer et al., 2020</xref>).</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Subjects</title><p>The experiment was approved by the Institutional Review Board of the National Institute of Neurological Disorders and Stroke (under protocol #14 N-0002). All subjects were right handed and neurologically healthy with normal or corrected-to-normal vision. Nineteen subjects between 19 and 33 years of age (mean age 24.5; nine females) participated in the MEG experiment. We excluded one subject from analysis due to repeatedly falling asleep during the task. All subjects provided written informed consent.</p></sec><sec id="s4-2"><title>Task design and behavioral analysis</title><p>The task was adapted from a previously run fMRI experiment (<xref ref-type="bibr" rid="bib61">Wang et al., 2013</xref>). In the study, two well-known ambiguous images (Necker cube and Rubin face–vase) were used to study bistable perception under continuous (<italic>Ambiguous</italic> condition) and intermittent presentation (<italic>Discontinuous</italic> condition) (<xref ref-type="fig" rid="fig1">Figure 1</xref>). As a control, we also included a condition where we manipulated the content, outlines, and shading of the ambiguous images to accentuate one of the two percepts (<italic>Unambiguous</italic> condition), with the intention that the subject would perceive that percept.</p><p>Stimuli were presented using E-Prime Software (Psychology Software Tools, Sharpsburg, PA) via a Panasonic PT-D3500U projector with an ET-DLE400 lens, with the screen 55 cm from the subject’s eyes. All face–vase images subtended 16.9 × 17.6 (height × width) degrees of visual angle, and all cube images subtended 14.3 × 14.5 degree.</p><p>Each subject completed 12 runs, consisting of 4 sets of 3 runs in the following order: Unambiguous, Ambiguous, and Discontinuous conditions.</p><p>Each Ambiguous run contained six trials, with each trial consisting of 2 s of written instruction, 2 s of fixation (while fixating on a crosshair in the center of the screen), 60 s of image presentation, and 3–7 s of intertrial interval (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Each ambiguous image was presented three times in a pseudorandom order. Subjects reported every spontaneous perceptual switch using their right hand via one of three buttons throughout the course of image presentation: one button for each of the possible percepts, and one for ‘Unsure’ which they were instructed to press if they experience neither or both of the possible percepts. In order to investigate spontaneous perceptual switches, subjects were instructed to passively view the images and not to try to switch or hold onto a percept.</p><p>Each Unambiguous run contained 32 trials, with each block consisting of 2 s of written instruction, 2 s of fixation, 5 s of image presentation, and 3–7 s of intertrial interval (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The four unambiguous images were presented eight times each in a pseudorandom order. Subjects were asked to indicate their percept via one of three buttons (one button for each possible percept, and one for unsure) at each image presentation. Valid trials consisted of subjects pressing the button for the intended percept once, and no other button presses (<xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><p>Each Discontinuous run contained six trials, with each trial consisting of 2 s of written instruction, 2 s of fixation, nine repetitions of 2 s image presentation followed by a 6 s blank period (of which the last second contained the crosshair in the center of the screen) (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). Subjects were asked to indicate their percept during each image presentation via a button press, and not to press buttons during the blank period. Perceptual switching during the 2 s image presentation was very rare and was excluded from analyses. The two ambiguous images were presented in alternating trials.</p><p>For all conditions, subjects were instructed to fixate upon a crosshair at the center of the screen at all times to avoid the potential influence of gaze on perception. Response mapping was altered between runs, by switching the buttons for the two percepts. For the first nine subjects the response mapping for the two percepts was switched after every run. For the final 10 subjects, we instead switched the response mapping after every set of 3 runs. Before entering the MEG, subjects performed practice runs until they were comfortable with the task and the buttons corresponding to each percept.</p></sec><sec id="s4-3"><title>MEG recordings</title><p>While performing the task, we recorded neural activity from each subject using a 275-channel whole-head MEG system (CTF). Three dysfunctional sensors were removed from all analyses. We also recorded gaze position and pupil size using a SR Research Eyelink 1000+ system. Eye-tracking was used for online monitoring of fixation and wakefulness during the experiment. MEG data were recorded at a sampling rate of 600 Hz, with a low-pass anti-aliasing filter of 150 Hz and no high-pass filter (i.e., DC recording). Before and after each run, the head position of a subject was measured using fiducial coils, in order to detect excessive movement. During each task subjects responded using a fibreoptic response button box. All MEG data samples were realigned with respect to the presentation delay of the projector (measured with a photodiode).</p></sec><sec id="s4-4"><title>MEG data preprocessing and feature extraction</title><p>All preprocessing and analysis of data were performed in MATLAB (Mathworks, Natick, MA) using custom-written code and the FieldTrip toolbox (<xref ref-type="bibr" rid="bib37">Oostenveld et al., 2011</xref>). MEG data were first demeaned and detrended. Data were then filtered at 0.05–150 Hz using a third-order Butterworth filter, and line noise as well as harmonics were removed using fourth-order Butterworth band-stop filters (58–62, 118–122, and 178–182 Hz). Independent component analysis (Fieldtrip <italic>runica</italic> method) was then applied, and components were manually inspected to remove those related to eye blinks, eye movements, or heart-beat-related artifacts.</p><p>Three different features of neural activity were then extracted. SCP activity was obtained using a third-order low-pass Butterworth filter at 5 Hz. Alpha-band amplitude was extracted by taking the absolute of the Hilbert transform (Matlab, <italic>abs(hilbert(data))</italic>) of the preprocessed MEG data that had been filtered at 8–13 Hz using a third-order Butterworth filter. Beta-band amplitude was extracted in the same way, but using data filtered in the 13–30 Hz range.</p></sec><sec id="s4-5"><title>Decoding perceptual content</title><p>We attempted to decode perceptual content during the Ambiguous and Unambiguous conditions using the three extracted neural features (SCP, alpha amplitude, beta amplitude). For the <italic>Ambiguous</italic> condition, we first extracted periods between button presses where each button press was for a different percept (excluding ‘Unsure’ button presses), and the period was labeled according to the first button press (i.e., Face, Vase, Green, or Blue). As these periods were all of different durations, we then rescaled them to be the same length by selecting 100 equally spaced time points, giving us percentiles of the percept’s duration. For the <italic>Unambiguous</italic> condition, we selected valid trials for analysis, wherein the subject only pressed a button once for the intended percept. The time period used for decoding was the 5 s that the image was on the screen, and MEG data were downsampled to 10 Hz before applying the decoding pipeline. The label of the trial was the image that was presented (i.e., Face, Vase, Green, or Blue). For both task conditions, the classification was done separately for the Necker Cube (Green vs. Blue) and Rubin face–vase (Face vs. vase). All trials were normalized (<italic>z</italic>-scored) across sensors at each time point. Trials were then split into fourfolds with an equal number of trials of each label in each fold. Trials for a fold were selected by taking every fourth trial of that trial type (ordered by when the trial occurred during the recording).</p><p>The decoding pipeline consisted of taking one fold as the testing set, and training a linear SVM classifier (cost = 1) using the LIBSVM packages (<xref ref-type="bibr" rid="bib9">Chang and Lin, 2011</xref>) at each time point to the trials from the other threefolds, which constituted the training set. Decoding accuracy of the classifier was then calculated on the testing set. The temporal cross-generalization of the classifier was also tested by assessing its classification accuracy at every other time point. This was done using each fold as the testing set, and the decoding accuracy (and temporal generalization) was averaged across the fourfolds.</p></sec><sec id="s4-6"><title>Cluster-based permutation tests for multivariate pattern decoding</title><p>The group-level statistical significance of classifier accuracy at each time point was assessed by a one-tailed, one-sample Wilcoxon signed-rank test against chance level (50%). To correct for multiple comparisons, we used cluster-based permutation tests (<xref ref-type="bibr" rid="bib33">Maris and Oostenveld, 2007</xref>). Temporal clusters were defined as contiguous time points with above-threshold classification accuracy (cluster-defining threshold: p &lt; 0.1). The test statistic <italic>W</italic> of the Wilcoxon signed-rank test was summed across time points in a cluster to yield a cluster’s summary statistic. Cluster summary statistics were compared to a null distribution, constructed by shuffling class labels 100 times, and extracting the largest cluster summary statistic for each permutation. Clusters in original data with summary statistics exceeding the 95th percentile of null distribution were considered significant (corresponding to p &lt; 0.05, cluster-corrected, one-tailed test). For classifier temporal generalization, the permutation-based approach for cluster-level statistical inference used the same procedure as above, where clusters were defined as contiguous time points in training and/or generalization dimensions with above threshold (p &lt; 0.1) classification accuracy.</p></sec><sec id="s4-7"><title>Neural state-space analysis</title><p>To work out the relative contributions of different behaviors to neural activity patterns, we developed a novel multivariate analysis method to extract the neural subspace relevant to each behavior, following the approach used in <xref ref-type="bibr" rid="bib32">Mante et al., 2013</xref>. While perceptual content is clearly an important aspect of behavior, there are other aspects of behavior which account for the perceptual switching dynamics (<italic>Ambiguous</italic> condition) and perceptual memory (<italic>Discontinuous</italic> condition). For the <italic>Ambiguous</italic> condition, we first selected 100 equally spaced time points from each period that occurred between button presses for the two percepts (i.e., not for time points preceded or followed by an unsure button press). We then defined four behavioral metrics for each time point:</p><list list-type="bullet"><list-item><p><italic>Type</italic>, a binary variable indicating the current percept.</p></list-item><list-item><p><italic>Duration</italic>, a continuous variable which takes the same value throughout a percept and is normalized within subject (i.e., 0 for the shortest percept reported and 1 for the longest percept).</p></list-item><list-item><p><italic>Switch</italic>, a continuous variable that was 0 at the time of a button press and 1 at the midway point between button presses, indicating the relative temporal distance to perceptual switches.</p></list-item><list-item><p><italic>Direction</italic>, a binary variable indicating whether the current percept is stabilizing (i.e., time point is in the first half of its duration) or destabilizing (i.e., in the second half of its duration).</p></list-item></list><p>For the <italic>Discontinuous</italic> condition, only time points during the blank period (6 s total, including the 1 s fixation period) were used, where the blank period was preceded and followed by an image presentation during which the subject pressed for one of the two percepts. Four behavioral metrics were defined.</p><list list-type="bullet"><list-item><p><italic>Pre</italic>, a binary variable indicating the percept reported before the blank period.</p></list-item><list-item><p><italic>Post</italic>, a binary variable indicating the percept reported after the blank period.</p></list-item><list-item><p><italic>Blank</italic>, a continuous variable increasing from 0 at the beginning of the blank period to 1 at the end of the blank period, indicating time elapsed during the blank period.</p></list-item><list-item><p><italic>Memory</italic>, a binary variable indicating whether the percept before the blank was the same as that after the blank, with 1 indicating the presence of a memory trace and 0 indicating the absence of a memory trace.</p></list-item></list><p>These time points were split into two datasets (first and second half of time points based on time through experiment), with the first half used as the training set, and the second half used as the test set. Using the training dataset, the MEG data (applied separately for the three neural features: SCP, alpha amplitude, and beta amplitude) for each sensor are first normalized over time using the mean and standard deviation from the training set. A multilinear regression of the following form was solved to find the <italic>β</italic> weights in the equation (using MATLAB function <italic>fitlm</italic>, with <italic>RobustOpts</italic>).<disp-formula id="equ1"><mml:math id="m1"><mml:msub><mml:mrow><mml:mi>M</mml:mi><mml:mi>E</mml:mi><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi> </mml:mi><mml:mi>ε</mml:mi></mml:math></disp-formula></p><p>These <italic>β</italic> weights define the axes of the behavioral subspace for that neural feature. MEG data from the test set (which has been normalized at the individual sensor level using the mean and standard deviation from the training set, so that the projection method does not depend on any information from the test set) can then be projected onto the behavioral axes (using the MATLAB function <italic>mldivide</italic>). This gives a prediction of the value for each behavioral metric based on neural activity at each time point of the test set.</p></sec><sec id="s4-8"><title>Statistics for neural state-space analysis</title><p>To assess the consistency across subjects of the <italic>β</italic> weights defining each behavioral axis, and whether each neural feature carried predictive information about the behavior, a cluster-based permutation method (<xref ref-type="bibr" rid="bib33">Maris and Oostenveld, 2007</xref>) was applied separately for each axis. This involved shuffling the behavioral information across all of the trials only for that axis. For axes where behavior was defined in the same way for each trial (Ambiguous: Switch and Direction Axes; Discontinuous: Blank Axis), each trial was instead ‘flipped’ with a 50% chance, where the flipped trial was equal to 1 — original behavior. Once the behavioral data were shuffled, the state-space analysis was reapplied, and this was done for 100 permutations of the data.</p><p>To assess consistency of the <italic>β</italic> weights defining each behavioral axis, a two-sided Wilcoxon sign-rank test against zero was applied separately to each electrode. To correct for multiple comparisons across sensors, we used cluster-based permutation tests (<xref ref-type="bibr" rid="bib33">Maris and Oostenveld, 2007</xref>). Spatially contiguous electrodes with a significant bias (p &lt; 0.05) and the same sign of the test statistic <italic>W</italic>, formed a cluster (either positive or negative depending on the sign) where the cluster summary statistic was the sum of the electrodes’ test statistic <italic>W</italic>. This cluster summary statistic was compared to a null distribution, formed from the largest (i.e., most positive or most negative) cluster summary statistic for each permutation. Clusters in original data with summary statistics exceeding the 95th percentile of null distribution were considered significant (corresponding to p &lt; 0.05, cluster-corrected, one-tailed test). Positive and negative clusters were assessed separately by comparison to the respective null distribution.</p><p>To assess consistency between two state spaces (either between <italic>β</italic> weight maps for the two different images and the same axis, or between two different axes and the same image), cosine similarity was applied.<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">B</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">A</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> correspond to the two <italic>β</italic> weight maps. Cosine similarity produces a value between −1 and 1, where 1 indicates that the projection of the MEG data into the two behavioral state spaces would produce perfectly correlated behavioral estimates, and −1 indicates that they would be entirely anticorrelated. To assess significance of the cosine similarity, a null distribution was created by calculating cosine similarity between the two <italic>β</italic> maps for each permutation, and the p value was calculated as the fraction of this distribution with values larger than the cosine similarity of the original data.</p><p>To assess whether each neural feature carried predictive information about each behavioral axis, a different test was applied depending on the axis. In the following analyses, a one-sided statistical test is often used because if the neural subspace is successfully extracted, the predicted behavioral metric in the test dataset should follow specific relationships similar to the definition of these axes (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><p>First, data from the test dataset were projected into the neural subspace defined for each axis using the training data. For those axes with binary behavior that had the same value across time for each trial (Ambiguous: Type; Discontinuous: Pre, Post), a paired <italic>t</italic>-test across subjects (one-sided) was applied at each time point between the trial-averaged predicted behavior for the two groups of trials (e.g., Green Cube and Blue Cube).</p><p>For the axis with continuous behavior that had the same value across time for each trial (Ambiguous: Duration), two analyses were carried out: (1) (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) For each subject, predicted percept duration (using neural activity at each time point) was correlated with the actual percept duration across trials by a Spearman correlation. The rho values were then subjected to a Wilcoxon sign-rank test across subjects (one-sided), and corrected for multiple comparisons using cluster-based permutation test.</p><p>A one-sided Wilcoxon sign-rank test was applied at each time point between the predicted and actual behavior. (2) (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>) A median split was performed on the test dataset for each subject according to percept duration. The projected data (i.e., predicted percept duration based on neural data) were then compared between the two groups of trials by a paired <italic>t</italic>-test across subjects (one-sided), and corrected for multiple comparisons using cluster-based permutation test.</p><p>For those axes where the actual behavior changed across time within a trial in a continuous manner (Ambiguous: Switch; Discontinuous: Blank), the trial-averaged predicted behavior from each subject was compared to the actual behavior using a Spearman correlation. The Spearman rho values were then subjected to a group-level test using a Wilcoxon signed-rank test against zero (one-sided).</p><p>Lastly, for the axis where actual behavior changed across a trial in a binary manner (Ambiguous: Direction), the trial-averaged predicted behavior for each subject was compared between the first half of the trial and the second half of the trial using a two-sample <italic>t</italic>-test. The resulting <italic>t</italic>-values were then subjected to a Wilcoxon signed-rank test against zero (one-sided) at the group level.</p><p>To correct for multiple comparisons, we used cluster-based permutation tests (<xref ref-type="bibr" rid="bib33">Maris and Oostenveld, 2007</xref>). Temporal clusters were defined as contiguous time points with above-threshold test statistic (cluster-defining threshold: p &lt; 0.05). The test statistic (Wilcoxon signed rank (<italic>W</italic>) or <italic>t</italic>-test (<italic>t</italic>)) was summed across time points in a cluster to yield a cluster’s summary statistic. Cluster summary statistics were compared to a null distribution, formed by extracting the largest cluster summary statistic for each permutation. Clusters in original data with summary statistics exceeding the 95th percentile of null distribution were considered significant (corresponding to p &lt; 0.05, cluster-corrected, one-tailed test).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation</p></fn><fn fn-type="con" id="con3"><p>Investigation</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Validation, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>This experiment was approved by the Institutional Review Board of the National Institute of Neurological Disorders and Stroke (under protocol #14 N-0002). All subjects provided written informed consent for the research use and eventual publication of their data.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-78108-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The dataset generated by this study, including data and code to reproduce all the figures, are shared through figshare: doi:<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.19375910">https://doi.org/10.6084/m9.figshare.19375910</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Hardstone</surname><given-names>R</given-names></name><name><surname>Flounders</surname><given-names>MW</given-names></name><name><surname>Zhu</surname><given-names>M</given-names></name></person-group><source>figshare</source><pub-id pub-id-type="doi">10.6084/m9.figshare.19375910</pub-id><year iso-8601-date="2022">2022</year><data-title>Analysis Scripts, Plotting Scripts, Data for Plotting</data-title></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by a National Science Foundation CAREER Award (BCS-1753218), an Irma T Hirschl Career Scientist Award, and a National Institutes of Health grant (R01EY032085) to B.J.H. M.Z. was supported by NIH Training Grant R90DA043849.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baria</surname><given-names>AT</given-names></name><name><surname>Maniscalco</surname><given-names>B</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Initial-state-dependent, robust, transient neural dynamics encode conscious visual perception</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005806</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005806</pub-id><pub-id pub-id-type="pmid">29176808</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname><given-names>AM</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>Bosman</surname><given-names>CA</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Dowdall</surname><given-names>JR</given-names></name><name><surname>De Weerd</surname><given-names>P</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Visual areas exert feedforward and feedback influences through distinct frequency channels</article-title><source>Neuron</source><volume>85</volume><fpage>390</fpage><lpage>401</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.12.018</pub-id><pub-id pub-id-type="pmid">25556836</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bourdillon</surname><given-names>P</given-names></name><name><surname>Hermann</surname><given-names>B</given-names></name><name><surname>Guénot</surname><given-names>M</given-names></name><name><surname>Bastuji</surname><given-names>H</given-names></name><name><surname>Isnard</surname><given-names>J</given-names></name><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>Sitt</surname><given-names>J</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain-scale cortico-cortical functional connectivity in the delta-theta band is a robust signature of conscious states: an intracranial and scalp EEG study</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>14037</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-70447-7</pub-id><pub-id pub-id-type="pmid">32820188</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Briggman</surname><given-names>KL</given-names></name><name><surname>Abarbanel</surname><given-names>HDI</given-names></name><name><surname>Kristan</surname><given-names>WB</given-names><suffix>Jr</suffix></name></person-group><year iso-8601-date="2005">2005</year><article-title>Optical imaging of neuronal populations during decision-making</article-title><source>Science</source><volume>307</volume><fpage>896</fpage><lpage>901</lpage><pub-id pub-id-type="doi">10.1126/science.1103736</pub-id><pub-id pub-id-type="pmid">15705844</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britz</surname><given-names>J</given-names></name><name><surname>Landis</surname><given-names>T</given-names></name><name><surname>Michel</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Right parietal brain activity precedes perceptual alternation of bistable stimuli</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>55</fpage><lpage>65</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn056</pub-id><pub-id pub-id-type="pmid">18424780</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Canales-Johnson</surname><given-names>A</given-names></name><name><surname>Billig</surname><given-names>AJ</given-names></name><name><surname>Olivares</surname><given-names>F</given-names></name><name><surname>Gonzalez</surname><given-names>A</given-names></name><name><surname>Garcia</surname><given-names>MDC</given-names></name><name><surname>Silva</surname><given-names>W</given-names></name><name><surname>Vaucheret</surname><given-names>E</given-names></name><name><surname>Ciraolo</surname><given-names>C</given-names></name><name><surname>Mikulan</surname><given-names>E</given-names></name><name><surname>Ibanez</surname><given-names>A</given-names></name><name><surname>Huepe</surname><given-names>D</given-names></name><name><surname>Noreika</surname><given-names>V</given-names></name><name><surname>Chennu</surname><given-names>S</given-names></name><name><surname>Bekinschtein</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dissociable neural information dynamics of perceptual integration and differentiation during bistable perception</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>4563</fpage><lpage>4580</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhaa058</pub-id><pub-id pub-id-type="pmid">32219312</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carlson</surname><given-names>T</given-names></name><name><surname>Tovar</surname><given-names>DA</given-names></name><name><surname>Alink</surname><given-names>A</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Representational dynamics of object vision: the first 1000 MS</article-title><source>Journal of Vision</source><volume>13</volume><elocation-id>e1</elocation-id><pub-id pub-id-type="doi">10.1167/13.10.1</pub-id><pub-id pub-id-type="pmid">23908380</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cavanagh</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1991">1991</year><chapter-title>What’s up in top-down processing</chapter-title><person-group person-group-type="editor"><name><surname>Cavanagh</surname><given-names>P</given-names></name></person-group><source>Representation of Vision: Trends and Tacit Assumptions in Vision Research</source><publisher-name>Cambridge University Press</publisher-name><fpage>295</fpage><lpage>304</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CC</given-names></name><name><surname>Lin</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>LIBSVM: a library for support vector machines</article-title><source>ACM Transactions on Intelligent Systems and Technology</source><volume>2</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1145/1961189.1961199</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Foster</surname><given-names>JD</given-names></name><name><surname>Nuyujukian</surname><given-names>P</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id><pub-id pub-id-type="pmid">25151264</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Jong</surname><given-names>MC</given-names></name><name><surname>Hendriks</surname><given-names>RJM</given-names></name><name><surname>Vansteensel</surname><given-names>MJ</given-names></name><name><surname>Raemaekers</surname><given-names>M</given-names></name><name><surname>Verstraten</surname><given-names>FAJ</given-names></name><name><surname>Ramsey</surname><given-names>NF</given-names></name><name><surname>Erkelens</surname><given-names>CJ</given-names></name><name><surname>Leijten</surname><given-names>FSS</given-names></name><name><surname>van Ee</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Intracranial recordings of occipital cortex responses to illusory visual events</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>6297</fpage><lpage>6311</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0242-15.2016</pub-id><pub-id pub-id-type="pmid">27277806</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donoghue</surname><given-names>T</given-names></name><name><surname>Haller</surname><given-names>M</given-names></name><name><surname>Peterson</surname><given-names>EJ</given-names></name><name><surname>Varma</surname><given-names>P</given-names></name><name><surname>Sebastian</surname><given-names>P</given-names></name><name><surname>Gao</surname><given-names>R</given-names></name><name><surname>Noto</surname><given-names>T</given-names></name><name><surname>Lara</surname><given-names>AH</given-names></name><name><surname>Wallis</surname><given-names>JD</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>Shestyuk</surname><given-names>A</given-names></name><name><surname>Voytek</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Parameterizing neural power spectra into periodic and aperiodic components</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1655</fpage><lpage>1665</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00744-x</pub-id><pub-id pub-id-type="pmid">33230329</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flounders</surname><given-names>MW</given-names></name><name><surname>González-García</surname><given-names>C</given-names></name><name><surname>Hardstone</surname><given-names>R</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural dynamics of visual ambiguity resolution by perceptual prior</article-title><source>eLife</source><volume>8</volume><elocation-id>e861</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.41861</pub-id><pub-id pub-id-type="pmid">30843519</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fulvio</surname><given-names>JM</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cognitive control, not time, determines the status of items in working memory</article-title><source>Journal of Cognition</source><volume>3</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.5334/joc.98</pub-id><pub-id pub-id-type="pmid">32292872</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelbard-Sagiv</surname><given-names>H</given-names></name><name><surname>Mudrik</surname><given-names>L</given-names></name><name><surname>Hill</surname><given-names>MR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human single neuron activity precedes emergence of conscious perception</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>2057</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-03749-0</pub-id><pub-id pub-id-type="pmid">29802308</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardstone</surname><given-names>R</given-names></name><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Flinker</surname><given-names>A</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name><name><surname>Devore</surname><given-names>S</given-names></name><name><surname>Friedman</surname><given-names>D</given-names></name><name><surname>Dugan</surname><given-names>P</given-names></name><name><surname>Doyle</surname><given-names>WK</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Long-Term priors influence visual perception through recruitment of long-range feedback</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>6288</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26544-w</pub-id><pub-id pub-id-type="pmid">34725348</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname><given-names>S</given-names></name><name><surname>Meinecke</surname><given-names>F</given-names></name><name><surname>Görgen</surname><given-names>K</given-names></name><name><surname>Dähne</surname><given-names>S</given-names></name><name><surname>Haynes</surname><given-names>J-D</given-names></name><name><surname>Blankertz</surname><given-names>B</given-names></name><name><surname>Bießmann</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>On the interpretation of weight vectors of linear models in multivariate neuroimaging</article-title><source>NeuroImage</source><volume>87</volume><fpage>96</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.067</pub-id><pub-id pub-id-type="pmid">24239590</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haynes</surname><given-names>JD</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Predicting the stream of consciousness from activity in human visual cortex</article-title><source>Current Biology</source><volume>15</volume><fpage>1301</fpage><lpage>1307</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2005.06.026</pub-id><pub-id pub-id-type="pmid">16051174</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>BJ</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The fMRI signal, slow cortical potential and consciousness</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>302</fpage><lpage>309</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.04.004</pub-id><pub-id pub-id-type="pmid">19535283</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>BJ</given-names></name><name><surname>Zempel</surname><given-names>JM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The temporal structures and functional significance of scale-free brain activity</article-title><source>Neuron</source><volume>66</volume><fpage>353</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.04.020</pub-id><pub-id pub-id-type="pmid">20471349</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Scale-free brain activity: past, present, and future</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>480</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.04.003</pub-id><pub-id pub-id-type="pmid">24788139</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Mazaheri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Shaping functional architecture by oscillatory alpha activity: gating by inhibition</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>186</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00186</pub-id><pub-id pub-id-type="pmid">21119777</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kayser</surname><given-names>SJ</given-names></name><name><surname>McNair</surname><given-names>SW</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Prestimulus influences on auditory perception from sensory representations and decision processes</article-title><source>PNAS</source><volume>113</volume><fpage>4842</fpage><lpage>4847</lpage><pub-id pub-id-type="doi">10.1073/pnas.1524087113</pub-id><pub-id pub-id-type="pmid">27071110</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id><pub-id pub-id-type="pmid">24593982</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>J-R</given-names></name><name><surname>Pescetelli</surname><given-names>N</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Brain mechanisms underlying the brief maintenance of seen and unseen sensory information</article-title><source>Neuron</source><volume>92</volume><fpage>1122</fpage><lpage>1134</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.051</pub-id><pub-id pub-id-type="pmid">27930903</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Meindertsma</surname><given-names>T</given-names></name><name><surname>Hillebrand</surname><given-names>A</given-names></name><name><surname>van Dijk</surname><given-names>BW</given-names></name><name><surname>Lamme</surname><given-names>VAF</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Top-Down modulation in human visual cortex predicts the stability of a perceptual illusion</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>1063</fpage><lpage>1076</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2014</pub-id><pub-id pub-id-type="pmid">25411458</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kornmeier</surname><given-names>J</given-names></name><name><surname>Wörner</surname><given-names>R</given-names></name><name><surname>Riedel</surname><given-names>A</given-names></name><name><surname>Tebartz van Elst</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A different view on the Necker cube-differences in multistable perception dynamics between Asperger and non-asperger observers</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0189197</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0189197</pub-id><pub-id pub-id-type="pmid">29244813</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Wilke</surname><given-names>M</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Stable perception of visually ambiguous patterns</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>605</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1038/nn0602-851</pub-id><pub-id pub-id-type="pmid">11992115</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Hill</surname><given-names>Z</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatiotemporal dissociation of brain activity underlying subjective awareness, objective performance and confidence</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>4382</fpage><lpage>4395</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1820-13.2014</pub-id><pub-id pub-id-type="pmid">24647958</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lozano-Soldevilla</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On the physiological modulation and potential mechanisms underlying parieto-occipital alpha oscillations</article-title><source>Frontiers in Computational Neuroscience</source><volume>12</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2018.00023</pub-id><pub-id pub-id-type="pmid">29670518</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-Dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michalareas</surname><given-names>G</given-names></name><name><surname>Vezoli</surname><given-names>J</given-names></name><name><surname>van Pelt</surname><given-names>S</given-names></name><name><surname>Schoffelen</surname><given-names>J-M</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Alpha-Beta and gamma rhythms subserve feedback and feedforward influences among human visual cortical areas</article-title><source>Neuron</source><volume>89</volume><fpage>384</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.018</pub-id><pub-id pub-id-type="pmid">26777277</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mongillo</surname><given-names>G</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Synaptic theory of working memory</article-title><source>Science</source><volume>319</volume><fpage>1543</fpage><lpage>1546</lpage><pub-id pub-id-type="doi">10.1126/science.1150769</pub-id><pub-id pub-id-type="pmid">18339943</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nobre</surname><given-names>AC</given-names></name><name><surname>van Ede</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Anticipated moments: temporal structure in attention</article-title><source>Nature Reviews. Neuroscience</source><volume>19</volume><fpage>34</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1038/nrn.2017.141</pub-id><pub-id pub-id-type="pmid">29213134</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><elocation-id>156869</elocation-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id><pub-id pub-id-type="pmid">21253357</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orbach</surname><given-names>J</given-names></name><name><surname>Zucker</surname><given-names>E</given-names></name><name><surname>Olson</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Reversibility of the Necker cube: VII reversal rate as a function of figure-on and figure-off durations</article-title><source>Perceptual and Motor Skills</source><volume>22</volume><fpage>615</fpage><lpage>618</lpage><pub-id pub-id-type="doi">10.2466/pms.1966.22.2.615</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panagiotaropoulos</surname><given-names>TI</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Kapoor</surname><given-names>V</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuronal discharges and gamma oscillations explicitly reflect visual consciousness in the lateral prefrontal cortex</article-title><source>Neuron</source><volume>74</volume><fpage>924</fpage><lpage>935</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.013</pub-id><pub-id pub-id-type="pmid">22681695</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearson</surname><given-names>J</given-names></name><name><surname>Brascamp</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sensory memory for ambiguous vision</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>334</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.05.006</pub-id><pub-id pub-id-type="pmid">18684661</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piantoni</surname><given-names>G</given-names></name><name><surname>Romeijn</surname><given-names>N</given-names></name><name><surname>Gomez-Herrero</surname><given-names>G</given-names></name><name><surname>Van Der Werf</surname><given-names>YD</given-names></name><name><surname>Van Someren</surname><given-names>EJW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Alpha power predicts persistence of bistable perception</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>5208</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-05610-8</pub-id><pub-id pub-id-type="pmid">28701732</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitts</surname><given-names>MA</given-names></name><name><surname>Martínez</surname><given-names>A</given-names></name><name><surname>Stalmaster</surname><given-names>C</given-names></name><name><surname>Nerger</surname><given-names>JL</given-names></name><name><surname>Hillyard</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural generators of ERPs linked with Necker cube reversals</article-title><source>Psychophysiology</source><volume>46</volume><fpage>694</fpage><lpage>702</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2009.00822.x</pub-id><pub-id pub-id-type="pmid">19490514</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>CE</given-names></name><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Freyberg</surname><given-names>J</given-names></name><name><surname>Baron-Cohen</surname><given-names>S</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Slower rate of binocular rivalry in autism</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>16983</fpage><lpage>16991</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0448-13.2013</pub-id><pub-id pub-id-type="pmid">24155303</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>NS</given-names></name><name><surname>LaRocque</surname><given-names>JJ</given-names></name><name><surname>Riggall</surname><given-names>AC</given-names></name><name><surname>Gosseries</surname><given-names>O</given-names></name><name><surname>Starrett</surname><given-names>MJ</given-names></name><name><surname>Meyering</surname><given-names>EE</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reactivation of latent working memories with transcranial magnetic stimulation</article-title><source>Science</source><volume>354</volume><fpage>1136</fpage><lpage>1139</lpage><pub-id pub-id-type="doi">10.1126/science.aah7011</pub-id><pub-id pub-id-type="pmid">27934762</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salti</surname><given-names>M</given-names></name><name><surname>Monto</surname><given-names>S</given-names></name><name><surname>Charles</surname><given-names>L</given-names></name><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct cortical codes and temporal dynamics for conscious and unconscious percepts</article-title><source>eLife</source><volume>4</volume><elocation-id>e652</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05652</pub-id><pub-id pub-id-type="pmid">25997100</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samaha</surname><given-names>J</given-names></name><name><surname>Iemi</surname><given-names>L</given-names></name><name><surname>Haegens</surname><given-names>S</given-names></name><name><surname>Busch</surname><given-names>NA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Spontaneous brain oscillations and perceptual decision-making</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>639</fpage><lpage>653</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.05.004</pub-id><pub-id pub-id-type="pmid">32513573</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandberg</surname><given-names>K</given-names></name><name><surname>Bahrami</surname><given-names>B</given-names></name><name><surname>Kanai</surname><given-names>R</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name><name><surname>Overgaard</surname><given-names>M</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Early visual responses predict conscious face perception within and between subjects during binocular rivalry</article-title><source>Journal of Cognitive Neuroscience</source><volume>25</volume><fpage>969</fpage><lpage>985</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00353</pub-id><pub-id pub-id-type="pmid">23281780</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandberg</surname><given-names>K</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name><name><surname>Bahrami</surname><given-names>B</given-names></name><name><surname>Kanai</surname><given-names>R</given-names></name><name><surname>Overgaard</surname><given-names>M</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Distinct MEG correlates of conscious experience, perceptual reversals and stabilization during binocular rivalry</article-title><source>NeuroImage</source><volume>100</volume><fpage>161</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.06.023</pub-id><pub-id pub-id-type="pmid">24945667</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shpiro</surname><given-names>A</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name><name><surname>Rinzel</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Balance between noise and adaptation in competition models of perceptual bistability</article-title><source>Journal of Computational Neuroscience</source><volume>27</volume><fpage>37</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1007/s10827-008-0125-3</pub-id><pub-id pub-id-type="pmid">19125318</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Souza</surname><given-names>AS</given-names></name><name><surname>Oberauer</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Time-Based forgetting in visual working memory reflects temporal distinctiveness, not decay</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>22</volume><fpage>156</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.3758/s13423-014-0652-z</pub-id><pub-id pub-id-type="pmid">24825306</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spitzer</surname><given-names>B</given-names></name><name><surname>Haegens</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Beyond the status quo: a role for beta oscillations in endogenous content (re) activation</article-title><source>ENeuro</source><volume>4</volume><elocation-id>eNeuro</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0170-17.2017</pub-id><pub-id pub-id-type="pmid">28785729</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>R</given-names></name><name><surname>Russell</surname><given-names>DP</given-names></name><name><surname>Edelman</surname><given-names>GM</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Increased synchronization of neuromagnetic responses during conscious perception</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>5435</fpage><lpage>5448</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-13-05435.1999</pub-id><pub-id pub-id-type="pmid">10377353</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname><given-names>MG</given-names></name><name><surname>Kusunoki</surname><given-names>M</given-names></name><name><surname>Sigala</surname><given-names>N</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Gaffan</surname><given-names>D</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dynamic coding for cognitive control in prefrontal cortex</article-title><source>Neuron</source><volume>78</volume><fpage>364</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.01.039</pub-id><pub-id pub-id-type="pmid">23562541</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural circuits as computational dynamical systems</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>156</fpage><lpage>163</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.01.008</pub-id><pub-id pub-id-type="pmid">24509098</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toker</surname><given-names>D</given-names></name><name><surname>Pappas</surname><given-names>I</given-names></name><name><surname>Lendner</surname><given-names>JD</given-names></name><name><surname>Frohlich</surname><given-names>J</given-names></name><name><surname>Mateos</surname><given-names>DM</given-names></name><name><surname>Muthukumaraswamy</surname><given-names>S</given-names></name><name><surname>Carhart-Harris</surname><given-names>R</given-names></name><name><surname>Paff</surname><given-names>M</given-names></name><name><surname>Vespa</surname><given-names>PM</given-names></name><name><surname>Monti</surname><given-names>MM</given-names></name><name><surname>Sommer</surname><given-names>FT</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Consciousness is supported by near-critical slow cortical electrodynamics</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2024455119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2024455119</pub-id><pub-id pub-id-type="pmid">35145021</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tong</surname><given-names>F</given-names></name><name><surname>Nakayama</surname><given-names>K</given-names></name><name><surname>Vaughan</surname><given-names>JT</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Binocular rivalry and visual awareness in human extrastriate cortex</article-title><source>Neuron</source><volume>21</volume><fpage>753</fpage><lpage>759</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)80592-9</pub-id><pub-id pub-id-type="pmid">9808462</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Srinivasan</surname><given-names>R</given-names></name><name><surname>Russell</surname><given-names>DP</given-names></name><name><surname>Edelman</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Investigating neural correlates of conscious perception by frequency-tagged neuromagnetic responses</article-title><source>PNAS</source><volume>95</volume><fpage>3198</fpage><lpage>3203</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.6.3198</pub-id><pub-id pub-id-type="pmid">9501240</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trübutschek</surname><given-names>D</given-names></name><name><surname>Marti</surname><given-names>S</given-names></name><name><surname>Ueberschär</surname><given-names>H</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Probing the limits of activity-silent non-conscious working memory</article-title><source>PNAS</source><volume>116</volume><fpage>14358</fpage><lpage>14367</lpage><pub-id pub-id-type="doi">10.1073/pnas.1820730116</pub-id><pub-id pub-id-type="pmid">31243145</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Dagnino</surname><given-names>B</given-names></name><name><surname>Gariel-Mathis</surname><given-names>MA</given-names></name><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>van der Togt</surname><given-names>C</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex</article-title><source>PNAS</source><volume>111</volume><fpage>14332</fpage><lpage>14341</lpage><pub-id pub-id-type="doi">10.1073/pnas.1402773111</pub-id><pub-id pub-id-type="pmid">25205811</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Loon</surname><given-names>AM</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Scholte</surname><given-names>HS</given-names></name><name><surname>St John-Saaltink</surname><given-names>E</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Lamme</surname><given-names>VAF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Gaba shapes the dynamics of bistable perception</article-title><source>Current Biology</source><volume>23</volume><fpage>823</fpage><lpage>827</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.03.067</pub-id><pub-id pub-id-type="pmid">23602476</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Arteaga</surname><given-names>D</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain mechanisms for simple perception and bistable perception</article-title><source>PNAS</source><volume>110</volume><fpage>E3350</fpage><lpage>E3359</lpage><pub-id pub-id-type="doi">10.1073/pnas.1221945110</pub-id><pub-id pub-id-type="pmid">23942129</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weilnhammer</surname><given-names>V</given-names></name><name><surname>Röd</surname><given-names>L</given-names></name><name><surname>Eckert</surname><given-names>A-L</given-names></name><name><surname>Stuke</surname><given-names>H</given-names></name><name><surname>Heinz</surname><given-names>A</given-names></name><name><surname>Sterzer</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Psychotic experiences in schizophrenia and sensitivity to sensory evidence</article-title><source>Schizophrenia Bulletin</source><volume>46</volume><fpage>927</fpage><lpage>936</lpage><pub-id pub-id-type="doi">10.1093/schbul/sbaa003</pub-id><pub-id pub-id-type="pmid">32090246</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuille</surname><given-names>A</given-names></name><name><surname>Kersten</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Vision as Bayesian inference: analysis by synthesis?</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>301</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.05.002</pub-id><pub-id pub-id-type="pmid">16784882</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Hardstone</surname><given-names>R</given-names></name><name><surname>He</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neural oscillations promoting perceptual stability and perceptual memory during bistable perception</article-title><source>Scientific Reports</source><volume>12</volume><elocation-id>2760</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-022-06570-4</pub-id><pub-id pub-id-type="pmid">35177702</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.78108.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Luo</surname><given-names>Huan</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.03.18.484861" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.03.18.484861"/></front-stub><body><p>Bistable visual perception offers a unique window to study how perception arises and changes via an interaction between bottom-up and top-down processes. In three Magnetoencephalography (MEG) experiments with advanced neural state space analysis, this study demonstrates that two key aspects of bistable visual perception – perceptual content and perceptual stability – are mediated by slow cortical potential (SCP) and α-β-band neural oscillations, respectively. The findings will be of interest for many fields, including those studying perception, consciousness, and attention.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.78108.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Luo</surname><given-names>Huan</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.03.18.484861">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.03.18.484861v1">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Frequency-specific neural signatures of perceptual content and perceptual stability&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Chris Baker as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>We are very sorry for taking so long to make our decisions. We generally need three reviewers but now go ahead with the current two received reviews to avoid further delays. Both reviewers acknowledged your important findings but also raised several concerns that need substantial revision and new results. There are also other suggestions for you to consider.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Need more results supporting the dissociation of perceptual content and perceptual stability as claimed in the paper. For example, the statistical evidence for the specificity of SCP to perceptual content (1st point by Reviewer 2), the neural representation of perceptual duration also in SCP in addition to α-β oscillation (1st point by Reviewer 1), the exact relationship between SCP and α-β oscillation (2nd point by Reviewer 1), and the vague results about the α-β tracking of memory under discontinuous condition (3rd point by Reviewer 1).</p><p>2) Reviewer 2 raised substantial concerns about the rationale of the behavioral metrics used in the neural state space analysis (see 2nd point by Reviewer 2), considering the power-law distribution of perceptual duration during bistable perception. This is a critical point since it would challenge the core assumption of the main analysis. The authors should provide strong evidence to verify their analysis rationale.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>(1) The main conclusion of the paper is the dissociation of SCP and α-β oscillation for perceptual content and perceptual stability, respectively. Meanwhile, the results for perceptual stability using the neural state-space analysis could not fully support the dissociation claim. As shown in Figure S2, the SCP showed clear representations of perceptual duration, similar to that for α and β power. The author argued that the corresponding spatial map for SCP is less reliable compared to α-β, but I am not convinced that this would serve as strong evidence excluding SCP's role.</p><p>(2) Related to the above point, I would suggest the authors dig into the exact relationship between SCP and α-β oscillation, particularly regarding their functions in perceptual stability. For example, α and β might be the key top-down modulation signal to sustain the perception, which would contribute to the observed perceptual duration effect in SCP.</p><p>(3) As shown in Figure 4, the authors stated that the α-β tracked the memory during the blank interval for the Discontinuous condition, while SCP could not. Meanwhile, the results look vague and noisy. Instead of comparing stable and unstable trials, I am confused that why the authors do not plot a single time course denoting the memory tracking instead of the current two lines (stable and unstable). Moreover, the difference between stable and unstable seems to occur at random times and is not stable between conditions. How to interpret these inconsistencies? Finally, the SCP displayed a similar (stable&gt;unstable) trend and the cube condition even showed a significant difference. I think there should be consistent criteria to define whether or not there is significant tracking.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>It is not necessary but I just wonder what would happen if we use γ band data. If the authors have some solid reasons to exclude the band, I hope such reasons would be clarified in the text.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.78108.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Need more results supporting the dissociation of perceptual content and perceptual stability as claimed in the paper. For example, the statistical evidence for the specificity of SCP to perceptual content (1st point by Reviewer 2), the neural representation of perceptual duration also in SCP in addition to α-β oscillation (1st point by Reviewer 1), the exact relationship between SCP and α-β oscillation (2nd point by Reviewer 1), and the vague results about the α-β tracking of memory under discontinuous condition (3rd point by Reviewer 1).</p></disp-quote><p>We have now included additional results regarding the specificity of SCP to perceptual content (new Figure 2—figure supplement 1), additional discussion on the role of SCP in perceptual duration (and its relationship to the role of α and β oscillations, see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>), and have replotted the α and β tracking of perceptual memory under discontinuous condition which shows highly reliable results between the two images (Figure 4). Detailed responses are included below.</p><disp-quote content-type="editor-comment"><p>2) Reviewer 2 raised substantial concerns about the rationale of the behavioral metrics used in the neural state space analysis (see 2nd point by Reviewer 2), considering the power-law distribution of perceptual duration during bistable perception. This is a critical point since it would challenge the core assumption of the main analysis. The authors should provide strong evidence to verify their analysis rationale.</p></disp-quote><p>See our response to reviewer 2 below, which (1) disputes that the distribution of percept durations follows a power law (it is a γ distribution); and (2) includes a control analysis which shows that the exact choice of the behavioral timing function is not critical for the presented results.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>(1) The main conclusion of the paper is the dissociation of SCP and α-β oscillation for perceptual content and perceptual stability, respectively. Meanwhile, the results for perceptual stability using the neural state-space analysis could not fully support the dissociation claim. As shown in Figure S2, the SCP showed clear representations of perceptual duration, similar to that for α and β power. The author argued that the corresponding spatial map for SCP is less reliable compared to α-β, but I am not convinced that this would serve as strong evidence excluding SCP's role.</p></disp-quote><p>We have now toned down the claim of separation of neural activity for perceptual stability, and have highlighted that SCP carries information about perceptual stability.</p><p>Abstract:</p><p>“Perceptual stability is additionally influenced by the amplitude of α and β oscillations.”</p><p>Introduction:</p><p>“We therefore hypothesized that there might exist a frequency-band separation between neural activity supporting perceptual content and neural activity supporting perceptual stability, with the former residing in the non-oscillatory activity in the SCP range, and the latter predominantly residing in oscillatory activity in the α/β range.”</p><p>“Surprisingly, we also found that SCP modulated perceptual stability, although with less spatial consistency across subjects compared to α and β oscillations.”</p><p>We believe that the significance of the spatial map is informative about the strength of the role of a neural feature in the behavior. The spatial map represents multivariate regressions, and its weights can be interpreted as evidence for the involvement of a neural feature in a behavior (unlike decoder weight maps where it is unclear if a strong weight is due to signal or suppressing noise see Haufe et al., Neuroimage 2014). Further, we show that there is no consistency between the two images in how percept duration is encoded in SCP (as reflected in their different spatial topography), suggesting that the relation of SCP activity to perceptual duration is image-specific.</p><p>Therefore, while SCP does carry information about perceptual stability, it likely does so in a more distributed and less anatomically defined way as compared to α and β oscillations where the information is predominantly in posterior regions. In addition, the image-specific relationship between SCP and percept duration suggests that it is not picking up on a generic perceptual stability mechanism. We have added a sentence to the relevant <italic>Results section</italic> to clarify this point:</p><p>“Therefore, we conclude that information about perceptual stability, as captured by percept duration, is primarily carried by the amplitude of α- and β-band activity. Although this information also exists in the SCP band, it is encoded in a less consistent manner across subjects and across different image inputs.”</p><p>In sum, we hope that revisions to the text mentioned above address the concern raised by the reviewer by clearly stating that SCP also modulates perceptual stability.</p><disp-quote content-type="editor-comment"><p>(2) Related to the above point, I would suggest the authors dig into the exact relationship between SCP and α-β oscillation, particularly regarding their functions in perceptual stability. For example, α and β might be the key top-down modulation signal to sustain the perception, which would contribute to the observed perceptual duration effect in SCP.</p></disp-quote><p>To test the relationship between SCP and α-β oscillation in their functions in perceptual stability, we compared the neural activity projected into the sub-spaces for percept duration for the three neural features (SCP, α, β). We did this by applying partial correlation between each projected neural feature and the behavior, regressing out the influence of the other two neural features. We then compared this partial correlation with the original correlation. For SCP we found no significant reduction in the correlation (<xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>, left column), suggesting that SCP carries different information about perceptual stability compared to α and β oscillations. For α and β we did find a significant reduction (<xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>, middle and right columns), suggesting that α and β oscillations exert partially redundant influences on perceptual stability.</p><p>Since this analysis does not directly speak to the reviewer’s hypothesis about α and β being involved in top-down modulation and is somewhat peripheral to our main analyses, we have elected not to include it in the revised manuscript.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>SCP carries unique information about perceptual stability.</title><p>Black trace shows reduction in correlation with percept duration when regressing out the other two neural features; shaded areas show s.e.m. across subjects. Red bars indicate time points where partial correlation was significantly reduced as compared to the original correlation (one-sided t-test, <italic>p</italic>&lt;0.05, cluster-based permutation test with 1000 permutations).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78108-sa2-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>(3) As shown in Figure 4, the authors stated that the α-β tracked the memory during the blank interval for the Discontinuous condition, while SCP could not. Meanwhile, the results look vague and noisy. Instead of comparing stable and unstable trials, I am confused that why the authors do not plot a single time course denoting the memory tracking instead of the current two lines (stable and unstable). Moreover, the difference between stable and unstable seems to occur at random times and is not stable between conditions. How to interpret these inconsistencies? Finally, the SCP displayed a similar (stable&gt;unstable) trend and the cube condition even showed a significant difference. I think there should be consistent criteria to define whether or not there is significant tracking.</p></disp-quote><p>We thank the reviewer for this suggestion, and agree that plotting the difference between stable and unstable trials is more intuitive. The new plots (included in the revised Figure 4 and Figure 4—figure supplement 2) emphasize that for β oscillations there is a consistent relationship with perceptual memory at ~0.5–1.5 seconds, and for α oscillations there is a consistent relationship with perceptual memory at ~1.5–3 seconds. By contrast, SCP’s relationship with perceptual memory occurs later, more transiently, and is only significant for one of the two ambiguous images tested.</p><p>We do not think that the neural correlate for perceptual memory should necessarily manifest in the neural dynamics in a stable fashion across the blank period, even though, behaviorally, perceptual memory lasts throughout this period. As is now well established in the working memory literature (e.g., Stokes et al., Neuron 2013; Murray et al. PNAS 2017), working memory traces that last across a long delay period are supported by heterogeneous and temporally changing neural dynamics, including ‘activity-silent states” that would not manifest in population activity recordings such as MEG. Finally, our finding of transient neural activity correlate of perceptual memory is also consistent with a recent EEG study using a similar task (Zhu et al., Sci Rep 2022). We have now included these considerations in the relevant Results section:</p><p>“Interestingly, the encoding of perceptual memory during the blank periods occurs first in β activity (at ~0.5–1.5 sec after blank onset), followed by α activity (at ~1.5–3 sec), and is not significant in either frequency band during the latter half of the blank period (3–6 sec) (Figure 4B and Figure 4—figure supplement 2). This transient encoding of perceptual memory in neural dynamics is consistent with a recent EEG study using a similar paradigm (Zhu et al., 2022). Speculatively, after the transient encoding in β and α activity, perceptual memory trace might be maintained in short-term synaptic plasticity within the network in an “activity-silent” state without measurable signatures in active neural dynamics (Mongillo et al., 2008; Stokes et al., 2013; Rose et al., 2016).”</p><p>Finally, regarding the criteria for deciding whether there is significant neural tracking of a behavior, one criterion that we rely quite heavily on throughout the manuscript is the consistent and reproducible findings between the two ambiguous images. Although not mandated by the current norm in the field, we felt strongly that collecting data using two separate ambiguous images and separately analyzing data from them allowed us to perform a within-study reproducibility and generalizability check. Therefore, the results that are consistent between images are not only reproduced (using independent data from the same subjects) but also generalize across the specific choice of stimulus. Our lab has adopted this strategy to ensure that our results are robust and stand the test of time in several previous publications on bistable perception (Wang et al., PNAS 2013; Hardstone et al., Nat. Commun. 2021; Zhu et al., Sci Rep 2022). Because SCP’s relationship with perceptual memory fails this important criterion, we do not emphasize it in the conclusions.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>It is not necessary but I just wonder what would happen if we use γ band data. If the authors have some solid reasons to exclude the band, I hope such reasons would be clarified in the text.</p></disp-quote><p>In initial analysis we did not find significant decoding of perceptual content using γ-band power, consistent with our earlier MEG study (Baria et al., PLoS Comput Biol 2017). While it is likely that γ band does carry perceptual coding information (e.g., see Panagiotaropoulos et al., Neuron 2012), we believe that this question would be best addressed using intracranial recordings where SNR for γ-band activity is better. We have added a sentence in Discussion to this point:</p><p>“Finally, the potential role of γ frequency band in encoding perceptual content should be further investigated in future studies using intracranial recordings which are more sensitive to γ-band activity than MEG [e.g., (Panagiotaropoulos et al., 2012)].”</p></body></sub-article></article>