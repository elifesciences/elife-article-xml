<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">75474</article-id><article-id pub-id-type="doi">10.7554/eLife.75474</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>The interpretation of computational model parameters depends on the context</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-229224"><name><surname>Eckstein</surname><given-names>Maria Katharina</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0330-9367</contrib-id><email>maria.eckstein@berkeley.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-230211"><name><surname>Master</surname><given-names>Sarah L</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2726-4586</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-262330"><name><surname>Xia</surname><given-names>Liyu</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-230212"><name><surname>Dahl</surname><given-names>Ronald E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1794-7132</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="pa1">†</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-96001"><name><surname>Wilbrecht</surname><given-names>Linda</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3492-8141</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-104362"><name><surname>Collins</surname><given-names>Anne GE</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3751-3662</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>Department of Psychology, University of California, Berkeley</institution></institution-wrap><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Department of Psychology, New York University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>Department of Mathematics, University of California, Berkeley</institution></institution-wrap><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>Institute of Human Development, University of California, Berkeley</institution></institution-wrap><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an7q238</institution-id><institution>Helen Wills Neuroscience Institute, University of California, Berkeley</institution></institution-wrap><addr-line><named-content content-type="city">Berkeley</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Hartley</surname><given-names>Catherine</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>New York University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>School of Public Health, UC Berkeley, Berkeley, United States</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>04</day><month>11</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e75474</elocation-id><history><date date-type="received" iso-8601-date="2021-11-11"><day>11</day><month>11</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-09-09"><day>09</day><month>09</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-05-28"><day>28</day><month>05</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.05.28.446162"/></event></pub-history><permissions><copyright-statement>© 2022, Eckstein et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Eckstein et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-75474-v1.pdf"/><abstract><p>Reinforcement Learning (RL) models have revolutionized the cognitive and brain sciences, promising to explain behavior from simple conditioning to complex problem solving, to shed light on developmental and individual differences, and to anchor cognitive processes in specific brain mechanisms. However, the RL literature increasingly reveals contradictory results, which might cast doubt on these claims. We hypothesized that many contradictions arise from two commonly-held assumptions about computational model parameters that are actually often invalid: That parameters <italic>generalize</italic> between contexts (e.g. tasks, models) and that they capture <italic>interpretable</italic> (i.e. unique, distinctive) neurocognitive processes. To test this, we asked 291 participants aged 8–30 years to complete three learning tasks in one experimental session, and fitted RL models to each. We found that some parameters (exploration / decision noise) showed significant generalization: they followed similar developmental trajectories, and were reciprocally predictive between tasks. Still, generalization was significantly below the methodological ceiling. Furthermore, other parameters (learning rates, forgetting) did not show evidence of generalization, and sometimes even opposite developmental trajectories. Interpretability was low for all parameters. We conclude that the systematic study of context factors (e.g. reward stochasticity; task volatility) will be necessary to enhance the generalizability and interpretability of computational cognitive models.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>computational modeling</kwd><kwd>reinforcement learning</kwd><kwd>Interpretability</kwd><kwd>Generalizability</kwd><kwd>Development</kwd><kwd>cognition</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>sl-cn 1640885</award-id><principal-award-recipient><name><surname>Dahl</surname><given-names>Ronald E</given-names></name><name><surname>Collins</surname><given-names>Anne GE</given-names></name><name><surname>Wilbrecht</surname><given-names>Linda</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Context factors such as experimental task and model parameterization can significantly impact modeling results, such that across tasks, the same participants show different fitted parameter values, and parameters capture different cognitive processes across tasks.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In recent decades, cognitive neuroscience has made breakthroughs in computational modeling, demonstrating that reinforcement learning (RL) models can explain foundational aspects of human thought and behavior. RL models can explain not only simple cognitive processes such as stimulus-outcome and stimulus-response learning (<xref ref-type="bibr" rid="bib94">Schultz et al., 1997</xref>; <xref ref-type="bibr" rid="bib82">O’Doherty et al., 2004</xref>; <xref ref-type="bibr" rid="bib47">Gläscher et al., 2009</xref>), but also highly complex processes, including goal-directed, temporally extended behavior (<xref ref-type="bibr" rid="bib91">Ribas-Fernandes et al., 2011</xref>; <xref ref-type="bibr" rid="bib28">Daw et al., 2011</xref>), meta-learning (<xref ref-type="bibr" rid="bib111">Wang et al., 2018</xref>), and abstract problem solving requiring hierarchical thinking (<xref ref-type="bibr" rid="bib35">Eckstein and Collins, 2020</xref>; <xref ref-type="bibr" rid="bib10">Botvinick, 2012</xref>; <xref ref-type="bibr" rid="bib16">Collins and Koechlin, 2012</xref>; <xref ref-type="bibr" rid="bib115">Werchan et al., 2016</xref>). Underlining their centrality in the study of human cognition, RL models have been applied across the lifespan (<xref ref-type="bibr" rid="bib106">van den Bos et al., 2018</xref>; <xref ref-type="bibr" rid="bib8">Bolenz et al., 2017</xref>; <xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>), and in both healthy participants and those experiencing psychiatric illness (<xref ref-type="bibr" rid="bib55">Huys et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Adams et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib3">Ahn and Busemeyer, 2016</xref>; <xref ref-type="bibr" rid="bib32">Deserno et al., 2013</xref>). RL models are of particular interest because they also promise a close link to brain function: A specialized network of brain regions, including the basal ganglia and prefrontal cortex, implement computations that mirror specific components of RL algorithms, including action values and reward prediction errors (<xref ref-type="bibr" rid="bib41">Frank and Claus, 2006</xref>; <xref ref-type="bibr" rid="bib80">Niv, 2009</xref>; <xref ref-type="bibr" rid="bib66">Lee et al., 2012</xref>; <xref ref-type="bibr" rid="bib83">O’Doherty et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Glimcher, 2011</xref>; <xref ref-type="bibr" rid="bib42">Garrison et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Dayan and Niv, 2008</xref>). In sum, RL, explaining behavior ranging from simple conditioning to complex problem solving, appropriate for diverse human (and nonhuman) populations, based on a compelling theoretical foundation (<xref ref-type="bibr" rid="bib101">Sutton and Barto, 2017</xref>), and with strong ties to brain function, has seen a surge in published studies since its introduction (<xref ref-type="bibr" rid="bib85">Palminteri et al., 2017</xref>), and emerged as a powerful and potentially unifying modeling framework for cognitive and neural processing.</p><p>Computational modeling enables researchers to condense rich behavioral datasets into simple, falsifiable models (e.g. RL) and fitted model parameters (e.g. learning rate, decision temperature) (<xref ref-type="bibr" rid="bib106">van den Bos et al., 2018</xref>; <xref ref-type="bibr" rid="bib85">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="bib27">Daw, 2011</xref>; <xref ref-type="bibr" rid="bib116">Wilson and Collins, 2019</xref>; <xref ref-type="bibr" rid="bib50">Guest and Martin, 2021</xref>; <xref ref-type="bibr" rid="bib7">Blohm et al., 2020</xref>). These models and parameters are often interpreted as a reflection of (or ‘<italic>window into’</italic>) cognitive and/or neural processes, with the ability to dissect these processes into specific, unique components, and to measure participants’ inherent characteristics along these components. For example, RL models have been praised for their ability to separate the decision making process into value updating and choice selection stages, allowing for the separate investigation of each dimension. Hereby, RL models infer person-specific parameters for each dimension (e.g. learning rate and decision noise), seemingly providing a direct measure of individuals’ inherent characteristics. Crucially, many current research practices are firmly based on these (often implicit) assumptions, which give rise to the expectation that parameters have a task- and model-independent <italic>interpretation</italic> and will seamlessly <italic>generalize</italic> between studies. However, there is growing—though indirect—evidence that these assumptions might not (or not always) be valid. The following section lays out existing evidence in favor and in opposition of model generalizability and interpretability. Building on our previous opinion piece, which—based on a review of published studies—argued that there is less evidence for model generalizability and interpretability than expected based on current research practices (<xref ref-type="bibr" rid="bib36">Eckstein et al., 2021</xref>), this study seeks to directly address the matter empirically.</p><p>Many current research practices are implicitly based on the interpretability and generalizability of computational model parameters (despite the fact that many researchers explicitly distance themselves from them). For our purposes, we define a model variable (e.g. fitted parameter) as <italic>generalizable</italic> if it is consistent across uses, such that a person would be characterized with the same values independent of the specific model or task used to estimate the variable. Generalizability is a consequence of the assumption that parameters are intrinsic to participants rather than task dependent (e.g. a high learning rate is a personal characteristic that might reflect an individual’s unique brain structure). One example of our implicit assumptions about generalizability is the fact that we often directly compare model parameters between studies—for example, comparing our findings related to learning rate parameters to a previous study’s findings related to learning rate parameters. Note that such a comparison is only valid if parameters capture the same underlying constructs across studies, tasks, and model variations, that is, if parameters <italic>generalize</italic>. The literature has implicitly equated parameters in this way in review articles (<xref ref-type="bibr" rid="bib55">Huys et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Adams et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Frank and Claus, 2006</xref>; <xref ref-type="bibr" rid="bib80">Niv, 2009</xref>; <xref ref-type="bibr" rid="bib66">Lee et al., 2012</xref>; <xref ref-type="bibr" rid="bib83">O’Doherty et al., 2015</xref>; <xref ref-type="bibr" rid="bib48">Glimcher, 2011</xref>; <xref ref-type="bibr" rid="bib29">Dayan and Niv, 2008</xref>), meta-analyses (<xref ref-type="bibr" rid="bib42">Garrison et al., 2013</xref>; <xref ref-type="bibr" rid="bib118">Yaple and Yu, 2019</xref>; <xref ref-type="bibr" rid="bib70">Liu et al., 2016</xref>), and also most empirical papers, by relating parameter-specific findings across studies. We also implicitly evoke parameter generalizability when we study task-independent empirical parameter priors (<xref ref-type="bibr" rid="bib44">Gershman, 2016</xref>), or task-independent parameter relationships (e.g. interplay between different kinds of learning rates [<xref ref-type="bibr" rid="bib51">Harada, 2020</xref>]), because we presuppose that parameter settings are inherent to participants, rather than task specific.</p><p>We define a model variable as <italic>interpretable</italic> if it isolates specific and unique cognitive elements, and/or is implemented in separable and unique neural substrates. Interpretability follows from the assumption that the decomposition of behavior into model parameters ‘carves cognition at its joints’, and provides fundamental, meaningful, and factual components (e.g. separating value updating from decision making). We implicitly invoke interpretability when we tie model variables to neural substrates in a task-general way (e.g. reward prediction errors to dopamine function [<xref ref-type="bibr" rid="bib95">Schultz and Dickinson, 2000</xref>]), or when we use parameters as markers of psychiatric conditions in a model-independent way (e.g. working-memory deficits in schizophrenia [<xref ref-type="bibr" rid="bib17">Collins et al., 2014</xref>]). Interpretability is also required when we relate abstract parameters to aspects of real-world decision making (<xref ref-type="bibr" rid="bib54">Heinz et al., 2017</xref>), and generally, when we assume that model variables are particularly ‘theoretically meaningful’ (<xref ref-type="bibr" rid="bib55">Huys et al., 2016</xref>).</p><p>However, in the midst of the growing application of computational modeling of behavior, the focus has also shifted toward inconsistencies and apparent contradictions in the emerging literature, which are becoming apparent in cognitive (<xref ref-type="bibr" rid="bib78">Nassar and Frank, 2016</xref>), developmental (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>; <xref ref-type="bibr" rid="bib57">Javadi et al., 2014</xref>; <xref ref-type="bibr" rid="bib6">Blakemore and Robbins, 2012</xref>; <xref ref-type="bibr" rid="bib31">DePasque and Galván, 2017</xref>), clinical (<xref ref-type="bibr" rid="bib2">Adams et al., 2016</xref>; <xref ref-type="bibr" rid="bib53">Hauser et al., 2019</xref>; <xref ref-type="bibr" rid="bib3">Ahn and Busemeyer, 2016</xref>; <xref ref-type="bibr" rid="bib32">Deserno et al., 2013</xref>), and neuroscience studies (<xref ref-type="bibr" rid="bib42">Garrison et al., 2013</xref>; <xref ref-type="bibr" rid="bib118">Yaple and Yu, 2019</xref>; <xref ref-type="bibr" rid="bib70">Liu et al., 2016</xref>; <xref ref-type="bibr" rid="bib75">Mohebi et al., 2019</xref>), and have recently become the focus of targeted investigations (<xref ref-type="bibr" rid="bib92">Robinson and Chase, 2017</xref>; <xref ref-type="bibr" rid="bib114">Weidinger et al., 2019</xref>; <xref ref-type="bibr" rid="bib12">Brown et al., 2020</xref>; <xref ref-type="bibr" rid="bib89">Pratt et al., 2021</xref>). For example, some developmental studies have shown that learning rates increased with age (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib26">Davidow et al., 2016</xref>), whereas others have shown that they decrease (<xref ref-type="bibr" rid="bib30">Decker et al., 2015</xref>). Yet others have reported U-shaped trajectories with either peaks (<xref ref-type="bibr" rid="bib93">Rosenbaum et al., 2020</xref>) or troughs (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>) during adolescence, or stability within this age range (<xref ref-type="bibr" rid="bib84">Palminteri et al., 2016</xref>) (for a comprehensive review, see <xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>; for specific examples, see <xref ref-type="bibr" rid="bib78">Nassar and Frank, 2016</xref>). This is just one striking example of inconsistencies in the cognitive modeling literature, and many more exist (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>). These inconsistencies could signify that computational modeling is fundamentally flawed or inappropriate to answer our research questions. Alternatively, inconsistencies could signify that the method is valid, but our current implementations are inappropriate (<xref ref-type="bibr" rid="bib85">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="bib104">Uttal, 1990</xref>; <xref ref-type="bibr" rid="bib113">Webb, 2001</xref>; <xref ref-type="bibr" rid="bib79">Navarro, 2019</xref>; <xref ref-type="bibr" rid="bib119">Yarkoni, 2020</xref>; <xref ref-type="bibr" rid="bib116">Wilson and Collins, 2019</xref>). However, we hypothesize that inconsistencies can also arise for a third reason: Even if both method and implementation are appropriate, inconsistencies like the ones above are expected—and not a sign of failure—if implicit assumptions of generalizability and interpretability are not always valid. For example, model parameters might be more context-dependent and less person-specific than we often appreciate (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>; <xref ref-type="bibr" rid="bib78">Nassar and Frank, 2016</xref>; <xref ref-type="bibr" rid="bib118">Yaple and Yu, 2019</xref>; <xref ref-type="bibr" rid="bib4">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib74">McGuire et al., 2014</xref>).</p><p>To illustrate this point, the current project began as an investigation into the development of learning in adolescence, with the aim of combining the insights of three different learning tasks to gain a more complete understanding of the underlying mechanisms. However, even though each task individually showed strong and interesting developmental patterns in terms of model parameters (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>), these patterns were very different—and even contradictory—across tasks. This implied that specific model parameters (e.g. learning rate) did not necessarily isolate specific cognitive processes (e.g. value updating) and consistently measure individuals on these processes, but that they captured different processes depending on the learning context of the task (lack of <italic>generalizability</italic>). In addition, the processes identified by one parameter were not necessarily distinct from the cognitive processes (e.g. decision making) identified by other parameters (e.g. decision temperature), but could overlap between parameters (lack of <italic>interpretability</italic>). In a nutshell, the ‘same’ parameters seemed to measure something different in each task.</p><p>The goal of the current project was to assess these patterns formally: We determined the degree to which parameters generalized between three different RL tasks, investigated whether parameters were interpretable as unique and specific processes, and provide initial evidence for context factors that potentially modulate generalizability and interpretability of model parameters, including feedback stochasticity, task volatility, and memory demands. To this aim, we compared the same individuals’ RL parameters, fit to different learning tasks in a single study, in a developmental dataset (291 participants, ages 8–30 years). Using a developmental dataset had several advantages: It provided large between-participant variance and hence better coverage of the parameter space, and allowed us to specifically target outstanding discrepancies in the developmental psychology literature (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>). The three learning tasks we used varied on several common dimensions, including feedback stochasticity, task volatility, and memory demands (<xref ref-type="fig" rid="fig1">Figure 1E</xref>), and have been used previously to study RL processes (<xref ref-type="bibr" rid="bib26">Davidow et al., 2016</xref>; <xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib57">Javadi et al., 2014</xref>; <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). However, like many tasks in the literature, the tasks likely also engaged other cognitive processes besides RL, such as working memory and reasoning. The within-participant design of our study allowed us to test directly whether the same participants showed the same parameters across tasks (generalizability), and the combination of multiple tasks shed light on which cognitive processes the same parameters captured in each task (interpretability). We extensively compared and validated all RL models (<xref ref-type="bibr" rid="bib85">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="bib116">Wilson and Collins, 2019</xref>; <xref ref-type="bibr" rid="bib65">Lee, 2011</xref>) and have reported each task’s unique developmental results separately (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Overview of the experimental paradigm.</title><p>(<bold>A</bold>) Participant sample. Left: Number of participants in each age group, broken up by sex (self-reported). Age groups were determined by within-sex age quartiles for participants between 8–17 years (see <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref> for details) and 5 year bins for adults. Right: Number of participants whose data were excluded because they failed to reach performance criteria in at least one task. (<bold>B</bold>) Task A procedure of (‘Butterfly task’). Participants saw one of four butterflies on each trial and selected one of two flowers in response, via button press on a game controller. Each butterfly had a stable preference for one flower throughout the task, but rewards were delivered stochastically (70% for correct responses, 30% for incorrect). For details, see section 'Task design' and the original publication (<xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). (<bold>C</bold>) Task B Procedure (‘Stochastic Reversal’). Participants saw two boxes on each trial and selected one with the goal of finding gold coins. At each point in time, one box was correct and had a high (75%) probability of delivering a coin, whereas the other was incorrect (0%). At unpredictable intervals, the correct box switched sides. For details, see section 'Task design' and <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>. (<bold>D</bold>) Task C procedure (‘Reinforcement learning-working memory’). Participants saw one stimulus on each trial and selected one of three buttons (<inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) in response. All correct and no incorrect responses were rewarded. The task contained blocks of 2–5 stimuli, determining its ‘set size’. The task was designed to disentangle set size-sensitive working memory processes from set size-insensitive RL processes. For details, see section 'Task design' and <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>. (<bold>E</bold>) Pairwise similarities in terms of experimental design between tasks A (<xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>), B (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>), and C (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>). Similarities are shown on the arrows connecting two tasks; the lack of a feature implies a difference. E.g., a ‘Stable set size’ on tasks A and B implies an unstable set size in task C. Overall, task A shared more similarities with tasks B and C than these shared with each other. (<bold>F</bold>) Summary of the computational models for each task (for details, see section 'Computational models' and original publications). Each row shows one model, columns show model parameters. ‘Y’ (yes) indicates that a parameter is present in a given model, ‘—’ indicates that a parameter is not present. ‘<inline-formula><mml:math id="inf2"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="inf3"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>’ refer to exploration / noise parameters; <inline-formula><mml:math id="inf4"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> (<inline-formula><mml:math id="inf5"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>) to learning rate for positive (negative) outcomes; ‘Persist. P’ to persistence; ‘WM pars’. to working memory parameters.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-fig1-v1.tif"/></fig><p>Our results show a striking lack of generalizability and interpretability for some tasks and parameters, but convincing generalizability for others. This reveals an urgent need for future research to address the role of context factors in computational modeling, and reveals the necessity of taking context factors into account when interpreting and generalizing results. It also suggests that some prior discrepancies are likely explained by differences in context.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>This section gives a brief overview of the experimental tasks (<xref ref-type="fig" rid="fig1">Figure 1B–D</xref>) and computational models (<xref ref-type="fig" rid="fig1">Figure 1F</xref>; also see sections 'Task Design', 'Computational Models', and 'Appendix 2'; for details, refer to original publications [<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>]). We then show our main findings on parameter generalizability (section 'Part I: parameter generalizability') and interpretability (section 'Part II: parameter interpretability'). All three tasks are learning tasks and have been previously well-captured by RL models, yet with differences in parameterization (<xref ref-type="bibr" rid="bib57">Javadi et al., 2014</xref>; <xref ref-type="bibr" rid="bib26">Davidow et al., 2016</xref>; <xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>). In our study as well, the best-fitting RL models differed between tasks, containing some parameters that were the same across tasks, and some that were task-specific (<xref ref-type="fig" rid="fig1">Figure 1F</xref>). Thus, our setup provides a realistic reflection of the diversity of computational models in the literature.</p><p>Task A required participants to learn the correct associations between each of four stimuli (butterflies) and two responses (flowers) based on probabilistic feedback (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The best-fitting model contained three free parameters: learning rate from positive outcomes <inline-formula><mml:math id="inf6"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, inverse decision temperature <inline-formula><mml:math id="inf7"><mml:mi>β</mml:mi></mml:math></inline-formula>, and forgetting <inline-formula><mml:math id="inf8"><mml:mi>F</mml:mi></mml:math></inline-formula>. It also contained one fixed parameter: learning rate from negative outcomes <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). Task B required participants to adapt to unexpected switches in the action-outcome contingencies of a simple bandit task (only one of two boxes contained a gold coin at any time) based on semi-probabilistic feedback (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The best-fitting RL model contained four free parameters: <inline-formula><mml:math id="inf10"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf11"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf12"><mml:mi>β</mml:mi></mml:math></inline-formula>, and choice persistence <inline-formula><mml:math id="inf13"><mml:mi>p</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>). Task C required learning of stimulus-response associations like task A, but over several task blocks with varying numbers of stimuli, and using deterministic feedback (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). The best model for this task combined RL and working memory mechanisms, containing RL parameters <inline-formula><mml:math id="inf14"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf15"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>; working memory parameters capacity <inline-formula><mml:math id="inf16"><mml:mi>K</mml:mi></mml:math></inline-formula>, forgetting <inline-formula><mml:math id="inf17"><mml:mi>F</mml:mi></mml:math></inline-formula>, and noise <inline-formula><mml:math id="inf18"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>; and mixture parameter <inline-formula><mml:math id="inf19"><mml:mi>ρ</mml:mi></mml:math></inline-formula>, which determined the relative weights of RL and working memory (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>). The Markov decision process (MDP) framework provides a common language to describe learning tasks like ours, by breaking them down into states, actions, and reward functions. Appendix 2 summarizes the tasks in this way and highlights major differences.</p><p>We employed rigorous model fitting, comparison, and validation to obtain the best-fitting models presented here (see Appendix 4 and <xref ref-type="bibr" rid="bib85">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="bib27">Daw, 2011</xref>; <xref ref-type="bibr" rid="bib116">Wilson and Collins, 2019</xref>; <xref ref-type="bibr" rid="bib65">Lee, 2011</xref>): For each task, we compared a large number of competing models, based on different parameterizations and cognitive mechanisms, and selected the best one based on quantitative model comparison scores as well as the models’ abilities to reproduce participants’ behavior in simulation (<xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>). We also used hierarchical Bayesian methods for model fitting and comparison where possible, to obtain the most accurate parameter estimates (<xref ref-type="bibr" rid="bib65">Lee, 2011</xref>; <xref ref-type="bibr" rid="bib12">Brown et al., 2020</xref>). Individual publications provide further details on the set of models compared and validate the claim that the models presented here are the best-fitting ones for each task (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>), an important premise for the claim that individual parameters are well estimated. This qualitative validation step for each dataset ensures that potential parameter discrepancies between tasks are not due to a lack of modeling quality, and can indeed provide accurate information about parameter generalizability and interpretability. (Though we acknowledge that no model is ever right.)</p><sec id="s2-1"><title>Part I: parameter generalizability</title><p>Crucially, the parameter inconsistencies observed in previous literature could be caused by non-specific differences between studies (e.g. participant samples, testing procedures, modeling approaches, research labs). Our within-participant design allows us to rule these out by testing whether the same participants show different parameter values when assessed using different tasks; this finding would be strong evidence for the hypothesized lack of parameter generalizability. To assess this, we first determined whether participants showed similar parameter values across tasks, and then whether tasks showed similar parameter age trajectories.</p><sec id="s2-1-1"><title>Differences in absolute parameter values</title><p>We first used repeated-measures analyses of variance (ANOVAs) to test for task effects on absolute parameter values (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). When ANOVAs showed significant task effects, we followed up with repeated-measures t-tests to compare each pair of tasks, using the Bonferroni correction.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Generalizability of absolute parameter values (<bold>A–B</bold>) and of parameter age trajectories / z-scored parameters (<bold>C–D</bold>).</title><p>(<bold>A</bold>) Fitted parameters over participant age (binned) for all three tasks (A: green; B: orange; C: blue). Parameter values differed significantly between tasks; significance stars show the p-values of the main effects of task on parameters (<xref ref-type="table" rid="table1">Table 1</xref>; * <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; ** <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; *** <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). Dots indicate means of the participants in each age group (for n’s, see <xref ref-type="fig" rid="fig1">Figure 1A</xref>), error bars specify the confidence level (0–1) for interval estimation of the population mean. (<bold>B</bold>) Summary of the main results of part A. Double-sided arrows connecting tasks are replicated from <xref ref-type="fig" rid="fig1">Figure 1E</xref> and indicate task similarity (dotted arrow: small similarity; full arrow: large similarity). Lines connecting parameters between tasks show test statistics (<xref ref-type="table" rid="table1">Table 1</xref>). Dotted lines indicate significant task differences in Bonferroni-corrected pairwise t-tests (full lines would indicate the lack of difference). All t-tests were significant, indicating that absolute parameter values differed between each pair of tasks. (<bold>C</bold>) Parameter age trajectories, that is, within-task z-scored parameters over age. Age trajectories reveal similarities that are obscured by differences in means or variances in absolute values (part A). Significance stars show significant effects of task on age trajectories (<xref ref-type="table" rid="table2">Table 2</xref>). (<bold>D</bold>) Summary of the main results of part C. Lines connecting parameters between tasks show statistics of regression models predicting each parameter from the corresponding parameter in a different task (<xref ref-type="table" rid="table4">Table 4</xref>). Full lines indicate significant predictability and dotted lines indicate a lack thereof. In contrast to absolute parameter values, age trajectories were predictive in several cases, especially for tasks with more similarities (A and B; A and C), compared to tasks with fewer (B and C).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-fig2-v1.tif"/></fig><p>Learning rates <inline-formula><mml:math id="inf23"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> were so dissimilar across tasks that they occupied largely separate ranges: They were very low in task C (<inline-formula><mml:math id="inf25"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> mean: 0.07, sd: 0.18; <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> mean: 0.03, sd: 0.13), intermediate in task A (<inline-formula><mml:math id="inf27"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> mean: 0.22, sd: 0.09; <inline-formula><mml:math id="inf28"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was fixed at 0), but fairly high in task B (<inline-formula><mml:math id="inf29"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> mean: 0.77, sd: 0.11; <inline-formula><mml:math id="inf30"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> mean: 0.62, sd: 0.14; for statistical comparison, see <xref ref-type="table" rid="table1">Table 1</xref>). Decision noise was high in task B (<inline-formula><mml:math id="inf31"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> mean: 0.33, sd: 0.15), but low in tasks A (<inline-formula><mml:math id="inf32"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> mean: 0.095, sd: 0.0087) and C (<inline-formula><mml:math id="inf33"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> mean: 0.025, sd: 0.032; statistics in <xref ref-type="table" rid="table1">Table 1</xref> ignore <inline-formula><mml:math id="inf34"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> because its absolute values were not comparable to <inline-formula><mml:math id="inf35"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> due to the different parameterization; see section 'Computational models'). Forgetting was significantly higher in task C (mean: 0.19, sd: 0.17) than A (mean: 0.056, sd: 0.028). Task B was best fit without forgetting.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Statistics of ANOVAs predicting raw parameter values from task (A, B, C).</title><p>When an ANOVA showed a significant task effect, we followed up with post-hoc, Bonferroni-corrected t-tests. * <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; ** <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; *** <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Model</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom">F / t</th><th align="left" valign="bottom">df</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf39"><mml:mi>p</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf40"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula></td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">A, B</td><td align="char" char="." valign="bottom">830</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs B</td><td align="char" char="." valign="bottom">25</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf43"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">A, B, C</td><td align="char" char="." valign="bottom">2,018</td><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs B</td><td align="char" char="." valign="bottom">66</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs C</td><td align="char" char="." valign="bottom">12</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">B vs C</td><td align="char" char="." valign="bottom">51</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf48"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">B, C</td><td align="char" char="." valign="bottom">2,357</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">B vs C</td><td align="char" char="." valign="bottom">49</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">A, C</td><td align="char" char="." valign="bottom">161</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs C</td><td align="char" char="." valign="bottom">49</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr></tbody></table></table-wrap><p>For all parameters, absolute parameter values hence differed substantially between tasks. This shows that the three tasks produced significantly different estimates of learning rates, decision noise/exploration, and forgetting for the same participants (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Interestingly, these parameter differences echoed specific task demands: Learning rates and noise/exploration were highest in task B, where frequent switches required quick updating and high levels of exploration. Similarly, forgetting was highest in task C, which posed the largest memory demands. Using regression models that controlled for age (instead of ANOVA) led to similar results (Table <xref ref-type="table" rid="app8table2">Appendix 8—table 2</xref>).</p></sec><sec id="s2-1-2"><title>Relative parameter differences</title><p>However, comparing parameters in terms of their absolute values has shortcomings because it minimizes the role of relative variance between participants, which reflects participants’ mutual relationships to each other, and might be an important component of parameters. To test whether parameters generalized in relative, rather than absolute terms, we first correlated corresponding parameters between each pair of tasks, using Spearman correlation (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref>). Indeed, both <inline-formula><mml:math id="inf53"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1A</xref>) and noise/exploration parameters (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1B</xref>) were significantly positively correlated between tasks A and B as well as between tasks A and C. Significant correlations were lacking between tasks B and C. This suggests that both <inline-formula><mml:math id="inf54"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and noise/exploration generalized in terms of the relationships they captured between participants; however, this generalization was only evident between tasks A and B or A and C, potentially due to the fact that task A was more similar to tasks B and C than these were to each other (<xref ref-type="fig" rid="fig1">Figure 1E</xref>; also see section 'Main axes of variation'). Fig. <xref ref-type="fig" rid="app8fig3">Appendix 8—figure 3</xref> shows the correlations between all pairs of features in the dataset (model parameters and behavioral measures). Note that noise parameters generalized between tasks A and C despite differences in parameterization (<inline-formula><mml:math id="inf55"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> vs. <inline-formula><mml:math id="inf56"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>), showing robustness in the characterization of choice stochasticity (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1B</xref>).</p></sec><sec id="s2-1-3"><title>Parameter age trajectories</title><p>This correlation analysis, however, is limited in its failure to account for age, an evident source of variance in our dataset. This means that apparent parameter generalization could be driven by a common dependence on age, rather than underlying age-independent similarities. To address this, we next focused on parameter age trajectories, aiming to remove differences between tasks that are potentially arbitrary (e.g. absolute mean and variance), while conserving patterns that are potentially more meaningful (e.g. shape of variance, i.e. participants’ values relative to each other). Age trajectories were calculated by z-scoring each parameter within each task (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). To test for differences, mixed-effects regression was used to predict parameters of all tasks from two age predictors (age and squared age) and task (A, B, or C). A better fit of this model compared to the corresponding one without task indicates that task characteristics affected age trajectories. In this case, we followed up with post-hoc models comparing individual pairs of tasks.</p><p>For <inline-formula><mml:math id="inf57"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, the task-based regression model showed a significantly better fit, revealing an effect of task on <inline-formula><mml:math id="inf58"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>’s age trajectory (<xref ref-type="table" rid="table2">Table 2</xref>). Indeed, <inline-formula><mml:math id="inf59"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> showed fundamentally different trajectories in task B compared to C (in task A, <inline-formula><mml:math id="inf60"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was fixed): In task B, <inline-formula><mml:math id="inf61"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> decreased linearly, modulated by a U-shaped curvature (linear effect of age: <inline-formula><mml:math id="inf62"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.11</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; quadratic: <inline-formula><mml:math id="inf64"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.003</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), but in task C, it increased linearly, modulated by an inverse-U curvature (linear: <inline-formula><mml:math id="inf66"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.32</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; quadratic: <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.07</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig2">Figure 2C</xref>). The fact that these patterns are opposites of each other was reflected in the significant interaction terms of the overall regression model (<xref ref-type="table" rid="table3">Table 3</xref>). Indeed, we previously reported a U-shaped trajectory of <inline-formula><mml:math id="inf70"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> in task B, showing a minimum around age 13–15 (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>), but a consistent increase up to early adulthood in task C (<xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). This shows striking differences when estimating <inline-formula><mml:math id="inf71"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> using task B compared to C. These differences might reflect differences in task demands: Negative feedback was diagnostic in task C, requiring large learning rates from negative feedback <inline-formula><mml:math id="inf72"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> for optimal performance, whereas negative feedback was not diagnostic in task B, requiring small <inline-formula><mml:math id="inf73"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> for optimal performance.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Assessing task effects on parameter age trajectories.</title><p>Model fits (AIC scores) of regression models predicting parameter age trajectories, comparing the added value of including (‘AIC with task’) versus excluding (‘AIC without task’) task as a predictor. Differences in AIC scores were tested statistically using F-tests. Better (smaller) model fits are highlighted in bold. The coefficients of the winning models (simpler model ‘without task’ unless adding task predictor leads to significantly better model fit) are shown in <xref ref-type="table" rid="table3">Table 3</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">AIC without task</th><th align="left" valign="bottom">AIC with task</th><th align="left" valign="bottom">F(df)</th><th align="left" valign="bottom">p</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf74"><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mi mathsize="80%">ϵ</mml:mi></mml:mrow></mml:math></inline-formula></td><td align="char" char="." valign="bottom">2,044</td><td align="char" char="." valign="bottom">2,054</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf75"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">2,044</td><td align="char" char="." valign="bottom">2,042</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf76"><mml:mrow><mml:mrow><mml:mi mathsize="80%">F</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mn mathsize="80%">4</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">245</mml:mn><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">2.34</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf77"><mml:mrow><mml:mi mathsize="80%">p</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">0.056</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf78"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">1,395</td><td align="char" char="." valign="bottom">1,373</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf79"><mml:mrow><mml:mrow><mml:mi mathsize="80%">F</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mn mathsize="80%">2</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">245</mml:mn><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">6.99</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf80"><mml:mrow><mml:mi mathsize="80%">p</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">0.0011</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="char" char="." valign="bottom">1,406</td><td align="char" char="." valign="bottom">1,411</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">–</td></tr></tbody></table></table-wrap><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Statistical tests on age trajectories: mixed-effects regression models predicting z-scored parameter values from task (A, B, C), age, and squared age (months).</title><p>When the task-less model fitted best, the coefficients of this (‘grand’) model are shown, reflecting shared age trajectories (<xref ref-type="table" rid="table2">Table 2</xref>; <inline-formula><mml:math id="inf81"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac><mml:mo>/</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf82"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, forgetting). When the age-based model fitted better, pairwise follow-up models are shown (<inline-formula><mml:math id="inf83"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>), reflecting task differences. p-Values of follow-up models were corrected for multiple comparison using the Bonferroni correction. * <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; ** <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, *** <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf88"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula>(Bonf.)</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf89"><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mi mathsize="80%">ϵ</mml:mi></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom">A, B, C</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">1.86</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">–0.17</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">0.004</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf92"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">A, B, C</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">–2.10</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">0.20</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">–0.004</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf96"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">B, C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">4.15</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">0.43</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">–0.010</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="left" valign="bottom">A, C</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.37</td><td align="char" char="." valign="bottom">0.44</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">–0.034</td><td align="char" char="." valign="bottom">0.53</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">0.001</td><td align="char" char="." valign="bottom">0.63</td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><p>For <inline-formula><mml:math id="inf100"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, adding task as a predictor did not improve model fit, suggesting that <inline-formula><mml:math id="inf101"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> showed similar age trajectories across tasks (<xref ref-type="table" rid="table2">Table 2</xref>). Indeed, <inline-formula><mml:math id="inf102"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> showed a linear increase that tapered off with age in all tasks (linear increase: task A: <inline-formula><mml:math id="inf103"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.33</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; task B: <inline-formula><mml:math id="inf105"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.052</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; task C: <inline-formula><mml:math id="inf107"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.28</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; quadratic modulation: task A: <inline-formula><mml:math id="inf109"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.007</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; task B: <inline-formula><mml:math id="inf111"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; task C: <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.006</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). For noise/exploration and forgetting parameters, adding task as a predictor also did not improve model fit (<xref ref-type="table" rid="table2">Table 2</xref>), suggesting similar age trajectories across tasks. For decision noise/exploration, the grand model revealed a linear decrease and tapering off with age (<xref ref-type="fig" rid="fig2">Figure 2C</xref>; <xref ref-type="table" rid="table3">Table 3</xref>), in accordance with previous findings (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>). For forgetting, the grand model did not reveal any age effects (<xref ref-type="fig" rid="fig2">Figure 2C</xref>; <xref ref-type="table" rid="table3">Table 3</xref>), suggesting inconsistent or lacking developmental changes.</p><p>In summary, <inline-formula><mml:math id="inf115"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> showed different age trajectories depending on the task. This suggests a lack of generalizability: The estimated developmental trajectories of learning rates for negative outcomes might not generalize between experimental paradigms. However, the age trajectories of noise/exploration parameters, <inline-formula><mml:math id="inf116"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, and forgetting did not differ between tasks. This lack of statistically-significant task differences might indicate parameter generalizability—but it could also reflect high levels of parameter estimation noise. Subsequent sections will disentangle these two possibilities.</p></sec><sec id="s2-1-4"><title>Predicting age trajectories</title><p>The previous analysis, focusing on parameter differences, revealed some <italic>lack</italic> of generalization (e.g. <inline-formula><mml:math id="inf117"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>). The next analysis takes the inverse approach, assessing similarities in an effort to provide evidence <italic>for</italic> generalization: We used linear regression to predict participants’ parameters in one task from the corresponding parameter on another task, controlling for age and squared age.</p><p>For both <inline-formula><mml:math id="inf118"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and noise/exploration parameters, task A predicted tasks B and C, and tasks B and C predicted task A, but tasks B and C did not predict each other (<xref ref-type="table" rid="table4">Table 4</xref>; <xref ref-type="fig" rid="fig2">Figure 2D</xref>), reminiscent of the correlation results (section 'Relative parameter differences'). For <inline-formula><mml:math id="inf119"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, tasks B and C showed a marginally significant <italic>negative</italic> relationship (<xref ref-type="table" rid="table4">Table 4</xref>), suggesting that predicting <inline-formula><mml:math id="inf120"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> between tasks can lead to systematically biased predictions, confirming the striking differences observed before (section 'Parameter age trajectories'). For forgetting, tasks A and C were not predictive of each other (<xref ref-type="table" rid="table4">Table 4</xref>), suggesting that the lack of significant differences we observed previously (<xref ref-type="table" rid="table3">Table 3</xref>) did not necessarily imply successful generalization, but might have been caused by other factors, for example, elevated noise.</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Statistics of the regression models predicting each parameter from the corresponding parameter in a different task, while controlling for age.</title><p>Results were identical when predicting task A from B and task B from A, for all pairs of tasks. Therefore, only one set of results is shown, and predictor and outcome task are not differentiated. Stars indicate significance as before; ‘$’ indicates <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf122"><mml:mi>β</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom">p</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf123"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula>, <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">A &amp; B</td><td align="char" char="." valign="bottom">0.28</td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">A &amp; C</td><td align="char" char="." valign="bottom">0.19</td><td align="char" char="." valign="bottom">0.0022</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">B &amp; C</td><td align="char" char="." valign="bottom">0.039</td><td align="char" char="." valign="bottom">0.54</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf125"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">A &amp; B</td><td align="char" char="." valign="bottom">0.13</td><td align="char" char="." valign="bottom">0.035</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">A &amp; C</td><td align="char" char="." valign="bottom">0.23</td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">B &amp; C</td><td align="char" char="." valign="bottom">–0.073</td><td align="char" char="." valign="bottom">0.25</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf126"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">B &amp; C</td><td align="char" char="." valign="bottom">–0.12</td><td align="char" char="." valign="bottom">0.058</td><td align="char" char="." valign="bottom">$</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="left" valign="bottom">A &amp; C</td><td align="char" char="." valign="bottom">0.097</td><td align="char" char="." valign="bottom">0.13</td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap></sec><sec id="s2-1-5"><title>Statistical comparison to generalizability ceiling</title><p>Our analyses so far suggest that some parameters did not generalize between tasks: We observed differences in age trajectories (section 'Parameter age trajectories') and a lack of mutual prediction (section 'Predicting age trajectories'). However, the lack of correspondence could also arise due to other factors, including behavioral noise, noise in parameter fitting, and parameter trade-offs within tasks. To rule these out, we next established the ceiling of generalizability attainable using our method.</p><p>We established the ceiling in the following way: We first created a dataset with perfect generalizability, simulating behavior from agents that use the same parameters across all tasks (<xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>). We then fitted this dataset in the same way as the human dataset (e.g. using the same models), and performed the same analyses on the fitted parameters, including an assessment of age trajectories (<xref ref-type="table" rid="app5table1">Appendix 5—table 1</xref>) and prediction between tasks (<xref ref-type="table" rid="app5table2">Appendix 5—table 2</xref>, <xref ref-type="table" rid="app5table3">Appendix 5—table 3</xref>, and <xref ref-type="table" rid="app5table4">Appendix 5—table 4</xref>). These results provide the practical ceiling of generalizability, given the limitations of our data and modeling approach. We then compared the human results to this ceiling to ensure that the apparent lack of generalization was a valid conclusion, rather than stemming from methodological constraints: If the empirical human dataset is significantly below ceiling, we can conclude a lack of generalization, but if it is not significantly different from the expected ceiling, our approach might lack validity.</p><p>The results of this analysis support our conclusions. Specifically, whereas humans had shown divergent trajectories for parameter <inline-formula><mml:math id="inf127"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2B</xref>; <xref ref-type="table" rid="table1">Table 1</xref>), the simulated agents (that used the same parameters for all tasks) did not show task differences for <inline-formula><mml:math id="inf128"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> or any other parameter (<xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1B</xref>, <xref ref-type="table" rid="app5table1">Appendix 5—table 1</xref>), even when controlling for age (<xref ref-type="table" rid="app5table2">Appendix 5—table 2</xref>, <xref ref-type="table" rid="app5table3">Appendix 5—table 3</xref>). Furthermore, the same parameters were predictive between tasks in all cases (<xref ref-type="table" rid="app5table4">Appendix 5—table 4</xref>). These results show that our method reliably detected parameter generalization in a dataset that exhibited generalization.</p><p>Lastly, we established whether the degree of generalization in humans was significantly different from agents. To this aim, we calculated the Spearman correlations between each pair of tasks for each parameter, for both humans (section 'Relative parameter differences'; <xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref>) and agents, and then compared humans and agents using bootstrapped confidence intervals (Appendix 5). Human parameter correlations were significantly below the ceiling for most parameters (exceptions: <inline-formula><mml:math id="inf129"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in A vs B; <inline-formula><mml:math id="inf130"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> / <inline-formula><mml:math id="inf131"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> in A vs C; <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1C</xref>). This suggests that the human sample showed less-than-perfect generalization for most task combinations and most parameters: Generalization was lower than in agents for parameters forgetting, <inline-formula><mml:math id="inf132"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf133"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> (in two of three task combinations), and <inline-formula><mml:math id="inf134"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> / <inline-formula><mml:math id="inf135"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> (in two of three task combinations).</p></sec><sec id="s2-1-6"><title>Summary part I: Generalizability</title><p>So far, no parameter has shown generalization between tasks in terms of <italic>absolute values</italic> (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>), but noise/exploration and <inline-formula><mml:math id="inf136"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> showed similar <italic>age trajectories</italic> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), at least in tasks that were sufficiently similar (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). To summarize, (1) all parameters differed significantly between tasks in terms of absolute values (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>). Intriguingly, absolute parameter values varied more between tasks than between participants within tasks, suggesting that task demands played a larger role in determining parameter values than participants’ individual characteristics. This was the case for all four model parameters (Noise/Exploration, <inline-formula><mml:math id="inf137"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf138"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, and Forgetting). (2) However, there was evidence that in some cases, parameter age trajectories generalized between tasks: Task identity did not affect the age trajectories of noise/exploration, forgetting, or learning rate <inline-formula><mml:math id="inf139"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), suggesting possible generalization. However, only noise/exploration and <inline-formula><mml:math id="inf140"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> age trajectories were the same between tasks, hence revealing deeper similarities, and this was only possible when tasks were sufficiently similar (<xref ref-type="table" rid="table4">Table 4</xref>), highlighting the limits of generalization. No generalization was possible for <inline-formula><mml:math id="inf141"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, whose age trajectory differed both qualitatively and quantitatively between tasks, showing striking inverse patterns. Like for absolute parameter values, differences in parameter age trajectories were likely caused by differences in task demands. (3) Parameter <inline-formula><mml:math id="inf142"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> reached ceiling generalizability between tasks A and B, and parameter <inline-formula><mml:math id="inf143"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> / <inline-formula><mml:math id="inf144"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> between tasks A and C. Generalizability of all other task combinations and parameters was significantly lower than expected from a perfectly-generalizing population. (4) For the parameters whose age trajectories showed signs of generalization, our results replicated patterns in the literature, with noise/exploration decreasing and <inline-formula><mml:math id="inf145"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> increasing from childhood to early adulthood (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>).</p></sec></sec><sec id="s2-2"><title>Part II: Parameter interpretability</title><p>To address the second assumption identified above, Part II focuses on parameter interpretability, testing whether parameters captured specific, unique, and meaningful cognitive processes. To this end, we first investigated the relations between different parameters to assess whether individual parameters were uniquely interpretable (i.e. specific and distinct from each other). We then determined how parameters were related to observed behavior, seeking evidence for external interpretability.</p><sec id="s2-2-1"><title>Main axes of variation</title><p>To build a foundation for parameter interpretation, we first aimed to understand which cognitive processes and aspects of participant behavior were captured by each parameter. We opted for a data-driven approach, interpreting parameters based on the major axes of variance that emerged in our large dataset, identified without a priori hypotheses. Concretely, we used PCA to identify the principal components (PCs) of our joint dataset of behavioral features and model parameters (<xref ref-type="bibr" rid="bib1">Abdi and Williams, 2010</xref>). We first gained a thorough understanding of these PCs, and then employed them to better understand what was captured by model parameters. Detailed information on our approach is provided in sections 'Principal component analysis (PCA)' (PCA methods), 'Appendix 6' (behavioral features), and <xref ref-type="fig" rid="app8fig4">Appendix 8—figure 4</xref> (additional PCA results).</p><p>We first analyzed PC1, the axis of largest variation and main source of individual differences in our dataset (25.1% of explained variance; <xref ref-type="fig" rid="app8fig4">Appendix 8—figure 4A</xref>). We found that behaviors that indicated good task participation (e.g. higher percentage of correct choices) loaded positively on PC1, whereas behaviors that indicated poor participation loaded negatively (e.g. more missed trials, longer response times; <xref ref-type="fig" rid="fig3">Figure 3A</xref>). This was the case for performance measures in the narrow sense of maximizing choice accuracy (e.g. percentage correct choices, trials to criterion, proportion of win-stay choices), but also in the wider sense of reflecting task engagement (e.g. number of missed trials, response times, response time variability). PC1 therefore captured a range of ‘good’, task-engaged behaviors, and is likely similar to the construct of ‘decision acuity’ (<xref ref-type="bibr" rid="bib76">Moutoussis et al., 2021</xref>): Decision acuity was recently identified as the first component of a factor analysis (variant of PCA) conducted on 32 decision-making measures on 830 young people, and separated good and bad performance indices. Decision acuity reflected generic decision-making ability, predicted mental health factors, and was reflected in resting-state functional connectivity, but distinct from IQ (<xref ref-type="bibr" rid="bib76">Moutoussis et al., 2021</xref>). Like decision acuity <xref ref-type="bibr" rid="bib76">Moutoussis et al., 2021</xref>, our PC1 increased significantly with age, consistent with increasing performance (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>; age effects of subsequent PCs in <xref ref-type="fig" rid="app8fig4">Appendix 8—figure 4</xref>; <xref ref-type="table" rid="app8table1">Appendix 8—table 1</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Identifying the major axes of variation in the dataset.</title><p>A PCA was conducted on the entire dataset (39 behavioral features and 15 model parameters). The figure shows the factor loadings (y-axis) of of all dataset features (x-axis) for the first three PCs (panels A, B, and C). Features that are RL model parameters are bolded and in purple. Behavioral features are explained in detail in Appendix 1 and Appendix 3 (note that behavioral features differed between tasks). Dotted lines aid visual organization by grouping similar features across tasks (e.g. missed trials of all three tasks) or within tasks (e.g. working-memory-related features for task C). (<bold>A</bold>) PC1 captured broadly-defined task engagement, with negative loadings on features that were negatively associated with performance (e.g. number of missed trials) and positive loadings on features that were positively associated with performance (e.g. percent correct trials). (<bold>B–C</bold>) PC2 (<bold>B</bold>) and PC3 (<bold>C</bold>) captured task contrasts. PC2 loaded positively on features of task B (orange box) and negatively on features of task C (purple box). PC3 loaded positively on features of task A (green box) and negatively on features of tasks B and C. Loadings of features that are negative on PC1 are flipped in PC2 and PC3 to better visualize the task contrasts (section 'Principal component analysis (PCA)').</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-fig3-v1.tif"/></fig><p>How can this understanding of PC1 (decision acuity) help us interpret model parameters? In all three tasks, noise/exploration and forgetting parameters loaded negatively on PC1 (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), showing that elevated decision stochasticity and the decay of learned information were associated with poorer performance in all tasks. <inline-formula><mml:math id="inf146"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> showed positive loadings throughout, suggesting that faster integration of positive feedback was associated with better performance in all tasks. Taken together, noise/exploration, forgetting, and <inline-formula><mml:math id="inf147"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> showed consistency across tasks in terms of their interpretation with respect to decision acuity. Contrary to this, <inline-formula><mml:math id="inf148"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> loaded positively in task C, but negatively in task B, suggesting that performance increased when participants integrated negative feedback faster in task C, but performance decreased when they did the same in task B. As mentioned before, contradictory patterns of <inline-formula><mml:math id="inf149"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> were likely related to task demands: The fact that negative feedback was diagnostic in task C likely favored fast integration of negative feedback, while the fact that negative feedback was not diagnostic in task B likely favored slower integration (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). This interpretation is supported by behavioral findings: ‘lose-stay’ behavior (repeating choices that produce negative feedback) showed the same contrasting pattern as <inline-formula><mml:math id="inf150"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> on PC1, loading positively in task B, which shows that lose-stay behavior benefited performance, but negatively on task C, which shows that it hurt performance (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). This supports the claim that lower <inline-formula><mml:math id="inf151"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was beneficial in task B, while higher <inline-formula><mml:math id="inf152"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was beneficial in task C, in accordance with participant behavior and developmental differences.</p><p>We next analyzed PC2 and PC3. For easier visualization, we flipped the loadings of all features with negative loadings on PC1 to remove the effects of task engagement (PC1) when interpreting subsequent PCs (for details, see section 'Principal component analysis (PCA)'). This revealed that PC2 and PC3 encoded task contrasts: PC2 contrasted task B to task C (loadings were positive / negative / near-zero for corresponding features of tasks B / C / A; <xref ref-type="fig" rid="fig3">Figure 3B</xref>). PC3 contrasted task A to both B and C (loadings were positive / negative for corresponding features on task A / tasks B and C; <xref ref-type="fig" rid="fig3">Figure 3C</xref>). (As opposed to most features of our dataset, missed trials and response times did not show these task contrasts, suggesting that these features did not differentiate between tasks). The ordering of PC2 before PC3 shows that participants’ behavior differed more between task B compared to C (PC2: 8.9% explained variance) than between B and C compared to A (PC3: 6.2%; <xref ref-type="fig" rid="app8fig4">Appendix 8—figure 4</xref>), as expected based on task similarity (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). PC2 and PC3 therefore show that, after task engagement, the main variation in our dataset arose from behavioral differences between tasks.</p><p>How can this understanding of PC2-3 promote our understanding of model parameters? The task contrasts encoded by the main behavioral measures were also evident in several parameters, including noise/exploration parameters, <inline-formula><mml:math id="inf153"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf154"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>: These parameters showed positive loadings for task B in PC2 (A in PC3), and negative loadings for task C (B and C; PC2: <xref ref-type="fig" rid="fig3">Figure 3B</xref>, PC3: 3 C). This indicates that noise/exploration parameters, <inline-formula><mml:math id="inf155"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf156"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> captured different behavioral patterns depending on the task: The variance present in these parameters allowed for the discrimination of all tasks from each other, with PC2 discriminating task B from C, and PC3 discriminating tasks B and C from A. In other words, these parameters were clearly distinguishable between tasks, showing that they did not capture the same processes. Had they captured the same processes across tasks, they would not be differentiable between tasks, similar to, for example, response times. What is more, each parameter captured sufficient task-specific variance to indicate in which task it was measured. In sum, these findings contradict the assumption that parameters are specific or interpretable in a task-independent way.</p><p>Taken together, the PCA revealed that the emerging major axes of variation in our large dataset, together capturing 40.2% of explained variance, were task engagement (PC1) and task differences (PC2-PC3). These dimensions can be employed to better understand model parameters: Task engagement / decision acuity (PC1) played a crucial role for all four parameters (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), and this role was consistent across tasks for noise/exploration, forgetting, and <inline-formula><mml:math id="inf157"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>. This consistency supports the claim that parameters captured specific, task-independent processes in terms of PC1. For <inline-formula><mml:math id="inf158"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, however, PC1 played inverse roles across tasks, showing a lack of task-independent specificity that was likely due to differences in task demands. Furthermore, PC2 and PC3 revealed that noise/exploration, <inline-formula><mml:math id="inf159"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf160"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> specifically encoded task contrasts, suggesting that the parameters captured different cognitive processes across tasks, lacking a task-independent core of meaning.</p></sec><sec id="s2-2-2"><title>Parameters and cognitive processes</title><p>Whereas the previous analysis revealed that parameter roles were not entirely consistent across tasks, it did not distinguish between parameter specificity (whether the same parameter captures the same cognitive processes across tasks) and distinctiveness (whether different parameters capture different cognitive processes).</p><p>To assess this, we probed how much parameter variance was explained by both corresponding and non-corresponding parameters across tasks: We predicted one parameter from all others to get a sense for which relationships were least and most explanatory, while accounting for all relationships of all parameters, using regression. We assumed that parameters reflected one or more cognitive processes, such that shared variance implies overlapping cognitive processes. If parameters are specific (i.e. reflect similar cognitive processes across tasks), then corresponding parameters should be predictive of each other (e.g. when predicting task B’s <inline-formula><mml:math id="inf161"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> from task A’s parameters, task A’s <inline-formula><mml:math id="inf162"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> should show a significant regression coefficient). If parameters are also distinct, then non-corresponding parameters should furthermore not be predictive (e.g. no other parameters beside task A’s <inline-formula><mml:math id="inf163"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> should predict task B’s <inline-formula><mml:math id="inf164"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula>). We used repeated, k-fold cross-validated Ridge regression to avoid overfitting, obtaining unbiased out-of-sample estimates of the means and variances of explained variance <inline-formula><mml:math id="inf165"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> and regression coefficients <inline-formula><mml:math id="inf166"><mml:mi>w</mml:mi></mml:math></inline-formula> (for methods, see section 'Ridge regression').</p><p>Assessing general patterns that arose in this analysis, we found that all significant coefficients connected tasks A and B or tasks A and C but never tasks B and C, mirroring previous results (<xref ref-type="fig" rid="fig2">Figure 2D</xref>; section 'Relative parameter differences') with regard to task similarity (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). This suggests that no parameter had a specific core that extended across all three tasks—the largest shared variance encompassed two tasks.</p><p>We first address parameter specificity. Focusing on noise/exploration parameters, coefficients were significant when predicting noise/exploration in task A from noise/exploration in tasks B or C, but the inverse was not true, such that coefficients were not significant when predicting tasks B or C from task A (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="table" rid="table5">Table 5</xref>). The first result implies parameter specificity, showing that noise/exploration parameters captured variance (cognitive processes) in task A that they also captured in tasks B and C. The second result, however, implies a lack of specificity, showing that noise/exploration parameters captured additional cognitive processes in tasks B and C that they did not capture in task A. A further lack of specificity was evident in that even the variance that both B and C captured in A was not the same: Prediction accuracy increased when combining tasks B and C to predict task A, showing that noise/exploration parameters in tasks B and C captured partly non-overlapping aspects of noise/exploration (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, left-most set of bars, compare purple to orange and blue).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Assessing parameter interpretability by analyzing shared variance.</title><p>(<bold>A</bold>) Parameter variance that is shared between tasks. Each arrow shows a significant regression coefficient when predicting a parameter in one task (e.g. <inline-formula><mml:math id="inf167"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in task A) from all parameters of a different task (e.g. <inline-formula><mml:math id="inf168"><mml:mi>P</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf169"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf170"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf171"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> in task B). The predicted parameter is shown at the arrow head, predictors at its tail. Full lines indicate positive regression coefficients, and are highlighted in purple when connecting two identical parameters; dotted lines indicate negative coefficients; non-significant coefficients are not shown. <xref ref-type="table" rid="table5">Table 5</xref> provides the full statistics of the models summarized in this figure. (<bold>B</bold>) Amount of variance of each parameter that was captured by parameters of other models. Each bar shows the percentage of explained variance (<inline-formula><mml:math id="inf172"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>) when predicting one parameter from all parameters of a different task/model, using Ridge regression. Part (<bold>A</bold>) of this figure shows the coefficients of these models. The x-axis shows the predicted parameter, and colors differentiate between predicting tasks. Three models were conducted to predict each parameter: One combined the parameters of both other tasks (pink), and two kept them separate (green, orange, blue). Larger amounts of explained variance (e.g., Task A <inline-formula><mml:math id="inf173"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> and <inline-formula><mml:math id="inf174"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>) suggest more shared processes between predicted and predicting parameters; the inability to predict variance (e.g. Task B <inline-formula><mml:math id="inf175"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>; Task C working memory parameters) suggests that distinct processes were captured. Bars show mean <inline-formula><mml:math id="inf176"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>, averaged over <inline-formula><mml:math id="inf177"><mml:mi>k</mml:mi></mml:math></inline-formula> data folds (<inline-formula><mml:math id="inf178"><mml:mi>k</mml:mi></mml:math></inline-formula> was chosen for each model based on model fit, using repeated cross-validated Ridge regression; for details, see section 'Ridge regression'); error bars show standard errors of the mean across folds. (<bold>C</bold>) Relations between parameters and behavior. The arrows visualize Ridge regression models that predict parameters (bottom row) from behavioral features (top row) within tasks (full statistics in <xref ref-type="table" rid="table6">Table 6</xref>). Arrows indicate significant regression coefficients, colors denote tasks, and line types denote the sign of the coefficients, like before. All significant within-task coefficients are shown. Task-based consistency (similar relations between behaviors and parameters across tasks) occurs when arrows point from the same behavioral features to the same parameters in different tasks (i.e. parallel arrows). (<bold>D</bold>) Variance of each parameter that was explained by behavioral features; corresponds to the behavioral Ridge models shown in part (<bold>C</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-fig4-v1.tif"/></fig><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Selected coefficients of the repeated, k-fold cross-validated Ridge regression models predicting one parameter from all parameters of a different task.</title><p>The table includes all significant coefficients and selected non-significant coefficients.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Predicted parameter (Task)</th><th align="left" valign="bottom">Predicting parameter (Task)</th><th align="left" valign="bottom">Coefficient</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf179"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom">Noise/exploration (A)</td><td align="left" valign="bottom">Exploration <inline-formula><mml:math id="inf180"><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac></mml:math></inline-formula> (B)</td><td align="char" char="." valign="bottom">0.14</td><td align="char" char="." valign="bottom">0.031</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf181"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (B)</td><td align="char" char="." valign="bottom">0.14</td><td align="char" char="." valign="bottom">0.032</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Persistence (B)</td><td align="char" char="." valign="bottom">–0.19</td><td align="char" char="." valign="bottom">0.0029</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Noise <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom">0.12</td><td align="char" char="." valign="bottom">0.038</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf183"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom">–0.18</td><td align="char" char="." valign="bottom">0.045</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">–0.19</td><td align="char" char="." valign="bottom">0.023</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom">Noise/exploration (B)</td><td align="left" valign="bottom">Noise/exploration (A)</td><td align="char" char="." valign="bottom">0.09</td><td align="char" char="." valign="bottom">0.27</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom">Noise/exploration (C)</td><td align="left" valign="bottom">Noise/exploration (A)</td><td align="char" char="." valign="bottom">0.04</td><td align="char" char="." valign="bottom">0.63</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf184"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (A)</td><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf185"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom">0.22</td><td align="char" char="." valign="bottom">0.011</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom">0.16</td><td align="char" char="." valign="bottom">0.050</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf187"><mml:mi mathsize="80%">K</mml:mi></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom">0.15</td><td align="char" char="." valign="bottom">0.020</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Exploration <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula> (B)</td><td align="char" char="." valign="bottom">0.19</td><td align="char" char="." valign="bottom">0.0026</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf189"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (B)</td><td align="char" char="." valign="bottom">–0.21</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf191"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (B)</td><td align="char" char="." valign="bottom">0.0042</td><td align="char" char="." valign="bottom">0.94</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Persistence (B)</td><td align="char" char="." valign="bottom">0.23</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf193"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula>(B)</td><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf194"><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac></mml:math></inline-formula> (A)</td><td align="char" char="." valign="bottom">–0.077</td><td align="char" char="." valign="bottom">0.37</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf195"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (A)</td><td align="char" char="." valign="bottom">0.058</td><td align="char" char="." valign="bottom">0.48</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf196"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom">–0.00018</td><td align="char" char="." valign="bottom">0.99</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"/><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf197"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom">–0.000055</td><td align="char" char="." valign="bottom">1.00</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Forgetting (A)</td><td align="char" char="." valign="bottom">0.015</td><td align="char" char="." valign="bottom">0.82</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf198"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (C)</td><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf199"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (A)</td><td align="char" char="." valign="bottom">0.20</td><td align="char" char="." valign="bottom">0.013</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf200"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (B)</td><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf201"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (A)</td><td align="char" char="." valign="bottom">–0.25</td><td align="char" char="." valign="bottom">0.0018</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf202"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (C)(C)</td><td align="char" char="." valign="bottom"><inline-formula><mml:math id="inf203"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (A)</td><td align="char" char="." valign="bottom">0.24</td><td align="char" char="." valign="bottom">0.0022</td><td align="char" char="." valign="bottom">**</td></tr></tbody></table></table-wrap><table-wrap id="table6" position="float"><label>Table 6.</label><caption><title>Statistics of selected coefficients in the repeated, k-fold cross-validated Ridge regression models predicting each model parameter from all behavioral features of all three tasks.</title><p>The table includes all significant coefficients of within-task predictors, and a selected number of non-significant and between-task coefficients.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Predicted parameter (Task)</th><th align="left" valign="bottom">Predicting parameter (Task)</th><th align="left" valign="bottom">coefficient</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf204"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom">Noise/exploration (A)</td><td align="left" valign="bottom">Win-stay (A)</td><td align="char" char="." valign="bottom">–0.30</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Lose-stay (A)</td><td align="char" char="." valign="bottom">–0.23</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Accuracy (A)</td><td align="char" char="." valign="bottom">–0.19</td><td align="char" char="." valign="bottom">0.0076</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Response times (A)</td><td align="char" char="." valign="bottom">0.092</td><td align="char" char="." valign="bottom">0.029</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Delay (A)</td><td align="char" char="." valign="bottom">0.25</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom">Noise/exploration (B)</td><td align="left" valign="bottom">Win-stay (B)</td><td align="char" char="." valign="bottom">–0.58</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Lose-stay (B)</td><td align="char" char="." valign="bottom">0.091</td><td align="char" char="." valign="bottom">0.0034</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Accuracy (B)</td><td align="char" char="." valign="bottom">–0.36</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Win-stay (A)</td><td align="char" char="." valign="bottom">–0.12</td><td align="char" char="." valign="bottom">0.032</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Response times (A)</td><td align="char" char="." valign="bottom">0.059</td><td align="char" char="." valign="bottom">0.051</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf205"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (A)</td><td align="left" valign="bottom">Win-stay (A)</td><td align="char" char="." valign="bottom">0.74</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf206"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (B)</td><td align="left" valign="bottom">Win-stay (B)</td><td align="char" char="." valign="bottom">0.27</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf207"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula> (C)</td><td align="left" valign="bottom">Accuracy (C)</td><td align="char" char="." valign="bottom">0.24</td><td align="char" char="." valign="bottom">0.033</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf208"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (B)</td><td align="left" valign="bottom">Win-stay (B)</td><td align="char" char="." valign="bottom">0.29</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Lose-stay (B)</td><td align="char" char="." valign="bottom">–0.71</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Accuracy (B)</td><td align="char" char="." valign="bottom">–0.28</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf209"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula> (C)</td><td align="left" valign="bottom">Win-stay (C)</td><td align="char" char="." valign="bottom">0.16</td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Lose-stay (C)</td><td align="char" char="." valign="bottom">–0.41</td><td align="char" char="." valign="bottom">&lt;0.001</td><td align="char" char="." valign="bottom">***</td></tr></tbody></table></table-wrap><p>Focusing next on learning rates, specificity was evident in that learning rate <inline-formula><mml:math id="inf210"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in task A showed a significant regression coefficient when predicting learning rates <inline-formula><mml:math id="inf211"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf212"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> in task C, and learning rate <inline-formula><mml:math id="inf213"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> in task C showed a significant coefficient when predicting learning rate <inline-formula><mml:math id="inf214"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in task A (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="table" rid="table5">Table 5</xref>). This suggests a shared core of cognitive processes between learning rates <inline-formula><mml:math id="inf215"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf216"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> in tasks A and C. However, a lack of specificity was evident in task B: When predicting <inline-formula><mml:math id="inf217"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in task B, no parameter of any task showed a significant coefficient (including <inline-formula><mml:math id="inf218"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in other tasks; <xref ref-type="table" rid="table5">Table 5</xref>), and it was impossible to predict variance in task B’s <inline-formula><mml:math id="inf219"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> even when combining all parameters of the other tasks (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, ‘Task B’ panel). This reveals that <inline-formula><mml:math id="inf220"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> captured fundamentally different cognitive processes in task B compared to the other tasks. The case was similar for parameter <inline-formula><mml:math id="inf221"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, which strikingly was inversely related between tasks A and B (<xref ref-type="table" rid="table5">Table 5</xref>), and impossible to predict in task B from all other parameters (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). This reveals a fundamental lack of specificity, implying that learning rates in task B did not capture the same core of cognitive processes compared to other tasks.</p><p>We next turned to distinctiveness, that is, whether different parameters capture different cognitive processes. Noise/exploration in task A was predicted by Persistence and <inline-formula><mml:math id="inf222"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> in task B, and by <inline-formula><mml:math id="inf223"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> and working memory weight <inline-formula><mml:math id="inf224"><mml:mi>ρ</mml:mi></mml:math></inline-formula> in task C (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="table" rid="table5">Table 5</xref>). This shows that processes that were captured by noise/exploration parameters in task A were captured by different parameters in other tasks, such that noise/exploration parameters did not capture distinct cognitive processes.</p><p>In the case of learning rates, <inline-formula><mml:math id="inf225"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> in task A was predicted nonspecifically by all parameters of task B (with the notable exception of <inline-formula><mml:math id="inf226"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> itself; <xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="table" rid="table5">Table 5</xref>), suggesting that the cognitive processes that <inline-formula><mml:math id="inf227"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> captured in task A were captured by an interplay of several parameters in task B. Furthermore, task A’s <inline-formula><mml:math id="inf228"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> was predicted by task C’s working memory parameters <inline-formula><mml:math id="inf229"><mml:mi>ρ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf230"><mml:mi>K</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; <xref ref-type="table" rid="table5">Table 5</xref>), suggesting that <inline-formula><mml:math id="inf231"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> captured a conglomerate of RL and working memory processes in task A that was isolated by different parameters in task C (<xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>). In support of this interpretation, no variance in task C’s working memory parameters could be explained by any other parameters (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), suggesting that they captured unique working memory processes that were not captured by other parameters. Task C’s RL parameters, on the other hand, could be explained by parameters in other tasks (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), suggesting they captured overlapping RL processes. In tasks B and C, <inline-formula><mml:math id="inf232"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf233"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> were partly predicted by other learning rate parameters (specific and distinct), partly not predicted at all (lack of specificity), and partly predicted by several parameters (lack of distinctiveness; <xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><p>In sum, in the case of noise/exploration, there was evidence for both specificity and a lack thereof (mutual prediction between some, but not all noise/exploration parameters). Noise/exploration parameters were also not perfectly distinct, being predicted by a small set of other parameters from different tasks. In the case of learning rates, some specificity was evident in the shared variance between tasks A and C, but that specificity was missing in task B. Distinctiveness was particularly low for learning rates, with variance shared widely between multiple different parameters. When conducting the same analyses in simulated agents using the same parameters across tasks (section 'Statistical comparison to generalizability ceiling'), we obtained much higher specificity and distinctiveness.</p></sec><sec id="s2-2-3"><title>Parameters and behavior</title><p>The previous sections suggested that parameters captured different cognitive processes across tasks (i.e. different internal characteristics of learning and choice). We lastly examined whether parameters also captured different behavioral features across tasks (e.g. tendency to stay after positive feedback), and whether behavioral features generalized better. To investigate this question, we assessed the relationships between model parameters and behavioral features across tasks, using regularized Ridge regression as before, and predicting each model parameter from each task’s behavioral features (15 predictors, see 'Appendix 1' and 'Appendix '6; for regression methods, see section 'Ridge regression').</p><p>We found that noise/exploration parameters were predicted by the same behavioral features in tasks A and B, such that task A’s accuracy, win-stay, and lose-stay behavior predicted task A’s <inline-formula><mml:math id="inf234"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula>; and task B’s accuracy, win-stay, and lose-stay behavior predicted task B’s <inline-formula><mml:math id="inf235"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4C</xref>; <xref ref-type="table" rid="table6">Table 6</xref>). This shows consistency in terms of which (task-specific) behaviors were related to (task-specific) parameter <inline-formula><mml:math id="inf236"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula>. Similarly for learning rates, <inline-formula><mml:math id="inf237"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> was predicted by the same behavior (win-stay) in tasks A and B, and <inline-formula><mml:math id="inf238"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was predicted by the same behaviors (lose-stay, win-stay) in tasks B and C (<xref ref-type="fig" rid="fig4">Figure 4C</xref>; <xref ref-type="table" rid="table6">Table 6</xref>). This consistency in <inline-formula><mml:math id="inf239"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> is especially noteworthy given the pronounced lack of consistency in the previous analyses.</p><p>In sum, noise/exploration parameters, <inline-formula><mml:math id="inf240"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf241"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> successfully generalized between tasks in terms of which behaviors they reflected (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), despite the fact that many of the same parameters did not generalize in terms of how they characterized participants (sections 'Differences in absolute parameter values', 'Relative parameter differences', and 'Parameter age trajectories'), and which cognitive processes they captured (sections 'Main axes of variation and parameters and cognitive processes'). Notably, the behavioral and parameter differences we observed between tasks often seemed tuned to specific task characteristics (<xref ref-type="fig" rid="fig1">Figure 1E</xref>), both in the case of parameters (most notably <inline-formula><mml:math id="inf242"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>; <xref ref-type="fig" rid="fig2">Figures 2C</xref> and <xref ref-type="fig" rid="fig3">3A</xref>) and behavior (most notably lose-stay behavior; <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>), suggesting that both behavioral responses and model parameters were shaped by task characteristics. This suggests a succinct explanation for why parameters did not generalize between tasks: Because different tasks elicited different behaviors (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>), and because each behavior was captured by the same parameter across tasks (<xref ref-type="fig" rid="fig4">Figure 4C</xref>), parameters necessarily differed between tasks.</p></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Both generalizability (<xref ref-type="bibr" rid="bib78">Nassar and Frank, 2016</xref>) and interpretability (i.e. the inherent ‘meaningfulness’ of parameters <xref ref-type="bibr" rid="bib55">Huys et al., 2016</xref>) have been stated as advantages of computational modeling, and many current research practices (e.g. comparing parameter-specific findings between studies) endorse them (<xref ref-type="bibr" rid="bib36">Eckstein et al., 2021</xref>). However, RL model generalizability and interpretability has so far eluded investigation, and growing inconsistencies in the literature potentially cast doubt on these assumptions. It is hence unclear whether, to what degree, and under which circumstances we should assume generalizability and interpretability. Our developmental, within-participant study revealed that these assumptions warrant both increased scepticism and continued investigation: Generalizability and interpretability were suprisingly low for most parameters and tasks, but reassuringly high for a few others:</p><p>Exploration/noise parameters showed considerable generalizability in the form of correlated variance and age trajectories. Furthermore, the decline in exploration/noise we observed between ages 8–17 was consistent with previous studies (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>; <xref ref-type="bibr" rid="bib98">Somerville et al., 2017</xref>; <xref ref-type="bibr" rid="bib49">Gopnik, 2020</xref>), revealing consistency across tasks, models, and research groups that supports the generalizability of exploration/noise parameters. Still, for 2/3 pairs of tasks, the degree of generalization was significantly below the level of generalization expected by agents with perfect generalization.</p><p>Interpretability of exploration/noise parameters was mixed: Despite evidence for specificity in some cases (overlap in parameter variance between tasks), it was missing in others (lack of overlap), and crucially, parameters lacked distinctiveness (substantial overlap in variance with other parameters). Thus, while exploration/noise parameters were generalizable across tasks, they were not neurocognitively “interpretable” (as defined above).</p><p>Learning rate from negative feedback showed a substantial lack of generalizability: parameters were less consistent within participants than within tasks, and age trajectories differed both quantitatively and qualitatively. Learning rates from positive feedback, however, showed some convincing patterns of generalization. These results are consistent with the previous literature, which shows mixed results for learning rate parameters (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>). In terms of interpretability, learning rates from positive and negative feedback combined were somewhat specific (overlap in variance between some tasks). However, a lack of specificity (lack of shared core variance) and distinctiveness (fundamental entangling with several other parameters, most notably working memory parameters) overshadowed this result.</p><p>Taken together, our study confirms the patterns of generalizable exploration/noise parameters and task-specific learning rate parameters that are emerging from the literature (<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>). Furthermore, we show that this is not a result of between-participant comparisons, but that the same participants will show different parameters when tested using different tasks. The inconsistency of learning rate parameters leads to the important conclusion that we cannot measure an individual’s ‘intrinsic learning rate’, and that we should not draw general conclusions about ‘the development of learning rates’ with the implication that they apply to all contexts.</p><p>These findings help clarify the source of parameter inconsistencies in previous literature (besides replication problems and technical issues, such as model misspecification [<xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>], lack of model comparison and validation [<xref ref-type="bibr" rid="bib85">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="bib116">Wilson and Collins, 2019</xref>], lack of model critique [<xref ref-type="bibr" rid="bib78">Nassar and Frank, 2016</xref>], inappropriate fitting methods [<xref ref-type="bibr" rid="bib27">Daw, 2011</xref>; <xref ref-type="bibr" rid="bib65">Lee, 2011</xref>], and lack of parameter reliability [<xref ref-type="bibr" rid="bib12">Brown et al., 2020</xref>]): Our results show that discrepancies are expected even with a consistent methodological pipeline and up-to-date modeling techniques, because they are an expected consequence of variations in <italic>context</italic> (e.g. features of the experimental task [section Parameters and behavior] and the computational model). The results also suggest that the mapping between cognitive processes and exhibited behavior is many-to-many, such that different cognitive mechanisms (e.g. reasoning, value learning, episodic memory) can give rise to the same behaviors (e.g. lose-stay behavior) and parameters (e.g. <inline-formula><mml:math id="inf243"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>), while the same cognitive mechanism (e.g. value learning) can give rise to different behaviors (e.g. win-stay, lose-shift) and influence several parameters (e.g. <inline-formula><mml:math id="inf244"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf245"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>), depending on context factors. Under this view, analysis of model parameters alone does not permit unequivocal conclusions about cognitive processes if the context varies (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), and the interpretation of model parameter results requires careful contextualization.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>What do model parameters measure? (<bold>A</bold>) View based on generalizability and interpretability.</title><p>In this view, which is implicitly endorsed by much current computational modeling research, models are fitted in order to reveal individuals’ intrinsic model parameters, which reflect clearly delineated, separable, and meaningful (neuro)cognitive processes, a concept we call <italic>interpretability</italic>. Interpretability is the assumption that every model parameter captures a specific cognitive process (bidirectional arrows between each parameter and process), and that cognitive processes are separable from each other (no connections between processes). Task characteristics are treated as irrelevant, a concept we call <italic>generalizability</italic>, such that parameters of any learning task (within reason) are expected to capture similar cognitive processes. (<bold>B</bold>) Updated view, based on our results, that acknowledges the role of context (e.g. task characteristics, model parameterization, participant sample) in computational modeling. Which cognitive processes are captured by each model parameter is influenced by context (green, orange, blue), as shown by distinct connections between parameters and cognitive processes. Different parameters within the same task can capture overlapping cognitive processes (not interpretable), and the same parameters can capture different processes depending on the task (not generalizable). However, parameters likely capture consistent behavioral features across tasks (thick vertical arrows).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-fig5-v1.tif"/><permissions><copyright-statement>© 2021, Elsevier</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Elsevier</copyright-holder><license><license-p>Figure 5 is reprinted from Figure 3 from <xref ref-type="bibr" rid="bib36">Eckstein et al., 2021</xref>, with permission from Current Opinion in Behavioral Sciences. It is not covered by the CC-BY 4.0 license and further reproduction of this panel would need permission from the copyright holder.</license-p></license></permissions></fig><p>Future research needs to investigate context factors to characterize these issues in more detail. For example, which task characteristics determine which parameters will generalize and which will not, and to what extent? Does context impact whether parameters capture overlapping versus distinct variance? Here, the systematic investigation of task space (i.e., testing the same participants on a large battery of learning tasks created as the full factorial of all task features) could elucidate the relationships between parameter generalizability and task-based context factors (e.g., stochasticity, volatility, reward probability). To determine the distance between tasks, the MDP framework might be especially useful because it decomposes tasks along theoretically meaningful features. Future research will also need to determine the relative contributions of different sources of inconsistency, differentiating those caused by technical issues from those caused by context differences.</p><p>In sum, our results suggest that relating model parameters to cognitive constructs and real-world behavior might require us to carefully account for task variables and environmental variability in general. This ties into a broader open question of how neurocognitive processes are shared between tasks (<xref ref-type="bibr" rid="bib39">Eisenberg et al., 2019</xref>; <xref ref-type="bibr" rid="bib76">Moutoussis et al., 2021</xref>), and reflects a larger pattern of thought in psychology that we cannot objectively assess an individual’s cognitive processing while ignoring context. We have shown that in lab studies, different task contexts recruit different system settings within an individual; similarly, our real-life surroundings, the way they change during development, and our past environments (<xref ref-type="bibr" rid="bib68">Lin et al., 2020</xref>; <xref ref-type="bibr" rid="bib69">Lin et al., 2022</xref>) may also modulate which cognitive processes we recruit.</p><sec id="s3-1"><title>Limitations</title><p>Our study faces several potential limitations, both due to the technical aspects of model creation and selection, and to the broader issue of parameter reliability. One potential technical limitation is the existence of within-model parameter correlations. These correlations may mean the values of parameters of the same model trade off during fitting, potentially leading to lower parameter correlations between models, and decreased estimates of parameter generalizability. However, this limitation is unlikely to affect our overall conclusion: Our simulation analysis showed that generalization was detectable despite this issue (section 'Statistical comparison to generalizability ceiling'), suggesting that we would have been able to detect more generalization in humans if it had been present. Furthermore, the majority of previous work using computational models to study human behavior is subject to the same within-model parameter tradeoffs (e.g. common negative correlation between <inline-formula><mml:math id="inf246"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf247"><mml:mi>β</mml:mi></mml:math></inline-formula> in RL models), meaning that the results of our study likely give a realistic estimate of expected parameter generalization in the current literature.</p><p>Another limitation relates to the potential effects of model misspecification on our results. An example of model misspecification is the failure to include a variable in the model that was relevant in the data-generating process (e.g. outcome-independent choice persistence); such misspecification can lead to the inaccurate estimation of other parameters in the model (e.g. learning rate [<xref ref-type="bibr" rid="bib61">Katahira, 2018</xref>]). In our study, model misspecification—if present—could account for some of the lack of generalization we observed. As for the previous limitation, however, the fact that model misspecification is likely a ubiquitous feature of the current modeling literature (and potentially fundamentally unattainable when fitting complex data-generating processes such as human decision makers) means that our results likely provide a realistic picture of the generalizability of current models.</p><p>Another potential limitation is the difference between the models for each task, despite shared or overlapping cognitive processes. It is possible, for example, that parameters would generalize better if the same model had been used across tasks. The current dataset, however, is not suitable to answer this question: It would be impossible to fit the same model to each task due to issues of model misspecification (when using a model that is too simple) or violation of the principle of simplicity (when using a model that is too complex; for details, see 'Appendix 7'). Future research will be required to address this issue, and to potentially dissociate the effects of model differences and task differences we here jointly call ‘context’.</p><p>Lastly, model parameter reliability might play a crucial role for our results: If parameters lack consistency between two instantiations of the same task (reliability), generalization between different tasks would necessarily be low as well. A recent wave of research, however, has convincingly demonstrated that good reliability is possible for several common RL models (<xref ref-type="bibr" rid="bib12">Brown et al., 2020</xref>; <xref ref-type="bibr" rid="bib97">Shahar et al., 2019</xref>; <xref ref-type="bibr" rid="bib89">Pratt et al., 2021</xref>; <xref ref-type="bibr" rid="bib109">Waltmann et al., 2022</xref>), and we employ the recommended methods here (<xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>). In addition, our simulation analysis shows that our approach can detect generalization.</p><p>In conclusion, a variety of methodological issues could explain (part of) the lack of generalization we find for most parameters in the human sample. However, these issues cannot explain all of our results because the same approach successfully detects generalization in a simulated dataset. Furthermore, none of these issues are unique to our approach, but likely ubiquitous in the current modeling literature. This means that our results likely provide a realistic estimate of parameter generalization based on current methods. A more detailed discussion of each limitation is provided in 'Appendix 7'.</p></sec><sec id="s3-2"><title>Moving forward</title><p>With this research, we do not intend to undermine RL modeling as a practice, or challenge pre-existing findings drawn from it, but to improve its quality. Computational model parameters potentially provide highly valuable insights into (neuro)cognitive processing—we just need to refrain from assuming that the identified processes are always—through their mere nature as model parameters—specific, distinct, and ‘theoretically meaningful’ (<xref ref-type="bibr" rid="bib55">Huys et al., 2016</xref>). Some parameters with the same names do not tend to transfer between different tasks, making them non-interchangeable, while others seem to transfer well. And in all cases, the behavioral features captured by parameters seem to generalize well. In the long term, we need to understand why RL parameters differ between tasks. We suggest three potential, not mutually exclusive answers:</p><list list-type="order"><list-item><p><bold>Adaptation and Optimality.</bold> Variance in RL parameters may reflect how participants adapt their behavior to task demands, an explanation proposed by <xref ref-type="bibr" rid="bib81">Nussenbaum and Hartley, 2019</xref>. Whereas it is commonly assumed that parameters reflect participants’ intrinsic cognitive ‘settings’ (e.g. 10-year-olds have a learning rate of 20%; 16-year-olds of 40%), the optimality-based view suggests that participants instead adaptively tune parameters to task characteristics (e.g. adopting lower learning rates in stable than volatile contexts [<xref ref-type="bibr" rid="bib4">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib77">Nassar et al., 2016</xref>]). Hence, different tasks lead to different parameter estimates because different values are required for optimal behavior; an ‘optimal’ participant—achieving optimal behavior in each task—would therefore naturally show different values across tasks. Similar optimality-based views are held by others (<xref ref-type="bibr" rid="bib74">McGuire et al., 2014</xref>). If adaptation to achieve optimality exists, then we would also predict, for example, that learning rates differ between deterministic and stochastic tasks because each task requires different amounts of behavioral change in response to feedback to reach optimal performance. We indeed observed this pattern in the current study. Age differences in parameters can be explained as differences in adaptation flexibility and/or differences in optimal settings due to interaction with different environments. Participants might require differing levels of change detection or adaptation abilities, depending on their developmental stage (e.g. adolescent cognition may be better adapted to changing environments). More research is needed, however, to determine whether parameter optimality and the capacity to optimize behavior can explain all inconsistencies in the literature. For example, our finding that participants showed the most optimal learning rates in the intermediate age range in task B (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>), whereas optimality increased monotonously with age in tasks A and C (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>), suggests that other factors besides optimization might play a role as well.</p></list-item><list-item><p><bold>Modulatory processes.</bold> RL parameters may vary as a function of modulatory processes that are not well-captured in current RL models. Modulatory processes have been described in cognition and neurobiology and likely serve to shift functional outputs (e.g. hunger increasing motivation [<xref ref-type="bibr" rid="bib5">Berridge, 2007</xref>; <xref ref-type="bibr" rid="bib120">Yu and Dayan, 2005</xref>; <xref ref-type="bibr" rid="bib11">Bouret and Sara, 2005</xref>]). Some modulatory processes reflect external contextual information (e.g. uncertainty affects dopamine neuron firing [<xref ref-type="bibr" rid="bib45">Gershman, 2017</xref>; <xref ref-type="bibr" rid="bib99">Starkweather et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Gershman and Uchida, 2019</xref>]), and RL processes might depend on these same modulatory processes (e.g. RL reward-prediction errors and dopamine [<xref ref-type="bibr" rid="bib94">Schultz et al., 1997</xref>]). Indeed, environments with different degrees of uncertainty have been shown to elicit different learning rates (<xref ref-type="bibr" rid="bib4">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib69">Lin et al., 2022</xref>), and EEG markers of neuromodulator release predicted learning rates (<xref ref-type="bibr" rid="bib58">Jepma et al., 2016</xref>). It is thus possible that neuromodulation by task uncertainty modulates RL processes, reflected in RL parameters. In our data, feedback stochasticity and task volatility likely contribute to uncertainty-related modulation. However, other factors like task similarity, task volatility (<xref ref-type="bibr" rid="bib4">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib77">Nassar et al., 2016</xref>), feedback stochasticity, memory load (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>), feedback valence and conditioning type (<xref ref-type="bibr" rid="bib42">Garrison et al., 2013</xref>), and choice of model parameters (e.g. forgetting [<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>]), counter-factual learning (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>), negative and positive learning rates (<xref ref-type="bibr" rid="bib51">Harada, 2020</xref>; <xref ref-type="bibr" rid="bib61">Katahira, 2018</xref>; <xref ref-type="bibr" rid="bib100">Sugawara and Katahira, 2021</xref>), have also been shown to affect RL parameters, but are independent of uncertainty. More research is therefore needed to investigate the extent of the contribution of modulatory processes, and its impact on cognition and computation.</p></list-item><list-item><p><bold>RL processes are multifaceted.</bold> RL parameters capture a multitude of cognitive processes, whose composition likely differs across tasks (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; <xref ref-type="bibr" rid="bib36">Eckstein et al., 2021</xref>). RL algorithms are framed in the most general way to allow application to a wide range of contexts, including AI, neuroscience, and psychology (<xref ref-type="bibr" rid="bib101">Sutton and Barto, 2017</xref>; <xref ref-type="bibr" rid="bib36">Eckstein et al., 2021</xref>; <xref ref-type="bibr" rid="bib64">Lake et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Collins, 2019</xref>). As behavioral models, their use has spanned a variety of behaviors, meaning that the same parameters capture cognitive processes that vary considerably in type and complexity: For example, the same RL parameters have been said to capture the slow acquisition of implicit preferences (<xref ref-type="bibr" rid="bib94">Schultz et al., 1997</xref>), long-term memory for preferences (<xref ref-type="bibr" rid="bib20">Collins, 2018</xref>), quick recognition of contingency switches (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib103">Tai et al., 2012</xref>), selection of abstract high-level strategies (<xref ref-type="bibr" rid="bib35">Eckstein and Collins, 2020</xref>; <xref ref-type="bibr" rid="bib16">Collins and Koechlin, 2012</xref>; <xref ref-type="bibr" rid="bib34">Donoso et al., 2014</xref>), meta-learning (<xref ref-type="bibr" rid="bib111">Wang et al., 2018</xref>), habitual and goal-directed decision making (<xref ref-type="bibr" rid="bib28">Daw et al., 2011</xref>), working memory or episodic memory-guided choice (<xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib9">Bornstein and Norman, 2017</xref>; <xref ref-type="bibr" rid="bib108">Vikbladh et al., 2019</xref>), and many others. This list of cognitive processes outnumbers the list of typical RL model parameters, suggesting that RL parameters necessarily capture different (combinations of) cognitive processes depending on the paradigm. Indeed, adaptive learning does not seem to be a unitary phenomenon, but seems to be composed of several distinct neuro-cognitive factors (<xref ref-type="bibr" rid="bib74">McGuire et al., 2014</xref>).</p></list-item></list></sec><sec id="s3-3"><title>Conclusion</title><p>Our research has important implications for computational modeling in general, and specifically for fields that focus on individual differences, including developmental and clinical computational research: We show that contextual factors critically impact computational modeling results. Larger, targeted studies will be necessary to identify the most important contextual factors and their precise roles, and to quantify their effects. Other areas of modeling besides RL might face similar issues, given that generalizability and interpretability are also commonly assumed in models of sequential sampling (<xref ref-type="bibr" rid="bib96">Sendhilnathan et al., 2020</xref>; <xref ref-type="bibr" rid="bib73">McDougle and Collins, 2021</xref>), Bayesian inference (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib90">Radulescu et al., 2019</xref>; <xref ref-type="bibr" rid="bib62">Konovalov and Krajbich, 2018</xref>), model-based versus model-free RL (<xref ref-type="bibr" rid="bib12">Brown et al., 2020</xref>; <xref ref-type="bibr" rid="bib63">Kool et al., 2016</xref>; <xref ref-type="bibr" rid="bib52">Hare, 2020</xref>), and others.</p><p>If a model parameter lacks generalizability and/or interpretability, it does not measure task-independent, person-specific characteristics, as we often assume. This parameter is more closely tied to the specific, contextual factors of experimental paradigms, and should be interpreted within the context of that task, and only compared between studies with the clear understanding of this task-dependence. We hope that acknowledging this will help the field of computational modeling to accurately interpret computational models (in direct relation to the experimental task), to combine insights of different studies (by taking into account differences in parameter optimality, modulatory factors, and processes captured by each parameter), and to achieve improved generalizability and interpretability of findings in the future. This work aims not to discourage the use of RL models to model behavior, but to improve the application of these models, in particular the robustness of the conclusions we draw from their fits.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Study design</title><p>Our sample of 291 participants was balanced between females and males, and all ages (8–30 years) were represented equally (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, left). Participants completed four computerized tasks, questionnaires, a saliva sample during the 1–2 hr lab visit, and another take-home sample (see section 'Testing procedure'). To reduce noise, we excluded participants based on task-specific performance criteria (see section 'Participant sample'). Due to worse performance, more younger than older participants were excluded, which is a caveat for the interpretation of age effects (note, however, that these exclusions cannot account for the observed age effects but act against them; <xref ref-type="fig" rid="fig1">Figure 1A</xref>). Our tasks—A (‘Butterfly task’ <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>; <xref ref-type="bibr" rid="bib26">Davidow et al., 2016</xref>), B (‘Stochastic Reversal’ <xref ref-type="bibr" rid="bib103">Tai et al., 2012</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>), and C (‘Reinforcement learning-Working memory’ <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>)—were all classic reinforcement learning tasks: on each trial, participants chose between several actions in an effort to earn rewards, which were presented as binary feedback (win/point or lose/no point) after each choice.</p><p>The tasks varied on several common dimensions (<xref ref-type="fig" rid="fig1">Figure 1E</xref>), which have been related to discrepancies in behavioral and neurocognitive results in the literature (<xref ref-type="bibr" rid="bib42">Garrison et al., 2013</xref>; <xref ref-type="bibr" rid="bib118">Yaple and Yu, 2019</xref>; <xref ref-type="bibr" rid="bib70">Liu et al., 2016</xref>). For example, in one task (task C), positive feedback was deterministic, such that every correct action led to a positive outcome, whereas in the two other tasks (tasks A and B), positive feedback was stochastic, such that some correct actions led to positive and others to negative outcomes. A different set of two tasks (B and C) provided diagnostic positive feedback, such that every positive outcome indicated a correct action, whereas in the third (A), positive feedback was non-diagnostic, such that positive outcomes could indicate both correct and incorrect actions. Two tasks (A and C) presented several different stimuli/states for which correct actions had to be learned, whereas the third (B) only presented a single one. Overall, task A shared more similarities with both tasks B and C than either of these shared with each other, allowing us to ask the exploratory question whether task similarity played a role in parameter generalizability and interpretability. A comprehensive list of task differences is shown in <xref ref-type="fig" rid="fig1">Figure 1E</xref>, and each task is described in more detail in section 'Task design'. Section 'Appendix 3' explains the most prominent findings of each task individually, and shows several behavioral measures over age.</p></sec><sec id="s4-2"><title>Participant sample</title><sec id="s4-2-1"><title>Sample overview</title><p>All procedures were approved by the Committee for the Protection of Human Subjects at the University of California, Berkeley, with reference number 2016-06-8925. We tested 312 participants: 191 children and adolescents (ages 8–17) and 55 adults (ages 25–30) were recruited from the community and completed a battery of computerized tasks, questionnaires, and saliva samples; 66 university undergraduate students (aged 18–50) completed the four tasks as well, but not the questionnaires or saliva sample. Community participants of all ages were pre-screened for the absence of present or past psychological and neurological disorders; the undergraduate sample indicated the absence of these. Compensation for community participants consisted of $25 for the 1–2 hr in-lab portion of the experiment and $25 for completing optional take-home saliva samples; undergraduate students received course credit for participation in the 1-hr study.</p></sec><sec id="s4-2-2"><title>Participant exclusion</title><p>Two participants from the undergraduate sample were excluded because they were older than 30, and 7 were excluded because they failed to indicate their age. This led to a sample of 191 community participants under 18, 57 undergraduate participants between the ages of 18–28, and 55 community participants between the ages of 25–30. Of the 191 participants under 18, 184 completed task B, and 187 completed tasks A and C. Reasons for not completing a task included getting tired, running out of time, and technical issues. All 57 undergraduate participants completed tasks B and C and 55 completed task A. All 55 community adults completed tasks B and A, and 45 completed task C. Appropriate exclusion criteria were implemented separately for each task to exclude participants who failed to pay attention and who performed critically worse than the remaining sample (for task A, see <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>; task B <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; task C <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>). Based on these criteria, 5 participants under the age of 18 were excluded from task B, 10 from task A, and none from task C. One community adult participant was excluded from task A, but no adult undergraduates or community participants were excluded from tasks B or C.</p><p>Because this study related the results from all three tasks, we only included participants who were not excluded in any task, leading to a final sample of 143 participants under the age of 18 (male: 77; female: 66), 51 undergraduate participants (male: 17; female: 34), and 53 adults from the community (male: 25; female: 28), for a total of 247 participants (male: 119; female: 128). We excluded the fourth task of our study from the current analysis, which was modeled after a rodent task and used in humans for the first time (<xref ref-type="bibr" rid="bib59">Johnson and Wilbrecht, 2011</xref>), because the applied performance criterion led to the exclusion of the majority of participants under 18. We split participants into quantiles based on age, which were calculated separately within each sex (for details, see <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>).</p></sec><sec id="s4-2-3"><title>Testing procedure</title><p>After entering the testing room, participants under 18 years and their guardians provided informed assent and permission; participants over 18 provided informed consent. Guardians and participants over 18 filled out a demographic form. Participants were led into a quiet testing room in view of their guardians, where they used a video game controller to complete four computerized tasks, in the following order: The first task was called ‘4-choice’ and assessed reversal learning in an environment with 4 different choice options, with a duration of approximately 5 min (designed after <xref ref-type="bibr" rid="bib59">Johnson and Wilbrecht, 2011</xref>). This task was excluded from the current analysis (see section 'Participant exclusion'). The second task was C (‘Reinforcement learning-Working memory’) and took about 25 min to complete (<xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>). After the second task, participants between the ages of 8–17 provided a saliva sample (for details, see <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>) and took a snack break (5–10 min). After that, participants completed task A (‘Butterfly task’), which took about 15 min (<xref ref-type="bibr" rid="bib26">Davidow et al., 2016</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>), and task B (‘Stochastic Reversal’), which took about 10 min to complete (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>). At the conclusion of the tasks, participants between 11 and 18 completed the Pubertal Development Scale (PDS <xref ref-type="bibr" rid="bib87">Petersen et al., 1988</xref>) and were measured in height and weight. Participants were then compensated with $25 Amazon gift cards. For subjects under 11, their guardians completed the PDS on their behalf. The PDS questionnaire and saliva samples were administered to investigate the role of pubertal maturation on learning and decision making. Pubertal analyses are not the focus of the current study and will be or have been reported elsewhere (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). For methodological details, refer to <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>. The entire lab visit took 60–120 min, depending on the participant, and the order of procedures was the same for all subjects.</p></sec></sec><sec id="s4-3"><title>Task design</title><sec id="s4-3-1"><title>Task A (‘butterfly task’)</title><p>The goal of task A was to collect as many points as possible, by guessing correctly which of two flowers was associated with each of four butterflies. Participants were instructed to guess which flower each butterfly liked more, having been told that butterflies would sometimes also choose the less-liked flower (i.e. act probabilistically). Correct guesses were rewarded with 70% probability, and incorrect guesses with 30%. The task contained 120 trials (30 for each butterfly) that were split into 4 equal-sized blocks, and took between 10 and 20 min to complete. More detailed information about methods and results can be found in <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>.</p></sec><sec id="s4-3-2"><title>Task B (‘stochastic reversal’)</title><p>The goal of task B was to collect golden coins, which were hidden in two green boxes. Participants completed a child-friendly tutorial, in which they were instructed to help a leprechaun find his treasure by collecting individual coins from two boxes. Task volatility (i.e. boxes switching sides) and stochasticity (i.e. correct box not rewarded each time) were introduced one-by-one (for details, see <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>). The task could be in one of two states: ‘Left box is correct’ or ‘Right box is correct’. In the former, selecting the left box led to reward in 75% of trials, while selecting the right box never led to a reward (0%). Several times throughout the task, task contingencies changed unpredictably and without notice (after participants had reached a performance criterion indicating they had learned the current state), and the task switched states. Participants completed 120 trials of this task (2–9 reversals), which took approximately 5–15 min. For more information and additional task details, refer to <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>.</p></sec><sec id="s4-3-3"><title>Task C (‘reinforcement learning-working memory’)</title><p>The goal of task C was to collect as many points as possible by pressing the correct key for each stimulus. Participants were instructed to learn an ‘alien language’ of key presses by associating individual pictures with specific key presses. Pressing the correct key for a specific stimulus deterministically led to reward, and the correct key for a stimulus never changed. Different blocks required subjects to learn about different numbers of stimuli, with set sizes ranging from 2 to 5 images. In each block, each stimulus was presented 12–14 times, for a total of 13 * set size trials per block. Three blocks had set sizes of 2–3, and 2 blocks had set sizes of 4–5, for a total of 10 blocks. The task took between 15 and 25 minutes to complete. For more details, as well as a full analysis of this dataset, refer to <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>.</p></sec></sec><sec id="s4-4"><title>Computational models</title><p>For all tasks, we used RL theory to model how participants adapted their behavior in order to maximize reward. RL models assume that agents learn a policy <inline-formula><mml:math id="inf248"><mml:mrow><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that determines (probabilistically) which action <inline-formula><mml:math id="inf249"><mml:mi>a</mml:mi></mml:math></inline-formula> to take in each state <inline-formula><mml:math id="inf250"><mml:mi>s</mml:mi></mml:math></inline-formula> of the world (<xref ref-type="bibr" rid="bib101">Sutton and Barto, 2017</xref>). Here and in most cognitive RL models, this policy is based on action values <inline-formula><mml:math id="inf251"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, that is, the values of each action <inline-formula><mml:math id="inf252"><mml:mi>a</mml:mi></mml:math></inline-formula> in each state <inline-formula><mml:math id="inf253"><mml:mi>s</mml:mi></mml:math></inline-formula>. Agents learn action values by observing the reward outcomes, <italic>r</italic><sub><italic>t</italic></sub>, of their actions at each time step <inline-formula><mml:math id="inf254"><mml:mi>t</mml:mi></mml:math></inline-formula>. Learning consists of updating existing action values <inline-formula><mml:math id="inf255"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using the ‘reward prediction error’, the difference between the expected reward <inline-formula><mml:math id="inf256"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the actual reward <italic>r</italic><sub><italic>t</italic></sub>:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>How much a learner weighs past action value estimates relative to new outcomes is determined by parameter <inline-formula><mml:math id="inf257"><mml:mi>α</mml:mi></mml:math></inline-formula>, the learning rate. Small learning rates favor past experience and lead to stable learning over long time horizons, while large learning rates favor new outcomes and allow for faster and more flexible changes according to shorter time horizons. With enough time and in a stable environment, the RL updating scheme guarantees that value estimates will reflect the environment’s true reward probabilities, and thereby allow for optimal long-term choices (<xref ref-type="bibr" rid="bib101">Sutton and Barto, 2017</xref>).</p><p>In order to choose actions, most cognitive RL models use a (noisy) ‘softmax’ function to translate action values <inline-formula><mml:math id="inf258"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> into policies <inline-formula><mml:math id="inf259"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mtext> </mml:mtext><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>β</mml:mi><mml:mtext> </mml:mtext><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf260"><mml:mi>A</mml:mi></mml:math></inline-formula> refers to the set of all available actions (tasks A and B have 2 actions, task C has 3), and <italic>a</italic><sub><italic>i</italic></sub> and <italic>a</italic><sub><italic>j</italic></sub> to individual actions within the set. How deterministically versus noisily this translation is executed is determined by exploration parameter <inline-formula><mml:math id="inf261"><mml:mi>β</mml:mi></mml:math></inline-formula>, also called inverse decision temperature, and/or <inline-formula><mml:math id="inf262"><mml:mi>ϵ</mml:mi></mml:math></inline-formula>, the decision noise (see below). Small decision temperatures <inline-formula><mml:math id="inf263"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> favor the selection of the highest-valued actions, biasing an agent towards exploitation, whereas large decision temperatures select actions of low and high values more evenly, enabling exploration. Parameter <inline-formula><mml:math id="inf264"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> adds undirected noise to action selection, selecting random actions with a small probability <inline-formula><mml:math id="inf265"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> on each trial.</p><p>Besides <inline-formula><mml:math id="inf266"><mml:mi>α</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf267"><mml:mi>β</mml:mi></mml:math></inline-formula>, and noise, cognitive RL models often include additional parameters to better fit empirical behavior in humans or animals. Common choices include Forgetting—a consistent decay of action values back to baseline—, and Persistence—the tendency to repeat the same action independent of outcomes, a parameter also known as sticky choice or perseverance (<xref ref-type="bibr" rid="bib100">Sugawara and Katahira, 2021</xref>). In addition, cognitive models often differentiate learning from positive versus negative rewards, splitting learning rate <inline-formula><mml:math id="inf268"><mml:mi>α</mml:mi></mml:math></inline-formula> into two separate parameters <inline-formula><mml:math id="inf269"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf270"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, which are applied to only positive and only negative outcomes, respectively (<xref ref-type="bibr" rid="bib51">Harada, 2020</xref>; <xref ref-type="bibr" rid="bib57">Javadi et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Christakou et al., 2013</xref>; <xref ref-type="bibr" rid="bib105">van den Bos et al., 2012</xref>; <xref ref-type="bibr" rid="bib40">Frank et al., 2004</xref>; <xref ref-type="bibr" rid="bib13">Cazé and van der Meer, 2013</xref>; <xref ref-type="bibr" rid="bib84">Palminteri et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Lefebvre et al., 2017</xref>; <xref ref-type="bibr" rid="bib25">Dabney et al., 2020</xref>). The next paragraphs introduce these parameters in detail.</p><p>In task A, the best fitting model included a forgetting mechanism, which was implemented as a decay in Q-values applied to all action values of the three stimuli (butterflies) that were not shown on the current trial:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>*</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The free parameter <inline-formula><mml:math id="inf271"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> reflects individuals’ tendencies to forget.</p><p>In task B, free parameter <inline-formula><mml:math id="inf272"><mml:mi>P</mml:mi></mml:math></inline-formula> captured choice persistence, which biased choices on the subsequent trial toward staying (<inline-formula><mml:math id="inf273"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) or switching (<inline-formula><mml:math id="inf274"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). <inline-formula><mml:math id="inf275"><mml:mi>P</mml:mi></mml:math></inline-formula> modifies action values <inline-formula><mml:math id="inf276"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> into <inline-formula><mml:math id="inf277"><mml:mrow><mml:msup><mml:mi>Q</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, as follows:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>In addition, the model of task B included counter-factual learning parameters <inline-formula><mml:math id="inf278"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf279"><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula>, which added counter-factual updates based on the inverse outcome and affected the non-chosen action. For example, after receiving a positive outcome (<inline-formula><mml:math id="inf280"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) for choosing left (<inline-formula><mml:math id="inf281"><mml:mi>a</mml:mi></mml:math></inline-formula>), counter-factual updating would lead to an ‘imaginary’ negative outcome (<inline-formula><mml:math id="inf282"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>) for choosing right (<inline-formula><mml:math id="inf283"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula>).<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>−</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula><disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf284"><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula> indicates the non-chosen action, and <inline-formula><mml:math id="inf285"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula> indicates the inverse of the received outcome, <inline-formula><mml:math id="inf286"><mml:mrow><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. The best model fits were achieved with <inline-formula><mml:math id="inf287"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf288"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>-</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>, so counter-factual learning rates are not reported in this paper.</p><p>In tasks A and B, positive and negative learning rates are differentiated in the following way:<disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></disp-formula><disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p><p>In the best model for task A, only <inline-formula><mml:math id="inf289"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> was a free parameter, while <inline-formula><mml:math id="inf290"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was fixed to 0. In task C, <inline-formula><mml:math id="inf291"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was a function of <inline-formula><mml:math id="inf292"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, such that <inline-formula><mml:math id="inf293"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf294"><mml:mi>b</mml:mi></mml:math></inline-formula> is the neglect bias parameter that determines how much negative feedback is neglected compared to positive feedback. Throughout the paper, we report <inline-formula><mml:math id="inf295"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for task C.</p><p>In addition to an RL module, the model of task C included a working memory module with perfect recall of recent outcomes, but fast forgetting and strict capacity limitations. Perfect recall was modeled as an RL process with learning rate <inline-formula><mml:math id="inf296"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> that operated on working-memory weights <inline-formula><mml:math id="inf297"><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> rather than action values. On trials with positive outcomes (<inline-formula><mml:math id="inf298"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), the model reduces to:<disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula></p><p>On trials with negative outcomes (<inline-formula><mml:math id="inf299"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), multiplying <inline-formula><mml:math id="inf300"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> with the neglect bias <inline-formula><mml:math id="inf301"><mml:mi>b</mml:mi></mml:math></inline-formula> leads to potentially less-than perfect memory:<disp-formula id="equ11"><mml:math id="m11"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Working-memory weights <inline-formula><mml:math id="inf302"><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> were transformed into action policies <inline-formula><mml:math id="inf303"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in a similar way as RL weights <inline-formula><mml:math id="inf304"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> were transformed into action probabilities <inline-formula><mml:math id="inf305"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, using a softmax transform combined with undirected noise:<disp-formula id="equ12"> <mml:math id="m12"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mpadded width="+5pt"><mml:mi>β</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mpadded width="+5pt"><mml:mi>β</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>Q</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>*</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf306"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> is the number of available actions and <inline-formula><mml:math id="inf307"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mfrac></mml:math></inline-formula> is the uniform policy over these actions; <inline-formula><mml:math id="inf308"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> is the undirected noise parameter.</p><p>Forgetting was implemented as a decay in working-memory weights <inline-formula><mml:math id="inf309"><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (but not RL Q-values):<disp-formula id="equ13"><mml:math id="m13"><mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>*</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Capacity limitations on working memory were modeled as an adjustment in the weight <inline-formula><mml:math id="inf310"><mml:mi>w</mml:mi></mml:math></inline-formula> of <inline-formula><mml:math id="inf311"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>W</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> compared to <inline-formula><mml:math id="inf312"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the final calculation of action probabilities <inline-formula><mml:math id="inf313"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ14"><mml:math id="m14"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∗</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mi>K</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ15"><mml:math id="m15"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>W</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∗</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The free parameter <inline-formula><mml:math id="inf314"><mml:mi>ρ</mml:mi></mml:math></inline-formula> is the probability of using values stored in working memory to choose an action (relative to RL), <inline-formula><mml:math id="inf315"><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> indicates a block’s stimulus set size, and <inline-formula><mml:math id="inf316"><mml:mi>K</mml:mi></mml:math></inline-formula> captures individual differences in working memory capacity.</p><p>We fitted a separate RL model to each task, using state-of-the-art methods for model construction, fitting, and validation (<xref ref-type="bibr" rid="bib116">Wilson and Collins, 2019</xref>; <xref ref-type="bibr" rid="bib85">Palminteri et al., 2017</xref>). Models for tasks A and B were fitted using hierarchical Bayesian methods with Markov-Chain Monte-Carlo sampling, which is an improved method compared to maximum likelihood that leads to better parameter recovery, amongst other advantages (<xref ref-type="bibr" rid="bib43">Gelman et al., 2013</xref>; <xref ref-type="bibr" rid="bib60">Katahira, 2016</xref>; <xref ref-type="bibr" rid="bib112">Watanabe, 2013</xref>). The model for task C was fitted using classic non-hierarchical maximum-likelihood because model parameter <inline-formula><mml:math id="inf317"><mml:mi>K</mml:mi></mml:math></inline-formula> is discrete, which renders hierarchical sampling less tractable. In all cases, we verified that the model parameters were recoverable by the selected model-fitting procedure, and that the models were identifiable. Details of model-fitting procedures are provided in the original publications (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>).</p><p>For additional details on any of these models, as well as detailed model comparison and validation, the reader is referred to the original publications (task A: <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>; task B: <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; task C: <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>).</p></sec><sec id="s4-5"><title>Principal component analysis (PCA)</title><p>The PCA in section Main axes of variation included 15 model parameters (<inline-formula><mml:math id="inf318"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and noise/exploration in each task; Forgetting and <inline-formula><mml:math id="inf319"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> in two tasks; Persistence in task B; four working memory parameters in task C; see section 'Computational models') and 39 model-free features, including simple behavioral features (e.g. overall performance, reaction times, tendency to switch), results of behavioral regression models (e.g. effect of delay between presentations of the same stimulus on accuracy), and the model parameters of an alternative Bayesian inference model in task B. All behavioral features, including their development over age, are described in detail in Appendix 6 and <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>. For simplicity, section Main axes of variation focused on the first three PCs only; the weights, explained variance, and age trajectories of remaining PCs are shown in <xref ref-type="fig" rid="app8fig4">Appendix 8—figure 4</xref>.</p><p>PCA is a statistical tool that decomposes the variance of a dataset into so-called ‘principal components’ (PCs; <xref ref-type="bibr" rid="bib1">Abdi and Williams, 2010</xref>). PCs are linear combinations of a dataset’s original features (e.g. response times, accuracy, learning rates), and explain the same variance in the dataset as the original features. The advantage of PCs is that they are orthogonal to each other and therefore capture independent aspects of the data. In addition, subsequent PCs explain subsequently less variance, such that selecting just the top PCs of a dataset retains the bulk of the variance and the ability to reconstruct the dataset up to some ceiling determined by random noise. When using this approach, it is important to understand which concept each PC captures. So-called factor loadings, the original features’ weights on each PC, can provide this information.</p><p>PCA performs a <italic>change of basis</italic>: Instead of describing the dataset using the original features (in our case, 54 behaviors and model parameters), it creates new features, PCs, that are linear combinations of the original features and capture the same variance, but are orthogonal to each other. PCs are created by eigendecomposition of the covariance matrix of the dataset: the eigenvector with the largest eigenvalue shows the direction in the dataset in which most variance occurs, and represents the first PC. Eigenvectors with subsequently smaller eigenvalues form subsequent PCs. PCA is related to Factor analysis, and results are very consistent between both methods in our dataset. PCA and FA are often used for dimensionality reduction. In this case, only a small number of PCs / Factors is retained, whereas the majority is discarded, in an effort to retain most variance with a reduced number of features.</p><p>We highlight the most central behavioral features here; more detail is provided in 'Appendix 1' and 'Appendix 6'. Response to feedback was assessed using features ‘Win-stay’ (percentage of trials in which a rewarded choice was repeated), and ‘Lose-stay’ (percentage of trials in which a non-rewarded choice was repeated). For task B, we additionally included ‘Win-lose-stay’ tendencies, which is the proportion of trials in which participants stay after a winning trial that is followed by a losing trial. This is an important measure for this task because the optimal strategy required staying after single losses.</p><p>We also included behavioral persistence measures in all tasks. In tasks A and C, these included a measure of action repetition (percentage of trials in which the previous key was pressed again, irrespective of the stimulus and feedback) and choice repetition (percentage of trials in which the action was repeated that was previously selected for the same stimulus, irrespective of feedback). In task B, both measures were identical because every trial presents the same stimulus.</p><p>We further included task-specific measures of performance. In task A, these were: the average accuracy for the first three presentations of each stimulus, reflecting early learning speed; and the asymptote, intercept, and slope of the learning progress in a regression model predicting performance (for details about these measures, see <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). In task B, task-specific measures of performance included the number of reversals (because reversals were performance-based); and the average number of trials to reach criterion after a switch. In tasks A and C, we also included a model-independent measure of forgetting. In task A, this was the effect of delay on performance in the regression model mentioned above. In task C, this was the effect of delay in a similar regression model, which also included set size, the number of previous correct choices, and the number of previous incorrect choices, whose effects were also included. Lastly for task C, we included the slope of accuracy and response times over set sizes, as measures of the effect of set size on performance. For task B, we also included the difference between early (first third of trials) and late (last third) performance as a measure of learning. To avoid biases in the PCA toward any specific task, we included equal numbers of behavioral features for each task. Before performing the PCA, we individually standardized each feature, such that each feature was centered with a mean of 0 and a standard deviation of 1.</p><p>To facilitate the interpretation of PC2 and PC3, we normalized the loadings (PCA weights) of each feature (behavioral and model parameter) with respect to PC1, flipping the loadings of all features in PC2 and PC3 that loaded negatively on PC1. This step ensured that the directions of factor loadings on PC2 and PC3 were interpretable in the same way for all features, irrespective of their role for task performance, and revealed the encoding of task contrasts.</p></sec><sec id="s4-6"><title>Ridge regression</title><p>In sections Parameters and cognitive processes and parameters and behavior, we use regularized, cross-validated Ridge regression to determine whether parameters captured overlapping variance, which would point to an overlap in cognitive processes. We used Ridge regression to avoid problems that would be caused by overfitting when using regular regression models. Ridge regression regularizes regression weight parameters <inline-formula><mml:math id="inf320"><mml:mi>w</mml:mi></mml:math></inline-formula> based on their L2-norm. Regular regression identifies a vector of regression weights <inline-formula><mml:math id="inf321"><mml:mi>w</mml:mi></mml:math></inline-formula> that minimize the linear least squares <inline-formula><mml:math id="inf322"><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>. Here, <inline-formula><mml:math id="inf323"><mml:mrow><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>a</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> is the L2-norm of a vector <inline-formula><mml:math id="inf324"><mml:mi>a</mml:mi></mml:math></inline-formula>, vector <inline-formula><mml:math id="inf325"><mml:mi>y</mml:mi></mml:math></inline-formula> represents the outcome variable (in our case, a vector of parameters, one fitted to each participant), matrix <inline-formula><mml:math id="inf326"><mml:mi>X</mml:mi></mml:math></inline-formula> represents the predictor variables (in our case, either several behavioral features for each participant [section 'Parameters and cognitive processes'], or several parameters fitted to each participant [section 'Parameters and behavior']), and vector <inline-formula><mml:math id="inf327"><mml:mi>w</mml:mi></mml:math></inline-formula> represents the weights assigned to each feature in <inline-formula><mml:math id="inf328"><mml:mi>X</mml:mi></mml:math></inline-formula> (in our case, the weight assigned to each predicting behavioral pattern or each predicting parameter).</p><p>When datasets are small compared to the number of predictors in a regression model, <italic>exploding</italic> regression weights <inline-formula><mml:math id="inf329"><mml:mi>w</mml:mi></mml:math></inline-formula> can lead to overfitting. Ridge regression avoids this issue by not only minimizing the linear least squares like regular regression, but also the L2 norm of weights <inline-formula><mml:math id="inf330"><mml:mi>w</mml:mi></mml:math></inline-formula>, that is, by minimizing <inline-formula><mml:math id="inf331"><mml:mrow><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:mrow><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>*</mml:mo><mml:msubsup><mml:mrow><mml:mo fence="true">||</mml:mo><mml:mi>w</mml:mi><mml:mo fence="true">||</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. Parameter <inline-formula><mml:math id="inf332"><mml:mi>α</mml:mi></mml:math></inline-formula> is a hyper-parameter of Ridge regression, which needs to be chosen by the experimenter. To avoid bias in the selection of <inline-formula><mml:math id="inf333"><mml:mi>α</mml:mi></mml:math></inline-formula>, we employed repeated cross-validated grid search. At each iteration of this procedure, we split the dataset into a predetermined number <inline-formula><mml:math id="inf334"><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> [2, 3, …, 8] of equal-sized folds, and then fitted a Ridge regression to each fold, using values of <inline-formula><mml:math id="inf335"><mml:mrow><mml:mi>α</mml:mi><mml:mo>∈</mml:mo><mml:mi/></mml:mrow></mml:math></inline-formula> [0, 10, 30, 50, 100, 300, …, 10,000, 100,000, 1,000,000]. For each <inline-formula><mml:math id="inf336"><mml:mi>s</mml:mi></mml:math></inline-formula>, we determined the best value of <inline-formula><mml:math id="inf337"><mml:mi>α</mml:mi></mml:math></inline-formula> based on cross-validation between folds, using the amount of explained variance, <inline-formula><mml:math id="inf338"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>, as the selection criterion. To avoid biases based on the random assignment of participants into folds, we repeated this procedure <inline-formula><mml:math id="inf339"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> times for each value of <inline-formula><mml:math id="inf340"><mml:mi>α</mml:mi></mml:math></inline-formula>. To avoid biases due to the number of folds, the entire process was repeated for each <inline-formula><mml:math id="inf341"><mml:mi>s</mml:mi></mml:math></inline-formula>, and the final value of <inline-formula><mml:math id="inf342"><mml:mi>s</mml:mi></mml:math></inline-formula> was selected based on <inline-formula><mml:math id="inf343"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula>. We used the python package ‘scikit learn’ (<xref ref-type="bibr" rid="bib86">Pedregosa et al., 2011</xref>) to implement the procedure.</p><p>We conducted three models per parameter to determine the relations between parameters: predicting each parameter from all the parameters of each of the other two tasks (2 models); and predicting each parameter from all parameters of both other tasks combined (1 model; <xref ref-type="fig" rid="fig4">Figure 4A</xref>). We conducted the same three models per parameter to determine the relations between parameters and behaviors, predicting each parameter from behavioral features of the other tasks (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). In addition, we conducted a fourth model for behaviors, predicting each parameter from the behaviors of all three tasks combined, to assess the contributions of all behaviors to each parameter (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Meta-parameters <inline-formula><mml:math id="inf344"><mml:mi>s</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf345"><mml:mi>α</mml:mi></mml:math></inline-formula> were allowed to differ (and differed) between models. The final values of <inline-formula><mml:math id="inf346"><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4B and D</xref>) and the final regression weights <inline-formula><mml:math id="inf347"><mml:mi>w</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4A and C</xref>; <xref ref-type="table" rid="table6">Table 6</xref>) were determined by refitting the winning model.</p></sec><sec id="s4-7"><title>Data Availability</title><p>The data collected for this study are openly available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/h4qr6/">osf.io/h4qr6/</ext-link>. The analysis code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/MariaEckstein/SLCN/blob/master/models/MetaSLCN-01ReadInData.ipynb">https://github.com/MariaEckstein/SLCN/blob/master/models/MetaSLCN-01ReadInData.ipynb</ext-link>. (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:2208f3398c0661225348312d6b0915cfd2f59cda;origin=https://github.com/MariaEckstein/SLCN;visit=swh:1:snp:2e353f04cfbb36a541776a2cbcc0ea45eac969a5;anchor=swh:1:rev:4fb5955c1142fcbd8ec80d7fccdf6b35dbfd1616">swh:1:rev:4fb5955c1142fcbd8ec80d7fccdf6b35dbfd1616</ext-link>, <xref ref-type="bibr" rid="bib37">Eckstein, 2022</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Funding acquisition, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Resources, Supervision, Funding acquisition, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: We obtained informed consent from all participants at least 18 years of age, and informed assent and parents' informed consent from younger participants. We obtained ethical approval for this research from the Institutional Review Board of UC Berkeley.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-75474-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data collected for this project have been made available online on the OSF data servers.</p><p>The following datasets were generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>The Unique Advantage of Adolescents in Probabilistic Reversal</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/jm2c8/">jm2c8</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset2"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Modeling Changes in Probabilistic Reinforcement Learning during Adolescence</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/wq4te/">wq4te</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset3"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>M</given-names></name><name><surname>Master</surname><given-names>SL</given-names></name><name><surname>Zou</surname><given-names>AR</given-names></name><name><surname>Collins</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Data for &quot;The interpretation of computational model parameters depends on the context&quot;</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/h4qr6/">h4qr6</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Ian Ballard, Mayank Agrawal, Gautam Agarwal, and Bas van Opheusden for helpful comments on this manuscript, and Catherine Hartley and other members of her lab for fruitful discussion. We also thank Angela Radulescu and one anonymous reviewer for their helpful comments and suggestions. Numerous people contributed to this research: Amy Zou, Lance Kriegsfeld, Celia Ford, Jennifer Pfeifer, Megan Johnson, Vy Pham, Rachel Arsenault, Josephine Christon, Shoshana Edelman, Lucy Eletel, Neta Gotlieb, Haley Keglovits, Julie Liu, Justin Morillo, Nithya Rajakumar, Nick Spence, Tanya Smith, Benjamin Tang, Talia Welte, and Lucy Whitmore. We are also grateful to our participants and their families. The work was funded by National Science Foundation SL-CN grant 1640885 to RD, AGEC, and LW.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdi</surname><given-names>H</given-names></name><name><surname>Williams</surname><given-names>LJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Principal component analysis</article-title><source>Wiley Interdisciplinary Reviews: Computational Statistics</source><volume>2</volume><fpage>433</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1002/wics.101</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>RA</given-names></name><name><surname>Huys</surname><given-names>QJM</given-names></name><name><surname>Roiser</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational psychiatry: towards a mathematically informed understanding of mental illness</article-title><source>Journal of Neurology, Neurosurgery, and Psychiatry</source><volume>87</volume><fpage>53</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1136/jnnp-2015-310737</pub-id><pub-id pub-id-type="pmid">26157034</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahn</surname><given-names>WY</given-names></name><name><surname>Busemeyer</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Challenges and promises for translating computational tools into clinical practice</article-title><source>Current Opinion in Behavioral Sciences</source><volume>11</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.02.001</pub-id><pub-id pub-id-type="pmid">27104211</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><pub-id pub-id-type="doi">10.1038/nn1954</pub-id><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berridge</surname><given-names>KC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The debate over dopamine ’ S role in reward: the case for incentive salience</article-title><source>Psychopharmacology</source><volume>191</volume><fpage>391</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1007/s00213-006-0578-x</pub-id><pub-id pub-id-type="pmid">17072591</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blakemore</surname><given-names>SJ</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decision-Making in the adolescent brain</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1184</fpage><lpage>1191</lpage><pub-id pub-id-type="doi">10.1038/nn.3177</pub-id><pub-id pub-id-type="pmid">22929913</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blohm</surname><given-names>G</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name><name><surname>Schrater</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A how-to-model guide for neuroscience</article-title><source>ENeuro</source><volume>7</volume><elocation-id>ENEURO.0352-19.2019</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0352-19.2019</pub-id><pub-id pub-id-type="pmid">32046973</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolenz</surname><given-names>F</given-names></name><name><surname>Reiter</surname><given-names>AMF</given-names></name><name><surname>Eppinger</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Developmental changes in learning: computational mechanisms and social influences</article-title><source>Frontiers in Psychology</source><volume>8</volume><elocation-id>2048</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2017.02048</pub-id><pub-id pub-id-type="pmid">29250006</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bornstein</surname><given-names>AM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reinstated episodic context guides sampling-based decisions for reward</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>997</fpage><lpage>1003</lpage><pub-id pub-id-type="doi">10.1038/nn.4573</pub-id><pub-id pub-id-type="pmid">28581478</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Hierarchical reinforcement learning and decision making</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>956</fpage><lpage>962</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.05.008</pub-id><pub-id pub-id-type="pmid">22695048</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouret</surname><given-names>S</given-names></name><name><surname>Sara</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Network reset: a simplified overarching theory of locus coeruleus noradrenaline function</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>574</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2005.09.002</pub-id><pub-id pub-id-type="pmid">16165227</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>VM</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Gillan</surname><given-names>CM</given-names></name><name><surname>Price</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Improving the reliability of computational analyses: model-based planning and its relationship with compulsivity</article-title><source>Biological Psychiatry. Cognitive Neuroscience and Neuroimaging</source><volume>5</volume><fpage>601</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1016/j.bpsc.2019.12.019</pub-id><pub-id pub-id-type="pmid">32249207</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cazé</surname><given-names>RD</given-names></name><name><surname>van der Meer</surname><given-names>MAA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Adaptive properties of differential learning rates for positive and negative outcomes</article-title><source>Biol Cybern</source><volume>107</volume><fpage>711</fpage><lpage>719</lpage><pub-id pub-id-type="doi">10.1007/s00422-013-0571-5</pub-id><pub-id pub-id-type="pmid">24085507</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christakou</surname><given-names>A</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Simmons</surname><given-names>A</given-names></name><name><surname>Brammer</surname><given-names>M</given-names></name><name><surname>Rubia</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural and psychological maturation of decision-making in adolescence and young adulthood</article-title><source>Journal of Cognitive Neuroscience</source><volume>25</volume><fpage>1807</fpage><lpage>1823</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00447</pub-id><pub-id pub-id-type="pmid">23859647</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis</article-title><source>The European Journal of Neuroscience</source><volume>35</volume><fpage>1024</fpage><lpage>1035</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2011.07980.x</pub-id><pub-id pub-id-type="pmid">22487033</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Reasoning, learning, and creativity: frontal lobe function and human decision-making</article-title><source>PLOS Biology</source><volume>10</volume><elocation-id>e1001293</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1001293</pub-id><pub-id pub-id-type="pmid">22479152</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Brown</surname><given-names>JK</given-names></name><name><surname>Gold</surname><given-names>JM</given-names></name><name><surname>Waltz</surname><given-names>JA</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Working memory contributions to reinforcement learning impairments in schizophrenia</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>13747</fpage><lpage>13756</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0989-14.2014</pub-id><pub-id pub-id-type="pmid">25297101</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Albrecht</surname><given-names>MA</given-names></name><name><surname>Waltz</surname><given-names>JA</given-names></name><name><surname>Gold</surname><given-names>JM</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Interactions among working memory, reinforcement learning, and effort in value-based choice: a new paradigm and selective deficits in schizophrenia</article-title><source>Biological Psychiatry</source><volume>82</volume><fpage>431</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2017.05.017</pub-id><pub-id pub-id-type="pmid">28651789</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Ciullo</surname><given-names>B</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Badre</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Working memory load strengthens reward prediction errors</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>4332</fpage><lpage>4342</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2700-16.2017</pub-id><pub-id pub-id-type="pmid">28320846</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The tortoise and the hare: interactions between reinforcement learning and working memory</article-title><source>Journal of Cognitive Neuroscience</source><volume>30</volume><fpage>1422</fpage><lpage>1432</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01238</pub-id><pub-id pub-id-type="pmid">29346018</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Within- and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and working memory</article-title><source>PNAS</source><volume>115</volume><fpage>2502</fpage><lpage>2507</lpage><pub-id pub-id-type="doi">10.1073/pnas.1720963115</pub-id><pub-id pub-id-type="pmid">29463751</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reinforcement learning: bringing together computation and cognition</article-title><source>Current Opinion in Behavioral Sciences</source><volume>29</volume><fpage>63</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2019.04.011</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>Clark</surname><given-names>L</given-names></name><name><surname>Owen</surname><given-names>AM</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Defining the neural mechanisms of probabilistic reversal learning using event-related functional magnetic resonance imaging</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>4563</fpage><lpage>4567</lpage><pub-id pub-id-type="pmid">12040063</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cools</surname><given-names>R</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Gibbs</surname><given-names>SE</given-names></name><name><surname>Miyakawa</surname><given-names>A</given-names></name><name><surname>Jagust</surname><given-names>W</given-names></name><name><surname>D’Esposito</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Striatal dopamine predicts outcome-specific reversal learning and its sensitivity to dopaminergic drug administration</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>1538</fpage><lpage>1543</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4467-08.2009</pub-id><pub-id pub-id-type="pmid">19193900</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dabney</surname><given-names>W</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Starkweather</surname><given-names>CK</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Munos</surname><given-names>R</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A distributional code for value in dopamine-based reinforcement learning</article-title><source>Nature</source><volume>577</volume><fpage>671</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1924-6</pub-id><pub-id pub-id-type="pmid">31942076</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidow</surname><given-names>JY</given-names></name><name><surname>Foerde</surname><given-names>K</given-names></name><name><surname>Galván</surname><given-names>A</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An upside to reward sensitivity: the hippocampus supports enhanced reinforcement learning in adolescence</article-title><source>Neuron</source><volume>92</volume><fpage>93</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.031</pub-id><pub-id pub-id-type="pmid">27710793</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2011">2011</year><chapter-title>Trial-by-trial data analysis using computational models</chapter-title><person-group person-group-type="editor"><name><surname>Delgado</surname><given-names>MR</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><source>Decision Making, Affect, and Learning: Attention and Performance XXIII</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name><fpage>3</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1093/acprof:oso/9780199600434.001.0001</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Seymour</surname><given-names>B</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Model-Based influences on humans ’ choices and striatal prediction errors</article-title><source>Neuron</source><volume>69</volume><fpage>1204</fpage><lpage>1215</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.02.027</pub-id><pub-id pub-id-type="pmid">21435563</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Reinforcement learning: the good, the bad and the ugly</article-title><source>Current Opinion in Neurobiology</source><volume>18</volume><fpage>185</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2008.08.003</pub-id><pub-id pub-id-type="pmid">18708140</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decker</surname><given-names>JH</given-names></name><name><surname>Lourenco</surname><given-names>FS</given-names></name><name><surname>Doll</surname><given-names>BB</given-names></name><name><surname>Hartley</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Experiential reward learning outweighs instruction prior to adulthood</article-title><source>Cognitive, Affective &amp; Behavioral Neuroscience</source><volume>15</volume><fpage>310</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.3758/s13415-014-0332-5</pub-id><pub-id pub-id-type="pmid">25582607</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DePasque</surname><given-names>S</given-names></name><name><surname>Galván</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Frontostriatal development and probabilistic reinforcement learning during adolescence</article-title><source>Neurobiology of Learning and Memory</source><volume>143</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2017.04.009</pub-id><pub-id pub-id-type="pmid">28450078</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deserno</surname><given-names>L</given-names></name><name><surname>Boehme</surname><given-names>R</given-names></name><name><surname>Heinz</surname><given-names>A</given-names></name><name><surname>Schlagenhauf</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Reinforcement learning and dopamine in schizophrenia: dimensions of symptoms or specific features of a disease group?</article-title><source>Frontiers in Psychiatry</source><volume>4</volume><elocation-id>172</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyt.2013.00172</pub-id><pub-id pub-id-type="pmid">24391603</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dickstein</surname><given-names>DP</given-names></name><name><surname>Finger</surname><given-names>EC</given-names></name><name><surname>Brotman</surname><given-names>MA</given-names></name><name><surname>Rich</surname><given-names>BA</given-names></name><name><surname>Pine</surname><given-names>DS</given-names></name><name><surname>Blair</surname><given-names>JR</given-names></name><name><surname>Leibenluft</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Impaired probabilistic reversal learning in youths with mood and anxiety disorders</article-title><source>Psychological Medicine</source><volume>40</volume><fpage>1089</fpage><lpage>1100</lpage><pub-id pub-id-type="doi">10.1017/S0033291709991462</pub-id><pub-id pub-id-type="pmid">19818204</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donoso</surname><given-names>M</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Human cognition. Foundations of human Reasoning in the prefrontal cortex</article-title><source>Science</source><volume>344</volume><fpage>1481</fpage><lpage>1486</lpage><pub-id pub-id-type="doi">10.1126/science.1252254</pub-id><pub-id pub-id-type="pmid">24876345</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Computational evidence for hierarchically structured reinforcement learning in humans</article-title><source>PNAS</source><volume>117</volume><fpage>29381</fpage><lpage>29389</lpage><pub-id pub-id-type="doi">10.1073/pnas.1912330117</pub-id><pub-id pub-id-type="pmid">33229518</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>What do reinforcement learning models measure? interpreting model parameters in cognition and neuroscience</article-title><source>Current Opinion in Behavioral Sciences</source><volume>41</volume><fpage>128</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2021.06.004</pub-id><pub-id pub-id-type="pmid">34984213</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>About the SLCN project</data-title><version designator="swh:1:rev:4fb5955c1142fcbd8ec80d7fccdf6b35dbfd1616">swh:1:rev:4fb5955c1142fcbd8ec80d7fccdf6b35dbfd1616</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:2208f3398c0661225348312d6b0915cfd2f59cda;origin=https://github.com/MariaEckstein/SLCN;visit=swh:1:snp:2e353f04cfbb36a541776a2cbcc0ea45eac969a5;anchor=swh:1:rev:4fb5955c1142fcbd8ec80d7fccdf6b35dbfd1616">https://archive.softwareheritage.org/swh:1:dir:2208f3398c0661225348312d6b0915cfd2f59cda;origin=https://github.com/MariaEckstein/SLCN;visit=swh:1:snp:2e353f04cfbb36a541776a2cbcc0ea45eac969a5;anchor=swh:1:rev:4fb5955c1142fcbd8ec80d7fccdf6b35dbfd1616</ext-link></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Master</surname><given-names>SL</given-names></name><name><surname>Dahl</surname><given-names>RE</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Reinforcement learning and Bayesian inference provide complementary models for the unique advantage of adolescents in stochastic reversal</article-title><source>Developmental Cognitive Neuroscience</source><volume>55</volume><elocation-id>101106</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2022.101106</pub-id><pub-id pub-id-type="pmid">35537273</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eisenberg</surname><given-names>IW</given-names></name><name><surname>Bissett</surname><given-names>PG</given-names></name><name><surname>Zeynep Enkavi</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>MacKinnon</surname><given-names>DP</given-names></name><name><surname>Marsch</surname><given-names>LA</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Uncovering the structure of self-regulation through data-driven ontology discovery</article-title><source>Nature Communications</source><volume>10</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41467-019-10301-1</pub-id><pub-id pub-id-type="pmid">31127115</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Seeberger</surname><given-names>LC</given-names></name><name><surname>O’reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title><source>Science</source><volume>306</volume><fpage>1940</fpage><lpage>1943</lpage><pub-id pub-id-type="doi">10.1126/science.1102941</pub-id><pub-id pub-id-type="pmid">15528409</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Claus</surname><given-names>ED</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Anatomy of a decision: striato-orbitofrontal interactions in reinforcement learning, decision making, and reversal</article-title><source>Psychological Review</source><volume>113</volume><fpage>300</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.2.300</pub-id><pub-id pub-id-type="pmid">16637763</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrison</surname><given-names>J</given-names></name><name><surname>Erdeniz</surname><given-names>B</given-names></name><name><surname>Done</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Prediction error in reinforcement learning: a meta-analysis of neuroimaging studies</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>37</volume><fpage>1297</fpage><lpage>1310</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2013.03.023</pub-id><pub-id pub-id-type="pmid">23567522</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A</given-names></name><name><surname>Carlin</surname><given-names>JB</given-names></name><name><surname>Stern</surname><given-names>HS</given-names></name><name><surname>Dunson</surname><given-names>DB</given-names></name><name><surname>Vehtari</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Bayesian Data Analysis</source><publisher-name>Chapman and Hall/CRC, Boca Raton</publisher-name></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Empirical priors for reinforcement learning models</article-title><source>Journal of Mathematical Psychology</source><volume>71</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2016.01.006</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dopamine, inference, and uncertainty</article-title><source>Neural Computation</source><volume>29</volume><fpage>3311</fpage><lpage>3326</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01023</pub-id><pub-id pub-id-type="pmid">28957023</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Believing in dopamine</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>703</fpage><lpage>714</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0220-7</pub-id><pub-id pub-id-type="pmid">31570826</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gläscher</surname><given-names>J</given-names></name><name><surname>Hampton</surname><given-names>AN</given-names></name><name><surname>O’Doherty</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Determining a role for ventromedial prefrontal cortex in encoding action-based value signals during reward-related decision making</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>483</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn098</pub-id><pub-id pub-id-type="pmid">18550593</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glimcher</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Understanding dopamine and reinforcement learning: the dopamine reward prediction error hypothesis</article-title><source>PNAS</source><volume>108 Suppl 3</volume><fpage>15647</fpage><lpage>15654</lpage><pub-id pub-id-type="doi">10.1073/pnas.1014269108</pub-id><pub-id pub-id-type="pmid">21389268</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gopnik</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Childhood as a solution to explore-exploit tensions</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>375</volume><elocation-id>20190502</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2019.0502</pub-id><pub-id pub-id-type="pmid">32475327</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guest</surname><given-names>O</given-names></name><name><surname>Martin</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>How computational modeling can force theory building in psychological science</article-title><source>Perspectives on Psychological Science</source><volume>16</volume><fpage>789</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1177/1745691620970585</pub-id><pub-id pub-id-type="pmid">33482070</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harada</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning from success or failure?-positivity biases revisited</article-title><source>Frontiers in Psychology</source><volume>11</volume><elocation-id>1627</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2020.01627</pub-id><pub-id pub-id-type="pmid">32848998</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hare</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Humans Are Primarily Model-Based Learners in the Two-Stage Task</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/682922</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>TU</given-names></name><name><surname>Will</surname><given-names>GJ</given-names></name><name><surname>Dubois</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Annual research review: developmental computational psychiatry</article-title><source>Journal of Child Psychology and Psychiatry, and Allied Disciplines</source><volume>60</volume><fpage>412</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1111/jcpp.12964</pub-id><pub-id pub-id-type="pmid">30252127</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinz</surname><given-names>A</given-names></name><name><surname>Deserno</surname><given-names>L</given-names></name><name><surname>Zimmermann</surname><given-names>US</given-names></name><name><surname>Smolka</surname><given-names>MN</given-names></name><name><surname>Beck</surname><given-names>A</given-names></name><name><surname>Schlagenhauf</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Targeted intervention: computational approaches to elucidate and predict relapse in alcoholism</article-title><source>NeuroImage</source><volume>151</volume><fpage>33</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.07.055</pub-id><pub-id pub-id-type="pmid">27480622</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huys</surname><given-names>QJM</given-names></name><name><surname>Maia</surname><given-names>TV</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational psychiatry as a bridge from neuroscience to clinical applications</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>404</fpage><lpage>413</lpage><pub-id pub-id-type="doi">10.1038/nn.4238</pub-id><pub-id pub-id-type="pmid">26906507</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izquierdo</surname><given-names>A</given-names></name><name><surname>Brigman</surname><given-names>JL</given-names></name><name><surname>Radke</surname><given-names>AK</given-names></name><name><surname>Rudebeck</surname><given-names>PH</given-names></name><name><surname>Holmes</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The neural basis of reversal learning: an updated perspective</article-title><source>Neuroscience</source><volume>345</volume><fpage>12</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2016.03.021</pub-id><pub-id pub-id-type="pmid">26979052</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Javadi</surname><given-names>AH</given-names></name><name><surname>Schmidt</surname><given-names>DHK</given-names></name><name><surname>Smolka</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adolescents adapt more slowly than adults to varying reward contingencies</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>2670</fpage><lpage>2681</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00677</pub-id><pub-id pub-id-type="pmid">24960048</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>PR</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Rangel-Gomez</surname><given-names>M</given-names></name><name><surname>Meeter</surname><given-names>M</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Catecholaminergic regulation of learning rate in a dynamic environment</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005171</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005171</pub-id><pub-id pub-id-type="pmid">27792728</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>C</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Juvenile mice show greater flexibility in multiple choice reversal learning than adults</article-title><source>Developmental Cognitive Neuroscience</source><volume>1</volume><fpage>540</fpage><lpage>551</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2011.05.008</pub-id><pub-id pub-id-type="pmid">21949556</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katahira</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How hierarchical models improve point estimates of model parameters at the individual level</article-title><source>Journal of Mathematical Psychology</source><volume>73</volume><fpage>37</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2016.03.007</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katahira</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The statistical structures of reinforcement learning with asymmetric value updates</article-title><source>Journal of Mathematical Psychology</source><volume>87</volume><fpage>31</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2018.09.002</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konovalov</surname><given-names>A</given-names></name><name><surname>Krajbich</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neurocomputational dynamics of sequence learning</article-title><source>Neuron</source><volume>98</volume><fpage>1282</fpage><lpage>1293</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.05.013</pub-id><pub-id pub-id-type="pmid">29861282</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kool</surname><given-names>W</given-names></name><name><surname>Cushman</surname><given-names>FA</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>When does model-based control pay off?</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1005090</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005090</pub-id><pub-id pub-id-type="pmid">27564094</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lake</surname><given-names>BM</given-names></name><name><surname>Ullman</surname><given-names>TD</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Building machines that learn and think like people</article-title><source>The Behavioral and Brain Sciences</source><volume>40</volume><elocation-id>e253</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X16001837</pub-id><pub-id pub-id-type="pmid">27881212</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How cognitive modeling can benefit from hierarchical Bayesian models</article-title><source>Journal of Mathematical Psychology</source><volume>55</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2010.08.013</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Seo</surname><given-names>H</given-names></name><name><surname>Jung</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural basis of reinforcement learning and decision making</article-title><source>Annual Review of Neuroscience</source><volume>35</volume><fpage>287</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150512</pub-id><pub-id pub-id-type="pmid">22462543</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lefebvre</surname><given-names>G</given-names></name><name><surname>Lebreton</surname><given-names>M</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Bourgeois-Gironde</surname><given-names>S</given-names></name><name><surname>Palminteri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Behavioural and neural characterization of optimistic reinforcement learning</article-title><source>Nature Human Behaviour</source><volume>1</volume><elocation-id>0067</elocation-id><pub-id pub-id-type="doi">10.1038/s41562-017-0067</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>WC</given-names></name><name><surname>Delevich</surname><given-names>K</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A role for adaptive developmental plasticity in learning and decision making</article-title><source>Current Opinion in Behavioral Sciences</source><volume>36</volume><fpage>48</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.07.010</pub-id><pub-id pub-id-type="pmid">35891805</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>WC</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Kosillo</surname><given-names>P</given-names></name><name><surname>Tai</surname><given-names>LH</given-names></name><name><surname>Galarce</surname><given-names>E</given-names></name><name><surname>Bateup</surname><given-names>HS</given-names></name><name><surname>Lammel</surname><given-names>S</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Transient food insecurity during the juvenile-adolescent period affects adult weight, cognitive flexibility, and dopamine neurobiology</article-title><source>Current Biology</source><volume>32</volume><fpage>3690</fpage><lpage>3703</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2022.06.089</pub-id><pub-id pub-id-type="pmid">35863352</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Hairston</surname><given-names>J</given-names></name><name><surname>Schrier</surname><given-names>M</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Common and distinct networks underlying reward valence and processing stages: a meta-analysis of functional neuroimaging studies</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>35</volume><fpage>1219</fpage><lpage>1236</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2010.12.012</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lourenco</surname><given-names>F</given-names></name><name><surname>Casey</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Adjusting behavior to changing environmental demands with development</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>37</volume><fpage>2233</fpage><lpage>2242</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2013.03.003</pub-id><pub-id pub-id-type="pmid">23518271</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Master</surname><given-names>SL</given-names></name><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Gotlieb</surname><given-names>N</given-names></name><name><surname>Dahl</surname><given-names>R</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Distentangling the systems contributing to changes in learning during adolescence</article-title><source>Developmental Cognitive Neuroscience</source><volume>41</volume><elocation-id>100732</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2019.100732</pub-id><pub-id pub-id-type="pmid">31826837</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDougle</surname><given-names>SD</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Modeling the influence of working memory, reinforcement, and action uncertainty on reaction time and choice during instrumental learning</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>28</volume><fpage>20</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.3758/s13423-020-01774-z</pub-id><pub-id pub-id-type="pmid">32710256</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Functionally dissociable influences on learning rate in a dynamic environment</article-title><source>Neuron</source><volume>84</volume><fpage>870</fpage><lpage>881</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id><pub-id pub-id-type="pmid">25459409</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohebi</surname><given-names>A</given-names></name><name><surname>Pettibone</surname><given-names>JR</given-names></name><name><surname>Hamid</surname><given-names>AA</given-names></name><name><surname>Wong</surname><given-names>JMT</given-names></name><name><surname>Vinson</surname><given-names>LT</given-names></name><name><surname>Patriarchi</surname><given-names>T</given-names></name><name><surname>Tian</surname><given-names>L</given-names></name><name><surname>Kennedy</surname><given-names>RT</given-names></name><name><surname>Berke</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dissociable dopamine dynamics for learning and motivation</article-title><source>Nature</source><volume>570</volume><fpage>65</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1235-y</pub-id><pub-id pub-id-type="pmid">31118513</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moutoussis</surname><given-names>M</given-names></name><name><surname>Garzón</surname><given-names>B</given-names></name><name><surname>Neufeld</surname><given-names>S</given-names></name><name><surname>Bach</surname><given-names>DR</given-names></name><name><surname>Rigoli</surname><given-names>F</given-names></name><name><surname>Goodyer</surname><given-names>I</given-names></name><name><surname>Bullmore</surname><given-names>E</given-names></name><name><surname>Guitart-Masip</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><collab>NSPN Consortium</collab></person-group><year iso-8601-date="2021">2021</year><article-title>Decision-Making ability, psychopathology, and brain connectivity</article-title><source>Neuron</source><volume>109</volume><fpage>2025</fpage><lpage>2040</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.04.019</pub-id><pub-id pub-id-type="pmid">34019810</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Bruckner</surname><given-names>R</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Li</surname><given-names>SC</given-names></name><name><surname>Heekeren</surname><given-names>HR</given-names></name><name><surname>Eppinger</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Age differences in learning emerge from an insufficient representation of uncertainty in older adults</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>11609</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms11609</pub-id><pub-id pub-id-type="pmid">27282467</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Taming the beast: extracting generalizable knowledge from computational models of cognition</article-title><source>Current Opinion in Behavioral Sciences</source><volume>11</volume><fpage>49</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.04.003</pub-id><pub-id pub-id-type="pmid">27574699</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navarro</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Between the devil and the deep blue sea: tensions between scientific judgement and statistical model selection</article-title><source>Computational Brain &amp; Behavior</source><volume>2</volume><fpage>28</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1007/s42113-018-0019-z</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reinforcement learning in the brain</article-title><source>Journal of Mathematical Psychology</source><volume>53</volume><fpage>139</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2008.12.005</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nussenbaum</surname><given-names>K</given-names></name><name><surname>Hartley</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reinforcement learning across development: what insights can we draw from a decade of research?</article-title><source>Developmental Cognitive Neuroscience</source><volume>40</volume><elocation-id>100733</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2019.100733</pub-id><pub-id pub-id-type="pmid">31770715</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Doherty</surname><given-names>J</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Schultz</surname><given-names>J</given-names></name><name><surname>Deichmann</surname><given-names>R</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title><source>Science</source><volume>304</volume><fpage>452</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1126/science.1094285</pub-id><pub-id pub-id-type="pmid">15087550</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Doherty</surname><given-names>JP</given-names></name><name><surname>Lee</surname><given-names>SW</given-names></name><name><surname>McNamee</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The structure of reinforcement-learning mechanisms in the human brain</article-title><source>Current Opinion in Behavioral Sciences</source><volume>1</volume><fpage>94</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2014.10.004</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Kilford</surname><given-names>EJ</given-names></name><name><surname>Coricelli</surname><given-names>G</given-names></name><name><surname>Blakemore</surname><given-names>SJ</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The computational development of reinforcement learning during adolescence</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004953</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004953</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palminteri</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The importance of falsification in computational cognitive modeling</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>425</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.03.011</pub-id><pub-id pub-id-type="pmid">28476348</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Passos</surname><given-names>A</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Brucher</surname><given-names>M</given-names></name><name><surname>Perrot</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>AC</given-names></name><name><surname>Crockett</surname><given-names>L</given-names></name><name><surname>Richards</surname><given-names>M</given-names></name><name><surname>Boxer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>A self-report measure of pubertal status: reliability, validity, and initial norms</article-title><source>Journal of Youth and Adolescence</source><volume>17</volume><fpage>117</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1007/BF01537962</pub-id><pub-id pub-id-type="pmid">24277579</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peterson</surname><given-names>DA</given-names></name><name><surname>Elliott</surname><given-names>C</given-names></name><name><surname>Song</surname><given-names>DD</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name><name><surname>Poizner</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Probabilistic reversal learning is impaired in Parkinson ’ S disease</article-title><source>Neuroscience</source><volume>163</volume><fpage>1092</fpage><lpage>1101</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2009.07.033</pub-id><pub-id pub-id-type="pmid">19628022</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pratt</surname><given-names>DN</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Carter</surname><given-names>CS</given-names></name><name><surname>Gold</surname><given-names>JM</given-names></name><name><surname>Ragland</surname><given-names>JD</given-names></name><name><surname>Silverstein</surname><given-names>SM</given-names></name><name><surname>MacDonald</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Reliability and replicability of implicit and explicit reinforcement learning paradigms in people with psychotic disorders</article-title><source>Schizophrenia Bulletin</source><volume>47</volume><fpage>731</fpage><lpage>739</lpage><pub-id pub-id-type="doi">10.1093/schbul/sbaa165</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radulescu</surname><given-names>A</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Ballard</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Holistic reinforcement learning: the role of structure and attention</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>278</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.01.010</pub-id><pub-id pub-id-type="pmid">30824227</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ribas-Fernandes</surname><given-names>JJF</given-names></name><name><surname>Solway</surname><given-names>A</given-names></name><name><surname>Diuk</surname><given-names>C</given-names></name><name><surname>McGuire</surname><given-names>JT</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A neural signature of hierarchical reinforcement learning</article-title><source>Neuron</source><volume>71</volume><fpage>370</fpage><lpage>379</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.042</pub-id><pub-id pub-id-type="pmid">21791294</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname><given-names>OJ</given-names></name><name><surname>Chase</surname><given-names>HW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Learning and choice in mood disorders: searching for the computational parameters of anhedonia</article-title><source>Computational Psychiatry</source><volume>1</volume><fpage>208</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1162/CPSY_a_00009</pub-id><pub-id pub-id-type="pmid">29400358</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Rosenbaum</surname><given-names>G</given-names></name><name><surname>Grassie</surname><given-names>H</given-names></name><name><surname>Hartley</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Valence Biases in Reinforcement Learning Shift across Adolescence and Modulate Subsequent Memory</article-title><source>PsyArXiv</source><ext-link ext-link-type="uri" xlink:href="https://psyarxiv.com/n3vsr/">https://psyarxiv.com/n3vsr/</ext-link></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Montague</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>A neural substrate of prediction and reward</article-title><source>Science</source><volume>275</volume><fpage>1593</fpage><lpage>1599</lpage><pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id><pub-id pub-id-type="pmid">9054347</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schultz</surname><given-names>W</given-names></name><name><surname>Dickinson</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neuronal coding of prediction errors</article-title><source>Annual Review of Neuroscience</source><volume>23</volume><fpage>473</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.473</pub-id><pub-id pub-id-type="pmid">10845072</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sendhilnathan</surname><given-names>N</given-names></name><name><surname>Semework</surname><given-names>M</given-names></name><name><surname>Goldberg</surname><given-names>ME</given-names></name><name><surname>Ipata</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural correlates of reinforcement learning in mid-lateral cerebellum</article-title><source>Neuron</source><volume>106</volume><fpage>188</fpage><lpage>198</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.12.032</pub-id><pub-id pub-id-type="pmid">32001108</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shahar</surname><given-names>N</given-names></name><name><surname>Hauser</surname><given-names>TU</given-names></name><name><surname>Moutoussis</surname><given-names>M</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Keramati</surname><given-names>M</given-names></name><name><surname>Consortium</surname><given-names>N</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Improving the reliability of model-based decision-making estimates in the two-stage decision task with reaction-times and drift-diffusion modeling</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006803</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006803</pub-id><pub-id pub-id-type="pmid">30759077</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Somerville</surname><given-names>LH</given-names></name><name><surname>Sasse</surname><given-names>SF</given-names></name><name><surname>Garrad</surname><given-names>MC</given-names></name><name><surname>Drysdale</surname><given-names>AT</given-names></name><name><surname>Abi Akar</surname><given-names>N</given-names></name><name><surname>Insel</surname><given-names>C</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Charting the expansion of strategic exploratory behavior during adolescence</article-title><source>Journal of Experimental Psychology. General</source><volume>146</volume><fpage>155</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1037/xge0000250</pub-id><pub-id pub-id-type="pmid">27977227</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Starkweather</surname><given-names>CK</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The medial prefrontal cortex shapes dopamine reward prediction errors under state uncertainty</article-title><source>Neuron</source><volume>98</volume><fpage>616</fpage><lpage>629</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.036</pub-id><pub-id pub-id-type="pmid">29656872</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugawara</surname><given-names>M</given-names></name><name><surname>Katahira</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dissociation between asymmetric value updating and perseverance in human reinforcement learning</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>3574</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-80593-7</pub-id><pub-id pub-id-type="pmid">33574424</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name><name><surname>Barto</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2017">2017</year><source>Reinforcement Learning: An Introduction</source><edition>2nd Edition</edition><publisher-loc>Cambridge, MA; London, England</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swainson</surname><given-names>R</given-names></name><name><surname>Rogers</surname><given-names>RD</given-names></name><name><surname>Sahakian</surname><given-names>BJ</given-names></name><name><surname>Summers</surname><given-names>BA</given-names></name><name><surname>Polkey</surname><given-names>CE</given-names></name><name><surname>Robbins</surname><given-names>TW</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Probabilistic learning and reversal deficits in patients with Parkinson ’ S disease or frontal or temporal lobe lesions: possible adverse effects of dopaminergic medication</article-title><source>Neuropsychologia</source><volume>38</volume><fpage>596</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.1016/s0028-3932(99)00103-7</pub-id><pub-id pub-id-type="pmid">10689037</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tai</surname><given-names>LH</given-names></name><name><surname>Lee</surname><given-names>AM</given-names></name><name><surname>Benavidez</surname><given-names>N</given-names></name><name><surname>Bonci</surname><given-names>A</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Transient stimulation of distinct subpopulations of striatal neurons mimics changes in action value</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/nn.3188</pub-id><pub-id pub-id-type="pmid">22902719</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uttal</surname><given-names>WR</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>On some two-way barriers between models and mechanisms</article-title><source>Perception &amp; Psychophysics</source><volume>48</volume><fpage>188</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.3758/bf03207086</pub-id><pub-id pub-id-type="pmid">2201003</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Bos</surname><given-names>W</given-names></name><name><surname>Cohen</surname><given-names>MX</given-names></name><name><surname>Kahnt</surname><given-names>T</given-names></name><name><surname>Crone</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Striatum-medial prefrontal cortex connectivity predicts developmental changes in reinforcement learning</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>1247</fpage><lpage>1255</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr198</pub-id><pub-id pub-id-type="pmid">21817091</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van den Bos</surname><given-names>W</given-names></name><name><surname>Bruckner</surname><given-names>R</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Mata</surname><given-names>R</given-names></name><name><surname>Eppinger</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Computational neuroscience across the lifespan: promises and pitfalls</article-title><source>Developmental Cognitive Neuroscience</source><volume>33</volume><fpage>42</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2017.09.008</pub-id><pub-id pub-id-type="pmid">29066078</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Schaaf</surname><given-names>ME</given-names></name><name><surname>Warmerdam</surname><given-names>E</given-names></name><name><surname>Crone</surname><given-names>EA</given-names></name><name><surname>Cools</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Distinct linear and non-linear trajectories of reward and punishment reversal learning during development: relevance for dopamine ’ S role in adolescent decision making</article-title><source>Developmental Cognitive Neuroscience</source><volume>1</volume><fpage>578</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2011.06.007</pub-id><pub-id pub-id-type="pmid">22436570</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vikbladh</surname><given-names>OM</given-names></name><name><surname>Meager</surname><given-names>MR</given-names></name><name><surname>King</surname><given-names>J</given-names></name><name><surname>Blackmon</surname><given-names>K</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hippocampal contributions to model-based planning and spatial memory</article-title><source>Neuron</source><volume>102</volume><fpage>683</fpage><lpage>693</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.02.014</pub-id><pub-id pub-id-type="pmid">30871859</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waltmann</surname><given-names>M</given-names></name><name><surname>Schlagenhauf</surname><given-names>F</given-names></name><name><surname>Deserno</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Sufficient reliability of the behavioral and computational readouts of a probabilistic reversal learning task</article-title><source>Behavior Research Methods</source><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.3758/s13428-021-01739-7</pub-id><pub-id pub-id-type="pmid">35167111</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waltz</surname><given-names>JA</given-names></name><name><surname>Gold</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Probabilistic reversal learning impairments in schizophrenia: further evidence of orbitofrontal dysfunction</article-title><source>Schizophrenia Research</source><volume>93</volume><fpage>296</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1016/j.schres.2007.03.010</pub-id><pub-id pub-id-type="pmid">17482797</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>JX</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>Tirumala</surname><given-names>D</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Botvinick</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prefrontal cortex as a meta-reinforcement learning system</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>860</fpage><lpage>868</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0147-8</pub-id><pub-id pub-id-type="pmid">29760527</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A widely applicable Bayesian information criterion</article-title><source>Journal of Machine Learning Research</source><volume>14</volume><fpage>867</fpage><lpage>897</lpage></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Webb</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Can robots make good models of biological behaviour?</article-title><source>The Behavioral and Brain Sciences</source><volume>24</volume><fpage>1033</fpage><lpage>1050</lpage><pub-id pub-id-type="doi">10.1017/s0140525x01000127</pub-id><pub-id pub-id-type="pmid">12412325</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Weidinger</surname><given-names>L</given-names></name><name><surname>Gradassi</surname><given-names>A</given-names></name><name><surname>Molleman</surname><given-names>L</given-names></name><name><surname>van den Bos</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Test-retest reliability of canonical reinforcement learning models</article-title><conf-name>2019 Conference on Cognitive Computational Neuroscience</conf-name><pub-id pub-id-type="doi">10.32470/CCN.2019.1053-0</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Werchan</surname><given-names>DM</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Amso</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Role of prefrontal cortex in learning and generalizing hierarchical rules in 8-month-old infants</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>10314</fpage><lpage>10322</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1351-16.2016</pub-id><pub-id pub-id-type="pmid">27707968</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Collins</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Ten simple rules for the computational modeling of behavioral data</article-title><source>eLife</source><volume>8</volume><elocation-id>e49547</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.49547</pub-id><pub-id pub-id-type="pmid">31769410</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>L</given-names></name><name><surname>Master</surname><given-names>SL</given-names></name><name><surname>Eckstein</surname><given-names>MK</given-names></name><name><surname>Baribault</surname><given-names>B</given-names></name><name><surname>Dahl</surname><given-names>RE</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>AGE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Modeling changes in probabilistic reinforcement learning during adolescence</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008524</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008524</pub-id><pub-id pub-id-type="pmid">34197447</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yaple</surname><given-names>ZA</given-names></name><name><surname>Yu</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fractionating adaptive learning: a meta-analysis of the reversal learning paradigm</article-title><source>Neuroscience and Biobehavioral Reviews</source><volume>102</volume><fpage>85</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2019.04.006</pub-id><pub-id pub-id-type="pmid">31004627</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarkoni</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The generalizability crisis</article-title><source>The Behavioral and Brain Sciences</source><volume>45</volume><elocation-id>e1</elocation-id><pub-id pub-id-type="doi">10.1017/S0140525X20001685</pub-id><pub-id pub-id-type="pmid">33342451</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Behavioral measures</title><p>In addition to RL model parameters, we also extracted behavioral features from each of the three tasks, conducted regression analyses, and in one case fitted a non-RL computational model. The resulting features of these analyses were used in the PCA (sections Main axes of variation and principal component analysis (PCA); <xref ref-type="fig" rid="fig3">Figure 3</xref>; <xref ref-type="fig" rid="app8fig4">Appendix 8—figure 4</xref>), behavioral Ridge regression (sections Parameters and behavior and ridge regression), and comprehensive correlation matrix (<xref ref-type="fig" rid="app8fig3">Appendix 8—figure 3</xref>). The following list details these features, using the labels in <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="app8fig4">Appendix 8—figure 4</xref>, and <xref ref-type="fig" rid="app8fig3">Appendix 8—figure 3</xref> to denote each feature:</p><list list-type="bullet"><list-item><p>Basic performance measures</p><list list-type="simple"><list-item><p>‘Missed trials’ (percentage of missed trials)</p></list-item><list-item><p>‘Response times’ (average response times on correct trials)</p></list-item><list-item><p>‘Response time variability’ (standard deviation of response times on correct trials)</p></list-item><list-item><p>‘Percent correct’ (accuracy; overall percentage of correct trials)</p></list-item></list></list-item><list-item><p>Advanced performance measures</p><list list-type="simple"><list-item><p>‘Acc. first 3 trials’ (only for task A; average accuracy on the first three trials of each stimulus; a measure of initial learning)</p></list-item><list-item><p>‘Asymptotic acc.’ (only for task A; an exponential curve was fit to the learning curve of each subject. The functional form was: <inline-formula><mml:math id="inf348"><mml:mrow><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>+</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>*</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf349"><mml:mi>t</mml:mi></mml:math></inline-formula> is trial number. <inline-formula><mml:math id="inf350"><mml:mi>a</mml:mi></mml:math></inline-formula> is bounded <inline-formula><mml:math id="inf351"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf352"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. This feature refers to the asymptote of the curve: <inline-formula><mml:math id="inf353"><mml:mrow><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>+</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>*</mml:mo><mml:mi>e</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf354"><mml:mi>T</mml:mi></mml:math></inline-formula> is total number of trials completed by the subject)</p></list-item><list-item><p>‘Learning slope’ (only for task A; this feature refers to the slope <inline-formula><mml:math id="inf355"><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the model above)</p></list-item><list-item><p>‘Acc. intercept’ (only for task A; hierarchical regression was fit to predict the probability of a correct choice on each trial. The regression formula was <inline-formula><mml:math id="inf356"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo rspace="5.8pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf357"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="normal">…</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> indicates random effects by subject id. This feature refers to the random intercept for each subject)</p></list-item><list-item><p>‘Reward effect on acc.’ (in the same regression model, this feature refers to the random slope for the reward history predictor, which is the z-scored number of correct trials for each butterfly)</p></list-item><list-item><p>‘Delay’ (only tasks A and C; in the same [or an equivalent] regression model, this feature refers to the random slope for the delay predictor, which is the z-scored number of trials since last time the same stimulus was seen and the participant chose the correct action)</p></list-item><list-item><p>‘Number of switches’ (only for task B; the number of task switches experienced by each participant; because the occurrence of switches was based on performance, the number of switches is an additional criterion of task performance)</p></list-item><list-item><p>‘Criterion after switch’ (only for task B; number of trials after a task switch until participants reached a performance criterion of 2 correct choices after the task switch)</p></list-item><list-item><p>‘Acc. late minus early’ (only for task B; difference in accuracy between the first and last third of trials in the task, as a measure of ‘slow’ learning)</p></list-item></list></list-item><list-item><p>Action repetition</p><list list-type="simple"><list-item><p>‘Stay (choice)’ (for tasks A and C; percentage of choices that were repeated with respect to each stimulus, averaged across stimuli)</p></list-item><list-item><p>‘Stay (motor)’ (for tasks A and C; percentage of choices that were repeated between two subsequent trials, irrespective of the shown stimulus)</p></list-item><list-item><p>‘Stay (both)’ (for task B; because the task only provided a single stimulus, stay-choice and stay-motor were identical)</p></list-item><list-item><p>‘Win-stay’ (Fraction of trials in which participants repeated a choice for a given stimulus that was rewarded on the previous trial for that stimulus, normalized by number of win trials, and averaged over stimuli: <inline-formula><mml:math id="inf358"><mml:mfrac><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>n</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>n</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>n</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math></inline-formula>)</p></list-item><list-item><p>‘Win-lose-stay’ (for task B only; fraction of trials in which participants repeated a choice that was rewarded two trials back, but not rewarded on the previous trial, normalized by number of win-lose trials)</p></list-item><list-item><p>‘Lose-stay’ (Fraction of trials in which participants repeated a choice for a given stimulus that was not rewarded on the previous trial for that stimulus, normalized by number of lose trials, and averaged over stimuli: <inline-formula><mml:math id="inf359"><mml:mfrac><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>e</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>e</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>e</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mfrac></mml:math></inline-formula>)</p></list-item></list></list-item><list-item><p>Bayesian model parameters (task B only)</p><list list-type="simple"><list-item><p>‘<inline-formula><mml:math id="inf360"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> param.’ (a Bayesian inference model was fit in addition to the RL model. The Bayesian model employed a mental model of the task, which was based on two hidden states ‘Left is correct’ and ‘Right is correct’, and used Bayesian inference to infer the current hidden state based on recent outcomes. The free parameters of this model were the task parameters of the mental model, switch probability on each trial <inline-formula><mml:math id="inf361"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and probability of reward for a correct choice <inline-formula><mml:math id="inf362"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, choice parameters Persistence <inline-formula><mml:math id="inf363"><mml:mi>P</mml:mi></mml:math></inline-formula> and inverse decision temperature <inline-formula><mml:math id="inf364"><mml:mi>β</mml:mi></mml:math></inline-formula>. Detailed information about this model is provided in <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>. This feature refers to model parameter <inline-formula><mml:math id="inf365"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.)</p></list-item><list-item><p>‘<inline-formula><mml:math id="inf366"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> param.’ (parameter <inline-formula><mml:math id="inf367"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the Bayesian model)</p></list-item></list></list-item><list-item><p>Behavioral measures of working memory (task C only)</p><list list-type="simple"><list-item><p>‘Set size effect on acc.’ (a logistic regression was fitted to choice data, assessing the effects of set size, delay, number of previous correct trials, and number of previous incorrect trials on choice accuracy; this feature refers to the effect of set size)</p></list-item><list-item><p>‘Feature <inline-formula><mml:math id="inf368"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>’ (this features refers to the effect of the number of previous correct trials)</p></list-item><list-item><p>‘Feature <inline-formula><mml:math id="inf369"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>’ (this features refers to the effect of the number of previous incorrect trials)</p></list-item><list-item><p>‘Set size Acc. slope’ (performance was averaged for blocks of each set size, and the slope in performance over set sizes was determined)</p></list-item><list-item><p>‘Set size Acc. slope’ (similar to the previous feature, but replacing performance with response times)</p></list-item></list></list-item></list> </sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Task descriptions in the Markov decision process (MDP) framework</title><p>In order to enhance theoretical consistency between RL studies in the psychological literature, one step is the use of a common framework to describe and design laboratory tasks. One such framework is the MDP. Table <xref ref-type="table" rid="app2table1">Appendix 2—table 1</xref> shows our three tasks in terms of this frameworks, and complements <xref ref-type="fig" rid="fig1">Figure 1E</xref>.</p><table-wrap id="app2table1" position="float"><label>Appendix 2—table 1.</label><caption><title>Task descriptions in the Markov decision process framework.</title><p>POMDP: Partially-observable Markov Decision Process. ‘Pos. stochastic’: positive outcomes are delivered stochastically. ‘Neg. deterministic’: negative outcomes are delivered deterministically.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom">Number of States</th><th align="left" valign="bottom">Number of Actions</th><th align="left" valign="bottom">Reward function</th></tr></thead><tbody><tr><td align="left" valign="bottom">Task A</td><td align="char" char="." valign="bottom">4 (1 per trial)</td><td align="left" valign="bottom">2 (visible on screen)</td><td align="left" valign="bottom">Stable, stochastic</td></tr><tr><td align="left" valign="bottom">Task B</td><td align="left" valign="bottom">Stateless / POMDP</td><td align="left" valign="bottom">2 (visible on screen)</td><td align="left" valign="bottom">Volatile, pos. stochastic, neg. deterministic</td></tr><tr><td align="left" valign="bottom">Task C</td><td align="char" char="." valign="bottom">2/3/4/5 (1 per trial)</td><td align="char" char="." valign="bottom">3 (not visible)</td><td align="left" valign="bottom">Stable, deterministic</td></tr></tbody></table></table-wrap></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Previous results</title><fig id="app3fig1" position="float"><label>Appendix 3—figure 1.</label><caption><title>Main results of tasks A, B, and C.</title><p>(<bold>A</bold>) Top: In task A, performance increased with age and plateaued in early adulthood, as captured in decreases in decision temperature <inline-formula><mml:math id="inf370"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> and increases in learning rate <inline-formula><mml:math id="inf371"><mml:mi>α</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). Performance also increased over task time (blocks). Middle: In task B, performance showed a remarkable inverse U-shaped age trajectory: Performance increased markedly from early childhood (8–10 years) to mid-adolescence (13-15), but decreased in late adolescence (15-17) and adulthood (18-30) (<xref ref-type="bibr" rid="bib93">Rosenbaum et al., 2020</xref>). Bottom: Task C showed that the effect of set size on performance (regression coefficient) decreased with age, which was captured by increases in RL learning rate, but stable WM limitations (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>). (<bold>B</bold>) Main behavioral features over age; colors denote task; all features are z-scored. Some measures (e.g. response times [RT], win-stay choices) were consistent across tasks, while others (e.g. accuracy [Acc.], lose-stay choices) showed significant differences (see Table <xref ref-type="table" rid="app6table1">Appendix 6—table 1</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-app3-fig1-v1.tif"/></fig><p>Each task was first analyzed independently, and detailed results have been presented elsewhere (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>). We summarize the key results here. In task A, participants saw one of four butterflies on each trial, and aimed to pick the one of two flowers that was preferred by this butterfly. Each butterfly had a stable preference for one flower, and participants received a stochastic reward (80% probability) when they chose this flower. Nevertheless, sometimes the butterfly liked the opposite flower, and participants got a reward with 20% when they chose the opposite flower (<xref ref-type="fig" rid="fig1">Figure 1B</xref>; section Testing procedure). Task A has been used previously to investigate the role of reward sensitivity and its interplay with episodic memory, shedding light on the neural substrate of these processes, notably the striatum and hippocampus, and revealing a unique role of adolescence in stochastic learning (<xref ref-type="bibr" rid="bib26">Davidow et al., 2016</xref>). In our sample, performance on task A increased with age through the early-twenties and then stabilized (<xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>; <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1A</xref>). Using hierarchical Bayesian methods to fit RL models, we showed that this performance increase was driven by increasing positive learning rate <inline-formula><mml:math id="inf372"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> and decreasing decision noise <inline-formula><mml:math id="inf373"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula>. Forgetting rates decreased very slightly with age, and negative learning rate <inline-formula><mml:math id="inf374"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> was 0, suggesting that participants ignored negative outcomes (<xref ref-type="fig" rid="fig2">Figure 2A and C</xref>).</p><p>In task B, participants saw two boxes and selected one on each trial, with the goal of collecting gold coins. For some period of time, one box was correct and led to a stochastic reward (75% probability), while the other was unrewarded (0% probability). Then, the contingencies switched unpredictably and unsignaled, and the opposite box became the correct one. A 120-trials session contained 2–7 switches (<xref ref-type="fig" rid="fig1">Figure 1C</xref>; section Testing procedure). Task B was adapted from the rodent literature, where it has been used to show a causal link between stimulation of striatal spiny projection neurons and subsequent choices (<xref ref-type="bibr" rid="bib103">Tai et al., 2012</xref>). Stochastic reversal tasks are also common in the human literature (<xref ref-type="bibr" rid="bib88">Peterson et al., 2009</xref>; <xref ref-type="bibr" rid="bib102">Swainson et al., 2000</xref>; <xref ref-type="bibr" rid="bib107">van der Schaaf et al., 2011</xref>; <xref ref-type="bibr" rid="bib110">Waltz and Gold, 2007</xref>; <xref ref-type="bibr" rid="bib33">Dickstein et al., 2010</xref>; <xref ref-type="bibr" rid="bib23">Cools et al., 2002</xref>; <xref ref-type="bibr" rid="bib24">Cools et al., 2009</xref>; <xref ref-type="bibr" rid="bib71">Lourenco and Casey, 2013</xref>; <xref ref-type="bibr" rid="bib56">Izquierdo et al., 2017</xref>). A notable feature of our task compared to others is the deterministic feedback for incorrect choices. In our study, we found that human youth age 13–15 years markedly outperformed younger youth (8-12), older youth (16-17), and even young adults (18-30), suggesting that adolescent brains might be specifically adapted to perform well in the stochastic and volatile environment of task B. Computational modeling, using hierarchical Bayesian fitting, revealed that some model parameters (e.g. decision temperature <inline-formula><mml:math id="inf375"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula>, Persistence) increased monotonically from childhood to adulthood, whereas others (e.g. learning rate for negative feedback <inline-formula><mml:math id="inf376"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, Bayesian inference parameters <inline-formula><mml:math id="inf377"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf378"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) showed pronounced U-shapes with peaks in 13-to-15-year-olds, similar to performance. Blending RL and a Bayesian inference models using PCA revealed that adolescents operated at a sweet spot that combined mature levels of task performance with child-like, short time scales of learning, and provided an explanation for adolescents’ superior performance (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>).</p><p>Task C was designed to dissociate the effects of RL and working memory, and has been used in diverse samples of adult participants (<xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>; <xref ref-type="bibr" rid="bib19">Collins et al., 2017b</xref>; <xref ref-type="bibr" rid="bib54">Heinz et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Collins et al., 2017a</xref>; <xref ref-type="bibr" rid="bib21">Collins and Frank, 2018</xref>; <xref ref-type="bibr" rid="bib20">Collins, 2018</xref>; <xref ref-type="bibr" rid="bib105">van den Bos et al., 2012</xref>), but this study was the first to test it in a developmental samples (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>). In this task, participants saw one stimulus at a time (e.g. bee) and chose one of three actions in response (left, up, right; <xref ref-type="fig" rid="fig1">Figure 1D</xref>, right). Feedback was deterministic, that is, reliably identified each action as correct or incorrect. The goal of task C was to learn the correct response for each stimulus. The key feature of the task is that stimuli appear in independent blocks of different sizes, ranging from 2 to 5 stimuli (e.g. the bee could be presented in a block containing just 1 other animal, or up to 4 other animals). As set sizes increase, participants have been shown to shift the balance between using their capacity-limited, but reliable working memory system, to using their unlimited, but slower RL system (<xref ref-type="bibr" rid="bib15">Collins and Frank, 2012</xref>). Task C estimates both memory systems, RL as well as working memory. We found that participants aged 8–12 learned slower than participants aged 13–17, and were more sensitive to set size (<xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1A</xref>). Computational modeling revealed that developmental changes in RL were more protracted than changes in working memory: RL learning rate <inline-formula><mml:math id="inf379"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> increased until age 18, whereas WM parameters showed weaker and more subtle changes early in adolescence (<xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>).</p></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>Computational model validation</title><p>This section provides more information on the set of computational models compared in each task and validates the claim that the models employed in the current study are the best-fitting models, and provide comparably good fit to each respective task.</p><p><xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref> shows human and simulated model behavior side-by-side for each of the three tasks. Specifically, the figure shows the human behavior we observed in the current study, as well as the simulated behavior of the winning model of each task for artificial agents, each of which used the fitted parameters of a particular human participant. The fact that in each case, human behavior is approximated closely by model simulations validates the claim that the models we have chosen as the winning models explain human behavior adequately, and other models are not expected to perform qualitatively better.</p><p>To arrive at this conclusion, several competing models were compared in each study: In task A, the following six models were compared: Classic RL (<inline-formula><mml:math id="inf380"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>); RL with asymmetric learning rates (<inline-formula><mml:math id="inf381"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>); Asymmetric RL with <inline-formula><mml:math id="inf382"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (<inline-formula><mml:math id="inf383"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>); RL with forgetting (<inline-formula><mml:math id="inf384"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>β</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>), Asymmetric RL with forgetting (<inline-formula><mml:math id="inf385"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula>); and Asymmetric RL with <inline-formula><mml:math id="inf386"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and forgetting (<inline-formula><mml:math id="inf387"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:math></inline-formula>).</p><p>In task B, final comparison involved seven models with increasing complexity (the order of adding free parameters was determined in pre-analyses): Classic RL (<inline-formula><mml:math id="inf388"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>); RL with counterfactual updating (<inline-formula><mml:math id="inf389"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>, counterfactual <inline-formula><mml:math id="inf390"><mml:mi>α</mml:mi></mml:math></inline-formula>); RL with counterfactual updating and perseverance (<inline-formula><mml:math id="inf391"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>, counterfactual <inline-formula><mml:math id="inf392"><mml:mi>α</mml:mi></mml:math></inline-formula>, perseverance); RL with perseverance, separate learning from positive versus negative outcomes, and counterfactual updating for positive outcomes (<inline-formula><mml:math id="inf393"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>, counterfactual <inline-formula><mml:math id="inf394"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, perseverance, <inline-formula><mml:math id="inf395"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>); RL with perseverance, separate learning from positive versus negative outcomes, and counterfactual updating for positive and negative outcomes (<inline-formula><mml:math id="inf396"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>, counterfactual <inline-formula><mml:math id="inf397"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, perseverance, <inline-formula><mml:math id="inf398"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, counterfactual <inline-formula><mml:math id="inf399"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>); winning, simplified 4-parameter RL model with perseverance and separate learning rates for positive versus negative outcomes, which are identical to the respective counterfactual updating rates (<inline-formula><mml:math id="inf400"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> = counterfactual <inline-formula><mml:math id="inf401"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf402"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> = counterfactual <inline-formula><mml:math id="inf403"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf404"><mml:mi>β</mml:mi></mml:math></inline-formula>, perseverance).</p><p>In task C, model comparison involved six competing models: Classic RL (<inline-formula><mml:math id="inf405"><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula>), RL with undirected noise, RL with positive learning bias, RL with forgetting, RL with 4 learning rates, and the winning RL model with working memory (”RLWM”).</p><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>Behavioral validation of the winning model for each task.</title><p>(<bold>A</bold>) Task A. The left figure shows performance (y-axis; probability of correct choice) over time on the task (x-axis; trial number). The right figure shows the average performance for each age group (in years). Red indicates human data, and blue indicates simulations from the winning model, based on best-fitting parameters. The close match between the red and blue datapoints indicates good model fit. (<bold>A</bold>) is reproduced from Figure 2 from <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>. (<bold>B</bold>) Task B. The top figure shows performance (y-axis; percentage of correct choices) aligned to switch trials (x-axis; i.e., trial on which the correct box switches sides), separately for male and female participants. The bottom figure shows another behavioral measures, the probability of repeating the same choice (y-axis; ‘% stay’) based on the previous outcome history (x-axis; ‘+ +’: two rewards in a row; ‘- +’: no reward followed by reward; etc.), separately for male and female participants. Colors indicate participant age. The columnwise panels compare human behavior (left) to simulated behavior of the winning RL model (right). The close correspondence between human and simulated model behavior indicates good model fit. (<bold>B</bold>) is reproduced from Figure 4 from <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>. (<bold>C</bold>) Task C. Each figure shows human performance (y-axis; percentage of correct trials) over time (x-axis; number of trials for each stimulus), with colors differentiating age groups. The two rows show blocks of different set sizes (top: set size of two stimuli per block; bottom: set size of five). The left two figures show human behavior, the right two show model simulations. (<bold>C</bold>) is reproduced from Figure 3C from <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-app4-fig1-v1.tif"/><permissions><copyright-statement>© 2022, Eckstein et al.</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Eckstein et al</copyright-holder><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>Appendix 4- Figure 1B is reproduced from Figure 4 from <xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>. The image is published under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 license</ext-link>.</license-p></license></permissions><permissions><copyright-statement>© 2020, Master et al.</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Master et al</copyright-holder><license><ali:license_ref>https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>Appendix 4 - Figure 1C is reproduced from Figure 3C from <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>. The image is published under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0 license</ext-link>.</license-p></license></permissions></fig></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s12"><title>Comparison of human parameter generalization to ceiling</title><p>Section Statistical comparison to generalizability ceiling describes the results of our analysis comparing humans to simulated agents with perfect generalization. This section provides additional methodological detail.</p><p>We each to create an agent population that was maximally similar to the human population, in order to obtain a ceiling of generalizability that was as realistic as possible for the current study. To this aim, we created simulated agents in the following way: We first obtained age trajectories for each parameter (<inline-formula><mml:math id="inf406"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf407"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf408"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> / <inline-formula><mml:math id="inf409"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula>, forget) by averaging human z-scored parameter values across tasks (e.g. for <inline-formula><mml:math id="inf410"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, averaging z-scored values of <inline-formula><mml:math id="inf411"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> across tasks B and C). We then obtained task-specific parameter values by ‘un-z-scoring’ these age trajectories: <inline-formula><mml:math id="inf412"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow><mml:mo>*</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. This operation projects the shared parameter age trajectory of a parameter into the appropriate scale for each task. We chose this approach instead of averaging raw parameter values across tasks because the scale of each parameter differed so much between tasks (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) that simulated behavior would hardly be interpretable outside this range.</p><p>For analyses, the same exact methods were used as for humans when fitting parameters (section Computational models), visualizing age trajectories (Fig. <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1A</xref> and <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1B</xref>), and performing statistical tests (ANOVA: <xref ref-type="table" rid="app5table1">Appendix 5—table 1</xref>; regression models: Tables <xref ref-type="table" rid="app5table2">Appendix 5—table 2</xref>, <xref ref-type="table" rid="app5table3">Appendix 5—table 3</xref>, and <xref ref-type="table" rid="app5table4">Appendix 5—table 4</xref>).</p><p>To statistically compare human results to the ceiling obtained from the simulated sample, we performed a bootstrapped correlation analysis: We first calculated the raw Spearman correlation scores between each pair of tasks for each parameter (e.g. <inline-formula><mml:math id="inf413"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> task A <inline-formula><mml:math id="inf414"><mml:mo>↔</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> task B; <inline-formula><mml:math id="inf415"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> task A <inline-formula><mml:math id="inf416"><mml:mo>↔</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> task C; <inline-formula><mml:math id="inf417"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> task B <inline-formula><mml:math id="inf418"><mml:mo>↔</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> task C), for both the human and simulated sample (dots in Fig. <xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1C</xref>). We then calculated 95% confidence intervals for each correlation coefficient using bootstrapping, using the ‘BCa’ (reverse of the bias-corrected and accelerated bootstrap confidence interval) method of python’s scipy package, with 1000 bootstrap samples per correlation coefficient. To determine whether there was a significant difference between humans and simulations, we determined whether the human correlation coefficient was within the 95% confidence interval of the simulated sample. This corresponds to a two-sided rejection criterion of <inline-formula><mml:math id="inf419"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>.</p><fig id="app5fig1" position="float"><label>Appendix 5—figure 1.</label><caption><title>Comparison of human parameter correlations to generalization ceiling.</title><p>(<bold>A–B</bold>) Same as <xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, but for simulated agents with perfect generalization, rather than humans. (<bold>C</bold>) Parameter correlations (dots) for each pair of tasks (x-axis), with bootstrapped 95% confidence intervals (error bars). Stars indicate significance at the level of <inline-formula><mml:math id="inf420"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>, that is, the human correlation coefficient is not contained within the confidence interval of the corresponding simulated correlation coefficient.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-app5-fig1-v1.tif"/></fig><table-wrap id="app5table1" position="float"><label>Appendix 5—table 1.</label><caption><title>Same as <xref ref-type="table" rid="table1">Table 1</xref>, but for simulated agents with perfect generalization, rather than humans.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Model</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom">F / t</th><th align="left" valign="bottom">df</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf421"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula></th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf422"><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac></mml:math></inline-formula></td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">A, B</td><td align="char" char="." valign="bottom">2629</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf423"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs B</td><td align="char" char="." valign="bottom">49</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf424"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf425"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">A, B, C</td><td align="char" char="." valign="bottom">3753</td><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf426"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs B</td><td align="char" char="." valign="bottom">189</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf427"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs C</td><td align="char" char="." valign="bottom">13</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf428"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">B vs C</td><td align="char" char="." valign="bottom">67</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf429"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf430"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">B, C</td><td align="char" char="." valign="bottom">6608</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf431"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">B vs C</td><td align="char" char="." valign="bottom">81</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf432"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="left" valign="bottom">ANOVA</td><td align="left" valign="bottom">A, C</td><td align="char" char="." valign="bottom">185</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf433"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">t-test</td><td align="left" valign="bottom">A vs C</td><td align="char" char="." valign="bottom">14</td><td align="char" char="." valign="bottom">246</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf434"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr></tbody></table></table-wrap><table-wrap id="app5table2" position="float"><label>Appendix 5—table 2.</label><caption><title>Same as <xref ref-type="table" rid="table2">Table 2</xref>, but for simulated agents with perfect generalization, rather than humans.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">AIC without task</th><th align="left" valign="bottom">AIC with task</th><th align="left" valign="bottom">F(df)</th><th align="left" valign="bottom">p</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf435"><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mi mathsize="80%">ϵ</mml:mi></mml:mrow></mml:math></inline-formula></td><td align="char" char="." valign="bottom">1,938</td><td align="char" char="." valign="bottom">1,937</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf436"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">1,992</td><td align="char" char="." valign="bottom">1,996</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf437"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">1,350</td><td align="char" char="." valign="bottom">1,355</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">NA</td><td align="left" valign="bottom">–</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="char" char="." valign="bottom">1,345</td><td align="char" char="." valign="bottom">1,344</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf438"><mml:mrow><mml:mrow><mml:mi mathsize="80%">F</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="80%" minsize="80%">(</mml:mo><mml:mn mathsize="80%">2</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">245</mml:mn><mml:mo maxsize="80%" minsize="80%">)</mml:mo></mml:mrow></mml:mrow><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">4.42</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf439"><mml:mrow><mml:mi mathsize="80%">p</mml:mi><mml:mo mathsize="80%" stretchy="false">=</mml:mo><mml:mn mathsize="80%">0.013</mml:mn></mml:mrow></mml:math></inline-formula></td><td align="char" char="." valign="bottom">*</td></tr></tbody></table></table-wrap><table-wrap id="app5table3" position="float"><label>Appendix 5—table 3.</label><caption><title>Same as <xref ref-type="table" rid="table3">Table 3</xref>, but for simulated agents with perfect generalization, rather than humans.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf440"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf441"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>(Bonf.)</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf442"><mml:mrow><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac><mml:mo mathsize="80%" stretchy="false">/</mml:mo><mml:mi mathsize="80%">ϵ</mml:mi></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom">A, B, C</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">2.55</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf443"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">–0.25</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf444"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">0.005</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf445"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf446"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">A, B, C</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">–2.27</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf447"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">0.22</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf448"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">–0.004</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf449"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf450"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">A, B, C</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">–1.03</td><td align="char" char="." valign="bottom">0.055</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">0.06</td><td align="char" char="." valign="bottom">0.12</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">–0.002</td><td align="char" char="." valign="bottom">0.25</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="left" valign="bottom">A, C</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.57</td><td align="char" char="." valign="bottom">0.29</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">–0.045</td><td align="char" char="." valign="bottom">0.47</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">0.001</td><td align="char" char="." valign="bottom">0.70</td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><table-wrap id="app5table4" position="float"><label>Appendix 5—table 4.</label><caption><title>Same as <xref ref-type="table" rid="table4">Table 4</xref>, but for simulated agents with perfect generalization, rather than humans.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf451"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom">p</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf452"><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac></mml:math></inline-formula>, <inline-formula><mml:math id="inf453"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">A &amp; B</td><td align="char" char="." valign="bottom">3.04</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf454"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">A &amp; C</td><td align="char" char="." valign="bottom">0.72</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf455"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">B &amp; C</td><td align="char" char="." valign="bottom">0.44</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf456"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf457"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">A &amp; B</td><td align="char" char="." valign="bottom">0.34</td><td align="char" char="." valign="bottom">0.002</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">A &amp; C</td><td align="char" char="." valign="bottom">0.01</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf458"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">B &amp; C</td><td align="char" char="." valign="bottom">0.008</td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf459"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">B &amp; C</td><td align="char" char="." valign="bottom">0.018</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf460"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="left" valign="bottom">A &amp; C</td><td align="char" char="." valign="bottom">0.023</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf461"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr></tbody></table></table-wrap></sec></app><app id="appendix-6"><title>Appendix 6</title><sec sec-type="appendix" id="s13"><title>Age trajectories of behavioral measures</title><p>This section provides additional information about selected behavioral features (Appendix 1) and assesses their development with age. For statistical testing, we assessed age trajectories using similar regression models as before (section Parameter age trajectories).</p><p>Response times, reflecting choice fluidity and task engagement, sped up with age in all tasks, whereby age trajectories differed significantly between tasks A and B in pairwise follow-up models (grand model <inline-formula><mml:math id="inf462"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>h</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.868</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf463"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.871</mml:mn></mml:mrow></mml:math></inline-formula>; for detailed statistics, see Table <xref ref-type="table" rid="app6table1">Appendix 6—table 1</xref>; <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>). Accuracy, reflecting subjective ease and task engagement, showed a significant increase with age, and no significant pairwise differences in age trajectories after correcting for multiple comparisons, despite the better fit of the model including task compared to the model without task (<inline-formula><mml:math id="inf464"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>h</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.015</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf465"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.024</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>; Table <xref ref-type="table" rid="app6table1">Appendix 6—table 1</xref>).</p><table-wrap id="app6table1" position="float"><label>Appendix 6—table 1.</label><caption><title>Statistics of mixed-effects regression models predicting z-scored behavioral features from task (task A, task B, task C), age, and squared age (months).</title><p>The task-less grand model is reported when it had the best model fit (win-stay, Delay). Otherwise, pairwise follow-up models are shown (RT, ACC, lose-stay), with p-values corrected for multiple comparison using the Bonferroni correction. * <inline-formula><mml:math id="inf466"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; ** <inline-formula><mml:math id="inf467"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, *** <inline-formula><mml:math id="inf468"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf469"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom"><inline-formula><mml:math id="inf470"><mml:mi mathsize="80%">p</mml:mi></mml:math></inline-formula>(Bonf.)</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom">RT</td><td align="left" valign="bottom">task B &amp; task A</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">2.15</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">–0.23</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.25</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">0.007</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task B &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">–0.76</td><td align="char" char="." valign="bottom">0.69</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">–0.48</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf471"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">0.10</td><td align="char" char="." valign="bottom">0.45</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">–0.003</td><td align="char" char="." valign="bottom">0.288</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task A &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">1.40</td><td align="char" char="." valign="bottom">0.63</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">–0.23</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.15</td><td align="char" char="." valign="bottom">0.084</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">0.004</td><td align="char" char="." valign="bottom">0.129</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">ACC</td><td align="left" valign="bottom">task B &amp; task A</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">1.27</td><td align="char" char="." valign="bottom">0.36</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">0.27</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf472"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.10</td><td align="char" char="." valign="bottom">0.87</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">0.001</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task B &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">–2.15</td><td align="char" char="." valign="bottom">0.033</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">0.17</td><td align="char" char="." valign="bottom">0.036</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">0.20</td><td align="char" char="." valign="bottom">0.118</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">–0.004</td><td align="char" char="." valign="bottom">0.33</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task A &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">–0.88</td><td align="char" char="." valign="bottom">0.60</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">0.27</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf473"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">0.10</td><td align="char" char="." valign="bottom">0.57</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">–0.003</td><td align="char" char="." valign="bottom">0.57</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">WS</td><td align="char" char="ndash" valign="bottom">—–</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">–3.05</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf474"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">0.31</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf475"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">–0.007</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf476"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom">LS</td><td align="left" valign="bottom">task B &amp; task A</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">–0.90</td><td align="char" char="." valign="bottom">0.42</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">0.075</td><td align="char" char="." valign="bottom">0.87</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">0.12</td><td align="char" char="." valign="bottom">0.42</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">–0.004</td><td align="char" char="." valign="bottom">0.29</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task B &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">4.84</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf477"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">0.20</td><td align="char" char="." valign="bottom">0.015</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.51</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf478"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">0.012</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf479"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task A &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">3.94</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf480"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear age</td><td align="char" char="." valign="bottom">0.075</td><td align="char" char="." valign="bottom">0.54</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.39</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf481"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">0.008</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom">Delay</td><td align="char" char="ndash" valign="bottom">—–</td><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.95</td><td align="char" char="." valign="bottom">0.035</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (linear)</td><td align="char" char="." valign="bottom">–0.09</td><td align="char" char="." valign="bottom">0.07</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Age (quadratic)</td><td align="char" char="." valign="bottom">0.002</td><td align="char" char="." valign="bottom">0.14</td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap><p>Win-stay (WS) behavior reflects participants’ tendency to repeat rewarded actions, while lose-stay (LS) behavior reflects participants’ tendency to repeat non-rewarded actions. Win-stay behavior increased with age, without task differences (<inline-formula><mml:math id="inf482"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>h</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.961</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf483"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.959</mml:mn></mml:mrow></mml:math></inline-formula>; <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>; Table <xref ref-type="table" rid="app6table1">Appendix 6—table 1</xref>). Lose-stay behavior showed marked task differences (<inline-formula><mml:math id="inf484"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>h</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.075</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf485"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>2.109</mml:mn></mml:mrow></mml:math></inline-formula>), with inverse trajectories in task C compared to the other tasks: In task C, lose-stay behavior decreased monotonically until mid-adolescence (linear effect of age: <inline-formula><mml:math id="inf486"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.31</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf487"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; quadratic effect: <inline-formula><mml:math id="inf488"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.007</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf489"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), whereas in task A, it increased slightly (linear effect of age: <inline-formula><mml:math id="inf490"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.075</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf491"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; quadratic effect: <inline-formula><mml:math id="inf492"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf493"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). In task B, lose-stay behavior showed an inverse-U trajectory (linear effect: <inline-formula><mml:math id="inf494"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.20</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf495"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; quadratic: <inline-formula><mml:math id="inf496"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>0.005</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf497"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="app3fig1">Appendix 3—figure 1B</xref>). These differences mirrored differences in optimal task strategies: Lose-stay is always a bad strategy in task C because negative feedback is diagnostic and actions with negative outcomes should never be repeated. In tasks A and B, on the other hand, some proportion of lose-stay choices is necessary because individual negative feedback is not diagnostic, and several pieces of evidence need to be integrated over time.</p><p>Lastly, the Delay pattern measured the decrease in accuracy with increasing delay between two presentations of the same stimulus (Appendix 1). Delay did not show significant age changes (Table <xref ref-type="table" rid="app6table1">Appendix 6—table 1</xref>), and did not differ between tasks (<inline-formula><mml:math id="inf498"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>h</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.405</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf499"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+5pt"><mml:mi>o</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.402</mml:mn></mml:mrow></mml:math></inline-formula>).</p></sec></app><app id="appendix-7"><title>Appendix 7</title><sec sec-type="appendix" id="s14"><title>Limitations of this research</title><sec sec-type="appendix" id="s14-1"><title>Within-task parameter correlations</title><p>One limitation of our results is that regression analyses might be contaminated by parameter cross-correlations (sections Relative parameter differences, Parameter age trajectories, Predicting age trajectories), which would reflect modeling limitations (non-orthogonal parameters), and not necessarily shared cognitive processes. Concretely, parameters could be correlated between tasks for two reasons: (1) Because parameters are generalizable and consistent (which would be a great outcome). (2) However, a parameter like learning rate could also be correlated between two tasks because exploration parameters are correlated (e.g. due to generalization), simply because learning rates are negatively correlated with exploration parameters (which actually is the case in our study, as shown in <xref ref-type="fig" rid="app8fig2">Appendix 8—figure 2</xref>). So the ‘actual’ correlation of exploration parameters between tasks would lead to a ‘spurious’ correlation of learning rate parameters between tasks, just because exploration and learning rates are correlated within tasks. In other words, the significant correlation in <xref ref-type="fig" rid="app8fig2">Appendix 8—figure 2</xref> could indicate an ‘actual’ or a ‘spurious’ correlation, and we cannot know with certainty which one we are observing. However, this issue likely applies to most—if not all—computational modeling studies, and we hope that future research will provide more clarity on the issue. In other words, parameters <inline-formula><mml:math id="inf500"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf501"><mml:mi>β</mml:mi></mml:math></inline-formula> are mathematically related in the regular RL modeling framework (<xref ref-type="bibr" rid="bib101">Sutton and Barto, 2017</xref>; <xref ref-type="bibr" rid="bib27">Daw, 2011</xref>), and we observed significant within-task correlations between these parameters for two of our three tasks (<xref ref-type="fig" rid="app8fig2">Appendix 8—figure 2</xref>, <xref ref-type="fig" rid="app8fig3">Appendix 8—figure 3</xref>). This indicates that caution is required when interpreting correlation results. However, correlations were also present between tasks (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref>, <xref ref-type="fig" rid="app8fig3">Appendix 8—figure 3</xref>), suggesting that within-model trade-offs were not the only explanation for shared variance, and that shared cognitive processes likely also played a role.</p><p>Another issue might arise if such parameter cross-correlations differ between models, due to the differences in model parameterizations across tasks. For example, memory-related parameters (e.g. <inline-formula><mml:math id="inf502"><mml:mi>F</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf503"><mml:mi>K</mml:mi></mml:math></inline-formula> in models A and C) might interact with learning- and choice-related parameters (e.g. <inline-formula><mml:math id="inf504"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf505"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula>, noise/exploration), but such an interaction is missing in models that do not contain memory-related parameters (e.g. task B). If this indeed the case, that is, parameters trade off with each other in different ways across tasks, then a lack of correlation between tasks might not reflect a lack of generalization, but just the differences in model parameterizations. <xref ref-type="fig" rid="app8fig2">Appendix 8—figure 2</xref> indeed shows significant, medium-sized, positive and negative correlations between several pairs of Forgetting, memory-related, learning-related, and exploration parameters (though with relatively small effect sizes; Spearman correlation: <inline-formula><mml:math id="inf506"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0.17</mml:mn><mml:mo>&lt;</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.22</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><p>The existence of these correlations (and differences in correlations between tasks) suggest that memory parameters likely traded off with each other, as well as with other parameters, which potentially affected generalizability across tasks. However, some of the observed correlations might be due to shared causes, such as a common reliance on age, and the regression analyses in the main paper control for these additional sources of variance, and might provide a cleaner picture of how much variance is actually shared between parameters.</p><p>Furthermore, correlations between parameters within models are frequent in the existing literature, and do not prevent researchers from interpreting parameters—in this sense, the existence of similar correlations in our study allows us to address the question of generalizability and interpretability in similar circumstances as in the existing literature. And lastly, we confirmed that our method is able to detect generalizability using the simulation approach described in section Statistical Comparison to Generalizability Ceiling. In other words, even though within-task parameter cross-correlations likely induced some noise, the sensitivity with which we are still able to detect generalization was enough to show successful generalization in the simulated sample (and a significant reduction in humans).</p></sec><sec sec-type="appendix" id="s14-2"><title>Test-retest reliability</title><p>Furthermore, parameter generalizability is naturally bounded by parameter reliability, that is, the stability of parameter estimates when participants perform the same task twice (test-retest reliability) or when estimating parameters from different subsets of the same dataset (split-half reliability). The reliability of RL models has recently become the focus of several parallel investigations (<xref ref-type="bibr" rid="bib114">Weidinger et al., 2019</xref>; <xref ref-type="bibr" rid="bib12">Brown et al., 2020</xref>; <xref ref-type="bibr" rid="bib89">Pratt et al., 2021</xref>; <xref ref-type="bibr" rid="bib97">Shahar et al., 2019</xref>), some employing very similar tasks to ours (<xref ref-type="bibr" rid="bib109">Waltmann et al., 2022</xref>). The investigations collectively suggest that excellent reliability can often be achieved with the right methods, most notably by using hierarchical model fitting. Reliability might still differ between tasks or models, potentially being lower for learning rates than other RL parameters (<xref ref-type="bibr" rid="bib109">Waltmann et al., 2022</xref>), and differing between tasks (e.g. compare <xref ref-type="bibr" rid="bib114">Weidinger et al., 2019</xref> to <xref ref-type="bibr" rid="bib12">Brown et al., 2020</xref>). In this study, we used hierarchical fitting for tasks A and B and assessed a range of qualitative and quantitative measures of model fit for each task (<xref ref-type="bibr" rid="bib38">Eckstein et al., 2022</xref>; <xref ref-type="bibr" rid="bib72">Master et al., 2020</xref>; <xref ref-type="bibr" rid="bib117">Xia et al., 2021</xref>), boosting our confidence in high reliability of our parameter estimates, and the conclusion that the lack of between-task parameter correlations was not due to a lack of parameter reliability, but a lack of generalizability. This conclusion is further supported by the fact that larger between-task parameter correlations (<inline-formula><mml:math id="inf507"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>r</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) than those observed in humans were attainable—using the same methods—in a simulated dataset with perfect generalization.</p></sec><sec sec-type="appendix" id="s14-3"><title>Model misspecification</title><p>Another concern relates to potential model misspecification and its effects on model parameter estimates: If components of the true data-generating process are not included in a model (i.e. a model is misspecified), estimates of existing model parameters may be biased. For example, if choices have an outcome-independent history dependence that is not modeled properly, learning rate parameters have shown to be biased (<xref ref-type="bibr" rid="bib61">Katahira, 2018</xref>). Indeed, we found that learning rate parameters were inconsistent across the tasks in our study, and two of our models (A and C) did not model history dependence in choice, while the third (model B) only included the effect of one previous choice (persistence parameter), but no multi-trial dependencies. It is hence possible that the differences in learning rate parameters between tasks were caused by differences in the bias induced by misspecification of history dependence, rather than a lack of generalization. Though pressing, however, this issue is difficult to resolve in practicality, because it is impossible to include all combinations of possible parameters in all computational models, that is, to exhaustively search the space of possible models (‘Every model is wrong, but to varying degrees’). Furthermore, even though our models were likely affected by some degree of misspecification, the research community is currently using models of this kind. Our study therefore sheds light on generalizability and interpretability in a realistic setting, which likely includes models with varying degrees of misspecification. Lastly, our models were fitted to high standards and achieved good behavioral recovery (Fig. <xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>), which also reduces the likelihood of model misspecification.</p></sec><sec sec-type="appendix" id="s14-4"><title>Difference in models between tasks</title><p>Another pressing issue is to what degree the claims of this study are dependent on the precise specification of the model for each task. For example, if all models included the same common set of parameters, would the same claims hold? This question could theoretically be addressed by using the same exact model (i.e. including the exact same equations and parameters) on all tasks. However, this approach is in practice unfeasible:</p><p>1) If we chose the ‘smallest common denominator’ model, that is, the simplest model that could produce behavior on all tasks (e.g. simple <inline-formula><mml:math id="inf508"><mml:mi>α</mml:mi></mml:math></inline-formula>-<inline-formula><mml:math id="inf509"><mml:mi>β</mml:mi></mml:math></inline-formula> RL), we would induce significant model misspecification as described above, and render fitted parameters—and claims about their generalizability and interpretability—uninterpretable.</p><p>2) However, choosing a ‘mega’ model including all current models as special cases is likewise impossible, for two reasons: First, even our relatively large dataset would not allow fitting such a big model due to the number of free parameters (i.e. the mega model would lose in model comparison to simpler models due to Occam’s razor). And second, each individual task is too restrictive to fit such a model (e.g. task B does not tax memory for states, and would not allow fitting the range of memory parameters present in the other two models). Taken together, from a theoretical perspective, comparing parameters of the same model between different tasks would provide a good test of parameter generalizability. However, this is in practice infeasible given current methods and standards (e.g. simplistic, highly-controlled tasks; current modeling practices, including model fitting; data limitations). Advances in any of these areas might lead to an increase in the generalizability and interpretability of computational modeling parameters in the future.</p><p>Taking a step back, current practices ostensibly force us to choose between model misspecification on one hand and model generality on the other (<xref ref-type="bibr" rid="bib79">Navarro, 2019</xref>): If we use the same, general model for different tasks, we induce model misspecification as described above, leading to biased and uninterpretable parameters. But if we use task-specific models that reproduce human behavior more closely, we induce differences in parameterization that likely create differences in interpretation and generalizability.</p></sec></sec></app><app id="appendix-8"><title>Appendix 8</title><sec sec-type="appendix" id="s15"><title>Other supplemental figures</title><fig id="app8fig1" position="float"><label>Appendix 8—figure 1.</label><caption><title>Between-task parameter correlations.</title><p>(<bold>A</bold>) Parameter <inline-formula><mml:math id="inf510"><mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:math></inline-formula> across tasks (<inline-formula><mml:math id="inf511"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> in task C). (<bold>B</bold>) Parameters <inline-formula><mml:math id="inf512"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>β</mml:mi></mml:mfrac></mml:math></inline-formula> (task A, B) and <inline-formula><mml:math id="inf513"><mml:mi>ϵ</mml:mi></mml:math></inline-formula> (task C). (<bold>C</bold>) Parameter <inline-formula><mml:math id="inf514"><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub></mml:math></inline-formula> across tasks (<inline-formula><mml:math id="inf515"><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mo>-</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in task C). Same conventions as in Fig. <xref ref-type="fig" rid="app8fig2">Appendix 8—figure 2</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-app8-fig1-v1.tif"/></fig><fig id="app8fig2" position="float"><label>Appendix 8—figure 2.</label><caption><title>Within-task parameter correlations, focusing on learning rates (x-axes) and exploration / noise parameters (y-axes).</title><p>Each column shows one task. Each dot in the scatter plots refers to a participant, colors indicates age. Inserted are Spearman correlation statistics.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-app8-fig2-v1.tif"/></fig><fig id="app8fig3" position="float"><label>Appendix 8—figure 3.</label><caption><title>Full Spearman correlation matrix of all features in the dataset.</title><p>Feature order is the same as in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Deeper red (blue) colors indicate stronger positive (negative) correlations in terms of Spearman’s <inline-formula><mml:math id="inf516"><mml:mi>ρ</mml:mi></mml:math></inline-formula> (see color legend). Only correlations with p-values  are shown; remaining squares are left blank.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-app8-fig3-v1.tif"/></fig><fig id="app8fig4" position="float"><label>Appendix 8—figure 4.</label><caption><title>Additional PCA results.</title><p>(<bold>A</bold>) Cumulative variance explained by all PCs of the PCA (<xref ref-type="fig" rid="fig3">Figure 3</xref>; 2.2.1). The smooth, non-stepped function does not provide evidence for lower-dimensional structure within the dataset. (<bold>B</bold>) Feature loadings (weights) of PC4-PC9. Loadings are flipped based on their relation to task performance, like for PC2-PC3 in <xref ref-type="fig" rid="fig3">Figure 3</xref>. (<bold>C</bold>) Age trajectories of the top 8 PCs, by age group. Corresponding statistics in <xref ref-type="table" rid="app8table1">Appendix 8—table 1</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-app8-fig4-v1.tif"/></fig><table-wrap id="app8table1" position="float"><label>Appendix 8—table 1.</label><caption><title>Statistics of regular regression models predicting each PC from two age predictors (linear and quadratic).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">PC</th><th align="left" valign="bottom">Effect</th><th align="left" valign="bottom"><inline-formula><mml:math id="inf517"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th align="left" valign="bottom">t</th><th align="left" valign="bottom">p</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">age (linear)</td><td align="char" char="." valign="bottom">1.56</td><td align="char" char="." valign="bottom">6.56</td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">age (quadratic)</td><td align="char" char="." valign="bottom">0.035</td><td align="char" char="." valign="bottom">5.61</td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">***</td></tr><tr><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">age (linear)</td><td align="char" char="." valign="bottom">0.34</td><td align="char" char="." valign="bottom">2.17</td><td align="char" char="." valign="bottom">0.031</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">age (quadratic)</td><td align="char" char="." valign="bottom">0.007</td><td align="char" char="." valign="bottom">1.64</td><td align="char" char="." valign="bottom">0.10</td><td align="left" valign="bottom">—</td></tr><tr><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">age (linear)</td><td align="char" char="." valign="bottom">0.46</td><td align="char" char="." valign="bottom">3.27</td><td align="char" char="." valign="bottom">0.001</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">age (quadratic)</td><td align="char" char="." valign="bottom">–0.011</td><td align="char" char="." valign="bottom">–3.13</td><td align="char" char="." valign="bottom">0.002</td><td align="char" char="." valign="bottom">**</td></tr></tbody></table></table-wrap><table-wrap id="app8table2" position="float"><label>Appendix 8—table 2.</label><caption><title>Statistics of mixed-effects regression models predicting parameter values from task (A, B, and C), age, and squared age (months).</title><p>Only effects including task are reported. * <inline-formula><mml:math id="inf518"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>; ** <inline-formula><mml:math id="inf519"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.01</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, *** <inline-formula><mml:math id="inf520"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Tasks</th><th align="left" valign="bottom">Predictor</th><th align="left" valign="bottom"/><th align="left" valign="bottom">p</th><th align="left" valign="bottom">sig.</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf521"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">+</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">task B &amp; task A</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">0.79</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf522"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.025</td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">**</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">0.001</td><td align="char" char="." valign="bottom">0.021</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task B &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">0.84</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf523"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.012</td><td align="char" char="." valign="bottom">0.41</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf524"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0.55</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">task A &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">0.048</td><td align="char" char="." valign="bottom">0.70</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.12</td><td align="char" char="." valign="bottom">0.37</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf525"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0.36</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf526"><mml:mfrac><mml:mn mathsize="80%">1</mml:mn><mml:mi mathsize="80%">β</mml:mi></mml:mfrac></mml:math></inline-formula></td><td align="left" valign="bottom">task B &amp; task A</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">0.49</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf527"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">–0.026</td><td align="char" char="." valign="bottom">0.046</td><td align="char" char="." valign="bottom">*</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">0.001</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf528"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf529"><mml:msub><mml:mi mathsize="80%">α</mml:mi><mml:mo mathsize="80%" stretchy="false">-</mml:mo></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">task B &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">11.70</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf530"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">0.58</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf531"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="char" char="." valign="bottom">–0.013</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf532"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">***</td></tr><tr><td align="left" valign="bottom">Forgetting</td><td align="left" valign="bottom">task B &amp; task C</td><td align="left" valign="bottom">Task (main effect)</td><td align="char" char="." valign="bottom">0.10</td><td align="char" char="." valign="bottom">0.36</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * linear age (interaction)</td><td align="char" char="." valign="bottom">0.005</td><td align="char" char="." valign="bottom">0.70</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Task * quadratic age (interaction)</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf533"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0.67</td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75474.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Hartley</surname><given-names>Catherine</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>New York University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.05.28.446162" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.05.28.446162"/></front-stub><body><p>This study adopts a within-participant approach to address two important questions in the field of human reinforcement learning: to what extent do estimated computational model parameters generalize across different tasks and can their meaning be interpreted in the same way in different task contexts? The authors find that inferred parameters show moderate to little generalizability across tasks, and that their interpretation strongly depends on task context.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75474.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Hartley</surname><given-names>Catherine</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>New York University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Radulescu</surname><given-names>Angela</given-names></name><role>Reviewer</role><aff><institution/><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.05.28.446162">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.05.28.446162v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Learning Rates Are Not All the Same: The Interpretation of Computational Model Parameters Depends on the Context&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Timothy Behrens as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Angela Radulescu (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) The authors should carefully consider whether model misspecification may play a role in the observed results. More information should be provided on the set of models compared to validate the claim that the models presented are the best-fitting models and to establish whether each best-fitting model provides a comparably good fit to its respective task. For example, might models that incorporate various different forms of memory processes provide a better fit to the data for Tasks A and B? Moreover, to what degree are the claims in the current paper dependent on the precise specification of the model for each task? If a common set of parameters are included in each model specification, do the same claims hold?</p><p>2) While it may be beyond the scope of the current data, it would be helpful to include some discussion of test-retest reliability of the current tasks, and of RL tasks more generally, and how these measures relate to expectations about generalizability.</p><p>3) Was there a reason that the authors used PCA rather than factor analysis to extract common components across task parameters/behavioral indices?</p><p>4) The finding that both the positive learning rate and inverse temperature generalized across tasks is an important result that is not given the same weight in the exposition of the results as those parameters that exhibit generalization failures. The abstract and title could be edited to provide a more balanced reflection of these findings and to eliminate the somewhat &quot;straw man&quot;-ish implication that the field expects that the absolute values of learning rates should be the same across tasks.</p><p>5) To determine what might be a reasonably expected ceiling on the degree of generalizability, as suggested by the reviewer, the authors could simulate data from agents using the same generative parameters across the three tasks and report the correlations between the resulting parameters estimates.</p><p>6) Descriptions of the tasks that capture their distinguishing features through the lens of Markov Decision Process theory might be valuable to contextualize the current results within a broader reinforcement learning literature.</p><p>The reviewers also made a number of concrete suggestions for ways in which the manuscript might be improved that the authors should consider carefully.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>I hope that the above three points will be discussed in the Discussion section or in the relevant part of the Method section. In the following, I will discuss some minor points.</p><p>p 4, Line 87</p><p>The citations for clinical research areas [15-18] seem to be mostly review articles in computational psychiatry, and I am not sure if the literature explicitly addressing the inconsistencies discussed here is properly cited. For example, a review of the lack of agreement between studies on whether the association with depression appears in learning rates or temperature parameters (Robinson and Chase, 2017, Computational Psychiatry, 1, 208-233) and the literature cited there may also be included.</p><p>p.14</p><p>The symbol '$' in Table 4 needs to be explained.</p><p>p.25</p><p>Figure 5: Is 'B' the correct label for 'Panel C'?</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>With regard to obtaining a ceiling on correlations that indicate relative generalizability, it might be possible to get an answer to this w/o collecting new data by simulating behavior of the *same N agents* (with uniformly sampled params, or params sampled from prior group distribution used in the hierarchical fit, or params sampled from distributions centered around ideal observer values). If we then re-run model fitting on these simulated datasets, what is the max correlation between LRs estimated from different tasks? And can we bootstrap to obtain some CIs around this ceiling? In general, the authors consider the tasks to be fairly similar, but I'm not sure that is actually the case -- even A and C, which share the most similarities, differ markedly in the reward function (probabilistic vs. deterministic).</p><p>With regard to clarifying the interaction between memory parameters and LR/exploration, have authors specifically determined the degree to which memory-related parameters F and/or K interact with α_+/β, e.g. by plotting likelihood function surfaces as a function of pairs of parameters? I also couldn't find the pairwise correlation between F (Task A) and F( Task C) in this section, were these reported? I'm guessing these were not significant based on the results in 2.1.4 showing F in A does not predict F in B, but it would be helpful to include them for completeness.</p><p>The current study was not designed for systematically varying different aspects of the MDP to see how this affects inferred parameter generalizability and interpretability, which is okay. But perhaps one step the paper can make in this direction of theoretical consistency is to explicitly name the features of each task from an MDP theory standpoint, or at least additionally include this as a table or additional panel in Figure 1. e.g. size of state and action space (+ mapping to &quot;set size&quot; jargon), reward function, etc. Authors do this at several points in the paper (including the appendix), and this can only help as a practice that allows the RL community to think about tasks in a common way. In the present study, this convention can illuminate why the tasks presented here are actually quite different from one another. Task A: 4 states (1 per trial), 2 actions (visible on screen), stable stochastic reward function; Task B: stateless, 2 actions, reversal in stochastic reward function; Task C: RL-WM task: 2-5 states (1 per trial), 3 actions (not visible on screen), stable deterministic reward function.</p><p>With regard to model selection:</p><p>– For the section describing the computational models for the first time, it would be helpful to summarize info about parameters in a table, emphasizing those parameters common across best-fitting models. For example, just from a rhetorical standpoint, it seemed strange that Tasks A and C are not both best fit by a model that allows LR- to vary freely, even though both tasks are taken as similar in the paper's taxonomy.</p><p>– It would be helpful to show upfront in a figure that each best-fitting model explains data in its respective task as well as models in the other tasks. i.e. can we say that each model explains about the same number of choices in every task? This is important because incomplete models are the reason we might see &quot;contamination&quot; whereby variance explained by one parameter in a task is explained by a different parameter in a second task.</p><p>– I did wonder here to what extent some of the inconsistencies can be explained by the fact that authors only instantiated a model that formalizes explicit memory demands only for Task C. We know from past work (e.g. by Bornstein and colleagues) that even in stateless bandit tasks such as Task B, explicit memory of outcomes stretching back tens of trials ago impact decisions. Task A is also potentially solvable by a WM module that keeps track of explicit state-action associations, bearing similarity to Task C. Is the forgetting parameter F enough to capture all the memory processes that might *also* be present in Task A? And would a RL-WM model with a fixed set size do better at explaining behavior on Task A? The lack of specificity in the noise/exploration parameter for Task A (evidenced by the fact that it was correlated with different parameters in other tasks, including working memory weight from C), strongly supports this possibility, as this parameter is known to absorb unexplained variance.</p><p>Finally, I think it is important to provide a bit more detail upfront about the training and instructions protocol for each task, and, to the extent that it is possible, provide evidence that instruction comprehension is not related to parameter differences. One simple analysis here would be to examine the &quot;lose-stay&quot; distribution in Tasks B and C and look for any evidence of bimodality that can be traced to how instructions were presented. I would also be curious if this distribution varies with age, potentially explaining the striking divergence in age trajectories for LR- in Tasks B and C.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.75474.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>[Essential revisions]: “More information should be provided on the set of models compared to validate the claim that the models presented are the best-fitting models and to establish whether each best-fitting model provides a comparably good fit to its respective task.”</p></disp-quote><p>We thank the reviewer for this helpful comment, as we indeed did not provide much information about our models. We have addressed this issue in several ways, including a new supplementary section with information about the set of models compared, modifications to the introduction that provide more information about the winning models, a new panel that specifies the parameters of each winning model in Figure 1, clearer references to the original publications (which contain in-depth information about the specific models for each task), and a supplemental figure that compares the behavior of humans and simulations of each winning model. For convenience, we copy these modifications below.</p><p>New supplementary section with information about the set of models compared:</p><p>“In task A, the following six models were compared: Classic RL (α, β); RL with asymmetric learning rates (α+, α-, β); Asymmetric RL with α- = 0 (α+, 0, β); RL with forgetting (α, β, f), Asymmetric RL with forgetting (α+, α-, β, f); and Asymmetric RL with α- = 0 and forgetting (α+, 0, β, f).</p><p>In task B, final comparison involved seven models with increasing complexity (the order of adding free parameters was determined in pre-analyses): Classic RL (α, β); RL with counterfactual updating (α, β, counterfactual α); RL with counterfactual updating and perseverance (α, β, counterfactual α, perseverance); RL with perseverance, separate learning from positive versus negative outcomes, and counterfactual updating for positive outcomes (α+, β, counterfactual α+, perseverance, α-); RL with perseverance, separate learning from positive versus negative outcomes, and counterfactual updating for positive and negative outcomes (α+, β, counterfactual α+, perseverance, α-, counterfactual α-); winning, simplified 4-parameter RL model with perseverance and separate learning rates for positive versus negative outcomes, which are identical to the respective counterfactual updating rates (α+ = counterfactual α+, α = counterfactual α-, β, perseverance).</p><p>In task C, model comparison involved six competing models: Classic RL (α, β), RL with undirected noise, RL with positive learning bias, RL with forgetting, RL with 4 learning rates, and the winning RL model with working memory (&quot;RLWM&quot;).”</p><p>In order to establish that each best-fitting model provides a good fit to its respective task data, we have Appendix 4-figure 1 that shows simulated behavior from each model, which in each case closely resembles human behavior.</p><disp-quote content-type="editor-comment"><p>[Reviewer #3]: “For the section describing the computational models for the first time, it would be helpful to summarize info about parameters in a table, emphasizing those parameters common across best-fitting models. For example, just from a rhetorical standpoint, it seemed strange that Tasks A and C are not both best fit by a model that allows LR- to vary freely, even though both tasks are taken as similar in the paper's taxonomy.”</p></disp-quote><p>We thank the reviewer for this comment. We have added the suggested table to Figure 1, shown in the comment above.</p><p>As for the models of tasks A and C, despite many similarities, both tasks also differ on several dimensions, including the nature of feedback (stochastic vs deterministic), the number of stimuli to learn about, and the number and visibility of available actions. These differences likely explain the differences in computational models, including the difference in LR-.</p><disp-quote content-type="editor-comment"><p>[Reviewer #3]: “It would be helpful to show upfront in a figure that each best-fitting model explains data in its respective task as well as models in the other tasks. i.e. can we say that each model explains about the same number of choices in every task? This is important because incomplete models are a reason we might see &quot;contamination&quot; whereby variance explained by one parameter in a task is explained by a different parameter in a second task.”</p></disp-quote><p>We agree with the sentiment that all models should fit their respective task equally well. However, there is no good quantitative measure of model fit that is comparable across tasks and models – for example, because of the difference in difficulty between the tasks, the number of choices explained would not be a valid measure to compare how well the models are doing across tasks. To address this issue, we have added the new supplemental section (Appendix C) mentioned above that includes information about the set of models compared, and explains why we have reason to believe that all models fit (equally) well. We also created the new supplemental Figure D.7, which directly compares human and simulated model behavior in each task, and shows a close correspondence for all tasks. Because the quality of all our models was a major concern for us in this research, we also refer the reviewer and other readers to the three original publications that describe all our modeling efforts in much more detail, and hopefully convince the reviewer that our model fitting was performed according to high standards.</p><disp-quote content-type="editor-comment"><p>[Essential revisions]: “For example, might models that incorporate various different forms of memory processes provide a better fit to the data for Tasks A and B?”</p><p>[Reviewer #3]: “I did wonder here to what extent some of the inconsistencies can be explained by the fact that authors only instantiated a model that formalizes explicit memory demands for Task C. We know from past work (e.g. by Bornstein and colleagues) that even in stateless bandit tasks such as Task B, explicit memory of outcomes stretching back tens of trials ago impact decisions. Task A is also potentially solvable by a WM module that keeps track of explicit state-action associations, bearing similarity to Task C. Is the forgetting parameter F enough to capture all the memory processes that might *also* be present in Task A? And would a RL-WM model with a fixed set size do better at explaining behavior on Task A? The lack of specificity in the noise/exploration parameter for Task A (evidenced by the fact that it was correlated with different parameters in other tasks, including working memory weight from C), strongly supports this possibility, as this parameter is known to absorb unexplained variance.”</p></disp-quote><p>We appreciate this very thoughtful question, which raises several important issues. (1) As the reviewer said, the models for task A and task C are relatively different even though the underlying tasks are relatively similar (minus the differences the reviewer already mentioned, in terms of visibility of actions, number of actions, and feedback stochasticity). (2) We also agree that the model for task C did not include episodic memory processes even though episodic memory likely played a role in this task, and agree that neither the forgetting parameters in tasks A and C, nor the noise/exploration parameters in tasks A, B, and C are likely specific enough to capture all the memory / exploration processes participants exhibited in these tasks.</p><p>However, this problem is difficult to solve: We cannot fit an episodic-memory model to task B because the task lacks an episodic-memory manipulation (such as, e.g., in Bornstein et al., 2017), and we cannot fit a WM model to task A because it lacks the critical set-size manipulation enabling identification of the WM component (modifying set size allows the model to identify individual participants’ WM capacities, so the issue cannot be avoided in tasks with only one set size). Similarly, we cannot model more specific forgetting or exploration processes in our tasks because they were not designed to dissociate these processes. If we tried fitting more complex models that include these processes to these tasks, they would most likely lose in model comparison because the increased complexity would not lead to additional explained behavioral variance, given that the tasks do not elicit the relevant behavioral patterns. Because the models therefore do not specify all the cognitive processes that participants likely employ, the situation described by the reviewer arises, namely that different parameters sometimes capture the same cognitive processes across tasks and models, while the same parameters sometimes capture different processes.</p><p>And while the reviewer focussed largely on memory-related processes, the issue of course extends much further: Besides WM, episodic memory, and more specific aspects of forgetting and exploration, our models also did not take into account a range of other processes that participants likely engaged in when performing the tasks, including attention (selectivity, lapses), reasoning / inference, mental models (creation and use), prediction / planning, hypothesis testing, etc., etc. In full agreement with the reviewer’s sentiment, we recently argued that this situation is ubiquitous to computational modeling, and should be considered very carefully by all modelers because it can have a large impact on model interpretation (Eckstein et al., 2021).</p><p>If we assume that many more cognitive processes are likely engaged in each task than are modeled, and consider that every computational model includes just a small number of free parameters, parameters then necessarily reflect a multitude of cognitive processes. The situation is additionally exacerbated by the fact that more complex models become increasingly difficult to fit from a methodological perspective, and that current laboratory tasks are designed in a highly controlled and consequently relatively simplistic way that does not lend itself to simultaneously test a variety of cognitive processes.</p><p>The best way to deal with this situation, we think, is to *recognize* that in different contexts (e.g., different tasks, different computational models, different subject populations), the same parameters can capture different behaviors, and different parameters can capture the same behaviors, for the reasons the reviewer lays out. Recognizing this helps to avoid misinterpreting modeling results, for example by focusing our interpretation of model parameters to our specific task and model, rather than aiming to generalize across multiple tasks. We think that recognizing this fact also helps us understand the factors that determine whether parameters will capture the same or different processes across contexts and whether they will generalize. This is why we estimated here whether different parameters generalize to different degrees, which other factors affect generalizability, etc. Knowing the practical consequences of using the kinds of models we currently use will therefore hopefully provide a first step in resolving the issues the reviewer laid out.</p><disp-quote content-type="editor-comment"><p>[Reviewer #3]: “With regard to clarifying the interaction between memory parameters and LR/exploration, have authors specifically determined the degree to which memory-related parameters F and/or K interact with α_+/β, e.g. by plotting likelihood function surfaces as a function of pairs of parameters? I also couldn't find the pairwise correlation between F(Task A) and F(Task C) in this section, were these reported? I'm guessing these were not significant based on the results in 2.1.4 showing F in A does not predict F in B, but it would be helpful to include them for completeness.”</p></disp-quote><p>We thank the reviewer for this comment, which raises an important issue. We are adding the specific pairwise correlations and scatter plots for the pairs of parameters the reviewer asked about in <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> (“bf_α” = LR task A; “bf_forget” = F task A; “rl_forget” = F task C; “rl_log_α” = LR task C; “rl_K” = WM capacity task C):</p><p>Within tasks:</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-sa2-fig1-v1.tif"/></fig><p>Between tasks:</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-sa2-fig2-v1.tif"/></fig><p>To answer the question in more detail, we have expanded our section about limitations stemming from parameter tradeoffs in the following way:“One limitation of our results is that regression analyses might be contaminated by parameter cross-correlations (sections 2.1.2, 2.1.3, 2.1.4), which would reflect modeling limitations (non-orthogonal parameters), and not necessarily shared cognitive processes. For example, parameters α and β are mathematically related in the regular RL modeling framework, and we observed significant within-task correlations between these parameters for two of our three tasks (suppl. Figure H.10, H.11). This indicates that caution is required when interpreting correlation results. However, correlations were also present between tasks (suppl. Figure H.9, H.11), suggesting that within-model trade-offs were not the only explanation for shared variance, and that shared cognitive processes likely also played a role.</p><p>Another issue might arise if such parameter cross-correlations differ between models, due to the differences in model parameterizations across tasks. For example, memory-related parameters (e.g., F, K in models A and C) might interact with learning- and choice-related parameters (e.g., α+, α-, noise/exploration), but such an interaction is missing in models that do not contain memory-related parameters (e.g., task B). If this indeed the case, i.e., parameters trade off with each other in different ways across tasks, then a lack of correlation between tasks might not reflect a lack of generalization, but just the differences in model parameterizations. Appendix 5-figure 1 indeed shows significant, medium-sized, positive and negative correlations between several pairs of Forgetting, memory-related, learning-related, and exploration parameters (though with relatively small effect sizes; Spearman correlation: 0.17 &lt; |r| &lt; 0.22).</p><p>The existence of these correlations (and differences in correlations between tasks) suggest that memory parameters likely traded off with each other, as well as with other parameters, which potentially affected generalizability across tasks. However, some of the observed correlations might be due to shared causes, such as a common reliance on age, and the regression analyses in the main paper control for these additional sources of variance, and might provide a cleaner picture of how much variance is actually shared between parameters.</p><p>Furthermore, correlations between parameters within models are frequent in the existing literature, and do not prevent researchers from interpreting parameters---in this sense, the existence of similar correlations in our study allows us to address the question of generalizability and interpretability in similar circumstances as in the existing literature.”</p><disp-quote content-type="editor-comment"><p>[Essential revisions]: “Moreover, to what degree are the claims in the current paper dependent on the precise specification of the model for each task? If a common set of parameters are included in each model specification, do the same claims hold?”</p></disp-quote><p>We thank the reviewers for this excellent question, and added the following paragraph to our Limitations sections to discuss the issue:</p><p>“Another pressing issue is to what degree the claims of this study are dependent on the precise specification of the model for each task. For example, if all models included the same common set of parameters, would the same claims hold? This question could theoretically be addressed by using the same exact model (i.e., including the exact same equations and parameters) on all tasks. However, this approach is in practice unfeasible:</p><p>1) If we chose the &quot;smallest common denominator&quot; model, i.e., the simplest model that could produce behavior on all tasks (e.g., simple α-β RL), we would induce significant model misspecification as described above, and render fitted parameters---and claims about their generalizability and interpretability---uninterpretable.</p><p>2) However, choosing a &quot;mega&quot; model including all current models as special cases is likewise impossible, for two reasons: First, even our relatively large dataset would not allow fitting such a big model due to the number of free parameters (i.e., the mega model would lose in model comparison to simpler models, since model comparison penalizes models with high high numbers of free parameters). And second, each individual task is too restrictive to fit such a model (e.g., task B does not tax memory for states, and would not allow fitting the range of memory parameters present in the other two models).</p><p>Taken together, from a theoretical perspective, comparing parameters of the same model between different tasks would provide a good test of parameter generalizability. However, this is in practice infeasible given current methods and standards (e.g., simplistic, highly-controlled tasks; current modeling practices, including model fitting; data limitations). Advances in any of these areas might lead to an increase in the generalizability and interpretability of computational modeling parameters in the future.</p><p>Taking a step back, current practices ostensibly force us to choose between model misspecification on one hand and model generality on the other […]: If we use the same, general model for different tasks, we induce model misspecification as described above, leading to biased and uninterpretable parameters. But if we use task-specific models that reproduce human behavior more closely, we induce differences in parameterization that likely create differences in interpretation and generalizability.“</p><disp-quote content-type="editor-comment"><p>[Essential revisions]: “While it may be beyond the scope of the current data, it would be helpful to include some discussion of test-retest reliability of the current tasks, and of RL tasks more generally, and how these measures relate to expectations about generalizability.”</p></disp-quote><p>We thank the reviewer for this useful comment, and have added the following paragraph to the Discussion section to address it:</p><p>“Furthermore, parameter generalizability is naturally bounded by parameter reliability, i.e., the stability of parameter estimates when participants perform the same task twice (test-retest reliability) or when estimating parameters from different subsets of the same dataset (split-half reliability). The reliability of RL models has recently become the focus of several parallel investigations […], some employing very similar tasks to ours […]. The investigations collectively suggest that excellent reliability can often be achieved with the right methods, most notably by using hierarchical model fitting. Reliability might still differ between tasks or models, potentially being lower for learning rates than other RL parameters […], and differing between tasks (e.g., compare […] to […]). In this study, we used hierarchical fitting for tasks A and B and assessed a range of qualitative and quantitative measures of model fit for each task […], boosting our confidence in high reliability of our parameter estimates, and the conclusion that the lack of between-task parameter correlations was not due to a lack of parameter reliability, but a lack of generalizability. This conclusion is further supported by the fact that larger between-task parameter correlations (r&gt;0.5) than those observed in humans were attainable---using the same methods---in a simulated dataset with perfect generalization.”</p><disp-quote content-type="editor-comment"><p>[Essential revisions]: “Was there a reason that the authors used PCA rather than factor analysis to extract common components across task parameters/behavioral indices?”</p></disp-quote><p>To answer the reviewer's first question: We indeed standardized all features before performing the PCA. Apologies for missing to include this information – we have now added a corresponding sentence to the methods sections.</p><p>We also thank the reviewer for the mentioned reference, which is very relevant to our findings and can help explain the roles of different PCs. Like in our study, Moutoussis et al. found a first PC that captured variability in task performance, and subsequent PCs that captured task contrasts. We added the following paragraph to our manuscript:</p><p>“PC1 therefore captured a range of &quot;good&quot;, task-engaged behaviors, likely related to the construct of &quot;decision acuity&quot; […]. Like our PC1, decision acuity was the first component of a factor analysis (variant of PCA) conducted on 32 decision-making measures on 830 young people, and separated good and bad performance indices. Decision acuity reflects generic decision-making ability, and predicted mental health factors, was reflected in resting-state functional connectivity, but was distinct from IQ […].”</p><p>To answer the reviewer's question about PCA versus FA, both approaches are relatively similar conceptually, and oftentimes share the majority of the analysis pipeline in practice. The main difference is that PCA breaks up the existing variance in a dataset in a new way (based on PCs rather than the original data features), whereas FA aims to identify an underlying model of latent factors that explain the observable features. This means that PCs are linear combinations of the original data features, whereas Factors are latent factors that give rise to the observable features of the dataset with some noise, i.e., including an additional error term.</p><p>However, in practice, both methods share the majority of computation in the way they are implemented in most standard statistical packages: FA is usually performed by conducting a PCA and then rotating the resulting solution, most commonly using the Varimax rotation, which maximizes the variance between features loadings on each factor in order to make the result more interpretable, and thereby foregoing the optimal solution that has been achieved by the PCA (which lack the error term). Maximum variance in feature loadings means that as many features as possible will have loadings close to 0 and 1 on each factor, reducing the number of features that need to be taken into account when interpreting this factor. Most relevant in our situation is that PCA is usually a special case of FA, with the only difference that the solution is not rotated for maximum interpretability. (Note that this rotation can be minor if feature loadings already show large variance in the PCA solution.)</p><p>To determine how much our results would change in practice if we used FA instead of PCA, we repeated the analysis using FA. See Figure 3 and <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>, the results are quite similar:</p><p>FA</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-sa2-fig3-v1.tif"/></fig><p>We therefore conclude that our specific results are robust to the choice of method used, and that there is reason to believe that our PC1 is related to Moutoussis et al.’s F1 despite the differences in method.</p><disp-quote content-type="editor-comment"><p>[Essential revisions]: “The finding that both the positive learning rate and inverse temperature generalized across tasks is an important result that is not given the same weight in the exposition of the results as those parameters that exhibit generalization failures. The abstract and title could be edited to provide a more balanced reflection of these findings and to eliminate the somewhat &quot;straw man&quot;-ish implication that the field expects that the absolute values of learning rates should be the same across tasks.”</p></disp-quote><p>We thank the reviewers for this recommendation and have reworked the paper substantially to address the issue. We have modified the highlights, abstract, introduction, discussion, conclusion, and relevant parts of the Results section to provide equal weight to the successes and failures of generalization.</p><p>Highlights:</p><p>Abstract:</p><p>The introduction now introduces different potential outcomes of our study with more equal weight:</p><p>“Computational modeling enables researchers to condense rich behavioral datasets into simple, falsifiable models (e.g., RL) and fitted model parameters (e.g., learning rate, decision temperature) […]. These models and parameters are often interpreted as a reflection of (&quot;window into&quot;) cognitive and/or neural processes, with the ability to dissect these processes into specific, unique components, and to measure participants' inherent characteristics along these components.</p><p>For example, RL models have been praised for their ability to separate the decision making process into value updating and choice selection stages, allowing for the separate investigation of each dimension. Crucially, many current research practices are firmly based on these (often implicit) assumptions, which give rise to the expectation that parameters have a task- and model-independent interpretation and will seamlessly generalize between studies. However, there is growing---though indirect---evidence that these assumptions might not (or not always) be valid.</p><p>The following section lays out existing evidence in favor and in opposition of model generalizability and interpretability. Building on our previous opinion piece, which---based on a review of published studies---argued that there is less evidence for model generalizability and interpretability than expected based on current research practices […], this study seeks to directly address the matter empirically.”</p><p>We now also provide more even evidence for both potential outcomes:</p><p>“Many current research practices are implicitly based on the interpretability and generalizability of computational model parameters (despite the fact that many researchers explicitly distance themselves from these assumptions). For our purposes, we define a model variable (e.g., fitted parameter, reward-prediction error) as generalizable if it is consistent across uses, such that a person would be characterized with the same values independent of the specific model or task used to estimate the variable. Generalizability is a consequence of the assumption that parameters are intrinsic to participants rather than task dependent (e.g., a high learning rate is a personal characteristic that might reflect an individual's unique brain structure). One example of our implicit assumptions about generalizability is the fact that we often directly compare model parameters between studies---e.g., comparing our findings related to learning-rate parameters to a previous study's findings related to learning-rate parameters. Note that such a comparison is only valid if parameters capture the same underlying constructs across studies, tasks, and model variations, i.e., if parameters generalize. The literature has implicitly equated parameters in this way in review articles […], meta-analyses […], and also most empirical papers, by relating parameter-specific findings across studies. We also implicitly evoke parameter generalizability when we study task-independent empirical parameter priors […], or task-independent parameter relationships (e.g., interplay between different kinds of learning rates […]), because we presuppose that parameter settings are inherent to participants, rather than task specific.</p><p>We define a model variable as interpretable if it isolates specific and unique cognitive elements, and/or is implemented in separable and unique neural substrates. Interpretability follows from the assumption that the decomposition of behavior into model parameters &quot;carves cognition at its joints&quot;, and provides fundamental, meaningful, and factual components (e.g., separating value updating from decision making).</p><p>We implicitly invoke interpretability when we tie model variables to neural substrates in a task-general way (e.g., reward prediction errors to dopamine function […]), or when we use parameters as markers of psychiatric conditions (e.g., working-memory parameter and schizophrenia […]). Interpretability is also required when we relate abstract parameters to aspects of real-world decision making […], and generally, when we assume that model variables are particularly &quot;theoretically meaningful&quot; […].</p><p>However, in midst the growing recognition of computational modeling, the focus has also shifted toward inconsistencies and apparent contradictions in the emerging literature, which are becoming apparent in cognitive […], developmental […], clinical […], and neuroscience studies […], and have recently become the focus of targeted investigations […]. For example, some developmental studies have shown that learning rates increased with age […], whereas others have shown that they decrease […]. Yet others have reported U-shaped trajectories with either peaks […] or troughs […] during adolescence, or stability within this age range […] (for a comprehensive review, see […]; for specific examples, see […]). This is just one striking example of inconsistencies in the cognitive modeling literature, and many more exist […]. These inconsistencies could signify that computational modeling is fundamentally flawed or inappropriate to answer our research questions. Alternatively, inconsistencies could signify that the method is valid, but our current implementations are inappropriate […]. However, we hypothesize that inconsistencies can also arise for a third reason: Even if both method and implementation are appropriate, inconsistencies like the ones above are expected---and not a sign of failure---if implicit assumptions of generalizability and interpretability are not always valid. For example, model parameters might be more context-dependent and less person-specific that we often appreciate […].”</p><p>In the Results section, we now highlight findings more that are compatible with generalization: “For α+, adding task as a predictor did not improve model fit, suggesting that α+ showed similar age trajectories across tasks (Table 2). Indeed, α+ showed a linear increase that tapered off with age in all tasks (linear increase: task A: β = 0.33, p &lt; 0.001; task B: β = 0.052, p &lt; 0.001; task C: β = 0.28, p &lt; 0.001; quadratic modulation: task A: β = −0.007, p &lt; 0.001; task B: β = −0.001, p &lt; 0.001; task C: β = −0.006, p &lt; 0.001). For noise/exploration and Forgetting parameters, adding task as a predictor also did not improve model fit (Table 2), suggesting similar age trajectories across tasks.”</p><p>“For both α+ and noise/exploration parameters, task A predicted tasks B and C, and tasks B and C predicted task A, but tasks B and C did not predict each other (Table 4; Figure 2D), reminiscent of the correlation results that suggested successful generalization (section 2.1.2).”</p><p>“Noise/exploration and α+ showed similar age trajectories (Figure 2C) in tasks that were sufficiently similar (Figure 2D).”</p><p>And with respect to our simulation analysis (for details, see next section):</p><p>“These results show that our method reliably detected parameter generalization in a dataset that exhibited generalization. ”</p><p>We also now provide more nuance in our discussion of the findings:</p><p>“Both generalizability […] and interpretability (i.e., the inherent &quot;meaningfulness&quot; of parameters) […] have been explicitly stated as advantages of computational modeling, and many implicit research practices (e.g., comparing parameter-specific findings between studies) showcase our conviction in them […]. However, RL model generalizability and interpretability has so far eluded investigation, and growing inconsistencies in the literature potentially cast doubt on these assumptions. It is hence unclear whether, to what degree, and under which circumstances we should assume generalizability and interpretability. Our developmental, within-participant study revealed a nuanced picture: Generalizability and interpretability differed from each other, between parameters, and between tasks.”</p><p>“Exploration/noise parameters showed considerable generalizability in the form of correlated variance and age trajectories. Furthermore, the decline in exploration/noise we observed between ages 8-17 was consistent with previous studies [13, 66, 67], revealing consistency across tasks, models, and research groups that supports the generalizability of exploration / noise parameters. However, for 2/3 pairs of tasks, the degree of generalization was significantly below the level of generalization expected for perfect generalization.</p><p>Interpretability of exploration / noise parameters was mixed: Despite evidence for specificity in some cases (overlap in parameter variance between tasks), it was missing in others (lack of overlap), and crucially, parameters lacked distinctiveness (substantial overlap in variance with other parameters).”</p><p>“Taken together, our study confirms the patterns of generalizable exploration/noise parameters and task-specific learning rate parameters that are emerging from the literature [13].”</p><disp-quote content-type="editor-comment"><p>[Essential revisions]: “To determine what might be a reasonably expected ceiling on the degree of generalizability, as suggested by the reviewer, the authors could simulate data from agents using the same generative parameters across the three tasks and report the correlations between the resulting parameters estimates.”</p><p>[Reviewer #3]: “With regard to obtaining a ceiling on correlations that indicate relative generalizability, it might be possible to get an answer to this w/o collecting new data by simulating behavior of the *same N agents* (with uniformly sampled params, or params sampled from prior group distribution used in the hierarchical fit, or params sampled from distributions centered around ideal observer values). If we then re-run model fitting on these simulated datasets, what is the max correlation between LRs estimated from different tasks? And can we bootstrap to obtain some Cis around this ceiling? In general, the authors consider the tasks to be fairly similar, but I'm not sure that is actually the case–- even A and C, which share the most similarities, differ markedly in the reward function (probabilistic vs. deterministic).”</p></disp-quote><p>We thank the reviewer for this excellent suggestion, which we think helped answer a central question that our previous analyses had failed to address, and also provided answers to several other concerns raised by both reviewers in other section. We have conducted these additional analyses as suggested, simulating artificial behavioral data for each task, fitting these data using the models used in humans, repeating the analyses performed on humans on the new fitted parameters, and using bootstrapping to statistically compare humans to the hence obtained ceiling of generalization. We have added the following section to our paper, which describes the results in detail:</p><p>“Our analyses so far suggest that some parameters did not generalize between tasks, given differences in age trajectories (section 2.1.3) and a lack of mutual prediction (section 2.1.4). However, the lack of correspondence could also arise due to other factors, including behavioral noise, noise in parameter fitting, and parameter trade-offs within tasks. To rule these out, we next established the ceiling of generalizability attainable using our method.</p><p>We established the ceiling in the following way: We first created a dataset with perfect generalizability, simulating behavior from agents that use the same parameters across all tasks (suppl. Appendix E). We then fitted this dataset in the same way as the human dataset (e.g., using the same models), and performed the same analyses on the fitted parameters, including an assessment of age trajectories (suppl. Table E.8) and prediction between tasks (suppl. Tables E.9, E.10, and E.11). These results provide the practical ceiling of generalizability. We then compared the human results to this ceiling to ensure that the apparent lack of generalization was valid (significant difference between humans and ceiling), and not in accordance with generalization (lack of difference between humans and ceiling).</p><p>Whereas humans had shown divergent trajectories for parameter α- (Figure 2B; Table 1), the simulated agents did not show task differences for α- or any other parameter (suppl. Figure E.8B; suppl. Table E.8), even when controlling for age (suppl. Tables E.9 and E.10), as expected from a dataset of generalizing agents. Furthermore, the same parameters were predictive between tasks in all cases (suppl. Table E.11). These results show that our method reliably detected parameter generalization in a dataset that exhibited generalization.</p><p>Lastly, we established whether the degree of generalization in humans was significantly different from agents. To this aim, we calculated the Spearman correlations between each pair of tasks for each parameter, for both humans (section 2.1.2; suppl. Figure H.9) and agents, and compared both using bootstrapped confidence intervals (suppl. Appendix E). Human parameter correlations were significantly below the ceiling for all parameters except α+ (A vs B) and epsilon / 1/β (A vs C; suppl. Figure E.8C). This suggests that humans were within the range of maximally detectable generalization in two cases, but showed less-than-perfect generalization between other task combinations and for parameters Forgetting and α-.”</p><disp-quote content-type="editor-comment"><p>[Essential revisions]: “Descriptions of the tasks that capture their distinguishing features through the lens of Markov Decision Process theory might be valuable to contextualize the current results within a broader reinforcement learning literature.”</p><p>[Reviewer #3]: “The current study was not designed for systematically varying different aspects of the MDP to see how this affects inferred parameter generalizability and interpretability, which is okay. But perhaps one step the paper can make in this direction of theoretical consistency is to explicitly name the features of each task from an MDP theory standpoint, or at least additionally include this as a table or additional panel in Figure 1. E.g. size of state and action space (+ mapping to &quot;set size&quot; jargon), reward function, etc. Authors do this at several points in the paper (including the appendix), and this can only help as a practice that allows the RL community to think about tasks in a common way. In the present study, this convention can illuminate why the tasks presented here are actually quite different from one another. Task A: 4 states (1 per trial), 2 actions (visible on screen), stable stochastic reward function; Task B: stateless, 2 actions, reversal in stochastic reward function; Task C: RL-WM task: 2-5 states (1 per trial), 3 actions (not visible on screen), stable deterministic reward function.”</p></disp-quote><p>We thank the reviewer for this comment, and will address both points in turn:</p><p>1) We agree with the reviewer's sentiment about relative generalizability: If we all interpreted our models exclusively with respect to our specific task design, and never expected our results to generalize to other tasks or models, there would not be a problem. However, the current literature shows a different pattern: Literature reviews, meta-analyses, and Discussion sections of empirical papers regularly compare specific findings between studies. We compare specific parameter values (e.g., empirical parameter priors), parameter trajectories over age, relationships between different parameters (e.g., balance between LR+ and LR-), associations between parameters and clinical symptoms, and between model variables and neural measures on a regular basis. The goal of this paper was really to see if and to what degree this practice is warranted. And the reviewer rightfully alerted us to the fact that our data imply that these assumptions might be valid in some cases, just not in others.</p><p>2) With regard to providing task descriptions that relate to the MDP framework, we have included the following sentence in the Discussion section:</p><p>“Our results show that discrepancies are expected even with a consistent methodological pipeline, and using up-to-date modeling techniques, because they are an expected consequence of variations in experimental tasks and computational models (together called &quot;context&quot;). Future research needs to investigate these context factors in more detail. For example, which task characteristics determine which parameters will generalize and which will not, and to what extent? Does context impact whether parameters capture overlapping versus distinct variance? A large-scale study could answer these questions by systematically covering the space of possible tasks, and reporting the relationships between parameter generalizability and distance between tasks. To determine the distance between tasks, the MDP framework might be especially useful because it decomposes tasks along theoretically meaningful features of the underlying Markov Decision Process.”</p><disp-quote content-type="editor-comment"><p>[Reviewer #3]: “Finally, I think it is important to provide a bit more detail upfront about the training and instructions protocol for each task, and, to the extent that it is possible, provide evidence that instruction comprehension is not related to parameter differences. One simple analysis here would be to examine the &quot;lose-stay&quot; distribution in Tasks B and C and look for any evidence of bimodality that can be traced to how instructions were presented. I would also be curious if this distribution varies with age, potentially explaining the striking divergence in age trajectories for LR- in Tasks B and C.”</p></disp-quote><p>We are happy to hear the reviewer's general agreement to our interpretation of the results with regard to LR- task differences, and appreciate the reviewer's suggested alternative explanation. Indeed, if participants assumed (wrongly) that feedback was stochastic in task C, elevated values of LR- on this task might reflect a misunderstanding of task instructions, rather than learning from negative feedback, and the resulting difference in what LR- captures across tasks would lead to a decrease in generalizability. In order to address this issue, we will address each of the reviewer's points in turn:</p><p>(1) The task order was identical for all participants and is described in the section “Testing Procedure” in the Methods. The order was: task C; break; task A; task B. Because task B was presented after task C, global strategies could not have transferred from task B to task C.</p><p>(2) We have now added more specific information about training and task instructions to section “4.4. Task Design” in the Methods section (also see Appendix C). Because the instructions and training differed between tasks and accommodated for the younger population in multiple ways, we cannot explain everything in the current paper, but we refer the interested reader to the original publications:</p><p>“Task A (&quot;Butterfly task&quot;)</p><p>The goal of task A was to collect as many points as possible, by guessing correctly which of two flowers was associated with each of four butterflies. Participants were instructed to guess which flower each butterfly liked more, having been told that butterflies would sometimes also choose the less-liked flower (i.e., act probabilistically). Correct guesses were rewarded with 70% probability, and incorrect guesses with 30%. The task contained 120 trials (30 for each butterfly) that were split into 4 equal-sized blocks, and took between 10-20 minutes to complete. More detailed information about methods and results can be found in […].</p><p>Task B (&quot;Stochastic Reversal&quot;)</p><p>The goal of task B was to collect golden coins, which were hidden in two green boxes. Participants completed a child-friendly tutorial, in which they were instructed to help a leprechaun find his treasure by collecting individual coins from two boxes. Task volatility (i.e., boxes switching sides) and stochasticity (i.e., correct box not rewarded each time) were introduced one-by-one (for details, see […]). The task could be in one of two states: &quot;Left box is correct&quot; or &quot;Right box is correct&quot;. In the former, selecting the left box led to reward in 75\% of trials, while selecting the right box never led to a reward (0\%). Several times throughout the task, task contingencies changed unpredictably and without notice (after participants had reached a performance criterion indicating they had learned the current state), and the task switched states. Participants completed 120 trials of this task (2-9 reversals), which took approximately 5-15 minutes. For more information and additional task details, refer to […].</p><p>Task C (&quot;Reinforcement Learning-Working Memory&quot;)</p><p>The goal of task C was to collect as many points as possible by pressing the correct key for each stimulus. Participants were instructed to learn an &quot;alien language&quot; of key presses by associating individual pictures with specific key presses. Pressing the correct key for a specific picture deterministically led to reward, and the correct key for a stimulus never changed. Stimuli appeared in blocks that varied in the number of different stimuli, with set sizes ranging from 2-5. In each block, each stimulus was presented 12-14 times, for a total of 13 * set size trials per block. Three blocks were presented for set sizes 2-3, and 2 blocks were presented for set sizes 4-5, for a total of 10 blocks. The task took between 15-25 minutes to complete. For more details, as well as a full analysis of this dataset, refer to […].”</p><p>(1) We examined the “lose-stay” distributions of tasks B and C, but did not find evidence of bimodality:</p><fig id="sa2fig4" position="float"><label>Author response image 4.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-75474-sa2-fig4-v1.tif"/></fig><p>Figure C.6 in the paper shows the age trajectories of lose-stay behavior over age, and we do not see increased error bars for the younger participants, which we would expect if there was increased bimodality at that age:</p></body></sub-article></article>