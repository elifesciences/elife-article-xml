<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">60563</article-id><article-id pub-id-type="doi">10.7554/eLife.60563</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural signatures of vigilance decrements predict behavioural errors before they occur</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-195367"><name><surname>Karimi-Rouzbahani</surname><given-names>Hamid</given-names></name><contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2694-3595</contrib-id><email>hamid.karimi-rouzbahani@mrc-cbu.cam.ac.uk</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-142346" equal-contrib="yes"><name><surname>Woolgar</surname><given-names>Alexandra</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-130747" equal-contrib="yes"><name><surname>Rich</surname><given-names>Anina N</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Perception in Action Research Centre, Faculty of Human Sciences, Macquarie University</institution><addr-line><named-content content-type="city">Sydney</named-content></addr-line><country>Australia</country></aff><aff id="aff2"><label>2</label><institution>Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution>Department of Cognitive Science, Faculty of Human Sciences, Macquarie University</institution><addr-line><named-content content-type="city">Sydney</named-content></addr-line><country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Kok</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Radboud University</institution><country>Netherlands</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>08</day><month>04</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e60563</elocation-id><history><date date-type="received" iso-8601-date="2020-07-03"><day>03</day><month>07</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-04-02"><day>02</day><month>04</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Karimi-Rouzbahani et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Karimi-Rouzbahani et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-60563-v3.pdf"/><abstract><p>There are many monitoring environments, such as railway control, in which lapses of attention can have tragic consequences. Problematically, sustained monitoring for rare targets is difficult, with more misses and longer reaction times over time. What changes in the brain underpin these ‘vigilance decrements’? We designed a multiple-object monitoring (MOM) paradigm to examine how the neural representation of information varied with target frequency and time performing the task. Behavioural performance decreased over time for the rare target (monitoring) condition, but not for a frequent target (active) condition. There was subtle evidence of this also in the neural decoding using Magnetoencephalography: for one time-window (of 80ms) coding of critical information declined more during monitoring versus active conditions. We developed new analyses that can predict behavioural errors from the neural data more than a second before they occurred. This facilitates pre-empting behavioural errors due to lapses in attention and provides new insight into the neural correlates of vigilance decrements.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>visual attention</kwd><kwd>magnetoencephalography</kwd><kwd>multi-variate pattern analysis</kwd><kwd>informational connectivity</kwd><kwd>vigilance decrements</kwd><kwd>error prediction</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>DP170101780</award-id><principal-award-recipient><name><surname>Rich</surname><given-names>Anina N</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000923</institution-id><institution>Australian Research Council</institution></institution-wrap></funding-source><award-id>FT170100105</award-id><principal-award-recipient><name><surname>Woolgar</surname><given-names>Alexandra</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100008134</institution-id><institution>The Royal Society</institution></institution-wrap></funding-source><award-id>NIF\R1\192608</award-id><principal-award-recipient><name><surname>Karimi-Rouzbahani</surname><given-names>Hamid</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000265</institution-id><institution>Medical Research Council</institution></institution-wrap></funding-source><award-id>SUAG/052/G101400</award-id><principal-award-recipient><name><surname>Woolgar</surname><given-names>Alexandra</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Declined coding of sensory information in the brain reflects human vigilance decrements and allows prediction of behavioural errors.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>When people monitor displays for rare targets, they are slower to respond and more likely to miss those targets relative to frequent target conditions (<xref ref-type="bibr" rid="bib73">Wolfe et al., 2005</xref>; <xref ref-type="bibr" rid="bib70">Warm et al., 2008</xref>; <xref ref-type="bibr" rid="bib57">Rich et al., 2008</xref>; <xref ref-type="bibr" rid="bib55">Reason, 1990</xref>; <xref ref-type="bibr" rid="bib56">Reason, 2000</xref>). This effect is more pronounced as the time doing the task increases, which is often called a ‘vigilance decrement’. Theoretical accounts of vigilance decrements fall into two main categories. ‘Cognitive depletion’ theories suggest performance drops as cognitive resources are ‘used up’ by the difficulty of sustaining attention under vigilance conditions (<xref ref-type="bibr" rid="bib28">Helton and Warm, 2008</xref>; <xref ref-type="bibr" rid="bib27">Helton and Russell, 2011</xref>; <xref ref-type="bibr" rid="bib70">Warm et al., 2008</xref>). In contrast, ‘mind wandering’ theories suggest that the boredom of the task tends to result in insufficient involvement of cognitive resources, which in turn leads to performance decrements (<xref ref-type="bibr" rid="bib44">Manly et al., 1999</xref>; <xref ref-type="bibr" rid="bib64">Smallwood and Schooler, 2006</xref>; <xref ref-type="bibr" rid="bib80">Young and Stanton, 2002</xref>). Either way, there are many real-life situations where such a decrease in performance over time can lead to tragic consequences, such as the Paddington railway disaster (UK, 1999), in which a slow response time to a stop signal resulted in a train moving another 600 m past the signal into the path of an oncoming train. With the move towards automated and semi-automated systems in many high-risk domains (e.g., power-generation and trains), humans now commonly need to monitor systems for infrequent computer failures or errors. These modern environments challenge our attentional systems and make it urgent to understand the way in which monitoring conditions change the way important information about the task is encoded in the human brain.</p><p>To date, most vigilance and rare target studies have used simple displays with static stimuli. Traditional vigilance tasks, inspired by radar operators in WWII, require participants to respond to infrequent visual events on otherwise blank screens, and show more targets are missed as time on task increases (<xref ref-type="bibr" rid="bib43">Mackworth, 1948</xref>). More recent vigilance tasks have participants detect infrequent target stimuli among non-targets, and typically show an increase in misses as time on task increases. In <xref ref-type="bibr" rid="bib67">Temple et al., 2000</xref>, for example, with only 20% targets, after 10 min target detection rates declined from 97% to 93% for high contrast (easy) and from 95% to 83% for low (hard) contrast targets. Other approaches have been to test for vigilance effects using frequent responses to non-targets, which have the advantage of more data points for analysis. The Sustained Attention to Response Task (SART), for example, requires participants to respond to each non-target item in a rapid stream of stimuli and occasionally withhold a response to a target item (<xref ref-type="bibr" rid="bib6">Beck et al., 1956</xref>; <xref ref-type="bibr" rid="bib58">Rosenberg et al., 2013</xref>). These approaches usually show effects on reaction times (RTs), which increase and become more variable with time on task (<xref ref-type="bibr" rid="bib58">Rosenberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib46">Möckel et al., 2015</xref>; <xref ref-type="bibr" rid="bib63">Singleton, 1953</xref>), although others have found RTs decrease (<xref ref-type="bibr" rid="bib60">Rubinstein, 2020</xref>). Faster RTs also occur for ‘target absent’ responses in rare target visual search (<xref ref-type="bibr" rid="bib73">Wolfe et al., 2005</xref>; <xref ref-type="bibr" rid="bib57">Rich et al., 2008</xref>). Overall, vigilance decrements in terms of poorer performance can be seen in both accuracy and in RTs, depending on the task.</p><p>Despite these efforts, modern environments (e.g., rail and air traffic control) have additional challenges not encapsulated by these measures. This includes multiple moving objects, potentially appearing at different times, and moving simultaneously in different directions. When an object moves in the space, its neural representation has to be continuously updated so we can perceive the object as having the same identity. Tracking moving objects also requires considerable neural computation: in addition to spatial remapping, for example, we need to predict direction, speed, and the distance of the object to a particular destination. These features cannot be studied using static stimuli; they require objects that shift across space over time. In addition, operators have complex displays requiring selection of some items while ignoring others. We therefore need new approaches to study vigilance decrements in situations that more closely resemble the real-life environments in which humans are now operating. Developing these methods will provide a new perspective on fundamental questions of how the brain implements sustained attention in moving displays, and the way in which monitoring changes the encoding of information compared with active task involvement. These new methods may also provide avenues to optimise performance in high-risk monitoring environments.</p><p>The brain regions involved in maintaining attention over time has been studied using functional magnetic resonance imaging (fMRI), which measures changes in cerebral blood flow (<xref ref-type="bibr" rid="bib1">Adler et al., 2001</xref>; <xref ref-type="bibr" rid="bib7">Benedict et al., 2002</xref>; <xref ref-type="bibr" rid="bib11">Coull et al., 1996</xref>; <xref ref-type="bibr" rid="bib21">Gilbert et al., 2006</xref>; <xref ref-type="bibr" rid="bib31">Johannsen et al., 1997</xref>; <xref ref-type="bibr" rid="bib52">Ortuño et al., 2002</xref>; <xref ref-type="bibr" rid="bib53">Périn et al., 2010</xref>; <xref ref-type="bibr" rid="bib62">Schnell et al., 2007</xref>; <xref ref-type="bibr" rid="bib65">Sturm et al., 1999</xref>; <xref ref-type="bibr" rid="bib66">Tana et al., 2010</xref>; <xref ref-type="bibr" rid="bib68">Thakral and Slotnick, 2009</xref>; <xref ref-type="bibr" rid="bib72">Wingen et al., 2008</xref>). These studies compared brain activation in task vs. resting baseline or sensorimotor control (which involved no action) conditions and used univariate analyses to identify regions with higher activation under task conditions. This has the limitation that there are many features that differ between the contrasted (subtracted) conditions, not just the matter of sustained attention. Specifically, this comparison cannot distinguish whether the activation during sustained attention is caused by the differences in the task, stimuli, responses, or a combination of these factors. As it is challenging to get sufficient data from monitoring (vigilance) tasks in the scanner, many previous studies used tasks with relatively frequent targets, in which vigilance decrements usually do not occur. However, despite these challenges, <xref ref-type="bibr" rid="bib40">Langner and Eickhoff, 2013</xref> reviewed vigilance neuroimaging studies and identified a network of right-lateralised brain regions including dorsomedial, mid- and ventrolateral prefrontal cortex, anterior insula, parietal and a few subcortical areas that they argue form the core network subserving vigilant attention in humans. The areas identified by <xref ref-type="bibr" rid="bib40">Langner and Eickhoff, 2013</xref> show considerable overlap with a network previously identified as being recruited by many cognitively challenging tasks, the ‘multiple demand’ (MD) regions, which include the right inferior frontal gyrus, anterior insula, and intra-parietal sulcus (<xref ref-type="bibr" rid="bib16">Duncan and Owen, 2000</xref>; <xref ref-type="bibr" rid="bib15">Duncan, 2010</xref>; <xref ref-type="bibr" rid="bib20">Fedorenko et al., 2013</xref>; <xref ref-type="bibr" rid="bib75">Woolgar et al., 2011</xref>; <xref ref-type="bibr" rid="bib76">Woolgar et al., 2015a</xref>; <xref ref-type="bibr" rid="bib77">Woolgar et al., 2015b</xref>).</p><p>Other fMRI studies of vigilance have focused on the default mode network, composed of discrete areas in the lateral and medial parietal, medial prefrontal, and medial and lateral temporal cortices such as posterior cingulate cortex (PCC) and ventral anterior cingulate cortex (vACC), which is thought to be active during ‘resting state’ and less active during tasks (<xref ref-type="bibr" rid="bib24">Greicius et al., 2003</xref>; <xref ref-type="bibr" rid="bib25">Greicius et al., 2009</xref>; <xref ref-type="bibr" rid="bib54">Raichle, 2015</xref>). <xref ref-type="bibr" rid="bib17">Eichele et al., 2008</xref> suggested that lapses in attention can be predicted by decrease of deactivation of this default mode network. In contrast, <xref ref-type="bibr" rid="bib71">Weissman et al., 2006</xref> identified deactivation in the anterior cingulate and right prefrontal regions in pre-stimulus time windows when targets were missed. <xref ref-type="bibr" rid="bib19">Ekman et al., 2012</xref> also observed decreased connectivity between sensory visual areas and frontal brain areas on the pre-stimulus time span of incorrect trials in colour/motion judgement tasks. More recently, <xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2015</xref> showed that the functional connectivity between sensory and ‘vigilance-related’ (cingulo-opercular) brain areas decreased prior to behavioural misses in an auditory task while between the same sensory area and the default-mode network the connectivity increased. These findings suggest that modulation of interactions between sensory and vigilance-related brain areas might be related to behavioural misses in monitoring tasks.</p><p>Detecting changes in brain activation that correlate with lapses of attention can be particularly challenging with fMRI, given that it has poor temporal resolution. Electroencephalography (EEG), which records electrical activity at the scalp, has much better temporal resolution, and has been the other major approach for examining changes in brain activity during sustained attention tasks. Frequency band analyses have shown that low-frequency alpha (8–10.9 Hz) oscillations predict task workload and performance during monitoring of simulated air traffic (static) displays with rare targets, while frontal theta band (4–7.9 Hz) activity predicts task workload only in later stages of the experiment (<xref ref-type="bibr" rid="bib32">Kamzanova et al., 2014</xref>). Other studies find that increases in occipital alpha oscillations can predict upcoming error responses (<xref ref-type="bibr" rid="bib45">Mazaheri et al., 2009</xref>) and misses (<xref ref-type="bibr" rid="bib51">O'Connell et al., 2009</xref>) in go/no-go visual tasks with target frequencies of 11% and 9%, respectively. These changes in signal power that correlate with the task workload or behavioural outcome of trials are useful, but provide relatively coarse-level information about what changes in the brain during vigilance decrements.</p><p>Understanding the neural basis of decreases in performance over time under vigilance conditions is not just theoretically important, it also has potential real-world applications. In particular, if we could identify a reliable neural signature of attentional lapses, then we could potentially intervene prior to any overt error. For example, with the development of autonomous vehicles, being able to detect when a driver is not engaged, combined with information about a potential threat, could allow emergency braking procedures to be initiated. Previous studies have used physiological measures such as pupil size (<xref ref-type="bibr" rid="bib79">Yoss et al., 1970</xref>), body temperature (<xref ref-type="bibr" rid="bib48">Molina et al., 2019</xref>), skin conductance, and blood pressure (<xref ref-type="bibr" rid="bib42">Lohani et al., 2019</xref>) to indicate the level of human arousal or alertness, but these lack the fine-grained information necessary to distinguish transient dips from problematic levels of inattention in which task-related information is lost. In particular, we lack detail on how information processing changes in the brain during vigilance decrements. This knowledge is crucial to develop a greater understanding of how humans sustain vigilance.</p><p>In this study, we developed a new task, multiple-object monitoring (MOM), which includes key features of real-life situations confronting human operators in high-risk environments. These features include moving objects, varying levels of target frequency, and a requirement to detect and avoid collisions. A key feature of our MOM task is that it allows measurement of the specific decrements in performance during vigilance (sustaining attention in a situation where only infrequent responses are needed) separate from more general decreases in performance simply due to doing a task for an extended period. Surprisingly, this is not typically the case in vigilance tasks. We recorded neural data using the highly sensitive method of magnetoencephalography (<xref ref-type="bibr" rid="bib4">Baillet, 2017</xref>) and used multivariate pattern analyses (MVPA) to determine how behavioural vigilance decrements correlate with changes in the neural representation of information. We used these new approaches to better understand the way in which changes between active and monitoring tasks affect neural representation, including functional connectivity. We then examined the potential for using these neural measures to predict forthcoming behavioural misses based on brain activity.</p></sec><sec sec-type="results" id="s2"><title>Results</title><p>Participants completed the MOM task during which they monitored several dots moving on visible trajectories towards a centrally presented fixed object (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). The trajectories spanned from corners of the screen towards the central object and deflected at 90° before contacting the central object. The participants’ task was to keep fixation on the central object and press the button to deflect the moving dot if it violated its trajectory and continued towards the central object after reaching the deflection point. They were tasked to do so before the object ‘collided’ with the central object. In each block, only dots of one colour (either green or red; called Attended vs. Unattended) was relevant and should be responded to by the participants (~110 s). Either 50% or 6% of the attended dots (cued colour) were targets (i.e., violated their trajectory requiring a response; see Materials and methods) generating <italic>Active</italic> and <italic>Monitoring</italic> conditions, respectively.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The multiple-object monitoring (MOM) task and types of information decoded.</title><p>(<bold>A</bold>) At the start of a block, the relevant colour is cued (here, green; distractors in red). Over the on-task period (~30 min per task condition), multiple dots entered from either direction, each moving along a visible individual trajectory towards the middle object. Only attended dots that failed to deflect along the trajectories at the deflection point required a response (Target: bottom right display). Participants did not need to press the button for the unattended dot (Distractor: top right display) or the dots that kept moving on the trajectories (Event: middle right panel). Each dot took ~1226 ms from appearance to deflection. (<bold>B</bold>) Direction of approach information (left display: left vs. right as indicated by dashed and solid lines, respectively) and distance to object information (right display). Note the blue dashed lines and orange arrows were not present in the actual display. d1, d2, etc. denote the ‘distance units’ used to train the classifier for the key distance to object information. A demo of the task can be found here [<ext-link ext-link-type="uri" xlink:href="https://osf.io/5aw8v/">https://osf.io/5aw8v/</ext-link>].</p></caption><graphic xlink:href="elife-60563-fig1-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><sec id="s2-1"><title>Behavioural data: The MOM task evokes a reliable vigilance decrement</title><p>In the first block of trials (i.e., the first 110 s, excluding the two practice blocks), participants missed 29% of targets in the Active condition and 40% of targets in the Monitoring condition. However, note the number of targets in any single block is necessarily very low for the Monitoring (for a single block, there are 16 targets for Active but only two targets for Monitoring). The pattern becomes more robust over blocks, and <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows the miss rates changed over time in different directions for the Active vs. Monitoring conditions. For Active blocks, miss rates decreased over the first five blocks and then plateaued at ~17%. For Monitoring, however, miss rates increased throughout the experiment: by the final block, these miss rates were up to 76% (but again, the low number of targets in Monitoring mean that we should use caution in interpreting the results of any single block alone). There was evidence that miss rates were higher in the Monitoring than Active conditions from the fourth block onwards (BF &gt;3; <xref ref-type="fig" rid="fig2">Figure 2A</xref>). Participants’ RTs on <italic>correct</italic> trials also showed evidence of specific vigilance decrements, increasing over time under Monitoring but decreasing under Active task conditions (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). There was evidence that RTs were slower for Monitoring compared with Active from the sixth block onwards (BF &gt;3, except for Block #11). The characteristic pattern of increasing miss rates and slower RTs over time in the Monitoring relative to the Active condition validates the MOM task as effectively evoking vigilance decrements.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Behavioural performance on the MOM task.</title><p>The percentage of miss trials (<bold>A</bold>), and correct reaction times (<bold>B</bold>), as a function of block. Thick lines show the average across participants (shading 95% confidence intervals) for Active (blue) and Monitoring (red) conditions. Each block lasted for 110 s and had either 16 (Active) or 2 (Monitoring) targets out of 32 cued-colour and 32 non-cued colour dots. Bayes factors (BF) are shown in the bottom section of each graph: Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence when evaluating the contrast between Active and Monitoring conditions.</p></caption><graphic xlink:href="elife-60563-fig2-v3.tif" mimetype="image" mime-subtype="tiff"/></fig></sec><sec id="s2-2"><title>Neural data: Decoding different aspects of task-related information</title><p>We used multivariate pattern analysis (i.e., decoding) to extract two types of information from MEG data about each dot’s movement on the screen: information about the <italic>direction of approach</italic> (whether the dot was approaching the central object from left or right side of the screen) and <italic>distance to object</italic> (how far was the dot relative to the central object; <xref ref-type="fig" rid="fig1">Figure 1B</xref>; see Materials and methods).</p><p>With so much going on in the display at one time, we first needed to verify that we can successfully decode the major aspects of the moving stimuli, relative to chance. The full data figures and details are presented in Supplementary materials: We were able to decode both <italic>direction of approach</italic> and <italic>distance to object</italic> from MEG signals (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Thus, we can turn to our main question about how these representations were affected by the Target Frequency, Attention, and Time on Task.</p></sec><sec id="s2-3"><title>The neural correlates of the vigilance decrement</title><p>As the behavioural results showed (<xref ref-type="fig" rid="fig2">Figure 2</xref>), the difference between Active and Monitoring conditions increased over time, showing the greatest difference during the final blocks of the experiment. To explore the neural correlates of these vigilance decrements, we evaluated information representation in the brain during the first five and last five blocks of each task (called early and late blocks, respectively) and the interactions between the Target Frequency, Attention, and the Time on Task using a three-way Bayes factor ANOVA.</p></sec><sec id="s2-4"><title>Effects of target frequency on <italic>direction of approach</italic> information</title><p><italic>Direction of approach</italic> information is a very clear visual signal (‘from the left’ vs. ‘from the right’) and therefore is unlikely to be strongly modulated by other factors, except perhaps whether the dot was in the cued colour (Attended) or the distractor colour (could be ignored: Unattended). There was moderate or strong evidence for a main effect of Attention (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; BF &gt;3, Bayes factor ANOVA, cyan dots) starting from 265 ms and lasting until dots faded. This is consistent with maintenance of information about the attended dots and attenuation of the information about unattended dots (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). The large difference in coding attributable to attention remained for as long as the dots were visible.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Impact of different conditions and their interactions on information on correct trials (all trials except those in which a target was missed or there was a false alarm).</title><p>(<bold>A</bold>) Decoding of direction of approach information (less task-relevant) and (<bold>B</bold>) decoding of distance to object information (most task-relevant). Left two columns: Attended dots; Right two columns: Unattended (‘distractor’) dots. Thick lines show the average across participants (shading 95% confidence intervals). Horizontal dashed line refers to theoretical chance-level decoding (50%). Vertical dashed lines indicate critical times in the trial. Bottom panels: Bayesian evidence for main effects and interactions, Bayes factors (BF): Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence. Main effects and interactions of conditions calculated using BF ANOVA analysis. Cyan, purple, green, and red dots indicate the main effects of Attention, Target frequency, Time on Task, and the interaction between Target frequency and Time on Task, respectively. The results of BF analysis (i.e., the main effects of the three conditions and their interactions) are from the same three-way ANOVA analysis and are therefore identical for attended and unattended panels. Early = data from the first five blocks (~10 min). Late = data from the last five blocks (~10 min). Note the different scales of the BF panels, and the down-sampling, for clearer illustration.</p></caption><graphic xlink:href="elife-60563-fig3-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Impact of different conditions in the direction of approach and distance to object information coding and their Bayesian evidence for difference from chance.</title><p>Two left graphs: Attended dots; Two right graphs: Unattended (‘distractor’) dots. (<bold>A</bold>) Decoding of direction of approach information (less task-relevant). (<bold>B</bold>) Decoding of distance to object information (most task-relevant). Thick lines show the average across participants (shading 95% confidence intervals). The horizontal dashed lines refer to chance-level decoding. Vertical dashed lines indicate critical times in the trial. Bayes factors (BF) are shown in the bottom section of each graph: Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence. They show the results of BF analysis when evaluating the difference of the decoding values from chance as explained in Materials and methods. Early = data from the first five blocks (~10 min). Late = data from the last five blocks (~10 min). Note the different scales of the BF panels, and the down-sampling, for clearer illustration.</p></caption><graphic xlink:href="elife-60563-fig3-figsupp1-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Impact of different conditions and their interactions on information processing on correct trials (all trials except those in which a target was missed or there was a false alarm) without and with standard eye-artefact removal.</title><p>Left and right panels show the results without (repeated from <xref ref-type="fig" rid="fig3">Figure 3</xref>) and with eye-standard eye-artefact removal, respectively. (<bold>A</bold>) Decoding of direction of approach information (less task-relevant) and (<bold>B</bold>) decoding of distance to object information (most task-relevant). Left two columns: Attended dots; Right two columns: Unattended (‘distractor’) dots. Thick lines show the average across participants (shading 95% confidence intervals). Horizontal dashed line refers to theoretical chance-level decoding (50%). Vertical dashed lines indicate critical times in the trial. Bottom panels: Bayesian evidence for main effects and interactions, Bayes factors (BF): Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence. Main effects and interactions of conditions calculated using BF ANOVA analysis. Cyan, purple, green, and red dots indicate the main effects of Attention, Target frequency, Time on Task, and the interaction between Target frequency and Time on Task, respectively. The results of BF analysis (i.e., the main effects of the three conditions and their interactions) are from the same three-way ANOVA analysis and are therefore identical for attended and unattended panels. Early = data from the first five blocks (~10 min). Late = data from the last five blocks (~10 min). Note the different scales of the BF panels, and the down-sampling, for clearer illustration.</p></caption><graphic xlink:href="elife-60563-fig3-figsupp2-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>The statistical relationship between the proportion of eye-related measures and Target Frequency, Attention, and Time on the task factors.</title><p>(<bold>A</bold>) Eye-related measures. The error bars show 95% confidence interval around the mean across participants. (<bold>B</bold>) Bayes factor evidence for the main effects and interactions between factors and eye-related measures.</p></caption><graphic xlink:href="elife-60563-fig3-figsupp3-v3.tif" mimetype="image" mime-subtype="tiff"/></fig></fig-group><p>In contrast, there was no sustained main effect of Target Frequency on the same <italic>direction of approach</italic> coding. For the majority of the epoch there was moderate or strong evidence for the null hypothesis (BF &lt;1/3; Bayes factor ANOVA, <xref ref-type="fig" rid="fig3">Figure 3A</xref>, purple dots). The sporadic time point with a main effect of Target Frequency, observed before the deflection (BF &gt;3), likely reflects noise in the data as there is no clustering. Recall that we only focus on time points prior to deflection, as after this point there are visual differences between Active and Monitoring, with more dots deflecting in the Monitoring condition.</p><p>There was also no sustained main effect of the Time on Task on information about the <italic>direction of approach</italic> (BF &lt;3; Bayes factor ANOVA, green dots; <xref ref-type="fig" rid="fig3">Figure 3A</xref>). There were no sustained two-way or three-way interactions between Attention, Target Frequency, and Time on Task (BF &lt;3; Bayes factor ANOVA). Note that the number of trials used in the training and testing of the classifiers were equalised across the eight conditions and equalled the minimum available number of trials across those conditions shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. Therefore, the observed effects cannot be attributed to a difference in the number of trials across conditions.</p></sec><sec id="s2-5"><title>Effects of target frequency on critical <italic>distance to object</italic> information</title><p>The same analysis for the representation of the task-relevant <italic>distance to object</italic> information showed strong evidence for a main effect of Attention (BF &gt; 10; Bayes factor ANOVA) at all 15 distances, no effect of Time on Task (BF &lt; 0.3; Bayes factor ANOVA) at any of the distances, and an interaction between Time on Task and Target Frequency at one of the distances (BF = 6.7, <xref ref-type="fig" rid="fig3">Figure 3B</xref>). The interaction between Target Frequency and Time on Task at distance 13 (time-window: 160 to 240 ms after stimulus onset, BF = 6.7) reflected opposite effects of time on task in the Active and Monitoring conditions. In Active blocks, there was moderate evidence that coding was stronger in late blocks than in early blocks (BF = 3.1), whereas in the Monitoring condition, decoding declined with time and was weaker in late than in easy blocks (BF = 4.3). However, as there was only moderate evidence for this interaction at one of the time-windows, we do not overinterpret it. Decoding of attended information tended to be lower in late compared to early Monitoring blocks (Figure 3B lower panel red dotted line) in several time-windows across the trial, which may echo the behavioural pattern of performance (Figure 2). As there was moderate evidence for no interaction between Attention and Target Frequency (BF &lt; 0.3, 2-way Bayes factor ANOVA) except for distance 6 (BF = 3.3; no consistent pattern (insufficient evidence for pairwise comparisons: BFs 2.4-2.8)), no interaction between Attention and Time on Task (BF &lt; 0.3, 2-way Bayes factor ANOVA) or simultaneously between the three factors (BF &lt; 0.3, 3-way Bayes factor ANOVA), we do not show those statistical results in the figure.</p><p>Although eye-movements should not drive the classifiers due to our design, it is still important to verify that the results replicate when standard artefact removal is applied. We can also use eye-movement data as an additional measure, examining blinks, saccades and fixations for effects of our attention and vigilance manipulations.</p><p>First, to make sure that our neural decoding results replicate after eye-related artefact removal, we repeated our analyses on the data after eye-artefact removal, which provided analogous results to the original analysis (see the decoding results with and without artefact removal in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Specifically, for our crucial <italic>distance to object</italic> data, the main effect of Attention remained after eye-artefact removal, replicating our initial pattern of results. Moderate evidence (BF = 4.2) for an interaction between Target Frequency and Time on Task was also found, but now at distance 6 instead of distance 13. This interaction again reflected a larger effect of Time on Task in Monitoring compared to Active blocks (Monitoring: weaker coding in late relative to early blocks (BF = 3.1); Active: insufficient evidence for change in coding from early to late (BF = 2.0)).</p><p>Second, we conducted a post hoc analysis to explore whether eye movement data showed the same patterns of vigilance decrements and therefore could explain our decoding results. We extracted the proportion of eye blinks, saccades, and fixations per trial as well as the duration of those fixations from the eye-tracking data for <italic>correct</italic> trials (−100 to 1400 ms aligned to the stimulus onset time), and statistically compared them across our critical conditions (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). We saw strong evidence (BF = 4.8e<sup>8</sup>) for a difference in the number of eye blinks between attention conditions: There were more eye blinks for the Unattended (distractor) than Attended (potentially targets) colour dots. We also observed moderate evidence (BF = 3.4) for difference between the number of fixations, with more fixations in Unattended vs. Attended conditions. These suggest that there are systematic differences in the number of eye blinks and fixations due to our attentional manipulation, consistent with previous observations showing that the frequency of eye blinks can be affected by the level of attentional recruitment (<xref ref-type="bibr" rid="bib49">Nakano et al., 2013</xref>). However, there was either insufficient evidence (0.3 &lt; BF &lt;3) or moderate or strong evidence for no differences (0.1 &lt; BF &lt;0.3 and BF &lt;0.3, respectively) between the number of eye blinks and saccades across our Active, Monitoring, Early, and Late blocks, where we observed our ‘vigilance decrement’ effects in decoding. Therefore, this suggests that the main vigilance decrement effects in decoding, which were evident as an interaction between Target frequency (Active vs. Monitoring) and Time on the task (Early vs. Late; <xref ref-type="fig" rid="fig3">Figure 3</xref>), are not primarily driven by eye movements. However, artefact removal algorithms are not perfect, making it is impossible to fully rule out all potentially meaningful eye-related artefacts from the MEG data (e.g. the difference in the number of eye blinks between attended and unattended conditions). Thus, although the results are similar with and without standard eye-artefact removal, it is impossible to fully rule out all potential eye movement effects.</p><p>Together, these results suggest that while vigilance conditions had little or no impact on coding of the <italic>direction of approach</italic>, they did impact the critically task-relevant information about the <italic>distance</italic> of the dot from the object, albeit only for one 80ms time-window. In this time-window, coding declined as time on task increased specifically when the target events happened infrequently, forming a possible neural correlate for our behavioural vigilance decrements.</p></sec><sec id="s2-6"><title>Is informational brain connectivity modulated by Attention, Target Frequency, and Time on Task?</title><p>Using graph-theory-based univariate connectivity analysis, it has been shown that the connectivity between relevant sensory areas and ‘vigilance-related’ cognitive areas changes prior to lapses in attention (behavioural errors; <xref ref-type="bibr" rid="bib19">Ekman et al., 2012</xref>; <xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2015</xref>). Therefore, we asked whether vigilance decrements across the time course of our task corresponded to changes in multivariate informational connectivity, which evaluates the similarity of information encoding, between frontal attentional networks and sensory visual areas. In line with attentional effects on sensory perception, we predicted that connectivity between the frontal attentional and sensory networks should be lower when not attending (vs. attending; <xref ref-type="bibr" rid="bib23">Goddard et al., 2019</xref>). Behavioural errors were also previously predicted by reduced connection between sensory and ‘vigilance-related’ frontal brain areas (<xref ref-type="bibr" rid="bib19">Ekman et al., 2012</xref>; <xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2015</xref>). Therefore, we predicted a decline in connectivity when targets were lower in frequency, and with increased time on task, as these led to increased errors in behaviour, specifically under vigilance conditions in our task (i.e., late blocks in Monitoring vs. late blocks in Active; <xref ref-type="fig" rid="fig2">Figure 2</xref>). We used a simplified version of our method of RSA-based informational connectivity to evaluate the (Spearman’s rank) correlation between <italic>distance</italic> information RDMs across the peri-frontal and peri-occipital electrodes (<xref ref-type="bibr" rid="bib22">Goddard et al., 2016</xref>; <xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Relationship between informational connectivity and Attention, Target Frequency, Time on Task, and the behavioural outcome of the trial (i.e., correct vs. miss).</title><p>(<bold>A</bold>) Calculation of connectivity using Spearman’s rank correlation between RDMs obtained from the peri-frontal and peri-occipital sensors as indicated by coloured boxes, respectively. RDMs include decoding accuracies obtained from testing the 105 classifiers trained to discriminate different distance to object categories. (<bold>B</bold>) Connectivity values for the eight different conditions of the task and the results of three-way Bayes factor ANOVA with factors Time on Task (Early, Late), Attention (Attended, Unattended), and Target Frequency (Active, Monitoring), using only correct trials. (<bold>C</bold>) Connectivity values for the Active and Monitoring, Early and Late blocks of each task for correct and miss trials (attended condition only), and the result of Bayes factor ANOVA with factors Target Frequency (Active, Monitoring), Time on Task (Early, Late), and behavioural outcome (correct, miss) as inputs. Number of trials are equalised across conditions in <bold>B</bold> and <bold>C</bold> separately. Bars show the average across participants (error bars 95% confidence intervals). Bold fonts indicate moderate or strong evidence for either the effect or the null hypothesis.</p></caption><graphic xlink:href="elife-60563-fig4-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><p>Results showed strong evidence (Bayes factor ANOVA, BF = 6.5e<sup>3</sup>) for higher informational connectivity for trials with Attended compared to Unattended dots, and moderate evidence for no effect of Target Frequency (Bayes factor ANOVA, BF = 0.11; <italic>Figure 4B</italic>). There was insufficient evidence to determine whether there was a main effect of Time on Task (Bayes factor ANOVA, BF = 0.72). There was evidence in the direction of the null for the two-way interactions between the factors (Bayes factor ANOVA, two-way Time on Task-Target Frequency: BF = 0.36; Time on Task-Attention: BF = 0.39; Target Frequency-Attention: BF = 0.15) and insufficient evidence regarding their three-way interaction (BF = 0.95). These results suggest that [--deleted text--] trials in which the dots are in the distractor (Unattended) colour, in which the attentional load is low, result in less informational connectivity between occipital and frontal brain areas compared to [--deleted text--] Attended trials. This is consistent with a previous study (<xref ref-type="bibr" rid="bib2">Alnæs et al., 2015</xref>), which suggested that large-scale functional brain connectivity depends on the attentional load, and might underpin or accompany the decrease in information decoding across the brain in the unattended condition., which suggested that large-scale functional brain connectivity depends on the attentional load, and might underpin or accompany the decrease in information decoding across the brain in these conditions.</p><p>We also compared the connectivity for the <italic>correct</italic> vs. <italic>miss</italic> trials (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). This analysis was performed only for Attended condition as there are no <italic>miss</italic> trials for Unattended condition, by definition. There was moderate evidence for no difference in connectivity on <italic>miss</italic> compared to <italic>correct</italic> trials (Bayes factor ANOVA, BF = 0.11). In addition, there was moderate evidence for no effect of Time on Task and Target Frequency (BF = 0.11 and BF = 0.10, respectively), as well as for two-way and three-way interactions between the three factors (Bayes factor ANOVA, Behaviour-Target Frequency: BF = 0.14; Behaviour-Time on Task: BF = 0.14; Target Frequency-Time on Task: BF = 0.15; their 3-way interaction BF = 0.14). Therefore, in contrast to an auditory monitoring task which showed decline in univariate graph-theoretic connectivity before behavioural errors (<xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2015</xref>), we observed no change in informational connectivity on error. Note that, the number of trials is equalized across the 8 conditions in each of our analyses separately.</p></sec><sec id="s2-7"><title>Is neural representation different on <italic>miss</italic> trials?</title><p>The results presented in <xref ref-type="fig" rid="fig3">Figure 3</xref>, which used only <italic>correct</italic> trials, showed changes due to target frequency to the representation of task-relevant information when the task was performed successfully. We next move on to our second question, which is whether these neural representations change when overt behaviour <italic>is</italic> affected, and therefore, whether we can use the neural activity as measured by MEG to predict behavioural errors before they occur. We used our method of error data analysis (<xref ref-type="bibr" rid="bib78">Woolgar et al., 2019</xref>) to examine whether the patterns of information coding on <italic>miss</italic> trials differed from <italic>correct</italic> trials. For these analyses we used only attended dots, as unattended dots do not have behavioural responses, and we matched the total number of trials in our implementation of correct and miss classification.</p><p>First, we evaluated the representation of the less relevant information – the <italic>direction of approach</italic> measure (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). The results for <italic>correct</italic> trials provided information dynamics very similar to the Attended condition in <xref ref-type="fig" rid="fig3">Figure 3A</xref>, except for higher overall decoding, which is explained by the inclusion of the data from the whole experiment (15 blocks) rather than just the five early and late blocks (note the number of trials is still matched to <italic>miss</italic> trials).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Decoding of information on correct vs miss trials.</title><p>(<bold>A</bold>) Decoding of direction of approach information (less task-relevant). (<bold>B</bold>) Decoding of distance to object information (most task-relevant). The horizontal dashed lines refer to theoretical chance-level decoding. Left panels: Decoding using correct trials; Right panels: Decoding using miss trials. In both right and left panels, the classifiers were trained on correct trials and tested on (left out) correct and all miss trials, respectively. Thick lines show the average across participants (shading 95% confidence intervals). Vertical dashed lines indicate critical events in the trial. Bayes factors (BF) are shown in the bottom section of each graph: Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence. They show the results of BF analysis when evaluating the difference of the decoding values from chance for Active (blue) and Monitoring (red) conditions separately, the comparison of the two conditions (green), and the comparison of correct and miss trials (black). Note that for the comparison of correct and miss trials, Active and Monitoring conditions were averaged separately. Note the different scales of the BF panels, and down-sampling, for clearer illustration.</p></caption><graphic xlink:href="elife-60563-fig5-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Distribution of decoding accuracies for every individual correct and miss trial in the Active and Monitoring conditions for all 21 subjects.</title><p><bold>A</bold> and <bold>B</bold> show the data for correct and miss trials, respectively. The percentages show the percentage of trials for which there was strong (BF &gt;10) evidence for above-chance decoding in Active and Monitoring conditions. (<bold>C</bold>) Difference between the decoding accuracies in the correct (<bold>A</bold>) and miss (<bold>B</bold>) trials as evaluated using Cohen’s d.</p></caption><graphic xlink:href="elife-60563-fig5-figsupp1-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Decoding of information on correct vs false alarm trials.</title><p>(<bold>A</bold>) Decoding of direction of approach information (less task-relevant). (<bold>B</bold>) Decoding of distance to object information (most task-relevant). The horizontal dashed lines refer to theoretical chance-level decoding. Left panels: Decoding using correct trials; Right panels: Decoding using false alarm trials. In both right and left panels, the classifiers were trained on correct trials and tested on (left out) correct and all false alarm trials, respectively. Thick lines show the average across participants (shading 95% confidence intervals). Vertical dashed lines indicate critical events in the trial. Bayes factors (BF) are shown in the bottom section of each graph: Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence. They show the results of BF analysis when evaluating the difference of the decoding values from chance for Active (blue) and Monitoring (red) conditions separately, the comparison of the two conditions (green) and the comparison of correct and false alarm trials (black). Note that for the comparison of correct and miss trials, Active and Monitoring conditions were averaged separately. Note the different scales of the BF panels, and the down-sampling, for clearer illustration.</p></caption><graphic xlink:href="elife-60563-fig5-figsupp2-v3.tif" mimetype="image" mime-subtype="tiff"/></fig></fig-group><p>For the <italic>direction of approach</italic> information, there was moderate or strong evidence (i.e., BF &gt;3) in both Active and Monitoring conditions after ~100 ms for above-chance decoding. However, when the classifiers were tested on <italic>miss</italic> trials, from onset to deflection, the pattern of information dynamics were different, even though we had matched the number of trials. Specifically, while the level of information was comparable to <italic>correct</italic> trials with spurious instances (but no sustained time windows) of difference (BF &gt;3 as indicated by black dots) before 500 ms, decoding traces were much noisier for <italic>miss</italic> trials with more variation across trials and between nearby time points (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Note that after the deflection, the visual signal is different for <italic>correct</italic> and <italic>miss</italic> trials, so the difference between their decoding curves (BF &gt;3) is not meaningful. These results suggest a noisier representation of <italic>direction of approach</italic> information for the missed dots compared to correctly deflected dots.</p><p>We then repeated the same procedure on the representation of the most task-relevant <italic>distance to object</italic> information on <italic>correct</italic> vs. <italic>miss</italic> trials (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). On <italic>correct</italic> trials, the <italic>distance</italic> information for both Active and Monitoring conditions was above chance (<xref ref-type="fig" rid="fig5">Figure 5B</xref> left panels; BF &gt; 10<sup>4</sup>). For <italic>miss</italic> trials, the corresponding <italic>distance</italic> information was still above chance (<xref ref-type="fig" rid="fig5">Figure 5B</xref> right panels; BF &gt; 10<sup>3</sup>) but the direct comparison revealed that distance information dropped on miss trials compared to correct trials (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; Black dots; BF &gt;3 across all distances; Active and Monitoring results were averaged for <italic>correct</italic> and <italic>miss</italic> trials separately before Bayes analyses).</p><p>In principle, the average decoding levels could be composed of ‘all or none’ misses or graded drops in information, and it is possible that on some miss trials there is a good representation but the target is missed for other reasons (e.g., a response-level error). As neural data are noisy and multivariate decoding needs cross-validation across subsamples of the data, and because each trial, at each distance, can only be classified correctly or incorrectly by a two-way classifier, we tend not to compare the decoding accuracies in a trial-by-trial manner, but rather on average (<xref ref-type="bibr" rid="bib26">Grootswagers et al., 2017</xref>). However, if we look at an individual data set and examine all the miss trials (averaged over the 15 distances and cross-validation runs) in our distance-to-object decoding, we can get some insights into the underlying distributions (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Results showed that, for all participants, the distribution of classifier accuracies for both correct and miss trials followed approximate normal distributions. However, while the distribution of decoding accuracies for correct trials was centred around 60%, the decoding accuracies for individual miss trials were centred around 56%. We evaluated the difference in the distribution of classification accuracies between the two types of trials using Cohen’s d. Cohen’s d ranged from 0 to 2.5 across participants and conditions. 14 out of 21 subjects showed moderate (d &gt; 0.5) to large (d &gt; 0.8; <xref ref-type="bibr" rid="bib10">Cohen, 1969</xref>) differences between the distribution of correct and miss trials in either Active or Monitoring condition or both. Therefore, although the miss trials vary somewhat in levels of information, only a minority of (&lt; 24%) miss trials are as informative as the least informative correct trials. These results are consistent with the interpretation that there was less effective representation of the crucial information about the distance from the object preceding a behavioural miss.</p><p>Please note that the results presented so far were from <italic>correct</italic> and <italic>miss</italic> trials and we excluded early, late, and wrong-colour <italic>false alarms</italic> to be more specific about the error type. However, the false alarm results (collapsed across all three types of false alarms) were very similar (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>) to those of the missed trials (<xref ref-type="fig" rid="fig5">Figure 5</xref>): noisy information about the <italic>direction of approach</italic> and at-chance information about the <italic>distance to object</italic>. This may suggest that both <italic>miss</italic> and <italic>false alarm</italic> trials are caused by impaired processing of information, or at least, are captured similarly by our decoding methods. The average number of <italic>miss</italic> trials was 58.17 (±21.63 SD) and false alarm trials was 65.94 (±21.13 SD; out of 1920 trials).</p></sec><sec id="s2-8"><title>Can we predict behavioural errors using neuroimaging?</title><p>Finally, we asked whether we could use this information to predict the behavioural outcome of each trial. To do so, we developed a new method that classified trials based on their behavioural outcomes (<italic>correct</italic> vs. <italic>miss</italic>) by asking how well a set of classifiers, pre-trained on <italic>correct</italic> trials, would classify the distance of the dot from the target (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). To achieve this, we used a second-level classifier which labelled a trial as <italic>correct</italic> or <italic>miss</italic> based on the average accumulated accuracies obtained for that dot at every distance from the first-level decoding classifiers which were trained on <italic>correct</italic> trials (<xref ref-type="fig" rid="fig6">Figure 6A,B</xref>). If the accumulated accuracy for the given dot at the given distance was less than the average accuracy obtained from testing on the validation set minus a specific threshold (based on standard deviation), the testing dot (trial) was labelled as <italic>correct</italic>, otherwise <italic>miss</italic>. In this analysis, the goal was to maximise the accuracy of predicting behaviour. For that purpose, we accumulated classification accuracies along the distances. Moreover, as each classifier performs a binary classification for each testing dot at each distance, the accumulation of classification accuracies also avoided the spurious classification accuracies to drive the decision, providing smooth ‘accumulated’ accuracies for predicting the behaviour. As <xref ref-type="fig" rid="fig6">Figure 6B</xref> shows, there was strong evidence (BF &gt;10) that decoding accuracy of distances was higher for <italic>correct</italic> than <italic>miss</italic> trials with the inclusion of more classifier accuracies as the dot approached from the corner of the screen towards the centre. This clear separation of accumulated accuracies for <italic>correct</italic> vs. <italic>miss</italic> trials allowed us to predict with above-chance accuracy the behavioural outcome of the ongoing trial (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). To find the optimal threshold for each participant, we evaluated the thresholds used for all other participants except for a single testing participant for whom we used the average of the best thresholds that led to highest prediction accuracy for other participants. This was ~0.4 standard deviation below the average accuracy on the other participants’ validation (correct trial) sets (<xref ref-type="fig" rid="fig6">Figure 6C</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Prediction of behavioural outcome (correct vs miss) trial-by-trial using decoding of distance to object information.</title><p>(<bold>A</bold>) Sample classifiers’ accuracies (correct or incorrect classification of current distance as indicated by colours) for a miss (left panel; average accuracy ≅ 43% when the dot reached the deflection point) and a correct trial (right panel; average accuracy ≅ 67% at the deflection point). The classifiers were trained on the data from correct trials and tested on the data from correct and miss trials. For the miss trials, around half the classifiers categorised the dot’s distance incorrectly by the time it reached the deflection point. (<bold>B</bold>) Accumulation of classifiers’ accuracies over decreasing dot distances/time to deflection. This shows stronger information coding of the crucial distance to object information on the correct trials over miss trials. A variable threshold used in (<bold>C</bold>) is shown as a green dashed line. (<bold>C</bold>) Prediction of behavioural outcome as a function of threshold and distance using a second-level behavioural outcome classification. Results showed highest prediction accuracies on the participant set at around the threshold of 0.4SD under the decoding level for correct validation trials, increasing at closer distances. (<bold>D</bold>) Accuracy of predicting behavioural outcome for the left-out participant using the threshold obtained from all the other participants as function of distance/time from the deflection point. Results showed successful (~=59%) prediction of behavioural outcome of the trial as early as 80 ms after stimulus appearance. Thick lines and shading refer to average and one standard deviation around the mean across participants, respectively. Bayes factors (BF) are shown in the bottom section of each graph: Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence (black dots under <bold>B</bold> and <bold>D</bold>).</p></caption><graphic xlink:href="elife-60563-fig6-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Accuracy of predicting behavioural outcome of trials in the early (first 5) vs late (last 5) blocks of trials before eye-blink removal.</title><p>Left column shows the result for the early and right shows the result for the late blocks. (<bold>A</bold>) Result of classifier accumulation of decoding accuracy. (<bold>B</bold>) Prediction accuracy and (<bold>C</bold>) same results (as in <bold>B</bold>) overlapping on the same plot with Bayes factor (BF) analysis of the difference. The details of this figure are identical to <xref ref-type="fig" rid="fig6">Figure 6B and D</xref>. BF in <bold>A</bold> and <bold>C</bold> show the evidence for and against the alternative of difference between the curves and the BFs in <bold>B</bold> reflect the evidence for and against the alternative for difference from chance.</p></caption><graphic xlink:href="elife-60563-fig6-figsupp1-v3.tif" mimetype="image" mime-subtype="tiff"/></fig></fig-group><p>The prediction accuracy of behavioural outcome was above chance level (59% vs. 50%; BF &gt; 10) even when the dot had only been on the screen for 80 ms, which corresponds to our furthest distance #15 (1160ms prior to deflection point; <xref ref-type="fig" rid="fig6">Figure 6D</xref>). The accuracy increased to 65.4% as the dot approached the centre of the screen, with ~64% accuracy with still 800 ms to go before required response. Importantly, the prediction algorithm showed generalisable results across participants; the threshold for decision obtained from the other participants could predict the accuracy of an independent participant’s behaviour using only their neural data.</p><p>The prediction of behavioural outcome (<xref ref-type="fig" rid="fig6">Figure 6</xref>) was performed using the data from the whole data set. To test if prediction accuracy depended on the stage of the experiment, we performed the behavioural prediction procedure on data sets obtained from the first 5 (early) and the last 5 (late) stages of the experiment separately (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). There was no evidence for a change in the prediction power in the late vs. early blocks of trials.</p></sec></sec><sec sec-type="discussion" id="s3"><title>Discussion</title><p>This study developed new methods to gain insights into how attention, the frequency of target events, and the time doing a task affect the representation of information in the brain. Our new MOM task evoked reliable specific vigilance decrements in both accuracy and RT in a situation that more closely resembles real-life modern tasks than classic vigilance tasks. Using the sensitive analysis method of MVPA, we showed that neural coding was stronger for attended compared to distractor information. There was also one time-window where the interaction between the time on the task and target frequency affected decoding, with a larger decline in coding under monitoring conditions, which may reflect a neural correlate of the behavioural vigilance decrements. We also developed a novel informational brain connectivity analysis, which showed that the correlation between information coding across peri-occipital and peri-frontal areas varied with different levels of attention but did not change with errors. Finally, we utilised our recent error data analysis to predict forthcoming behavioural misses based on the neural data. In the following sections, we explain each of these findings in detail and compare them with relevant literature.</p><p>First, the MOM task includes key features of real-world monitoring situations that are not usually part of other vigilance tasks (e.g., <xref ref-type="bibr" rid="bib43">Mackworth, 1948</xref>; <xref ref-type="bibr" rid="bib67">Temple et al., 2000</xref>; <xref ref-type="bibr" rid="bib6">Beck et al., 1956</xref>; <xref ref-type="bibr" rid="bib58">Rosenberg et al., 2013</xref>), and the results show clear evidence of vigilance decrements. Behavioural performance, measured with both RT and accuracy, deteriorated over time in Monitoring (infrequent targets) relative to Active (frequent targets) conditions. One important additional advantage of the MOM task over conventional vigilance tasks is that it allows us to be specific about the vigilance decrements (by comparing Active and Monitoring conditions) separate from general time on task effects which affect <italic>both</italic> Active and Monitoring conditions (c.f. <xref ref-type="fig" rid="fig3">Figure 3</xref>). These vigilance decrements demonstrate that the MOM task can be used to explore vigilance in situations more closely resembling modern environments, namely those involving moving stimuli and selection of relevant from irrelevant information, giving a useful tool for future research.</p><p>Second, the high sensitivity of MVPA to extract information from neural signals allowed us to investigate the temporal dynamics of information processing along the time course of each trial. The manipulation of attention showed a strong overall effect with enhanced representation of both the less important <italic>direction of approach</italic> and the most task-relevant <italic>distance to object</italic> information for cued dots, regardless of how frequent the targets were (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The improved representation of information under attention extends previous findings from us and others (<xref ref-type="bibr" rid="bib77">Woolgar et al., 2015b</xref>; <xref ref-type="bibr" rid="bib23">Goddard et al., 2019</xref>; <xref ref-type="bibr" rid="bib50">Nastase et al., 2017</xref>) to moving displays, in which the participants monitor multiple objects simultaneously. When targets were infrequent, modelling real-life monitoring situations, there was a strong behavioural drop in performance (i.e., vigilance effects in both accuracy and RT; <xref ref-type="fig" rid="fig2">Figure 2</xref>) and a hint in the brain activity data of a change in neural coding (namely one time-window showing evidence of an interaction between Target Frequency and Time on Task). We need more data to fully test this effect, however, our main finding is that of being able to use the difference in decoding between correct and miss trials to predict behaviour. Although the results replicated after standard eye-artefact removal, as algorithms of artefact removal are not perfect, there is still the possibility that our MEG data could be affected by some residual patterns of eye movements across conditions. In a real-world setting, it may be possible to combine information from the brain and eye-movements to further improve the prediction accuracy.</p><p>When people miss targets, they might process or encode the relevant sensory information <italic>less</italic> effectively than when they correctly respond to targets. This is consistent with our finding that on the majority of <italic>miss</italic> trials, there was <italic>less</italic> effective representation about the task-relevant information in the neural signal, in contrast to the consistently <italic>more</italic> effective representation on <italic>correct</italic> trials. Note that our vigilance decrement effects are defined as the difference between Active and Monitoring conditions, which allows us to be sure that we are not interpreting general task (e.g., participant fatigue) or hardware-related effects as vigilance decrements.</p><p>It is important to note that previous studies have tried other physiological/behavioural measures to determine participants’ vigilance or alertness, such as pupil size (<xref ref-type="bibr" rid="bib79">Yoss et al., 1970</xref>), response time variability (<xref ref-type="bibr" rid="bib58">Rosenberg et al., 2013</xref>), blood pressure and thermal energy (<xref ref-type="bibr" rid="bib42">Lohani et al., 2019</xref>) or even body temperature (<xref ref-type="bibr" rid="bib48">Molina et al., 2019</xref>). We used highly sensitive analysis of neuroimaging data so that we could address two questions that could not be answered using these more general vigilance measures. We tested for changes in the way information is processed in the brain, particularly testing for differences in the impact of monitoring on the relevance of the information, rather than whether the participants were vigilant and alert in general. Moreover, we could also investigate how the most relevant and less relevant information was affected by the target frequency and time on the task, to find neural correlates for the behavioural vigilance decrements observed in many previous studies (e.g., <xref ref-type="bibr" rid="bib13">Dehais et al., 2019</xref>; <xref ref-type="bibr" rid="bib73">Wolfe et al., 2005</xref>; <xref ref-type="bibr" rid="bib74">Wolfe et al., 2007</xref>; <xref ref-type="bibr" rid="bib32">Kamzanova et al., 2014</xref>; <xref ref-type="bibr" rid="bib29">Ishibashi et al., 2012</xref>). The less relevant information about direction of approach was modulated by attention, but its representation was not detectably affected by target frequency and time on task, and was noisier, but not noticeably attenuated, on error trials. The relative stability of these representations might reflect the large visual difference between stimuli approaching from the top left vs bottom right of the screen. In contrast, the task-relevant information of distance to object was affected by attention and was attenuated on errors. The difference might reflect the fact that only the distance information is relevant to deciding whether an item is a target, and/or the classifier having to rely on much more subtle differences to distinguish the distance categories, which collapsed over stimuli appearing on the left and right sides of the display, removing the major visual signal.</p><p>Our information-based brain connectivity method showed moderate evidence for no change in connectivity between correct and error trials. Informational connectivity is unaffected by differences in absolute levels of information encoding (e.g., lower coding on <italic>miss</italic> vs. <italic>correct</italic> trials). It could be sensitive to different levels of noise between conditions, but there was no evidence for that in this case. Apart from sensory information coding and sensory-based informational connectivity, which were evaluated here, there may be other correlates we have not addressed. Effects on response-level selection, for example, independently or in conjunction with sensory information coding, could also affect performance under vigilance conditions, and need further research.</p><p>Our connectivity method follows the recent major recent shift in literature from univariate to multivariate informational connectivity analyses (<xref ref-type="bibr" rid="bib22">Goddard et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Karimi-Rouzbahani et al., 2017</xref>; <xref ref-type="bibr" rid="bib3">Anzellotti and Coutanche, 2018</xref>; <xref ref-type="bibr" rid="bib23">Goddard et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Kietzmann et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Karimi-Rouzbahani et al., 2019</xref>; <xref ref-type="bibr" rid="bib5">Basti et al., 2020</xref>; <xref ref-type="bibr" rid="bib36">Karimi-Rouzbahani et al., 2021</xref>). This is in contrast with the majority of neuroimaging studies using univariate connectivity analyses which can miss existing connectivity across areas when encountering low-amplitude activity on individual sensors (<xref ref-type="bibr" rid="bib3">Anzellotti and Coutanche, 2018</xref>; <xref ref-type="bibr" rid="bib5">Basti et al., 2020</xref>). Informational connectivity, on the other hand, is measured either through calculating the correlation between temporally resolved patterns of decoding accuracies across a pair of areas (<xref ref-type="bibr" rid="bib12">Coutanche and Thompson-Schill, 2013</xref>) or the correlation between representational dissimilarity matrices (RDMs) obtained from a pair of areas (<xref ref-type="bibr" rid="bib37">Kietzmann et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Goddard et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Goddard et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Karimi-Rouzbahani et al., 2019</xref>; <xref ref-type="bibr" rid="bib36">Karimi-Rouzbahani et al., 2021</xref>). Either one measures how much similarity in information coding there is between two brain areas across conditions, which is interpreted as reflecting their potential informational connectivity, and is less affected by absolute activity values compared to conventional univariate connectivity measures (<xref ref-type="bibr" rid="bib3">Anzellotti and Coutanche, 2018</xref>). The method we used here evaluated the correlation between RDMs, which has provided high-dimensional information about <italic>distance to object</italic>, obtained from multiple sensors across the brain areas. This makes our analysis sensitive to different aspects of connectivity compared to conventional univariate analyses.</p><p>Fourth, building upon our recently developed method of error analysis (<xref ref-type="bibr" rid="bib78">Woolgar et al., 2019</xref>), we were able to predict forthcoming behavioural misses based on the decoding data, before the response was given. Our method is different from the conventional method of error prediction, in which people directly discriminate correct and miss trials by feeding both types of trials to classifiers in the training phase and testing the classifiers on the left-out correct and miss trials (e.g., <xref ref-type="bibr" rid="bib8">Bode and Stahl, 2014</xref>). Our method only uses correct trials for training, which makes its implementation plausible for real-world situations since we usually have plenty of correct trials and only few miss trials (i.e., cases when the railway controller diverts the trains correctly vs. misses and a collision happens). Moreover, it allows us to directly test whether the neural representations of correct trials contain information which is (on average) less observable in miss trials. We statistically compared the two types of trials and showed a reliable advantage in the level of information contained at individual-trial-level in correct vs. miss trials.</p><p>Our error prediction results showed a reliable decline in the crucial task-relevant (i.e., <italic>distance to object</italic>) information decoding on <italic>miss</italic> vs. <italic>correct</italic> trials but less decline in the less task-relevant information (i.e., <italic>direction of approach</italic>). A complementary analysis allowed the prediction of behaviourally missed trials as soon as the stimulus appeared on the screen (after ~80 ms), which was ~1160 ms before the time of response. This method was generalisable across participants, with the decision threshold for trial classification based on other participants’ data successful in predicting errors for a left-out participant. A number of previous studies have shown that behavioural performance can be correlated with aspects of brain activity even before the stimulus onset (<xref ref-type="bibr" rid="bib8">Bode and Stahl, 2014</xref>; <xref ref-type="bibr" rid="bib17">Eichele et al., 2008</xref>; <xref ref-type="bibr" rid="bib18">Eichele et al., 2010</xref>; <xref ref-type="bibr" rid="bib71">Weissman et al., 2006</xref>; <xref ref-type="bibr" rid="bib19">Ekman et al., 2012</xref>; <xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2015</xref>). Those studies have explained the behavioural errors by implicit measures such as less deactivation of the default-mode network, reduced stimulus-evoked sensory activity (<xref ref-type="bibr" rid="bib71">Weissman et al., 2006</xref>; <xref ref-type="bibr" rid="bib17">Eichele et al., 2008</xref>), and even the connectivity between sensory and vigilance-related/default-mode brain areas (<xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2015</xref>). It would be informative, however, if they could show how (if at all) the processing of task-relevant information is disrupted in the brain and how this might lead to behavioural errors. To serve an applied purpose, it would be ideal if there was a procedure to use those neural signatures to predict behavioural outcomes. Only three previous studies have approached this goal. <xref ref-type="bibr" rid="bib8">Bode and Stahl, 2014</xref>, <xref ref-type="bibr" rid="bib61">Sadaghiani et al., 2015</xref>, and <xref ref-type="bibr" rid="bib13">Dehais et al., 2019</xref> reported maximum prediction accuracies of 62%, 63%, and 72% (with adjusted chance levels of 50%, 55%, and 59%, respectively). Here, we obtained up to 65% prediction (with a chance level of 50%), suggesting our method accesses relevant neural signatures of attention lapses, and may be sensitive in discriminating these. The successful prediction of an error from neural data more than a second in advance of the impending response provides a promising avenue for detecting lapses of attention before any consequences occur.</p><p>The overall goal of this study was to understand how neural representation of dynamic displays was affected by attention and target frequency, and whether reliable changes in behaviour over time could be predicted on the basis of neural patterns. We observed that the neural representation of critically relevant information in the brain was particularly poor on trials where participants missed the target. We used this observation to predict behavioural outcome of individual trials and showed that we could predict behavioural outcome more than a second before action was needed. These results provide new insights about how momentary lapses in attention impact information coding in the brain and propose an avenue for predicting behavioural errors using novel neuroimaging analysis techniques.</p></sec><sec sec-type="materials|methods" id="s4"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>We tested 21 right-handed participants (10 male, 11 female, mean age = 23.4 years [SD = 4.7 years], all Macquarie University students) with normal or corrected to normal vision. The Human Research Ethics Committee of Macquarie University approved the experimental protocols and the participants gave informed consent before participating in the experiment. We reimbursed each participant AU$40 for their time completing the MEG experiment, which lasted for 2 hr including setup.</p></sec><sec id="s4-2"><title>Apparatus</title><p>We recorded neural activity using a whole-head MEG system (KIT, Kanazawa, Japan) with 160 coaxial first-order gradiometers, at a sampling rate of 1000 Hz. We projected the visual stimuli onto a mirror at a distance of 113 cm above participants’ heads while they were in the MEG. An InFocus IN5108 LCD back projection system (InFocus, Portland, Oregon, USA), located outside the magnetically shielded room, presented the dynamically moving stimuli, controlled by a desktop computer (Windows 10; Core i5 CPU; 16 GB RAM; NVIDIA GeForce GTX 1060 6 GB Graphics Card) using MATLAB with Psychtoolbox 3.0 extension (<xref ref-type="bibr" rid="bib9">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib38">Kleiner et al., 2007</xref>). We set the refresh rate of the projector at 60 Hz and used parallel port triggers and a photodiode to mark the beginning (dot appearing on the screen) and end (dot disappearing off the screen) of each trial. We recorded participant’s head shape using a pen digitiser (Polhemus Fastrack, Colchester, VT) and placed five marker coils on the head which allowed the location of the head in the MEG helmet to be monitored during the recording – we checked head location at the beginning, half way through and the end of recording. We used a fibre optic response pad (fORP, Current Designs, Philadelphia, PA, USA) to collect responses and an EyeLink 1000 MEG-compatible remote eye-tracking system (SR Research, 1000 Hz monocular sampling rate) to record eye position. We focused the eye-tracker on the right eye of the participant and calibrated the eye-tracker immediately before the start of MEG data recording.</p></sec><sec id="s4-3"><title>Task and stimuli</title><sec id="s4-3-1"><title>Task summary</title><p>The task was to avoid collisions of relevant moving dots with the central object by pressing the space bar if the dot passed a deflection point in a visible predicted trajectory without changing direction to avoid the central object (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>; a demo can be found here <ext-link ext-link-type="uri" xlink:href="https://osf.io/5aw8v/">https://osf.io/5aw8v/</ext-link>). A text cue at the start of each block indicated which colour of dot was relevant for that block. The participant only needed to respond to targets in this colour (Attended); dots in the other colour formed distractors (Unattended). Pressing the button deflected the dot in one of two possible directions (counterbalanced) to avoid collision. Participants were asked to fixate on the central object throughout the experiment.</p></sec><sec id="s4-3-2"><title>Stimuli</title><p>The stimuli were moving dots in one of two colours that followed visible trajectories and covered a visual area of 3.8 × 5° of visual angle (dva; <xref ref-type="fig" rid="fig1">Figure 1A</xref>). We presented the stimuli in blocks of 110 s duration, with at least one dot moving on the screen at all times during the 110 s block. The trajectories directed the moving dots from two corners of the screen (top left and bottom right) straight towards a centrally presented static ‘object’ (a white circle of 0.25 dva) and then deflected away (either towards the top right or bottom left of the screen; in pathways orthogonal to their <italic>direction of approach</italic>) from the static object at a set distance (the deflection point).</p><p>Target dots deviated from the visible trajectory at the deflection point and continued moving towards the central object. The participant had to push the space bar to prevent a ‘collision’. If the response was made before the dot reached the centre of the object, the dot deflected, and this was counted as a ‘hit’. If the response came after this point, the dot continued straight, and this was counted as a ‘miss’, even if they pressed the button before the dot totally passed through central object.</p><p>The time from dot onset in the periphery to the point of deflection was 1226 ± 10 (mean ± SD) ms. Target (and distractor event) dots took 410 ± 10 (mean ± SD) ms to cross from the deflection point to the collision point. In total, each dot moved across the display for 2005 ± 12 (mean ± SD) ms before starting to fade away after either deflection or travel through the object. The time delay between the onsets of different dots (ISI) was 1660 ± 890 (mean ± SD) ms. There were 1920 dots presented in the whole experiment (~56 min). Each 110 s block contained 64 dots, 32 (50%) in red, and 32 (50%) in green, while the central static object and trajectories were presented in white on a black background.</p></sec><sec id="s4-3-3"><title>Conditions</title><p>There were two target frequency conditions. In ‘Monitoring’ blocks, target dots were ~6.2% of cued-colour dots (2 out of 32 dots). In ‘Active’ blocks, target dots were 50% of cued-colour dots (16 out of 32 dots). The same proportion of dots in the non-cued colour failed to deflect; these were distractors (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>, top right panel). Participants completed two practice blocks of the Active condition and then completed 30 blocks in the main experiment (15 Active followed by 15 Monitoring or <italic>vice versa</italic>, counterbalanced across participants).</p><p>The time between the appearance of target dots varied unpredictably, with distractors and correctly deflecting dots (events) intervening. In Monitoring blocks, there was an average time between targets of 57.88 (±36.03 SD) s. In Active blocks, there was an average time between targets of 7.20 (±6.36 SD) s.</p><p>Feedback: On target trials, if the participant pressed the space bar in time, this ‘hit’ was indicated by a specific tone and deflection of the target dot. There were three types of potential false alarm, all indicated by an error tone and no change in the trajectory of the dot. These were if the participant responded: (1) too early, while the dot was still on the trajectory; (2) when the dot was not a target and had been deflected automatically (‘event’ in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, middle right); or (3) when the dot was in the non-cued colour (‘distractor’ in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, top right) in any situation. Participants had only one chance to respond per dot; any additional responses resulted in ‘error’ tones. As multiple dots could be on the screen, we always associated the button press to the dot which was closest to the central object.</p></sec></sec><sec id="s4-4"><title>Pre-processing</title><p>MEG data were filtered online using band-pass filters in the range of 0.03–200 Hz and notch-filtered at 50 Hz. We then imported the data into MATLAB and epoched them from −100 to 3000 ms relative to the trial onset time. We performed all the analyses once without and once with standard eye-artefact removal (post hoc, explained below) to see if eye movements and blinks had a significant impact on our results and interpretations. Finally, we down-sampled the data to 200 Hz for the decoding of our two key measures: <italic>direction of approach</italic> and <italic>distance to object</italic> (see below).</p></sec><sec id="s4-5"><title>Eye-related artefact removal</title><p>There are two practical reasons that the effects of eye-related artefacts (e.g. eye-blinks, saccades, etc.) should not be dominantly picked up by our classification procedure. First, the decoding analysis is time-resolved and computed in small time windows (5 ms and 80 ms, for <italic>direction</italic> and <italic>distance</italic> information decoding, respectively). For eye-related artefacts to be picked up by the classifier, they would need to occur at consistent time points across trials of the same condition, and not in the other condition, which seems implausible. Second, our MEG helmet does not have the very frontal sensors where eye-related artefacts most strongly affect neural activations (<xref ref-type="bibr" rid="bib47">Mognon et al., 2011</xref>). However, to check that our results were not dominantly driven by eye-movement artefacts, we also did a post hoc analysis in which we removed these using ‘runica’ Independent Components Analysis (ICA) algorithm as implemented by EEGLAB. We used the ADJUST plugin (<xref ref-type="bibr" rid="bib47">Mognon et al., 2011</xref>) of EEGLAB to decide which ICA components were related to eye artefacts for removal. This toolbox extracts spatiotemporal features from components to quantitatively measure if a component is related to eye movements or blinks. For all subjects except two, we identified only one component which were attributed to eye artefacts (i.e., located frontally and surpassing the ADJUST’s threshold) which we removed. For the two other participants, we identified and removed two components with these characteristics. The body of the paper presents the results of our analyses on the data without eye-artefact removal, but the corrected data can be found in the Supplementary materials.</p></sec><sec id="s4-6"><title>Multivariate pattern analyses</title><p>We measured the information contained in the multivariate (multi-sensor) patterns of MEG data by training a linear discriminant analysis (LDA) classifier using a set of training trials from two categories (e.g., for the <italic>direction of approach</italic> measure, this was dots approaching from left vs. right, see below). We then tested to see whether the classifier could predict the category of an independent (left-out) set of testing data from the same participant. We used a 10-fold cross-validation approach, splitting the data into training and testing subsets. Specifically, we trained the LDA classifier on 90% of the trials and tested it on the left-out 10% of the trials. This procedure was repeated 10 times each time leaving out a different 10% subset of the data for testing (i.e., 10-fold cross validation).</p><p>We decoded two major task features from the neural data: (1) the <italic>direction of approach</italic> (left vs. right); and (2) the distance of each moving dot from the centrally fixed object (<italic>distance to object</italic>), which correspond to visual (retinal) information changing over time. Our interest was in the effect of selective attention (Attended vs. Unattended) and Target Frequency conditions (Active vs. Monitoring) on the neural representation of this information, and how the representation of information changed on trials when participants missed the target.</p><p>We decoded left vs. right <italic>directions of approach</italic> (as indicated by yellow arrows in <xref ref-type="fig" rid="fig1">Figure 1B</xref>) every 5 ms starting from 100 ms before the appearance of the dot on the screen to 3000 ms later. Please note that as each moving dot is considered a trial, trial time windows (epochs) overlapped for 62.2% of trials. In Monitoring blocks, 1.2% of target trials overlapped (two targets were on the screen simultaneously but lagged relative to one another). In Active blocks, 17.1% of target trials overlapped.</p><p>For the decoding of <italic>distance to object</italic>, we split the trials into the time windows corresponding to 15 equally spaced distances of the moving dot relative to the central object (as indicated by blue lines in <xref ref-type="fig" rid="fig1">Figure 1B</xref>), with distance 1 being closest to the object, and 15 being furthest away (the dot having just appeared on the screen). Each distance covered a time window of ~80ms (varied slightly as dot trajectories varied in angle) which consisted of 4 or 5 signal samples depending on which of the 15 predetermined distances was temporally closest to each signal sample and therefore could incorporate it. Next, we concatenated the MEG signals from identical distances (splits) across both sides of the screen (left and right), so that every distance included data from dots approaching from both left and right side of the screen. This concatenation ensures that <italic>distance</italic> information decoding is not affected by the <italic>direction of approach</italic>. Finally, we trained and tested a classifier to distinguish between the MEG signals (a vector comprising data from all MEG sensors, concatenated over all time points in the relevant time window), pertaining to each pair of distances (e.g., 1 vs. 2) using a leave-one-out cross-validation procedure. As within-trial autocorrelation in signals could inflate classification accuracy (signal samples closer in time are more similar than those farther apart), we ensured that in every cross-validation run and each distance, the training and testing sets used samples from distinct sets of trials. To achieve this, trials were first allocated randomly into 10 folds, without separating their constituent signal samples. This way, the 4 or 5 signal samples from within each distance of a given trial remained together across all cross-validation runs and were never split across training and testing sets. We obtained classification accuracy for all possible pairs of distances (105 combinations of 15 distances). To obtain a single decoding value per distance, we averaged the 14 classification values that corresponded to that distance against other 14 distances. For example, the final decoding accuracy for distance 15 was an average of 15 vs. 14, 15 vs. 13, 15 vs. 12, and so on until 15 vs. 1. We repeated this procedure for our main Target Frequency conditions (Active vs. Monitoring), Attention conditions (Attended vs. Unattended), and Time on Task (first and last five blocks of each task condition, which are called early and late blocks here, respectively). This was done separately for <italic>correct</italic> and <italic>miss</italic> trials and for each participant separately.</p><p>Note that the ‘<italic>direction of approach</italic>’ and ‘<italic>distance to object</italic>’ information cannot be directly compared on an analogous platform as the two types of information are defined differently. There are also different number of classes in decoding for the two types of information: only two classes for the <italic>direction</italic> information (left vs. right), compared to the 15 classes for the <italic>distance</italic> information (15 distances).</p></sec><sec id="s4-7"><title>Informational connectivity analysis</title><p>To evaluate possible modulations of brain connectivity between the attentional networks of the frontal brain and the occipital visual areas, we used a simplified version of our recently developed RSA-based informational connectivity analysis (<xref ref-type="bibr" rid="bib22">Goddard et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Goddard et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Karimi-Rouzbahani, 2018</xref>; <xref ref-type="bibr" rid="bib35">Karimi-Rouzbahani et al., 2019</xref>). Specifically, we evaluated the informational connectivity, which measures the similarity of <italic>distance</italic> decoding patterns between areas, across our main Target Frequency conditions (Active vs. Monitoring), Attention conditions (Attended vs. Unattended), and Time on Task (first and last five blocks of each task condition, which are called early and late blocks here, respectively). There are a few considerations in the implementation and interpretation of our connectivity analysis. First, it reflects the similarity of the way a pair of brain areas encode ‘<italic>distance</italic>’ information during the whole trial. This means that we could not use the component of time in the evaluation of our connectivity as we have implemented elsewhere (<xref ref-type="bibr" rid="bib35">Karimi-Rouzbahani et al., 2019</xref>; <xref ref-type="bibr" rid="bib36">Karimi-Rouzbahani et al., 2021</xref>). Second, rather than a simple correlation of magnitudes of decoding accuracy between two regions of interest, our connectivity measure reflects a correlation of the <italic>patterns</italic> of decoding accuracies across conditions (i.e., distances here). Finally, our connectivity analysis evaluates sensory information encoding, rather than other aspects of cognitive or motor information encoding, which might have also been affected by our experimental manipulations.</p><p>Connectivity was calculated separately for <italic>correct</italic> and <italic>miss</italic> trials, using RDMs (<xref ref-type="bibr" rid="bib39">Kriegeskorte et al., 2008</xref>). To construct the RDMs, we decoded all possible combinations of distances from each other yielding a 15 by 15 cross-distance classification matrix, for each condition separately. We obtained these matrices from peri-occipital and peri-frontal areas to see how the manipulation of Attention, Target Frequency, and Time on Task modulated the correlation of information (RDMs) between those areas on <italic>correct</italic> and <italic>miss</italic> trials. We quantified connectivity using Spearman’s rank correlation of the matrices obtained from those areas, only including the lower triangle of the RDMs (105 decoding values). To avoid bias when comparing the connectivity on <italic>correct</italic> vs. <italic>miss</italic> trials, the number of trials were equalised by subsampling the <italic>correct</italic> trials to the number of <italic>miss</italic> trials and repeating the subsampling 100 times before finally averaging them for comparison with <italic>miss</italic> trials.</p></sec><sec id="s4-8"><title>Error data analysis</title><p>Next, we asked what information was coded in the brain when participants missed targets. To study information coding in the brain on <italic>miss</italic> trials, where the participants failed to press the button when targets failed to automatically deflect, we used our recently developed method of error data analysis (<xref ref-type="bibr" rid="bib78">Woolgar et al., 2019</xref>). Essentially, this analysis asks whether the brain represents the information similarly on <italic>correct</italic> and <italic>miss</italic> trials. For that purpose, we trained a classifier using the neural data from a proportion of <italic>correct</italic> trials (i.e., when the target dot was detected and manually deflected punctually) and tested on both the left-out portion of the <italic>correct</italic> trials (i.e., cross-validation) and on the <italic>miss</italic> trials. If decoding accuracy is equal between the <italic>correct</italic> and <italic>miss</italic> trials, we can conclude that information coding is maintained on <italic>miss</italic> trials as it is on <italic>correct</italic> trials. However, if decoding accuracy is lower on <italic>miss</italic> trials than on <italic>correct</italic> trials, we can infer that information coding differs on <italic>miss</italic> trials, consistent with the change in behaviour. Since <italic>correct</italic> and <italic>miss</italic> trials were visually different after the deflection point, we only used data from before the deflection point.</p><p>For these error data analyses, the number of folds for cross-validation were determined based on the proportion of <italic>miss</italic> to <italic>correct</italic> trials (number of folds = number of <italic>miss</italic> trials/number of <italic>correct</italic> trials). This allowed us to test the trained classifiers with equal numbers of <italic>miss</italic> and <italic>correct</italic> trials to avoid bias in the comparison.</p></sec><sec id="s4-9"><title>Predicting behavioural performance from neural data</title><p>We developed a new method to predict, based on the most task-relevant information in the neural signal, whether or not a participant would press the button for a target dot in time to deflect it on a particular trial. This method includes three steps, with the third step being slightly different for the left-out testing participant vs. the other 20 participants. First, for every participant, we trained 105 classifiers using ~80% of <italic>correct</italic> trials to discriminate the 15 distances. Second, we tested those classifiers using half of the left-out portion (~10%) of the <italic>correct</italic> trials, which we called validation trials, by simultaneously accumulating (i.e., including in averaging) the accuracies of the classifiers at each distance and further distances as the validation dot approached the central object. The validation set allowed us to determine a decision threshold for predicting the outcome of each testing trial: whether it was a <italic>correct</italic> or <italic>miss</italic> trial. Third, we performed a second-level classification on testing trials which were the other half (~10%) of the left-out portion of the <italic>correct</italic> trials and the <italic>miss</italic> trials, using each dot’s accumulated accuracy calculated as in the previous step. Accordingly, if the testing dot’s accumulated accuracy was <bold><italic>higher</italic></bold> than the decision threshold, it was predicted as <italic>correct</italic>, otherwise <italic>miss</italic>. For all participants, except for the left-out testing one, the decision threshold was chosen from a range of <bold><italic>multiples</italic></bold> (0.1 to 4 in steps of 0.1) of the standard deviation below the accumulated accuracy obtained for the validation set on the second step. For determining the optimal threshold for the testing participant, however, instead of a range of multiples, we used the average of the best performing multiples (i.e., the one which predicted the behavioural outcome of the trial more accurately) obtained from the other 20 participants. This avoided circularity in the analysis.</p><p>To give more detail on the second and third steps, when the validation/testing dots were at distance #15, we averaged the accuracies of the 14 classifiers trained to classify dots at distance #15 from all other distances. Accordingly, when the dot reached distance #14, we also included and averaged accuracies from classifiers which were trained to classify distance #14 from all other distances leading to 27 classifier accuracies. Therefore, by the time the dot reached distance #1, we had 105 classifier accuracies to average and predict the behavioural outcome of the trial. Every classifier’s accuracies were either 1 or 0 corresponding to correct or incorrect classification of dot’s distance, respectively. Note that accumulation of classifiers’ accuracies, as compared to using classifier accuracy on every distance independently, provides a more robust and smoother classification measure for deciding on the label of the trials. The validation set, which was different from the testing set, allowed us to set the decision threshold based on the validation data within each subject and from the 20 participants and finally test our prediction classifiers on a separate testing set from the 21st individual participant, iteratively. The optimal threshold was 0.4 (± 0.07) times the SD below the decoding accuracy on the validation set across participants.</p></sec><sec id="s4-10"><title>Statistical analyses</title><p>To determine the evidence for the null and the alternative hypotheses, we used Bayes analyses as implemented by Krekelberg (<ext-link ext-link-type="uri" xlink:href="https://klabhub.github.io/bayesFactor/">https://klabhub.github.io/bayesFactor/</ext-link>) based on <xref ref-type="bibr" rid="bib59">Rouder et al., 2012</xref>. We used standard rules for interpreting levels of evidence (<xref ref-type="bibr" rid="bib41">Lee and Wagenmakers, 2005</xref>; <xref ref-type="bibr" rid="bib14">Dienes, 2014</xref>): Bayes factors of &gt;10 and &lt;1/10 were interpreted as strong evidence for the alternative and null hypotheses, respectively, and &gt;3 and &lt;1/3 were interpreted as moderate evidence for the alternative and null hypotheses, respectively. We interpreted the Bayes factors which fell between 3 and 1/3 as reflecting insufficient evidence either way.</p><p>Specifically, for the behavioural data, we asked whether there was a difference between Active and Monitoring conditions in terms of miss rates and RTs. Accordingly, we calculated the Bayes factor as the probability of the data under alternative (i.e., difference) relative to the null (i.e., no difference) hypothesis in each block separately. In the decoding, we repeated the same procedure to evaluate the evidence for the alternative hypothesis of a difference between decoding accuracies across conditions (e.g., Active vs. Monitoring and Attended vs. Unattended) vs. the null hypothesis of no difference between them, at every time point/distance. To evaluate evidence for the alternative of above-chance decoding accuracy vs. the null hypothesis of no difference from chance, we calculated the Bayes factor between the distribution of actual accuracies obtained and a set of 1000 random accuracies obtained by randomising the class labels across the same pair of conditions (null distribution) at every time point/distance.</p><p>To evaluate the evidence for the alternative of main effects of different factors (Attention, Target Frequency, and Time on Task) in decoding, we used Bayes factor ANOVA (<xref ref-type="bibr" rid="bib59">Rouder et al., 2012</xref>). This analysis evaluates the evidence for the null and alternative hypothesis as the ratio of the Bayes factor for the full model ANOVA (i.e., including all three factors of Target Frequency, Attention, and the Time on Task) relative to the restricted model (i.e., including the two other factors while excluding the factor being evaluated). For example, for evaluating the main effect of Time on Task, the restricted model included Attention and Target Frequency factors but excluded the factor of Time on Task.</p><p>The priors for all Bayes factor analyses were determined based on Jeffrey-Zellner-Siow priors (<xref ref-type="bibr" rid="bib30">Jeffreys, 1961</xref>; <xref ref-type="bibr" rid="bib81">Zellner and Siow, 1980</xref>) which are from the Cauchy distribution based on the effect size that is initially calculated in the algorithm using a <italic>t</italic>-test (<xref ref-type="bibr" rid="bib59">Rouder et al., 2012</xref>). The priors are data-driven and have been shown to be invariant with respect to linear transformations of measurement units (<xref ref-type="bibr" rid="bib59">Rouder et al., 2012</xref>), which reduces the chance of being biased towards the null or alternative hypotheses.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was funded by an Australian Research Council (ARC) Discovery Project grant to ANR and AW (DP170101780). AW was supported by an ARC Future Fellowship (FT170100105) and MRC intramural funding SUAG/052/G101400. H K-R was supported by Newton International Fellowship from Royal Society (NIF\R1\192608). We thank Denise Moerel, Mark Wiggins, Jeremy Wolfe, and William Helton for contributions to an earlier design of the MOM task.</p></ack><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Formal analysis, Supervision, Funding acquisition, Methodology, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Methodology, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Human subjects: The Human Research Ethics Committee of Macquarie University approved the experimental protocols and the participants gave informed consent before participating in the experiment. The approval identifier is 52020297914411.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-60563-transrepform-v3.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>We have shared the Magnetoencephalography data (i.e. time series) as well as behavioral data in Matlab '.mat' format on the Open Science Framework website at <ext-link ext-link-type="uri" xlink:href="https://osf.io/5aw8v/">https://osf.io/5aw8v/</ext-link> with the DOI: 10.17605/OSF.IO/5AW8V. We have also uploaded a video of the &quot;Multiple-Object-Monitoring&quot; paradigm, developed for this study, for easier understanding of the task at the same address. The mentioned address is dedicated to this project and we will regularly update the contents to make them easier to follow for other researchers.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Karimi-Rouzbahani</surname><given-names>H</given-names></name><name><surname>Woolgar</surname><given-names>A</given-names></name><name><surname>Rich</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Neural signatures of vigilance decrements predict behavioural errors before they occur</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="accession" xlink:href="https://osf.io/5aw8v/">10.17605/OSF.IO/5AW8V</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adler</surname> <given-names>CM</given-names></name><name><surname>Sax</surname> <given-names>KW</given-names></name><name><surname>Holland</surname> <given-names>SK</given-names></name><name><surname>Schmithorst</surname> <given-names>V</given-names></name><name><surname>Rosenberg</surname> <given-names>L</given-names></name><name><surname>Strakowski</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Changes in neuronal activation with increasing attention demand in healthy volunteers: an fMRI study</article-title><source>Synapse</source><volume>42</volume><fpage>266</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1002/syn.1112</pub-id><pub-id pub-id-type="pmid">11746725</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alnæs</surname> <given-names>D</given-names></name><name><surname>Kaufmann</surname> <given-names>T</given-names></name><name><surname>Richard</surname> <given-names>G</given-names></name><name><surname>Duff</surname> <given-names>EP</given-names></name><name><surname>Sneve</surname> <given-names>MH</given-names></name><name><surname>Endestad</surname> <given-names>T</given-names></name><name><surname>Nordvik</surname> <given-names>JE</given-names></name><name><surname>Andreassen</surname> <given-names>OA</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Westlye</surname> <given-names>LT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Attentional load modulates large-scale functional brain connectivity beyond the core attention networks</article-title><source>NeuroImage</source><volume>109</volume><fpage>260</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.01.026</pub-id><pub-id pub-id-type="pmid">25595500</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anzellotti</surname> <given-names>S</given-names></name><name><surname>Coutanche</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Beyond functional connectivity: investigating networks of multivariate representations</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>258</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.12.002</pub-id><pub-id pub-id-type="pmid">29305206</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baillet</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Magnetoencephalography for brain electrophysiology and imaging</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>327</fpage><lpage>339</lpage><pub-id pub-id-type="doi">10.1038/nn.4504</pub-id><pub-id pub-id-type="pmid">28230841</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basti</surname> <given-names>A</given-names></name><name><surname>Nili</surname> <given-names>H</given-names></name><name><surname>Hauk</surname> <given-names>O</given-names></name><name><surname>Marzetti</surname> <given-names>L</given-names></name><name><surname>Henson</surname> <given-names>RN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Multi-dimensional connectivity: a conceptual and mathematical review</article-title><source>NeuroImage</source><volume>221</volume><elocation-id>117179</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117179</pub-id><pub-id pub-id-type="pmid">32682988</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname> <given-names>LH</given-names></name><name><surname>Bransome</surname> <given-names>ED</given-names></name><name><surname>Mirsky</surname> <given-names>AF</given-names></name><name><surname>Rosvold</surname> <given-names>HE</given-names></name><name><surname>Sarason</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="1956">1956</year><article-title>A continuous performance test of brain damage</article-title><source>Journal of Consulting Psychology</source><volume>20</volume><fpage>343</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1037/h0043220</pub-id><pub-id pub-id-type="pmid">13367264</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benedict</surname> <given-names>RH</given-names></name><name><surname>Shucard</surname> <given-names>DW</given-names></name><name><surname>Santa Maria</surname> <given-names>MP</given-names></name><name><surname>Shucard</surname> <given-names>JL</given-names></name><name><surname>Abara</surname> <given-names>JP</given-names></name><name><surname>Coad</surname> <given-names>ML</given-names></name><name><surname>Wack</surname> <given-names>D</given-names></name><name><surname>Sawusch</surname> <given-names>J</given-names></name><name><surname>Lockwood</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Covert auditory attention generates activation in the rostral/dorsal anterior cingulate cortex</article-title><source>Journal of Cognitive Neuroscience</source><volume>14</volume><fpage>637</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1162/08989290260045765</pub-id><pub-id pub-id-type="pmid">12126504</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bode</surname> <given-names>S</given-names></name><name><surname>Stahl</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Predicting errors from patterns of event-related potentials preceding an overt response</article-title><source>Biological Psychology</source><volume>103</volume><fpage>357</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2014.10.002</pub-id><pub-id pub-id-type="pmid">25450163</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1969">1969</year><source>Statistical Power Analysis for the Behavioral Sciences</source><publisher-loc>New York</publisher-loc><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coull</surname> <given-names>JT</given-names></name><name><surname>Frith</surname> <given-names>CD</given-names></name><name><surname>Frackowiak</surname> <given-names>RS</given-names></name><name><surname>Grasby</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A fronto-parietal network for rapid visual information processing: a PET study of sustained attention and working memory</article-title><source>Neuropsychologia</source><volume>34</volume><fpage>1085</fpage><lpage>1095</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(96)00029-2</pub-id><pub-id pub-id-type="pmid">8904746</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coutanche</surname> <given-names>MN</given-names></name><name><surname>Thompson-Schill</surname> <given-names>SL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Informational connectivity: identifying synchronized discriminability of multi-voxel patterns across the brain</article-title><source>Frontiers in Human Neuroscience</source><volume>7</volume><elocation-id>15</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2013.00015</pub-id><pub-id pub-id-type="pmid">23403700</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehais</surname> <given-names>F</given-names></name><name><surname>Roy</surname> <given-names>RN</given-names></name><name><surname>Scannella</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Inattentional deafness to auditory alarms: inter-individual differences, electrophysiological signature and single trial classification</article-title><source>Behavioural Brain Research</source><volume>360</volume><fpage>51</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2018.11.045</pub-id><pub-id pub-id-type="pmid">30508609</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dienes</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Using Bayes to get the most out of non-significant results</article-title><source>Frontiers in Psychology</source><volume>5</volume><elocation-id>781</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2014.00781</pub-id><pub-id pub-id-type="pmid">25120503</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>172</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.01.004</pub-id><pub-id pub-id-type="pmid">20171926</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname> <given-names>J</given-names></name><name><surname>Owen</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Common regions of the human frontal lobe recruited by diverse cognitive demands</article-title><source>Trends in Neurosciences</source><volume>23</volume><fpage>475</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1016/S0166-2236(00)01633-7</pub-id><pub-id pub-id-type="pmid">11006464</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichele</surname> <given-names>T</given-names></name><name><surname>Debener</surname> <given-names>S</given-names></name><name><surname>Calhoun</surname> <given-names>VD</given-names></name><name><surname>Specht</surname> <given-names>K</given-names></name><name><surname>Engel</surname> <given-names>AK</given-names></name><name><surname>Hugdahl</surname> <given-names>K</given-names></name><name><surname>von Cramon</surname> <given-names>DY</given-names></name><name><surname>Ullsperger</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Prediction of human errors by maladaptive changes in event-related brain networks</article-title><source>PNAS</source><volume>105</volume><fpage>6173</fpage><lpage>6178</lpage><pub-id pub-id-type="doi">10.1073/pnas.0708965105</pub-id><pub-id pub-id-type="pmid">18427123</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichele</surname> <given-names>H</given-names></name><name><surname>Juvodden</surname> <given-names>HT</given-names></name><name><surname>Ullsperger</surname> <given-names>M</given-names></name><name><surname>Eichele</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Mal-adaptation of event-related EEG responses preceding performance errors</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>65</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00065</pub-id><pub-id pub-id-type="pmid">20740080</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekman</surname> <given-names>M</given-names></name><name><surname>Derrfuss</surname> <given-names>J</given-names></name><name><surname>Tittgemeyer</surname> <given-names>M</given-names></name><name><surname>Fiebach</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Predicting errors from reconfiguration patterns in human brain networks</article-title><source>PNAS</source><volume>109</volume><fpage>16714</fpage><lpage>16719</lpage><pub-id pub-id-type="doi">10.1073/pnas.1207523109</pub-id><pub-id pub-id-type="pmid">23012417</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname> <given-names>E</given-names></name><name><surname>Duncan</surname> <given-names>J</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Broad domain generality in focal regions of frontal and parietal cortex</article-title><source>PNAS</source><volume>110</volume><fpage>16616</fpage><lpage>16621</lpage><pub-id pub-id-type="doi">10.1073/pnas.1315235110</pub-id><pub-id pub-id-type="pmid">24062451</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilbert</surname> <given-names>SJ</given-names></name><name><surname>Simons</surname> <given-names>JS</given-names></name><name><surname>Frith</surname> <given-names>CD</given-names></name><name><surname>Burgess</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Performance-related activity in medial rostral prefrontal cortex (area 10) during low-demand tasks</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>32</volume><fpage>45</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.32.1.45</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goddard</surname> <given-names>E</given-names></name><name><surname>Carlson</surname> <given-names>TA</given-names></name><name><surname>Dermody</surname> <given-names>N</given-names></name><name><surname>Woolgar</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Representational dynamics of object recognition: feedforward and feedback information flows</article-title><source>NeuroImage</source><volume>128</volume><fpage>385</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.01.006</pub-id><pub-id pub-id-type="pmid">26806290</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Goddard</surname> <given-names>E</given-names></name><name><surname>Carlson</surname> <given-names>TA</given-names></name><name><surname>Woolgar</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spatial and feature-selective attention have distinct effects on population-level tuning</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/530352</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greicius</surname> <given-names>MD</given-names></name><name><surname>Krasnow</surname> <given-names>B</given-names></name><name><surname>Reiss</surname> <given-names>AL</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Functional connectivity in the resting brain: a network analysis of the default mode hypothesis</article-title><source>PNAS</source><volume>100</volume><fpage>253</fpage><lpage>258</lpage><pub-id pub-id-type="doi">10.1073/pnas.0135058100</pub-id><pub-id pub-id-type="pmid">12506194</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greicius</surname> <given-names>MD</given-names></name><name><surname>Supekar</surname> <given-names>K</given-names></name><name><surname>Menon</surname> <given-names>V</given-names></name><name><surname>Dougherty</surname> <given-names>RF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Resting-state functional connectivity reflects structural connectivity in the default mode network</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn059</pub-id><pub-id pub-id-type="pmid">18403396</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grootswagers</surname> <given-names>T</given-names></name><name><surname>Wardle</surname> <given-names>SG</given-names></name><name><surname>Carlson</surname> <given-names>TA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Decoding dynamic brain patterns from evoked responses: a tutorial on multivariate pattern analysis applied to time series neuroimaging data</article-title><source>Journal of Cognitive Neuroscience</source><volume>29</volume><fpage>677</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01068</pub-id><pub-id pub-id-type="pmid">27779910</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helton</surname> <given-names>WS</given-names></name><name><surname>Russell</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Feature absence-presence and two theories of lapses of sustained attention</article-title><source>Psychological Research</source><volume>75</volume><fpage>384</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1007/s00426-010-0316-1</pub-id><pub-id pub-id-type="pmid">21103888</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helton</surname> <given-names>WS</given-names></name><name><surname>Warm</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Signal salience and the mindlessness theory of vigilance</article-title><source>Acta Psychologica</source><volume>129</volume><fpage>18</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.actpsy.2008.04.002</pub-id><pub-id pub-id-type="pmid">18499079</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishibashi</surname> <given-names>K</given-names></name><name><surname>Kita</surname> <given-names>S</given-names></name><name><surname>Wolfe</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The effects of local prevalence and explicit expectations on search termination times</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>74</volume><fpage>115</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.3758/s13414-011-0225-4</pub-id><pub-id pub-id-type="pmid">22006528</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jeffreys</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1961">1961</year><source>Theory of Probability</source><edition>3rd ed</edition><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johannsen</surname> <given-names>P</given-names></name><name><surname>Jakobsen</surname> <given-names>J</given-names></name><name><surname>Bruhn</surname> <given-names>P</given-names></name><name><surname>Hansen</surname> <given-names>SB</given-names></name><name><surname>Gee</surname> <given-names>A</given-names></name><name><surname>Stodkilde-Jorgensen</surname> <given-names>H</given-names></name><name><surname>Gjedde</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Cortical sites of sustained and divided attention in normal elderly humans</article-title><source>NeuroImage</source><volume>6</volume><fpage>145</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1006/nimg.1997.0292</pub-id><pub-id pub-id-type="pmid">9344819</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamzanova</surname> <given-names>AT</given-names></name><name><surname>Kustubayeva</surname> <given-names>AM</given-names></name><name><surname>Matthews</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Use of EEG workload indices for diagnostic monitoring of vigilance decrement</article-title><source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source><volume>56</volume><fpage>1136</fpage><lpage>1149</lpage><pub-id pub-id-type="doi">10.1177/0018720814526617</pub-id><pub-id pub-id-type="pmid">25277022</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karimi-Rouzbahani</surname> <given-names>H</given-names></name><name><surname>Bagheri</surname> <given-names>N</given-names></name><name><surname>Ebrahimpour</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Hard-wired feed-forward visual mechanisms of the brain compensate for affine variations in object recognition</article-title><source>Neuroscience</source><volume>349</volume><fpage>48</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2017.02.050</pub-id><pub-id pub-id-type="pmid">28245990</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karimi-Rouzbahani</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Three-stage processing of category and variation information by entangled interactive mechanisms of peri-occipital and peri-frontal cortices</article-title><source>Scientific Reports</source><volume>8</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1038/s41598-018-30601-8</pub-id><pub-id pub-id-type="pmid">30111859</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karimi-Rouzbahani</surname> <given-names>H</given-names></name><name><surname>Vahab</surname> <given-names>E</given-names></name><name><surname>Ebrahimpour</surname> <given-names>R</given-names></name><name><surname>Menhaj</surname> <given-names>MB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spatiotemporal analysis of category and target-related information processing in the brain during object detection</article-title><source>Behavioural Brain Research</source><volume>362</volume><fpage>224</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2019.01.025</pub-id><pub-id pub-id-type="pmid">30654124</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karimi-Rouzbahani</surname> <given-names>H</given-names></name><name><surname>Ramezani</surname> <given-names>F</given-names></name><name><surname>Woolgar</surname> <given-names>A</given-names></name><name><surname>Rich</surname> <given-names>A</given-names></name><name><surname>Ghodrati</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Perceptual difficulty modulates the direction of information flow in familiar face recognition</article-title><source>NeuroImage</source><volume>233</volume><elocation-id>117896</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117896</pub-id><pub-id pub-id-type="pmid">33667671</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kietzmann</surname> <given-names>TC</given-names></name><name><surname>Spoerer</surname> <given-names>CJ</given-names></name><name><surname>Sörensen</surname> <given-names>LKA</given-names></name><name><surname>Cichy</surname> <given-names>RM</given-names></name><name><surname>Hauk</surname> <given-names>O</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Recurrence is required to capture the representational dynamics of the human visual system</article-title><source>PNAS</source><volume>116</volume><fpage>21854</fpage><lpage>21863</lpage><pub-id pub-id-type="doi">10.1073/pnas.1905544116</pub-id><pub-id pub-id-type="pmid">31591217</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleiner</surname> <given-names>M</given-names></name><name><surname>Brainard</surname> <given-names>D</given-names></name><name><surname>Pelli</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>What's new in Psychtoolbox-3</article-title><source>Perception</source><volume>36</volume><fpage>1</fpage><lpage>16</lpage></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Bandettini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langner</surname> <given-names>R</given-names></name><name><surname>Eickhoff</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Sustaining attention to simple tasks: a meta-analytic review of the neural mechanisms of vigilant attention</article-title><source>Psychological Bulletin</source><volume>139</volume><fpage>870</fpage><lpage>900</lpage><pub-id pub-id-type="doi">10.1037/a0030694</pub-id><pub-id pub-id-type="pmid">23163491</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>MD</given-names></name><name><surname>Wagenmakers</surname> <given-names>EJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Bayesian statistical inference in psychology: comment on trafimow (2003)</article-title><source>Psychological Review</source><volume>112</volume><fpage>662</fpage><lpage>668</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.112.3.662</pub-id><pub-id pub-id-type="pmid">16060758</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohani</surname> <given-names>M</given-names></name><name><surname>Payne</surname> <given-names>BR</given-names></name><name><surname>Strayer</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A review of psychophysiological measures to assess cognitive states in Real-World driving</article-title><source>Frontiers in Human Neuroscience</source><volume>13</volume><elocation-id>57</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2019.00057</pub-id><pub-id pub-id-type="pmid">30941023</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackworth</surname> <given-names>NH</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>The breakdown of vigilance during prolonged visual search</article-title><source>Quarterly Journal of Experimental Psychology</source><volume>1</volume><fpage>6</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1080/17470214808416738</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manly</surname> <given-names>T</given-names></name><name><surname>Robertson</surname> <given-names>IH</given-names></name><name><surname>Galloway</surname> <given-names>M</given-names></name><name><surname>Hawkins</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The absent mind: further investigations of sustained attention to response</article-title><source>Neuropsychologia</source><volume>37</volume><fpage>661</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(98)00127-4</pub-id><pub-id pub-id-type="pmid">10390027</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazaheri</surname> <given-names>A</given-names></name><name><surname>Nieuwenhuis</surname> <given-names>IL</given-names></name><name><surname>van Dijk</surname> <given-names>H</given-names></name><name><surname>Jensen</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prestimulus alpha and mu activity predicts failure to inhibit motor responses</article-title><source>Human Brain Mapping</source><volume>30</volume><fpage>1791</fpage><lpage>1800</lpage><pub-id pub-id-type="doi">10.1002/hbm.20763</pub-id><pub-id pub-id-type="pmid">19308934</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Möckel</surname> <given-names>T</given-names></name><name><surname>Beste</surname> <given-names>C</given-names></name><name><surname>Wascher</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The effects of time on task in response selection - An ERP study of mental fatigue</article-title><source>Scientific Reports</source><volume>5</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/srep10113</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mognon</surname> <given-names>A</given-names></name><name><surname>Jovicich</surname> <given-names>J</given-names></name><name><surname>Bruzzone</surname> <given-names>L</given-names></name><name><surname>Buiatti</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>ADJUST: an automatic EEG artifact detector based on the joint use of spatial and temporal features</article-title><source>Psychophysiology</source><volume>48</volume><fpage>229</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2010.01061.x</pub-id><pub-id pub-id-type="pmid">20636297</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molina</surname> <given-names>E</given-names></name><name><surname>Sanabria</surname> <given-names>D</given-names></name><name><surname>Jung</surname> <given-names>TP</given-names></name><name><surname>Correa</surname> <given-names>Á</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Electroencephalographic and peripheral temperature dynamics during a prolonged psychomotor vigilance task</article-title><source>Accident Analysis &amp; Prevention</source><volume>126</volume><fpage>198</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.aap.2017.10.014</pub-id><pub-id pub-id-type="pmid">29061281</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakano</surname> <given-names>T</given-names></name><name><surname>Kato</surname> <given-names>M</given-names></name><name><surname>Morito</surname> <given-names>Y</given-names></name><name><surname>Itoi</surname> <given-names>S</given-names></name><name><surname>Kitazawa</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Blink-related momentary activation of the default mode network while viewing videos</article-title><source>PNAS</source><volume>110</volume><fpage>702</fpage><lpage>706</lpage><pub-id pub-id-type="doi">10.1073/pnas.1214804110</pub-id><pub-id pub-id-type="pmid">23267078</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname> <given-names>SA</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Oosterhof</surname> <given-names>NN</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></name><name><surname>Gors</surname> <given-names>J</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Attention selectively reshapes the geometry of distributed semantic representation</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>4277</fpage><lpage>4291</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx138</pub-id><pub-id pub-id-type="pmid">28591837</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connell</surname> <given-names>RG</given-names></name><name><surname>Dockree</surname> <given-names>PM</given-names></name><name><surname>Robertson</surname> <given-names>IH</given-names></name><name><surname>Bellgrove</surname> <given-names>MA</given-names></name><name><surname>Foxe</surname> <given-names>JJ</given-names></name><name><surname>Kelly</surname> <given-names>SP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Uncovering the neural signature of lapsing attention: electrophysiological signals predict errors up to 20 s before they occur</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>8604</fpage><lpage>8611</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5967-08.2009</pub-id><pub-id pub-id-type="pmid">19571151</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ortuño</surname> <given-names>F</given-names></name><name><surname>Ojeda</surname> <given-names>N</given-names></name><name><surname>Arbizu</surname> <given-names>J</given-names></name><name><surname>López</surname> <given-names>P</given-names></name><name><surname>Martí-Climent</surname> <given-names>JM</given-names></name><name><surname>Peñuelas</surname> <given-names>I</given-names></name><name><surname>Cervera</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Sustained attention in a counting task: normal performance and functional neuroanatomy</article-title><source>NeuroImage</source><volume>17</volume><fpage>411</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1006/nimg.2002.1168</pub-id><pub-id pub-id-type="pmid">12482094</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Périn</surname> <given-names>B</given-names></name><name><surname>Godefroy</surname> <given-names>O</given-names></name><name><surname>Fall</surname> <given-names>S</given-names></name><name><surname>de Marco</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Alertness in young healthy subjects: an fMRI study of brain region interactivity enhanced by a warning signal</article-title><source>Brain and Cognition</source><volume>72</volume><fpage>271</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.bandc.2009.09.010</pub-id><pub-id pub-id-type="pmid">19875216</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The brain's default mode network</article-title><source>Annual Review of Neuroscience</source><volume>38</volume><fpage>433</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071013-014030</pub-id><pub-id pub-id-type="pmid">25938726</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Reason</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><source>Human Errorx</source><publisher-loc>Cambridge, United Kingdom</publisher-loc><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reason</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Human error: models and management</article-title><source>BMJ</source><volume>320</volume><fpage>768</fpage><lpage>770</lpage><pub-id pub-id-type="doi">10.1136/bmj.320.7237.768</pub-id><pub-id pub-id-type="pmid">10720363</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rich</surname> <given-names>AN</given-names></name><name><surname>Kunar</surname> <given-names>MA</given-names></name><name><surname>Van Wert</surname> <given-names>MJ</given-names></name><name><surname>Hidalgo-Sotelo</surname> <given-names>B</given-names></name><name><surname>Horowitz</surname> <given-names>TS</given-names></name><name><surname>Wolfe</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Why do we miss rare targets? exploring the boundaries of the low prevalence effect</article-title><source>Journal of Vision</source><volume>8</volume><elocation-id>15</elocation-id><pub-id pub-id-type="doi">10.1167/8.15.15</pub-id><pub-id pub-id-type="pmid">19146299</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenberg</surname> <given-names>M</given-names></name><name><surname>Noonan</surname> <given-names>S</given-names></name><name><surname>DeGutis</surname> <given-names>J</given-names></name><name><surname>Esterman</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>75</volume><fpage>426</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.3758/s13414-012-0413-x</pub-id><pub-id pub-id-type="pmid">23299180</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouder</surname> <given-names>JN</given-names></name><name><surname>Morey</surname> <given-names>RD</given-names></name><name><surname>Speckman</surname> <given-names>PL</given-names></name><name><surname>Province</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Default bayes factors for ANOVA designs</article-title><source>Journal of Mathematical Psychology</source><volume>56</volume><fpage>356</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2012.08.001</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinstein</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Divergent response-time patterns in vigilance decrement tasks</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>46</volume><fpage>1058</fpage><lpage>1076</lpage><pub-id pub-id-type="doi">10.1037/xhp0000813</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadaghiani</surname> <given-names>S</given-names></name><name><surname>Poline</surname> <given-names>JB</given-names></name><name><surname>Kleinschmidt</surname> <given-names>A</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Ongoing dynamics in large-scale functional connectivity predict perception</article-title><source>PNAS</source><volume>112</volume><fpage>8463</fpage><lpage>8468</lpage><pub-id pub-id-type="doi">10.1073/pnas.1420687112</pub-id><pub-id pub-id-type="pmid">26106164</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schnell</surname> <given-names>K</given-names></name><name><surname>Heekeren</surname> <given-names>K</given-names></name><name><surname>Schnitker</surname> <given-names>R</given-names></name><name><surname>Daumann</surname> <given-names>J</given-names></name><name><surname>Weber</surname> <given-names>J</given-names></name><name><surname>Hesselmann</surname> <given-names>V</given-names></name><name><surname>Möller-Hartmann</surname> <given-names>W</given-names></name><name><surname>Thron</surname> <given-names>A</given-names></name><name><surname>Gouzoulis-Mayfrank</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>An fMRI approach to particularize the frontoparietal network for visuomotor action monitoring: detection of incongruence between test subjects' actions and resulting perceptions</article-title><source>NeuroImage</source><volume>34</volume><fpage>332</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.08.027</pub-id><pub-id pub-id-type="pmid">17046287</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Singleton</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="1953">1953</year><source>Deterioration of Performance on a Short-Term Perceptual-Motor Task</source></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname> <given-names>J</given-names></name><name><surname>Schooler</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The restless mind</article-title><source>Psychological Bulletin</source><volume>132</volume><fpage>946</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.132.6.946</pub-id><pub-id pub-id-type="pmid">17073528</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sturm</surname> <given-names>W</given-names></name><name><surname>de Simone</surname> <given-names>A</given-names></name><name><surname>Krause</surname> <given-names>BJ</given-names></name><name><surname>Specht</surname> <given-names>K</given-names></name><name><surname>Hesselmann</surname> <given-names>V</given-names></name><name><surname>Radermacher</surname> <given-names>I</given-names></name><name><surname>Herzog</surname> <given-names>H</given-names></name><name><surname>Tellmann</surname> <given-names>L</given-names></name><name><surname>Müller-Gärtner</surname> <given-names>HW</given-names></name><name><surname>Willmes</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Functional anatomy of intrinsic alertness: evidence for a fronto-parietal-thalamic-brainstem network in the right hemisphere</article-title><source>Neuropsychologia</source><volume>37</volume><fpage>797</fpage><lpage>805</lpage><pub-id pub-id-type="doi">10.1016/S0028-3932(98)00141-9</pub-id><pub-id pub-id-type="pmid">10408647</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tana</surname> <given-names>MG</given-names></name><name><surname>Montin</surname> <given-names>E</given-names></name><name><surname>Cerutti</surname> <given-names>S</given-names></name><name><surname>Bianchi</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Exploring cortical attentional system by using fMRI during a continuous performance test</article-title><source>Computational Intelligence and Neuroscience</source><volume>2010</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1155/2010/329213</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Temple</surname> <given-names>JG</given-names></name><name><surname>Warm</surname> <given-names>JS</given-names></name><name><surname>Dember</surname> <given-names>WN</given-names></name><name><surname>Jones</surname> <given-names>KS</given-names></name><name><surname>LaGrange</surname> <given-names>CM</given-names></name><name><surname>Matthews</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The effects of signal salience and caffeine on performance, workload, and stress in an abbreviated vigilance task</article-title><source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source><volume>42</volume><fpage>183</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1518/001872000779656480</pub-id><pub-id pub-id-type="pmid">11022879</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thakral</surname> <given-names>PP</given-names></name><name><surname>Slotnick</surname> <given-names>SD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The role of parietal cortex during sustained visual spatial attention</article-title><source>Brain Research</source><volume>1302</volume><fpage>157</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2009.09.031</pub-id><pub-id pub-id-type="pmid">19765554</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>VanRullen</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The power of the feed-forward sweep</article-title><source>Advances in Cognitive Psychology</source><volume>3</volume><fpage>167</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.2478/v10053-008-0022-3</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warm</surname> <given-names>JS</given-names></name><name><surname>Parasuraman</surname> <given-names>R</given-names></name><name><surname>Matthews</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Vigilance requires hard mental work and is stressful</article-title><source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source><volume>50</volume><fpage>433</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1518/001872008X312152</pub-id><pub-id pub-id-type="pmid">18689050</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weissman</surname> <given-names>DH</given-names></name><name><surname>Roberts</surname> <given-names>KC</given-names></name><name><surname>Visscher</surname> <given-names>KM</given-names></name><name><surname>Woldorff</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The neural bases of momentary lapses in attention</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>971</fpage><lpage>978</lpage><pub-id pub-id-type="doi">10.1038/nn1727</pub-id><pub-id pub-id-type="pmid">16767087</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wingen</surname> <given-names>M</given-names></name><name><surname>Kuypers</surname> <given-names>KP</given-names></name><name><surname>van de Ven</surname> <given-names>V</given-names></name><name><surname>Formisano</surname> <given-names>E</given-names></name><name><surname>Ramaekers</surname> <given-names>JG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sustained attention and serotonin: a pharmaco-fMRI study</article-title><source>Human Psychopharmacology: Clinical and Experimental</source><volume>23</volume><fpage>221</fpage><lpage>230</lpage><pub-id pub-id-type="doi">10.1002/hup.923</pub-id><pub-id pub-id-type="pmid">18257001</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname> <given-names>JM</given-names></name><name><surname>Horowitz</surname> <given-names>TS</given-names></name><name><surname>Kenner</surname> <given-names>NM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Rare items often missed in visual searches</article-title><source>Nature</source><volume>435</volume><fpage>439</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1038/435439a</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolfe</surname> <given-names>JM</given-names></name><name><surname>Horowitz</surname> <given-names>TS</given-names></name><name><surname>Van Wert</surname> <given-names>MJ</given-names></name><name><surname>Kenner</surname> <given-names>NM</given-names></name><name><surname>Place</surname> <given-names>SS</given-names></name><name><surname>Kibbi</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Low target prevalence is a stubborn source of errors in visual search tasks</article-title><source>Journal of Experimental Psychology: General</source><volume>136</volume><fpage>623</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.136.4.623</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolgar</surname> <given-names>A</given-names></name><name><surname>Hampshire</surname> <given-names>A</given-names></name><name><surname>Thompson</surname> <given-names>R</given-names></name><name><surname>Duncan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Adaptive coding of task-relevant information in human frontoparietal cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>14592</fpage><lpage>14599</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2616-11.2011</pub-id><pub-id pub-id-type="pmid">21994375</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolgar</surname> <given-names>A</given-names></name><name><surname>Afshar</surname> <given-names>S</given-names></name><name><surname>Williams</surname> <given-names>MA</given-names></name><name><surname>Rich</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="2015">2015a</year><article-title>Flexible coding of task rules in frontoparietal cortex: an adaptive system for flexible cognitive control</article-title><source>Journal of Cognitive Neuroscience</source><volume>27</volume><fpage>1895</fpage><lpage>1911</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00827</pub-id><pub-id pub-id-type="pmid">26058604</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolgar</surname> <given-names>A</given-names></name><name><surname>Williams</surname> <given-names>MA</given-names></name><name><surname>Rich</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="2015">2015b</year><article-title>Attention enhances multi-voxel representation of novel objects in frontal, parietal and visual cortices</article-title><source>NeuroImage</source><volume>109</volume><fpage>429</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.12.083</pub-id><pub-id pub-id-type="pmid">25583612</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Woolgar</surname> <given-names>A</given-names></name><name><surname>Dermody</surname> <given-names>N</given-names></name><name><surname>Afshar</surname> <given-names>S</given-names></name><name><surname>Williams</surname> <given-names>MA</given-names></name><name><surname>Rich</surname> <given-names>AN</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Meaningful patterns of information in the brain revealed through analysis of errors</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/673681</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoss</surname> <given-names>RE</given-names></name><name><surname>Moyer</surname> <given-names>NJ</given-names></name><name><surname>Hollenhorst</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Pupil size and spontaneous pupillary waves associated with alertness, drowsiness, and sleep</article-title><source>Neurology</source><volume>20</volume><elocation-id>545</elocation-id><pub-id pub-id-type="doi">10.1212/WNL.20.6.545</pub-id><pub-id pub-id-type="pmid">5463609</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname> <given-names>MS</given-names></name><name><surname>Stanton</surname> <given-names>NA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Malleable attentional resources theory: a new explanation for the effects of mental underload on performance</article-title><source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source><volume>44</volume><fpage>365</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1518/0018720024497709</pub-id><pub-id pub-id-type="pmid">12502155</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zellner</surname> <given-names>A</given-names></name><name><surname>Siow</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1980">1980</year><chapter-title>Posterior odds ratios for selected regression hypotheses</chapter-title><person-group person-group-type="editor"><name><surname>Bernardo</surname> <given-names>J. M</given-names></name><name><surname>DeGroot</surname> <given-names>M. H</given-names></name><name><surname>Lindley</surname> <given-names>D. V</given-names></name><name><surname>Smith</surname> <given-names>A. F. M</given-names></name></person-group><source>Bayesian Statistics: Proceedings of the First International Meeting Held in Valencia (Spain)</source><publisher-name>University of Valencia</publisher-name><fpage>585</fpage><lpage>603</lpage></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Supplementary materials</title><boxed-text><sec id="s9"><title>Source text file for <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref></title><p>Our first analysis was to verify that our analyses could decode the important aspects of the display, relative to chance, given the overlapping moving stimuli. Here, we give the detailed results of this analysis.</p><p>We started with the information about the <italic>direction of approach</italic> (top left or bottom right of screen) which is a strong visual signal but not critical to the task decision. From 95 ms post-stimulus onset onwards, this visual information could be decoded from the MEG signal for all combinations of the factors: Attended and Unattended dots, both Target Frequency conditions (Active, Monitoring), and both our Time on Task durations (Early – first 5 blocks; Late – last 5 blocks; all BF &gt; 3, different from chance).</p><p>All conditions were decodable above chance until at least 385 ms post-stimulus onset (BF &gt; 3; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>), which was when the dots came closer to the centre, losing their visual difference. There was a rapid increase in information about the direction of approach between 50 ms and 150 ms post-stimulus onset, consistent with an initial forward sweep of visual information processing (<xref ref-type="bibr" rid="bib69">VanRullen, 2007</xref>; <xref ref-type="bibr" rid="bib33">Karimi-Rouzbahani et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Karimi-Rouzbahani et al., 2019</xref>). For attended dots only (but regardless of the Target Frequency or Time on Task), the information then increased again before the deflection time, and remained different from chance until 1915 ms post-stimulus onset, which is just before the dot faded (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). The second rise of decoding, which was more pronounced for the attended dots, could reflect the increasing relevance to the task as the dot approached the crucial deflection point, but it could also be due to higher visual acuity in foveal compared to peripheral areas of the visual field. The decoding peak observed after the deflection point for the attended dots was most probably caused by the large visual difference between the deflection trajectories for the dots approaching from the left vs. right side of the screen (see the deflection trajectories in <xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><p>The most task-relevant feature of the motion is the distance between the moving dot and the central object, with the deflection point of the trajectories being the key decision point. We therefore tested for decoding of <italic>distance</italic> information (<italic>distance to object,</italic> see Materials and methods). There was a brief increase in decoding of <italic>distance to object</italic> for attended dots across the other factors (Target Frequency and Time on Task) between the 15th and 10th distances and for the unattended dots across the other factors between 15th and the 12th distances. This corresponds to the first 400 ms for the attended dots and the first 240 ms for the unattended dots after the onset (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). <italic>Distance</italic> decoding then dropped somewhat before ascending again as the dot approached the deflection point. The second rise of decoding, which was more pronounced for the attended dots, could reflect the increasing relevance to the task as the dot approached the crucial deflection point, but it could also be due to higher visual acuity in foveal compared to peripheral areas of the visual field. There was moderate or strong evidence that decoding of <italic>distance</italic> information for all attended conditions was greater than chance (50%, BF &gt; 3) across all 15 distance levels with the exception of distance 8 in the late monitoring condition (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>, left panels). There were also timepoints with greater than chance decoding for the unattended conditions but these were far less consistent (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>, right panels).</p></sec></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60563.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Kok</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>In our modern work environment there are many situations where humans have to pay sustained attention in order to catch infrequent computer errors, such as while monitoring railway systems. Combining a novel multiple-object monitoring task with computationally sophisticated analyses of human magnetoencephalography (MEG) data, Karimi-Rouzbahani and colleagues find that increasing the rarity of targets leads to a worse neural representation of a crucial target feature (distance to a potential collision). They were also able to predict whether participants would catch or miss a target based on their neural data, which may prove a first step towards developing methods to pre-empt such potentially disastrous errors.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Neural signatures of vigilance decrements predict behavioural errors before they occur&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Floris de Lange as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional analyses are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>Karimi-Rouzbahani and colleagues investigate vigilance and sustained monitoring, using a multiple-object monitoring task in combination with magnetoencephalography (MEG) recordings in humans to investigate the neural coding and decoding-based connectivity of vigilance decrements. Using computationally sophisticated multivariate analyses of the MEG data, they found that increasing the rarity of targets led to weaker decoding accuracy for the crucial feature (distance to an object), and weaker decoding was also found for misses compared to correct responses.</p><p>While the reviewers agreed the study was interesting, they also had concerns about the approach and the interpretation of the results.</p><p>Essential revisions:</p><p>1. The introduction makes it clear that the authors acknowledge that there may be multiple sources of interference contributing to declining vigilance over time: the encoding of sensory information, appropriate responses to the stimuli, or a combination of both. In the introduction, it would help if the authors review how infrequent targets affect response patterns. In addition, it would help if the theoretical approach and assumptions of the authors were explicitly stated. For instance, the a priori assumptions surrounding the connectivity analysis should be acknowledged and discussed in the interpretation of the pattern of results (e.g., p. 32, line 658). Specifically, the focus on connectivity between frontal and occipital areas seems to assume the effects are related to sensory processing alone, but this does not preclude other influences. For instance, effects could also occur on response patterns. These considerations should be added as caveats to the interpretation.</p><p>2. It is not clear what role eye fixations play here. Participants could freely scan the display, so the retinotopic representations would change depending on where the participants fixate, but at the same time the authors claim that eye position did not matter. Materials and methods, Page 11: The authors state that &quot;We did not perform eye-blink artefact removal because it has been shown that blink artefacts are successfully ignored by multivariate classifiers as long as they are not systematically different between decoded conditions (Grootswagers et al., 2017).&quot; This is not a sufficiently convincing argument. Firstly, the cited paper makes a theoretical argument rather than showing this empirically. Secondly, even if this were true, the frequency of eye-related artefacts seems to be of crucial importance for a paradigm that involves moving stimuli (and no fixation). There could indeed be systematic differences between conditions that are then picked up by the classifier (i.e. if more eye-blinks are related to tiredness and in turn decreased vigilance). The authors should show that their results replicate if standard artefact removal is performed on the data.</p><p>Relatedly, on page 16 the authors claim that &quot;If the prediction from the MEG decoding was stronger than that of the eye tracking, it would mean that there was information in the neural signal over and above any artefact associated with eye movement.&quot; This statement is problematic: Firstly, such a result might only mean that prediction from MEG decoding is stronger than decoding from eye-movements, but not relate to &quot;artefacts&quot; in general, to which blinks would also count. Secondly, given that the signal underlying both analyses is entirely different (and the number of features), it is not valid to directly compare the results between these analyses. More detailed analyses of fixations and fixation duration on targets and distractors might indeed be strongly related to behaviour. What is decodable at a given time might just be driven by what participants are looking at.</p><p>3. One key finding was that while classifying the direction of the dots was modulated by attention, it was insensitive to many features that were captured by a classifier trained to decode the distance from the deflection. This is surprising since both are spatial features that seem hard to separate. In addition, the procedures to decode direction vs distance were very different. Do these differences still hold if the procedure used to train the two classifiers is more analogous or matched?</p><p>4. The distance classifier was trained using only correct trials. Then in the testing stage, it was generalized to either correct or miss trials. While there is a rationale for using correct trials only, could the decoding of error prediction be an artifact of the training sample, reflecting the fact that misses were not included in the training set?</p><p>5. By accumulating classifiers across time, it looks like classifier prediction improves closer to deflection. However, this could also be due to the fact that the total amount of information provided to the classifier increased. Is there a way to control for the total amount of information at different timepoints (e.g., by using a trailing window lag rather than accumulation), or contrast the classifier that derives from accumulating information with the classifier trained moment-by-moment?</p><p>6. Predicting miss trials: The implicit assumption here is that there is &quot;less representation&quot; for miss trials compared to correct trials (e.g., of distance to object). But even for miss trials, the representation is significantly above chance. However, maybe the lower accuracy for the miss trials resulted from on average more trials in which the target was not represented at all rather than a weaker representation across all trials. This would call into questions the interpretation of a decline in coding. In other words, on a single trial, a representation might only be present (but could result in a miss for other reasons) or not present (which would be the case for many miss trials), and the lower averages for misses would then be the result of more trials in which the information was completely absent.</p><p>It could be that the results of the subsequent analysis (predicting misses and correct responses before they occur) are in conflict with this more pessimistic interpretation. If we understand this correctly, here the classifier predicts Distance to Object for each individual trial, and Figure 6B shows that while there is a clear difference between the correct and miss trials, the latter can still be predicted above chance level but never exceed the threshold? If this is true for all single trials, this would indeed speak for a weak but &quot;unused&quot; representation on miss trials. But for this the authors need to show how many of the miss trials per participant had a chance-level accuracy (i.e. might be truly unrepresented), and how many were above chance but did not exceed the threshold (i.e. might have been &quot;less represented&quot;).</p><p>7. The relationship between the vigilance decrement and error prediction. Is vigilance decrement driving the error prediction? That is, if errors increase later on, and the signal goes down, then maybe the classifier is worse. Alternatively, maybe the classifier predictions do not necessarily monotonically decrease throughout the experiment. Is the classifier equally successful at predicting errors early and late?</p><p>8. When decoding distance, active decoding declines from early to late, even though performance does not decline (or even slightly improves from early to late). This discrepancy seems hard to explain. Is this decline in classification driven by differences in the total signal from early to late?</p><p>9. Classifier performance was extremely high almost immediately after trial onset. Does the classifier perform at chance before the trial onset, or does this reflect sustained but not stimulus-specific information?</p><p>10. The connectivity analysis appears to be just a correlation of decoding results between two regions of interest. This means, if one &quot;region&quot; allows for decoding the distance to the object, the other one does too. However, this alone does not equal connectivity. It could simply mean that patterns across the entire brain allow for decoding the same information. For example, it would not be surprising to find that both ROIs correlate more strongly for correct trials (i.e. the brain has obviously represented the relevant information) than for errors (i.e. the brain has failed to represent the information), without this necessarily being related to connectivity at all. The more parsimonious interpretation here is that information might have been represented across all channels at this time. The authors show no evidence that only these two (arbitrarily selected) &quot;regions&quot; encode the information while other do not. To show evidence for meaningful connectivity, (a) the spread of information should be limited to small sub-regions, and (b) the decoding results in one &quot;region&quot; should predict the results in another region in time (as for DCM).</p><p>11. The display of the results is very dense, and it not always clear whether decoding for a specific variable was above chance or not. The authors often focused on relative differences, making it difficult to fully understand the meaning of the full pattern of results. The Bayes-factor plots in the decoding results figures are so cramped that it is very difficult to actually see the individual dots and to unpack all of this (e.g., Figure 3). Could this complexity be somehow reduced, maybe by dividing the panels into separate figures? The two top panels in Figure 3B should also include the chance level as in A. It looks like the accuracy is very low for unattended trials, which is only true in comparison to attended trials, but (as also shown in Supplementary Figure 1) it was clearly also encoded in unattended trials, which is very important for interpreting the results.</p><p>12. While this is methodologically interesting work, there is no convincing case made for what exactly the contribution of this study is for theories of vigilance. It seems that the findings can be reduced to that a lack of decodability of relevant target features from brain activity predicts that participants will miss the target. This alone, however, does not seem to be very novel. Even if the issues above are addressed, the study only demonstrates that with less attention to the target, there is less evidence of representations of the relevant features of targets in the brain. The authors also find the expected decrements for rare targets and when participants do not actively monitor the targets. How do these findings contribute to &quot;theories of vigilance&quot;, as claimed by the authors?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60563.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. The introduction makes it clear that the authors acknowledge that there may be multiple sources of interference contributing to declining vigilance over time: the encoding of sensory information, appropriate responses to the stimuli, or a combination of both. In the introduction, it would help if the authors review how infrequent targets affect response patterns.</p></disp-quote><p>We added the relevant information about response patterns to the Introduction as below:</p><p>“To date, most vigilance and rare target studies have used simple displays with static stimuli. […] Overall, vigilance decrements in terms of poorer performance can be seen in both accuracy and in reaction times, depending on the task.”</p><disp-quote content-type="editor-comment"><p>In addition, it would help if the theoretical approach and assumptions of the authors were explicitly stated. For instance, the a priori assumptions surrounding the connectivity analysis should be acknowledged and discussed in the interpretation of the pattern of results (e.g., p. 32, line 658). Specifically, the focus on connectivity between frontal and occipital areas seems to assume the effects are related to sensory processing alone, but this does not preclude other influences. For instance, effects could also occur on response patterns. These considerations should be added as caveats to the interpretation.</p></disp-quote><p>We have now carefully reviewed the manuscript to be sure our assumptions and approach for the connectivity analyses are explicit. We have added the suggested material to the interpretation of the pattern of results, and acknowledge the potential for other influences on the connectivity results as caveats to our interpretation.</p><p>We now limit our discussion of the connectivity results as relevant to evaluating sensory aspects of information encoding (in the Materials and methods section) as below:</p><p>“There are a few considerations in the implementation and interpretation of our connectivity analysis. First, it reflects the similarity of the way a pair of brain areas encode “distance” information during the whole trial. This means that we could not use the component of time in the evaluation of our connectivity as we have implemented elsewhere (Karimi-Rouzbahani et al., 2019; Karimi-Rouzbahani et al., 2020). Second, rather than a simple correlation of magnitudes of decoding accuracy between two regions of interest, our connectivity measure reflects a correlation of the patterns of decoding accuracies across conditions (i.e., distances here). Finally, our connectivity analysis evaluates sensory information encoding, rather than other aspects of cognitive or motor information encoding, which might have also been affected by our experimental manipulations.”</p><p>We now provide the rationale and our predictions about the impact of visual and auditory attention on our connectivity metric (in the Results section) based on the literature, as below.</p><p>“In line with attentional effects on sensory perception, we predicted that connectivity between the frontal attentional and sensory networks should be lower when not attending (vs. attending; Goddard et al., 2019). Behavioural errors were also previously predicted by reduced connection between sensory and ‘vigilance-related’ frontal brain areas (Ekman et al., 2012; Sadaghiani et al., 2015). Therefore, we predicted a decline in connectivity when targets were lower in frequency, and with increased time on task, as these led to increased errors in behaviour, specifically under vigilance conditions in our task (i.e., late blocks in Monitoring vs. late blocks in Active; Figure 2).”</p><p>We have toned down our conclusions (a) and added the possibility that other factors could also contribute to our vigilance decrement effects in the Discussion, as below (b).</p><p>a) “One explanation for the decrease in decoding accuracy for task-relevant information could be that when people monitor for rare targets, they process or encode the relevant sensory information less effectively as the time passes, relative to conditions in which they are actively engaged in completing the task.”</p><p>b) “Apart from sensory information coding and sensory-based informational connectivity, which were evaluated here and provide plausible neural correlates for the vigilance decrement, there may be other correlates we have not addressed. Effects on response-level selection, for example, independently or in conjunction with sensory information coding, could also affect performance under vigilance conditions, and need further research.”</p><disp-quote content-type="editor-comment"><p>2. It is not clear what role eye fixations play here. Participants could freely scan the display, so the retinotopic representations would change depending on where the participants fixate, but at the same time the authors claim that eye position did not matter.</p></disp-quote><p>We did not mean to claim that eye position doesn’t matter at all, but rather that our design ensures minimal effect of eye-related artefacts on the classifiers. We have carefully revised the manuscript to ensure this is clear (detailed response and additional analyses below).</p><disp-quote content-type="editor-comment"><p>Materials and methods, Page 11: The authors state that &quot;We did not perform eye-blink artefact removal because it has been shown that blink artefacts are successfully ignored by multivariate classifiers as long as they are not systematically different between decoded conditions (Grootswagers et al., 2017).&quot; This is not a sufficiently convincing argument. Firstly, the cited paper makes a theoretical argument rather than showing this empirically. Secondly, even if this were true, the frequency of eye-related artefacts seems to be of crucial importance for a paradigm that involves moving stimuli (and no fixation). There could indeed be systematic differences between conditions that are then picked up by the classifier (i.e. if more eye-blinks are related to tiredness and in turn decreased vigilance). The authors should show that their results replicate if standard artefact removal is performed on the data.</p></disp-quote><p>We appreciate the point here. There are theoretical and practical arguments that eye-related artefacts should not drive our effects, but to be sure we also now present our results with standard artefact removal as well.</p><p>Overall increases in eye-related artefacts (such as blinks) over time-on-task would not be an issue, as our design relies on comparisons between Active and Monitoring, and so any general effects should have negligible impact. But for these comparisons, there may indeed be differences in the number of eye blinks – and in fact, these conditions involve different levels of attentional recruitment, which has previously shown to correlate with the frequency of eye blinks (Nakano et al., 2013). Thus, we certainly do not want to claim that eye-related artefacts do not matter at all, but, importantly, there are two practical reasons that the effects of eye blinks should not be dominantly picked up by our classification procedure. First, the decoding analysis is time-resolved and computed in small time windows (5 ms and 80 ms, for direction and distance information decoding, respectively). For eye blink patterns to be picked up by the classifier, they would need to occur at consistent time points across trials of the same condition, and not in the other condition, which seems implausible. Second, our MEG helmet does not have the very frontal sensors where eye-related artefacts most strongly affect neural activations (Mognon et al., 2011), but we appreciate that this does not rule out their presence altogether.</p><p>To check empirically that eye-related artefacts were not driving our effects, we re-ran our analyses with standard artefact removal as requested. We see the same pattern of results as before, for both the key task-relevant feature of distance-to-object and the less relevant feature of direction of approach. We present the full comparative analysis in Figure 3—figure supplement 2. In the paper we now state that the results replicate with artefact removal and present the additional eye-movement-corrected results in the supplementary materials.</p><p>“…,we also did a post-hoc analysis in which we removed these using “runica” Independent Components Analysis (ICA) algorithm as implemented by EEGLAB. We used the ADJUST plugin (Mognon et al., 2011) of EEGLAB to decide which ICA components were related to eye artefacts for removal. This toolbox extracts spatiotemporal features from components to quantitatively measure if a component is related to eye movements or blinks. For all subjects except two, we identified only 1 component which were attributed to eye artefacts (i.e., located frontally and surpassing the ADJUST’s threshold) which we removed. For the two other participants, we identified and removed two components with these characteristics.”</p><p>Figure 3—figure supplement 2B shows the decoding results for the key task-relevant feature of distance-to-object without and with eye-related artefact removal, in the left and right panels, respectively. The main effects of attention and time on the task and the key interaction between target frequency and time on the task remain after eye artefact removal, replicating our initial pattern of results.</p><p>Figure 3—figure supplement 2A shows the decoding results for the direction of approach information without and with eye artefact removal. The results again replicate those of the original analysis: as before there is a main effect of Attention but no main effect of Time on Task or Target Frequency, and no interaction.</p><p>We also checked to see if our trial outcome prediction (Figure 6D) could be driven by eye artefacts by repeating our prediction procedure using the eye-movement corrected MEG data. The results (<xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>) show that although removal of eye artefacts seems to reduce the prediction accuracy slightly overall, it only has minimal effect on the statistics, replicating our original findings. We can still predict the outcome of the trial with &gt;80% accuracy at closer distances.</p><fig id="sa2fig1"><label>Author response image 1.</label><caption><title>The accuracy of predicting behavioral outcome of trials without and with eye artefact removal.</title><p>The results are for the left-out participant (averaged over all participants) using the threshold obtained from all the other participants as function of distance/time from the deflection point. Figure 6D shows the result without eye artefact removal and <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> with eye artefact removal. Thick lines and shading refer to average and one standard deviation around the mean across participants, respectively. Bayes Factors are shown in the bottom section of each graph: Filled circles show moderate/strong evidence for either hypothesis and empty circles indicate insufficient evidence.</p></caption><graphic xlink:href="elife-60563-resp-fig1-v3.tif" mimetype="image" mime-subtype="tiff"/></fig><p>In the Materials and methods section, we removed the sentence “We did not perform eye-blink artefact removal because it has been shown that blink artefacts are successfully ignored by multivariate classifiers as long as they are not systematically different between decoded conditions (Grootswagers et al., 2017).”</p><p>We also added the following explanations and the figures to the manuscript in the Results section to cover this point.</p><p>“Although eye-movements should not drive the classifiers due to our design (see Materials and methods), it is still important to verify that the results replicate when standard artefact removal is applied. We can also use eye-movement data as an additional measure, examining blinks, saccades and fixations for effects of our attention and vigilance manipulations.</p><p>First, to make sure that our neural decoding results replicate after eye-related artefact removal, we repeated our analyses on the data after eye-artefact removal (see Materials and methods), which provided analogous results to the original analysis (see the decoding results without and with artefact removal in Figure 3—figure supplement 2). Specifically, for our crucial distance to object data, the main effects of Attention and Time on Task and the key interaction between Target Frequency and Time on Task remain after eye-artefact removal, replicating our initial pattern of results.</p><p>Second, we conducted a post-hoc analysis to explore whether eye movement data showed the same patterns of vigilance decrements and therefore could explain our decoding results. We extracted the proportion of eye blinks, saccades and fixations per trial as well as the duration of those fixations from the eye-tracking data for correct trials (-100 to 1400 ms aligned to the stimulus onset time), and statistically compared them across our critical conditions (Figure 3—figure supplement 3). We saw strong evidence (BF = 4.8e8) for a difference in the number of eye blinks between attention conditions: There were more eye blinks for the Unattended (distractor) than Attended (potentially targets) colour dots. We also observed moderate evidence (BF = 3.4) for difference between the number of fixations, with more fixations in Unattended vs. Attended conditions. These suggest that there are systematic differences in the number of eye blinks and fixations due to our attentional manipulation, consistent with previous observations showing that the frequency of eye blinks can be affected by the level of attentional recruitment (Nakano et al. 2013). However, there was either insufficient evidence (0.3 &lt; BF &lt; 3) or moderate or strong evidence for no differences (0.1 &lt; BF &lt; 0.3 and BF &lt; 0.3, respectively) between the number of eye blinks and saccades across our Active, Monitoring, Early and Late blocks, where we observed our ‘vigilance decrement’ effects in decoding. Therefore, this suggests that the main vigilance decrement effects in decoding, which were evident as an interaction between Target frequency (Active vs. Monitoring) and Time on the task (Early vs. Late) (Figure 3), were not driven by eye movements.”</p><disp-quote content-type="editor-comment"><p>Relatedly, on page 16 the authors claim that &quot;If the prediction from the MEG decoding was stronger than that of the eye tracking, it would mean that there was information in the neural signal over and above any artefact associated with eye movement.&quot; This statement is problematic: Firstly, such a result might only mean that prediction from MEG decoding is stronger than decoding from eye-movements, but not relate to &quot;artefacts&quot; in general, to which blinks would also count. Secondly, given that the signal underlying both analyses is entirely different (and the number of features), it is not valid to directly compare the results between these analyses. More detailed analyses of fixations and fixation duration on targets and distractors might indeed be strongly related to behaviour. What is decodable at a given time might just be driven by what participants are looking at.</p></disp-quote><p>We take the point on the issues with this comparison, and so have removed the analysis from the manuscript, replacing it instead with more detailed analyses of the eye movement data:</p><p>We extracted the proportion of eye blinks, saccades and fixations per trial as well as the duration of those fixations from the eye-tracking data for correct trials (-100 to 1400 ms aligned to the stimulus onset time), and statistically compared them across our critical conditions as Figure 3—figure supplement 3. We saw strong evidence (BF=4.8e<sup>8</sup>) for a difference in the number of eye blinks between attention conditions: There were more eye blinks for Unattended (distractor) than Attended (potentially targets) color dots. We also observed moderate evidence (BF=3.4) for difference between the number of fixations, with more fixations in Unattended vs Attended conditions. These suggest that there are systematic differences in the number of eye blinks and fixations due to our attentional manipulation, consistent with Nakano et al., (2013). However, we observed either insufficient evidence (0.3&lt;BF&lt;3) or moderate to strong evidence for no difference (0.1&lt;BF&lt;0.3 and BF&lt;0.3, respectively) between the number of eye blinks and saccades across our Active, Monitoring, Early and Late blocks, where we observed our ‘vigilance decrement’ effects in decoding. Consistent with the replication of the results with artefact removal presented above, this suggests that the main vigilance decrement effects in decoding, which were evident as an interaction between Target frequency (Active vs. Monitoring) and Time on the task (Early vs. Late) (Figure 3), were not driven by eye movements.</p><p>This information has also been added to the supplementary materials (Figure 3—figure supplement 3) and referred to in the manuscript (text quoted under previous bullet point).</p><disp-quote content-type="editor-comment"><p>3. One key finding was that while classifying the direction of the dots was modulated by attention, it was insensitive to many features that were captured by a classifier trained to decode the distance from the deflection. This is surprising since both are spatial features that seem hard to separate.</p></disp-quote><p>Yes, we see vigilance decrement effects for the distance information but not the direction of approach. Although they both rely on similar features of the visual display, the direction information classifier is likely to be driven primarily by the large visual difference between the categories (approach from the left vs approach from the right). In the key distance measure, we collapse across left and right approaching dots, which means the classifier has to use much more subtle differences (and is therefore more likely to be sensitive to other modulations). Moreover, the two types of information also differ in their importance to the task: Only the distance information is relevant to deciding whether an item is a target.</p><p>We have added to the Discussion noting this point.</p><p>“The less relevant information about direction of approach was modulated by attention, but its representation was not detectably affected by target frequency and time on task, and was noisier, but not noticeably attenuated, on error trials. The relative stability of these representations might reflect the large visual difference between stimuli approaching from the top left vs bottom right of the screen. In contrast, the task-relevant information of distance to object was affected by attention, target frequency and time on task and was dramatically attenuated on errors. The difference might reflect the fact that only the distance information is relevant to deciding whether an item is a target, and/or the classifier having to rely on much more subtle differences to distinguish the distance categories, which collapsed over stimuli appearing on the left and right sides of the display, removing the major visual signal.”</p><disp-quote content-type="editor-comment"><p>In addition, the procedures to decode direction vs distance were very different. Do these differences still hold if the procedure used to train the two classifiers is more analogous or matched?</p></disp-quote><p>In terms of technical differences in the decoding procedure between distance and direction information, we cannot directly compare the two types of information on an analogous platform because they have to be defined differently. There are a different number of classes in decoding for the two types of information: only two classes for the <italic>direction</italic> information (left vs. right), compared to the 15 classes for the distance information (15 distances). Therefore, if anything, the decoding of distance should result in less information compared to the direction of approach as the higher number of classes in decoding could potentially result in more noise in the data by decreasing signal to noise ratio per class.</p><p>We have added the following paragraph to the Materials and methods section to clarify the point:</p><p>“Note that the ‘direction of approach’ and ‘distance to object’ information cannot be directly compared on an analogous platform as the two types of information are defined differently. There are also different number of classes in decoding for the two types of information: only two classes for the direction information (left vs. right), compared to the 15 classes for the distance information (15 distances).”</p><disp-quote content-type="editor-comment"><p>4. The distance classifier was trained using only correct trials. Then in the testing stage, it was generalized to either correct or miss trials. While there is a rationale for using correct trials only, could the decoding of error prediction be an artifact of the training sample, reflecting the fact that misses were not included in the training set?</p></disp-quote><p>No, we do not think there is any way it could be an artefact. Our hypothesis is that correct trials contain information which is missing from miss trials. In other words, miss trials are in some way different from correct trials. Thus, it is crucial to use only correct trials in the training set. Please note that our approach is different from most conventional studies in which people directly discriminate correct and miss trials by feeding both types of trials to classifiers in the training phase and test the classifiers on the left-out correct and miss trials (i.e., without any feature extraction; as in Bode and Stahl, 2014). While this standard approach might lead to a higher classification performance, we developed our new approach for two main reasons. First, in the real world and many vigilance studies, there is usually not enough miss data to train classifiers. Second, we wanted to directly test whether the neural representations of correct trials contain some information which is (on average) less observable in miss trials. The result of conventional methods can reflect general differences between correct and miss trials (i.e., general level of attention, not time-locked to stimulus presentation), but cannot inform us about whether the difference reflects changes in information coding in the correct vs. miss trials; our approach allows this more specific inference.</p><p>In our approach, we trained our classifiers on correct trials and tested them on both correct and miss trials. Crucially, we tested the trained classifiers only on unseen data for both correct and miss trials. Specifically, when testing the classifiers, we used only the correct trials which were not used in the training phase. Therefore, there is no artefactual reason that the testing trials should be more similar to the training-phase trials for the correct compared to miss trials; the decoding prediction works because the correct testing trials have more similar neural representations to the correct training trials than the miss testing trials do.</p><p>We have added an explanation of the difference between approaches to the manuscript to ensure this point is clearer to the reader.</p><p>“Our method is different from the conventional method of error prediction, in which people directly discriminate correct and miss trials by feeding both types of trials to classifiers in the training phase and testing the classifiers on the left-out correct and miss trials (e.g., Bode and Stahl, 2014). Our method only uses correct trials for training, which makes its implementation plausible for real-world situations since we usually have plenty of correct trials and only few miss trials (i.e., cases when the railway controller diverts the trains correctly vs. misses and a collision happens). Moreover, it allows us to directly test whether the neural representations of correct trials contain information which is (on average) less observable in miss trials. We statistically compared the two types of trials and showed a large advantage in the level of information contained at individual-trial-level in correct vs. miss trials.”</p><disp-quote content-type="editor-comment"><p>5. By accumulating classifiers across time, it looks like classifier prediction improves closer to deflection. However, this could also be due to the fact that the total amount of information provided to the classifier increased. Is there a way to control for the total amount of information at different timepoints (e.g., by using a trailing window lag rather than accumulation), or contrast the classifier that derives from accumulating information with the classifier trained moment-by-moment?</p></disp-quote><p>Although it is likely that some of the increase in information reflects increased attention as the dot approaches the object, we think primarily that yes, the improved prediction power closer to the central object is likely to be due to accumulation of information (Figure 6D) and it will decline if we use a subsample of the accumulated information. We took this approach as the main purpose of our prediction analysis was to predict the outcome of the trial with maximal accuracy. We added the following sentence to the manuscript to clarify the point.</p><p>“In this analysis, the goal was to maximise the accuracy of predicting behaviour. For that purpose, we accumulated classification accuracies along the distances. Moreover, as each classifier performs a binary classification for each testing dot at each distance, the accumulation of classification accuracies also avoided the spurious classification accuracies to drive the decision, providing smooth “accumulated” accuracies for predicting the behaviour.”</p><disp-quote content-type="editor-comment"><p>6. Predicting miss trials: The implicit assumption here is that there is &quot;less representation&quot; for miss trials compared to correct trials (e.g., of distance to object). But even for miss trials, the representation is significantly above chance. However, maybe the lower accuracy for the miss trials resulted from on average more trials in which the target was not represented at all rather than a weaker representation across all trials. This would call into questions the interpretation of a decline in coding. In other words, on a single trial, a representation might only be present (but could result in a miss for other reasons) or not present (which would be the case for many miss trials), and the lower averages for misses would then be the result of more trials in which the information was completely absent.</p><p>It could be that the results of the subsequent analysis (predicting misses and correct responses before they occur) are in conflict with this more pessimistic interpretation. If we understand this correctly, here the classifier predicts Distance to Object for each individual trial, and Figure 6B shows that while there is a clear difference between the correct and miss trials, the latter can still be predicted above chance level but never exceed the threshold? If this is true for all single trials, this would indeed speak for a weak but &quot;unused&quot; representation on miss trials. But for this the authors need to show how many of the miss trials per participant had a chance-level accuracy (i.e. might be truly unrepresented), and how many were above chance but did not exceed the threshold (i.e. might have been &quot;less represented&quot;).</p></disp-quote><p>This is a really good point. Yes, in principle, the average decoding levels could be composed of ‘all or none’ misses or graded drops in information, and it is possible that on some miss trials there is a good representation but the target is missed for other reasons (e.g., a response-level error). As neural data are noisy and multivariate decoding needs cross-validation across sub samples of the data, and because each trial, at each distance, can only be classified correctly or incorrectly by a two-way classifier, we tend not to compare the decoding accuracies in a trial-by-trial manner, but rather on average (Grootswagers et al., 2017). However, if we look at an individual dataset and examine all the miss trials (averaged over the 15 distances and cross-validation runs) in our distance-to-object decoding, we can get some insights into the underlying distributions.</p><p>We show the distribution of individual trial decoding accuracies for all participants on correct (Figure 5—figure supplement 1A) and miss (Figure 5—figure supplement 1B) trials. The vertical axis shows the number of trials in each accuracy bin of the histogram and the horizontal axis shows the decoding accuracy for each trial obtained by averaging its decoding accuracies over cross-validation folds (i.e., done by subsampling the correct trials into train and test sets and repeating the procedure until all correct trials are used once as training data and once as testing data) and distances. We calculated the percentage of miss trials for which there was strong evidence (BF&gt;10) for above-chance decoding accuracies. To do this, we generated a null distribution with 100*N trials, where we produced 1000 decoding accuracies for each trial by randomizing the labels of distances for that trial. We used the same procedure for Bayes analyses as detailed in the manuscript.</p><p>The histograms of individual miss trials suggest a single distribution centred around chance decoding or slightly above (Figure 5—figure supplement 1B). This means that on an individual miss trial, there may be higher or lower decoding, but it is nowhere near the consistent high decoding levels we see for correct trials (Figure 5—figure supplement 1A). This seems consistent with an interpretation that on (most) miss trials, information is less present than on correct trials. Presumably it is this difference that allows our second level classifier to successfully predict the behavioural outcome on &gt;80% of trials.</p><p>In contrast, for the correct trials, all trials (100%) for all subjects showed above-chance (&gt;50%) decoding accuracy, with average accuracies around 80%. This suggest that as opposed to missed trials, in which some trials showed some distance information and some did not, on correct trials, all trials reflect the task-related information.</p><p>In order to quantify the overlap between correct and miss trials in individual trial level (as opposed to group-level Bayes factor analysis in the manuscript (Figure 5)), we calculated the Cohen’s d (Cohen, 1969) between the two distributions. As the results show (Figure 5—figure supplement 2C), there is a large difference (d &gt;2) between the two distributions for every participant and condition. D values were mostly higher than 3 which corresponds to less than 7% overlap between decoding accuracies obtained for the correct and miss trials.</p><p>Overall, this additional analysis demonstrates that although the miss trials vary somewhat in levels of information (as measured by decoding), with some trials representing the distance information while others do not represent the distance information at all, very few miss trials are as informative as the least informative correct trials (the distributions overlap by less than ~7%). The miss trials with high decoding are presumably those on which our second level classifier makes the wrong prediction. We have revised the description in the manuscript to make this clearer and added the following paragraph and analyses to the manuscript.</p><p>“In principle, the average decoding levels could be composed of ‘all or none’ misses or graded drops in information, and it is possible that on some miss trials there is a good representation but the target is missed for other reasons (e.g., a response-level error). As neural data are noisy and multivariate decoding needs cross-validation across sub samples of the data, and because each trial, at each distance, can only be classified correctly or incorrectly by a two-way classifier, we tend not to compare the decoding accuracies in a trial-by-trial manner, but rather on average (Grootswagers et al., 2017). However, if we look at an individual dataset and examine all the miss trials (averaged over the 15 distances and cross-validation runs) in our distance-to-object decoding, we can get some insights into the underlying distributions (Figure 5—figure supplement 1). Results showed that, for all participants, the distribution of classifier accuracies for both correct and miss trials followed approximate normal distributions. However while the distribution of decoding accuracies for correct trials was centred around 80%, the decoding accuracies for individual miss trials were centred around chance-level. We evaluated the difference in the distribution of classification accuracies between the two types of trials using Cohen’s d. Cohen’s d was approximately 3 or higher for all participants and conditions, indicating a large (d &gt; 2; Cohen, 1969) difference between the distribution of correct and miss trials. Therefore, although the miss trials vary somewhat in levels of information, very few (&lt; 7%) miss trials are as informative as the least informative correct trials. These results are consistent with the interpretation that there was less effective representation of the crucial information about the distance from the object preceding a behavioural miss.”</p><disp-quote content-type="editor-comment"><p>7. The relationship between the vigilance decrement and error prediction. Is vigilance decrement driving the error prediction? That is, if errors increase later on, and the signal goes down, then maybe the classifier is worse. Alternatively, maybe the classifier predictions do not necessarily monotonically decrease throughout the experiment. Is the classifier equally successful at predicting errors early and late?</p></disp-quote><p>Thanks for the nice question. Our error prediction results initially were obtained from the whole dataset, including all blocks of trials. To answer the reviewer’s question, we now split the blocks into the first 5 (early) and the last 5 (late) blocks and repeated the error prediction procedure on the five early and late blocks separately. To remove the potential confound of the number of trials, we equalised the number of trials across the early and late time windows. As decoding of distances decreased along the time course of the experiment on correct trials (Figure 3), we would predict that there should be less difference in decoding of correct and miss trials in the later vs earlier blocks. The new analysis bears this out: Prediction accuracy for the trial outcome (correct vs miss) declined in later stages of the experiment (moderate to strong evidence (BF&gt;3) for higher predictability for the trial outcome in early vs. late blocks of the experiment). Importantly, even with the decline in predicting accuracy, it is still possible to predict the behavioural outcome in the late blocks with well above-chance accuracy.</p><p>We have added these results to the supplementary material of the paper (Figure 6—figure supplement 1).</p><p>“The prediction of behavioural outcome (Figure 6) was performed using the data from the whole dataset. However, it is possible that the prediction would not be as accurate in later stages of the experiment (compared to the earlier stages) as the decoding performance of the distance information declined in general in later stages (Figure 3B). To test this, we performed the behavioural prediction procedure on datasets obtained from the first 5 (early) and the last 5 (late) stages of the experiment (Figure 6—figure supplement 1). There was strong evidence for a decline in the prediction power in the late vs. early blocks of trials. However, even with the decline in prediction accuracy, it is still possible to predict the behavioural outcome in the late blocks with well above-chance accuracy (up to 75%).”</p><disp-quote content-type="editor-comment"><p>8. When decoding distance, active decoding declines from early to late, even though performance does not decline (or even slightly improves from early to late). This discrepancy seems hard to explain. Is this decline in classification driven by differences in the total signal from early to late?</p></disp-quote><p>Thanks for the question. We explicitly define the vigilance effects as the difference between Active and Monitoring conditions to ensure that we are not interpreting general task effects like this one as vigilance decrements. This is important because otherwise effects that are not specific to maintaining vigilance (i.e., sustaining attention in the situation where only infrequent responses are necessary) could be misinterpreted. In this case, it could be driven by a number of general factors that are not specific to vigilance such as fatigue, but also equipment effects like the MEG recording system fluctuations in baseline (e.g., due to warming up). Our crucial comparisons for both behaviour and neural correlates are the increase in ‘miss rate’ and ‘reaction time’ for Monitoring vs. Active from early to late blocks and more decline in distance decoding information (from early to late blocks) for Monitoring than for Active (Figure 3B. Interaction between Target Frequency and Time on the task). We have now added the following sentence to Discussion and amended the manuscript to ensure this is clear.</p><p>“Note that our vigilance decrement effects are defined as the difference between Active and Monitoring conditions, which allows us to be sure that we are not interpreting general task (e.g., participant fatigue) or hardware-related effects as vigilance decrements. For example, the drop in decoding over time for both Active and Monitoring that is seen in Figure 3 might reflect some of the general changes in the characteristics of the recording hardware over the course of the experiment (e.g., the MEG system warming up), but our design allows us to dissociate these from the key vigilance effects we are interested in.”</p><disp-quote content-type="editor-comment"><p>9. Classifier performance was extremely high almost immediately after trial onset. Does the classifier perform at chance before the trial onset, or does this reflect sustained but not stimulus-specific information?</p></disp-quote><p>Thanks for pointing out that we were missing this information – yes, the classifier performs at chance in the pre-stimulus onset time. We have now added this to the modified figures in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>10. The connectivity analysis appears to be just a correlation of decoding results between two regions of interest. This means, if one &quot;region&quot; allows for decoding the distance to the object, the other one does too. However, this alone does not equal connectivity. It could simply mean that patterns across the entire brain allow for decoding the same information. For example, it would not be surprising to find that both ROIs correlate more strongly for correct trials (i.e. the brain has obviously represented the relevant information) than for errors (i.e. the brain has failed to represent the information), without this necessarily being related to connectivity at all. The more parsimonious interpretation here is that information might have been represented across all channels at this time. The authors show no evidence that only these two (arbitrarily selected) &quot;regions&quot; encode the information while other do not. To show evidence for meaningful connectivity, (a) the spread of information should be limited to small sub-regions, and (b) the decoding results in one &quot;region&quot; should predict the results in another region in time (as for DCM).</p></disp-quote><p>Thanks for the important point. Actually, our connectivity analysis is not simply a correlation of magnitudes of decoding accuracy between two regions of interest, but rather a correlation of the patterns of decoding accuracies across conditions (i.e., across distances). Our approach follows the concept of informational connectivity (explained in more detail below) which measures how much similarity in information coding there is between two brain areas across conditions, which is interpreted as reflecting their potential connectivity. Therefore, rather than the average magnitude of decoding accuracy (high vs. low), the connectivity is driven by the correlation between the patterns of decoding accuracies either across time (Coutanche and Thompson-Schill, 2013) or across conditions (Kietzmann et al., 2018). We used the latter (i.e., RDMs) here to study connectivity. This is a critical difference because high classification values in two regions will not necessarily correspond to high connectivity in our analysis.</p><p>Accordingly, the difference in classification levels between ‘correct’ and ‘miss’ trials should not determine the connectivity – it’s more the consistency of the pattern (see below example). Our connectivity relies on (Spearman’s) correlation (which normalizes absolute amplitude), and as such it is unaffected by absolute decoding values in the pairs of input vectors: connectivity will be high only if the two areas encode the information across conditions similarly rather than if they code the information very efficiently across all conditions (i.e., maximum decoding values). For example, assume that we have four brain areas A, B, C and D with (simplified and vectorized) distance RDMs (as in our work) with decoding values of [95 91 97 92], [96 98 99 94], [57 51 55 54], [58 52 59 55], respectively. The inter-area correlation/connectivity matrix would be as in <xref ref-type="table" rid="resptable1">Author response table 1</xref>. As you can see, a pair of brain areas with absolutely higher decoding values (A and B), but less similarity of patterns in their RDMs can led to small correlations/connectivity (0.4) while pairs of brain areas which have small decoding values but more similar patterns of decoding in their RDMs (C and D) resulted in much higher correlation/connectivity (0.8). Therefore, rather than the absolute decoding values (i.e., whether the pair of areas encode the information or not), their patterns in the RDMs determine how/if they are coding information similarly and are potentially connected.</p><table-wrap id="resptable1" position="float"><label>Author response table 1.</label><caption><title>Connectivity (correlation) matrix obtained from four sample areas.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>AREA</th><th><italic>A</italic></th><th><italic>B</italic></th><th><italic>C</italic></th><th><italic>D</italic></th></tr></thead><tbody><tr><td><italic>A</italic></td><td>1</td><td><italic>0.4</italic></td><td>0.8</td><td>1</td></tr><tr><td><italic>B</italic></td><td>0.4</td><td>1</td><td>0</td><td>0.4</td></tr><tr><td><italic>C</italic></td><td>0.8</td><td>0</td><td>1</td><td><italic>0.8</italic></td></tr><tr><td><italic>D</italic></td><td>1</td><td>0.4</td><td>0.8</td><td>1</td></tr></tbody></table></table-wrap><p>Although mathematically our connectivity should be unaffected by absolute decoding values, we acknowledge that potentially noisier patterns of distance information in the brain on miss vs. correct trials could result in apparently lower connectivity for misses. We therefore added the following paragraph to the manuscript acknowledging this possibility:</p><p>“While our connectivity is unaffected by the absolute levels of information encoding in the brain on miss vs. correct trials, potentially noisier patterns of information encoding in miss (vs. correct) trials could result in the lower level of connectivity observed on miss (vs. correct) trials. Therefore, the lower level of connectivity for miss vs. correct trials observed here could result from the pair of regions representing two distinct sets of information (i.e,. becoming in some sense less connected) or representing similar information but distorted by higher level of noise.”</p><p>The more parsimonious interpretation here is that information might have been represented across all channels at this time. The authors show no evidence that only these two (arbitrarily selected) &quot;regions&quot; encode the information while other do not. To show evidence for meaningful connectivity, (a) the spread of information should be limited to small sub-regions, and (b) the decoding results in one &quot;region&quot; should predict the results in another region in time (as for DCM).</p><p>a. Yes, it is possible that the whole brain may process the information with the same pattern of decoding but changing the ROIs to smaller ones would not rule out this potential scenario (which applies to all connectivity analyses, even the conventional ones). We avoid making claims about the spatial specificity of our connectivity effect, as we are using MEG (as reflected in the names we chose for the regions: peri-occipital and peri-frontal). Please note though that these sub-regions were not arbitrary, but rather based on areas known to be involved in vision and attention, and based on previous attention work which showed a flow of information across the two areas (Goddard et al., 2016; Goddard et al., 2019).</p><p>It is very important in the interpretation of our result that, rather than making any claims about the absolute existence or magnitude of potential connectivity in the brain, we compared our connectivity indices across conditions. In other words, we do not seek to test whether connectivity exists or not between our ROIs, but rather whether any such connectivity varies with our manipulations of vigilance. Therefore, even in if the entire brain was responding similarly, the modulation of the connectivity metric is only explainable by the manipulations across our conditions.</p><p>b. We could not check the time course of our connectivity as in our previous work (Goddard et al., 2016; Karimi-Rouzbahani et al., 2020), because our distance information involves the whole trial and the direction information does not have enough number of conditions to make RDMs (please see the informational connectivity text below). Therefore, we clarified in the manuscript that:</p><p>“Informational connectivity, on the other hand, is measured either through calculating the correlation between temporally resolved patterns of decoding accuracies across a pair of areas (Coutanche and Thompson-Schill, 2013) or the correlation between representational dissimilarity matrices (RDMs) obtained from a pair of areas (Kietzman et al., 2018; Goddard et al., 2016; Goddard et al., 2019; Karimi-Rouzbahani et al., 2019; Karimi-Rouzbahani et al., 2020). Either one measures how much similarity in information coding there is between two brain areas across conditions, which is interpreted as reflecting their potential informational connectivity, and is less affected by absolute activity values compared to conventional univariate connectivity measures (Anzellotti &amp; Coutanche, 2018).”</p><p>And added the following considerations to the methods:</p><p>“First, it reflects the similarity of the way a pair of brain areas encode “distance” information during the whole trial. This means that we could not use the component of time in the evaluation of our connectivity as we have implemented elsewhere (Karimi-Rouzbahani et al., 2019; Karimi-Rouzbahani et al., 2020). Second, rather than a simple correlation of magnitudes of decoding accuracy between two regions of interest, our connectivity measure reflects a correlation of the patterns of decoding accuracies across conditions (i.e., distances here). Finally, our connectivity analysis evaluates sensory information encoding, rather than other aspects of cognitive or motor information encoding, which might have also been affected by our experimental manipulations.”</p><disp-quote content-type="editor-comment"><p>11. The display of the results is very dense, and it not always clear whether decoding for a specific variable was above chance or not. The authors often focused on relative differences, making it difficult to fully understand the meaning of the full pattern of results. The Bayes-factor plots in the decoding results figures are so cramped that it is very difficult to actually see the individual dots and to unpack all of this (e.g., Figure 3). Could this complexity be somehow reduced, maybe by dividing the panels into separate figures? The two top panels in Figure 3B should also include the chance level as in A. It looks like the accuracy is very low for unattended trials, which is only true in comparison to attended trials, but (as also shown in Supplementary Figure 1) it was clearly also encoded in unattended trials, which is very important for interpreting the results.</p></disp-quote><p>We have extensively revised our figures, and expanded the Bayes plots; we hope they are now clear. We have split the panels in figures into Active and Monitoring panels, added the chance level line, and the pre-stimulus decoding values. We also reduced the density of Bayes Factor dots by down-sampling, and improved their appearance using a log scale and colour coding.</p><p>Regarding the relative differences, our design focuses on these because this allows us to be more specific about the effects that reflect actual vigilance decrements. This differs from many vigilance studies, and provides the opportunity for more specific inference. We have ensured this is clearer in the revision.</p><p>We hope the revised text and figures enhance the interpretability of the relative differences.</p><disp-quote content-type="editor-comment"><p>12. While this is methodologically interesting work, there is no convincing case made for what exactly the contribution of this study is for theories of vigilance. It seems that the findings can be reduced to that a lack of decodability of relevant target features from brain activity predicts that participants will miss the target. This alone, however, does not seem to be very novel. Even if the issues above are addressed, the study only demonstrates that with less attention to the target, there is less evidence of representations of the relevant features of targets in the brain. The authors also find the expected decrements for rare targets and when participants do not actively monitor the targets. How do these findings contribute to &quot;theories of vigilance&quot;, as claimed by the authors?</p></disp-quote><p>This work makes three clear contributions to vigilance research. First, we present a novel multiple-object-monitoring paradigm that clearly evokes specific vigilance decrements in a context that mimics real-world monitoring scenarios. Our design controls for general experiment-level effects that are not specific to vigilance conditions, which as mentioned above, is surprisingly rare in the vigilance literature (which we now make clearer in the revision). This is an important contribution to the field as it provides a tool for further studies and allows us to address our hypotheses in a new and more realistic context.</p><p>Second, we showed that behavioural vigilance decrements are reflected in the neural representation of information. Previous studies have only provided coarse-grained correlates for vigilance decrements such as α-band increase in power spectrum (Kamzanova et al., 2014; Mazaheri et al., 2009; O’Connell et al., 2009). Here, we show that the neural representation of task-related information (i.e., distance) is affected by target frequency. While we agree that this is clearly a plausible prediction, it is a major step forward for a field that has had limited success in exploring specific neural correlates.</p><p>Third, we showed that change in neural representation of information between miss trials and correct trials can be used to predict the behavioural outcome on a given trial. This involves new methods that will be widely applicable, contributes to the global endeavour to link brain and behaviour, and provides a foundation for further research into potential applications for industries where detecting lapses of attention (as measured by a drop in specific task-relevant information) could prevent tragic accidents, such as rail and air traffic control.</p><p>Although we mentioned the major theories of vigilance in the paper, the theories themselves are underspecified, making it difficult to directly test them. We therefore deliberately avoided making strong claims about how our results falsified (or otherwise) the theories: they just do not contain enough specificity to do this. Nonetheless to avoid the implication that we provide a direct test of these theories, we removed the relevant paragraph in the discussion and carefully revised the paper to be explicit that the goal is not to adjudicate between the descriptive cognitive theories but rather to (a) provide a specific tool for studying vigilance in situations that mimic real-world challenges; (b) to understand what changes in the information encoded in the brain when vigilant attention lapses; and (c) to develop a method that can use neural data to predict behavioural outcomes.</p></body></sub-article></article>