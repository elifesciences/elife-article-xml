<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">93633</article-id><article-id pub-id-type="doi">10.7554/eLife.93633</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93633.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Developmental Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Volumetric trans-scale imaging of massive quantity of heterogeneous cell populations in centimeter-wide tissue and embryo</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Ichimura</surname><given-names>Taro</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3740-3634</contrib-id><email>ichimura@otri.osaka-u.ac.jp</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Kakizuka</surname><given-names>Taishi</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Taniguchi</surname><given-names>Yoshitsugu</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author"><name><surname>Ejima</surname><given-names>Satoshi</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf3"/></contrib><contrib contrib-type="author"><name><surname>Sato</surname><given-names>Yuki</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Itano</surname><given-names>Keiko</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Seiriki</surname><given-names>Kaoru</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6548-4016</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund11"/><xref ref-type="other" rid="fund12"/><xref ref-type="other" rid="fund13"/><xref ref-type="other" rid="fund18"/><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Sugawara</surname><given-names>Ko</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf4"/></contrib><contrib contrib-type="author"><name><surname>Itoga</surname><given-names>Hiroya</given-names></name><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Onami</surname><given-names>Shuichi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8255-1724</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund16"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Nagai</surname><given-names>Takeharu</given-names></name><email>ng1@sanken.osaka-u.ac.jp</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund17"/><xref ref-type="other" rid="fund18"/><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/035t8zc32</institution-id><institution>Transdimensional Life Imaging Division, Institute for Open and Transdisciplinary Research, Initiatives, Osaka University, Osaka University</institution></institution-wrap><addr-line><named-content content-type="city">Osaka</named-content></addr-line><country>Japan</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/035t8zc32</institution-id><institution>Department of Biomolecular Science and Engineering, SANKEN, Osaka University</institution></institution-wrap><addr-line><named-content content-type="city">Osaka</named-content></addr-line><country>Japan</country></aff><aff id="aff3"><label>3</label><institution>SIGMAKOKI CO LTD, Midori, Sumida-ku</institution><addr-line><named-content content-type="city">Tokyo</named-content></addr-line><country>Japan</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00p4k0j84</institution-id><institution>Department of Anatomy and Cell Biology, Graduate School of Medical Sciences, Kyushu University</institution></institution-wrap><addr-line><named-content content-type="city">Fukuoka</named-content></addr-line><country>Japan</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/035t8zc32</institution-id><institution>Laboratory of Molecular Neuropharmacology, Graduate School of Pharmaceutical Sciences, Osaka University</institution></institution-wrap><addr-line><named-content content-type="city">Osaka</named-content></addr-line><country>Japan</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/023rffy11</institution-id><institution>Laboratory for Developmental Dynamics, RIKEN Center for Biosystems Dynamics Research</institution></institution-wrap><addr-line><named-content content-type="city">Kobe</named-content></addr-line><country>Japan</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02e16g702</institution-id><institution>Research Institute for Electronic Science, Hokkaido University</institution></institution-wrap><addr-line><named-content content-type="city">Sapporo</named-content></addr-line><country>Japan</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Xu</surname><given-names>Pingyong</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qbk4x57</institution-id><institution>University of Chinese Academy of Sciences</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Stainier</surname><given-names>Didier YR</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0165r2y73</institution-id><institution>Max Planck Institute for Heart and Lung Research</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>03</day><month>02</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP93633</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-11-25"><day>25</day><month>11</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-02-18"><day>18</day><month>02</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.08.21.553997"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-02-28"><day>28</day><month>02</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93633.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-12-27"><day>27</day><month>12</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93633.2"/></event></pub-history><permissions><copyright-statement>© 2024, Ichimura et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Ichimura et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-93633-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-93633-figures-v1.pdf"/><abstract><p>We established a volumetric trans-scale imaging system with an ultra-large field-of-view (FOV) that enables simultaneous observation of millions of cellular dynamics in centimeter-wide three-dimensional (3D) tissues and embryos. Using a custom-made giant lens system with a magnification of ×2 and a numerical aperture (NA) of 0.25, and a CMOS camera with more than 100 megapixels, we built a trans-scale scope AMATERAS-2, and realized fluorescence imaging with a transverse spatial resolution of approximately 1.1 µm across an FOV of approximately 1.5×1.0 cm<sup>2</sup>. The 3D resolving capability was realized through a combination of optical and computational sectioning techniques tailored for our low-power imaging system. We applied the imaging technique to 1.2 cm-wide section of mouse brain, and successfully observed various regions of the brain with sub-cellular resolution in a single FOV. We also performed time-lapse imaging of a 1-cm-wide vascular network during quail embryo development for over 24 hr, visualizing the movement of over 4.0×10<sup>5</sup> vascular endothelial cells and quantitatively analyzing their dynamics. Our results demonstrate the potential of this technique in accelerating production of comprehensive reference maps of all cells in organisms and tissues, which contributes to understanding developmental processes, brain functions, and pathogenesis of disease, as well as high-throughput quality check of tissues used for transplantation medicine.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>quail</kwd><kwd>optical microscopy</kwd><kwd>trans-scale imaging</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Mouse</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>21H00431</award-id><principal-award-recipient><name><surname>Sato</surname><given-names>Yuki</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>18H05416</award-id><principal-award-recipient><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>18H05412</award-id><principal-award-recipient><name><surname>Onami</surname><given-names>Shuichi</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>18H05410</award-id><principal-award-recipient><name><surname>Nagai</surname><given-names>Takeharu</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>18H05408</award-id><principal-award-recipient><name><surname>Nagai</surname><given-names>Takeharu</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>21H05590</award-id><principal-award-recipient><name><surname>Ichimura</surname><given-names>Taro</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>23H041350</award-id><principal-award-recipient><name><surname>Ichimura</surname><given-names>Taro</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>JP23H00395</award-id><principal-award-recipient><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id><institution>Japan Society for the Promotion of Science</institution></institution-wrap></funding-source><award-id>JP24K22022</award-id><principal-award-recipient><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002241</institution-id><institution>Japan Science and Technology Agency</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.52926/JPMJPR18G2</award-id><principal-award-recipient><name><surname>Ichimura</surname><given-names>Taro</given-names></name></principal-award-recipient></award-group><award-group id="fund11"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009619</institution-id><institution>Japan Agency for Medical Research and Development</institution></institution-wrap></funding-source><award-id>JP21dm0207117</award-id><principal-award-recipient><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name></principal-award-recipient></award-group><award-group id="fund12"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009619</institution-id><institution>Japan Agency for Medical Research and Development</institution></institution-wrap></funding-source><award-id>JP23ama121054</award-id><principal-award-recipient><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name></principal-award-recipient></award-group><award-group id="fund13"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009619</institution-id><institution>Japan Agency for Medical Research and Development</institution></institution-wrap></funding-source><award-id>JP23ama121052</award-id><principal-award-recipient><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name></principal-award-recipient></award-group><award-group id="fund14"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002241</institution-id><institution>Japan Science and Technology Agency</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.52926/jpmjcr15n3</award-id><principal-award-recipient><name><surname>Nagai</surname><given-names>Takeharu</given-names></name></principal-award-recipient></award-group><award-group id="fund15"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002241</institution-id><institution>Japan Science and Technology Agency</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.52926/jpmjcr1926</award-id><principal-award-recipient><name><surname>Sugawara</surname><given-names>Ko</given-names></name><name><surname>Onami</surname><given-names>Shuichi</given-names></name></principal-award-recipient></award-group><award-group id="fund16"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002241</institution-id><institution>Japan Science and Technology Agency</institution></institution-wrap></funding-source><award-id award-id-type="doi">10.52926/jpmjnd2201</award-id><principal-award-recipient><name><surname>Onami</surname><given-names>Shuichi</given-names></name></principal-award-recipient></award-group><award-group id="fund17"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100008732</institution-id><institution>Uehara Memorial Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Nagai</surname><given-names>Takeharu</given-names></name></principal-award-recipient></award-group><award-group id="fund18"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007449</institution-id><institution>Takeda Science Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name><name><surname>Nagai</surname><given-names>Takeharu</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Volumetric trans-scale imaging with a subcellular resolution across a wide field-of-view of 1.5 × 1.0 cm<sup>2</sup> has been realized, facilitating the analysis of cellular dynamics during embryogenesis and brain function.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Recently, life sciences have focused on comprehending the working principles of multicellular systems, spanning from basic biology to medical applications (<xref ref-type="bibr" rid="bib42">Sasai, 2013</xref>; <xref ref-type="bibr" rid="bib30">McDole et al., 2018</xref>; <xref ref-type="bibr" rid="bib8">Dominguez et al., 2023</xref>; <xref ref-type="bibr" rid="bib57">Ueda et al., 2020</xref>; <xref ref-type="bibr" rid="bib41">Rao et al., 2021</xref>). Multicellular systems are generally complex, comprising heterogeneous cells rather than homogeneous assemblies. To understand the mechanism by which numerous cells cooperate to express the function of the entire system, it is ideal to observe all individual components within the system simultaneously during the time span of a whole phenomenon. In particular, in scenarios where a small fraction of cells in a large multicellular system may influence the fate of the population, or when distant cells and tissues operate synchronously, deducing the entire system from observations of sub-populations becomes challenging. Therefore, the trans-scale measurement of collective dynamics of all individual cells that constitute the system of interest is desired.</p><p>In response to this demand, researchers have recently reported the development of imaging methods with large field-of-view (FOV; <xref ref-type="bibr" rid="bib29">McConnell et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">Sofroniew et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Fan et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Ota et al., 2021</xref>; <xref ref-type="bibr" rid="bib63">Yu et al., 2021</xref>; <xref ref-type="bibr" rid="bib20">Ichimura et al., 2021</xref>). Whereas most of these methods are focused on observing brain activity in neuroscience using two-photon excited fluorescence (<xref ref-type="bibr" rid="bib48">Sofroniew et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Fan et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Ota et al., 2021</xref>; <xref ref-type="bibr" rid="bib63">Yu et al., 2021</xref>), our efforts have been dedicated to developing techniques as versatile tools for studying multicellular systems science and developmental biology. In our previous work, we proposed a fluorescence imaging system for the visible wavelength region, capable of spatially resolving individual cells within a centimeter FOV, which we named AMATERAS-1 (A Multi-scale/modal Analytical Tool for Every Rare Activity in Singularity), enabling simultaneous observation of dynamics in the range of 10<sup>5</sup>–10<sup>6</sup> cells (<xref ref-type="bibr" rid="bib20">Ichimura et al., 2021</xref>). Additionally, we successfully detected less than 1% of cells with unique roles in multicellular systems and revealed how these rare cells trigger a drastic transition from unicellular to multicellular behavior in <italic>Dictyostelium discoideum</italic> (<xref ref-type="bibr" rid="bib22">Kakizuka et al., 2025</xref>). However, the imaging system had a numerical aperture (NA) of 0.12, which is insufficient for realizing volumetric observation owing to its broad depth of field (DOF). Overcoming this limitation and enabling volumetric imaging for diverse three-dimensional (3D) tissues and small organisms has been a significant challenge.</p><p>In this study, we developed AMATERAS-2, a volumetric optical imaging system with approximately 15×10 mm<sup>2</sup> FOV, equivalent to that of AMATERAS-1 (<xref ref-type="bibr" rid="bib20">Ichimura et al., 2021</xref>). The key component for the enhancement is the giant 2×lens system with an NA of 0.25, which offers improved 3D spatial resolution and higher sensitivity. By incorporating novel methodologies of optical sectioning and computational sectioning, we successfully added volumetric imaging capabilities. The effectiveness of these advancements was demonstrated in imaging 1.5-mm-thick brain section blocks and conducting a 25 hr time-lapse observation of vascular endothelial cells during quail embryogenesis, allowing us to trace the spatiotemporal dynamics of approximately 4.0×10<sup>5</sup> cells in three dimensions.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Optical configuration and performance</title><p>AMATERAS-1 utilized a telecentric macro lens with ×2 magnification, thus allowing dynamic observation in the centimeter-FOV with subcellular resolution (<xref ref-type="bibr" rid="bib20">Ichimura et al., 2021</xref>). Despite its efficacy in biological studies, its low NA (0.12) limits both its spatial resolution in the <italic>z</italic>-direction, and system brightness. To overcome these constraints and expand the possibilities for observing cell dynamics in tissues and embryos, we developed a giant lens system with a higher NA, consisting of a pair of objective and tube lenses. The objective lens is composed of 12 optical elements in 7 groups, while the tube lens is composed of 9 lenses in 6 groups (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Both lenses are infinity-corrected with NAs of 0.25 for the objective and 0.125 for the tube lens, and have a field number of 44 mm (diameter) suitable for large-area image sensors. They are effectively aberration-corrected to the diffraction limit or lower in the visible wavelength range of 436–656 nm. The objective lens and tube lens have sizes of 144 mm × 310 mm and 170 mm × 345 mm, respectively (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The objective and tube lenses exhibit zero vignetting, enabling observation of peripheral areas of the FOV with high brightness.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>AMATERAS-2, a centimeter-FOV cell-imaging system.</title><p>(<bold>A</bold>) Schematics of the design of the objective and tube lenses for AMATERAS-2. (<bold>B</bold>) Appearance of the objective and tube lenses with the width and length. (<bold>C</bold>) Diagram of the wide-field fluorescence imaging system, AMATERAS-2w, using the two lenses in (<bold>A–B</bold>). See Materials and methods for detail.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig1-v1.tif"/></fig><p>As the NA of AMATERAS-2 is 0.25, more than double that of AMATERAS-1 (0.12), our system in principle achieves over twice the spatial resolution in the transverse (<italic>xy</italic>) direction, more than four times the resolution in the longitudinal (<italic>z</italic>) direction, and over four times the brightness of AMATERAS-1.</p><p>Using this new lens system, we constructed a wide-field epi-illumination fluorescence imaging system, termed AMATERAS-2w, with a magnification of ×2, an NA of 0.25, and a field number of 44 mm (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, Materials and methods). We utilized either a 120-megapixel CMOS camera or a 250-megapixel CMOS camera, depending on the research purpose. Both the cameras have an approximately 35 mm diagonal, thus providing an observation FOV of 17.8 mm and 17.4 mm diagonal at ×2 magnification, respectively. The pixel sizes for these cameras are 2.2 and 1.5 µm, with sampling intervals of 1.1 and 0.75 µm at ×2 magnification, respectively.</p><p>We installed a high-brightness LED light sources for fluorescence excitation, directing it into the objective lens through a custom-made long-pass dichroic mirror designed for GFP imaging with a cut-off wavelength of 497 nm. To ensure uniform illumination across the entire FOV, we employed a lens-let array pair. Additionally, we incorporated a 2-inch band-pass fluorescence filter between the tube lens and the camera.</p><p>We experimentally obtained the optical point spread function (PSF) using green fluorescent beads (center wavelength: 515 nm) with a 0.2 µm diameter, employing both the 120-megapixel CMOS camera (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) and the 250-megapixel CMOS camera (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The left panels in <xref ref-type="fig" rid="fig2">Figure 2A and B</xref> display the PSFs in the <italic>xy</italic> and <italic>xz</italic> planes, respectively. The single-point spatial resolution was evaluated by the full-width of half-maximum (FWHM) of the line profiles determined through Gaussian-function fit. The transverse resolutions (<italic>xy</italic>-direction) obtained with the 120- and 250-megapixel cameras were 1.24±0.12 (N=100) and 1.12±0.072 (N=100; <xref ref-type="fig" rid="fig2">Figure 2A–B</xref>, right top), both of which are slightly downgraded from the theoretical FWHM, 1.05 µm, given by 0.51 <italic>λ<sub>em</sub></italic>/<italic>NA</italic> (<italic>λ<sub>em</sub></italic>em 515 nm, NA = 0.25; <xref ref-type="bibr" rid="bib23">Kino and Corle, 1996</xref>; <xref ref-type="bibr" rid="bib61">Wilson, 2011</xref>). This can be attributed to the coarse sampling interval (1.1 µm and 0.75 µm, respectively). In particular, in the 120-megapixel case, the apparent single-point resolution varies depending on the relative position of the bead within the pixel (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A–B</xref>). The coarse sampling also introduces uncertainty in the estimated position of the bead’s center coordinate (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1E</xref>). Although this may pose some challenges in quantitatively evaluating fine shapes in cells, it is not a practical issue in imaging at cell resolution. By contrast, the 250-megapixel camera provides a nearly constant resolution (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1C–D</xref>). Thus, the 250-megapixel camera is suitable when high-resolution images are required, whereas the 120-megapixel camera is suitable for other cases where increasing the number of photons per pixel or suppressing data size is necessary.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Optical performance of AMATERAS-2w.</title><p>(<bold>A</bold>, <bold>B</bold>) Experimentally obtained PSF of green fluorescent beads with a 0.2 µm diameter in the <italic>xy</italic> and <italic>xz</italic> planes, captured using CMOS cameras with (<bold>A</bold>) 120 megapixels (pixel size=2.2 µm) and (<bold>B</bold>) 250 megapixels (pixel size=1.5 µm). The representative line profiles in the <italic>x</italic> and <italic>z</italic> directions on the beads are shown (black lines with circular markers) along with Gaussian fit curves (red lines) and FWHMs, and the mean and standard deviation (SD) calculated for 100 beads are described beside each profile. (<bold>C</bold>) Fluorescence image of a cardiomyocyte sheet in the entire FOV. (<bold>D</bold>) Digitally magnified view of the area indicated by a magenta square at the center of (<bold>C</bold>); scale bar, 100 µm. (<bold>E</bold>) Same area as (<bold>D</bold>) but observed by AMATERAS-1 for comparison. (<bold>F</bold>) Line profiles of the lines in (<bold>D</bold>) and (<bold>E</bold>) for comparison of spatial resolution.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Uncertainty in spatial resolution and position owing to undersampling.</title><p>(<bold>A</bold>, <bold>B</bold>) Two cases of images of fluorescent beads (diameter, 0.2 µm) captured using the 120-megapixel camera. (<bold>C</bold>, <bold>D</bold>) Two cases of images of fluorescent beads (diameter, 0.2 µm) captured using the 250-megapixel camera. (<bold>E</bold>) Dependence of FWHM and center position on pixel size, as revealed by a numerical simulation. The number of photon (N) is varied from N~infinity, 1000, 100, and 30.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig2-figsupp1-v1.tif"/></fig></fig-group><p>In the depth direction (<italic>z</italic>-direction), we evaluated the DOF by fitting Gaussian curves to the line profiles (<xref ref-type="fig" rid="fig2">Figure 2A–B</xref>, right bottom). The DOF was measured to be 15.6±1.3 (N=100) and 14.8±1.1 (N=100) for the 120- and 250-megapixel cameras, respectively. This difference in DOF is attributed to the distinct pixel sizes of the cameras (<xref ref-type="bibr" rid="bib11">Gross et al., 2008</xref>). The DOF value for the 250-megapixel camera was found close to the theoretical FWHM, 14.3 µm, given by 1.78 <italic>λ<sub>em</sub></italic>/<italic>NA</italic><sup>2</sup> (<italic>λ<sub>em</sub></italic>em 515 nm, NA=0.25; <xref ref-type="bibr" rid="bib61">Wilson, 2011</xref>).</p><p>The spatial resolution in the transverse direction has been significantly improved, approximately two times compared with that of AMATERAS-1. <xref ref-type="fig" rid="fig2">Figure 2C and D</xref> display fluorescence images of cardiomyocytes derived from human induced pluripotent stem cells (hiPSCs) stained with Rhodamine phalloidin (C) across the entire FOV and (D) within a central local region indicated by a magenta square in (C). These images were captured using the 250-megapixel camera, and the FOV size was 14.7×9.4 mm<sup>2</sup>. For comparison, <xref ref-type="fig" rid="fig2">Figure 2E</xref> shows an image of the same area observed with AMATERAS-1 (<xref ref-type="bibr" rid="bib20">Ichimura et al., 2021</xref>). Evidently, AMATERAS-2w delivers more detailed images with finer spatial structures. This is further confirmed by the line profiles depicted in <xref ref-type="fig" rid="fig2">Figure 2F</xref>, where the filamentous actin stained with Rhodamine exhibits a sharper spatial resolution with AMATERAS-2w. This result indicated the capability of observing subcellular structures, such as myofibrils, in cell sheets with a large area, such as artificial myocardial sheets, which would enable us to simultaneously investigate microscale structures and macroscale multicellular dynamics.</p></sec><sec id="s2-2"><title>Spinning pinhole-array disk provides optical sectioning capability in wide-FOV</title><p>This imaging system utilizes wide-field illumination and detection, which currently lacks the capability to selectively acquire images of specific <italic>z</italic>-planes for volumetric imaging. To extend the system’s applicability, we developed two methods to enable the volumetric imaging, namely, optical sectioning and computational sectioning.</p><p>For optical sectioning, various options of optical techniques exist for achieving 3D fluorescence imaging with a large FOV in the visible wavelength region. These include scanning confocal microscopy (<xref ref-type="bibr" rid="bib29">McConnell et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Kino and Corle, 1996</xref>), light-sheet microscopy (<xref ref-type="bibr" rid="bib57">Ueda et al., 2020</xref>; <xref ref-type="bibr" rid="bib2">Battistella et al., 2022</xref>), light-field microscopy (<xref ref-type="bibr" rid="bib40">Prevedel et al., 2014</xref>), two-photon excitation microscopy (<xref ref-type="bibr" rid="bib48">Sofroniew et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Fan et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Ota et al., 2021</xref>; <xref ref-type="bibr" rid="bib63">Yu et al., 2021</xref>; <xref ref-type="bibr" rid="bib7">Demas et al., 2021</xref>), and spatiotemporal focusing (<xref ref-type="bibr" rid="bib36">Papagiakoumou et al., 2020</xref>). Among these options, we selected the confocal imaging method for this study. This is because the light-sheet microscopy struggles with uniform illumination over the centimeter scale FOV of AMATERAS (<xref ref-type="bibr" rid="bib2">Battistella et al., 2022</xref>; <xref ref-type="bibr" rid="bib58">Voigt et al., 2019</xref>), and the light-field microscopy involves a trade-off between spatial resolution and the ability to resolve three dimensions, which is incompatible with the AMATERAS’s concept (<xref ref-type="bibr" rid="bib34">Nöbauer et al., 2023</xref>). In addition, two-photon excitation microscopy, including that using spatiotemporal focusing, is crucial for deep tissue imaging, but still requires further innovations in pulsed laser power and scanning methods to be effectively applied to the wide FOV of AMATERAS.</p><p>We considered the confocal method to be the most compatible with our imaging system. Considering the vast FOV, we adopted the multipoint-scanning confocal system. The commonly used method involving a combination of a microlens array and a pinhole array disk (<xref ref-type="bibr" rid="bib19">Ichihara et al., 1996</xref>; <xref ref-type="bibr" rid="bib21">Ishihara, 2003</xref>) could not be employed in AMATERAS owing to the large NA of the tube lens (NA=0.125) compared with that of standard microscopes. Matching the NA requires shortening the distance between the two disks or enlarging the microlenses. However, shortening the inter-disk distance leads to a loss of space for inserting a dichroic mirror, and enlarging the microlenses reduces the number of foci. The confocal fluorescence microscopy requires a beam splitter due to the essential separation of fluorescence and excitation light. Therefore, designing microlens-pinhole arrays suitable for AMATERAS-2 presents a significant challenge. This challenge can be circumvented by using an optical configuration where excitation light and fluorescence pass through synchronized pinhole arrays on separate paths, as initially proposed in the early development of multipoint confocal microscopy (<xref ref-type="bibr" rid="bib37">Petráň et al., 1985</xref>). However, this solution would require duplicating the optics of the giant lens, which is currently unfeasible. Moreover, even if possible, the added complexity of the system would render this approach impractical.</p><p>To address this challenge, we opted to use pinhole arrays without microlenses, which is rather a more traditional configuration of multipoint confocal microscopy (<xref ref-type="bibr" rid="bib23">Kino and Corle, 1996</xref>; <xref ref-type="bibr" rid="bib62">Xiao et al., 1988</xref>; <xref ref-type="bibr" rid="bib13">Halpern et al., 2022</xref>). Although this method is less light-efficient compared with the one using microlenses, it aligns well with our imaging system’s high NA and low magnification. Here, we designed the pinhole array disk for fluorescence imaging in green (e.g. GFP, YFP) and red (e.g. RFP, mCherry) wavelengths. Commercial confocal systems using pinhole-array disks typically feature large pinhole sizes (e.g<italic>.</italic> 50 µm) and wide spacing between pinholes (e.g<italic>.</italic> 200 µm), designed for general microscopes. For AMATERAS-2, however, with its ×2 magnification and NA of 0.25, the pinhole size must be much smaller. The diameters of the Airy disk for green and red wavelengths are about 5 µm and 6 µm, respectively, at the focal plane of the tube lens (NA=0.125). As a prototype, we set the pinhole size to 6 µm (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), matching the Airy disk diameter for red wavelength. A more detailed discussion on the impact of pinhole diameter dependence on 3D resolution is available in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> (see also Appendix File - Note 1). The pinhole spacing was set as 24 µm, striking a balance between throughput and crosstalk (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). To implement this, we custom-made a pinhole-array disk and incorporated it into a rotary machine (CrestOptics, Rome, Italy).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>AMATERAS-2c, a multipoint confocal imaging system for 3D volume imaging.</title><p>(<bold>A</bold>) Design of our pinhole-array disk. (<bold>B</bold>) Schematic of the optical configuration using the pinhole-array disk. (<bold>C</bold>) Effect of background light rejection by the presence of the pinhole-array disk in a 292×202 µm<sup>2</sup> area at the FOV center corresponding to 1/50<sup>2</sup> of the entire FOV. (<bold>D</bold>, <bold>E</bold>) Experimentally obtained PSF of green fluorescent beads with a diameter of 0.5 µm in the <italic>xy</italic> and <italic>xz</italic> planes, captured using relay lens with (<bold>D</bold>) ×1 magnification (NA=0.079) and (<bold>E</bold>) ×2 magnification (NA=0.12). The representative line profiles in the <italic>x</italic> and <italic>z</italic> directions on the beads are also shown (black lines with circular markers) along with Gaussian fit curves (red lines) and FWHMs, and the mean and standard deviation (SD) calculated for 100 beads are described beside each profile.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Schematic configuration of the confocal system and the effect of the pinhole size.</title><p>(<bold>A</bold>) Effective configuration for excitation in the confocal imaging system, AMATERAS-2c. OL and TL denote objective lens and tube lens, respectively. (<bold>B</bold>) Diffraction pattern by a pinhole with various conditions (wavelength and pinhole diameter), calculated by <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. The intensity of diffracted light is plotted as a function of diffraction angle. The diffraction angle equivalent to the NA of the tube lens is represented by the dotted line. (<bold>C</bold>) Effective configuration for emission in AMATERAS-2c. (<bold>D</bold>) Intensity distribution of focused light spot by tube lens with 0.125 NA at the two fluorescence wavelengths (527 and 610 nm). The size of the 6 µm pinhole is indicated by the dashed lines.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Evaluation of the optical sectioning effect by the confocal system.</title><p>(<bold>A–B</bold>) Point-spread functions measured in the absence (<bold>A</bold>) and presence (<bold>B</bold>) of the pinhole-array disk (diameter: 6 µm). The optical configuration for this experiment employed the ×1 relay lens, the same as used in <xref ref-type="fig" rid="fig3">Figure 3D</xref> in the main text (total magnification: ×2). Left panels show <italic>xz</italic> planes centering at a single fluorescent bead. Right panels show the line profiles in the <italic>z</italic> direction across the bead positions in the left panels. The FWHMs are noted alongside the line profiles. The statistical values of 81 peaks are also shown as well.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig3-figsupp2-v1.tif"/></fig></fig-group><p>We positioned the pinhole array disk at the image plane of the tube lens and constructed a relay lens system to transfer the plane to the camera. This particular configuration, termed AMATERAS-2c, is illustrated in <xref ref-type="fig" rid="fig3">Figure 3B</xref> (Materials and methods). To split the light paths of fluorescence excitation light, we placed a short-pass dichroic mirror beneath the disk. For fluorescence excitation, we used a high-brightness LED with a center wavelength of 470 nm, the same as in the wide-field imaging system (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The relay lens consisted of a telecentric macro lens with ×1 magnification, and a 2-inch band-pass fluorescent filter was positioned at the entrance of the macro lens. If necessary, the relay lens can be replaced by a ×2 magnification lens to switch the total magnification from ×2 to ×4, based on resolution requirements.</p><p>Fluorescence images of 0.5 µm fluorescent beads were observed with and without the pinhole-array disk, where fluorescent beads were three-dimensionally dispersed in an agarose gel slab (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). The presence of the pinhole-array disk dramatically suppressed background light from outside the focal plane. This verified that optical sectioning can be achieved by the pinhole-array disk. The variations in the 3D PSF with and without the pinhole-array disk are detailed in the <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>. Typical 3D PSF was obtained with the fluorescence beads with the relay lens of (D) ×1 and (E) ×2 magnifications (<xref ref-type="fig" rid="fig3">Figure 3D and E</xref>). As NA of the ×1 relay lens (NA=0.079) is lower than that of the tube lens (NA=0.125), the transverse spatial resolution (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, right top) is degraded compared to the one obtained by the wide-field configuration without the relay lens (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>, Appendix File - Note 1). By contrast, the ×2 relay lens (NA=0.12) almost matches with the tube lens, and the reduction in the transverse spatial resolution is relatively small (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). As for the longitudinal resolution, the FWHM of the PSF was approximately 16 µm with a ×1 relay lens and approximately 14 µm with a ×2 relay lens, both values significantly exceeding the ideal value about 9.5 µm (Appendix File - Note 1). These discrepancies are attributed to the relatively loose focusing of the excitation light and the non-negligible size of the pinhole.</p></sec><sec id="s2-3"><title>Computational sectioning provides pseudo-depth-resolved imaging capability</title><p>In addition to optical sectioning, we developed a computational sectioning method to separate images of the focal plane and out-of-focal planes. During measurement, a <italic>z</italic>-stack is acquired in the wide-field imaging configuration (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) by scanning the focal position in the <italic>z</italic>-direction and capturing images at each step. The raw image in a 3D volume results from the superposition of in-focus and out-of-focus plane images. We estimated the contribution from out-of-focus planes as the baseline by iteratively applying low-pass filtering under the assumption that the image’s spatial frequency in the focal plane is higher than that in out-of-focus planes. The cut-off frequency of the low-pass filter was optimized using the principles of independent component analysis (Materials and methods, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref>–<xref ref-type="fig" rid="fig4s2">2</xref>, Appendix File – Note 2).</p><p>To demonstrate computational sectioning, we observed myocardial organoids derived from hiPSCs (<xref ref-type="bibr" rid="bib27">Ma et al., 2015</xref>). This 3D dome structure of a cavity chamber is extensively studied in developmental biology and regenerative medicine as a model for human myocardial tissue development (<xref ref-type="bibr" rid="bib17">Hofbauer et al., 2021</xref>; <xref ref-type="bibr" rid="bib25">Lewis-Israeli et al., 2021</xref>). We fabricated a large area of organoids across the entire FOV, chemically fixed and immunostained them for cardiac troponin T (cTnT) with Alexa488, and stained the nuclei with Hoechst33342 (Materials and methods). The <italic>z</italic>-stack was obtained within a <italic>z</italic>-range involving the organoids (approximately 250 µm) with 4 µm intervals. <xref ref-type="fig" rid="fig4">Figure 4A and B</xref> display two-color overlaid images of the island-formed organoids across the entire FOV, without and with computational sectioning, respectively (both are maximum-intensity projection (MIP) images of the <italic>z</italic>-stacks). <xref ref-type="fig" rid="fig4">Figure 4C and D</xref> present images of six layers in the <italic>z</italic>-direction of the yellow square region of <xref ref-type="fig" rid="fig4">Figure 4A and B</xref>, before and after computational sectioning, respectively. After the sectioning, the distribution of cTnT and nuclei in each <italic>z</italic>-layer is clearly visualized (<xref ref-type="fig" rid="fig4">Figure 4D</xref>): The island areas are composed of multilayered cells, and the inter-island spaces are covered with a single layer of cells, as shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref>, <italic>z</italic>=20 µm. A 3D isosurface representation (<xref ref-type="fig" rid="fig4">Figure 4E</xref>) shows that the hollow oval structure is formed by a thin layer of cTnT-positive cells (cardiomyocytes) whereas the underlying cell layer is composed of cTnT-negative cells, consistent with previous literature (<xref ref-type="bibr" rid="bib27">Ma et al., 2015</xref>). This demonstration validates the technique for wide-field imaging. Video files of <xref ref-type="fig" rid="fig4">Figure 4C–E</xref> are available in <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref> and <xref ref-type="video" rid="fig4video2">Figure 4—video 2</xref>.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Volumetric imaging with computational sectioning.</title><p>(<bold>A</bold>, <bold>B</bold>) Two-color images of the cavity chamber structure of a myocardial organoid (<bold>A</bold>) before and (<bold>B</bold>) after computational sectioning. Both (<bold>A</bold>) and (<bold>B</bold>) are MIP images of the <italic>z</italic>-stack data, captured using the 250-megapixel CMOS camera; here, magenta and cyan represent the distribution of immunostained cardiac troponin T and Hoechst-labeled nuclei, respectively. (<bold>C</bold>, <bold>D</bold>) Six z-layers with a difference of 40 µm in the yellow square region indicated in (<bold>A</bold>, <bold>B</bold>); scale bars, 200 µm. (<bold>E</bold>) Three-dimensional isosurface representation in the dashed square region indicated in (<bold>D</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Performance of computational sectioning with varied cutoff frequency.</title><p>(<bold>A</bold>) A raw image data, a local area of a <italic>z</italic>-layer (<italic>z</italic> = 140 µm) in a <italic>z</italic>-stack data of a dome structure of a myocardial organoid, which is shown in <xref ref-type="fig" rid="fig4">Figure 4</xref> in the main text. (<bold>B–C</bold>) Estimated in-focus images (<bold>B</bold>) and out-of-focus images (<bold>C</bold>) for three different cutoff frequencies, <italic>F<sub>c</sub></italic>=0.020, 0.063, and 0.141. Scale bar (white line): 200 µm. (<bold>D</bold>) Line profiles of intensity on the light-blue lines drawn in <bold>A, B</bold>, and <bold>C</bold>. (<bold>E</bold>) Four types of statistical measures for non-Gaussianity calculated as a function of cutoff frequency of the low-pass filter. The values were calculated for the in-focus image in the yellow square region. The three frequencies used for the image examples (<bold>B–D</bold>) are indicated by gray bars. See Appendix File – Note 2 for more detail.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Dependence of baseline estimation performance on object size.</title><p>(<bold>A–B</bold>) Top: Computer-generated fluorescence image of superposition of a 10 µm sphere and a 30 µm sphere (object) and a 50 µm sphere placed 100 µm deep (background). Bottom: Estimated in-focus image at the cutoff frequency of 0.045 and 0.022 (only in B). Line profiles of the raw, estimated in-focus and out-of-focus images are shown on the images. (<bold>C</bold>) Frequency dependence of the non-Gaussianity (skewness) of in-focus image for the 10 µm and 30 µm spheres. (<bold>D</bold>) Top: Computer-generated fluorescence image of superposition of a 30 µm sphere and a 10 µm sphere (object) and a 50 µm sphere placed 100 µm deep (background). Bottom: Estimated in-focus image at four cutoff frequencies (0.016, 0.032, 0.045, and 0.063) shown with line profiles of raw, in-focus and out-of-focus images. See Appendix File – Note 2 for more detail.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig4-figsupp2-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" id="fig4video1" xlink:href="elife-93633-fig4-video1.mp4"><label>Figure 4—video 1.</label><caption><title>A <italic>z</italic>-stack of a cavity chamber structure of myocardial organoid (left) without and (right) with the computational sectioning, corresponding to <xref ref-type="fig" rid="fig4">Figure 4C and D</xref>, respectively.</title><p>The <italic>z</italic>-position is swept with a step of 4 µm in 56 layers. Magenta and cyan colors represent the distribution of immunostained cardiac troponin T and Hoechst-labeled nuclei, respectively.</p></caption></media><media mimetype="video" mime-subtype="mp4" id="fig4video2" xlink:href="elife-93633-fig4-video2.mp4"><label>Figure 4—video 2.</label><caption><title>A 3D isosurface representation of a dome structure of cavity chamber with varying the view angle.</title><p>The cropped region is indicated by a dashed square in <xref ref-type="fig" rid="fig4">Figure 4D</xref>.</p></caption></media></fig-group><p>In principle, the signal component can be extracted as long as the signal intensity (in-focus component) is significantly higher than the statistical noise of the background intensity (out-of-focus component). This method is effective in cellular imaging when fluorescent molecules are localized within the cell, like in the nucleus, or when they exhibit a filament-like structure, thereby enabling cell recognition and dynamic tracking. It relies on the spatial frequency of the fluorescence image in the focal plane being uniform and clearly higher than that outside the focal plane.</p></sec><sec id="s2-4"><title>Observing a 1.2-cm wide and 1.5-mm-thick volume of mouse brain section</title><p>To demonstrate the potential for brain imaging, we performed imaging of a 1.5-mm-thick mouse brain section in the coronal plane (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). The brain was chemically cleared using CUBIC (<xref ref-type="bibr" rid="bib51">Susaki et al., 2014</xref>; <xref ref-type="bibr" rid="bib53">Tainaka et al., 2018</xref>), and the cell nuclei were stained with SYTOX-Green (Materials and methods). The ×1 relay lens was primarily employed (total magnification=×2) to cover the coronal plane in the FOV. Each layer’s exposure time was 1 s, and a total of 378 layers were acquired to cover the entire 1.5-mm-thick volume in steps of 4 µm in the <italic>z</italic>-direction. Optical and computational sectioning were both applied. <xref ref-type="fig" rid="fig5">Figure 5B</xref> shows a fluorescence image at a single <italic>z</italic>-layer (<italic>z</italic>=700 µm), revealing the 12 mm × 8 mm wide section with single-cell resolution. <xref ref-type="fig" rid="fig5">Figure 5C</xref> displays enlarged views of the <italic>xy</italic>-plane (coronal plane) in the dotted square region in <xref ref-type="fig" rid="fig5">Figure 5B</xref>, along with <italic>xz</italic> (transverse plane) and <italic>yz</italic> (sagittal plane) cross sections, essentially demonstrating successful <italic>z</italic>-direction sectioning. <xref ref-type="fig" rid="fig5">Figure 5D</xref> shows a 3D representation of the same volume of raw data obtained by optical sectioning alone, prior to computational sectioning. However, owing to intense background light overlapping, individual cells are challenging to distinguish, particularly in regions of high cell density. By utilizing computational sectioning to eliminate background light, clear images were obtained even in areas with strong background light. Image variation in the <italic>z</italic>-scan for the entire FOV and local regions can be seen in <xref ref-type="video" rid="fig5video1">Figure 5—video 1</xref> and <xref ref-type="video" rid="fig5video2">Figure 5—video 2</xref>.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Volumetric imaging of a mouse brain section obtained by AMATERAS-2c.</title><p>(<bold>A</bold>) Schematic of a mouse brain showing the placement of the brain sample in the inverted configuration. (<bold>B</bold>) Schematic of a single <italic>z</italic>-layer in the coronal plane with size of the effective area covering the entire brain section. (<bold>C</bold>) Fluorescence images of three orthogonal cross sections of the dotted square indicated in (<bold>B</bold>); here, the yellow, cyan, and magenta lines represent the <italic>z</italic>-, <italic>x</italic>-, and <italic>y</italic>-positions of the cross sections, respectively. (<bold>D</bold>) Cross-sectional images of raw data in the same region as (<bold>C</bold>), where the computational sectioning is not applied. (<bold>E</bold>, <bold>F</bold>) Magnified images of the hippocampal region (dashed square in (<bold>B</bold>)) in the (<bold>E</bold>) <italic>xy</italic>-plane and (<bold>F</bold>) <italic>xz</italic>-plane. For comparison, images obtained with ×2 (left) and ×4 (right) magnification systems are shown together. Note that the 3D regions observed at different magnifications do not perfectly match owing to the difficulty in optical alignment. (<bold>G–I</bold>) Cell detection by ELEPHANT in three brain regions, the cerebral cortex (<bold>G</bold>), medial habenula (<bold>H</bold>), and choroid plexus (<bold>I</bold>), where pairs of intersecting <italic>xy</italic>- and <italic>xz</italic>-planes are arranged vertically. The detected cells within each plane are marked with green and cyan ovals, and the straight line shared by the two planes is represented by a yellow dashed line, with certain cells along this line highlighted by magenta ovals. The <italic>xy</italic>-planes overlay the oval markers within a range of ±25 µm above and below the displayed planes, while the <italic>xz</italic>-planes show only oval markers on the planes.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig5-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" id="fig5video1" xlink:href="elife-93633-fig5-video1.mp4"><label>Figure 5—video 1.</label><caption><title>A <italic>z</italic>-stack of the mouse brain section shown in the full coronal plain region (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</title><p>The z-position is swept with a step of 4 µm in 378 layers.</p></caption></media><media mimetype="video" mime-subtype="mp4" id="fig5video2" xlink:href="elife-93633-fig5-video2.mp4"><label>Figure 5—video 2.</label><caption><title>A <italic>z</italic>-stack of the mouse brain section shown in the local volume corresponding to <xref ref-type="fig" rid="fig5">Figure 5C</xref>.</title><p>The <italic>z</italic>-position is swept with a step of 4 µm in 378 layers.</p></caption></media></fig-group><p><xref ref-type="fig" rid="fig5">Figure 5C</xref> visualizes the characteristic 3D structures of several regions, including hippocampal dentate gyrus, medial habenula, and choroid plexus, which are known to be associated with memory formation (<xref ref-type="bibr" rid="bib12">Hainmueller and Bartos, 2020</xref>), depression (<xref ref-type="bibr" rid="bib1">Agetsuma et al., 2010</xref>), and regulation of cerebrospinal fluid (<xref ref-type="bibr" rid="bib6">Dani et al., 2021</xref>), respectively. Close-up views of the hippocampal region (indicated with the dashed square in <xref ref-type="fig" rid="fig5">Figure 5B</xref>) in the <italic>xy</italic> and <italic>xz</italic> planes are shown in <xref ref-type="fig" rid="fig5">Figure 5E and F</xref>, respectively. A comparison of the images at ×2 and ×4 magnification in <xref ref-type="fig" rid="fig5">Figure 5E and F</xref> reveals that the higher magnification (×4) allows for improved spatial resolution and separation of individual cells in both the <italic>xy</italic> and <italic>xz</italic> planes.</p><p>For cell detection in the 3D imaging data of the mouse brain section, we used a recently developed interactive platform for cell detection and tracking, called ELEPHANT (Efficient LEarning using sParse Human Annotations for Nuclear Tracking; <xref ref-type="bibr" rid="bib49">Sugawara et al., 2022</xref>). This platform seamlessly integrates manual annotation with deep learning and allows for result proofreading (Materials and methods). Using this advanced image analysis technique, cell nuclei were detected within the 3D volume. <xref ref-type="fig" rid="fig5">Figure 5G</xref> illustrates the cell detection results on specific <italic>xy</italic> and <italic>xz</italic> planes within the cortex. As the cell density in the cortex is relatively low, the ellipsoid-shaped nuclei image does not overlap with neighboring cells, resulting in the successful detection of nearly all cells (as clearly shown in the <italic>z</italic>-scan video, <xref ref-type="video" rid="video1">Video 1</xref>). The precision and recall of the cell detection were estimated to be 99.4% and 97.6 %, respectively (Materials and methods). Based on these results, the cell density in the cortex was calculated to be 1.18×10<sup>5</sup> cells/mm<sup>3</sup>, which closely matches previous reports (<xref ref-type="bibr" rid="bib15">Herculano-Houzel and Lent, 2005</xref>). This technique was also applied to two other brain regions, the medial habenula and choroid plexus (<xref ref-type="fig" rid="fig5">Figure 5H–I</xref>). In these regions, cell density is higher than in the cortex and the signal-to-noise ratio is lower due to strong background intensity, making it difficult for traditional methods to detect cells accurately. However, with the assistance of ELEPHANT, we successfully detected the majority of cells.</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-93633-video1.mp4" id="video1"><label>Video 1.</label><caption><title>A <italic>z</italic>-stack of the mouse brain section shown in the local volume in the cortex region.</title><p>Cells detected by ELEPHANT are indicated by green oval markers. The <italic>z</italic>-position is swept with a step of 4 µm in 50 layers (200 µm) from the surface of the brain section.</p></caption></media></sec><sec id="s2-5"><title>Dynamics of over a 4.0 x 10<sup>5</sup> cells were captured over 24-hr development of a quail embryo</title><p>We employed the imaging methods described for a time-lapse observation of cell migration during quail development. The non-confocal optical configuration (AMATERAS-2w, <xref ref-type="fig" rid="fig1">Figure 1C</xref>) and utilizing computational sectioning alone were sufficient for this 250-µm-thick sample. We used a tie1:H2B-eYFP transgenic quail embryo (<xref ref-type="bibr" rid="bib43">Sato et al., 2010</xref>) in which enhanced yellow fluorescent protein (eYFP) visualizes the nuclei of vascular endothelial cells (Materials and methods). The embryo was cultured <italic>ex ovo</italic> on a 35 mm glass-bottom dish (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Time-lapse fluorescence imaging began at 36 hr (HH10) after the start of egg incubation and captured eYFP signals in the developing embryo for 25 hr. For 3D imaging, we acquired <italic>z</italic>-stacks every 7.5 min, with each <italic>z</italic>-stack containing 21 layers spaced 12 µm apart. The intensity density of the excitation light was 113 mW/cm² at the sample plane, and the exposure time per layer was 1 s, under which conditions the quail embryo developed normally without significant phototoxicity or photobleaching. This time-lapse 3D imaging yielded a total of 4200 image layers (21 layers ×200 time points) with a data size of approximately 500 GB. During the time-lapse observation, we stabilized the relative distance between the lens and the sample using a self-developed autofocus system (Materials and methods).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Dynamics of vascular endothelial cells in quail embryo captured by time-lapse observation.</title><p>(<bold>A</bold>) Schematic showing how the specimen is mounted (left) and a photograph of a specimen placed in a glass-bottom dish. (<bold>B</bold>) Representative images obtained at <italic>t</italic>=0 hr, 8 hr, and 16 hr; scale bars, 2 mm. (<bold>C</bold>) Enlarged view of the image corresponding at <italic>t</italic>=24 hr; the pseudo-colors represent the <italic>z</italic>-position of the cells and fluorescence intensity by their hue and brightness, respectively. (<bold>D</bold>) Magnified views of the anterior side of ventral aortae (left dashed square in (<bold>C</bold>)) at the four time-points with intervals of 8 hr; scale bars, 200 µm. (<bold>E</bold>) Three-dimensional isosurface representation of the dorsal aorta region (right dashed square in (<bold>C</bold>)) viewed from the left side. (<bold>F</bold>), (<bold>G</bold>) Cell position trajectories and spatial mapping of features related to the cell dynamics in the two time-regions of (<bold>F</bold>) <italic>t</italic>=8–10 hr and (<bold>G</bold>) <italic>t</italic>=16–18 hr. Left panels show enlarged views in the white square regions (292×202 µm<sup>2</sup>) indicated in the right panels. In both the panels, the rainbow-colored trajectories of the cell movement are overlaid on the grayscale MIP images at the first frame in the time regions (F: <italic>t</italic>=8 hr, G: <italic>t</italic>=16 hr). The scale bars are 50 µm. The rainbow color table represents the meandering index of the cell movement in the two time-regions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Computational processing and 3D visualization of the <italic>z</italic>-stack data of quail embryo.</title><p>(<bold>A</bold>) Raw image data. (<bold>B</bold>) In-focus component obtained by computational sectioning to eliminate the baseline component (out-of-focus component). (<bold>C</bold>) Images of projected max intensity and the z-layer number where maximum intensity is found, which are calculated from a set of <italic>z</italic>-stack. (<bold>D</bold>) Visualization of the 3D data using the HSB color table.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93633-fig6-figsupp1-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" id="fig6video1" xlink:href="elife-93633-fig6-video1.mp4"><label>Figure 6—video 1.</label><caption><title>Time lapse video of the quail development in: (6) the entire body region, (7) ventral aorta region, and (8) dorsal aorta region.</title><p>The time interval is 7.5 min in 25 hr (200 time points). The rainbow color of cells denotes the <italic>z</italic>-position based on the color scale shown in <xref ref-type="fig" rid="fig6">Figure 6C</xref>.</p></caption></media><media mimetype="video" mime-subtype="mp4" id="fig6video2" xlink:href="elife-93633-fig6-video2.mp4"><label>Figure 6—video 2.</label><caption><title>Time lapse video of the quail development in: (6) the entire body region, (7) ventral aorta region, and (8) dorsal aorta region.</title><p>The time interval is 7.5 min in 25 hr (200 time points). The rainbow color of cells denotes the <italic>z</italic>-position based on the color scale shown in <xref ref-type="fig" rid="fig6">Figure 6C</xref>.</p></caption></media><media mimetype="video" mime-subtype="mp4" id="fig6video3" xlink:href="elife-93633-fig6-video3.mp4"><label>Figure 6—video 3.</label><caption><title>Time lapse video of the quail development in: (6) the entire body region, (7) ventral aorta region, and (8) dorsal aorta region.</title><p>The time interval is 7.5 min in 25 hr (200 time points). The rainbow color of cells denotes the <italic>z</italic>-position based on the color scale shown in <xref ref-type="fig" rid="fig6">Figure 6C</xref>.</p></caption></media><media mimetype="video" mime-subtype="mp4" id="fig6video4" xlink:href="elife-93633-fig6-video4.mp4"><label>Figure 6—video 4.</label><caption><title>Time lapse video of the dorsal aorta region (<xref ref-type="fig" rid="fig6">Figure 6E</xref>) in the 3D isosurface representation.</title></caption></media></fig-group><p>Representative images of cell distribution based on the nuclear eYFP signals at four time-points (<italic>t</italic>=0, 8, 16, and 24 hr) are shown in <xref ref-type="fig" rid="fig6">Figure 6B and C</xref>. These images were reconstructed using the HSB color model to represent the 3D distribution after the baseline was removed by computational sectioning (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). The brightness indicates the intensity of the MIP image in the <italic>z</italic>-direction, whereas the hue represents the <italic>z</italic>-position with the maximum value in the MIP process (Materials and methods). As observed in <xref ref-type="fig" rid="fig6">Figure 6B and C</xref>, the cell nuclei distribution undergoes significant changes over time, thus resulting in the formation of organs such as the ventral aortae, heart, and dorsal aortae (<italic>t</italic>=24 hr, <xref ref-type="fig" rid="fig6">Figure 6C</xref>). The heart region appears blurred owing to its oscillating shape caused by beating. Time evolution of the HSB-color images in the entire FOV and magnified local regions can be seen in <xref ref-type="video" rid="fig6video1">Figure 6—videos 1</xref>–<xref ref-type="video" rid="fig6video3">3</xref>. <xref ref-type="fig" rid="fig6">Figure 6D</xref> shows enlarged views of the ventral aortae (indicated by the left dashed square in <xref ref-type="fig" rid="fig6">Figure 6C</xref>) at the four time-points. Additionally, a 3D isosurface of the <italic>z</italic>-stack of the dorsal aorta region (the right dashed square in <xref ref-type="fig" rid="fig6">Figure 6C</xref>) was calculated (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, and <xref ref-type="video" rid="fig6video4">Figure 6—video 4</xref>), clearly showing the developmental process of the two tube structures of the dorsal aortae (<xref ref-type="bibr" rid="bib44">Sato, 2013</xref>). Note that the upper vessel wall is partially missing in the second half of the video because the fluorescent image was disturbed by the blood flow that began around <italic>t</italic>=15 hr.</p><p>At the current spatiotemporal resolution, we successfully traced the movement of individual cells. Segmentation of cell nuclei allowed us to detect approximately 4.5×10<sup>6</sup> cells across all 200 time points, and by linking cells in close proximity over consecutive time points, we tracked about 4.0×10<sup>5</sup> cells. <xref ref-type="fig" rid="fig6">Figure 6F and G</xref> show cellular movement along with a feature parameter related to cell movement at <italic>t</italic>=8 hr and 16 hr. Both left panels are magnified views of the square regions in the right panels, with trajectories drawn on MIP images. By analyzing the cell segmentation and tracking results, various feature parameters related to cell nucleus morphology and dynamics were computed, including nuclear size, brightness, aspect ratio, velocity, acceleration, mean square displacement, and meandering index (<xref ref-type="bibr" rid="bib31">Meijering et al., 2012</xref>; <xref ref-type="bibr" rid="bib3">Beltman et al., 2009</xref>). Here, we used the meandering index, a measure representing the straightness of cellular movement, to color the trajectories in <xref ref-type="fig" rid="fig6">Figure 6F and G</xref> with the rainbow color table. We found that the distribution of high meandering index at <italic>t</italic>=8 hr and 16 hr was significantly changed. Further detailed analysis and biological interpretation employing the cell-tracking results will be discussed in a future paper.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we presented AMATERAS-2w, a large FOV fluorescence imaging system, along with its variant AMATERAS-2c. The system is built around a newly designed giant lens with an NA of 0.25, magnification of ×2, and field number of 44 mm. This innovative lens configuration allows for imaging with an impressive spatial resolution of approximately 1.1 μm within a centimeter-scale FOV (15×10 mm<sup>2</sup>). Notably, this FOV-to-spatial resolution ratio surpasses those of previously reported large-FOV imaging methods. The key metric ‘optical invariant’, derived from the product of NA and FOV, has a value of 2.75 (Materials and methods, <xref ref-type="bibr" rid="bib4">Bumstead et al., 2018</xref>), thus indicating excellent performance of the lens system. Furthermore, the ‘space-bandwidth product’, which signifies the FOV to spatial resolution ratio achieved under real measurement conditions (considering image sensor size and wavelength), reaches 4.3×10<sup>8</sup> (Materials and methods, <xref ref-type="bibr" rid="bib26">Lohmann et al., 1996</xref>). Both of these metrics significantly outperform those reported in earlier studies on large FOV imaging methods (<xref ref-type="bibr" rid="bib29">McConnell et al., 2016</xref>; <xref ref-type="bibr" rid="bib48">Sofroniew et al., 2016</xref>; <xref ref-type="bibr" rid="bib9">Fan et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Ota et al., 2021</xref>; <xref ref-type="bibr" rid="bib63">Yu et al., 2021</xref>; <xref ref-type="bibr" rid="bib4">Bumstead et al., 2018</xref>). Although these metrics are essential indicators of our system’s performance, they do not solely determine its superiority over other large-FOV imaging systems. Variations in biological targets and additional optical performance measures (such as frame rate and imaging depth) must also be considered. Our primary focus in designing this system was to expand the FOV, that is, maximize the number of observable cells at any instant, even at the cost of intracellular spatial resolution. Thus, in this aspect, our system excels as an instrument for such purposes.</p><p>The spatial resolution (FWHM) of AMATERAS-2w and –2 c was measured to be approximately 1.1–1.8 μm in the transverse direction (<italic>xy</italic>) and 13–16 μm in the longitudinal direction (<italic>z</italic>) through PSF measurements (<xref ref-type="fig" rid="fig2">Figures 2A, B</xref>, <xref ref-type="fig" rid="fig3">3D and E</xref>). These values represent a significant enhancement compared with the previous AMATERAS version (2.3 and 64 µm, respectively; <xref ref-type="bibr" rid="bib20">Ichimura et al., 2021</xref>). The improved transverse resolution enables clearer visualization of intracellular filamentous structures (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). Moreover, the refinement in longitudinal resolution was more than four times greater, thus demonstrating that the expected effect was achieved with more than double NA. Depending on the object of observation, it may be debatable whether this anisotropic spatial resolution elongated along the optical axis qualifies ‘cellular resolution’. Although this may be insufficient to resolve dense cell populations, it proves adequate for cells with only stained nuclei or those sparsely distributed, as observed in <xref ref-type="fig" rid="fig5">Figures 5F–I </xref>–<xref ref-type="fig" rid="fig6">6E</xref>. Using modern cell detection methods compatible with 3D big data, such as ELEPHANT employed in this study (<xref ref-type="bibr" rid="bib49">Sugawara et al., 2022</xref>), we can achieve accurate cell detection, counting and tracking to some extent, even without clear spatial separation in three dimensions. It goes without saying that the higher spatial resolution in raw image data would enhance the performance of subsequent image analysis. The next step in optical development involves further enhancing the NA of the lens system, including the relay lens, to further improve volumetric resolution and expand the range of observable biological objects.</p><p>We successfully achieved volumetric imaging of a 1.5-mm-thick mouse brain coronal section using the multipoint-scanning confocal imaging method, along with computational sectioning and tissue-clearing (<xref ref-type="fig" rid="fig5">Figure 5</xref>). This thickness corresponds to about one-tenth of the whole brain. The exposure time per image was 1 s, and data acquisition took less than 10 min. The ultimate goal is to apply this approach to enable whole-brain imaging. Unlike previous methods such as light-sheet imaging (<xref ref-type="bibr" rid="bib51">Susaki et al., 2014</xref>) and block-face serial microscopy tomography (<xref ref-type="bibr" rid="bib47">Seiriki et al., 2019</xref>), which require half a day or more for whole-brain data acquisition owing to tiling images from a narrow FOV, our method can significantly reduce the acquisition time when extended to the whole brain. This feature is effective not only for the brain imaging but also for imaging of other organs and whole body of an organism. We also plan to apply it to live imaging of highly transparent tissues such as zebrafish (<xref ref-type="bibr" rid="bib55">Takanezawa et al., 2021</xref>) and organoids (<xref ref-type="bibr" rid="bib16">Hof et al., 2021</xref>). Nevertheless, as the thickness increases, challenges such as increased background light and larger spherical aberration arise, thus resulting in weaker focal plane images. To address these issues and realize whole-brain imaging, we propose the incorporation of a mechanism for compensating spherical aberrations in the future. Additionally, we aim to improve the pinhole array pattern design and light source intensity to enhance transmittance and increase fluorescence intensity from samples, broadening the scope of applications.</p><p>We have shown that AMATERAS-2 can perform time-lapse observation of the centimeter-sized vascular networks in the quail embryo. It is a promising tool for understanding the multicellular behavior, especially the mechanisms of tissue formation during development (<xref ref-type="bibr" rid="bib42">Sasai, 2013</xref>; <xref ref-type="bibr" rid="bib30">McDole et al., 2018</xref>; <xref ref-type="bibr" rid="bib8">Dominguez et al., 2023</xref>). In regard to the quail embryo’s case, the data obtained here are the first demonstration of the dynamics of the extensive organization of the vascular network throughout the quail embryo at the single-cell level. Conventional methods of research employing traditional microscopy have selected a limited area for observation and thus had a difficulty in determining the distribution and synchronicity of cellular dynamics across the entire system. By analyzing such a huge four-dimensional data (<italic>xyz</italic> and <italic>t</italic>), we can gain insight into when and where each organ is formed, in what order, and in what interrelationships. In addition, employing this method allows us to break away from the conventional hypothesis-driven research manner and obtain new findings in a data-driven manner. This advantage can be realized not only for quail embryo but also for a variety of other species undergoing widespread and dynamic cellular events, making it a powerful tool in the study of multicellular organisms, especially in the study of tissue formation.</p><p>To further advance multicellular systems research, information on individual cell states is required in addition to cellular dynamics, therefore multiplex measurement is an essential technological challenge. Although most of the observations presented in this paper were made with monochromatic fluorescence imaging, multiplex imaging will lead to a more profound understanding if information on the distribution of cellular states can also be obtained by employing multiple fluorescent probes. This requires technological upgrades in optical filters and light sources for multicolor imaging. In addition, spatial transcriptomics has been rapidly developing in recent years and has become one of the most crucial tools for multicellular system study (<xref ref-type="bibr" rid="bib41">Rao et al., 2021</xref>). In the near future, dynamics imaging and spatial transcriptomics for the same sample will be a very important technological integration to advance an integrative understanding of self-organization in tissue formation. Rather than simply using AMATERAS sequentially with existing spatial transcriptomics, it could be employed as an optical detection system for spatial transcriptomics to achieve extremely high throughput in the same wide FOV of cellular dynamics imaging.</p><p>Finally, let us discuss a practical challenge we encountered with our instrument, primarily related to the handling of extensive image data. In our studies, the raw data for 3D imaging of the mouse brain section and time-lapse 3D imaging of the quail embryo amounted to approximately 100 and 500 GB, respectively. However, after multiple image processing and analysis steps, a single experimental measurement resulted in several terabyte of image data. Managing such vast data proves challenging for standard computers in terms of both software and hardware capabilities. To address software limitations, we opted not to employ commercial software for data analysis. Instead, we utilized our originally developed programs, implementing certain optimizations to reduce analysis time, minimize write/read cycles, and prevent memory overflows. As for hardware, we established a data server with petabyte storage, thereby enabling efficient data sharing among collaborators from diverse research institutions physically distant from one another. The existence of this infrastructure considerably facilitated the smooth progress of collaborative research within this study. Considering the increasing significance of handling image big data, we expect methodologies for image computation to become even more critical in the future. Ideally, a comprehensive system should be developed, encompassing not only data storage and sharing but also an integrated analysis solution in the cloud. We would like to actively promote the development of such a system, essentially encompassing advancements in imaging techniques and data-handling strategies.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Genetic reagent <break/>(coturnix japonica)</td><td align="left" valign="bottom">tie1:H2B-eYFP</td><td align="left" valign="bottom">Sato et al., PLoS One. <break/>5, e12674 (2010).</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Strain, strain <break/>background (mouse)</td><td align="left" valign="bottom">C57BL/6JJmsSlc</td><td align="left" valign="bottom">Japan SLC,Inc.</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:MGI:548896">MGI:5488963</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Cell line (<italic>Homo sapiens</italic>)</td><td align="left" valign="bottom">iPS cell</td><td align="left" valign="bottom">Riken Cell Bank <break/>Takahashi et al., Cell 131, 861–872 (2007).</td><td align="char" char="." valign="bottom">201B7<break/>RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:CVCL_A324">CVCL_A324</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">rabbit IgG anti-cTnT (polyclonal)</td><td align="left" valign="bottom">Bioss</td><td align="left" valign="bottom">Cat#:bs-10648R<break/></td><td align="char" char="." valign="bottom">1:200</td></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">alexa488 conjugated goat IgG anti-rabbit IgG (polyclonal)</td><td align="left" valign="bottom">Abcam</td><td align="left" valign="bottom">Cat#:Ab150077;<break/>RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:AB_2630356">AB_2630356</ext-link></td><td align="char" char="." valign="bottom">1:500</td></tr><tr><td align="left" valign="bottom">Other (culture medium)</td><td align="left" valign="bottom">CDM3</td><td align="left" valign="bottom">Burridge, et al., Nat. Methods. 11, 855–860 (2014)</td><td align="left" valign="bottom"/><td align="left" valign="bottom">used for initiation of iPSC differentiation</td></tr><tr><td align="left" valign="bottom">Other (culture medium)</td><td align="left" valign="bottom">StemFit</td><td align="left" valign="bottom">Ajinomoto</td><td align="left" valign="bottom">Cat#:AK02N</td><td align="left" valign="bottom">used for iPSC culture</td></tr><tr><td align="left" valign="bottom">Other (dish coating peptide)</td><td align="left" valign="bottom">iMatrix-511</td><td align="left" valign="bottom">Matrixome</td><td align="left" valign="bottom">Cat#:89292</td><td align="left" valign="bottom">used to coat a dish for iPSC culture</td></tr><tr><td align="left" valign="bottom">Other (cell detachment reagent)</td><td align="left" valign="bottom">TrypLE Select</td><td align="left" valign="bottom">Thermo Fisher Scientific,</td><td align="left" valign="bottom">Cat#:A1285901</td><td align="left" valign="bottom">used to dissociate iPSCs</td></tr><tr><td align="left" valign="bottom">Chemical compound</td><td align="left" valign="bottom">Y-27632</td><td align="left" valign="bottom">Fujifilm Wako</td><td align="left" valign="bottom">Cat#:030–24021</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Chemical compound</td><td align="left" valign="bottom">CHIR99021</td><td align="left" valign="bottom">Fujifilm Wako</td><td align="left" valign="bottom">CAS: 252917-06-9;Cat#:038–23101</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Chemical compound</td><td align="left" valign="bottom">IWP-2</td><td align="left" valign="bottom">Fujifilm Wako</td><td align="left" valign="bottom">CAS: 686770-61-6;Cat#:034–24301</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Chemical compound</td><td align="left" valign="bottom">Medetomidine</td><td align="left" valign="bottom">Nippon Zenyaku Kogyo</td><td align="left" valign="bottom">CAS:86347-14-0</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Chemical compound</td><td align="left" valign="bottom">midazolam</td><td align="left" valign="bottom">Sandoz Pharma</td><td align="left" valign="bottom">CAS:59467-70-8</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Chemical compound</td><td align="left" valign="bottom">butorphanol</td><td align="left" valign="bottom">Meiji Seika Pharma</td><td align="left" valign="bottom">CAS:42408-82-2</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Other (fluorescent dye)</td><td align="left" valign="bottom">Rhodamine phalloidin</td><td align="left" valign="bottom">Fujifilm Wako</td><td align="left" valign="bottom">Cat#:165–21641</td><td align="left" valign="bottom">used for fluorescent labelling of actin filaments in the cardiac cell sheet</td></tr><tr><td align="left" valign="bottom">Other (fluorescent dye)</td><td align="left" valign="bottom">Hoechst33342</td><td align="left" valign="bottom">Dojin</td><td align="left" valign="bottom">Cat#:H342</td><td align="left" valign="bottom">used for fluorescent labelling of nuclei of cardiac organoid</td></tr><tr><td align="left" valign="bottom">Other (fluorescent dye)</td><td align="left" valign="bottom">SYTOX Green</td><td align="left" valign="bottom">Thermo Fisher Scientific</td><td align="left" valign="bottom">Cat#:S7020</td><td align="left" valign="bottom">used for fluorescent labelling of nuclei in the mouse brain section</td></tr><tr><td align="left" valign="bottom">Other (tissue-clearing reagent)</td><td align="left" valign="bottom">CUBIC-L</td><td align="left" valign="bottom">Tokyo Chemical Industry</td><td align="left" valign="bottom">Cat#:T3740</td><td align="left" valign="bottom">used for tissue clearing of the mouse brain section</td></tr><tr><td align="left" valign="bottom">Other (tissue-clearing reagent)</td><td align="left" valign="bottom">CUBIC-R+(M)</td><td align="left" valign="bottom">Tokyo Chemical Industry</td><td align="left" valign="bottom">Cat#:T3741</td><td align="left" valign="bottom">used for tissue clearing of the mouse brain section</td></tr><tr><td align="left" valign="bottom">Software</td><td align="left" valign="bottom">ELEPHANT</td><td align="left" valign="bottom"><xref ref-type="bibr" rid="bib49">Sugawara et al., 2022</xref>; <xref ref-type="bibr" rid="bib50">Sugawara, 2024</xref></td><td align="left" valign="bottom">Server: v0.5.7i, Client: v0.5.0</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://github.com/elephant-track">https://github.com/elephant-track</ext-link></td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Wide-field imaging system (AMATERAS-2w) configuration</title><p>We aimed for AMATERAS to achieve a larger FOV-to-resolution ratio than conventional microscopes, which required a giant imaging lens system. We realized this design concept by collaborating with SIGMAKOKI CO., LTD. Inc (Tokyo, Japan) to manufacture the giant objective and tube lenses as shown in <xref ref-type="fig" rid="fig1">Figure 1</xref>. The characteristics of these lens are described in the main text. Designing such large lenses presents significant challenges in selecting optical glass materials compared to regular-sized lenses. Although there are over 200 types of optical glass available, our options are limited because the thickness or diameter of several types of glass may be unprocessable, or their transparency may degrade due to their size. Therefore, we iteratively explored the optimal design, considering the feasibility of material procurement and processing in conjunction with the optical design.</p><p>By combining these lenses, we constructed an imaging system with a 2×magnification, NA of 0.25, and a 44 mm field number. To facilitate both water-immersion and dry observation, we incorporated a glass plate whose thickness can be adjusted at the lens tip. The objective lens has a focal length of 120 mm, whereas its working distance is 14 mm owing to the presence of the attachment at the tip. The pupil positions of the objective lens and the tube lens are set externally to the lens bodies. This arrangement allows for the placement of a spatial filter or other devices at the pupil position, facilitating future enhancements in functionality.</p><p>For image acquisition, a 120-megapixel CMOS camera (VCC-120CXP1M, CIS, Tokyo, Japan) and a 250-megapixel CMOS camera (VCC-250CXP1M, CIS, Tokyo, Japan) were used, out of which we selected one depending on research purpose. Both the cameras have a chip size of 35 mm (diagonal). The pixel sizes of these two cameras are 2.2 µm and 1.5 µm, respectively. The sampling intervals are 1.1 µm and 0.75 µm at ×2 magnification. Image data captured by the CMOS cameras are loaded into a workstation via a CoaXpress frame grabber board (APX-3664G3, Aval Data, Tokyo, Japan). After the imaging experiments, they were transferred to a network server with large storage capacity for long-term storage and data sharing among project members.</p><p>By use of the lens system and CMOS cameras, a wide-field epi-illumination fluorescence imaging system was constructed. The imaging system chassis was designed to accommodate both inverted and upright microscope geometries. For this study, all experiments were conducted using the inverted microscope arrangement. Epi-illumination was achieved using a high-brightness LED sources (SOLIS-470C and SOLIS-385C, Thorlabs, Newton, NJ), with an excitation filter (#87–800, Edmund Optics, Barrington, NJ) placed immediately after it. The illumination light was homogenized using a pair of lenslet arrays and projected onto the sample surface. Additionally, a similar LED light source (SOLIS-525C, Thorlabs, Newton, NJ) with an illumination homogenizer was also mounted as transmitted illumination light for bright-field observation. To split the light path, we used a custom-made long-pass dichroic mirror measuring 158 mm × 120 mm×10 mm (BK7), which was designed for fluorescence imaging of GFP with a cut-off wavelength of 497 nm. A fluorescent filter (#86–992, Edmund Optics, Barrington, NJ) was positioned in front of the camera, which was firmly attached to the imaging lens using an F-mount.</p><p>The sample stage comprises a three-axis translational movable stage and a two-axis tilt stage. Only the <italic>z</italic>-axis stage is motorized, utilizing an electric actuator (SOM-C13E, SIGMAKOKI CO., LTD., Tokyo, Japan). For time-lapse observation under controlled conditions, we mounted a stage-top incubator (SV-141A, BLAST, Kawasaki, Japan) on the five-axis stage, providing a stable environment at 37 °C with CO<sub>2</sub> control. To ensure precise measurements, we enclosed the entire sample space within a dark box, shielding it from external light and temperature fluctuations.</p></sec><sec id="s4-2"><title>Multipoint confocal system (AMATERAS-2c) configuration</title><p>In the multipoint confocal imaging system, we utilized a custom-made pinhole array disk with specific dimensions (pinhole size: 6 µm, spacing: 24 µm). This disk was mounted on a high-speed rotating machine (CrestOptics, Rome, Italy) and placed precisely on the image plane of the imaging lens. Alignment throughout the FOV was ensured using a translation stage (XR25P/M, Thorlabs, Newton, NJ) and tilt stage (AIS-1016B, SIGMAKOKI CO., LTD., Tokyo, Japan) to adjust height and tilt. Beneath the disk, we positioned a short-pass dichroic mirror (DMSP490L, Edmund Optics, Barrington, NJ) to allow excitation light to be incident from below. The excitation light source included a high-brightness LED (SOLIS-470C, Thorlabs, Newton, NJ), an excitation filter (#87–800, Edmund Optics, Barrington, NJ), and a pair of lenslet arrays (#63–231, Edmund Optics, Barrington, NJ), together with a 75 mm lens (<italic>f</italic>=200 mm, LA1353-A, Thorlabs, Newton, NJ) to ensure uniform illumination onto the disk. The fluorescent image was reflected by the dichroic mirror, transmitted through a fluorescent filter (#86–992, Edmund Optics), and projected onto a 120-megapixel camera using either a 1×or 2×relay lens (LSTL10H-F and LSTL20H-F, Myutron, Tokyo, Japan). The relay lens and camera were attached with an F-mount and secured on a three-axis translational stage (PT3/M, Thorlabs, Newton, NJ). To adjust the focus, the stage for the optical axis direction was motorized using an electric actuator (SOM-C25E, SIGMAKOKI CO., LTD., Tokyo, Japan).</p></sec><sec id="s4-3"><title>Measurement of 3D point spread functions</title><p>To evaluate the optical performance of the imaging systems, the 3D point spread function was measured using green fluorescent beads. Fluorescent beads with a 0.2 µm diameter (FluoSphere F8811, Invitrogen, Thermo Fisher Scientific, Waltham, MA) were employed in the evaluation of AMATERAS-2w (<xref ref-type="fig" rid="fig2">Figure 2A–B</xref>) and those with a 0.5 µm diameter (FluoSphere F8813, Invitrogen, Thermo Fisher Scientific, Waltham, MA) were employed in the evaluation of AMATERAS-2c (<xref ref-type="fig" rid="fig3">Figure 3D–E</xref>). The beads were dispersed three-dimensionally in 1.5% (wt/vol) agarose gel on a glass-bottom dish, and <italic>z</italic>-stacks were obtained by moving the sample in the <italic>z</italic>-direction in 1 or 2 µm steps.</p></sec><sec id="s4-4"><title>Computational sectioning</title><p>In wide-field fluorescence imaging of a 3D volume, the superimposition of a fluorescent image from the focal plane and background light from outside the focal plane is a fundamental issue. This problem is not limited to wide-field imaging but also arises in multipoint confocal imaging of thick or high-density samples. To overcome this challenge, we employed computational sectioning, an image processing technique aimed at removing the background light component. Various algorithms have been proposed (<xref ref-type="bibr" rid="bib24">Lee and Yang, 2014</xref>; <xref ref-type="bibr" rid="bib59">Walter and Ziesche, 2019</xref>), and Leica microscopes' standard software includes this functionality. In this study, we developed an original algorithm as a simple and robust method for data analysis.</p><p>The critical step in our approach involves estimating the background light component at each layer of the <italic>z</italic>-stack data. To achieve this, we leverage the assumption that the background light exhibits a low spatial frequency, whereas the focal plane image demonstrates a high spatial frequency. Consequently, we employ an iterative low-pass filtering technique to estimate the background light component. Specifically, as shown in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A and B</xref>, a two-dimensional (2D) low-pass filter is applied to the raw data (<italic>f</italic><sub>0</sub>(<italic>x</italic>,<italic>y</italic>)) to obtain a smooth surface (<italic>L</italic><sub>0</sub>(<italic>x</italic>,<italic>y</italic>)). To obtain <italic>f</italic><sub>1</sub>(<italic>x</italic>,<italic>y</italic>), <italic>f</italic><sub>0</sub>(<italic>x</italic>,<italic>y</italic>) and <italic>L</italic><sub>0</sub>(<italic>x</italic>,<italic>y</italic>) are compared and the smaller one is chosen to <italic>f</italic><sub>1</sub>(<italic>x</italic>,<italic>y</italic>) at every position (<italic>x,y</italic>), as expressed by <xref ref-type="disp-formula" rid="equ1">Equation (1)</xref>.<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where min(<italic>a</italic>,<italic>b</italic>) returns the smaller value of <italic>a</italic> and <italic>b</italic>. Next, the low-pass filter is applied to <italic>f</italic><sub>1</sub>(<italic>x</italic>,<italic>y</italic>) to obtain <italic>L</italic><sub>1</sub>(<italic>x</italic>,<italic>y</italic>); this process is repeated to make <italic>L<sub>j</sub></italic>(<italic>x</italic>,<italic>y</italic>) closer to the baseline of the original image. The iteration stops when the standard deviation of the difference of <italic>f<sub>j</sub></italic>(<italic>x</italic>,<italic>y</italic>) and <italic>L<sub>j</sub></italic>(<italic>x</italic>,<italic>y</italic>) reaches a preset value (<italic>ε</italic>).<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msqrt><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt><mml:mo>&lt;</mml:mo><mml:mrow><mml:mi>ε</mml:mi></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Among various methods available as 2D low-pass filters, we sequentially applied one-dimensional (1D) infinite impulse response (IIR) filter in two directions (<italic>x</italic>,<italic>y</italic>). This method is faster than other methods such as a 2D Fourier transform (<xref ref-type="bibr" rid="bib10">Getreuer, 2013</xref>). This speed difference is especially significant when the number of pixels in an image is massive, as in the present case. We adopted the Butterworth type of the IIR low-pass filter.</p><p>When the focal plane is empty and there is a bright object in the background, the baseline estimation tends to be skewed by the intensity fluctuations of the background. To mitigate this, we applied a 3×3 moving average filter to the entire image as a pre-processing step before initiating the baseline estimation algorithm. A critical parameter in our algorithm is the cutoff frequency of the low-pass IIR filter. If the cutoff frequency is set too high, the focal plane component would be included in the background; if it is set to low, background light would remain in the focal plane. Thus, it is crucial to find an optimal middle ground for the cutoff frequency. During this optimization, we did not account for cell size or optical system performance. Indeed, we employed a user-friendly blind separation method based on independent component analysis (ICA) to enhance usability (<xref ref-type="bibr" rid="bib18">Hyvaerinen et al., 2001</xref>). Similar to ICA, we assumed that the fluorescence image in the focal plane deviates from the Gaussian (normal) distribution and that the superposition of images from multiple planes, including both in-focus and out-of-focus planes, results in a distribution closer to the Gaussian distribution. To quantify the non-Gaussian nature of the distribution, we considered several measures, including kurtosis, skewness, negentropy, and mutual information (<xref ref-type="bibr" rid="bib18">Hyvaerinen et al., 2001</xref>). Among these measures, we found skewness to be the most robust metric for our image dataset and incorporated it into our algorithm. The cutoff frequency was adjusted to maximize the skewness of the estimated in-focus image. The optimization of the cut-off frequency was performed on a subset of the data before applying it to the entire dataset. An example of the selection of non-Gaussianity measure and the optimization of the cut-off frequency is found in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref>–<xref ref-type="fig" rid="fig4s2">2</xref> (see also Appendix File - Note 2). The typical cut-off frequency was set at 0.06 in normalized frequency unit of 1/pixel, and the value was applied across all data.</p></sec><sec id="s4-5"><title>Culture of hiPSCs and differentiation into cardiac organoid with cavity chamber structure</title><p>We used a hiPSC line 201B7 (<xref ref-type="bibr" rid="bib54">Takahashi et al., 2007</xref>), which was authenticated and confirmed mycoplasma negative by the supplier (RIKEN Cell Bank, Japan). The hiPSC line was routinely maintained as previously described (<xref ref-type="bibr" rid="bib33">Nakagawa et al., 2014</xref>) on iMatrix-511 (Matrixome, 89292) coated culture dish in StemFit medium (Ajinomoto, AK02N), and 10 µM Y-27632 (Fujifilm Wako, 030–24021) was added for the first 24 hr after passage. Four days before inducing differentiation, hiPSCs were dissociated with TrypLE Select Enzyme (Thermo Fisher Scientific, A1285901) and 1.9×10<sup>5</sup> cells were passed into iMatrix-511 coated 12 well plate in StemFit medium supplemented with 10 µM Y-27632. After 24 hr, the medium was changed to StemFit without Y-27632 and was exchanged daily for 3 days. Differentiation was initiated with the CDM3 medium (<xref ref-type="bibr" rid="bib5">Burridge et al., 2014</xref>) composed of RPMI-1640 with HEPES (Fujifilm Wako, 189–02145), 0.5 mg/ml human recombinant albumin (Sigma Aldrich, A9731) and 0.2 mg/ml L-ascorbic acid 2-phosphate (Sigma-Aldrich, A8960) supplemented with 3 µM CHIR99021 (Fujifilm Wako, 038–23101) for 48 hr. On day 2 of differentiation, the medium was changed to CDM3 supplemented with 5 µM IWP-2 (Fujifilm Wako, 034–24301). From day 4 to day 8, the cells were cultured in CDM3 and the medium was changed every other day. From day 8, the medium was changed to RPMI-1640 with HEPES supplemented with 2% B27 (Thermo Fisher Scientific, 17504044) and was changed every other day. The cells were fixed in 4% paraformaldehyde (PFA; Thermo Fisher Scientific, 43368) on day 15 for immunocytochemical analysis.</p></sec><sec id="s4-6"><title>Immunocytochemical staining of cardiac organoid</title><p>Cells were fixed with 4% PFA for 15 min at room temperature (RT ~23 °C), permeabilized with 0.2% Triton X-100 (Fujifilm Wako, 807423) for 20 min at RT and incubated with blocking solution composed of D-PBS with 5% BSA and 10% FBS for 30 min at RT. Subsequently, the cells were incubated with primary antibody (1:200 rabbit IgG anti-cTnT, Bioss, bs-10648R) at 4 °C overnight. After washing three times, cells were incubated with secondary antibody (1:500 alexa488 conjugated goat IgG anti-rabbit IgG, Abcam, ab150077) for 2 hr at RT. The cells were washed three times in D-PBS with 1 µg/ml Hoechst33342 (Dojin, H342). Subsequently, the cells were incubated with D-PBS and used for fluorescent observation.</p></sec><sec id="s4-7"><title>Color representation of the 3D image</title><p><xref ref-type="fig" rid="fig6">Figure 6B–D</xref> show the 3D positions of the cells using the HSB (also known as HSV) color model. After applying the method described earlier to remove background light from the <italic>z</italic>-stack image, we conducted a maximum value intensity projection along the <italic>z</italic>-direction. The <italic>z</italic>-position of the maximum value at each <italic>xy</italic>-position was then recorded (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1C</xref>). The color image was reconstructed by associating the brightness and hue of the HSB table with the value of the maximum intensity and the maximum value position, respectively (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1D</xref>). For the hue table, we assigned red to blue to <italic>z</italic>-layer numbers ranging from 0 (<italic>z</italic>=0 µm) to 20 (<italic>z</italic>=240 µm).</p></sec><sec id="s4-8"><title>Preparation of mouse brain section</title><p>All animal care and handling procedures were conducted with approval from the Animal Care and Use Committee of Osaka University (Authorization number: R02-8-7). Our utmost efforts were made to minimize the number of animals used. Experiments involved adult male C57BL/6J mice (SLC, Shizuoka, Japan) aged between 2 and 3 mo. To ensure proper anesthesia, mice were deeply anesthetized through intraperitoneal injection of an anesthetic cocktail containing 0.3 mg/kg medetomidine (Nippon Zenyaku Kogyo, Fukushima, Japan), 4 mg/kg midazolam (Sandoz Pharma, Basel, Switzerland), and 5 mg/kg butorphanol (Meiji Seika Pharma, Tokyo, Japan). Subsequently, anesthetized mice underwent transcardial perfusion with saline, followed by 4% PFA (Nacalai Tesque, Kyoto, Japan) dissolved in phosphate-buffered saline (PBS). Brain tissues were then excised and immersed in a 4% PFA solution until further use. For tissue preparation, brain tissue blocks were sliced into 1.5-mm-thick coronal sections using a vibrating microtome (LinearSlicer Pro7N, Dosaka EM, Kyoto, Japan). Subsequent staining and tissue clearing involved immersion of sections in CUBIC-L (Tokyo Chemical Industry, Tokyo, Japan) for delipidation, SYTOX Green (Thermo Fisher Scientific, Waltham, MA, USA) solution (1:5000) diluted in 20% (vol/vol) DMSO in PBS for nuclear staining, and CUBIC-R+(M) (Tokyo Chemical Industry, Tokyo, Japan) for refractive index matching, following previously established methods (<xref ref-type="bibr" rid="bib53">Tainaka et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Susaki et al., 2020</xref>). After clearing, tissue sections were placed on glass bottom dishes and embedded in 2% (wt/vol) agarose gel prepared with CUBIC-R+(M) for subsequent imaging analysis.</p></sec><sec id="s4-9"><title>Preparation of quail embryo</title><p>Transgenic quail line, tie1:H2B-eYFP (<xref ref-type="bibr" rid="bib43">Sato et al., 2010</xref>) was bred in quail breeding facility at Kyushu University. Fertilized eggs were incubated at 38 °C. The staging of quail embryos was based on the Hamburger and Hamilton stages of chicken embryos (<xref ref-type="bibr" rid="bib14">Hamburger and Hamilton, 1951</xref>). The animal study was approved by the Institutional Animal Care and Use Committee of Kyushu University (Authorization number: A20-019). Ex ovo culture was performed as previously described (<xref ref-type="bibr" rid="bib45">Sato and Lansford, 2013</xref>). Black filter paper was used instead of white filter paper to avoid fluorescence background.</p></sec><sec id="s4-10"><title>Autofocus in time-lapse imaging</title><p>To address <italic>z</italic>-directional drift in the time-lapse observation of quail, we developed an original autofocus method. During the intervals between fluorescence <italic>z</italic>-images, we acquired bright-field <italic>z</italic>-stacks and analyzed the images to identify the most in-focus position. To achieve this, we used a black ink marker located on the substrate edge as the autofocus target instead of the variable sample itself. For evaluating the degree of in-focus, we applied a total variation (TV) filter to the marker image and used the kurtosis of the filtered image as the focus score. The <italic>z</italic>-position with the maximum focus score was identified as the in-focus location, thus signifying the sharpest image of the marker edge. Although other filter types and statistical moments are available options for the focus score (<xref ref-type="bibr" rid="bib28">Mateos-Pérez et al., 2012</xref>), our preliminary experiments demonstrated the suitability of the kurtosis of TV for the marker image. In the actual experiment, we acquired 15 images in 15 µm steps and plotted the focus scores against <italic>z</italic>-positions. Through quadratic function fitting of the focus scores at three z-positions (including the <italic>z</italic>-position with the maximum value and adjacent positions), we estimated the best in-focus position with an accuracy of 1 µm.</p></sec><sec id="s4-11"><title>Deep-learning based cell detection for the mouse brain data</title><p>Cell detection was conducted using ELEPHANT, a unified platform that facilitates manual annotation, deep learning and proofreading of results within a single user-friendly GUI (<xref ref-type="bibr" rid="bib49">Sugawara et al., 2022</xref>; <xref ref-type="bibr" rid="bib50">Sugawara, 2024</xref>). ELEPHANT serves as an extension to Mastodon (<xref ref-type="bibr" rid="bib56">Tinevez et al., 2025</xref>), an open-source framework for large-scale tracking deployed in Fiji, a widely used image-analysis software (<xref ref-type="bibr" rid="bib46">Schindelin et al., 2012</xref>). ELEPHANT supports incremental deep learning with sparse annotation, incorporating algorithms for detecting cells in 3D and tracking them in time-lapse 3D image datasets. In this paper, we utilized the cell detection function exclusively for analyzing 3D imaging data of mouse brain section (<xref ref-type="fig" rid="fig5">Figure 5G–I</xref>). The incremental learning approach allows cell detection models to be trained progressively on a dataset that begins with sparse annotations and is continuously enhanced through human proofreading. For visualization, image data were displayed using BigDataViewer (<xref ref-type="bibr" rid="bib38">Pietzsch et al., 2015</xref>) on Mastodon, accessed via BigDataServer (<xref ref-type="bibr" rid="bib39">Pietzsch, 2024</xref>). This setup permits the visualization of large-scale image data on client computers while maintaining the data on the server. Deep learning capabilities were provided by the ELEPHANT server, enabling remote GPU access. This setup allows non-experts to perform image analysis on big data using deep learning, effectively overcoming typical challenges such as the need for large amounts of high-quality training data, the absence of an interactive user interface, and limited access to computing resources, including substantial storage and high-end GPUs (<xref ref-type="bibr" rid="bib32">Moen et al., 2019</xref>; <xref ref-type="bibr" rid="bib60">Wen et al., 2021</xref>). The server computer used in this study is equipped with an Intel(R) Xeon(R) Gold 6132 CPU @ 2.60 GHz, runs Ubuntu 20.04, and includes 384 GB DDR4 2,666 MT/s RAM, 2 x NVIDIA Tesla V100-PCIE-32GB GPUs, and a network-attached Lustre parallel file system with over 2 PB of storage. The client computer features an Apple M1 Pro CPU, runs Sonoma 14.3, and has 16 GB of LPDDR5-6400 RAM and a 500 GB SSD.</p><p>In the analyses presented in this paper (<xref ref-type="fig" rid="fig5">Figure 5G–I</xref>), cell detection models were trained for three regions, including the cortex. In each region, the detection model was refined by repeating the sequence (annotation, training, prediction, and proofreading) five to seven times. By annotating approximately 100 cells in total, we were able to establish a model capable of detecting the vast majority of the cells. The training of the detection models was conducted on volumes of 256×256 x 16 voxels, which were prepared by preprocessing with a random flip in each dimension. During the label generation step, the center ratio was set to 0.4 and the background threshold was set to zero, meaning that only explicitly annotated voxels were used for training. In the prediction step, volumes cropped to dimensions of 700×700 × 100 around the target area were used as input. In the postprocessing step, a threshold for nucleus center probabilities was set to 0.5, and <italic>r<sub>min</sub></italic>, <italic>r<sub>max</sub></italic> and <italic>d<sub>sup</sub></italic> were set to 1 µm, 5 µm, and 3 µm, respectively (see details about the parameters in <xref ref-type="bibr" rid="bib49">Sugawara et al., 2022</xref>).</p><p>To quantitatively evaluate the performance of cell detection, we calculated precision and recall, defined as TP/(TP +FP) and TP/(TP +FN), respectively, where TP stands for true-positive, FP for false-positive, and FN for false-negative. In the actual 3D data of the cortical region, the values of TP, FP, and FN were manually counted by comparing the detection results of cells (N~640) within a defined volume of 310×170 × 100, one by one, with the actual images. As a result, we obtained a precision of 99.4% and a recall of 97.6%.</p></sec><sec id="s4-12"><title>Cell segmentation and tracking for the quail embryo data</title><p>For the analysis of quail embryo data, cell detection, segmentation and tracking were performed using a custom-made program coded in Python. The observed 3D volume has a transverse area (<italic>xy</italic>) of more than 1 cm<sup>2</sup> and a height (<italic>z</italic>) of 240 µm, which is relatively thin in the <italic>z</italic> direction compared to the <italic>xy</italic> plane. The overlap of multiple vascular endothelial cells in the <italic>z</italic> direction occurs with a very low probability. Therefore, to save computational costs and time, 2D cell detection was conducted on <italic>z</italic>-projected MIP images instead of full 3D cell detection. To avoid miss-detection of overlapping cells, we divided the <italic>z</italic>-stack data into three blocks along the z-axis and created MIP images for each block, on which 2D cell detection was performed on the MIP images. The resulting cell lists were compared to identify identical cells detected across multiple blocks. By recognizing double-detected cell pairs as identical, we updated the cell list accordingly. This process was applied to all double-detected cells, thus achieving effective cell detection in the 3D volume and enabling cell tracking throughout the observation period.</p></sec><sec id="s4-13"><title>Evaluation of optical system with optical invariant and space-bandwidth product</title><p>We employed two indices to evaluate the lens system’s scale range and compare it with previous research. The first index, the optical invariant, measures the lens system’s performance and is obtained by multiplying the FOV radius and NA. The second index, the space-bandwidth product, considers the image sensor and wavelength while quantifying the ratio of actual resolution to FOV. These indices are calculated using the following simplified formulas, respectively (<xref ref-type="bibr" rid="bib4">Bumstead et al., 2018</xref>).<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>S</mml:mi><mml:mi>B</mml:mi><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>O</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula></p><p>where <italic>I</italic>, <italic>FN</italic>, <italic>M</italic>, <italic>SBP</italic>, <italic>R<sub>FOV</sub></italic>, and <italic>dxy</italic> denote optical invariant, field number, magnification, space-bandwidth product, FOV radius, and spatial resolution (FWHM).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Y.T. is an employee of SIGMAKOKI CO., LTD</p></fn><fn fn-type="COI-statement" id="conf3"><p>S.E. is an employee of SIGMAKOKI CO., LTD</p></fn><fn fn-type="COI-statement" id="conf4"><p>K.S. is employed part-time by LPIXEL Inc</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Resources, Data curation, Visualization, Methodology</p></fn><fn fn-type="con" id="con3"><p>Resources, Methodology</p></fn><fn fn-type="con" id="con4"><p>Resources, Methodology</p></fn><fn fn-type="con" id="con5"><p>Resources, Data curation, Funding acquisition, Methodology</p></fn><fn fn-type="con" id="con6"><p>Data curation, Software, Visualization</p></fn><fn fn-type="con" id="con7"><p>Resources</p></fn><fn fn-type="con" id="con8"><p>Resources, Funding acquisition, Methodology</p></fn><fn fn-type="con" id="con9"><p>Data curation, Software, Funding acquisition, Validation, Visualization</p></fn><fn fn-type="con" id="con10"><p>Data curation, Software</p></fn><fn fn-type="con" id="con11"><p>Data curation, Software, Funding acquisition</p></fn><fn fn-type="con" id="con12"><p>Conceptualization, Funding acquisition, Methodology, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal care and handling procedures were conducted with approval by the Institutional Animal Care and Use Committee of Kyushu University (Authorization number: A20-019) and Osaka University (Authorization number: R02-8-7).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-93633-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All bioimaging data generated in this study are present in the paper and/or Supplementary Materials. The image datasets are available at ssbd-repos-000409, <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.24631/ssbd.repos.2024.12.409">https://doi.org/10.24631/ssbd.repos.2024.12.409</ext-link> in SSBD:repository.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Ichimura</surname><given-names>T</given-names></name><name><surname>Nagai</surname><given-names>T</given-names></name><name><surname>Kakizuka</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>A set of image data used for demonstration of a newly developed optical imaging system &quot;AMATERAS-2&quot;</data-title><source>SSBD:repository</source><pub-id pub-id-type="doi">10.24631/ssbd.repos.2024.12.409</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to thank Prof. K Fujita of Department of Applied Physics, Osaka University, Japan for his valuable comments on optics design. We are also grateful to Prof. S Miyagawa, and Prof. Y Sawa of Graduate School of Medicine, Osaka University, for their support on handling human iPS cells and valuable discussion. Funding: Grant-in-Aid for Scientific Research on Innovative Areas “Singularity Biology (No. 8007)” 21H00431 (YS), 18H05416 (HH), 18H05412 (SO), and 18H05410, 18H05408 (TN). Grant-in-Aid for Transformative Research Areas (A) “Seeing through Scattering Media (No. 20A207)” 21H05590 and 23H041350 (TI) the Research Program of Five-star Alliance in NJRC Mater. &amp; Dev. (TN) Precursory Research for Embryonic Science and Technology (PRESTO)JPMJPR18G2 (TI), JSPS KAKENHI JP23H00395 and JP24K22022 (HH), AMED Brain/MINDS, JP21dm0207117 (HH) and BINDS JP23ama121054 and JP23ama121052 (HH), The Uehara Memorial Foundation (TN), Takeda Science Foundation (TN, HH), Core Research for Evolutionary Science and Technology (CREST) JPMJCR15N3 (TN), JPMJCR1926 (KS, SO), RIKEN Cluster for Science, Technology and Innovation Hub (SO), JST NBDC Grant Number JPMJND2201 (SO).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agetsuma</surname><given-names>M</given-names></name><name><surname>Aizawa</surname><given-names>H</given-names></name><name><surname>Aoki</surname><given-names>T</given-names></name><name><surname>Nakayama</surname><given-names>R</given-names></name><name><surname>Takahoko</surname><given-names>M</given-names></name><name><surname>Goto</surname><given-names>M</given-names></name><name><surname>Sassa</surname><given-names>T</given-names></name><name><surname>Amo</surname><given-names>R</given-names></name><name><surname>Shiraki</surname><given-names>T</given-names></name><name><surname>Kawakami</surname><given-names>K</given-names></name><name><surname>Hosoya</surname><given-names>T</given-names></name><name><surname>Higashijima</surname><given-names>S</given-names></name><name><surname>Okamoto</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The habenula is crucial for experience-dependent modification of fear responses in zebrafish</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1354</fpage><lpage>1356</lpage><pub-id pub-id-type="doi">10.1038/nn.2654</pub-id><pub-id pub-id-type="pmid">20935642</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Battistella</surname><given-names>E</given-names></name><name><surname>Schniete</surname><given-names>J</given-names></name><name><surname>Wesencraft</surname><given-names>K</given-names></name><name><surname>Quintana</surname><given-names>JF</given-names></name><name><surname>McConnell</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Light-sheet mesoscopy with the Mesolens provides fast sub-cellular resolution imaging throughout large tissue volumes</article-title><source>iScience</source><volume>25</volume><elocation-id>104797</elocation-id><pub-id pub-id-type="doi">10.1016/j.isci.2022.104797</pub-id><pub-id pub-id-type="pmid">36034214</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beltman</surname><given-names>JB</given-names></name><name><surname>Marée</surname><given-names>AFM</given-names></name><name><surname>de Boer</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Analysing immune cell migration</article-title><source>Nature Reviews. Immunology</source><volume>9</volume><fpage>789</fpage><lpage>798</lpage><pub-id pub-id-type="doi">10.1038/nri2638</pub-id><pub-id pub-id-type="pmid">19834485</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bumstead</surname><given-names>JR</given-names></name><name><surname>Park</surname><given-names>JJ</given-names></name><name><surname>Rosen</surname><given-names>IA</given-names></name><name><surname>Kraft</surname><given-names>AW</given-names></name><name><surname>Wright</surname><given-names>PW</given-names></name><name><surname>Reisman</surname><given-names>MD</given-names></name><name><surname>Côté</surname><given-names>DC</given-names></name><name><surname>Culver</surname><given-names>JP</given-names></name><name><surname>Bumstead</surname><given-names>JR</given-names></name><name><surname>Park</surname><given-names>JJ</given-names></name><name><surname>Rosen</surname><given-names>IA</given-names></name><name><surname>Kraft</surname><given-names>AW</given-names></name><name><surname>Wright</surname><given-names>PW</given-names></name><name><surname>Reisman</surname><given-names>D</given-names></name><name><surname>Côté</surname><given-names>DC</given-names></name><name><surname>Culver</surname><given-names>JP</given-names></name><name><surname>Reisman</surname><given-names>MD</given-names></name><name><surname>Côté</surname><given-names>DC</given-names></name><name><surname>Culver</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Designing a large field-of-view two photon microscope using optical invariant analysis</article-title><source>Neurophotonics</source><volume>5</volume><elocation-id>025001</elocation-id><pub-id pub-id-type="doi">10.1364/TRANSLATIONAL.2018.JTh3A.60</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burridge</surname><given-names>PW</given-names></name><name><surname>Matsa</surname><given-names>E</given-names></name><name><surname>Shukla</surname><given-names>P</given-names></name><name><surname>Lin</surname><given-names>ZC</given-names></name><name><surname>Churko</surname><given-names>JM</given-names></name><name><surname>Ebert</surname><given-names>AD</given-names></name><name><surname>Lan</surname><given-names>F</given-names></name><name><surname>Diecke</surname><given-names>S</given-names></name><name><surname>Huber</surname><given-names>B</given-names></name><name><surname>Mordwinkin</surname><given-names>NM</given-names></name><name><surname>Plews</surname><given-names>JR</given-names></name><name><surname>Abilez</surname><given-names>OJ</given-names></name><name><surname>Cui</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JD</given-names></name><name><surname>Wu</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Chemically defined generation of human cardiomyocytes</article-title><source>Nature Methods</source><volume>11</volume><fpage>855</fpage><lpage>860</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2999</pub-id><pub-id pub-id-type="pmid">24930130</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dani</surname><given-names>N</given-names></name><name><surname>Herbst</surname><given-names>RH</given-names></name><name><surname>McCabe</surname><given-names>C</given-names></name><name><surname>Green</surname><given-names>GS</given-names></name><name><surname>Kaiser</surname><given-names>K</given-names></name><name><surname>Head</surname><given-names>JP</given-names></name><name><surname>Cui</surname><given-names>J</given-names></name><name><surname>Shipley</surname><given-names>FB</given-names></name><name><surname>Jang</surname><given-names>A</given-names></name><name><surname>Dionne</surname><given-names>D</given-names></name><name><surname>Nguyen</surname><given-names>L</given-names></name><name><surname>Rodman</surname><given-names>C</given-names></name><name><surname>Riesenfeld</surname><given-names>SJ</given-names></name><name><surname>Prochazka</surname><given-names>J</given-names></name><name><surname>Prochazkova</surname><given-names>M</given-names></name><name><surname>Sedlacek</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>Bryja</surname><given-names>V</given-names></name><name><surname>Rozenblatt-Rosen</surname><given-names>O</given-names></name><name><surname>Habib</surname><given-names>N</given-names></name><name><surname>Regev</surname><given-names>A</given-names></name><name><surname>Lehtinen</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A cellular and spatial map of the choroid plexus across brain ventricles and ages</article-title><source>Cell</source><volume>184</volume><fpage>3056</fpage><lpage>3074</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2021.04.003</pub-id><pub-id pub-id-type="pmid">33932339</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demas</surname><given-names>J</given-names></name><name><surname>Manley</surname><given-names>J</given-names></name><name><surname>Tejera</surname><given-names>F</given-names></name><name><surname>Barber</surname><given-names>K</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Traub</surname><given-names>FM</given-names></name><name><surname>Chen</surname><given-names>B</given-names></name><name><surname>Vaziri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>High-speed, cortex-wide volumetric recording of neuroactivity at cellular resolution using light beads microscopy</article-title><source>Nature Methods</source><volume>18</volume><fpage>1103</fpage><lpage>1111</lpage><pub-id pub-id-type="doi">10.1038/s41592-021-01239-8</pub-id><pub-id pub-id-type="pmid">34462592</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dominguez</surname><given-names>MH</given-names></name><name><surname>Krup</surname><given-names>AL</given-names></name><name><surname>Muncie</surname><given-names>JM</given-names></name><name><surname>Bruneau</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Graded mesoderm assembly governs cell fate and morphogenesis of the early mammalian heart</article-title><source>Cell</source><volume>186</volume><fpage>479</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2023.01.001</pub-id><pub-id pub-id-type="pmid">36736300</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>J</given-names></name><name><surname>Suo</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>J</given-names></name><name><surname>Xie</surname><given-names>H</given-names></name><name><surname>Shen</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>F</given-names></name><name><surname>Wang</surname><given-names>G</given-names></name><name><surname>Cao</surname><given-names>L</given-names></name><name><surname>Jin</surname><given-names>G</given-names></name><name><surname>He</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Luan</surname><given-names>G</given-names></name><name><surname>Kong</surname><given-names>L</given-names></name><name><surname>Zheng</surname><given-names>Z</given-names></name><name><surname>Dai</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Video-rate imaging of biological dynamics at centimetre scale and micrometre resolution</article-title><source>Nature Photonics</source><volume>13</volume><fpage>809</fpage><lpage>816</lpage><pub-id pub-id-type="doi">10.1038/s41566-019-0474-7</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Getreuer</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A survey of gaussian convolution algorithms</article-title><source>Image Processing On Line</source><volume>3</volume><fpage>286</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.5201/ipol.2013.87</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gross</surname><given-names>H</given-names></name><name><surname>Blechinger</surname><given-names>F</given-names></name><name><surname>Achtner</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Handbook of Optical Systems, Volume 4: Survey of Optical Instruments</source><publisher-loc>Weinheim</publisher-loc><publisher-name>Wiley-VCH</publisher-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hainmueller</surname><given-names>T</given-names></name><name><surname>Bartos</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Dentate gyrus circuits for encoding, retrieval and discrimination of episodic memories</article-title><source>Nature Reviews. Neuroscience</source><volume>21</volume><fpage>153</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0260-z</pub-id><pub-id pub-id-type="pmid">32042144</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halpern</surname><given-names>AR</given-names></name><name><surname>Lee</surname><given-names>MY</given-names></name><name><surname>Howard</surname><given-names>MD</given-names></name><name><surname>Woodworth</surname><given-names>MA</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>Vaughan</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Versatile, do-it-yourself, low-cost spinning disk confocal microscope</article-title><source>Biomedical Optics Express</source><volume>13</volume><fpage>1102</fpage><lpage>1120</lpage><pub-id pub-id-type="doi">10.1364/BOE.442087</pub-id><pub-id pub-id-type="pmid">35284165</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamburger</surname><given-names>V</given-names></name><name><surname>Hamilton</surname><given-names>HL</given-names></name></person-group><year iso-8601-date="1951">1951</year><article-title>A series of normal stages in the development of the chick embryo</article-title><source>Journal of Morphology</source><volume>88</volume><fpage>49</fpage><lpage>92</lpage><pub-id pub-id-type="pmid">24539719</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herculano-Houzel</surname><given-names>S</given-names></name><name><surname>Lent</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Isotropic fractionator: a simple, rapid method for the quantification of total cell and neuron numbers in the brain</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>2518</fpage><lpage>2521</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4526-04.2005</pub-id><pub-id pub-id-type="pmid">15758160</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hof</surname><given-names>L</given-names></name><name><surname>Moreth</surname><given-names>T</given-names></name><name><surname>Koch</surname><given-names>M</given-names></name><name><surname>Liebisch</surname><given-names>T</given-names></name><name><surname>Kurtz</surname><given-names>M</given-names></name><name><surname>Tarnick</surname><given-names>J</given-names></name><name><surname>Lissek</surname><given-names>SM</given-names></name><name><surname>Verstegen</surname><given-names>MMA</given-names></name><name><surname>van der Laan</surname><given-names>LJW</given-names></name><name><surname>Huch</surname><given-names>M</given-names></name><name><surname>Matthäus</surname><given-names>F</given-names></name><name><surname>Stelzer</surname><given-names>EHK</given-names></name><name><surname>Pampaloni</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Long-term live imaging and multiscale analysis identify heterogeneity and core principles of epithelial organoid morphogenesis</article-title><source>BMC Biology</source><volume>19</volume><elocation-id>37</elocation-id><pub-id pub-id-type="doi">10.1186/s12915-021-00958-w</pub-id><pub-id pub-id-type="pmid">33627108</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hofbauer</surname><given-names>P</given-names></name><name><surname>Jahnel</surname><given-names>SM</given-names></name><name><surname>Papai</surname><given-names>N</given-names></name><name><surname>Giesshammer</surname><given-names>M</given-names></name><name><surname>Deyett</surname><given-names>A</given-names></name><name><surname>Schmidt</surname><given-names>C</given-names></name><name><surname>Penc</surname><given-names>M</given-names></name><name><surname>Tavernini</surname><given-names>K</given-names></name><name><surname>Grdseloff</surname><given-names>N</given-names></name><name><surname>Meledeth</surname><given-names>C</given-names></name><name><surname>Ginistrelli</surname><given-names>LC</given-names></name><name><surname>Ctortecka</surname><given-names>C</given-names></name><name><surname>Šalic</surname><given-names>Š</given-names></name><name><surname>Novatchkova</surname><given-names>M</given-names></name><name><surname>Mendjan</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cardioids reveal self-organizing principles of human cardiogenesis</article-title><source>Cell</source><volume>184</volume><fpage>3299</fpage><lpage>3317</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2021.04.034</pub-id><pub-id pub-id-type="pmid">34019794</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hyvaerinen</surname><given-names>A</given-names></name><name><surname>Karhunen</surname><given-names>J</given-names></name><name><surname>Oja</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Independent Component Analysis</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley-Interscience</publisher-name></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ichihara</surname><given-names>A</given-names></name><name><surname>Tanaami</surname><given-names>T</given-names></name><name><surname>Isozaki</surname><given-names>K</given-names></name><name><surname>Sugiyama</surname><given-names>Y</given-names></name><name><surname>Kosugi</surname><given-names>Y</given-names></name><name><surname>Mikuriya</surname><given-names>K</given-names></name><name><surname>Abe</surname><given-names>M</given-names></name><name><surname>Uemura</surname><given-names>I</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>High-speed confocal fluorescence microscopy using a Nipkow scanner with microlenses for 3D-imaging of single fluorescent molecule in real time</article-title><source>Bioimaging</source><volume>4</volume><fpage>52</fpage><lpage>62</lpage></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ichimura</surname><given-names>T</given-names></name><name><surname>Kakizuka</surname><given-names>T</given-names></name><name><surname>Horikawa</surname><given-names>K</given-names></name><name><surname>Seiriki</surname><given-names>K</given-names></name><name><surname>Kasai</surname><given-names>A</given-names></name><name><surname>Hashimoto</surname><given-names>H</given-names></name><name><surname>Fujita</surname><given-names>K</given-names></name><name><surname>Watanabe</surname><given-names>TM</given-names></name><name><surname>Nagai</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Exploring rare cellular activity in more than one million cells by a transscale scope</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>16539</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-95930-7</pub-id><pub-id pub-id-type="pmid">34400683</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishihara</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A confocal surface measurement system having improved measurement accuracy for rough surfaces and measurement speed</article-title><source>Journal of Robotics and Mechatronics</source><volume>15</volume><fpage>331</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.20965/jrm.2003.p0331</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kakizuka</surname><given-names>T</given-names></name><name><surname>Nakaoka</surname><given-names>H</given-names></name><name><surname>Hara</surname><given-names>Y</given-names></name><name><surname>Ichiraku</surname><given-names>A</given-names></name><name><surname>Arai</surname><given-names>Y</given-names></name><name><surname>Itoga</surname><given-names>H</given-names></name><name><surname>Onami</surname><given-names>S</given-names></name><name><surname>Ichimura</surname><given-names>T</given-names></name><name><surname>Nagai</surname><given-names>T</given-names></name><name><surname>Horikawa</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Mesoscale heterogeneity is a critical determinant for spiral pattern formation in developing social amoeba</article-title><source>Scientific Reports</source><volume>15</volume><elocation-id>1422</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-025-85759-9</pub-id><pub-id pub-id-type="pmid">39789232</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kino</surname><given-names>GS</given-names></name><name><surname>Corle</surname><given-names>TR</given-names></name></person-group><year iso-8601-date="1996">1996</year><source>Confocal Scanning Optical Microscopy and Related Imaging Systems 1st Edition</source><publisher-loc>Cambridge, MA</publisher-loc><publisher-name>Academic Press</publisher-name><pub-id pub-id-type="doi">10.1016/B978-012408750-7/50009-4</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>HC</given-names></name><name><surname>Yang</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Computational removal ofbackground fluorescence for biological fluorescence microscopy</article-title><conf-name>IEEE 11th International Symposium on Biomedical Imaging (ISBI 2014)</conf-name><conf-loc>Beijing, China</conf-loc><pub-id pub-id-type="doi">10.1109/ISBI.2014.6867845</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis-Israeli</surname><given-names>YR</given-names></name><name><surname>Wasserman</surname><given-names>AH</given-names></name><name><surname>Gabalski</surname><given-names>MA</given-names></name><name><surname>Volmert</surname><given-names>BD</given-names></name><name><surname>Ming</surname><given-names>Y</given-names></name><name><surname>Ball</surname><given-names>KA</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name><name><surname>Zou</surname><given-names>J</given-names></name><name><surname>Ni</surname><given-names>G</given-names></name><name><surname>Pajares</surname><given-names>N</given-names></name><name><surname>Chatzistavrou</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Zhou</surname><given-names>C</given-names></name><name><surname>Aguirre</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Self-assembling human heart organoids for the modeling of cardiac development and congenital heart disease</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>5142</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-25329-5</pub-id><pub-id pub-id-type="pmid">34446706</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohmann</surname><given-names>AW</given-names></name><name><surname>Dorsch</surname><given-names>RG</given-names></name><name><surname>Mendlovic</surname><given-names>D</given-names></name><name><surname>Ferreira</surname><given-names>C</given-names></name><name><surname>Zalevsky</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Space–bandwidth product of optical signals and systems</article-title><source>Journal of the Optical Society of America A</source><volume>13</volume><elocation-id>470</elocation-id><pub-id pub-id-type="doi">10.1364/JOSAA.13.000470</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Loskill</surname><given-names>P</given-names></name><name><surname>Huebsch</surname><given-names>N</given-names></name><name><surname>Koo</surname><given-names>S</given-names></name><name><surname>Svedlund</surname><given-names>FL</given-names></name><name><surname>Marks</surname><given-names>NC</given-names></name><name><surname>Hua</surname><given-names>EW</given-names></name><name><surname>Grigoropoulos</surname><given-names>CP</given-names></name><name><surname>Conklin</surname><given-names>BR</given-names></name><name><surname>Healy</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Self-organizing human cardiac microchambers mediated by geometric confinement</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>7413</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms8413</pub-id><pub-id pub-id-type="pmid">26172574</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mateos-Pérez</surname><given-names>JM</given-names></name><name><surname>Redondo</surname><given-names>R</given-names></name><name><surname>Nava</surname><given-names>R</given-names></name><name><surname>Valdiviezo</surname><given-names>JC</given-names></name><name><surname>Cristóbal</surname><given-names>G</given-names></name><name><surname>Escalante-Ramírez</surname><given-names>B</given-names></name><name><surname>Ruiz-Serrano</surname><given-names>MJ</given-names></name><name><surname>Pascau</surname><given-names>J</given-names></name><name><surname>Desco</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Comparative evaluation of autofocus algorithms for a real-time system for automatic detection of <italic>Mycobacterium tuberculosis</italic></article-title><source>Cytometry. Part A</source><volume>81</volume><fpage>213</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1002/cyto.a.22020</pub-id><pub-id pub-id-type="pmid">22290716</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McConnell</surname><given-names>G</given-names></name><name><surname>Trägårdh</surname><given-names>J</given-names></name><name><surname>Amor</surname><given-names>R</given-names></name><name><surname>Dempster</surname><given-names>J</given-names></name><name><surname>Reid</surname><given-names>E</given-names></name><name><surname>Amos</surname><given-names>WB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A novel optical microscope for imaging large embryos and tissue volumes with sub-cellular resolution throughout</article-title><source>eLife</source><volume>5</volume><elocation-id>e18659</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18659</pub-id><pub-id pub-id-type="pmid">27661778</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDole</surname><given-names>K</given-names></name><name><surname>Guignard</surname><given-names>L</given-names></name><name><surname>Amat</surname><given-names>F</given-names></name><name><surname>Berger</surname><given-names>A</given-names></name><name><surname>Malandain</surname><given-names>G</given-names></name><name><surname>Royer</surname><given-names>LA</given-names></name><name><surname>Turaga</surname><given-names>SC</given-names></name><name><surname>Branson</surname><given-names>K</given-names></name><name><surname>Keller</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>In toto imaging and reconstruction of post-implantation mouse development at the single-cell level</article-title><source>Cell</source><volume>175</volume><fpage>859</fpage><lpage>876</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.09.031</pub-id><pub-id pub-id-type="pmid">30318151</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meijering</surname><given-names>E</given-names></name><name><surname>Dzyubachyk</surname><given-names>O</given-names></name><name><surname>Smal</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Methods for cell and particle tracking</article-title><source>Elsevier Inc</source><volume>504</volume><fpage>183</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-391857-4.00009-4</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moen</surname><given-names>E</given-names></name><name><surname>Bannon</surname><given-names>D</given-names></name><name><surname>Kudo</surname><given-names>T</given-names></name><name><surname>Graf</surname><given-names>W</given-names></name><name><surname>Covert</surname><given-names>M</given-names></name><name><surname>Van Valen</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Deep learning for cellular image analysis</article-title><source>Nature Methods</source><volume>16</volume><fpage>1233</fpage><lpage>1246</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0403-1</pub-id><pub-id pub-id-type="pmid">31133758</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakagawa</surname><given-names>M</given-names></name><name><surname>Taniguchi</surname><given-names>Y</given-names></name><name><surname>Senda</surname><given-names>S</given-names></name><name><surname>Takizawa</surname><given-names>N</given-names></name><name><surname>Ichisaka</surname><given-names>T</given-names></name><name><surname>Asano</surname><given-names>K</given-names></name><name><surname>Morizane</surname><given-names>A</given-names></name><name><surname>Doi</surname><given-names>D</given-names></name><name><surname>Takahashi</surname><given-names>J</given-names></name><name><surname>Nishizawa</surname><given-names>M</given-names></name><name><surname>Yoshida</surname><given-names>Y</given-names></name><name><surname>Toyoda</surname><given-names>T</given-names></name><name><surname>Osafune</surname><given-names>K</given-names></name><name><surname>Sekiguchi</surname><given-names>K</given-names></name><name><surname>Yamanaka</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A novel efficient feeder-free culture system for the derivation of human induced pluripotent stem cells</article-title><source>Scientific Reports</source><volume>4</volume><elocation-id>3594</elocation-id><pub-id pub-id-type="doi">10.1038/srep03594</pub-id><pub-id pub-id-type="pmid">24399248</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nöbauer</surname><given-names>T</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Vaziri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Mesoscale volumetric light-field (MesoLF) imaging of neuroactivity across cortical areas at 18 Hz</article-title><source>Nature Methods</source><volume>20</volume><fpage>600</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1038/s41592-023-01789-z</pub-id><pub-id pub-id-type="pmid">36823333</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ota</surname><given-names>K</given-names></name><name><surname>Oisi</surname><given-names>Y</given-names></name><name><surname>Suzuki</surname><given-names>T</given-names></name><name><surname>Ikeda</surname><given-names>M</given-names></name><name><surname>Ito</surname><given-names>Y</given-names></name><name><surname>Ito</surname><given-names>T</given-names></name><name><surname>Uwamori</surname><given-names>H</given-names></name><name><surname>Kobayashi</surname><given-names>K</given-names></name><name><surname>Kobayashi</surname><given-names>M</given-names></name><name><surname>Odagawa</surname><given-names>M</given-names></name><name><surname>Matsubara</surname><given-names>C</given-names></name><name><surname>Kuroiwa</surname><given-names>Y</given-names></name><name><surname>Horikoshi</surname><given-names>M</given-names></name><name><surname>Matsushita</surname><given-names>J</given-names></name><name><surname>Hioki</surname><given-names>H</given-names></name><name><surname>Ohkura</surname><given-names>M</given-names></name><name><surname>Nakai</surname><given-names>J</given-names></name><name><surname>Oizumi</surname><given-names>M</given-names></name><name><surname>Miyawaki</surname><given-names>A</given-names></name><name><surname>Aonishi</surname><given-names>T</given-names></name><name><surname>Ode</surname><given-names>T</given-names></name><name><surname>Murayama</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Fast, cell-resolution, contiguous-wide two-photon imaging to reveal functional network architectures across multi-modal cortical areas</article-title><source>Neuron</source><volume>109</volume><fpage>1810</fpage><lpage>1824</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.03.032</pub-id><pub-id pub-id-type="pmid">33878295</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papagiakoumou</surname><given-names>E</given-names></name><name><surname>Ronzitti</surname><given-names>E</given-names></name><name><surname>Emiliani</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Scanless two-photon excitation with temporal focusing</article-title><source>Nature Methods</source><volume>17</volume><fpage>571</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1038/s41592-020-0795-y</pub-id><pub-id pub-id-type="pmid">32284609</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petráň</surname><given-names>M</given-names></name><name><surname>Hadravský</surname><given-names>M</given-names></name><name><surname>Boyde</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>The tandem scanning reflected light microscope</article-title><source>Scanning</source><volume>7</volume><fpage>97</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1002/sca.4950070205</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pietzsch</surname><given-names>T</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>Tomancak</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>BigDataViewer: visualization and processing for large image data sets</article-title><source>Nature Methods</source><volume>12</volume><fpage>481</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3392</pub-id><pub-id pub-id-type="pmid">26020499</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pietzsch</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Bigdataviewer-server</data-title><version designator="3.0">3.0</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/bigdataviewer/bigdataviewer-server">https://github.com/bigdataviewer/bigdataviewer-server</ext-link></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prevedel</surname><given-names>R</given-names></name><name><surname>Yoon</surname><given-names>YG</given-names></name><name><surname>Hoffmann</surname><given-names>M</given-names></name><name><surname>Pak</surname><given-names>N</given-names></name><name><surname>Wetzstein</surname><given-names>G</given-names></name><name><surname>Kato</surname><given-names>S</given-names></name><name><surname>Schrödel</surname><given-names>T</given-names></name><name><surname>Raskar</surname><given-names>R</given-names></name><name><surname>Zimmer</surname><given-names>M</given-names></name><name><surname>Boyden</surname><given-names>ES</given-names></name><name><surname>Vaziri</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy</article-title><source>Nature Methods</source><volume>11</volume><fpage>727</fpage><lpage>730</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2964</pub-id><pub-id pub-id-type="pmid">24836920</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>A</given-names></name><name><surname>Barkley</surname><given-names>D</given-names></name><name><surname>França</surname><given-names>GS</given-names></name><name><surname>Yanai</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Exploring tissue architecture using spatial transcriptomics</article-title><source>Nature</source><volume>596</volume><fpage>211</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03634-9</pub-id><pub-id pub-id-type="pmid">34381231</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sasai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cytosystems dynamics in self-organization of tissue architecture</article-title><source>Nature</source><volume>493</volume><fpage>318</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1038/nature11859</pub-id><pub-id pub-id-type="pmid">23325214</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>Y</given-names></name><name><surname>Poynter</surname><given-names>G</given-names></name><name><surname>Huss</surname><given-names>D</given-names></name><name><surname>Filla</surname><given-names>MB</given-names></name><name><surname>Czirok</surname><given-names>A</given-names></name><name><surname>Rongish</surname><given-names>BJ</given-names></name><name><surname>Little</surname><given-names>CD</given-names></name><name><surname>Fraser</surname><given-names>SE</given-names></name><name><surname>Lansford</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Dynamic analysis of vascular morphogenesis using transgenic quail embryos</article-title><source>PLOS ONE</source><volume>5</volume><elocation-id>e12674</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0012674</pub-id><pub-id pub-id-type="pmid">20856866</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dorsal aorta formation: Separate origins, lateral‐to‐medial migration, and remodeling</article-title><source>Development, Growth &amp; Differentiation</source><volume>55</volume><fpage>113</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1111/dgd.12010</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname><given-names>Y</given-names></name><name><surname>Lansford</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Transgenesis and imaging in birds, and available transgenic reporter lines</article-title><source>Development, Growth &amp; Differentiation</source><volume>55</volume><fpage>406</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1111/dgd.12058</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schindelin</surname><given-names>J</given-names></name><name><surname>Arganda-Carreras</surname><given-names>I</given-names></name><name><surname>Frise</surname><given-names>E</given-names></name><name><surname>Kaynig</surname><given-names>V</given-names></name><name><surname>Longair</surname><given-names>M</given-names></name><name><surname>Pietzsch</surname><given-names>T</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>Rueden</surname><given-names>C</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Schmid</surname><given-names>B</given-names></name><name><surname>Tinevez</surname><given-names>JY</given-names></name><name><surname>White</surname><given-names>DJ</given-names></name><name><surname>Hartenstein</surname><given-names>V</given-names></name><name><surname>Eliceiri</surname><given-names>K</given-names></name><name><surname>Tomancak</surname><given-names>P</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Fiji: an open-source platform for biological-image analysis</article-title><source>Nature Methods</source><volume>9</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id><pub-id pub-id-type="pmid">22743772</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seiriki</surname><given-names>K</given-names></name><name><surname>Kasai</surname><given-names>A</given-names></name><name><surname>Nakazawa</surname><given-names>T</given-names></name><name><surname>Niu</surname><given-names>M</given-names></name><name><surname>Naka</surname><given-names>Y</given-names></name><name><surname>Tanuma</surname><given-names>M</given-names></name><name><surname>Igarashi</surname><given-names>H</given-names></name><name><surname>Yamaura</surname><given-names>K</given-names></name><name><surname>Hayata-Takano</surname><given-names>A</given-names></name><name><surname>Ago</surname><given-names>Y</given-names></name><name><surname>Hashimoto</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Whole-brain block-face serial microscopy tomography at subcellular resolution using FAST</article-title><source>Nature Protocols</source><volume>14</volume><fpage>1509</fpage><lpage>1529</lpage><pub-id pub-id-type="doi">10.1038/s41596-019-0148-4</pub-id><pub-id pub-id-type="pmid">30962606</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sofroniew</surname><given-names>NJ</given-names></name><name><surname>Flickinger</surname><given-names>D</given-names></name><name><surname>King</surname><given-names>J</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A large field of view two-photon mesoscope with subcellular resolution for in vivo imaging</article-title><source>eLife</source><volume>5</volume><elocation-id>e14472</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.14472</pub-id><pub-id pub-id-type="pmid">27300105</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugawara</surname><given-names>K</given-names></name><name><surname>Çevrim</surname><given-names>Ç</given-names></name><name><surname>Averof</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Tracking cell lineages in 3D by incremental deep learning</article-title><source>eLife</source><volume>11</volume><elocation-id>e69380</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.69380</pub-id><pub-id pub-id-type="pmid">34989675</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Sugawara</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>ELEPHANT</data-title><version designator="Server: v0.5.7i, Client: v0.5.0">Server: v0.5.7i, Client: v0.5.0</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/elephant-track">https://github.com/elephant-track</ext-link></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Susaki</surname><given-names>EA</given-names></name><name><surname>Tainaka</surname><given-names>K</given-names></name><name><surname>Perrin</surname><given-names>D</given-names></name><name><surname>Kishino</surname><given-names>F</given-names></name><name><surname>Tawara</surname><given-names>T</given-names></name><name><surname>Watanabe</surname><given-names>TM</given-names></name><name><surname>Yokoyama</surname><given-names>C</given-names></name><name><surname>Onoe</surname><given-names>H</given-names></name><name><surname>Eguchi</surname><given-names>M</given-names></name><name><surname>Yamaguchi</surname><given-names>S</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Kiyonari</surname><given-names>H</given-names></name><name><surname>Shimizu</surname><given-names>Y</given-names></name><name><surname>Miyawaki</surname><given-names>A</given-names></name><name><surname>Yokota</surname><given-names>H</given-names></name><name><surname>Ueda</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Whole-brain imaging with single-cell resolution using chemical cocktails and computational analysis</article-title><source>Cell</source><volume>157</volume><fpage>726</fpage><lpage>739</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.03.042</pub-id><pub-id pub-id-type="pmid">24746791</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Susaki</surname><given-names>EA</given-names></name><name><surname>Shimizu</surname><given-names>C</given-names></name><name><surname>Kuno</surname><given-names>A</given-names></name><name><surname>Tainaka</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Nishi</surname><given-names>K</given-names></name><name><surname>Morishima</surname><given-names>K</given-names></name><name><surname>Ono</surname><given-names>H</given-names></name><name><surname>Ode</surname><given-names>KL</given-names></name><name><surname>Saeki</surname><given-names>Y</given-names></name><name><surname>Miyamichi</surname><given-names>K</given-names></name><name><surname>Isa</surname><given-names>K</given-names></name><name><surname>Yokoyama</surname><given-names>C</given-names></name><name><surname>Kitaura</surname><given-names>H</given-names></name><name><surname>Ikemura</surname><given-names>M</given-names></name><name><surname>Ushiku</surname><given-names>T</given-names></name><name><surname>Shimizu</surname><given-names>Y</given-names></name><name><surname>Saito</surname><given-names>T</given-names></name><name><surname>Saido</surname><given-names>TC</given-names></name><name><surname>Fukayama</surname><given-names>M</given-names></name><name><surname>Onoe</surname><given-names>H</given-names></name><name><surname>Touhara</surname><given-names>K</given-names></name><name><surname>Isa</surname><given-names>T</given-names></name><name><surname>Kakita</surname><given-names>A</given-names></name><name><surname>Shibayama</surname><given-names>M</given-names></name><name><surname>Ueda</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Versatile whole-organ/body staining and imaging based on electrolyte-gel properties of biological tissues</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>1982</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15906-5</pub-id><pub-id pub-id-type="pmid">32341345</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tainaka</surname><given-names>K</given-names></name><name><surname>Murakami</surname><given-names>TC</given-names></name><name><surname>Susaki</surname><given-names>EA</given-names></name><name><surname>Shimizu</surname><given-names>C</given-names></name><name><surname>Saito</surname><given-names>R</given-names></name><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Hayashi-Takagi</surname><given-names>A</given-names></name><name><surname>Sekiya</surname><given-names>H</given-names></name><name><surname>Arima</surname><given-names>Y</given-names></name><name><surname>Nojima</surname><given-names>S</given-names></name><name><surname>Ikemura</surname><given-names>M</given-names></name><name><surname>Ushiku</surname><given-names>T</given-names></name><name><surname>Shimizu</surname><given-names>Y</given-names></name><name><surname>Murakami</surname><given-names>M</given-names></name><name><surname>Tanaka</surname><given-names>KF</given-names></name><name><surname>Iino</surname><given-names>M</given-names></name><name><surname>Kasai</surname><given-names>H</given-names></name><name><surname>Sasaoka</surname><given-names>T</given-names></name><name><surname>Kobayashi</surname><given-names>K</given-names></name><name><surname>Miyazono</surname><given-names>K</given-names></name><name><surname>Morii</surname><given-names>E</given-names></name><name><surname>Isa</surname><given-names>T</given-names></name><name><surname>Fukayama</surname><given-names>M</given-names></name><name><surname>Kakita</surname><given-names>A</given-names></name><name><surname>Ueda</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Chemical landscape for tissue clearing based on hydrophilic reagents</article-title><source>Cell Reports</source><volume>24</volume><fpage>2196</fpage><lpage>2210</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.07.056</pub-id><pub-id pub-id-type="pmid">30134179</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Tanabe</surname><given-names>K</given-names></name><name><surname>Ohnuki</surname><given-names>M</given-names></name><name><surname>Narita</surname><given-names>M</given-names></name><name><surname>Ichisaka</surname><given-names>T</given-names></name><name><surname>Tomoda</surname><given-names>K</given-names></name><name><surname>Yamanaka</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Induction of pluripotent stem cells from adult human fibroblasts by defined factors</article-title><source>Cell</source><volume>131</volume><fpage>861</fpage><lpage>872</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2007.11.019</pub-id><pub-id pub-id-type="pmid">18035408</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takanezawa</surname><given-names>S</given-names></name><name><surname>Saitou</surname><given-names>T</given-names></name><name><surname>Imamura</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Wide field light-sheet microscopy with lens-axicon controlled two-photon Bessel beam illumination</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>2979</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-23249-y</pub-id><pub-id pub-id-type="pmid">34016994</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Tinevez</surname><given-names>JY</given-names></name><name><surname>Pietzsch</surname><given-names>T</given-names></name><name><surname>Hahmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Mastodon</data-title><version designator="BSD-2-Clause">BSD-2-Clause</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/mastodon-sc/mastodon">https://github.com/mastodon-sc/mastodon</ext-link></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ueda</surname><given-names>HR</given-names></name><name><surname>Dodt</surname><given-names>HU</given-names></name><name><surname>Osten</surname><given-names>P</given-names></name><name><surname>Economo</surname><given-names>MN</given-names></name><name><surname>Chandrashekar</surname><given-names>J</given-names></name><name><surname>Keller</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Whole-brain profiling of cells and circuits in mammals by tissue clearing and light-sheet microscopy</article-title><source>Neuron</source><volume>106</volume><fpage>369</fpage><lpage>387</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.03.004</pub-id><pub-id pub-id-type="pmid">32380050</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voigt</surname><given-names>FF</given-names></name><name><surname>Kirschenbaum</surname><given-names>D</given-names></name><name><surname>Platonova</surname><given-names>E</given-names></name><name><surname>Pagès</surname><given-names>S</given-names></name><name><surname>Campbell</surname><given-names>RAA</given-names></name><name><surname>Kastli</surname><given-names>R</given-names></name><name><surname>Schaettin</surname><given-names>M</given-names></name><name><surname>Egolf</surname><given-names>L</given-names></name><name><surname>van der Bourg</surname><given-names>A</given-names></name><name><surname>Bethge</surname><given-names>P</given-names></name><name><surname>Haenraets</surname><given-names>K</given-names></name><name><surname>Frézel</surname><given-names>N</given-names></name><name><surname>Topilko</surname><given-names>T</given-names></name><name><surname>Perin</surname><given-names>P</given-names></name><name><surname>Hillier</surname><given-names>D</given-names></name><name><surname>Hildebrand</surname><given-names>S</given-names></name><name><surname>Schueth</surname><given-names>A</given-names></name><name><surname>Roebroeck</surname><given-names>A</given-names></name><name><surname>Roska</surname><given-names>B</given-names></name><name><surname>Stoeckli</surname><given-names>ET</given-names></name><name><surname>Pizzala</surname><given-names>R</given-names></name><name><surname>Renier</surname><given-names>N</given-names></name><name><surname>Zeilhofer</surname><given-names>HU</given-names></name><name><surname>Karayannis</surname><given-names>T</given-names></name><name><surname>Ziegler</surname><given-names>U</given-names></name><name><surname>Batti</surname><given-names>L</given-names></name><name><surname>Holtmaat</surname><given-names>A</given-names></name><name><surname>Lüscher</surname><given-names>C</given-names></name><name><surname>Aguzzi</surname><given-names>A</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The mesoSPIM initiative: open-source light-sheet microscopes for imaging cleared tissue</article-title><source>Nature Methods</source><volume>16</volume><fpage>1105</fpage><lpage>1108</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0554-0</pub-id><pub-id pub-id-type="pmid">31527839</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Walter</surname><given-names>K</given-names></name><name><surname>Ziesche</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Apparatus and Method, Particularly for Microscopes and Endoscopes, Using Baseline Estimation and Half-Quadratic Minimization for the Deblurring of Images, WO 2019/185174 A1</source><publisher-name>European Patent Office</publisher-name></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>C</given-names></name><name><surname>Miura</surname><given-names>T</given-names></name><name><surname>Voleti</surname><given-names>V</given-names></name><name><surname>Yamaguchi</surname><given-names>K</given-names></name><name><surname>Tsutsumi</surname><given-names>M</given-names></name><name><surname>Yamamoto</surname><given-names>K</given-names></name><name><surname>Otomo</surname><given-names>K</given-names></name><name><surname>Fujie</surname><given-names>Y</given-names></name><name><surname>Teramoto</surname><given-names>T</given-names></name><name><surname>Ishihara</surname><given-names>T</given-names></name><name><surname>Aoki</surname><given-names>K</given-names></name><name><surname>Nemoto</surname><given-names>T</given-names></name><name><surname>Hillman</surname><given-names>EM</given-names></name><name><surname>Kimura</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>3DeeCellTracker, a deep learning-based pipeline for segmenting and tracking cells in 3D time lapse images</article-title><source>eLife</source><volume>10</volume><elocation-id>e59187</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.59187</pub-id><pub-id pub-id-type="pmid">33781383</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Resolution and optical sectioning in the confocal microscope</article-title><source>Journal of Microscopy</source><volume>244</volume><fpage>113</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1111/j.1365-2818.2011.03549.x</pub-id><pub-id pub-id-type="pmid">22004276</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>GQ</given-names></name><name><surname>Corle</surname><given-names>TR</given-names></name><name><surname>Kino</surname><given-names>GS</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Real-time confocal scanning optical microscope</article-title><source>Applied Physics Letters</source><volume>53</volume><fpage>716</fpage><lpage>718</lpage><pub-id pub-id-type="doi">10.1063/1.99814</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>CH</given-names></name><name><surname>Stirman</surname><given-names>JN</given-names></name><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Hira</surname><given-names>R</given-names></name><name><surname>Smith</surname><given-names>SL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Diesel2p mesoscope with dual independent scan engines for flexible capture of dynamics in distributed neural circuitry</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>6639</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26736-4</pub-id><pub-id pub-id-type="pmid">34789723</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Note 1. Discussion on the confocal imaging system: Optical configuration, pinhole size and spatial resolution</title><p>This section describes the details of the confocal system configuration and the setting of the pinhole size. AMATERAS in this paper is designed for fluorescence imaging in the visible wavelength region. Currently, the system is a single-channel observation system using excitation light at 470–490 nm and observing fluorescence in 510–540 nm region, which is primarily targeted at green-to-yellow fluorescent proteins such as EGFP (emission peak: 507 nm) and EYFP (emission peak: 527 nm). As the next step, we are planning to develop a two-channel observation system, which will also be capable of observing red fluorescent proteins, such as mRFP (emission peak: 607 nm) and mCherry (emission peak: 610 nm).</p><sec sec-type="appendix" id="s8-1"><title>Excitation system</title><p>The point spread function (PSF) of a confocal microscope is expressed by multiplying the distribution of the focused spot of the excitation light by the PSF of the imaging system of fluorescence. In the excitation system, the pinhole is illuminated by the LED light (center wavelength: 470 nm), and the light is diffracted by the pinhole, causing the light to spread at the tube lens side (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). The diffracted light is collected and collimated by the tube lens and focused into the sample by the objective lens. The diffraction of light through a circular aperture is expressed by a well-known formula involving the Bessel function,<disp-formula id="equ5"> <label>(A1)</label><mml:math id="m5"><mml:mi>U</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>∝</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>k</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <italic>J</italic><sub>1</sub>(<italic>u</italic>), <italic>k</italic>, <italic>a</italic>, <italic>θ</italic> denote the Bessel function of the first kind with the order of 1, wavenumber, aperture radius, and diffraction angle, respectively. The angular dependence of intensity can be obtained by taking a square of <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>; <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>. The pinhole size in the current setup is 6 µm, at which the diffraction pattern has the first dark ring at about 0.1 radian (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). Since our tube lens has an NA of 0.125, the diffracted light does not fill the entire NA of the lens, and as a result, the effective NA of the focused light into the sample is lower than 0.25 (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). This differs from a typical, laser-based, single-focus scanning confocal microscope. On the other hand, the current configuration is an appropriate choice in terms of light efficiency since most of the diffracted light enters within the NA of the tube lens.</p></sec><sec sec-type="appendix" id="s8-2"><title>Fluorescence imaging system</title><p>As for the fluorescence imaging system (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1C</xref>), fluorescence light emitted from fluorescent molecules in the sample is collected by the objective lens with 0.25 NA. Since the fluorescence is emitted isotropically, it fills the entire object-side NA and is focused onto the pinhole by the tube lens with 0.125 NA. If the pinhole diameter is small enough (mathematically represented by the delta function), the focal light field spot focused by the objective lens at the fluorescence wavelength can be considered to correspond to the PSF of the imaging system. <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1D</xref> shows the ideal PSF. This PSF was obtained by numerical calculation of the scalar wave integration.</p></sec><sec sec-type="appendix" id="s8-3"><title>Selection of the pinhole diameter</title><p>Here, the selection of the pinhole size (diameter) for our optical system is discussed. The pinhole diameter of a confocal microscope is usually set based on the Airy disk diameter of the spot of fluorescence focused on the pinhole. In general-purpose instruments, the pinhole diameter is set to about the Airy disk diameter, but when high spatial resolution is required, it is set to a value smaller than the disk, <italic>e.g</italic>., half the diameter of Airy disk. At the green wavelength region (<italic>e.g</italic>., EGFP, EYFP) and the red wavelength region (<italic>e.g</italic>., mRFP, mCherry), which are currently considered as targets for AMATERAS observation, the Airy disk diameters of the spots focused by our tube lenses (NA = 0.125) are about 5 µm (EGFP: 4.95 µm, EYFP: 5.14 µm) and 6 µm (mRFP: 5.92 µm, mCherry: 5.95 µm), respectively, where we used the following equation for the Airy disk diameter, where <italic>λ</italic> denotes the wavelength.<disp-formula id="equ6"> <label>(A2)</label><mml:math id="m6"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>i</mml:mi><mml:mi>r</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1.22</mml:mn><mml:mfrac><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>The design of the pinhole diameter was considered for both of these systems, excitation and fluorescence imaging. In our optical system, the transmittance of the pinhole disk is low, so it is not desirable to make it smaller than the Airy disk to further reduce its efficiency. On the other hand, if the pinhole is made too much larger than the Airy disk, it is meaningless because it will not provide 3D resolution. Considering that it can be used in both of the two wavelength ranges, we decided on a pinhole size of 6 µm, which is comparable to the Airy disk diameter in the red wavelength range.</p></sec><sec sec-type="appendix" id="s8-4"><title>Theoretical and actual resolution in the longitudinal direction</title><p>The theoretical resolution (FWHM) in the <italic>z</italic>-direction in the ideal confocal fluorescence microscope optical system (excitation light is focused to the diffraction limit and detected by a detector of infinitesimal size) is approximately expressed by the following equation with NA, the wavelength of excitation light (<italic>λ<sub>ex</sub></italic>) and refractive index of immersion medium (<italic>n</italic>).<disp-formula id="equ7"> <label>(A3)</label><mml:math id="m7"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.64</mml:mn><mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msqrt><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>The value of Δ<italic>z<sub>cf</sub></italic> for NA = 0.25, <italic>λ<sub>ex</sub></italic>ex 470, and n=1 is 9.5 µm, which is considered the best possible resolution that can be achieved with our lens system. As mentioned above, the focusing NA of the excitation light is smaller than the NA of the objective lens, and the pinhole size is slightly larger than the Airy disk. These factors limit the resolution to more than 13 µm at present (<xref ref-type="fig" rid="fig3">Figure 3D–E</xref>). The challenge for the future is to resolve these issues and approach the ideal resolution.</p></sec><sec sec-type="appendix" id="s8-5"><title>Theoretical and actual resolution in the transverse direction</title><p>The theoretical spatial resolution (FWHM) in the transverse direction in the ideal confocal fluorescence microscope system is approximately expressed by the following equation.<disp-formula id="equ8"> <label>(A4)</label><mml:math id="m8"><mml:mo>∆</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.37</mml:mn><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>The value of Δ<italic>x<sub>cf</sub></italic> for NA = 0.25 and <italic>λ<sub>ex</sub></italic>ex 470 is 0.70 µm. However, the experimental value (<xref ref-type="fig" rid="fig3">Figure 3D–E</xref>) is significantly larger than this theoretical value. Similar to the above discussion on the resolution in the <italic>z</italic>-direction, this is attributed to the fact that our imaging system is far from the ideal system. In addition, the resolution in the transverse direction is also influenced by the secondary relay-lens system that transfers the fluorescence light component passing through the pinhole to the image sensor with magnification of 1×or 2× (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Since the NA of the 1×relay lens (0.079) is significantly smaller than that of the tube lens (0.125), large NA component (&gt;0.079) is lost at the edge of the entrance aperture of the relay lens. The effective NA for the fluorescence imaging is 0.158 at the sample space, which is the NA of the relay lens multiplied by the magnification factor (2×). This is the reason why the spatial resolution of AMATERAS-2c in the transverse direction (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) is downgraded from the wide-field imaging system (AMATERAS-2w) (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) as well as from the ideal confocal imaging system. The transverse resolution (FWHM) of the theoretical PSF for wide-field fluorescence imaging is expressed by the following equation with NA and emission wavelength (<italic>λ<sub>em</sub></italic>).<disp-formula id="equ9"> <label>(A5)</label><mml:math id="m9"><mml:mo>∆</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.51</mml:mn><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>The values of Δ<italic>x<sub>wf</sub></italic> for NA = 0.25 and 0.158 are 1.05 µm and 1.66 µm (<italic>λ<sub>em</sub></italic>em 515 nm), respectively. This difference explains the degradation of the resultant transverse resolution.</p><p>In the case when the 2×relay lens is used, on the other hand, its NA (0.12) is only slightly smaller than that of the tube lens (0.125). The degradation of the transverse resolution is well mitigated compared to the 1×relay lens (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p></sec></sec><sec sec-type="appendix" id="s9"><title>Note 2. Discussion on the computational sectioning: Parameter adjustment and limitation</title><sec sec-type="appendix" id="s9-1"><title>Basic concept</title><p>In the optimization of the cutoff frequency of the baseline estimation, we applied the concept of independent component analysis (ICA). As similar to ICA, we assumed that fluorescence image in the focal plane is away from a Gaussian distribution (normal distribution), but the superposition of images from multiple planes including in-focus and out-of-focus planes brings a distribution closer to a Gaussian distribution. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> shows how the estimated image varies depending on the cutoff frequency. The raw image (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>) is a part of the cardiac organoid shown in <xref ref-type="fig" rid="fig4">Figure 4</xref> in the main text. The computational sectioning calculation was applied with various cutoff frequencies (<italic>F<sub>c</sub></italic>) from 0.010 to 0.300 µm<sup>–1</sup>, and the four types of statistical measures to represent the non-Gaussian nature (non-Gaussianity) were calculated for the estimated in-focus images. The non-Gaussianity measures are kurtosis, skewness, negentropy, and mutual information (<xref ref-type="bibr" rid="bib10">Getreuer, 2013</xref>). The in-focus and out-of-focus images at three cutoff frequencies (<italic>F<sub>c</sub></italic> = 0.020, 0.063, 0.141 µm<sup>–1</sup>) are shown to see how the images change with the frequency (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B–C</xref>), and the line profiles on the raw image, in-focus, and out-of-focus images are shown in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1D</xref> to clarify their difference.</p></sec><sec sec-type="appendix" id="s9-2"><title>Determination of the non-Gaussianity measure and the cutoff frequency</title><p>First, we decided which measure we should use for the non-Gaussianity. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1E</xref> shows the cutoff frequency dependence of the four measures, which was calculated for the subregion of image (yellow square region in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>). In ICA, maximizing kurtosis or skewness is considered to maximize the non-Gaussianity, whereas minimizing negentropy or mutual information is considered to maximize the non-Gaussianity. Among these measures, negentropy and mutual information have their minimum around 0.141, but the estimated baseline contains the nuclear structure. The in-focus image, obtained by subtracting the baseline image from the original image, is noise-dominant (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1D</xref>, right). This is not suitable for our purposes, so we do not employ these indices. On the other hand, the skewness has a maximum value around 0.063, where the in-focus image appears to have clear nuclei, which is consistent with our objective (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>, middle). When the frequency was much lower (<italic>F<sub>c</sub></italic>=0.020) (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>, left), the background light component remained in the in-focus image. The kurtosis was found to have a similar frequency response to the skewness, with its maximum value at almost the same frequency. This trend was almost common in other images as well. These discussions led us to adopt skewness (or kurtosis) as non-Gaussianity measures, and set the cutoff frequency to <italic>F<sub>c</sub></italic>=0.063 for this image data, the frequency with the maximum skewness value. This optimization of the cutoff frequency was performed on a subset of a given data prior to the calculation of the entire dataset.</p></sec><sec sec-type="appendix" id="s9-3"><title>Limitation of the computational sectioning</title><p>Here, we discuss the limitation of applicability of our computational sectioning. As this method involves a baseline estimation process using a low-pass filter with a single cutoff frequency, the structures of the target object should be of uniform size, such as the cellular nucleus. When different sizes are mixed together in the object, the image processing often does not work well. An example of the application of this method to a computer-generated model image is shown in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>. In the model, a fluorescent sphere with a diameter of 10 µm or 30 µm is centered as the target object, and a 50 µm fluorescent sphere is placed 100 µm deep as the source of background light. A pseudo fluorescence image was generated on that 3D fluorescence distribution by the following procedure: (1) A theoretical point-spread function of the wide-field imaging system (NA = 0.25, wavelength = 520 nm) was convolved, (2) the intensity values was adjusted so that the maximum fluorescence intensity was 100, and (3) the values were converted to integers by rounding and Poisson noise was added. <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref> -top shows a fluorescence image of the <italic>z</italic>-plane passing through the center of a 10 µm target sphere. The in-focus image was estimated (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref> -bottom) by the method described above, with the optimal cutoff frequency set to the frequency at which the skewness is maximum, <italic>F<sub>c</sub></italic> = 0.045 (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2C</xref>). Similarly, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref> shows the original image of a 30 µm sphere and the estimated in-focus image. For the 30 µm sphere, a cutoff frequency of 0.022 was found to be optimal (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2C</xref>), with which the in-focus image was estimated (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>, bottom left). However, an artifact occurred where the area outside the boundary formed a valley, which happened because the spatial frequencies of the background light and the target sphere were close, leading to insufficient separation. If the cutoff frequency chosen for the 10 µm sphere is used for the 30 µm sphere image, the image of the target sphere falls within the baseline (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>, bottom right). <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2D</xref> shows images estimated using several frequencies in the case of 10 µm and 30 µm spheres side by side. At <italic>F<sub>c</sub></italic> = 0.045, the optimal frequency for 10 µm sphere (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2C</xref>), the 10 µm sphere is still well separated from the background, but the 30 µm sphere is included in the background light. Many artifacts occur at other frequencies as well. These results indicate that it is undesirable to apply this method to fluorescent images of two objects of very different sizes or of objects that are close in size to the background light.</p></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93633.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Xu</surname><given-names>Pingyong</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Chinese Academy of Sciences</institution><country>China</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>The <bold>important</bold> study established a large-scale objective and integrated multiple optical microscopy systems to demonstrate their potential for long-term imaging of the developmental process. The <bold>convincing</bold> imaging data cover a wide range of biological applications, such as organoids, mouse brains, and quail embryos, but enhancing image quality can further enhance the method's effectiveness. This work will appeal to biologists and imaging technologists focused on long-term imaging of large fields.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93633.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors are trying to develop a microscopy system that generates data output exceeding the previous systems based on huge objectives.</p><p>Strengths:</p><p>They have accomplished building such a system, with a field of view of 1.5x1.0 cm2 and a resolution of up to 1.2 um. They have also demonstrated their system performance on samples such as organoids, brain sections, and embryos.</p><p>Weaknesses:</p><p>To be used as a volumetric imaging technique, the authors only showcase the implementation of multi-focal confocal sectioning. On the other hand, most of the real biological samples were acquired under the wide-field illumination, and processed with so-called computational sectioning. Despite the claim that it improves the contrast, sometimes I felt that the images were oversharpened and the quantitative nature of these fluorescence images may be perturbed.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93633.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This manuscript introduced a volumetric trans-scale imaging system with an ultra-large field-of-view (FOV) that enables simultaneous observation of millions of cellular dynamics in centimeter-wide 3D tissues and embryos. In term of technique, this paper is just a minor improvement of the authors' previous work, which is a fluorescence imaging system working at visible wavelength region (<ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41598-021-95930-7">https://www.nature.com/articles/s41598-021-95930-7</ext-link>).</p><p>Strengths:</p><p>In this study, the authors enhanced the system's resolution and sensitivity by increasing the numerical aperture (NA) of the lens. Furthermore, they achieved volumetric imaging by integrating optical sectioning and computational sectioning. This study encompasses a broad range of biological applications, including imaging and analysis on organoids, mouse brains, and quail embryos, respectively. Overall, this method is useful and versatile.</p><p>Weaknesses:</p><p>What is the unique application that only can be done by this high-throughput system remains vague. Meanwhile, there are also several outstanding issues in this paper, such as the lack of technical advances, unclear method details and non-standardized figures.</p><p>Comments on revisions:</p><p>The revised manuscript has significantly improved in response to the initial review comments, particularly with the detailed additions regarding the objective lens and confocal imaging modes, which enhance the clarity and comprehensibility of the paper. While the structure and arguments are much clearer overall, there are still key issues that need to be addressed, specifically regarding algorithm validation, computational sectioning presentation, and volume imaging rate.</p><p>Algorithm Validation:</p><p>The validation of the algorithm's accuracy is not sufficiently robust. Reviewer 1's comment is entirely reasonable, and the authors should validate the algorithm's accuracy using well-established methods as ground truth. In the revised version, the authors attempt to demonstrate the fidelity of the algorithm by employing deep learning methods for high-accuracy cell recognition. However, this validation relies solely on comparisons between deep learning results and manual annotation results. The problem lies in the fact that both manual annotations and deep learning outcomes are derived from algorithm-processed data, which fails to prove the authenticity or validity of the data itself. To strengthen the validation, the authors should incorporate independent, gold-standard methods for comparison.</p><p>Computational Sectioning:</p><p>In the revised manuscript, the authors effectively demonstrate the ability of optical sectioning to improve axial resolution using fluorescent beads, as shown in Fig. S3, which is a strong point. However, the manuscript lacks a direct comparison for computational sectioning and does not provide a clear evaluation of axial resolution before and after applying computational sectioning. While some related information is included in Figs. 5.C and D, the details are insufficient, and intensity profiles are absent. I recommend that the authors include more direct visual demonstrations of computational sectioning, along with comparisons of axial resolution before and after applying computational sectioning. This would better showcase the method's effectiveness.</p><p>Volume Imaging Rate:</p><p>The manuscript currently omits critical details about the method's volume imaging rate. In the description of the quail embryo imaging experiment, key parameters such as exposure time and imaging speed are missing. Additionally, the manuscript does not discuss the maximum imaging rate supported by the system in confocal mode. The volume imaging rate is an essential factor for biological researchers to evaluate the applicability of the technique. Therefore, this information should be included, ideally in the abstract and introduction. Furthermore, the authors could describe how the volume imaging rate performs under different conditions and discuss its potential applications across various biological research contexts. Including such details would significantly enhance the paper's utility and appeal to the broader research community.</p><p>These adjustments will further strengthen the manuscript and address the reviewers' concerns effectively.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93633.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ichimura</surname><given-names>Taro</given-names></name><role specific-use="author">Author</role><aff><institution>Osaka University</institution><addr-line><named-content content-type="city">Suita</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Kakizuka</surname><given-names>Taishi</given-names></name><role specific-use="author">Author</role><aff><institution>Osaka University</institution><addr-line><named-content content-type="city">Ibaraki</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Taniguchi</surname><given-names>Yoshitsugu</given-names></name><role specific-use="author">Author</role><aff><institution>SIGMAKOKI CO., LTD.</institution><addr-line><named-content content-type="city">1-19-9 Midori, Sumida-ku, Tokyo</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Ejima</surname><given-names>Satoshi</given-names></name><role specific-use="author">Author</role><aff><institution>SIGMAKOKI CO., LTD.</institution><addr-line><named-content content-type="city">1-19-9 Midori, Sumida-ku, Tokyo</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Sato</surname><given-names>Yuki</given-names></name><role specific-use="author">Author</role><aff><institution>Kyushu University</institution><addr-line><named-content content-type="city">Fukuoka</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Itano</surname><given-names>Keiko</given-names></name><role specific-use="author">Author</role><aff><institution>Osaka University</institution><addr-line><named-content content-type="city">Ibaraki</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Seiriki</surname><given-names>Kaoru</given-names></name><role specific-use="author">Author</role><aff><institution>Osaka University</institution><addr-line><named-content content-type="city">Suita</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Hashimoto</surname><given-names>Hitoshi</given-names></name><role specific-use="author">Author</role><aff><institution>Osaka University</institution><addr-line><named-content content-type="city">Suita</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Sugawara</surname><given-names>Ko</given-names></name><role specific-use="author">Author</role><aff><institution>RIKEN Center for Biosystems Dynamics Research</institution><addr-line><named-content content-type="city">Kobe</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Itoga</surname><given-names>Hiroya</given-names></name><role specific-use="author">Author</role><aff><institution>RIKEN Center for Biosystems Dynamics Research</institution><addr-line><named-content content-type="city">Kobe</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Onami</surname><given-names>Shuichi</given-names></name><role specific-use="author">Author</role><aff><institution>RIKEN Center for Biosystems Dynamics Research</institution><addr-line><named-content content-type="city">Kobe</named-content></addr-line><country>Japan</country></aff></contrib><contrib contrib-type="author"><name><surname>Nagai</surname><given-names>Takeharu</given-names></name><role specific-use="author">Author</role><aff><institution>Osaka University</institution><addr-line><named-content content-type="city">Ibaraki</named-content></addr-line><country>Japan</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>The authors are trying to develop a microscopy system that generates data output exceeding the previous systems based on huge objectives.</p><p>Strengths:</p><p>They have accomplished building such a system, with a field of view of 1.5x1.0 cm2 and a resolution of up to 1.2 um. They have also demonstrated their system performance on samples such as organoids, brain sections, and embryos.</p><p>Weaknesses:</p><p>To be used as a volumetric imaging technique, the authors only showcase the implementation of multi-focal confocal sectioning. On the other hand, most of the real biological samples were acquired under wide-field illumination, and processed with so-called computational sectioning. Despite the claim that it improves the contrast, sometimes I felt that the images were oversharpened and the quantitative nature of these fluorescence images may be perturbed.</p><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>This manuscript introduced a volumetric trans-scale imaging system with an ultra-large field-of-view (FOV) that enables simultaneous observation of millions of cellular dynamics in centimeter-wide 3D tissues and embryos. In terms of technique, this paper is just a minor improvement of the authors' previous work, which is a fluorescence imaging system working at visible wavelength region (<ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41598-021-95930-7">https://www.nature.com/articles/s41598-021-95930-7</ext-link>).</p><p>Strengths:</p><p>In this study, the authors enhanced the system's resolution and sensitivity by increasing the numerical aperture (NA) of the lens. Furthermore, they achieved volumetric imaging by integrating optical sectioning and computational sectioning. This study encompasses a broad range of biological applications, including imaging and analysis of organoids, mouse brains, and quail embryos, respectively. Overall, this method is useful and versatile.</p><p>Weaknesses:</p><p>The unique application that only can be done by this high-throughput system remains vague. Meanwhile, there are also several outstanding issues in this paper, such as the lack of technical advances, unclear method details, and nonstandardized figures.</p></disp-quote><p>Here, we address the first part of the Weaknesses concerning the unique application, and will respond to the latter part in the Reply to the Recommendations.</p><p>We are developing 'large field of view with cellular resolution' imaging technique, aiming to apply it to the observation of multicellular systems consisting of a large number of cells. Our proposed optical system has achieved optical performance that enables simultaneous observation of more than one million cells in a single field of view. In this paper, we have succeeded in adding three-dimensional imaging capability while maintaining the size of this two-dimensional field of view. By simultaneously observing the dynamics of a large number of cells, we can reveal spatio-temporal sequences in state transitions (pattern formation, pathogenesis, embryogenesis, etc.) in multicellular systems and discover cells that serve as a starting point. These were mentioned in the 1st and 2nd paragraphs of the Introduction section (Line 48-, 58-) and discussed in the 4th paragraph of Discussion section (Line 398-) of the main text. While our previous work on two-dimensional specimens has shown its validity, the present work demonstrated that temporal changes of multicellular systems in three-dimensional specimens can be observed at the single-cell level.</p><p>Ideally, we aim to achieve the same level of depth observation capability as the FOV size in the lateral direction. However, at present, the penetration depth for living specimens is limited to a few hundred micrometers due to non-transparency, while the lateral FOV size exceeds 1 cm. The current optical performance is well-suited for systems where development occurs within a thin volume but a large area, such as the quail embryo presented in this paper (Fig. 6 in the revised manuscript). In addition to quail embryos, this technique can also be applied to the developmental systems of highly transparent model organisms, such as zebrafish. Furthermore, for chemically cleared specimens, even those thicker than 1.5 mm, as shown in this paper (Fig. 5 in the revised manuscript), can be observed. Besides organs other than the brain, it could also be applied to imaging entire living organisms. However, for observation depths up to 10 mm, such as in the whole mouse brain, a mechanism to compensate for spherical aberration is required, which we consider the next step in our technological development.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>(1) I suggest that authors shall re-examine the quantitative nature of their image processing algorithm. Also, I wonder whether there are parameters that could be adjusted, as images in Figure 3D and 4E seem to be oversharpened with potential loss of information.</p></disp-quote><p>As the reviewer pointed out, we recognized that there was an insufficient explanation of the image processing.</p><p>Therefore, descriptions on the quantitative nature and parameter adjustments have been added to the text (Materials and Methods, Line 552) and the Supplementary File (Fig. S4-5, Note 2), and these have been referenced in the main text. A summary is given below.</p><p>The adjustable parameters in our method include the cutoff frequency of the smoothing filter used in the background light estimation. If the cutoff frequency is too high, the focal plane component will be included in the “background”; if it is too low, background light will remain in the focal plane. The cutoff frequency needs to be optimized within this range. In this optimization, neither the size of the cell itself nor the performance of the optical system was considered; instead, we utilized the concept of independent component analysis (ICA). This approach is taken because the size and structure of cells vary from sample to sample, and the optical properties also vary with wavelength and location, making it impractical to consider each factor for every case. ICA employs a blind separation method, which is based on the principle that individual signals deviate from the normal (Gaussian) distribution, while the superimposition of signals tends to bring the distribution closer to the Gaussian distribution. Several indices have been proposed to quantify the non-Gaussian nature of the distribution, including kurtosis, skewness, negentropy, and mutual information. Among these measures, we empirically found skewness to be the most suitable and robust, and therefore adopted it for our algorithm. The optimal parameters were selected using a subset of the data before applying the calculations of the entire dataset. The determined values were then applied to the entire dataset.</p><p>Regarding the oversharpening, we believe that it rarely occurs in the image data shown in the manuscript. In a case where low-frequency structures and high-frequency structures are mixed in the focal plane, oversharpeninglike effect can occur because of the disappearance of low-frequency structures, which is discussed in Supplementary File (Note 2, Figs. S5D). However, in the case of a sample with nearly uniform spatial frequency, such as the nucleus observed in this study, oversharpening is unlikely to occur by setting appropriate parameters as described above. If it appears that some images are oversharpened in the figures, it is due to the contrast of the image.</p><disp-quote content-type="editor-comment"><p>(2) On the other hand, I am curious how a wide-field fluorescence system may reliably extract information from a denselylabeled sample within axial volume of 200 um, as they showed in the mouse brain in Figure 4. Thus I am skeptical regarding the fidelity and completeness of the signals and cells recorded there. It would be ideal if the authors could benchmark their system performance with a two-photon microscope system, which serves as the ground truth.</p></disp-quote><p>The reviewer's suggestion is reasonable; however, we are unfortunately unable to observe the same sample using a two-photon microscope. Instead, we will explain these differences from a theoretical perspective. Two-photon microscopes used for brain imaging typically employ objective lenses with a numerical aperture (NA) of at least 0.5, allowing for 3D imaging with depth resolution ranging from several micrometers down to sub-micrometer levels. In contrast, our method uses a lens system with NA of 0.25, and the optical configuration (focusing NA, pinhole size) are not optimized for resolution (Note 2 in Supplementary File), thus the longitudinal resolution (FWHM) is about 14 microns (Fig. 3E in the revised manuscript). This difference is significant in the brain imaging, where our method may not fully separate all cells in close proximity along the depth axis, as shown in the bottom panels (<italic>xz</italic>-plane) of Fig. 5F of the revised manuscript. Nevertheless, we believe that cell nuclei can be accurately detected in this 3D image using appropriate cell detection methods based on deep learning. To support this claim, we conducted cell detection using the state-of-the-art cell detection platform ELEPHANT and incorporated the results into Fig. 5 (Fig. 5G-I). This figure demonstrates that even with the current spatial resolution, accurate detection of cell nuclei is achievable.</p><p>We accordingly added one paragraph (Line 285) in the main text to explain the cell detection method and discuss the results. We also added one section into Materials and Methods for more detail of the cell detection (Line 650).</p><p>In conjunction with the revision, the developer of ELEPHANT (K. Sugawara) has been included as a co-author.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>In my opinion, the following concerns need to be addressed.</p><p>Major comments:</p><p>(1) The proposed system's crucial element involves the development of a giant lens system with a numerical aperture (NA) of 0.25. However, a comprehensive introduction and explanation of this significant giant lens system are missing from the manuscript. I strongly suggest that the authors supplement the relevant content to provide a clearer understanding of this integral component.</p></disp-quote><p>A detailed description of the giant lens system has been added to the main text (Optical Configuration and Performance, Line 83) and the Materials and Methods section (Wide -field imaging system (AMATERAS-2w) configuration, Line 446). A diagram of the lens configuration has also been included in Fig. 1A. In conjunction with these additions, two engineers from SIGMAKOKI CO. LTD., who made significant contributions to the design and manufacturing of the lens system, have been included as co-authors.</p><disp-quote content-type="editor-comment"><p>(2) The manuscript introduces a computational sectioning technique, based on iteratively filtering technology. However, the accuracy of this algorithm is not sufficiently validated.</p></disp-quote><p>It is challenging to discuss accuracy of the processing results compared to the ground truth, because the ground truth is unknown for any of the experiments. Instead, in the Supplementary File (Notes 2, Figures S4-5), we show how the processing results for the measured and simulated data vary with the parameter (cutoff frequency), illustrating the characteristics of our method. The results suggest that by optimally pre-selecting the parameter, it is possible to successfully separate the in-focus and out-of-focus components. This discussion is related to our response to the first recommendation made by the reviewer #1. Please review our response to Reviewer #1 regarding parameter optimization and oversharpening. Here, as an addition, we describe a discussion of the conditions that must be met in order to perform the calculation correctly, as described below (also included in Note 2, Limitation of the computational sectioning).</p><p>To apply this method, certain requirements must be met regarding cutoff spatial frequency and intensity. Regarding cutoff spatial frequency, the algorithm utilizes a low-pass filter with a single cutoff frequency, which can make it challenging to accurately extract structures in the focal plane when structures of varying sizes and shapes are mixed within the sample. This is illustrated by the simulation shown in Fig. S5 and described in Note 2. Conversely, regarding intensity, if the structure’s intensity in the focal plane is weak compared to the Gaussian fluctuations in the background intensity, it becomes difficult to extract the structure. However, intensity fluctuations can be reduced by applying a 3x3 moving average filter to the entire image as a pre-processing step before applying the baseline estimation algorithm.</p><p>In the experimental data presented in this paper (Figs. 4-6 in the revised manuscript), the spatial frequency issue was not significant because the target structures, which are stained nuclei, appear to be of nearly uniform size in the focal plane. The second issue, related to intensity, is also addressed in Fig. 4, as the signal intensity from the focal plane is sufficient to overcome background light in almost all regions. In the mouse brain example, the use of confocal imaging suppresses background light, allowing the structures in the focal plane to be accurately extracted.</p><disp-quote content-type="editor-comment"><p>(3) I didn't see a detailed description of the confocal imaging in the manuscript. If it adheres to conventional confocal technology, then the question arises: what truly constitutes the novel aspect of this technique?</p></disp-quote><p>The principle of confocal imaging and optics is based on the use of a pinhole array, a system also employed commercially by CrestOptics (X-Light, Italy). Prior to the 1990s, when the configuration utilizing Yokogawa Electric's pinhole array and microlens array pairs became popular, pinhole array-only setups were the norm, and are now considered somewhat traditional. We do not claim novelty in the optical configuration itself, but rather in the design of a confocal optical system tailored for our original large-field (low-magnification) imaging system with a relatively high NA. The pinhole array disk we designed features significantly smaller pinholes and correspondingly tighter pinhole spacing than those used for high-magnification observation purposes. We believe that this unique size and arrangement provides sufficient novelty.</p><p>We have revised the manuscript to clearly emphasize what we believe constitutes the novelty of this technique (paragraphs starting from Line 166 and Line 183). We have also added a discussion on our confocal optical configuration and its spatial resolution in the Supplementary File (Note 1, Fig. S2-3).</p><disp-quote content-type="editor-comment"><p>(4) Light-sheet and light-field microscopy, as two emerging 3D microscopy techniques which has theoretically higher throughput than confocal, are not sufficiently introduced in this manuscript.</p></disp-quote><p>In the previous version, we briefly mentioned light-sheet and light-field microscopy, but we recognized that more detailed explanations were necessary and should be included in the manuscript. We have added several sentences to the main text (Line 159-165). A summary is provided below.</p><p>Light-sheet microscopy requires the illumination light to propagate over long distances within the specimen, and many applications necessitate the use of transparency-enhanced tissue. Even when the sample is highly transparent, no existing technique can form thin optical sections as long as 1 cm. Therefore, light-sheet microscopy is not an effective method for the thin, wide, three-dimensional objects that are the focus of this project. Regarding light-field microscopy, it features a trade-off where the number of pixels in the two-dimensional plane is reduced in exchange for the ability to record three-dimensional fluorescence distribution information in a single shot. In our imaging system, the pixel spacing is set to be comparable to the Nyquist Frequency to observe as many cells as possible, meaning that no more additional pixels can be sacrificed. Therefore, the light-field microscopy technique is not suitable for our imaging system.</p><disp-quote content-type="editor-comment"><p>(5) The fluorescence images of cardiomyocytes derived from human induced pluripotent stem cells (hiPSCs) stained with Rhodamine phalloidin, as presented in Figure 1(E), exhibit suboptimal quality. This may hinder the effective use of the image for biological research. It is imperative that the authors address and explain this aspect, shedding light on the limitations and potential implications of the research findings.</p></disp-quote><p>We acknowledge the reviewer’s concern regarding the suboptimal quality of the fluorescence image. Upon further examination, we recognized that the resolution and clarity of the image could potentially limit its utility for detailed biological analysis. To address this, we have re-examined the image size and quality to enhance its presentation in Fig. 2C-E in the revised manuscript, which allows for finer structures to be recognized within the large image size.</p><p>Regarding the effective use of the image for biological research, the results shown in the images indicated the capability of observing subcellular structures, such as myofibrils, in cell sheets with a large area, such as myocardial sheets. This would enable us to simultaneously investigate micro-level structures (orientation and density of myofibrils) and macro-level multicellular dynamics (performance of myocardial sheet). We added the above explanation in the manuscript (Line 146). We hope this revision clarifies the quality and utility of the presented image.</p><disp-quote content-type="editor-comment"><p>(6) The imaging quality difference between the two techniques shown in Figure 1F, G is relatively small, and the signal distribution difference shown in Figure H is significant, unlike the effects expected from an improvement in resolution.</p></disp-quote><p>We acknowledge the reviewer's concern regarding the minimal apparent difference in imaging quality between the two images. Upon re-evaluation, we recognized that the original presentation may not have clearly demonstrated the improvements intended by the different techniques. Figure 1H, which showed the line profile of Figs. 1F and G, may have been impacted by the resolution and compression settings of the image file, leading to a less pronounced distinction between the two techniques. To address this, we have enlarged Figs 1F and 1G</p><p>(renumbered as Fig. 2D and 2E in the revised manuscript) and carefully reviewed the resolution and compression ratio to ensure that the differences are more clearly visible.</p><disp-quote content-type="editor-comment"><p>(7) The chart in Figure 2(C) lacks axis titles and numerical labels, making it challenging for readers to comprehend. To enhance reader convenience, it is recommended that the authors incorporate axis titles and numerical labels, providing a clearer context for interpreting the chart.</p></disp-quote><p>We appreciate the reviewer’s observation regarding the lack of axis titles and numerical labels in the figure. The vertical axis represents fluorescence intensity, which we initially omitted, assuming it was self-evident. However, as the reviewer correctly pointed out, it is crucial to ensure that figures are clear and accessible to readers from diverse backgrounds. In response, we have added the vertical axis title to Fig. 2C (renumbered as Fig. 3C in the revised manuscript) to enhance clarity, while the numerical labels remain omitted as the unit is arbitrary (a.u.). We have also reviewed all other figures in the manuscript to ensure that no similar errors are present.</p><disp-quote content-type="editor-comment"><p>(8) In Figures 2(D) and (E), where the authors present the point spread function for quantifying the lateral and axial resolution of the system, I would recommend increasing the number of fluorescent microspheres to more than 10 for statistical averaging. This adjustment would strengthen the persuasiveness of the data and contribute to a more robust analysis.</p></disp-quote><p>We appreciate the reviewer’s recommendation to increase the number of fluorescent microspheres for statistical averaging in Figs. 2D and E (renumbered as Fig. 3D-E in the revised manuscript). In response, we have revised the graphs to present the point spread function with the statistical mean and standard deviation (SD) of fluorescent images obtained from a large sample size (N = 100), and accordingly revised the main text to mention the statistics (Line 118, Line 132). We also recognized that a similar adjustment was necessary for Figs 1C and D (renumbered as Fig. 2A-B in the revised manuscript), and have accordingly made the same modifications to those figures as well. We believe these changes enhance the robustness and persuasiveness of our data.</p><disp-quote content-type="editor-comment"><p>(9) Figure 4(C) visually represents the characteristic 3D structures of several regions. However, discerning the 3D structural information in the images poses a challenge. To address this issue, I recommend that the authors optimize the 3D visualization to improve clarity and facilitate a more effective interpretation of the depicted structures.</p></disp-quote><p>We appreciate the reviewer’s suggestion regarding the challenges in discerning the 3D structural information in Fig. 4C. To address this, we have added representative images from the xy-plane and xz-plane of the cortex, medial habenula, and choroid plexus (Fig. 5G-I) in the revised manuscript. These additions provide a clearer visualization of the 3D distribution in each region, making it easier for readers to interpret the structures. Additionally, we have overlaid the results of deep-learning based cell detection on these images, further enhancing the visibility of the cells. This adjustment also aligns with our response to Reviewer #1's second comment.</p><disp-quote content-type="editor-comment"><p>Minor comments:</p><p>(1) The labelling of ROI is missing in Figure 1(e).</p></disp-quote><p>We appreciate the reviewer’s observation regarding the missing labeling of the ROI in Fig. 1E. Upon review, we confirmed that the ROI was indeed labeled with a white square in the previous manuscript; however, it was difficult to discern due to its small size and the black-and-white contrast. To improve visibility, we have recolored the square in magenta, ensuring that it stands out more clearly in the figure (Fig. 2C in the revised manuscript).</p><disp-quote content-type="editor-comment"><p>(2) The subfigure order and labeling in Fig. 1 and Fig. 2 are not consistent.</p></disp-quote><p>We appreciate the reviewer’s attention to the subfigure order and labeling in Fig. 1 and 2 (Fig. 1-3 in the revised manuscript). To accommodate subfigures of varying sizes without leaving gaps, we arranged the subfigures in a non-sequential order. However, we have ensured that the text refers to the figures in the correct order. We acknowledge the importance of consistency and will work with the editorial team to explore the best way to present the figures while maintaining clarity and alignment with standard practices.</p><disp-quote content-type="editor-comment"><p>(3) Figure 1B reappears in Figure 2.</p></disp-quote><p>We appreciate the reviewer’s observation regarding the repetition of Figure 1B in Figure 2. While the central part of the optical system (custom lens system) is common to both figures, the illumination system, pinhole array disk, and detection optics for the confocal set up differ. To provide a complete understanding of the optical system, we opted to include the full diagram in Fig. 2B (renumbered as Fig. 3B in the revised manuscript). We considered highlighting only the different components, but we felt that doing so might complicate the reader’s comprehension of the overall system. Therefore, we chose to include the common elements twice to ensure clarity.</p></body></sub-article></article>