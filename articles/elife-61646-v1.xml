<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">61646</article-id><article-id pub-id-type="doi">10.7554/eLife.61646</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural encoding of actual and imagined touch within human posterior parietal cortex</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-200920"><name><surname>Chivukula</surname><given-names>Srinivas</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3570-162X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-200921"><name><surname>Zhang</surname><given-names>Carey Y</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-200314"><name><surname>Aflalo</surname><given-names>Tyson</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0101-2455</contrib-id><email>taflalo@caltech.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-100057"><name><surname>Jafari</surname><given-names>Matiar</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-200922"><name><surname>Pejsa</surname><given-names>Kelsie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-193930"><name><surname>Pouratian</surname><given-names>Nader</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0426-3241</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-12342"><name><surname>Andersen</surname><given-names>Richard A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7947-0472</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Biology and Biological Engineering, California Institute of Technology</institution><addr-line><named-content content-type="city">Pasadena</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Tianqiao and Chrissy Chen Brain-Machine Interface Center, Chen Institute for Neuroscience, California Institute of Technology</institution><addr-line><named-content content-type="city">Pasadena</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Geffen School of Medicine, University of California, Los Angeles</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Makin</surname><given-names>Tamar R</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Makin</surname><given-names>Tamar R</given-names></name><role>Senior Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>01</day><month>03</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e61646</elocation-id><history><date date-type="received" iso-8601-date="2020-07-31"><day>31</day><month>07</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-02-08"><day>08</day><month>02</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Chivukula et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Chivukula et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-61646-v1.pdf"/><abstract><p>In the human posterior parietal cortex (PPC), single units encode high-dimensional information with <italic>partially mixed</italic> representations that enable small populations of neurons to encode many variables relevant to movement planning, execution, cognition, and perception. Here, we test whether a PPC neuronal population previously demonstrated to encode visual and motor information is similarly engaged in the somatosensory domain. We recorded neurons within the PPC of a human clinical trial participant during actual touch presentation and during a tactile imagery task. Neurons encoded actual touch at short latency with bilateral receptive fields, organized by body part, and covered all tested regions. The tactile imagery task evoked body part-specific responses that shared a neural substrate with actual touch. Our results are the first neuron-level evidence of touch encoding in human PPC and its cognitive engagement during a tactile imagery task, which may reflect semantic processing, attention, sensory anticipation, or imagined touch.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>touch</kwd><kwd>human</kwd><kwd>imagery</kwd><kwd>single neuron</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>R01EY015545</award-id><principal-award-recipient><name><surname>Aflalo</surname><given-names>Tyson</given-names></name><name><surname>Pouratian</surname><given-names>Nader</given-names></name><name><surname>Andersen</surname><given-names>Richard A</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>Conte Center</institution></institution-wrap></funding-source><award-id>P50MH094258</award-id><principal-award-recipient><name><surname>Aflalo</surname><given-names>Tyson</given-names></name><name><surname>Andersen</surname><given-names>Richard A</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>T&amp;C Chen Brain-Machine Interface Center at Caltech</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Aflalo</surname><given-names>Tyson</given-names></name><name><surname>Andersen</surname><given-names>Richard A</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100009822</institution-id><institution>Boswell Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Andersen</surname><given-names>Richard A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Single neurons in human posterior parietal cortex encode actual and imagined touch within a shared neural substrate.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Touch is a complex, multisensory perceptual process (<xref ref-type="bibr" rid="bib17">de Haan and Dijkerman, 2020</xref>; <xref ref-type="bibr" rid="bib18">de Lafuente and Romo, 2006</xref>; <xref ref-type="bibr" rid="bib33">Graziano and Gross, 1993</xref>). In non-human primates (NHPs), multisensory input (e.g., visual, tactile) converges upon neurons in higher-order brain regions such as the posterior parietal cortex (PPC) where they are integrated into coherent representations (<xref ref-type="bibr" rid="bib33">Graziano and Gross, 1993</xref>; <xref ref-type="bibr" rid="bib7">Avillac et al., 2007</xref>; <xref ref-type="bibr" rid="bib30">Graziano, 1999</xref>; <xref ref-type="bibr" rid="bib32">Graziano, 2001</xref>; <xref ref-type="bibr" rid="bib31">Graziano et al., 2000</xref>; <xref ref-type="bibr" rid="bib36">Holmes and Spence, 2004</xref>; <xref ref-type="bibr" rid="bib40">Hwang et al., 2014</xref>; <xref ref-type="bibr" rid="bib81">Seelke et al., 2012</xref>; <xref ref-type="bibr" rid="bib82">Sereno and Huang, 2014</xref>). Recent human neuroimaging studies suggest that the PPC is also recruited during touch cognition in the absence of actual tactile input (e.g., seen touch or imagined touch), supporting a notion that both higher-level touch processing and tactile cognition share a neural substrate (<xref ref-type="bibr" rid="bib14">Chan and Baker, 2015</xref>; <xref ref-type="bibr" rid="bib53">Lucas et al., 2015</xref>). To date, however, such a link has not been established at the single neuron level.</p><p>We recently reported an analogous relation in the parallel domain of motor function (<xref ref-type="bibr" rid="bib2">Aflalo et al., 2020</xref>; <xref ref-type="bibr" rid="bib1">Aflalo et al., 2015</xref>; <xref ref-type="bibr" rid="bib75">Rutishauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>). In these studies, we found that a shared PPC neuronal population coded for overt movements as well as cognitive motor variables including imagery, observed actions, and action verbs (<xref ref-type="bibr" rid="bib2">Aflalo et al., 2020</xref>; <xref ref-type="bibr" rid="bib1">Aflalo et al., 2015</xref>; <xref ref-type="bibr" rid="bib5">Andersen and Buneo, 2002</xref>; <xref ref-type="bibr" rid="bib75">Rutishauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>). This richness of representation is made possible through a <italic>partially mixed</italic> encoding in which single neurons represent multiple variables, allowing a relatively small neuronal population (recorded through a 4 × 4 mm implanted microelectrode array) to provide many movement-related signals (<xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>; <xref ref-type="bibr" rid="bib94">Zhang et al., 2020</xref>). Here, we hypothesize that the same PPC neuronal population engaged by high-level motor cognition also encodes actual tactile sensations as well as tactile cognition within this partially mixed encoding structure.</p><p>The neural correlates of somatosensory perception are characterized by spatially structured receptive fields to touch that respond at short latency (<xref ref-type="bibr" rid="bib47">Keysers et al., 2010</xref>). In NHPs, subregions of the PPC within and medial to the intraparietal sulcus (IPS) encode tactile receptive fields that respond to bilateral stimuli (<xref ref-type="bibr" rid="bib33">Graziano and Gross, 1993</xref>; <xref ref-type="bibr" rid="bib7">Avillac et al., 2007</xref>; <xref ref-type="bibr" rid="bib30">Graziano, 1999</xref>; <xref ref-type="bibr" rid="bib81">Seelke et al., 2012</xref>; <xref ref-type="bibr" rid="bib82">Sereno and Huang, 2014</xref>). These are often large receptive fields, extending across multiple body parts (<xref ref-type="bibr" rid="bib7">Avillac et al., 2007</xref>; <xref ref-type="bibr" rid="bib30">Graziano, 1999</xref>; <xref ref-type="bibr" rid="bib32">Graziano, 2001</xref>; <xref ref-type="bibr" rid="bib31">Graziano et al., 2000</xref>; <xref ref-type="bibr" rid="bib40">Hwang et al., 2014</xref>; <xref ref-type="bibr" rid="bib81">Seelke et al., 2012</xref>; <xref ref-type="bibr" rid="bib82">Sereno and Huang, 2014</xref>; <xref ref-type="bibr" rid="bib77">Sakata et al., 1973</xref>). In humans, functional magnetic resonance imaging (fMRI) studies support multisensory encoding of touch within and medial to the IPS in anterior portions of PPC (<xref ref-type="bibr" rid="bib38">Huang et al., 2018</xref>; <xref ref-type="bibr" rid="bib82">Sereno and Huang, 2014</xref>; <xref ref-type="bibr" rid="bib37">Huang et al., 2012</xref>). Although these studies indicate that relatively small regions of PPC may encode touch to large portions of the body, the limited spatial resolution of fMRI precludes a characterization of tactile receptive fields. The inability to resolve single neurons in fMRI is especially problematic when attempting to understand the significance of the grossly overlapping representations of actual touch and cognitive representations of touch (<xref ref-type="bibr" rid="bib14">Chan and Baker, 2015</xref>; <xref ref-type="bibr" rid="bib53">Lucas et al., 2015</xref>). Spatial correspondence in fMRI cannot confirm whether representations share a neuron-level substrate (<xref ref-type="bibr" rid="bib13">Caramazza et al., 2014</xref>). Taken together, it is unclear from the current literature whether individual neurons in human PPC discriminate touch to different segments of the body with spatially structured receptive fields, and, if so, whether cognitive processing of touch engages the same populations of cells.</p><p>In a unique opportunity, we investigated touch processing in a tetraplegic human subject at the level of single neurons recorded from an electrode array implanted in the left PPC for an ongoing brain machine interface (BMI) clinical trial. We recorded single- and multi-unit neural activity during the presentation of actual touch and during imagined touch to sensate dermatomes above the level of the participant’s injury. We found that neurons recorded at the junction of the postcental and intraparietal sulci in humans (postcentral-intraparietal, PC-IP) encoded actual touch at short latency (~50 ms) with bilateral spatially structured receptive fields, covering all tested, sensate regions within the head, face, neck, and shoulders. The tactile imagery task evoked body part-specific responses that shared a neural substrate with actual touch. Our results demonstrate that PPC neurons that discriminate touch are partially reactivated during a tactile imagery task in a body part-specific manner. The latter represents a novel finding, thus far untestable in NHP models, and suggests PPC involvement in the cognitive processing of touch.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We recorded from on average 101.6 ± 7.2 neurons (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) over 14 sessions in the PPC (left hemisphere) of a tetraplegic human participant (spinal injury at levels 3–4; C3/4). In previous work, we referred to the implant area as the anterior intraparietal cortex, a region functionally defined in NHPs (<xref ref-type="bibr" rid="bib2">Aflalo et al., 2020</xref>, <xref ref-type="bibr" rid="bib1">Aflalo et al., 2015</xref>; <xref ref-type="bibr" rid="bib75">Rutishauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>; <xref ref-type="bibr" rid="bib94">Zhang et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Andersen et al., 2019</xref>; <xref ref-type="bibr" rid="bib78">Sakellaridi et al., 2019</xref>). Here, we refer to the recording site as the PC-IP, acknowledging that further work is necessary to definitively characterize homologies between human and NHP anatomy. Recordings were split across four tasks, designed to probe basic properties of the neuronal population during both actual and imagined touch. Recordings were made from a chronic implanted array, and thus neuronal waveform sorting resulted in both well-isolated neuronal waveforms and multi-neuron groupings. The main figures aggregate across sorted channels while key analyses are performed separately for well-isolated and multi-unit activity in supplemental figures.</p><sec id="s2-1"><title>PC-IP neurons encode bilateral tactile receptive fields</title><p>We first examined the hypothesis that PC-IP neurons encode tactile receptive fields to dermatomes above the level of the participant’s spinal cord injury (SCI). Tactile stimuli were delivered as rubbing motions at approximately 1 Hz for 3 s. The subject was asked to keep her eyes closed to eliminate neural responses arising from visual input. Tactile stimuli were presented to bilateral axial (forehead, vertex, cheek, neck, back) and truncal (shoulder) body parts to determine the extent of body coverage of any tactile representations among PC-IP neurons. As controls, touch was also presented to the bilateral hands (insensate regions below the level of SCI), and a null condition was included (with no stimulus delivered) to verify that touch-related neural responses did not arise by chance.</p><p>For each neuron, we fit a linear model that explained firing rate as a function of responses to each touch location. Neural responses to a particular body location were considered significant if the t-statistic for the associated beta coefficient was significant (p&lt;0.05, false discovery rate [FDR] corrected for multiple comparisons). A significant fraction of the neuronal population encoded touch to each of the tested body parts with preserved somatosensation (χ<sup>2</sup>(1)<bold>=</bold>3908.98, p&lt;0.05; <xref ref-type="fig" rid="fig1">Figure 1A</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). These results are consistent with bilateral encoding as the tested body parts included both body sides. Neither touch to the hands nor the null condition elicited significant neuronal modulation. Single neurons discriminated the location of actual touch: Of the 263 responsive units shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, we found that 257 discriminated touch location (ANOVA, FDR corrected for multiple comparisons). Representative examples of neurons showing clear discrimination between the different touch locations are shown in <xref ref-type="fig" rid="fig1">Figure 1B</xref>. As expected, a population of discriminative cells enabled accurate cross-validated classification of the touched body part (<xref ref-type="fig" rid="fig1">Figure 1C</xref>; see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref> for single-session examples).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Postcentral-intraparietal (PC-IP) discriminably encodes bilateral tactile receptive fields.</title><p>(<bold>A</bold>) Percentage of the PC-IP neuronal population that demonstrated significant modulation relative to baseline for each tested stimulation site (p&lt;0.05, false discovery rate corrected, n = 398 units). Results are shown as the mean percentage (horizontal black line) of the population ± bootstrapped 95% confidence interval (bar height). Gray bars represent truncal (midline) body locations, blue bars represent left (ipsilateral)-sided sites, and orange bars represent right (contralateral)-sided sites. Population results were pooled across recording sessions (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) and were not qualitatively affected by pooling together single and potential multi-units (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). (<bold>B</bold>) Representative neuronal responses illustrating body part discrimination. Each column of panels depicts the response for one neuron to body parts on the left (top two rows) and on the right (bottom two rows). The first and third rows show the neural response (mean firing rate ± standard error on the mean, n = 10 trials) as a function of time. The second and fourth rows show the spike rasters. Within these rows, each panel depicts the spike activity over each of the 10 trials (rows) and time (x-axis), and are color-coded by tested body site. The vertical line labeled ‘Go’ indicates the start of the stimulus phase. (<bold>C</bold>) Confusion matrix of the cross-validated classification accuracy (as percentage) for predicting body parts from population neural data. Colors represent the cross-validated accuracy, as in the scale. The matrix is an average of the confusion matrices computed for each recording day individually (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). L: left body, ipsilateral to implant; R: right body, contralateral to implant.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Nonstationary waveforms across days indicate that recorded neurons are partially distinct.</title><p>We performed two analyses to quantify changes in neural recordings across days. In the first, we counted the number of waveforms on a channel and compared the number between days. If the number of waveforms changed, then this is strong evidence that there has been some substantial change in the neural recordings. By this measure, an average of 29 ± 4.2% of channels change across days. In the second analysis, we used a permutation shuffle test to measure whether the recorded waveforms on the same channel were more similar than waveforms across different channels. By this assessment, 58 ± 8% of channels change across days. These values indicate that there was some degree of neural turnover despite chronic recordings from the same implanted array. Representative changes are shown in the figure. In the two panels (left and right), the waveforms (mean ± SD) for all sorted neurons from each spatial position on the array are shown. An empty panel indicates no evidence of neural activity. Consistent with our analysis, both the presence and/or absence of waveforms as well as their shape can vary between sessions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Postcentral-intraparietal (PC-IP) population responsiveness is not qualitatively changed by pooling together single and multi-units.</title><p>(<bold>A</bold>) Percentage of the PC-IP neuronal population that demonstrated significant modulation (tuning) to each tested stimulation site (p&lt;0.05, false discovery rate corrected) when considering only high-quality single units. Within each bar, the black horizontal line represents the mean and the width of the bar represents the bootstrapped 95% confidence interval. Gray bars represent truncal (midline) body locations, blue bars represent left-sided sites, and orange bars represent right-sided sites. (<bold>B</bold>) Similar to <bold>A</bold>, but considering potential multi-units. N: sample size; L: left; R: right.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Population classification statistics were qualitatively unchanged between data recording sessions.</title><p>Each panel from left to right represents the confusion matrix of a labeled recording session. The cross-validated classification accuracy (as percentage) in predicting actual touch conditions from population neural data is shown. These data are averaged in the matrix shown in <xref ref-type="fig" rid="fig1">Figure 1C</xref>. L: left; R, right.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig1-figsupp3-v1.tif"/></fig></fig-group><p>Single neurons were heterogenous, responding to variable numbers of touch sites (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Right and left sides tended to respond to the same number of fields (evidenced by the strong diagonal structure of <xref ref-type="fig" rid="fig2">Figure 2A</xref>). Tactile receptive fields of PC-IP neurons were diverse with evidence both for broad single-peaked fields and multi-peaked fields characterized by spatially separated regions of enhanced response (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Neurons respond to variable numbers of bilateral receptive fields.</title><p>Bilateral responses are mirror-symmetric. (<bold>A</bold>) Matrix showing the number of neurons from within the postcentral-intraparietal population that responded to the number of body parts shown, along each of the left and right body sides. Colors represent the number of neurons. Population results were not qualitatively affected by pooling together single and potential multi-units (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Analysis of tactile receptive fields is shown in <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref> and <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>. (<bold>B</bold>) Neuronal population correlation demonstrating the relation in encoding structure between body locations. Colors represent strength of correlation, as in the scale. Population results were not qualitatively affected by pooling together single and potential multi-units (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>) or by choice of distance metric (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). For mirror-symmetry analysis at the single unit level, see <xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>. L: left body, ipsilateral to implant; R: right body, contralateral to implant.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Bilateral responses to actual touch are not qualitatively changed by pooling together single and multi-units.</title><p>(<bold>A</bold>) Matrix showing the number of neurons that responded to the number of body parts shown, along each of the left and right body sides. Only high-quality single units were considered in this matrix. The number of neurons is overlaid upon a heatmap in which the colors correspond to the number, as in the scale. (<bold>B</bold>) Similar to <bold>A</bold>, but considering potential multi-units. N: sample size; L: left; R: right.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Diverse tactile receptive fields in human postcentral-intraparietal (PC-IP) neurons.</title><p>Tactile receptive fields of PC-IP neurons were diverse with evidence both for broad single-and multi-peaked fields. Multi-peaked fields are defined as having spatially separated regions of enhanced response. (<bold>A</bold>) Percentage of neurons characterized by a broad single-peak response versus multiple peaks (mean ± 95% CI). The analysis is described in detail in 'Materials and methods: Spatial extent of single neuron responses'. In brief, for each neuron, we found the location of maximal response and asked whether we could find a second local maxima that rose significantly above the neighboring values. If no significant second local maxima was found, the neuron was categorized as single-peak; otherwise, the neuron was categorized as multi-peak. (<bold>B</bold>) Percentage of neurons characterized by a single peak versus multiple peaks split by their preferred response field (mean ± 95% CI). (<bold>C</bold>) Similar to <bold>A</bold>, but considering potential multi-units. (<bold>D</bold>) Similar to <bold>B</bold>, but considering potential multi-units. (<bold>E</bold>) Sample single-peak neuronal responses. Four rows depict sample units grouped according to their preferred response field (from top to bottom: forehead, cheek, neck, and shoulder). Within each panel, the neuron’s firing rate (in Hertz) is depicted as a shaded blue region (the width indicating the interval from [mean – 95% CI] to [mean + 95% CI], to each of the four labeled locations). (<bold>F</bold>) Sample multi-peak neuronal responses. Conventions as in <bold>C</bold>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig2-figsupp2-v1.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Receptive fields demonstrate local spatial structure.</title><p>In our first experiment (<xref ref-type="fig" rid="fig1">Figure 1</xref>), we found that neurons tended to demonstrate a region of peak response with gradual reduction of the response as a function of distance with the possibility for representations at larger distances. To better understand the local parametric structure of tactile receptive fields, we performed a second experiment that tested collinear sites at finer spatial resolution. (<bold>A</bold>) We performed a task variant aimed at estimating the size of neuronal receptive fields to actual touch ('Materials and methods: Receptive field size'). In this variant, we tested actual touch to nine equally spaced points, 2 cm apart, along a line from the subject’s cheek to her neck. This panel shows the location of stimulation points along the study subject’s face and neck. Photo credit: Tyson Aflalo, California Institute of Technology. The face is masked to obscure identity per publisher’s request. (<bold>B</bold>) Percentage of the neuronal population significantly modulated by touch to each stimulation location (p&lt;0.05, false discovery rate corrected, shown as mean ± 95% CI, n = 585 units). (<bold>C</bold>) Representative neuronal responses showing the firing rate at each stimulation site as a function of time (mean ± 95% CI; n = 10 trials). (<bold>D</bold>) Representative examples of neuronal responses and Gaussian fits used to estimate receptive field size (for full description, see 'Materials and methods: Receptive field size estimation'). Briefly, for each neuron demonstrating a differential response to touch to each of the nine fields, we identified the preferred site of stimulus delivery as the site associated with the largest firing rate. Next, we fit a Gaussian model to the average responses at the nine sites, with the mean/center of the model fixed at the preferred response site. The receptive field size was estimated as the full width at half maximum. In each of the examples depicted, the colored lines represent the Gaussian model fit to the average responses. The number of units included in the analysis for each example site is indicated in the title of each subplot (as both the absolute number of neurons and as a percentage of the recorded neuronal population). The receptive field size was described as the full width at half maximum, shown in the title of each subplot. In each subplot, the x-axis indicates the stimulation site. The y-axis is a standard (z) score. Hz: Hertz; cm: centimeter.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig2-figsupp3-v1.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Symmetry in population-level responses to bilateral touch is not qualitatively changed by pooling together single and multi-units.</title><p>(<bold>A</bold>) Population correlation demonstrating the relation in encoding structure between test conditions, when considering only high-quality single units. Colors represent the strength of correlation, as in the scale. (<bold>B</bold>) Similar to <bold>A</bold>, but considering potential multi-units. N: sample size; L: left; R: right.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig2-figsupp4-v1.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>Relationships of population responses to touch are conserved across distance metrics.</title><p>(<bold>A</bold>) Population similarity in encoding structure (for correlation data presented in <xref ref-type="fig" rid="fig2">Figure 2B</xref>) between test conditions when evaluated by Euclidean separation. Colors represent the distance, as in the scale. (<bold>B</bold>) Population similarity in encoding structure (for the same data as in <bold>A</bold>) between test conditions when evaluated by Mahalanobis separation. Colors represent the distance, as in the scale. L: Left; R: right.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig2-figsupp5-v1.tif"/></fig><fig id="fig2s6" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 6.</label><caption><title>The majority of postcentral-intraparietal neurons code tactile receptive fields bilaterally in a mirror-symmetric manner.</title><p>We evaluated mirror-symmetric bilateral coding at the level of single neurons. We used the same basic procedure as the population case (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), although in the single-unit case, cross-validated comparisons were done per-unit. All neurons demonstrating significant modulation from baseline for at least one location (263 of 398 units; 66.1%) were included in this analysis. (<bold>A</bold>) Scatter plot comparing the consistency in touch responses to the same body side against responses across body sides. Units close to the identity line code the left and right sides with the same pattern of activity and thus in a mirror-symmetric fashion (see 'Materials and methods: Tests for mirror-symmetric neural coding of body locations: single-unit analysis'). The analysis used in this plot is depicted schematically in <bold>B–E</bold>. (<bold>B</bold>) Firing rate for an example unit over 10 trials (red dots) is shown, to touch to each indicated body part (both left and right). The black horizontal line indicates the mean response. The variance in trial-by-trial responses to each body part within a body side is low (i.e., high discriminability). Moreover, the pattern of responses on the left and right sides is closely matched (i.e., the encoding is highly generalizable across sides). (<bold>C</bold>) Conventions are as in <bold>B</bold>. In this panel, the firing rate of a unit over 10 trials (blue dots) is shown. As in <bold>B</bold>, the variance in trial-by-trial responses within each body side is low (i.e., high discriminability). However, the patterns of responses on the left and right sides are dissimilar (i.e., the encoding is poorly generalizable across sides). (<bold>D</bold>) Conventions are as in <bold>B</bold>. Green dots represent the trial responses to touch. The inter-trial variance in responses is larger than that in the top two panels (i.e., moderate discriminability). The pattern of responses between the left and right sides is moderately matched (i.e., moderate generalizability). (<bold>E</bold>) Conventions as in <bold>B</bold>. In this panel, the yellow dots represent trial responses that have a high variance (i.e., low discriminability) and are also poorly matched in patterns between the left and right sides (i.e., low generalizability). (<bold>F</bold>) Scatter plot showing four illustrative neurons. These are color-coded as in <bold>B–E</bold> and demonstrate how neurons with similar and dissimilar patterns of encoding will be arranged when their corresponding strength of encoding within a body side (R<sup>2</sup><sub>Left to Left</sub>) is compared to how well one side generalized to the other body side (R<sup>2</sup><sub>Right to Left</sub>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig2-figsupp6-v1.tif"/></fig></fig-group><p>PC-IP neurons demonstrated mirror-symmetric bilateral coding. We performed a cross-validated population correlation analysis to measure population-level similarity in the responses to each touch location (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>). In brief, the neural activation pattern elicited by touch to each body location was quantified as a vector, with each vector element capturing the mean response for a particular neuron during actual touch. These vectors were then pairwise correlated in a cross-validated manner so that the strength of correlation between any two body parts could be compared against the strength of correlation for repeated touches applied to the same body part. We found that responses to the same touch locations on the right and left sides are highly correlated, comparable to the correlation for repeated touches applied to the same body part. This result is consistent with a strong, mirror-symmetric, bilateral encoding. As expected, correlations involving the hands and the null condition were distributed about zero, consistent with a lack of systematic neural population response to these conditions. The results from the correlation analysis were similar for alternative distance metrics (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). Further, analysis of single units revealed mirror symmetry in bilateral representation for the vast majority of the population, paralleling population-level findings (<xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>).</p></sec><sec id="s2-2"><title>Tactile responses occur at short latency to bilateral stimuli</title><p>We explored PC-IP population response latency to tactile stimulation on the contralateral and ipsilateral body sides. In a variation of the basic task paradigm, we used a capacitive touch sensing probe to acquire precise measurements of the time of contact with the skin surface in order to measure the latency in neuronal response from the time of tactile stimulation. We probed latency on the bilateral cheeks and shoulders. As a control, we included both hands in the task design.</p><p>We measured latency as the time at which the response of the neural population rose above the pre-stimulus baseline activity (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The neural population response was quantified as the first principal component computed from principal component analysis (PCA) of the activity of all neurons (<xref ref-type="bibr" rid="bib16">Cunningham and Yu, 2014</xref>; <xref ref-type="bibr" rid="bib15">Cunningham and Ghahramani, 2015</xref>). The first principal component was then fit with a piecewise linear function, and latency was computed as the time the linear function crossed the baseline pre-stimulus response. Response latency was short for both body sides and slightly shorter for contralateral (right) receptive fields (50 ms) than for ipsilateral (left) receptive fields (54 ms), although this difference was not statistically significant (permutation shuffle test, p&gt;0.05). <xref ref-type="fig" rid="fig3">Figure 3A</xref> shows the time course of the first principal component relative to time of contact of the touch probe (stepped window; 2 ms window size, stepped at 2 ms, no smoothing) along with the piecewise linear fit (dashed line). A bootstrap procedure was used to find the interquartile range of latency estimates (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Tactile responses occur at short latency.</title><p>(<bold>A</bold>) Population response was quantified as the first principal component (mean ± 95% CI). Population response was computed separately for the left (blue; ipsilateral to implant) and right body sides (orange; contralateral to implant) and is shown as a function of time (2 ms window size, 2 ms step size, no smoothing). Dashed lines show piecewise linear fit used to compute latency. Transparent vertical bar shows inter-quartile latency range based on a bootstrap procedure (see <bold>B</bold>). (<bold>B</bold>) Distribution illustrating variability of latency estimates for the recorded data using a bootstrap procedure. Color code as in <bold>A</bold>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig3-v1.tif"/></fig></sec><sec id="s2-3"><title>Tactile imagery task evokes body part-specific responses congruent with actual touch</title><p>The results thus far establish that PC-IP neurons have spatially structured tactile receptive fields that are activated at short latency consistent with processing of tactile sensations. Are neurons that encode tactile sensations also recruited during tactile imagery? And if so, how might evoked neural responses compare to those arising from actual touch? To address these questions, we performed an additional experiment allowing us to compare population activity elicited during a tactile imagery task with activity elicited during actual touch to matching body parts recorded during interleaved trials. During the imagery conditions, the participant was instructed to imagine touch to the right (contralateral) cheek, shoulder, or hand with the same qualities as the actual touch stimuli the participant experienced during interleaved trials. A null condition was included as a baseline to measure neural activity when no stimulus was presented.</p><p>As with findings for actual touch, neuronal responses elicited during the tactile imagery task following the go cue (during the imagery phase) were discriminably encoded (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, cross-validated accuracy 92%). High decode accuracy is consistent with the participant’s compliance with task instructions and implies that the tactile imagery task elicited discriminative neural responses. A significant fraction of PC-IP neurons encoded actual touch to the cheeks and shoulders but not to the hands (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; χ<sup>2</sup>(1)<bold>=</bold>355.73, p&lt;0.05), consistent with the results presented in <xref ref-type="fig" rid="fig1">Figure 1</xref>. In comparison, a smaller fraction of the neuronal population was responsive to the cheek and shoulder during imagery of tactile stimuli (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Of note, a significant number of neurons were active during imagined touch to the hand (χ<sup>2</sup>(1)<bold>=</bold>188.89, p&lt;0.05), despite the hand being clinically insensate in the study participant (and despite actual touch to the hand not eliciting neuronal activation). The extent of overlap between the set of units active during actual and the tactile imagery condition is illustrated in <xref ref-type="fig" rid="fig4">Figure 4C</xref>. The degree of overlap, compared to what is expected by chance, was statistically significant (permutation shuffle test, p&lt;0.05). Results were qualitatively similar for well-isolated single units (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Postcentral-intraparietal (PC-IP) neurons encode body part-specific responses during the tactile imagery task.</title><p>(<bold>A</bold>) Average classification confusion matrix across recording sessions for body parts during tactile imagery and the baseline (null) condition. Colors represent prediction accuracy as a percentage, as in the scale. (<bold>B</bold>) Percentage of PC-IP neurons significantly modulated from baseline (mean ± 95% CI, p&lt;0.05, false discovery rate corrected, n = 838 units) split by test condition. Population results were not qualitatively affected by pooling together single and potential multi-units (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). (<bold>C</bold>) Venn diagram illustrating the number (percentage) of PC-IP neurons recorded that activated during actual and imagined touch, and their overlap. (<bold>D</bold>) Population correlation matrix depicting similarity of the population response between all test conditions. Colors represent the correlation strength, as in the scale. (<bold>E</bold>) Distribution of correlations between actual shoulder (left) and cheek (right) touch and imagined cheek/shoulder touches, with the distributions computed over different splits of the data (see 'Materials and methods: Population correlation'). L: left body, ipsilateral to implant; R: right body, contralateral to implant.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Postcentral-intraparietal (PC-IP) responses during the tactile imagery task are not qualitatively changed by pooling together single and multi-units.</title><p>(<bold>A</bold>) Percentage of the PC-IP neuronal population that demonstrated significant modulation (tuning) to each tested stimulation site (p&lt;0.05, false discovery rate corrected) when considering only high-quality single units. Within each bar, the black horizontal line represents the mean and the height of the bar represents the bootstrapped 95% CI. Blue bars represent actual touch to left-sided sites, orange bars represent actual touch to right-sided sites, and red bars represent imagined touch (to right-sided sites). (<bold>B</bold>) Similar to <bold>A</bold>, but considering potential multi-units. (<bold>C</bold>) Population correlation demonstrating the relation in encoding structure between test conditions when considering only high-quality single units. Colors represent the strength of correlation, as in the scale. (<bold>D</bold>) Similar to <bold>C</bold>, but considering potential multi-units. (<bold>E</bold>) Venn diagram illustrating the number (percentage) of PC-IP neurons recorded that activated during actual and imagined touch, and their overlap, when considering only high-quality single units. (<bold>F</bold>) Similar to <bold>E</bold>, but considering potential multi-units. N: sample size; L, ;eft; R, right.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig4-figsupp1-v1.tif"/></fig></fig-group><p>We used the population correlation measure to compare population-level neural activity across conditions (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). Neural activity during the tactile imagery task shared a neural substrate with responses evoked by actual touch: representations evoked during the imagery task and during actual touch were more similar for matching body parts than for mismatched body parts (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, permutation shuffle test, p&lt;0.05).</p></sec><sec id="s2-4"><title>Dynamic evolution of population coding between task epochs suggests multiple cognitive processes</title><p>The analyses above were restricted to the mean neuronal activity following the go cue (e.g., during actual touch or during imagery) to allow a direct comparison with the results reported for the previous paradigms. We now expand this analysis. During the tactile imagery task, the participant heard a verbal cue specifying a body part (verbal cue = ‘cheek,’ ‘hand,’ or ‘shoulder’) followed approximately 1.5 s later by a beep instructing the participant to imagine the stimulus at the cued body part on the right side of the body. This cue-delay paradigm is standard in the motor physiology literature and is used to dissociate planning from motor execution-related neural activity (<xref ref-type="bibr" rid="bib1">Aflalo et al., 2015</xref>; <xref ref-type="bibr" rid="bib72">Rosenbaum, 1983a</xref>; <xref ref-type="bibr" rid="bib51">Lecas et al., 1986</xref>; <xref ref-type="bibr" rid="bib3">Ames et al., 2019</xref>). In our case, the cue-delay was unique to the tactile imagery condition. We utilized the cue-delay task to begin to dissociate in time neural activity related to different aspects of the task.</p><p>To leverage the benefits of the cue-delay paradigm, we performed a dynamic classification analysis (500 ms windows, stepped at 100 ms). Results are shown as a matrix (<xref ref-type="fig" rid="fig5">Figure 5</xref>). In brief, the diagonal elements represent the cross-validated prediction accuracy for a specific time window. The off-diagonal elements represent how well the classifier generalizes to alternate time windows. Each row can be interpreted as quantifying how well decision boundaries established for the diagonal time windows generalize to other time windows. This analysis allows us to measure when the neuronal population represents the different body parts (the diagonal) and whether population coding is similar or distinct during the task phases (the off-diagonal). We are interested in two main phases of the task: the early portion comprised the cue and delay (cue-delay), and the later portion when the participant is actively imagining the stimulus (go/imagery). <xref ref-type="fig" rid="fig5">Figure 5A</xref> schematically illustrates the examples of possible results. The examples are meant to be illustrative and are not an exhaustive list of possibilities. The population may be discriminative exclusively during the imagery phase, during the cue-delay and imagery phases but with distinct population coding, during the cue-delay and imagery phases with identical coding, or during the cue-delay and imagery phases with partially shared and partially distinct coding. Each pattern would suggest a different interpretation of various forms of cognitive processing that may be engaged in a tactile imagery task (see 'Discussion').</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Shared and distinct coding of body parts during cue-delay and imagery epochs.</title><p>(<bold>A</bold>) Schematic illustrating possible dynamic classification patterns over epochs of the tactile imagery task. In each panel, the window used for classifier training is along the y-axis and the window used for classifier testing is along the x-axis. The start of the auditory cue (marking the onset of the cue-delay epoch) and the beep (marking the go signal for the imagery epoch) is shown as solid white lines, labeled ‘Cue’ and ‘Go.’ (<bold>B</bold>) Dynamic classification analysis results for the imagined touch test conditions with conventions as in <bold>A</bold>. The colors represent prediction accuracy values (as percentage), as in the scale. (<bold>C</bold>) Illustration of distinct and shared neuronal responses between the cue/delay and imagery epochs for the boxed window of <bold>B</bold>. Shared response illustrated with cross-validated, classification generalization accuracy (blue, mean with 95% confidence interval computed across sessions). Distinct response illustrated with cross-validated Mahalanobis distance (gray, mean with 95% confidence interval computed across sessions). The dashed vertical line marks the onset of the imagery epoch. The dashed horizontal line marks chance classification accuracy. (<bold>D</bold>) Dynamic classification matrices were constructed separately for all selective units. The first three principal components (PCs) of the dynamic classification matrices of single-unit activity are shown, along with the fractional variance explained by each. The mean activity of all neurons within the PC is shown within each panel, color-coded by PC weights. Plot conventions are as in <bold>A</bold> and <bold>B</bold>. s: seconds.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig5-v1.tif"/></fig><p>The results of our classification analysis (<xref ref-type="fig" rid="fig5">Figure 5B</xref>) are most consistent with body part selectivity during both the cue-delay and imagery phases, with partially shared and partially distinct population coding of the body parts between phases. The shared component is evident in the significant generalization accuracy in the off-diagonal elements, a representative row of which is shown in <xref ref-type="fig" rid="fig5">Figure 5C</xref> (blue portion) where cross-validated accuracy generalizes from approximately 70% within the cue-delay phase to approximately 60% during the imagery phase. The distinct population activity between phases is highlighted by a cross-validated Mahalanobis distance that provides a sensitive measure of change that is masked by the discretization process of classification (expanded rationale in 'Materials and methods: Temporal dynamics of population activity'). The findings demonstrate a significant change between the activity patterns in the cue-delay and imagery epochs (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, gray).</p><p>To further clarify the properties of individual units, we conducted a dynamic classification analysis for each recorded unit. This resulted in the same matrices described above, but now each matrix represents how information coding evolves for a single unit. Time-resolved classification data were then analyzed using PCA, the first three principal components of which are shown in <xref ref-type="fig" rid="fig5">Figure 5D</xref>. A majority of variance (26%) is explained by units that are active during both epochs with similar coding. Coding during the imagery epoch exclusively or during the cue-delay epoch exclusively explained an additional 9% of variance.</p></sec><sec id="s2-5"><title>Cognitive processing during the cue-delay and imagery epochs of the tactile imagery task shares a neural substrate with that for actual touch</title><p>Finally, we look at how encoding patterns through time generalize between the tactile imagery and actual touch conditions. A dynamic correlation analysis was applied both within and across the imagery and actual touch condition types (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). In brief, the neural activation pattern elicited to each body location was quantified as a vector, and these vectors were concatenated to form a population response matrix for each condition type and for each point in time. These vectors were then pairwise correlated in a cross-validated manner so that the strength of correlation between conditions could be assessed relative to the strength of correlation within condition and across time. We found that the neural population pattern that defined responses to actual touch was similar to population responses both during the cue-delay or the imagery phases of the imagery task (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). This implies that cognitive processing prior to active imagery as well as during imagery shares a neural substrate with actual touch. Sample neuronal responses that help to understand single unit and population behavior are shown in <xref ref-type="fig" rid="fig6">Figure 6B</xref>.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Cue-delay and imagery-evoked neural activity shares a neural substrate with actual touch.</title><p>(<bold>A</bold>) Within- and across-condition dynamic, cross-validated correlation analysis demonstrating a shared neural substrate between imagined and actual tactile sensations. Each panel shows how the neural population response at one slice of time compares to all other slices of time for the two formats being compared (x- and y-axis labels). Correlation magnitude is indicated by color as in the bar. The start of the auditory cue (marking the onset of the cue-delay epoch) and the beep (marking the go signal for the imagery epoch) is shown as solid white lines, labeled ‘Cue’ and ‘Go.’ (<bold>B</bold>) Representative neuronal responses illustrating selectivity during actual and imagined sensations. Each panel shows the firing rate (in Hertz, mean ± SEM) through time (vertical lines signal onset of cue/delay and go phases as labeled). Each column illustrates the responses of the same unit to tactile imagery of the right side (top), actual touch on the right side (middle), and actual touch on the left side (bottom) for matched body parts.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-fig6-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have previously reported that human PPC encodes many action variables in a high-dimensional and <italic>partially mixed</italic> representation (<xref ref-type="bibr" rid="bib2">Aflalo et al., 2020</xref>; <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>; <xref ref-type="bibr" rid="bib94">Zhang et al., 2020</xref>). This architecture allows many parameters to be encoded by a small number of neurons, while still enabling meaningful relationships between variables to be preserved. Here, we show that neurons recorded from the same electrode array in the same clinical trial participant are also selective for bilateral touch at short latency. Responses to actual touch are organized around body part, sharing population representations between the left and right sides. Additionally, a tactile imagery task elicits body part-specific responses that share a neural substrate with that for actual touch. Furthermore, we found neural selectivity during the active imagery epoch as well as during the cue and delay epochs that precede imagery. The distinguishable population activity during these different phases indicates an encoding of multiple cognitive processes that may include semantic association, memory, attention, sensory anticipation, or imagery per se.</p><sec id="s3-1"><title>Human PC-IP encodes tactile stimuli with large and bilateral receptive fields</title><p>Cortical processing of somatosensory information begins in the anterior portion of the parietal cortex (APC) within four cyto-architectonically defined areas termed BA 3a, 3b, 1, and 2 (<xref ref-type="bibr" rid="bib46">Kaas, 1983</xref>; <xref ref-type="bibr" rid="bib45">Kaas et al., 1979</xref>; <xref ref-type="bibr" rid="bib86">Sur et al., 1980</xref>). Each of these four sub-regions represents primarily contralateral somatosensory information (<xref ref-type="bibr" rid="bib24">Ferezou et al., 2007</xref>; <xref ref-type="bibr" rid="bib29">Geyer et al., 2000</xref>; <xref ref-type="bibr" rid="bib41">Iwamura, 1998</xref>; <xref ref-type="bibr" rid="bib43">Jiang et al., 1997</xref>; <xref ref-type="bibr" rid="bib74">Ruben et al., 2001</xref>; <xref ref-type="bibr" rid="bib80">Schnitzler et al., 1995</xref>; <xref ref-type="bibr" rid="bib88">Tamè et al., 2016</xref>, <xref ref-type="bibr" rid="bib87">Tamè et al., 2015</xref>). Moving from the APC to superior regions of the PPC, spatially localized and segregated sensory representations become progressively more integrated, resulting in neuronal receptive fields that are larger, frequently encompassing multiple segments of the body (<xref ref-type="bibr" rid="bib18">de Lafuente and Romo, 2006</xref>; <xref ref-type="bibr" rid="bib77">Sakata et al., 1973</xref>; <xref ref-type="bibr" rid="bib12">Burton and Sinclair, 1990</xref>; <xref ref-type="bibr" rid="bib23">Dykes, 1983</xref>; <xref ref-type="bibr" rid="bib28">Garraghty et al., 1990</xref>; <xref ref-type="bibr" rid="bib64">Pei et al., 2009</xref>; <xref ref-type="bibr" rid="bib65">Pons et al., 1987</xref>; <xref ref-type="bibr" rid="bib76">Saal et al., 2015</xref>; <xref ref-type="bibr" rid="bib85">Soso and Fetz, 1980</xref>) including bilateral encoding (<xref ref-type="bibr" rid="bib80">Schnitzler et al., 1995</xref>; <xref ref-type="bibr" rid="bib88">Tamè et al., 2016</xref>, <xref ref-type="bibr" rid="bib87">Tamè et al., 2015</xref>; <xref ref-type="bibr" rid="bib95">Zhu et al., 2007</xref>). This process of integration is thought to play an integral role in sensory processing for the guidance of movement (<xref ref-type="bibr" rid="bib31">Graziano et al., 2000</xref>; <xref ref-type="bibr" rid="bib60">Mulliken et al., 2008</xref>). Our results, demonstrating that PPC neurons encode mirror-symmetric spatially structured tactile receptive fields at short latency, are consistent with these prior reports. They further provide the first single neuron evidence supporting a role of human PPC in tactile processing. As hypothesized, when comparing the current results with our prior reports, we find that the same PPC neuronal population engaged by high-level motor cognition also encodes actual tactile sensations, providing a common neural substrate for sensory and motor processing (<xref ref-type="bibr" rid="bib2">Aflalo et al., 2020</xref>, <xref ref-type="bibr" rid="bib1">Aflalo et al., 2015</xref>; <xref ref-type="bibr" rid="bib78">Sakellaridi et al., 2019</xref>).</p></sec><sec id="s3-2"><title>Short latency tactile responses</title><p>In NHPs, reported latency to touch responses in primary somatosensory cortex (S1) from contralateral touch ranges between 19 and 23 ms (<xref ref-type="bibr" rid="bib69">Reed et al., 2010</xref>; <xref ref-type="bibr" rid="bib90">Vázquez et al., 2012</xref>). PPC response latencies to touch are less clear, but neurons in the lateral intraparietal area within NHP PPC orient to visual stimuli at a mean latency of approximately 45 ms (<xref ref-type="bibr" rid="bib9">Bisley et al., 2004</xref>). A recent human-invasive electrocorticographic study reported mean latencies to visual response of approximately 60 ms in PPC (<xref ref-type="bibr" rid="bib70">Regev et al., 2018</xref>) similar to the mean response latencies to visual stimuli within the occipital cortex (<xref ref-type="bibr" rid="bib9">Bisley et al., 2004</xref>; <xref ref-type="bibr" rid="bib70">Regev et al., 2018</xref>). Our own response latency to actual touch of ~50 ms compares well with these data and is consistent with rapid somatosensory processing within PPC for updating internal estimates of the body (<xref ref-type="bibr" rid="bib31">Graziano et al., 2000</xref>; <xref ref-type="bibr" rid="bib60">Mulliken et al., 2008</xref>).</p></sec><sec id="s3-3"><title>Tactile imagery dynamically invokes multiple cognitive processes in human PC-IP that share a neural substrate with actual touch</title><p>In motor neurophysiology, neural activity related to planning and execution is dissociated in time by introducing a delay between the cue instructing movement and the movement in response to the cue (<xref ref-type="bibr" rid="bib51">Lecas et al., 1986</xref>; <xref ref-type="bibr" rid="bib73">Rosenbaum, 1983b</xref>). We have previously found that such distinctions between planning and execution are preserved during motor imagery paradigms in tetraplegic individuals (<xref ref-type="bibr" rid="bib1">Aflalo et al., 2015</xref>). Here, a similar paradigm allowed temporal dissociation in cognitive processing during tactile imagery. Single units demonstrated three dominant response profiles (<xref ref-type="fig" rid="fig5">Figure 5D</xref>): (1) a shared selectivity pattern between the cue-delay and imagery epochs, consistent with cognitive engagement during all phases of the imagery task; (2) selectivity exclusively during the cue-delay epoch but not the imagery epoch; and (3) selectivity exclusively during the imagery epoch but not the cue-delay epoch. In a previous study, we found similarly heterogeneous responses during the cue, delay, and imagery epochs for imagined hand grasp shapes (<xref ref-type="bibr" rid="bib50">Klaes et al., 2015</xref>). These single-unit temporal selectivity profiles provide a basis for the population-level findings of generalization in classification results between the cue-delay and imagery epochs (<xref ref-type="fig" rid="fig5">Figure 5B,C</xref>) but also a separation in neural state-space between these epochs (<xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p><p>The tactile imagery task evoked body part-specific cognitive activity that shared a neural substrate with actual touch within the PC-IP. Activity during imagined touch to the cheek, for example, was more similar in representation to actual touch to the cheek than to actual touch to the shoulder, and vice versa. Interestingly, the overlapping neural representations between actual touch and those elicited during imagery were not limited to the stimulus phase (actual touch and imagery) itself, but also extended to the cue-delay phase of the imagery task. This overlap echoes our recent findings for shared neural representations between imagined and attempted actions, as well as for shared neural representations between observed actions and action verbs (<xref ref-type="bibr" rid="bib2">Aflalo et al., 2020</xref>; <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>). These studies are consistent with views in which cognition recruits sensorimotor cortical regions (<xref ref-type="bibr" rid="bib8">Binder and Desai, 2011</xref>; <xref ref-type="bibr" rid="bib57">Meyer and Damasio, 2009</xref>; <xref ref-type="bibr" rid="bib58">Miyashita, 2019</xref>; <xref ref-type="bibr" rid="bib63">Patterson et al., 2007</xref>; <xref ref-type="bibr" rid="bib68">Ralph et al., 2017</xref>). We acknowledge that, as with all passive neural recording studies, ours cannot establish a causal role for these neurons in tactile cognition. Understanding the unique contribution of PC-IP neurons within the larger network of brain regions engaged in cognitive touch processing remains to be explored. Nonetheless, our current results provide the first human single-unit evidence of a shared neural substrate between tactile imagery and actual touch.</p><p>One concern with the use of all imagery experiments is that participant compliance cannot be externally validated. This raises the possibility that the participant is not performing the task or is performing the task in an unexpected manner. We think this is unlikely for three reasons. First, the subject by the time of this study was well versed in performing cue-delayed paradigms in the motor domain using both motor imagery and overt movements. In <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>, the participant’s performance of overt movements was perfect: the participant performed both the correct cued action and the action at the go cue (i.e., no movements began prior to the go cue as validated by measurements of electromyogram activity; <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>). Second, our current pattern of results that includes stable and accurate body part-specific encoding within the cue-delay and imagery epochs, with a shift between epochs, is consistent with the participant performing the task as instructed. At a minimum, it is consistent with the participant’s performing two distinct cognitive operations during the two primary phases of the task with remarkable trial-to-trial consistency. Third, evidence for a shared neural substrate between the actual touch and imagined touch conditions indicates that selective responses during the imagery task are related to tactile cognition.</p></sec><sec id="s3-4"><title>What does neural processing within human PC-IP during tactile imagery represent?</title><p>While our task identifies dynamic engagement of multiple cognitive processes during tactile imagery, it is inadequate to precisely define the cognitive correlates of the observed neural activity. A number of cognitive processes may be engaged during the tactile imagery task including preparation for and/or execution of imagery, engagement of an internal model of the body, semantic processing of the auditory cue, allocation of attention to the cued body location or nature of the upcoming stimulus, and/or sensory memory for the corresponding actual sensation applied by the experimenter.</p><p>The precise neural correlates of tactile imagery are unknown, but evidence suggests that both imagined and actual touch may engage the same internal mental representations, or internal models of the body (<xref ref-type="bibr" rid="bib49">Kilteni et al., 2018</xref>; <xref ref-type="bibr" rid="bib79">Schmidt and Blankenburg, 2019</xref>). Support for such a shared representation comes largely from the parallel domain of motor imagery (<xref ref-type="bibr" rid="bib49">Kilteni et al., 2018</xref>). Imagined and actual movements show similarity at the behavioral (e.g., similar duration), physiological (e.g., alteration of heart rate), and neural levels (e.g., activating the same neural substrates) (<xref ref-type="bibr" rid="bib21">Decety et al., 1993</xref>, <xref ref-type="bibr" rid="bib20">Decety et al., 1991</xref>, <xref ref-type="bibr" rid="bib19">Decety et al., 1989</xref>; <xref ref-type="bibr" rid="bib22">Decety and Michel, 1989</xref>; <xref ref-type="bibr" rid="bib52">Lotze and Halsband, 2006</xref>; <xref ref-type="bibr" rid="bib61">Papaxanthis et al., 2002a</xref>, <xref ref-type="bibr" rid="bib62">Papaxanthis et al., 2002b</xref>). These studies have been interpreted as evidence that imagined movements are the simulation of the internal models that track the state of our bodies during movement (<xref ref-type="bibr" rid="bib42">Jeannerod and Decety, 1995</xref>). In powerful support of such a notion, we have shown that populations of neurons in human PPC code motor imagery and overt actions in highly similar ways (<xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>). The domain of tactile imagery has been less studied in comparison. However, relevant to the current paper, behavioral evidence has demonstrated that internal models of motor actions can influence sensory perception of touch (<xref ref-type="bibr" rid="bib49">Kilteni et al., 2018</xref>). Further, human neuroimaging studies suggest that overlapping brain regions are activated during both imagined and actual touch, including the PPC (<xref ref-type="bibr" rid="bib79">Schmidt and Blankenburg, 2019</xref>; <xref ref-type="bibr" rid="bib53">Lucas et al., 2015</xref>; <xref ref-type="bibr" rid="bib92">Wise et al., 2016</xref>). This points to not only a shared substrate for the representation of imagined and actual touch, but also to their likely engagement of similar internal models. Because an internal model may be involved in anticipatory or planning activity (and/or related to imagery), it could at least partly explain the pre-stimulus (post-cue, pre-imagination) neural activity we observed.</p><p>Another possibility is that the neural activity following the auditory cue in our study represents semantic processing of the cued word. Evidence suggests that a network of brain regions is activated in processing word meaning, including those involved in processing their higher-order sensory aspects, or motor intentions such as PPC (<xref ref-type="bibr" rid="bib8">Binder and Desai, 2011</xref>; <xref ref-type="bibr" rid="bib57">Meyer and Damasio, 2009</xref>; <xref ref-type="bibr" rid="bib68">Ralph et al., 2017</xref>; <xref ref-type="bibr" rid="bib39">Huth et al., 2016</xref>; <xref ref-type="bibr" rid="bib56">Martin, 2016</xref>; <xref ref-type="bibr" rid="bib67">Pulvermüller, 2013</xref>). Within this framework, semantic processing of the auditory cue (e.g., instructing imagined touch to the cheek) may engage the same population of neurons responsible for the higher-level processing of touch, consistent with our data. In support, we recently reported that action verbs and visually observed actions share a common neural substrate in the same PPC neural populations reported in the current study (<xref ref-type="bibr" rid="bib2">Aflalo et al., 2020</xref>). Results were consistent with automatic semantic processing as distinct from imagery. The current findings would extend possible semantic processing to the tactile domain and demonstrate neuronal selectivity for auditory cues (in addition to written text used in the previous study).</p><p>Hearing an auditory cue can direct the study participant’s attention to the cued body part. Attention to a stimulated body part has been shown to enhance sensory processing in human neuroimaging (<xref ref-type="bibr" rid="bib44">Johansen-Berg et al., 2000</xref>; <xref ref-type="bibr" rid="bib34">Hämäläinen et al., 2000</xref>; <xref ref-type="bibr" rid="bib66">Puckett et al., 2017</xref>; <xref ref-type="bibr" rid="bib71">Roland, 1981</xref>). In neurophysiological studies, this manifests as a gain in stimulus responses (<xref ref-type="bibr" rid="bib10">Boynton, 2009</xref>; <xref ref-type="bibr" rid="bib91">Williford and Maunsell, 2006</xref>). However, during the imagery task, no stimulus was delivered to the participant. An attention account of our data would require that attention result in highly discriminable patterns of activity without a sensory stimulus (or pre-stimulus). Most studies of pre-stimulus attention report modest modulation of baseline neural activity (<xref ref-type="bibr" rid="bib10">Boynton, 2009</xref>; <xref ref-type="bibr" rid="bib91">Williford and Maunsell, 2006</xref>; <xref ref-type="bibr" rid="bib84">Snyder et al., 2018</xref>). However, the failure to find pre-stimulus effects may be the consequence of insensitive analysis techniques: indeed, recent single neuron work in NHP visual cortical area 4 (V4) demonstrated discriminable coding for the locus of attention prior to stimulus presentation and, further, that the pre-stimulus activation patterns were systematically related to the post-stimulus response patterns (<xref ref-type="bibr" rid="bib84">Snyder et al., 2018</xref>). These recent results suggest that attention may be decodable elsewhere, and they match the results presented in this paper. It is also consistent with what we have previously described as <italic>partially mixed</italic> selectivity (<xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>; <xref ref-type="bibr" rid="bib94">Zhang et al., 2020</xref>). If our results are interpreted within the framework of attention, our current findings are inconsistent with a simple gain-like mechanism for attention, but instead suggest a richer mechanism by which information is selectively enhanced for further processing (<xref ref-type="bibr" rid="bib84">Snyder et al., 2018</xref>).</p><p>Our task was not designed to tease apart the different possible cognitive correlates of the observed neural activity engaged during imagery. We think the temporal dynamics of the signal indicate that multiple cognitive process may be engaged throughout the course of the task. The above cognitive phenomena may each independently engage the same neural population as distinct phenomena or may be distinct processes that nonetheless engage the same underlying neural substrate.</p></sec><sec id="s3-5"><title>PC-IP and plasticity following spinal injury</title><p>The extent to which the human PPC reorganizes following SCI is unknown. Lesion studies in NHPs suggest that BA 3b and 3a, 1 and 2, show altered sensory maps following SCI in a manner dependent on thalamic input from the afferent sensory pathways such as the dorsal column-medial lemniscus system (<xref ref-type="bibr" rid="bib89">Tandon et al., 2009</xref>). With mid-cervical lesions, for instance, there is an initial loss of BA 3b hand representations and a slight expansion in face representation at approximately 2 years (<xref ref-type="bibr" rid="bib89">Tandon et al., 2009</xref>; <xref ref-type="bibr" rid="bib59">Mohammed and Hollis, 2018</xref>). Although significant axonal sprouting has been demonstrated to occur at the site of deafferentation in the spinal cord, with increased projections to brainstem nuclei, the changes observed in the somatosensory cortex are significantly smaller (<xref ref-type="bibr" rid="bib89">Tandon et al., 2009</xref>; <xref ref-type="bibr" rid="bib59">Mohammed and Hollis, 2018</xref>). Moreover, the reorganization in higher-order somatosensory centers such as the secondary somatosensory cortex is even more restricted than in BA 3b (<xref ref-type="bibr" rid="bib59">Mohammed and Hollis, 2018</xref>). Similar stability in the topography of the somatosensory cortex has been identified in human subjects that have suffered limb amputations. In these amputees, there is a preserved digit map within the primary somatosensory cortex (<xref ref-type="bibr" rid="bib48">Kikkert et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">Makin and Flor, 2020</xref>).</p><p>The results of our experiments suggest significant stability in tactile somatosensory architecture within the PPC. A substantial fraction of the neuronal population responded to imagined touch to the hand, while there was no significant response to actual touch (insensate in the study participant). The response during the imagery task lends support to the idea that despite the lack of peripheral input from the hand due to the participant’s SCI, the brain maintains an internal representation of tactile sensations (<xref ref-type="bibr" rid="bib54">Makin and Bensmaia, 2017</xref>). The findings that intracortical microstimulation produces discernible tactile perceptions from insensate body regions further reinforce a maintained representation of somatosensation after deafferentation (<xref ref-type="bibr" rid="bib6">Armenta Salas et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Flesher et al., 2016</xref>). These findings will prove useful for bidirectional neural prostheses. We acknowledge that while additional work probing cortical reorganization following SCI is necessary to fully understand its electrophysiological consequences, our results provide insight into the maintenance of basic tactile processing within the human PC-IP, after SCI.</p></sec><sec id="s3-6"><title>Conclusion</title><p>Multiple lines of evidence indicate a critical role for the human PPC in the integration of convergent multimodal sensory information to enable complex cognitive processing and motor control. To date, however, its processing of somatosensory information at the single neuron level has remained fundamentally unexplored. In the unique opportunity of a BMI clinical trial, we examined the neural encoding of actual and cognitive touch within the human PC-IP. We found that local populations of PC-IP neurons within a 4 × 4 mm patch of cortex encode bilateral touch sensations to all tested body regions above the level of the participant’s injury at short latency. A significant fraction of PC-IP neurons responded during the imagined touch condition with matching sensory fields to actual touch. The activity in the delay period of the task, between cueing and imagining touch, may reflect cognitive processes including tactile semantics, sensory anticipation, attention, as well as active imagery. Together, our results provide the first single-unit evidence of touch processing within the human PC-IP and identify a putative substrate for the encoding of cognitive representations of touch, thus far untested in animal models.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type (species) or <break/>resource</th><th>Designation</th><th>Source or reference</th><th>Identifiers</th><th>Additional <break/>information</th></tr></thead><tbody><tr><td>Software, algorithm</td><td valign="top">MATLAB</td><td valign="top">MathWorks, MATLAB R2019b</td><td valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001622">SCR_001622</ext-link></td><td/></tr><tr><td>Software, algorithm</td><td valign="top">Psychophysics toolbox</td><td valign="top">Psychophysics toolbox PTB3,<ext-link ext-link-type="uri" xlink:href="http://psychtoolbox.org/">http://psychtoolbox.org/</ext-link></td><td valign="top">RRID: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001622">SCR_001622</ext-link></td><td/></tr><tr><td>Other</td><td valign="top">Neuroport</td><td valign="top">Neuroport Recording System with Utah array implant, <ext-link ext-link-type="uri" xlink:href="https://blackrockmicro.com/">https://blackrockmicro.com/</ext-link></td><td valign="top"/><td/></tr><tr><td>Other</td><td>Capacitive Touch Sensory</td><td>Adafruit Capacitive Touch HAT for Raspberry Pi, <ext-link ext-link-type="uri" xlink:href="https://www.adafruit.com/product/2340">https://www.adafruit.com/product/2340</ext-link></td><td>Product ID: 2340</td><td/></tr></tbody></table></table-wrap><sec id="s4-1"><title>Study participant</title><p>The study participant, NS, is a 60-year-old tetraplegic female with a motor complete SCI at cervical level C3-4 that she sustained approximately 10 years prior to this report. She has intact motor and sensory function to the level of her bilateral deltoids. NS was implanted with two 96-channel Neuroport Utah electrode arrays (Blackrock Microsystems model numbers 4382 and 4383) 6 years post-injury for an ongoing BMI clinical study. Implants were made in the left hemisphere as human neuroimaging studies have typically reported stronger coding of intention-related activity in left versus right PPC (<xref ref-type="bibr" rid="bib26">Gallivan et al., 2011a</xref>, <xref ref-type="bibr" rid="bib27">Gallivan et al., 2011b</xref>). She consented to the surgical procedure as well as to the subsequent clinical studies after understanding their nature, objectives, and potential risks. All procedures were approved by the California Institute of Technology (IRB #18–0401), University of California, Los Angeles (IRB #13–000576-AM-00027), and Casa Colina Hospital and Centers for Healthcare (IRB #00002372) Institutional Review Boards.</p></sec><sec id="s4-2"><title>Implant methodology and physiological recordings</title><p>The electrode implant methodology in NS has been previously published (<xref ref-type="bibr" rid="bib1">Aflalo et al., 2015</xref>; <xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>; <xref ref-type="bibr" rid="bib94">Zhang et al., 2020</xref>). One array was implanted at the junction of the left IPS with the left post-central sulcus in what we refer to as PC-IP. The other was implanted in the left superior parietal lobule (SPL). Implant locations were determined based on preoperative fMRI. The participant performed imagined hand reaching and grasping movements during a functional MRI scan to localize limb and hand areas within this region. Following localization, a craniotomy was performed on August 26, 2014. The PC-IP electrode array was implanted over the hand/limb region of the PPC within the dominant (left) hemisphere, at Talairach coordinates [−36 lateral, 48 posterior, 53 superior]. In the weeks following implantation, it was found that the SPL implant did not function. Although this electrode array was not explanted, only data recorded from the PC-IP implant were used in this study.</p></sec><sec id="s4-3"><title>Experimental setup</title><p>All experimentation procedures were conducted at Casa Colina Hospital and Centers for Healthcare. Participant NS was seated in a motorized wheelchair in a well-lit room. Task procedures are presented in detail in the sections below. For most tasks, however, one experimenter stood directly behind the participant and was responsible for providing tactile stimuli to the participant. A 27-inch LCD monitor was positioned behind NS (visible to the experimenter but not to the subject) to cue the experimenter for the presentation of a stimulus. Cue presentation was controlled by the psychophysics toolbox (<xref ref-type="bibr" rid="bib11">Brainard, 1997</xref>) for MATLAB (MathWorks) (<xref ref-type="bibr" rid="bib11">Brainard, 1997</xref>).</p></sec><sec id="s4-4"><title>Data collection and unit selection</title><p>Data were collected over a period of approximately 8 months in the fourth year after NS was implanted. Study sessions were conducted between two and three times per week, lasting approximately 1 hr each. Neural activity recorded from the array was amplified, digitized, and sampled at 30 kHz from the electrodes using a Neuroport neural signal processor (NSP). The system has received Food and Drug Administration (FDA) clearance for less than 30 days of recording. We received an investigational device exemption (IDE) from the FDA (IDE #G120096, G120287) to extend the implant duration for the purposes of the BMI clinical study. Putative neuron action potentials were detected at threshold crossings of −3.5 times the root-mean-square of the high-pass filtered (250 Hz) full bandwidth signal. Each individual waveform was made of 48 samples (1.6 ms) with 10 samples prior to triggering and 38 samples after. Single- and multi-unit activity was sorted using Gaussian mixture modeling on the first three principal components of the detected waveforms. The details of our sorting algorithm have been previously published by our group (<xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>). To minimize noise and low-firing effects in our analyses, we used as a selection criterion for units, a mean firing rate greater than 0.5 Hz and a signal-to-noise ratio (SNR) greater than 0.5. We defined SNR for the waveform shapes as the difference between their mean peak amplitude and the baseline amplitude, divided by the variability in the baseline.</p><p>Each recording session was assumed to be independent in reporting the total number of units. However, it is likely that some fraction of units recorded on separate days are resamples of the same neuron, given that recordings for different days were made from the same array. Neural waveforms are largely a function of the geometry of the electrode with respect to the neuron, and not a unique signature that can be used to characterize a neuron. Thus, it is impossible to determine whether waveforms collected on separate days represent the same or different neurons. However, the degree to which recordings change from one day to the next can be taken as a general indicator of whether there may be some daily change in which neurons are recorded from. In other words, if the set of waveforms across the array are the exact same from one day to the next, it is likely that we are recording from the same neurons. Conversely, if the waveforms change substantially from one day to the next, it is likely that we are recording from, at least partially, distinct populations of neurons. We performed two analyses to quantify changes in neural recordings across days. In the first, more conservative of the two analyses, we compare the number of waveforms on each channel between days. If the number of waveforms on a single channel changes, then this is strong evidence that there has been some substantial change in the neural recordings. By this measure, an average of 29 ± 4.2% of channels change across days. In the second analysis, we used a permutation shuffle test to measure whether the recorded waveforms on the same channel were more similar than the waveforms across different channels. By this assessment, 58 ± 8% of neurons were distinct from one day to another. These values indicate that there was some degree of neural turnover from one day to the next.</p><p>Well-isolated single and multi-units were pooled across recording sessions. To ensure that such pooling did not bias the conclusions of this paper, we performed core analyses within this paper on single units alone, potential multi-units alone, and all units together. The results of these analyses, shown as supplemental figures for key results, generally demonstrate that our results were robust to the pooling of all sorted units together. For the separation of spike sorted units into high-quality single and multi-units, we used as a threshold the mean across all units of the base-10 logarithm of their cluster isolation distances, based on a previously described method (<xref ref-type="bibr" rid="bib93">Zhang et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Harris et al., 2016</xref>). Sorted units for which the cluster isolation distance was above this measure were considered single units, and those with a distance below this threshold were considered potential multi-units. Findings were robust to the exact choice of isolation distance threshold.</p><p>For measurements of neural latency to stimulus response (please refer to the task descriptions below for more information), a custom capacitive probe was used to record the exact time of tactile stimulation. This probe was built using a Raspberry Pi 2B and Adafruit Capacitive Touch Hat (Adafruit product ID 2340). The digital output (a binary output for touch or no touch) was transmitted through a BNC cable into the NSP at an analog signal sampling rate of 2 kHz.</p></sec><sec id="s4-5"><title>Task procedures</title><p>We used several experimental paradigms to probe various features of actual and imagined touch representations in the PC-IP. In each paradigm, the participant was instructed to keep her eyes closed. The basic task structure comprised three phases. Each trial began with the presentation of a cue to the experimenter (or an auditory cue in the tactile imagery condition, see specific task description below), 1.5 s in duration, indicating the stimulus (e.g., touch NS’s left cheek). This was followed by a brief delay, 1 s in duration. Then written text appeared on the screen to signal the experimenter to present the instructed stimulus, for 3 s (in the tactile imagery paradigm, a beep indicated the ‘go’ signal for the participant). Exact time intervals varied depending on task. Trials were pseudorandomly interleaved; all conditions were necessarily required to be performed at least once before they were repeated. In tasks in which both left and right body sides (ipsilateral and contralateral to the implant, respectively) were tested, stimuli were delivered to one body side at a time.</p></sec><sec id="s4-6"><title>Neural responsiveness to touch</title><p>This task variant explored neuronal responsiveness and selectivity to actual touch to body parts (receptive fields) with preserved somatosensory input (above the level of SCI). Body parts tested included the forehead, vertex of the head, left and right back of the head, left and right cheeks, left and right sides of the neck, and the dorsal surfaces of the left and right shoulders. As controls, the left and right hands (clinically insensate) and a null condition (no stimulus presentation) were also included. Actual touch stimuli were presented to each body part as finger rubs by the experimenter at approximately one per second. The experimenters’ fingertips were used to provide touch stimuli over an approximately 3 × 5 cm patch of skin on each tested body part. Stimuli to the left and right body sides were delivered on separate trials to evaluate each side independently. To ensure that any neural activity observed arose from actual touch and not from observed touch or other stimuli, NS was instructed to close her eyes throughout the task. She additionally wore ear plugs to block auditory input. This task was performed on four separate days. On each day, 10 trials per condition were conducted. In total, we recorded from 398 sorted units on four separate testing days.</p></sec><sec id="s4-7"><title>Neural response latency</title><p>The purpose of this task was to determine the latency of neural response to actual touch for the left and right sides of the body. Tested regions included the left and right cheeks, the left and right shoulders, and as controls, the left and right hands (insensate). Actual touch stimuli were presented as in the task above. Instead of finger rubs, however, a capacitive touch probe was used to enable precise delineation of the actual time of contact (touch) before the onset of a neural response. This task was performed on eight separate days, with eight trials per condition in each run of the task. In total, we recorded from 838 sorted units.</p></sec><sec id="s4-8"><title>Receptive field size</title><p>This task aimed to estimate the size of neuronal receptive fields to actual touch. Neural responses to nine equally spaced points were evaluated, 2 cm apart, along a straight line from NS’s right cheek to her neck (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Only the right side (contralateral to the implant) was tested in this task. The first of these nine points was on the malar eminence, and the ninth point was on the neck as shown. In addition to the nine points, a null condition (no stimulus presentation) was also included. Stimuli were presented via a paintbrush (3 mm round tip) gently brushed against each location, at a frequency of one brush per second. Touch was restricted to a small region of approximately 0.5 cm (parallel to test sites) by 2.5 cm (perpendicular to the test sites) immediately above the marked points shown in panel A of <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>. The paintbrush was employed to deliver spatially localized sensations without accompanying skin distortion that could mechanically stimulate nearby sensory fields. Data were recorded on six separate days. On each day, 10 trials of each condition were tested. In total, we recorded from 585 sorted units.</p></sec><sec id="s4-9"><title>Engagement during tactile imagery</title><p>This task was intended to establish whether PC-IP neurons are engaged by tactile imagery and whether neural patterns evoked by cognitive processing of imagined touch and actual touch share a common neural substrate (e.g., activate the same population of neurons in similar ways). In this variant, the participant was presented with either actual touch stimuli or instructed to imagine the sensation of being touched. NS was instructed to keep her eyes closed throughout. Actual stimuli were cued to the experimenter with written words that appeared on the monitor. Because the participant’s eyes were closed, the participant did not receive any information about the body part that would be stimulated prior to experiencing the touch. The cue was followed by a 1 s delay, and then at the sound of a beep (the ‘go’ signal), rubs at 1 Hz were presented with the capacitive touch probe to either the left or right cheeks, shoulders, or hands. During imagined touch trials, an auditory cue was presented to NS instructing her to imagine being touched on her right cheek, shoulder, or hand. The auditory cue consisted of a voice recording of the words ‘cheek,’ ‘hand,’ or ‘shoulder’ with cue duration of approximately 0.5 s. After a 1 s delay, at the sound of the beep, NS imagined touch to the cued body part. We asked the participant to imagine the sensations as alternating 1 Hz rubbing motions similar to what she actual during actual touch trials. A null condition (without actual or imagined touch), not preceded by an auditory cue, was used to establish a baseline neural response. Data were recorded on eight separate days. Eight trials of each condition were performed on each testing day. In total, we recorded from 838 sorted units.</p></sec><sec id="s4-10"><title>Quantification and statistical analysis</title><p>In the analysis of data from the various task paradigms used in this study, we utilized several statistical methods. Some were specific for certain tasks, but others were applicable to multiple sets of data from the different paradigms. For ease of reference, we have described all methods together in this section. Where necessary, we provide specific examples from tasks to help illustrate their use in this paper. Unless explicitly noted, all recorded units for a given task were used in the statistical analyses pertaining to that task.</p><sec id="s4-10-1"><title>Linear analysis (relevant for <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig4">4</xref>, and for <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>, <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>, and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>)</title><p>To determine whether a neuron was tuned (i.e., differentially modulated to touch locations), we fit a linear model that describes firing rate as a function of the neuron’s response to each touch location. Neuronal responses were summarized as the mean firing rate computed between 0.5 and 2.5 s after stimulus presentation onset. The starting time of 0.5 s was chosen to minimize the influence of variable experimenter delay in presenting the stimulus. The baseline response was summarized as the mean firing rate during the 1.5 s window before the stimulus presentation cue. The linear equation is written as<disp-formula id="equ1"><mml:math id="m1"><mml:mi>F</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf1"><mml:mi>F</mml:mi><mml:mi>R</mml:mi></mml:math></inline-formula> is the firing rate, <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the vector indicator variable for touch location <inline-formula><mml:math id="inf3"><mml:mi>c</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the estimated scalar weighting coefficient for touch location <inline-formula><mml:math id="inf5"><mml:mi>c</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is a constant offset term. <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was constructed by assigning a value of 1 if the corresponding firing rate was collected when touch location c was being stimulated and with a 0 otherwise. All baseline samples were also assigned a 0, effectively pooling together baseline data independent of subsequent touch location. Here, we used indicator variables as our predictors because our stimulus was applied in a binary manner, either touch was applied to a position on the skin or not. Note that in principle the formalism of linear models allows multiple indicator variables to take on a value of 1 at the same time. In our experiment, this would amount to simultaneous touch of two or more body parts. However, in out experiments, simultaneous touch was not tested and thus only one indicator variable could take a value of 1 at a time. Neural responses to a particular body location were considered responsive if the t-statistic for the associated beta coefficient was significant (p&lt;0.05, FDR corrected for multiple comparisons). A unit was considered tuned if the F-statistic comparing the beta coefficients was significant (p&lt;0.05, FDR corrected for multiple comparisons).</p><p>The linear models for each task were computed using all test conditions within the task, except when comparing discriminative coding between the left and right body sides. For this analysis, the goal was to determine how informative information encoded for one body side was for the other. Each neuron was fit by two linear models, one for touch locations exclusive to sensate regions of the contralateral side (e.g., contralateral shoulder, neck, back, and cheek) and one for touch locations exclusive to sensate regions of the ipsilateral side (e.g., ipsilateral shoulder, neck, back, and cheek). More details regarding this analysis are given in 'Materials and methods: Tests for mirror symmetric neural coding of body locations: single-unit analysis.'</p></sec><sec id="s4-10-2"><title>Population correlation (relevant for <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig4">4</xref>, and for <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref> and <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>)</title><p>We used correlation to compare the population neural representations of various tested conditions (stimulus presentations) against each other in a pairwise fashion. Correlation was chosen over alternative distance metrics (such as Mahalanobis or Euclidean distance) because it provides an intuitive metric of similarity that is robust to gross changes in baseline neural activity across the entire neural population. Alternative distance metrics were tested and gave comparable results (e.g., <xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>).</p><p>To perform the population correlation analyses, we quantified the neural representations as a vector of firing rates, one vector for each condition (stimulus location) with each vector element summarizing the response of an individual unit. As before, neural activity was summarized as the mean firing rate during the stimulation phase window, defined as 0.5–2.5 s after the onset of stimulus presentation. Firing rate vectors were constructed by averaging the responses across 50–50 splits of trial repetitions. The mean responses across different splits were correlated within and across conditions (e.g., across stimulations of different sensory fields), then the splits were regenerated, and the correlation computed 250 times. Performing the splits 250 times was chosen based on an empirical analysis applied to preliminary data. For preliminary data, we performed the analysis with N splits, with N ranging from 5 to 200 in steps of 5. We found that the mean correlation across splits converged to a stable value by about 80 splits. We then roughly tripled that to ensure that the numerical sampling scheme would capture a stable value of our cross-validated correlation metric. The across-condition correlations measured similarity between population responses for different sensory fields, answering the question – are the tactile sensations similar or dissimilar from the perspective of the recorded neural population? The within-condition correlations assist in our interpretation of the across-format correlations by allowing us to quantify the theoretical maxima of the similarity measure (e.g., if the within-condition correlation is measured at 0.6, then an across condition of 0.6 suggests identical neural representations).</p><p>To test whether the difference between any pair of conditions was statistically significant, we used a shuffle permutation test applied to the correlations computed over the 250 random splits. To illustrate, in <xref ref-type="fig" rid="fig4">Figure 4E</xref> we applied this analysis to test whether the correlation between actual and imagined cheek touch was significantly different from that of actual cheek touch and imagined shoulder touch. The true difference in the correlations was computed as the difference in the mean correlations between actual and imagined cheek touches (over the 250 splits) and the mean of the correlations between actual cheek touch and imagined shoulder touches. We then randomly shuffled the two distributions together (2000 times) and computed the difference in the mean correlations for each shuffle. The distribution of shuffled differences served as the null distribution, against which we compared the true difference to determine significance. As in the case above, our permutation shuffle test used 2000 shuffles to ensure that the numerical sampling scheme would capture a stable value of the percentile of our true difference compared to the empirical null distribution.</p></sec><sec id="s4-10-3"><title>Decode analysis (confusion matrix; relevant for <xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig4">4</xref>, and for <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>)</title><p>Classification was performed using linear discriminant analysis with the following parameter choices: (1) only the mean firing rates differ for unit activity in response to each touch location (covariance of the normal distributions are the same for each condition) and (2) firing rates for each unit are independent (covariance of the normal distribution is diagonal). These choices do not reflect assumptions about the behavior of neurons, but instead were found to improve cross-validation prediction accuracy on preliminary data. In our experiments, we acquired 10 repetitions per touch location, generally not enough data to robustly estimate the covariance matrix that describes the conditional dependence of the neural behavior on the stimulus. In choosing equal covariance, we are able to pool data across touch locations, achieving a more generalizable approximation of the neural response as verified by cross-validation.</p><p>The classifier took as input a matrix of firing rates for all sorted units. The analysis was not limited to significantly modulated units to avoid ‘peeking’ effects (<xref ref-type="bibr" rid="bib83">Smialowski et al., 2010</xref>). Classification performance is reported as prediction accuracy of a stratified leave-one-out cross-validation analysis. The analysis was performed independently for each recording session, and results were then averaged across days.</p></sec><sec id="s4-10-4"><title>Tests for mirror symmetric neural coding of body locations: single-unit analysis (relevant for <xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>)</title><p>The purpose of this analysis was to assess whether neural responses to one body side were the same as neural responses to the alternate body side on a single-unit basis. Heuristically, we used a cross-validation approach, similar in concept to the population correlation, to ask whether the neural responses to one body are similar to the other body side. The transition to single units required one major modification from the population approach: instead of comparing the pattern of response across neurons (as in the population case), we compared the pattern of response across the set of lateralized body locations (shoulder, neck, cheek, and back). We first selected the set of neurons that demonstrated discriminative encoding to at least one of the body locations that was tested to ensure that there was a meaningful discriminative pattern across sites to form a basis of comparison. Then we used a cross-validation procedure to compare within and across body-side encoding. A schematic representation of how the two sides were compared is shown in panels B–F of <xref ref-type="fig" rid="fig2s6">Figure 2—figure supplement 6</xref>.</p><p>For each neuron, we created a linear model that explained firing rate as a function of the response to each touch location on the right side. The linear model was constructed using indicator variables as described above; however, the set of body locations was restricted to shoulder, neck, cheek, and back. In this way, the response of a neuron is quantified by the continuous set of beta values for the four locations. This model was then used to predict the responses for the same four locations on the left side. The ability to predict the responses was quantified as the R<sup>2</sup><sub>Right to Left</sub>. This metric is hard to interpret on its own; a low R<sup>2</sup><sub>Right to Left</sub> could indicate that responses are very distinct between the right and left sides or it could indicate that the neuron is not very discriminative (e.g., there is high trial-to-trial variability relative to the differences in response to the different touch locations). Therefore, we also computed a cross-validated R<sup>2</sup><sub>Left to Left</sub> measure. This disambiguates the R<sup>2</sup><sub>Right to Left</sub> measure. If R<sup>2</sup><sub>Right to Left</sub> is low but R<sup>2</sup><sub>Left to Left</sub> is high, then we know that the unit is discriminative, but that the patterns of response between the right and left sides are distinct. To compare apples-to-apples, both the R<sup>2</sup><sub>Left to Left</sub> and R<sup>2</sup><sub>Right to Left</sub> were computed using leave-one-out cross-validation. This is necessary to ensure that the two measures are computed based on the same amount of training data. To directly compare these values, we plotted them against each other as a scatter plot. If the patterns of response are similar, this would lead to data points falling along the identity line. If the patterns are distinct, the data points should fall below the identity line.</p></sec><sec id="s4-10-5"><title>Response latency (relevant for <xref ref-type="fig" rid="fig3">Figure 3</xref>)</title><p>We quantified the neural response latency to touch stimuli at the level of the neural population. Prior to the analysis, trials were aligned by touch onset as detected by the capacitive touch sensor (ground truth). PCA was used to summarize the population-level temporal response of recorded neurons (<xref ref-type="bibr" rid="bib16">Cunningham and Yu, 2014</xref>). We constructed a matrix of neural data D that was (n) by (t * c * r) in size, with n being the number of neurons, t being the number of time points, c being the number of conditions, and r being the number of trial repetitions. For each neuron, activity was sampled every 2 ms and no additional smoothing was applied. 2 ms windows were chosen to allow high temporal resolution to precisely localize the timing of the neural response with respect to touch contact. We used t = 201 time bins starting from −150 ms and stopping at 250 ms with respect to the time of touch sensor contact. Different ranges from time of contact (up to −500 ms before and 500 ms after probe contact) were tested, and the basic average latency was robust to the exact window choice. c = 2, including data for touch to the cheek and touch to the shoulder. r = 10, as we acquired 10 repetitions per condition. Principal components were calculated based on the singular value decomposition algorithm.</p><p>The first principal component (1PC) was retained, and responses were averaged across conditions and repetitions. Single-trial results were visually inspected, and basic temporal profiles were consistent across conditions and repetitions. This process was performed separately for data acquired for touch to the left side and right side of the body. The 1PC was then fit with a piecewise linear function with two transition points. The choice of two transition points was set based on visual inspection of the data and allows for an initial baseline, a subsequent rise, and a final plateau. The time at which transitions occurred was not constrained, being purely a product of the fitting process. Latency was reported as the time the piecewise linear fit crossed the 95th percentile of the baseline data, as measured by the distribution of activity in the window between −150 and 0 ms. To compute bootstrapped quartile bounds of the latency estimates, the above process was repeated 1000 times while resampling with replacement from the 1PC single-trial results. To verify that 1000 resamples were sufficient to estimate a stable estimate of the quartile range, we repeated the process with 1500 resamples and found that the quartile estimate changed less than 1%.</p><p>To determine whether the mean difference of latency estimates was significant between the right and the left side, we performed a permutation shuffle test. We used a rank test to compare the true difference in latency estimates against an empirical null distribution of differences in latency estimates generated by shuffling labels and repeating the comparison 2000 times.</p></sec><sec id="s4-10-6"><title>Quantifying macroscale receptive field structure (relevant for <xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>)</title><p>We found that many neurons responded to touch to multiple body locations. We wished to further characterize the receptive field structure to determine whether neurons were characterized by single-peaked broad receptive fields or discontinuous receptive fields with multiple peaks. To adjudicate between these possibilities, we selected touch locations to the contralateral (right) forehead, cheek, neck, and shoulder for further analysis because these locations are approximately collinear. We reasoned that if neurons are characterized by single-peak-type responses, then responses across a collinear set of testing sites will result in a single local maximum (either with a single peak and fall off on either side or as a monotonic increase to the edge locations). On the other hand, if receptive fields are characterized by multiple peaks, then responses should have multiple local maxima.</p><p>Neurons were first restricted to those demonstrating significant differential responses between the four sites (ANOVA, p&lt;0.05, FDR corrected). Each neuron was then grouped according to its location of preferred (peak) response. This resulted in four groups of neurons: neurons that responded maximally to the forehead, cheek, neck, or shoulder. For each neuron, the goal was to identify if the firing rate monotonically decreases with increasing distance from the preferred location or rises again, allowing for a second maxima. For example, for a unit preferring the forehead, this would manifest as firing rate at forehead larger than at cheek, at cheek larger than at neck, and at neck larger than at shoulder. Tests of firing rate between adjacent locations were performed by one-tailed t-tests between the pair of locations, evaluating whether the firing rate at the location nearer the preferred response was greater than that at the location more distant. In the example of the forehead preferring units, the t-tests evaluated whether cheek&gt;neck and neck&gt;shoulder. If it was found that any of those comparisons was not true (e.g., firing rate at neck greater than at cheek) after correcting for multiple comparisons, this implied a second local maxima. The unit was then classified as multi-peak. If no second local maxima was found, the unit was classified as single peak.</p></sec><sec id="s4-10-7"><title>Receptive field size estimation (relevant for <xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>)</title><p>In our first experiment, we tested touch responses across major body parts at a course resolution. Patterns of neuronal responses suggest that multiple body parts can be represented in individual neurons, although the response field around each body part is locally narrow (not expansive, covering all body parts). To evaluate this further, as a complimentary dataset, we tested tactile representations at a finer spatial precision to begin to characterize the size of their receptive fields. We characterized the response patterns of individual neurons to tactile stimuli delivered to each of nine points along the subject’s face and neck. All units demonstrating a differential spatial response to touch to each of the nine fields were included in this analysis. For each of these units, we first identified the preferred site of stimulus delivery as the point associated with the largest firing rate. Next, we examined its response to delivering stimuli to the other points. To estimate the average size of a neuronal receptive field as a function of its preferred point of stimulus delivery, we fit a Gaussian model to the average responses grouped by the preference of the neuron. The Gaussian model had three free parameters and was defined as<disp-formula id="equ2"><mml:math id="m2"><mml:mi>G</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf8"><mml:mi>A</mml:mi></mml:math></inline-formula> is the amplitude of the Gaussian, <inline-formula><mml:math id="inf9"><mml:mi>σ</mml:mi></mml:math></inline-formula> is the standard deviation, and <inline-formula><mml:math id="inf10"><mml:mi>c</mml:mi></mml:math></inline-formula> is the constant offset term. µ is the mean/center of the Gaussian and was fixed at the preferred point. A separate model (with the appropriate value of µ) was fit to each of the response groups. The field size was described as the full width at half maximum.</p></sec><sec id="s4-10-8"><title>Temporal dynamics of population activity during tactile imagery task: within category (relevant for <xref ref-type="fig" rid="fig5">Figure 5</xref>)</title><p>We performed a sliding-window classification analysis to quantify the strength and temporal dynamics of population coding in the tactile imagery task. In this task, the participant heard an auditory cue specifying a body part (‘cheek,’ ‘hand,’ or ‘shoulder’) that lasted approximately 0.5 s, followed by an approximately 2 s delay, and finally a beep instructing the participant to initiate imagining a touch sensation at the cued body part. This task could engage at least four cognitive processes: (1) semantic processing of the cue, (2) preparation/anticipation for imagery, (3) attentional modulation, and (4) imagined touch per se. We used a dynamic classification analysis to understand how the neural population evolved during the course of the trial to determine whether the population was best described as mediating single or multiple cognitive processes. In brief, the analysis consisted of creating a dataset that consisted of the population response measured in small temporal windows throughout the course of the trial. We trained a classifier separately on each temporal window and applied each classifier to both temporal windows. In this way, we can measure how information about the cued stimulus evolves in time (e.g., does there exist neural coding during the delay portion of the trial, and, if so, does the neural coding during the delay match neural coding during active imagery). Classification was performed using linear discriminant analysis as described above. We used cross-validation to ensure that training and predicting on the same time window was directly comparable to training on one window and testing on an alternate time window; in other words, we were careful to ensure that accuracy across all comparisons reflects generalization accuracy using the same amount of training and test data. Classifiers were trained and tested on neural responses to the three imagery conditions: cheek, hand, and shoulder. Population response activity for each time window was computed as the average neural response within a 500 ms window, stepped at 100 ms intervals. Window onsets started at −700 ms relative to auditory cue onset (cue-delay epoch) with the final window chosen 3.5 s after the beep (onset of the imagery epoch). Classification was performed on all sorted units acquired within a single session. Mean and bootstrapped 95% CIs were computed for each time bin from the cross-validated accuracy values computed across sessions.</p><p>We used a fixed window size for averaging time series data for analysis (box-car smoothing) as it provides straightforward bounds for the temporal range of data that are included in the analysis for a particular time window. 500 ms was chosen as a good balance between temporal resolution and noise mitigation. We note that although the window size can influence various metrics (e.g., larger smoothing windows can increase coefficients of determination, R<sup>2</sup>) the choice of smoothing size is largely inconsequential as long as the kernel size is kept consistent when making comparisons across conditions. The choice of a 100 ms step size was anchored to the choice of smoothing window. A small step, such as 1 ms, would not be justified with a 500 ms time window. We chose 100 ms, representing a change in 20% of the data, to allow us the ability to temporally localize changes in neural response without unnecessarily oversampling a smoothed signal and thus not unnecessarily increasing computation time for analysis.</p><p>We believe that this technique, by helping us to understand when information appears and how information compares across task phases, provides a valuable approach to understanding how population activity relates to the underlying cognitive processes. For example, if neural decoding reaches significance only after the go cue, neural activity would be inconsistent with semantic or anticipatory processing. Alternatively, if neural processing begins with the cue, and the same pattern of neural activity is maintained throughout the trial, with no changes during the active imagery phase, then the data would be inconsistent with processing imagined touch per se.</p><p>The classification analysis described above was used to measure general similarity of the population response to the tested conditions across time. However, to explicitly test whether population activity was changing, we used Mahalanobis distance as our measure. This is necessary as classification involves a discretization step that makes the technique relatively insensitive to changes in neural population activity that do not cross decision thresholds. Mahalanobis distance, being a proper distance measure, is a more sensitive measure of change. To illustrate, imagine that a classifier is trained on time point A and tested on time point B. At time point A, the means of the two classes are 0 and 1, respectively, and at time point 2 the means are 0 and 4, respectively. All classes are assumed to have equal but negligible variance (e.g., 0.01) in this example. When trained on time point A, the classifier finds a decision boundary at 0.5. with 100% classification accuracy. When tested on time point B, with the same 0.5 decision boundary, the classifier again is 100%. Naively, this could be interpreted as signifying that no change in the underlying data has occurred, even though the mean of the second distribution has shifted.</p><p>Separation in neural activity between the cue-delay epoch and the imagery epoch was quantified using a cross-validated Mahalanobis distance computed between the observed neural activity at a time point and a reference (baseline) defined as the neural activity immediately following the presentation of the auditory cue, from 0.25 to 0.75 s. Distances were measured separately for each of the three conditions and then averaged. The mean and standard error on the mean were computed across sessions for the cross-validated distance measures and plotted in <xref ref-type="fig" rid="fig5">Figure 5C</xref>. Activity during the cue-delay epoch and go epoch was compared using a rank-sum test of the averaged activity during the phase-averaged responses across sessions.</p></sec><sec id="s4-10-9"><title>Temporal dynamics of single-unit activity during tactile imagery task: within category (relevant for <xref ref-type="fig" rid="fig5">Figure 5</xref>)</title><p>We wished to understand the behavior of single neurons that led to the temporal dynamics of the population. The temporal dynamics of single-unit activity during the imagery task (for the imagined touch conditions only) were quantified a PCA (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). A sliding-window classification analysis was first performed on each sorted unit from all testing days in the same manner as described above for the population activity, with the exception that classifier took as input a vector of the firing rates for a single unit as opposed to a matrix of the firing rates for all units recorded in a single session. This allowed a quantitative description of the temporal dynamics for each sorted unit. Next, a PCA was applied to the dynamic classification matrices with individual neurons counting as the independent observations. PCA has become a standard method for describing the behavior of neural populations (<xref ref-type="bibr" rid="bib16">Cunningham and Yu, 2014</xref>). Typically, PCA is applied to firing rate measurements of neurons. However, in our case, we were less interested in capturing the main modes of variability with respect to individual conditions, but instead wanted to capture the main modes of variability with respect to the temporal dynamics of information encoding.</p></sec><sec id="s4-10-10"><title>Temporal dynamics of population activity during tactile imagery task: across category (relevant for <xref ref-type="fig" rid="fig6">Figure 6</xref>)</title><p>We wished to evaluate the similarity in neural representations of actual and imagined touch in a time-resolved manner, as well as to compare the similarities in activity from one epoch (cue-delay) to another (stimulus: actual or imagined touch). We performed a sliding-window (dynamic) correlation analysis in a cross-validated manner to compute within-format correlation in addition to across-format correlations. For this analysis, we restricted the tested body sites in the actual touch format to the right cheek and right shoulder only. Neural activity from the left side was not used, to try and match the conditions for the imagined touch format, in which only touch to the right side was tested. Similarly, the hand was not included in this analysis to match conditions that evoked responses in both formats.</p><p>For cross-validation, the analysis began with splitting trial repetitions into training and testing sets (five trial repetitions each). A sliding time-window was used for the analysis with window size of 500 ms and step size of 100 ms. Correlations were computed between training and testing sets for all combinations of windows, starting from 500 ms before the cue onset to 1000 ms after the end of the stimulus phase. Within each window, we organized the neural response data into two matrices (one each for the training and the test trial splits) with two columns each. Each column contained trial-averaged firing rates during the corresponding time window for each of the two tested stimulation sites (cheek and shoulder), with one value per unit. The columns represented the two formats. Thus, for N units recorded, two tested stimulation sites and two formats (actual and imagined), each matrix was of size (2*N) × 2. The mean response across each matrix (computed separately for training and test sets) was subtracted from each value to ensure that a positive correlation across formats reflected a similarity in the pattern of responses to the two body sites and not general offsets in the mean response of the different neurons. Finally, correlations were computed between training and test sets for all combinations of time windows. This was done across 50 random 50–50 trial splits and the results averaged across these repetitions. The analysis was performed for each recording session independently and the depicted results averaged over days.</p></sec></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>The authors thank subject NS for participating in the studies, Viktor Shcherbatyuk for technical assistance, and Kelsie Pejsa for administrative and regulatory assistance. This work was supported by the National Institute of Health (R01EY015545), the Tianqiao and Chrissy Chen Brain-machine Interface Center at Caltech, the Conte Center for Social Decision Making at Caltech (P50MH094258), and the Boswell Foundation.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Software, Formal analysis, Validation, Investigation, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Investigation, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Resources, Data curation, Validation, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Resources, Data curation, Supervision, Funding acquisition, Methodology</p></fn><fn fn-type="con" id="con6"><p>Resources, Data curation, Funding acquisition, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con7"><p>Resources, Supervision, Funding acquisition, Validation, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Clinical trial registration NCT01958086.</p></fn><fn fn-type="other" id="fn2"><p>Human subjects: All procedures were approved by the California Institute of Technology (IRB #18-0401), University of California, Los Angeles (IRB #13-000576-AM-00027), and Casa Colina Hospital and Centers for Healthcare (IRB #00002372) Institutional Review Boards. Informed consent was obtained after the nature of the study and possible risks were explained.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-61646-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data and analysis for key figures will be made available on github: <ext-link ext-link-type="uri" xlink:href="https://github.com/tysonnsa/eLifePPCTouch">https://github.com/tysonnsa/eLifePPCTouch</ext-link> copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:aead504c828568a46cf9555598211f1800f2187d/">https://archive.softwareheritage.org/swh:1:rev:aead504c828568a46cf9555598211f1800f2187d/</ext-link>.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Kellis</surname> <given-names>S</given-names></name><name><surname>Klaes</surname> <given-names>C</given-names></name><name><surname>Lee</surname> <given-names>B</given-names></name><name><surname>Shi</surname> <given-names>Y</given-names></name><name><surname>Pejsa</surname> <given-names>K</given-names></name><name><surname>Shanfield</surname> <given-names>K</given-names></name><name><surname>Hayes-Jackson</surname> <given-names>S</given-names></name><name><surname>Aisen</surname> <given-names>M</given-names></name><name><surname>Heck</surname> <given-names>C</given-names></name><name><surname>Liu</surname> <given-names>C</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neurophysiology. decoding motor imagery from the posterior parietal cortex of a tetraplegic human</article-title><source>Science</source><volume>348</volume><fpage>906</fpage><lpage>910</lpage><pub-id pub-id-type="doi">10.1126/science.aaa5417</pub-id><pub-id pub-id-type="pmid">25999506</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Zhang</surname> <given-names>CY</given-names></name><name><surname>Rosario</surname> <given-names>ER</given-names></name><name><surname>Pouratian</surname> <given-names>N</given-names></name><name><surname>Orban</surname> <given-names>GA</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A shared neural substrate for action verbs and observed actions in human posterior parietal cortex</article-title><source>Science Advances</source><volume>6</volume><elocation-id>eabb3984</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abb3984</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ames</surname> <given-names>KC</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Simultaneous motor preparation and execution in a last-moment reach correction task</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2718</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10772-2</pub-id><pub-id pub-id-type="pmid">31221968</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname> <given-names>RA</given-names></name><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Kellis</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>From thought to action: the brain–machine interface in posterior parietal cortex</article-title><source>PNAS</source><volume>116</volume><fpage>26274</fpage><lpage>26279</lpage><pub-id pub-id-type="doi">10.1073/pnas.1902276116</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersen</surname> <given-names>RA</given-names></name><name><surname>Buneo</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Intentional maps in posterior parietal cortex</article-title><source>Annual Review of Neuroscience</source><volume>25</volume><fpage>189</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.25.112701.142922</pub-id><pub-id pub-id-type="pmid">12052908</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Armenta Salas</surname> <given-names>M</given-names></name><name><surname>Bashford</surname> <given-names>L</given-names></name><name><surname>Kellis</surname> <given-names>S</given-names></name><name><surname>Jafari</surname> <given-names>M</given-names></name><name><surname>Jo</surname> <given-names>H</given-names></name><name><surname>Kramer</surname> <given-names>D</given-names></name><name><surname>Shanfield</surname> <given-names>K</given-names></name><name><surname>Pejsa</surname> <given-names>K</given-names></name><name><surname>Lee</surname> <given-names>B</given-names></name><name><surname>Liu</surname> <given-names>CY</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Proprioceptive and cutaneous sensations in humans elicited by intracortical microstimulation</article-title><source>eLife</source><volume>7</volume><elocation-id>e32904</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32904</pub-id><pub-id pub-id-type="pmid">29633714</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avillac</surname> <given-names>M</given-names></name><name><surname>Ben Hamed</surname> <given-names>S</given-names></name><name><surname>Duhamel</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Multisensory integration in the ventral intraparietal area of the macaque monkey</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>1922</fpage><lpage>1932</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2646-06.2007</pub-id><pub-id pub-id-type="pmid">17314288</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname> <given-names>JR</given-names></name><name><surname>Desai</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neurobiology of semantic memory</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>527</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.10.001</pub-id><pub-id pub-id-type="pmid">22001867</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bisley</surname> <given-names>JW</given-names></name><name><surname>Krishna</surname> <given-names>BS</given-names></name><name><surname>Goldberg</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A rapid and precise on-response in posterior parietal cortex</article-title><source>Journal of Neuroscience</source><volume>24</volume><fpage>1833</fpage><lpage>1838</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5007-03.2004</pub-id><pub-id pub-id-type="pmid">14985423</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boynton</surname> <given-names>GM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A framework for describing the effects of attention on visual responses</article-title><source>Vision Research</source><volume>49</volume><fpage>1129</fpage><lpage>1143</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.11.001</pub-id><pub-id pub-id-type="pmid">19038281</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burton</surname> <given-names>H</given-names></name><name><surname>Sinclair</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Second somatosensory cortical area in macaque monkeys. I. neuronal responses to controlled, punctate indentations of glabrous skin on the hand</article-title><source>Brain Research</source><volume>520</volume><fpage>262</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(90)91714-R</pub-id><pub-id pub-id-type="pmid">2207635</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caramazza</surname> <given-names>A</given-names></name><name><surname>Anzellotti</surname> <given-names>S</given-names></name><name><surname>Strnad</surname> <given-names>L</given-names></name><name><surname>Lingnau</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Embodied cognition and mirror neurons: a critical assessment</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-071013-013950</pub-id><pub-id pub-id-type="pmid">25032490</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname> <given-names>AW</given-names></name><name><surname>Baker</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Seeing is not feeling: posterior parietal but not somatosensory cortex engagement during touch observation</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>1468</fpage><lpage>1480</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3621-14.2015</pub-id><pub-id pub-id-type="pmid">25632124</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Ghahramani</surname> <given-names>Z</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Linear dimensionality reduction: survey, insights, and generalizations</article-title><source>Journal of Machine Learning Research: JMLR</source><volume>16</volume><fpage>2859</fpage><lpage>2900</lpage></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id><pub-id pub-id-type="pmid">25151264</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Haan</surname> <given-names>EHF</given-names></name><name><surname>Dijkerman</surname> <given-names>HC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Somatosensation in the brain: a theoretical Re-evaluation and a new model</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>529</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.04.003</pub-id><pub-id pub-id-type="pmid">32430229</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Lafuente</surname> <given-names>V</given-names></name><name><surname>Romo</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Neural correlate of subjective sensory experience gradually builds up across cortical Areas</article-title><source>PNAS</source><volume>103</volume><fpage>14266</fpage><lpage>14271</lpage><pub-id pub-id-type="doi">10.1073/pnas.0605826103</pub-id><pub-id pub-id-type="pmid">16924098</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decety</surname> <given-names>J</given-names></name><name><surname>Jeannerod</surname> <given-names>M</given-names></name><name><surname>Prablanc</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The timing of mentally represented actions</article-title><source>Behavioural Brain Research</source><volume>34</volume><fpage>35</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(89)80088-9</pub-id><pub-id pub-id-type="pmid">2765170</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decety</surname> <given-names>J</given-names></name><name><surname>Jeannerod</surname> <given-names>M</given-names></name><name><surname>Germain</surname> <given-names>M</given-names></name><name><surname>Pastene</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Vegetative response during imagined movement is proportional to mental effort</article-title><source>Behavioural Brain Research</source><volume>42</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(05)80033-6</pub-id><pub-id pub-id-type="pmid">2029340</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decety</surname> <given-names>J</given-names></name><name><surname>Jeannerod</surname> <given-names>M</given-names></name><name><surname>Durozard</surname> <given-names>D</given-names></name><name><surname>Baverel</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Central activation of autonomic effectors during mental simulation of motor actions in man</article-title><source>The Journal of Physiology</source><volume>461</volume><fpage>549</fpage><lpage>563</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1993.sp019528</pub-id><pub-id pub-id-type="pmid">8102402</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Decety</surname> <given-names>J</given-names></name><name><surname>Michel</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Comparative analysis of actual and mental movement times in two graphic tasks</article-title><source>Brain and Cognition</source><volume>11</volume><fpage>87</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1016/0278-2626(89)90007-9</pub-id><pub-id pub-id-type="pmid">2789819</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dykes</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Parallel processing of somatosensory information: a theory</article-title><source>Brain Research Reviews</source><volume>287</volume><fpage>47</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/0165-0173(83)90004-8</pub-id><pub-id pub-id-type="pmid">6311356</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferezou</surname> <given-names>I</given-names></name><name><surname>Haiss</surname> <given-names>F</given-names></name><name><surname>Gentet</surname> <given-names>LJ</given-names></name><name><surname>Aronoff</surname> <given-names>R</given-names></name><name><surname>Weber</surname> <given-names>B</given-names></name><name><surname>Petersen</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Spatiotemporal dynamics of cortical sensorimotor integration in behaving mice</article-title><source>Neuron</source><volume>56</volume><fpage>907</fpage><lpage>923</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.10.007</pub-id><pub-id pub-id-type="pmid">18054865</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flesher</surname> <given-names>SN</given-names></name><name><surname>Collinger</surname> <given-names>JL</given-names></name><name><surname>Foldes</surname> <given-names>ST</given-names></name><name><surname>Weiss</surname> <given-names>JM</given-names></name><name><surname>Downey</surname> <given-names>JE</given-names></name><name><surname>Tyler-Kabara</surname> <given-names>EC</given-names></name><name><surname>Bensmaia</surname> <given-names>SJ</given-names></name><name><surname>Schwartz</surname> <given-names>AB</given-names></name><name><surname>Boninger</surname> <given-names>ML</given-names></name><name><surname>Gaunt</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Intracortical microstimulation of human somatosensory cortex</article-title><source>Science Translational Medicine</source><volume>8</volume><elocation-id>361ra141</elocation-id><pub-id pub-id-type="doi">10.1126/scitranslmed.aaf8083</pub-id><pub-id pub-id-type="pmid">27738096</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallivan</surname> <given-names>JP</given-names></name><name><surname>McLean</surname> <given-names>DA</given-names></name><name><surname>Valyear</surname> <given-names>KF</given-names></name><name><surname>Pettypiece</surname> <given-names>CE</given-names></name><name><surname>Culham</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2011">2011a</year><article-title>Decoding action intentions from preparatory brain activity in human Parieto-Frontal networks</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>9599</fpage><lpage>9610</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0080-11.2011</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallivan</surname> <given-names>JP</given-names></name><name><surname>McLean</surname> <given-names>DA</given-names></name><name><surname>Smith</surname> <given-names>FW</given-names></name><name><surname>Culham</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2011">2011b</year><article-title>Decoding effector-dependent and effector-independent movement intentions from human parieto-frontal brain activity</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>17149</fpage><lpage>17168</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1058-11.2011</pub-id><pub-id pub-id-type="pmid">22114283</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garraghty</surname> <given-names>PE</given-names></name><name><surname>Florence</surname> <given-names>SL</given-names></name><name><surname>Kaas</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Ablations of Areas 3a and 3b of monkey somatosensory cortex abolish cutaneous responsivity in area 1</article-title><source>Brain Research</source><volume>528</volume><fpage>165</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(90)90213-U</pub-id><pub-id pub-id-type="pmid">2245335</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geyer</surname> <given-names>S</given-names></name><name><surname>Schormann</surname> <given-names>T</given-names></name><name><surname>Mohlberg</surname> <given-names>H</given-names></name><name><surname>Zilles</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Areas 3a, 3b, and 1 of human primary somatosensory cortex. part 2. spatial normalization to standard anatomical space</article-title><source>NeuroImage</source><volume>11</volume><fpage>684</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1006/nimg.2000.0548</pub-id><pub-id pub-id-type="pmid">10860796</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graziano</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Where is my arm? the relative role of vision and proprioception in the neuronal representation of limb position</article-title><source>PNAS</source><volume>96</volume><fpage>10418</fpage><lpage>10421</lpage><pub-id pub-id-type="doi">10.1073/pnas.96.18.10418</pub-id><pub-id pub-id-type="pmid">10468623</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graziano</surname> <given-names>MS</given-names></name><name><surname>Cooke</surname> <given-names>DF</given-names></name><name><surname>Taylor</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Coding the location of the arm by sight</article-title><source>Science</source><volume>290</volume><fpage>1782</fpage><lpage>1786</lpage><pub-id pub-id-type="doi">10.1126/science.290.5497.1782</pub-id><pub-id pub-id-type="pmid">11099420</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graziano</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A system of multimodal Areas in the primate brain</article-title><source>Neuron</source><volume>29</volume><fpage>4</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00174-X</pub-id><pub-id pub-id-type="pmid">11182075</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graziano</surname> <given-names>MS</given-names></name><name><surname>Gross</surname> <given-names>CG</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>A bimodal map of space: somatosensory receptive fields in the macaque putamen with corresponding visual receptive fields</article-title><source>Experimental Brain Research</source><volume>97</volume><fpage>96</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1007/BF00228820</pub-id><pub-id pub-id-type="pmid">8131835</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hämäläinen</surname> <given-names>H</given-names></name><name><surname>Hiltunen</surname> <given-names>J</given-names></name><name><surname>Titievskaja</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>fMRI activations of SI and SII cortices during tactile stimulation depend on attention</article-title><source>NeuroReport</source><volume>11</volume><fpage>1673</fpage><lpage>1676</lpage><pub-id pub-id-type="doi">10.1097/00001756-200006050-00016</pub-id><pub-id pub-id-type="pmid">10852223</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Quiroga</surname> <given-names>RQ</given-names></name><name><surname>Freeman</surname> <given-names>J</given-names></name><name><surname>Smith</surname> <given-names>SL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Improving data quality in neuronal population recordings</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1165</fpage><lpage>1174</lpage><pub-id pub-id-type="doi">10.1038/nn.4365</pub-id><pub-id pub-id-type="pmid">27571195</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holmes</surname> <given-names>NP</given-names></name><name><surname>Spence</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The body schema and the multisensory representation(s) of peripersonal space</article-title><source>Cognitive Processing</source><volume>5</volume><fpage>94</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1007/s10339-004-0013-3</pub-id><pub-id pub-id-type="pmid">16467906</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>RS</given-names></name><name><surname>Chen</surname> <given-names>CF</given-names></name><name><surname>Tran</surname> <given-names>AT</given-names></name><name><surname>Holstein</surname> <given-names>KL</given-names></name><name><surname>Sereno</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Mapping multisensory parietal face and body Areas in humans</article-title><source>PNAS</source><volume>109</volume><fpage>18114</fpage><lpage>18119</lpage><pub-id pub-id-type="doi">10.1073/pnas.1207946109</pub-id><pub-id pub-id-type="pmid">23071340</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>RS</given-names></name><name><surname>Chen</surname> <given-names>CF</given-names></name><name><surname>Sereno</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spatiotemporal integration of looming visual and tactile stimuli near the face</article-title><source>Human Brain Mapping</source><volume>39</volume><fpage>2156</fpage><lpage>2176</lpage><pub-id pub-id-type="doi">10.1002/hbm.23995</pub-id><pub-id pub-id-type="pmid">29411461</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huth</surname> <given-names>AG</given-names></name><name><surname>de Heer</surname> <given-names>WA</given-names></name><name><surname>Griffiths</surname> <given-names>TL</given-names></name><name><surname>Theunissen</surname> <given-names>FE</given-names></name><name><surname>Gallant</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Natural speech reveals the semantic maps that tile human cerebral cortex</article-title><source>Nature</source><volume>532</volume><fpage>453</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1038/nature17637</pub-id><pub-id pub-id-type="pmid">27121839</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hwang</surname> <given-names>EJ</given-names></name><name><surname>Hauschild</surname> <given-names>M</given-names></name><name><surname>Wilke</surname> <given-names>M</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatial and temporal eye-hand coordination relies on the parietal reach region</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12884</fpage><lpage>12892</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3719-13.2014</pub-id><pub-id pub-id-type="pmid">25232123</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iwamura</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Hierarchical somatosensory processing</article-title><source>Current Opinion in Neurobiology</source><volume>8</volume><fpage>522</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(98)80041-X</pub-id><pub-id pub-id-type="pmid">9751655</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeannerod</surname> <given-names>M</given-names></name><name><surname>Decety</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Mental motor imagery: a window into the representational stages of action</article-title><source>Current Opinion in Neurobiology</source><volume>5</volume><fpage>727</fpage><lpage>732</lpage><pub-id pub-id-type="doi">10.1016/0959-4388(95)80099-9</pub-id><pub-id pub-id-type="pmid">8805419</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname> <given-names>W</given-names></name><name><surname>Tremblay</surname> <given-names>F</given-names></name><name><surname>Chapman</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Neuronal encoding of texture changes in the primary and the secondary somatosensory cortical Areas of monkeys during passive texture discrimination</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>1656</fpage><lpage>1662</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.3.1656</pub-id><pub-id pub-id-type="pmid">9084631</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johansen-Berg</surname> <given-names>H</given-names></name><name><surname>Christensen</surname> <given-names>V</given-names></name><name><surname>Woolrich</surname> <given-names>M</given-names></name><name><surname>Matthews</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Attention to touch modulates activity in both primary and secondary somatosensory Areas</article-title><source>NeuroReport</source><volume>11</volume><fpage>1237</fpage><lpage>1241</lpage><pub-id pub-id-type="doi">10.1097/00001756-200004270-00019</pub-id><pub-id pub-id-type="pmid">10817599</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaas</surname> <given-names>JH</given-names></name><name><surname>Nelson</surname> <given-names>RJ</given-names></name><name><surname>Sur</surname> <given-names>M</given-names></name><name><surname>Lin</surname> <given-names>CS</given-names></name><name><surname>Merzenich</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Multiple representations of the body within the primary somatosensory cortex of primates</article-title><source>Science</source><volume>204</volume><fpage>521</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1126/science.107591</pub-id><pub-id pub-id-type="pmid">107591</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaas</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>If anything, is SI? organization of first somatosensory area of cortex</article-title><source>Physiological Reviews</source><volume>63</volume><fpage>206</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1152/physrev.1983.63.1.206</pub-id><pub-id pub-id-type="pmid">6401864</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keysers</surname> <given-names>C</given-names></name><name><surname>Kaas</surname> <given-names>JH</given-names></name><name><surname>Gazzola</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Somatosensation in social perception</article-title><source>Nature Reviews Neuroscience</source><volume>11</volume><fpage>417</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1038/nrn2833</pub-id><pub-id pub-id-type="pmid">20445542</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kikkert</surname> <given-names>S</given-names></name><name><surname>Kolasinski</surname> <given-names>J</given-names></name><name><surname>Jbabdi</surname> <given-names>S</given-names></name><name><surname>Tracey</surname> <given-names>I</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Johansen-Berg</surname> <given-names>H</given-names></name><name><surname>Makin</surname> <given-names>TR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Revealing the neural fingerprints of a missing hand</article-title><source>eLife</source><volume>5</volume><elocation-id>e15292</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.15292</pub-id><pub-id pub-id-type="pmid">27552053</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kilteni</surname> <given-names>K</given-names></name><name><surname>Andersson</surname> <given-names>BJ</given-names></name><name><surname>Houborg</surname> <given-names>C</given-names></name><name><surname>Ehrsson</surname> <given-names>HH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Motor imagery involves predicting the sensory consequences of the imagined movement</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1617</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-03989-0</pub-id><pub-id pub-id-type="pmid">29691389</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klaes</surname> <given-names>C</given-names></name><name><surname>Kellis</surname> <given-names>S</given-names></name><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Lee</surname> <given-names>B</given-names></name><name><surname>Pejsa</surname> <given-names>K</given-names></name><name><surname>Shanfield</surname> <given-names>K</given-names></name><name><surname>Hayes-Jackson</surname> <given-names>S</given-names></name><name><surname>Aisen</surname> <given-names>M</given-names></name><name><surname>Heck</surname> <given-names>C</given-names></name><name><surname>Liu</surname> <given-names>C</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hand shape representations in the human posterior parietal cortex</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>15466</fpage><lpage>15476</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2747-15.2015</pub-id><pub-id pub-id-type="pmid">26586832</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lecas</surname> <given-names>JC</given-names></name><name><surname>Requin</surname> <given-names>J</given-names></name><name><surname>Anger</surname> <given-names>C</given-names></name><name><surname>Vitton</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Changes in neuronal activity of the monkey precentral cortex during preparation for movement</article-title><source>Journal of Neurophysiology</source><volume>56</volume><fpage>1680</fpage><lpage>1702</lpage><pub-id pub-id-type="doi">10.1152/jn.1986.56.6.1680</pub-id><pub-id pub-id-type="pmid">3806186</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lotze</surname> <given-names>M</given-names></name><name><surname>Halsband</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Motor imagery</article-title><source>Journal of Physiology-Paris</source><volume>99</volume><fpage>386</fpage><lpage>395</lpage><pub-id pub-id-type="doi">10.1016/j.jphysparis.2006.03.012</pub-id><pub-id pub-id-type="pmid">16716573</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lucas</surname> <given-names>MV</given-names></name><name><surname>Anderson</surname> <given-names>LC</given-names></name><name><surname>Bolling</surname> <given-names>DZ</given-names></name><name><surname>Pelphrey</surname> <given-names>KA</given-names></name><name><surname>Kaiser</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dissociating the neural correlates of experiencing and imagining affective touch</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>2623</fpage><lpage>2630</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu061</pub-id><pub-id pub-id-type="pmid">24700583</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makin</surname> <given-names>TR</given-names></name><name><surname>Bensmaia</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Stability of sensory topographies in adult cortex</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>195</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.01.002</pub-id><pub-id pub-id-type="pmid">28214130</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makin</surname> <given-names>TR</given-names></name><name><surname>Flor</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain (re)organisation following amputation: implications for phantom limb pain</article-title><source>NeuroImage</source><volume>218</volume><elocation-id>116943</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116943</pub-id><pub-id pub-id-type="pmid">32428706</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>GRAPES-Grounding representations in action, perception, and emotion systems: how object properties and categories are represented in the human brain</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>979</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.3758/s13423-015-0842-3</pub-id><pub-id pub-id-type="pmid">25968087</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname> <given-names>K</given-names></name><name><surname>Damasio</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Convergence and divergence in a neural architecture for recognition and memory</article-title><source>Trends in Neurosciences</source><volume>32</volume><fpage>376</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2009.04.002</pub-id><pub-id pub-id-type="pmid">19520438</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyashita</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Perirhinal circuits for memory processing</article-title><source>Nature Reviews Neuroscience</source><volume>20</volume><fpage>577</fpage><lpage>592</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0213-6</pub-id><pub-id pub-id-type="pmid">31485007</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohammed</surname> <given-names>H</given-names></name><name><surname>Hollis</surname> <given-names>ER</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cortical reorganization of sensorimotor systems and the role of intracortical circuits after spinal cord injury</article-title><source>Neurotherapeutics</source><volume>15</volume><fpage>588</fpage><lpage>603</lpage><pub-id pub-id-type="doi">10.1007/s13311-018-0638-z</pub-id><pub-id pub-id-type="pmid">29882081</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulliken</surname> <given-names>GH</given-names></name><name><surname>Musallam</surname> <given-names>S</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Forward estimation of movement state in posterior parietal cortex</article-title><source>PNAS</source><volume>105</volume><fpage>8170</fpage><lpage>8177</lpage><pub-id pub-id-type="doi">10.1073/pnas.0802602105</pub-id><pub-id pub-id-type="pmid">18499800</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papaxanthis</surname> <given-names>C</given-names></name><name><surname>Pozzo</surname> <given-names>T</given-names></name><name><surname>Skoura</surname> <given-names>X</given-names></name><name><surname>Schieppati</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002a</year><article-title>Does order and timing in performance of imagined and actual movements affect the motor imagery process? the duration of walking and writing task</article-title><source>Behavioural Brain Research</source><volume>134</volume><fpage>209</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1016/S0166-4328(02)00030-X</pub-id><pub-id pub-id-type="pmid">12191807</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papaxanthis</surname> <given-names>C</given-names></name><name><surname>Schieppati</surname> <given-names>M</given-names></name><name><surname>Gentili</surname> <given-names>R</given-names></name><name><surname>Pozzo</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2002">2002b</year><article-title>Imagined and actual arm movements have similar durations when performed under different conditions of direction and mass</article-title><source>Experimental Brain Research</source><volume>143</volume><fpage>447</fpage><lpage>452</lpage><pub-id pub-id-type="doi">10.1007/s00221-002-1012-1</pub-id><pub-id pub-id-type="pmid">11914790</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname> <given-names>K</given-names></name><name><surname>Nestor</surname> <given-names>PJ</given-names></name><name><surname>Rogers</surname> <given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Where do you know what you know? the representation of semantic knowledge in the human brain</article-title><source>Nature Reviews Neuroscience</source><volume>8</volume><fpage>976</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1038/nrn2277</pub-id><pub-id pub-id-type="pmid">18026167</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pei</surname> <given-names>YC</given-names></name><name><surname>Denchev</surname> <given-names>PV</given-names></name><name><surname>Hsiao</surname> <given-names>SS</given-names></name><name><surname>Craig</surname> <given-names>JC</given-names></name><name><surname>Bensmaia</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Convergence of submodality-specific input onto neurons in primary somatosensory cortex</article-title><source>Journal of Neurophysiology</source><volume>102</volume><fpage>1843</fpage><lpage>1853</lpage><pub-id pub-id-type="doi">10.1152/jn.00235.2009</pub-id><pub-id pub-id-type="pmid">19535484</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pons</surname> <given-names>TP</given-names></name><name><surname>Garraghty</surname> <given-names>PE</given-names></name><name><surname>Friedman</surname> <given-names>DP</given-names></name><name><surname>Mishkin</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Physiological evidence for serial processing in somatosensory cortex</article-title><source>Science</source><volume>237</volume><fpage>417</fpage><lpage>420</lpage><pub-id pub-id-type="doi">10.1126/science.3603028</pub-id><pub-id pub-id-type="pmid">3603028</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puckett</surname> <given-names>AM</given-names></name><name><surname>Bollmann</surname> <given-names>S</given-names></name><name><surname>Barth</surname> <given-names>M</given-names></name><name><surname>Cunnington</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Measuring the effects of attention to individual fingertips in somatosensory cortex using ultra-high field (7T) fMRI</article-title><source>NeuroImage</source><volume>161</volume><fpage>179</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.08.014</pub-id><pub-id pub-id-type="pmid">28801252</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pulvermüller</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How neurons make meaning: brain mechanisms for embodied and abstract-symbolic semantics</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>458</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.06.004</pub-id><pub-id pub-id-type="pmid">23932069</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ralph</surname> <given-names>MA</given-names></name><name><surname>Jefferies</surname> <given-names>E</given-names></name><name><surname>Patterson</surname> <given-names>K</given-names></name><name><surname>Rogers</surname> <given-names>TT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The neural and computational bases of semantic cognition</article-title><source>Nature Reviews Neuroscience</source><volume>18</volume><fpage>42</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.150</pub-id><pub-id pub-id-type="pmid">27881854</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reed</surname> <given-names>JL</given-names></name><name><surname>Qi</surname> <given-names>HX</given-names></name><name><surname>Zhou</surname> <given-names>Z</given-names></name><name><surname>Bernard</surname> <given-names>MR</given-names></name><name><surname>Burish</surname> <given-names>MJ</given-names></name><name><surname>Bonds</surname> <given-names>AB</given-names></name><name><surname>Kaas</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Response properties of neurons in primary somatosensory cortex of owl monkeys reflect widespread spatiotemporal integration</article-title><source>Journal of Neurophysiology</source><volume>103</volume><fpage>2139</fpage><lpage>2157</lpage><pub-id pub-id-type="doi">10.1152/jn.00709.2009</pub-id><pub-id pub-id-type="pmid">20164400</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Regev</surname> <given-names>TI</given-names></name><name><surname>Winawer</surname> <given-names>J</given-names></name><name><surname>Gerber</surname> <given-names>EM</given-names></name><name><surname>Knight</surname> <given-names>RT</given-names></name><name><surname>Deouell</surname> <given-names>LY</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human posterior parietal cortex responds to visual stimuli as early as peristriate occipital cortex</article-title><source>European Journal of Neuroscience</source><volume>48</volume><fpage>3567</fpage><lpage>3582</lpage><pub-id pub-id-type="doi">10.1111/ejn.14164</pub-id><pub-id pub-id-type="pmid">30240547</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roland</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Somatotopical tuning of postcentral gyrus during focal attention in man. A regional cerebral blood flow study</article-title><source>Journal of Neurophysiology</source><volume>46</volume><fpage>744</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1152/jn.1981.46.4.744</pub-id><pub-id pub-id-type="pmid">7288462</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rosenbaum</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="1983">1983a</year><chapter-title>The movement precuing technique: assumptions, applications and extensions</chapter-title><person-group person-group-type="editor"><name><surname>Magill</surname> <given-names>R. A</given-names></name></person-group><source>Memory and Control of Action</source><publisher-name>Amsterdam</publisher-name><fpage>231</fpage><lpage>274</lpage></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenbaum</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="1983">1983b</year><article-title>The movement precuing technique: assumptions, applications and extensions</article-title><source>Advances in Psychology</source><volume>12</volume><fpage>231</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1016/S0166-4115(08)61994-9</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruben</surname> <given-names>J</given-names></name><name><surname>Schwiemann</surname> <given-names>J</given-names></name><name><surname>Deuchert</surname> <given-names>M</given-names></name><name><surname>Meyer</surname> <given-names>R</given-names></name><name><surname>Krause</surname> <given-names>T</given-names></name><name><surname>Curio</surname> <given-names>G</given-names></name><name><surname>Villringer</surname> <given-names>K</given-names></name><name><surname>Kurth</surname> <given-names>R</given-names></name><name><surname>Villringer</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Somatotopic organization of human secondary somatosensory cortex</article-title><source>Cerebral Cortex</source><volume>11</volume><fpage>463</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1093/cercor/11.5.463</pub-id><pub-id pub-id-type="pmid">11313298</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutishauser</surname> <given-names>U</given-names></name><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Rosario</surname> <given-names>ER</given-names></name><name><surname>Pouratian</surname> <given-names>N</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single-Neuron representation of memory strength and recognition confidence in left human posterior parietal cortex</article-title><source>Neuron</source><volume>97</volume><fpage>209</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.029</pub-id><pub-id pub-id-type="pmid">29249283</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saal</surname> <given-names>HP</given-names></name><name><surname>Harvey</surname> <given-names>MA</given-names></name><name><surname>Bensmaia</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Rate and timing of cortical responses driven by separate sensory channels</article-title><source>eLife</source><volume>4</volume><elocation-id>e10450</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10450</pub-id><pub-id pub-id-type="pmid">26650354</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakata</surname> <given-names>H</given-names></name><name><surname>Takaoka</surname> <given-names>Y</given-names></name><name><surname>Kawarasaki</surname> <given-names>A</given-names></name><name><surname>Shibutani</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Somatosensory properties of neurons in the superior parietal cortex (area 5) of the rhesus monkey</article-title><source>Brain Research</source><volume>64</volume><fpage>85</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(73)90172-8</pub-id><pub-id pub-id-type="pmid">4360893</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakellaridi</surname> <given-names>S</given-names></name><name><surname>Christopoulos</surname> <given-names>VN</given-names></name><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Pejsa</surname> <given-names>KW</given-names></name><name><surname>Rosario</surname> <given-names>ER</given-names></name><name><surname>Ouellette</surname> <given-names>D</given-names></name><name><surname>Pouratian</surname> <given-names>N</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Intrinsic variable learning for Brain-Machine interface control by human anterior intraparietal cortex</article-title><source>Neuron</source><volume>102</volume><fpage>694</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.02.012</pub-id><pub-id pub-id-type="pmid">30853300</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname> <given-names>TT</given-names></name><name><surname>Blankenburg</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The somatotopy of mental tactile imagery</article-title><source>Frontiers in Human Neuroscience</source><volume>13</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2019.00010</pub-id><pub-id pub-id-type="pmid">30833894</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schnitzler</surname> <given-names>A</given-names></name><name><surname>Salmelin</surname> <given-names>R</given-names></name><name><surname>Salenius</surname> <given-names>S</given-names></name><name><surname>Jousmäki</surname> <given-names>V</given-names></name><name><surname>Hari</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Tactile information from the human hand reaches the ipsilateral primary somatosensory cortex</article-title><source>Neuroscience Letters</source><volume>200</volume><fpage>25</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1016/0304-3940(95)12065-C</pub-id><pub-id pub-id-type="pmid">8584258</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seelke</surname> <given-names>AM</given-names></name><name><surname>Padberg</surname> <given-names>JJ</given-names></name><name><surname>Disbrow</surname> <given-names>E</given-names></name><name><surname>Purnell</surname> <given-names>SM</given-names></name><name><surname>Recanzone</surname> <given-names>G</given-names></name><name><surname>Krubitzer</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Topographic maps within brodmann's Area 5 of macaque monkeys</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>1834</fpage><lpage>1850</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr257</pub-id><pub-id pub-id-type="pmid">21955920</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname> <given-names>MI</given-names></name><name><surname>Huang</surname> <given-names>RS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multisensory maps in parietal cortex</article-title><source>Current Opinion in Neurobiology</source><volume>24</volume><fpage>39</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.08.014</pub-id><pub-id pub-id-type="pmid">24492077</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smialowski</surname> <given-names>P</given-names></name><name><surname>Frishman</surname> <given-names>D</given-names></name><name><surname>Kramer</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Pitfalls of supervised feature selection</article-title><source>Bioinformatics</source><volume>26</volume><fpage>440</fpage><lpage>443</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp621</pub-id><pub-id pub-id-type="pmid">19880370</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snyder</surname> <given-names>AC</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Distinct population codes for attention in the absence and presence of visual stimulation</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>4382</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06754-5</pub-id><pub-id pub-id-type="pmid">30348942</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soso</surname> <given-names>MJ</given-names></name><name><surname>Fetz</surname> <given-names>EE</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Responses of identified cells in postcentral cortex of awake monkeys during comparable active and passive joint movements</article-title><source>Journal of Neurophysiology</source><volume>43</volume><fpage>1090</fpage><lpage>1110</lpage><pub-id pub-id-type="doi">10.1152/jn.1980.43.4.1090</pub-id><pub-id pub-id-type="pmid">6766995</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sur</surname> <given-names>M</given-names></name><name><surname>Merzenich</surname> <given-names>MM</given-names></name><name><surname>Kaas</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Magnification, receptive-field area, and &quot;hypercolumn&quot; size in areas 3b and 1 of somatosensory cortex in owl monkeys</article-title><source>Journal of Neurophysiology</source><volume>44</volume><fpage>295</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1152/jn.1980.44.2.295</pub-id><pub-id pub-id-type="pmid">7411189</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tamè</surname> <given-names>L</given-names></name><name><surname>Pavani</surname> <given-names>F</given-names></name><name><surname>Papadelis</surname> <given-names>C</given-names></name><name><surname>Farnè</surname> <given-names>A</given-names></name><name><surname>Braun</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Early integration of bilateral touch in the primary somatosensory cortex</article-title><source>Human Brain Mapping</source><volume>36</volume><fpage>1506</fpage><lpage>1523</lpage><pub-id pub-id-type="doi">10.1002/hbm.22719</pub-id><pub-id pub-id-type="pmid">25514844</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tamè</surname> <given-names>L</given-names></name><name><surname>Braun</surname> <given-names>C</given-names></name><name><surname>Holmes</surname> <given-names>NP</given-names></name><name><surname>Farnè</surname> <given-names>A</given-names></name><name><surname>Pavani</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Bilateral representations of touch in the primary somatosensory cortex</article-title><source>Cognitive Neuropsychology</source><volume>33</volume><fpage>48</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1080/02643294.2016.1159547</pub-id><pub-id pub-id-type="pmid">27314449</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tandon</surname> <given-names>S</given-names></name><name><surname>Kambi</surname> <given-names>N</given-names></name><name><surname>Lazar</surname> <given-names>L</given-names></name><name><surname>Mohammed</surname> <given-names>H</given-names></name><name><surname>Jain</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Large-scale expansion of the face representation in somatosensory Areas of the lateral sulcus after spinal cord injuries in monkeys</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>12009</fpage><lpage>12019</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2118-09.2009</pub-id><pub-id pub-id-type="pmid">19776287</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vázquez</surname> <given-names>Y</given-names></name><name><surname>Zainos</surname> <given-names>A</given-names></name><name><surname>Alvarez</surname> <given-names>M</given-names></name><name><surname>Salinas</surname> <given-names>E</given-names></name><name><surname>Romo</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural coding and perceptual detection in the primate somatosensory thalamus</article-title><source>PNAS</source><volume>109</volume><fpage>15006</fpage><lpage>15011</lpage><pub-id pub-id-type="doi">10.1073/pnas.1212535109</pub-id><pub-id pub-id-type="pmid">22927423</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williford</surname> <given-names>T</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Effects of spatial attention on contrast response functions in macaque area V4</article-title><source>Journal of Neurophysiology</source><volume>96</volume><fpage>40</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1152/jn.01207.2005</pub-id><pub-id pub-id-type="pmid">16772516</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wise</surname> <given-names>NJ</given-names></name><name><surname>Frangos</surname> <given-names>E</given-names></name><name><surname>Komisaruk</surname> <given-names>BR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Activation of sensory cortex by imagined genital stimulation: an fMRI analysis</article-title><source>Socioaffective Neuroscience &amp; Psychology</source><volume>6</volume><elocation-id>31481</elocation-id><pub-id pub-id-type="doi">10.3402/snp.v6.31481</pub-id><pub-id pub-id-type="pmid">27791966</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>CY</given-names></name><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Revechkis</surname> <given-names>B</given-names></name><name><surname>Rosario</surname> <given-names>ER</given-names></name><name><surname>Ouellette</surname> <given-names>D</given-names></name><name><surname>Pouratian</surname> <given-names>N</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Partially mixed selectivity in human posterior parietal association cortex</article-title><source>Neuron</source><volume>95</volume><fpage>697</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.040</pub-id><pub-id pub-id-type="pmid">28735750</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>CY</given-names></name><name><surname>Aflalo</surname> <given-names>T</given-names></name><name><surname>Revechkis</surname> <given-names>B</given-names></name><name><surname>Rosario</surname> <given-names>E</given-names></name><name><surname>Ouellette</surname> <given-names>D</given-names></name><name><surname>Pouratian</surname> <given-names>N</given-names></name><name><surname>Andersen</surname> <given-names>RA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Preservation of partially mixed selectivity in human posterior parietal cortex across changes in task context</article-title><source>Eneuro</source><volume>7</volume><elocation-id>ENEURO.0222-19.2019</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0222-19.2019</pub-id><pub-id pub-id-type="pmid">31969321</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname> <given-names>Z</given-names></name><name><surname>Disbrow</surname> <given-names>EA</given-names></name><name><surname>Zumer</surname> <given-names>JM</given-names></name><name><surname>McGonigle</surname> <given-names>DJ</given-names></name><name><surname>Nagarajan</surname> <given-names>SS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Spatiotemporal integration of tactile information in human somatosensory cortex</article-title><source>BMC Neuroscience</source><volume>8</volume><elocation-id>21</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2202-8-21</pub-id><pub-id pub-id-type="pmid">17359544</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.61646.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Makin</surname><given-names>Tamar R</given-names></name><role>Reviewing Editor</role><aff><institution>University College London</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p>Thank you for submitting your article &quot;Neural encoding of felt and imagined touch within human posterior parietal cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by Tamar Makin as the Senior and Reviewing Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, we are asking editors to accept without delay manuscripts, like yours, that they judge can stand as <italic>eLife</italic> papers without additional data, even if they feel that they would make the manuscript stronger. Thus the revisions requested below only address clarity and presentation.</p><p>Chivukula and colleagues report an extensive set of multi-unit neural recordings from PPC of a tetraplegic patient taking part in a brain machine interface clinical trial. The recordings were collected across a set of tasks, designed to investigate neuronal responses to both experienced and imagined touch. It was found that many neurons are responsive to touch in specific locations. Most of the recorded neurons were activated bilaterally, which is consistent with earlier monkey work from this lab. Probably the most important component of the work is the analysis of the modest activation in this area that occurs simply when the participant imagines different places on her body being touched – even the insensate arm. This work is virtually impossible to do in animals, and as such offers a unique opportunity to describe neural properties for higher-level representation of touch. The study therefore paves the way for a deeper understanding of the role of the human PPC in the cognitive processing of somatosensation.</p><p>Overall, we found the manuscript to be well-written, the study to be interesting, and for the most part the analyses are well thought out. But at the same time, the reviewers raised multiple main concerns regarding missing information and unclear descriptions of some of the analyses undertaken, which are detailed below. In addition, it was felt that there was unnecessary overlap across analyses – the first part especially contains a number of analyses that seem to make very similar points repeatedly or where it is not entirely clear what the point is in the first place. As such, there is a need to identify and cut a lot of the duplicative analyses/results and explain both the essential methods and the interpretation of the remaining results more succinctly and clearly. The key analyses could then be streamlined and better justified, ideally with an eye towards a consistent approach in both parts of the paper. As you will see, most of the comments detailed below are geared towards guiding the authors through this major revision (please forgive any duplicative comments on our behalf, given the technical nature of most of the comments, the Editor was keen to preserve the original comments as made by the reviewers). In addition, there are also some major considerations regarding the contextualisation and interpretation of the key imagery results, as detailed in the first major comment below.</p><p>1) Perhaps the most exciting innovation of the study relates to the neural responses related to the imagery conditions. Yet, we know from many previous studies in humans that cognitive processes (most notably attention), can modulate somatosensory responses. What the current study offers is an opportunity to characterise this cognitive modulation at a single neuron (and population) level over space and time, with hopes of achieving better insight into its underlying mechanism. While the reviewers agree that this unique contribution is valuable, it was also agreed that the manuscript would benefit from additional context in the Introduction as well as a more thorough discussion – particularly with respect to related research on this topic and potential mechanisms that could be recruited to support the observed neural modulation during the imagery condition.</p><p>Introduction: The second paragraph did well in establishing why one might be interested in examining somatosensory processing in the PPC. It was however, less clear why the particular questions at the end of the paragraph were being posed. Perhaps an extra paragraph could be added to bridge the notion that a sizeable body of literature has been developed around somatosensory representation within the PPC and the several &quot;fundamental&quot; questions remaining that are of interest here.</p><p>Discussion: The manuscript would benefit from a more thorough discussion of &quot;imagination per se&quot; and the various top-down processes that might be involved – as well as better positioning with respect to previous studies investigating top-down modulation of the somatosensory system. The authors state that the cognitive engagement during the tactile imagery may reflect semantic processing, sensory anticipation, and imagined touch per se – which we would not argue. But we would also expect some explicit mention of processes like attention and prediction. Perhaps these are intended to be captured by &quot;sensory anticipation&quot; – but, for example, attention can be deployed even if no sensation is anticipated. Importantly, it seems that imagining a sensation at a particular body site might well involve attending to that body part. That is, one may first attend to a body part before &quot;imagining&quot; a sensation there – and then even continue to attend there the entire time the imagining is being done. Because of this, perhaps the authors are considering attention to be a part of &quot;imagination per se&quot;. But since attention has been shown to modulate somatosensory cortex without imagination, how can one exclude the possibility that the neuronal activity measured here simply reflects this attention component?</p><p>Regardless, we think the Discussion would benefit from a more explicit treatment of these top-down processes – especially given the number of previous studies showing that they are able to modulate activity throughout the somatosensory system. Some literature that may be of interest include:</p><p>Roland P (1981) Somatotopical tuning of postcentral gyrus during focal attention in man. A regional cerebral blood flow study. Journal of Neurophysiology 46 (4):744-754</p><p>Johansen-Berg H, Christensen V, Woolrich M, Matthews PM (2000) Attention to touch modulates activity in both primary and secondary somatosensory areas. Neuroreport 11 (6):1237-1241</p><p>Hamalainen H, Hiltunen J, Titievskaja I (2000) fMRI activations of SI and SII cortices during tactile stimulation depend on attention. Neuroreport 11 (8):1673-1676. doi:10.1097/00001756-200006050-00016</p><p>Puckett AM, Bollmann S, Barth M, Cunnington R (2017) Measuring the effects of attention to individual fingertips in somatosensory cortex using ultra-high field (7T) fMRI. Neuroimage 161:179-187. doi:10.1016/j.neuroimage.2017.08.014</p><p>Yu Y, Huber L, Yang J, Jangraw DC, Handwerker DA, Molfese PJ, Chen G, Ejima Y, Wu J, Bandettini PA (2019) Layer-specific activation of sensory input and predictive feedback in the human primary somatosensory cortex. Sci Adv 5 (5):eaav9053. doi:10.1126/sciadv.aav9053</p><p>More useful references could be found in this recent review:</p><p>https://doi.org/10.1016/j.neuroimage.2020.117255</p><p>2) The Materials and methods would benefit from additional rationale / supporting references throughout. Whereas it is generally clear what was done, it is sometimes less clear why certain choices were made. Perhaps some of the choices are &quot;standard practice&quot; when working with single unit recordings, but I was left in want of a bit more reasoning (or at least direction to relevant literature). Some examples are below:</p><p>For the population correlation: why was the correlation computed 250 times or why were the two distributions shuffled together 2000 times?</p><p>For the decode analysis: consider providing a reference for those interested in better understanding the &quot;peeking&quot; effects mentioned.</p><p>Response latency: how were window parameters determined (for both visualization and the latency calculation). And what was the rationale for them being different – especially given that the data used for the response latency calculation was still visualized (at least in part)? Relatedly, I'd be curious to see the entire time-course for that data rather than just the shaded region of the &quot;visualization&quot; data. Also, it would be nice if a comment (or some data) could be provided regarding how much the latency estimates change based on these parameter choices.</p><p>Temporal dynamics of population activity: why use a 500 ms window, stepped at 100 ms intervals instead of something else?</p><p>Temporal dynamics of single unit activity: it is stated that the neurons were restricted to those whose 90th percentile accuracy was at least 50% to ensure only neurons with some degree of significant selectivity were used for the cluster analysis. But why these particular values? Are the results sensitive to this choice? In this section, I'd also suggest providing references for those interested in better understanding the use of Bayesian information criteria. Similarly, it is stated that PCA is a &quot;standard method for describing the behavior of neural populations&quot; – as such it would be nice to provide some relevant references for the reader</p><p>3) At the start of the Results section it is stated that the recordings were from &quot;well-isolate and multi-unit neurons&quot;. This seems to contradict the Materials and methods section, which only talks about &quot;sorted&quot; neurons. This needs to be clarified, and if multi-units were included, it should be stated which sections this concerns as it will have implications for the results (e.g. for selectivity for different body parts). In any case, the number of neurons included in different analyses should be evident. There are some numbers in the Materials and methods and sprinkled throughout the Results section, but for some of the analyses (e.g. clustering analysis, which was run only on a responsive subset of neurons) no numbers are provided.</p><p>4) The linear analysis section needs further details. The coefficients are matched to &quot;conditions&quot; but it is not explained how. I am assuming that each touch location is assigned to a condition c, however the way the model is described suggests that the vector X can in principle have multiple conditions active at the same time. Additionally, could the authors confirm whether it is the significance of the coefficients that determined whether a neuron was classed as responsive as shown in Figure 1? This analysis states a p-value but does give no further information on which test was run and on what data.</p><p>5) Figure 1C could be converted into a matrix that lists all combinations of RF numbers on either side of the body to highlight whether larger RFs on one side of the body generally imply larger RFs on the other side.</p><p>6) I am confused about the interpretation of the coefficient of determination as shown in Figure 2A. In the text this is described as testing the &quot;selectivity&quot; of the neurons. To clarify, I am assuming that the &quot;regression analysis&quot; is referring to the linear model described in a previous section. The authors then presumably took the coefficients from this model for a single side only and tested how well they could predict the responses to the opposite side, as assessed by R<sup>2</sup> (Figure 2C,E). Before that in Figure 2A, they tested how well each single-side model could predict the responses. This is all fine, but the &quot;within&quot; comparison then simply tests how well a linear model can explain the observed responses, and has nothing to do with the selectivity of the neuron. For example, the neuron might be narrowly or broadly selective, but the model might fit equally well.</p><p>7) We computed a cross-validated coefficient of determination (R<sup>2</sup> within) to measure the strength of neuronal selectivity for each body side.</p><p>Even after reading the methods (further comments below) it is difficult to figure out what all these related measures reveal. At this point in the text it is very difficult to intuit how R<sup>2</sup> would measure selectivity.</p><p>8) Regarding the timing analysis, it is not clear to me how the accuracy can top out at 100% as shown in the figure, when the control conditions were included. Additionally, the authors should state the p value and statistic for the comparison of latencies.</p><p>9) Spatial analysis. Could the authors provide the size of the paintbrush tip that was used in this analysis. Furthermore, as stimulation sites were 2 cm apart, it is not appropriate to specify receptive fields down to millimeter precision.</p><p>10) Imagery: how many neurons were responsive to both imagery and real touch? Were all neurons that were responsive to imagery also responsive to actual touch? This is left vague and Figure 5 only includes the percentages per condition, but gives no indication of how many neurons responded to several conditions. Whether and how many neurons were responsive to both conditions also determines the ceiling for the correlation analysis in Figure 5D (e.g. if the most neurons are responsive only to actual but not imaginary touch, this will limit the population correlation).</p><p>11) What is added by including both classification and Mahalanobis distance?</p><p>Relatedly, information coding evolves for a single unit. Two complimentary analyses were then performed.</p><p>In what sense are they complementary? What is added (besides complexity) by including both cluster analysis and PCA?</p><p>12) Classification was performed using linear discriminant analysis with the following assumptions:</p><p>one, the prior probability across tested task epochs was uniform;</p><p>It is not clear what prior probability this refers to. Just stimulus site?</p><p>two, the conditional probability distribution of each unit on any epoch was normal;</p><p>Is this a reference to firing rate probability conditioned on stimulus site?</p><p>three, only the mean firing rates differ for unit activity during each epoch (covariance of the normal distributions are the same for each);</p><p>four, firing rates for each input are independent (covariance of the normal distribution is diagonal).</p><p>Does this refer to independent firing rates of neurons across stimulus sites? This seem very unlikely, given everything we know about dimensionality of cortex. Perhaps it refers to something else. Cannot all of these assumptions be tested? Were they?</p><p>13) We computed the cross-validated coefficient of determination</p><p>(R2 within) to measure how well a neuron's firing rate could be explained by the responses to the sensory fields.</p><p>This needs a better description, and I may be missing the point entirely. I assume it is an analysis of mean firing rate (which should be stated explicitly) and that it uses something like the indicator variable of the linear analysis of individual neuron tuning above. In this case is this is a logistic regression? As it is computed for each side independently, it would appear that there are only four bits to describe the firing of any given neuron. This would seem to be a pretty impoverished statistic, even if the statistical model is accurate.</p><p>14) The purpose of computing a specificity index was to quantify the degree to which a neuron was tuned to represent information pertaining to one side of the body over the other.</p><p>This is all pretty hard to follow. The R2 metric itself is a bit mysterious, as noted above. Within and across R2 is fairly straightforward, but adds to the complexity, as does SI, which makes comparisons of three different combinations of these measures across sides. Aside from R2 itself, the math is pretty transparent. However, a better high-level description of what insight all the different combinations provide would help to justify using them all. As is, there is no discussion and virtually no description of the difference across these three scatter plot. The critical point apparently, is that, &quot;nearly all recorded PC-IP neurons demonstrate bilateral coding&quot;. There should be much a more direct way to make this point.</p><p>15) Computing response latency via RF discrimination is rather indirect and assumes that there is significant classification in the first place. I suspect it will add at least some delay beyond more typical tests. Why not a far simpler and more direct test of means in the same sliding window? Alternatively, a change point analysis?</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Neural encoding of felt and imagined touch within human posterior parietal cortex&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by Tamar Makin as the Senior and Reviewing Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The reviewers were happy with the vast majority of the extensive revisions that have been implemented relative to the original submission, but felt that the presentation of the results and their discussion was inadequate. While we recognise the enormous amount of work that was poured into the revisions, there are still a few issues, originating from the revisions, that the reviewers felt require further consideration. But beyond these specific considerations that are elaborated below, we all agreed that the paper, at its present form, is too dense with results/interpretation, making it very difficult to read and evaluate. As one of the reviewers summarised:</p><p>&quot;My main high-level concern was the, &quot;extensive and overlapping analyses&quot; that made it difficult to follow and to find a clear takeaway message from the paper. I suggested eliminating a number of figures and clarifying the remainder to improve the impact of the paper. Although a few small panels have disappeared, most of the duplication remains and there are now nine, fairly complex figures (had been eight). It's hard to judge how much longer the text got because the figures are no longer embedded, but that has certainly also increased. The paper has not improved as a consequence&quot;.</p><p>There is a strong need for a “deep clean” (or more precisely deep edit) of the paper. As highlighted in our original review, there's a lot of overlap between analyses/findings that will not be of interest to the average reader. We believe the key innovation of the study – the imagery results – could be presented a lot more concisely with a more focused discussion of the findings and the limitations of the suggested interpretation. Much of the details of the tactile RF properties is of secondary interest and as such should be moved to the supplementary section. I leave the decision of how to achieve this leaner and more focused version to the authors, but please consider the average reader (and their very limited time and attention span) when making the edits. As a rule of thumb, the reviewers estimated you will be likely be able to remove ~50% of the figure panels and 33% of the main text without weakening the key findings.</p><p>1) Perhaps the most exciting innovation of the study relates to the neural responses related to the imagery conditions. Yet, we know from many previous studies in humans that cognitive processes…</p><p>While the Introduction has been much improved, the Discussion still mostly disregards the alternative cognitive processes that are likely to drive the present findings (prediction, attention). The authors seem to downplays the impact of attention considerably. For example, they state:</p><p>&quot;Most studies of pre-stimulus attention report that any modulation of baseline activity is modest at best.&quot;</p><p>But especially when considering the modest effects of imagery, this statement is misleading. The Roland (1981) study that we provided, for example, show a 25% increase in rCBF when subjects attended the index finger without being stimulated. And this increase was spatially specific as it shifted to the lip area when attending to the upper lip instead of the finger. Although the other 3 attention references were looking at the effects of attention while sensory stimulation was present, they still seem relevant to the discussion and show what I'd consider to be greater than modest effects of attention. For example, the Puckett (2017) reference shows clear digit-specific modulation when attending to the different fingertips. Note that despite stimulation being present during this condition, the stimulation was constant (allowing the phasic attention-related signal to be somewhat isolated from the sensory signal). The amplitude of the phasic attention signal was similar to that elicited by phasic stimulation alone (i.e., without endogenous attention).</p><p>There needs to be a more serious consideration that the effects attributed here to imagery are in fact modulated by (or even driven by) related cognitive processes, such as prediction and attention, which are not specifically linked to the auditory cue used in the present study.</p><p>2) Figure 4: Several panels would be more effective…</p><p>This figure has changed quite lot, addressing my cosmetic concerns. However, I do not understand this statistical test: If no comparison was significant (FDR corrected), the unit was classified as &quot;single peak.&quot; If at least one of the comparisons was statistically significant, it was characterized as &quot;multi-peak.&quot; I must be missing something fundamental. I took this to be a test of differences of the responses to the different body parts, with respect to the peak response. How is this a single peak? No differences sounds like a flat line. By this definition a neuron with no response whatsoever would be &quot;single peak&quot;. Likewise, the multi-peak definition is a puzzle.</p><p>3) What is added by including both classification and Mahalanobis distance?</p><p>&quot;Mahalanobis distance that provides a sensitive measure of change which is masked by the discretization process of classification &quot;</p><p>I don't think the discrete nature of the classifier output is really the biggest issue. By averaging across many instances, it essentially becomes continuous, as in this figure. There are also classifier-related metrics that are by their nature, continuous. The nature of the distance measure they are making is likely more important. In this case, I do not understand why the classification rises only slightly at t=0 as the M distance increases sharply. Subsequently, between 1 and 2.5 s, classifier success drops back below its original level even as distance is stable. The two measures really don't seem to be concordant. What is going on here? I think this concern is not unrelated to my next comment about Figure 8C (now 9C).</p><p>4) Figure 8C: Despite my best efforts, I have no idea…</p><p>&quot;This asymmetry is likely a consequence of the analysis technique and may not be of physiological significance.”</p><p>I agree with the statement, but not its sentiment. Perhaps I'm missing something, but the fact that a single classifier can distinguish between rest state and two very different activation states does nothing to suggest those two states are a general representation of an input. The classification failure in the opposite direction only reinforces that. Presumably, classifying imagined and actual touch would be trivial, at a much higher level of success than rest and imagined touch, suggesting that they are in fact, rather different, even by this metric. If the authors wish to make the claim that their results show more than grossly common receptive fields bilaterally and across modes (which is not an uninteresting finding) they would do well to adopt tools more appropriate for it, like those that have been used by the groups of Shenoy, Churchland, Miller, Kaufman, and others: Canonical correlations, principal angles, subspace overlap…</p><p>5) Computing response latency via RF discrimination is rather indirect…</p><p>The authors have adopted a more sensible and sensitive test of latency. I do not agree with this statement, however: &quot;We believe this is likely related to discussion above about Mahalanobis distance versus classification: namely, changes in the underlying neural behavior are only detected once the neural responses cross a decision line which likely results in delays detecting changes in neural behavior.&quot; In what fundamental sense is classification significance different from a significant distance in M-space? It seems to me that the more likely explanation is simply that significant modulation precedes significant discrimination.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.61646.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Overall, we found the manuscript to be well-written, the study to be interesting, and for the most part the analyses are well thought out. But at the same time, the reviewers raised multiple main concerns regarding missing information and unclear descriptions of some of the analyses undertaken, which are detailed below. In addition, it was felt that there was unnecessary overlap across analyses – the first part especially contains a number of analyses that seem to make very similar points repeatedly or where it is not entirely clear what the point is in the first place. As such, there is a need to identify and cut a lot of the duplicative analyses/results and explain both the essential methods and the interpretation of the remaining results more succinctly and clearly. The key analyses could then be streamlined and better justified, ideally with an eye towards a consistent approach in both parts of the paper. As you will see, most of the comments detailed below are geared towards guiding the authors through this major revision (please forgive any duplicative comments on our behalf, given the technical nature of most of the comments, the Editor was keen to preserve the original comments as made by the reviewers). In addition, there are also some major considerations regarding the contextualisation and interpretation of the key imagery results, as detailed in the first major comment below.</p><p>1) Perhaps the most exciting innovation of the study relates to the neural responses related to the imagery conditions. Yet, we know from many previous studies in humans that cognitive processes (most notably attention), can modulate somatosensory responses. What the current study offers is an opportunity to characterise this cognitive modulation at a single neuron (and population) level over space and time, with hopes of achieving better insight into its underlying mechanism. While the reviewers agree that this unique contribution is valuable, it was also agreed that the manuscript would benefit from additional context in the Introduction as well as a more thorough discussion – particularly with respect to related research on this topic and potential mechanisms that could be recruited to support the observed neural modulation during the imagery condition.</p><p>Introduction: The second paragraph did well in establishing why one might be interested in examining somatosensory processing in the PPC. It was however, less clear why the particular questions at the end of the paragraph were being posed. Perhaps an extra paragraph could be added to bridge the notion that a sizeable body of literature has been developed around somatosensory representation within the PPC and the several &quot;fundamental&quot; questions remaining that are of interest here.</p></disp-quote><p>We have expanded the Introduction to better situate the questions we address in this manuscript. We have tried to highlight that despite a growing body of literature surrounding higher-order somatosensory processing within the PPC (both in humans and in animal models), there exist gaps in our knowledge related to the spatial structure of tactile receptive fields and whether tactile cognition engages the same populations of cells with similar spatial tuning preferences.</p><p>The modified text is below.</p><p>Introduction:</p><p>“Touch is a complex, multisensory perceptual process (1-3). In non-human primates (NHPs), multisensory input (e.g., visual, tactile) converges upon neurons in higher-order brain regions such as the posterior parietal cortex (PPC) where they are integrated into coherent representations (3-11). […] The latter represents a novel finding, thus far untestable in NHP models, and suggests PPC involvement in the cognitive processing of touch.”</p><disp-quote content-type="editor-comment"><p>Discussion: The manuscript would benefit from a more thorough discussion of &quot;imagination per se&quot; and the various top-down processes that might be involved – as well as better positioning with respect to previous studies investigating top-down modulation of the somatosensory system. The authors state that the cognitive engagement during the tactile imagery may reflect semantic processing, sensory anticipation, and imagined touch per se – which we would not argue. But we would also expect some explicit mention of processes like attention and prediction. Perhaps these are intended to be captured by &quot;sensory anticipation&quot; – but, for example, attention can be deployed even if no sensation is anticipated. Importantly, it seems that imagining a sensation at a particular body site might well involve attending to that body part. That is, one may first attend to a body part before &quot;imagining&quot; a sensation there – and then even continue to attend there the entire time the imagining is being done. Because of this, perhaps the authors are considering attention to be a part of &quot;imagination per se&quot;. But since attention has been shown to modulate somatosensory cortex without imagination, how can one exclude the possibility that the neuronal activity measured here simply reflects this attention component?</p><p>Regardless, we think the Discussion would benefit from a more explicit treatment of these top-down processes – especially given the number of previous studies showing that they are able to modulate activity throughout the somatosensory system. Some literature that may be of interest include:</p><p>Roland P (1981) Somatotopical tuning of postcentral gyrus during focal attention in man. A regional cerebral blood flow study. Journal of Neurophysiology 46 (4):744-754</p><p>Johansen-Berg H, Christensen V, Woolrich M, Matthews PM (2000) Attention to touch modulates activity in both primary and secondary somatosensory areas. Neuroreport 11 (6):1237-1241</p><p>Hamalainen H, Hiltunen J, Titievskaja I (2000) fMRI activations of SI and SII cortices during tactile stimulation depend on attention. Neuroreport 11 (8):1673-1676. doi:10.1097/00001756-200006050-00016</p><p>Puckett AM, Bollmann S, Barth M, Cunnington R (2017) Measuring the effects of attention to individual fingertips in somatosensory cortex using ultra-high field (7T) fMRI. Neuroimage 161:179-187. doi:10.1016/j.neuroimage.2017.08.014</p><p>Yu Y, Huber L, Yang J, Jangraw DC, Handwerker DA, Molfese PJ, Chen G, Ejima Y, Wu J, Bandettini PA (2019) Layer-specific activation of sensory input and predictive feedback in the human primary somatosensory cortex. Sci Adv 5 (5):eaav9053. doi:10.1126/sciadv.aav9053</p><p>More useful references could be found in this recent review:</p><p>https://doi.org/10.1016/j.neuroimage.2020.117255</p></disp-quote><p>We significantly modified the Discussion to better discuss possible contributions to cognitive touch processing, especially imagery.</p><p>The pertinent modified text from the Discussion is below.</p><p>“What does neural processing within human PC-IP during tactile imagery represent?</p><p>While our task identifies dynamic engagement of multiple cognitive processes during tactile imagery, it is inadequate to precisely define the cognitive correlates of the observed neural activity. […] The above cognitive phenomena may each independently engage the same neural population as distinct phenomena, or may be distinct processes that nonetheless engage the same underlying neural substrate.”</p><disp-quote content-type="editor-comment"><p>2) The Materials and methods would benefit from additional rationale / supporting references throughout. Whereas it is generally clear what was done, it is sometimes less clear why certain choices were made. Perhaps some of the choices are &quot;standard practice&quot; when working with single unit recordings, but I was left in want of a bit more reasoning (or at least direction to relevant literature).</p></disp-quote><p>We have updated the Materials and methods section to clarify the analyses, provide additional technical details, expand motivation for analysis choices, and to point the reader to supporting references for further information.</p><disp-quote content-type="editor-comment"><p>Some examples are below:</p><p>For the population correlation: why was the correlation computed 250 times or why were the two distributions shuffled together 2000 times?</p></disp-quote><p>In the correlation analysis, for each condition (touch location), we split the data into test and training sets, averaged responses across repetitions, and finally computed a correlation to measure population response similarity within and across conditions. Because the correlation was computed for independent training and testing sets, within and across condition correlations can be directly compared. We repeated this process 250 times, each time creating new random assignments of which trials are put into the training and test sets. Each split gives a slightly different correlation value, and we average across all values to give our best estimate of the actual population correlation. Performing the splits 250 times is somewhat arbitrary, but was chosen based on an empirical analysis applied to preliminary data. For preliminary data, we performed the analysis with N splits, with N ranging from 5 to 200 in steps of 5. We found that the mean correlation across splits converged to a stable value by about 80 splits. We then roughly tripled that number to be safe. So 250 was chosen to ensure that the numerical sampling scheme would capture a stable value of our cross-validated correlation metric. A similar process was used for performing 2000 shuffles as part of our permutation shuffle test.</p><p>The following was added to the relevant Materials and methods section (“Population Correlation”)</p><p>“Performing the splits 250 times was chosen based on an empirical analysis applied to preliminary data. For the preliminary data, we performed the analysis with N splits, with N ranging from 5 to 200 in steps of 5. We found that the mean correlation across splits converged to a stable value by approximately 80 splits. We then roughly tripled this value to ensure that the numerical sampling scheme would capture a stable value of our cross-validated correlation metric.”</p><p>“As in the case above, our permutation shuffle test used 2000 shuffles to ensure that the numerical sampling scheme would capture a stable value of the percentile of our true difference as compared to the empirical null distribution.”</p><disp-quote content-type="editor-comment"><p>For the decode analysis: consider providing a reference for those interested in better understanding the &quot;peeking&quot; effects mentioned.</p></disp-quote><p>The “peeking” phenomena refers to overestimation of generalization error when using supervised feature selection on the entire dataset. We have added a reference to the text, Smialowski, Frishman and Kramer, 2010. To quickly touch on the subject and provide intuition, imagine that you have a population of 1000 neurons that are unmodulated by task condition. By chance, some of these units may appear task-modulated: with a p-value of 0.05, we would expect to find 50 or so “modulated” units. This is expected to occur by chance and is the reason multiple comparisons corrections are needed. Here, peeking refers to the situation where neurons are preselected to be modulated prior to cross-validated classification analysis. By cherry-picking “modulated” units you break the logic of cross-validation which requires independence between training and testing sets.</p><disp-quote content-type="editor-comment"><p>Response latency: how were window parameters determined (for both visualization and the latency calculation). And what was the rationale for them being different – especially given that the data used for the response latency calculation was still visualized (at least in part)? Relatedly, I'd be curious to see the entire time-course for that data rather than just the shaded region of the &quot;visualization&quot; data. Also, it would be nice if a comment (or some data) could be provided regarding how much the latency estimates change based on these parameter choices.</p></disp-quote><p>We are replacing the original version of the latency analysis. In line with other reviewer comments, in the updated manuscript, we measure latency using the basic responsiveness, not discriminability, of the neural population. One benefit of the updated approach is that we did not have to introduce any additional smoothing beyond averaging activity within 2 ms windows. The updates and rationale for the new latency calculation are discussed in response to major point 15.</p><p>The following is not included in the revised manuscript as we have revised how we perform the latency analysis. While no longer pertinent to the latency analysis in the revised manuscript, we include a response below for completeness:</p><p>As background, selecting the window size/smoothing kernel involves a balance between preserving temporal resolution (which asks for a smaller time window) and mitigating against noise (which asks for a larger window). For computing the latency estimate, fine temporal resolution is critical and so we chose a narrow smoothing kernel, essentially as small as we could make it without high-frequency noise obscuring the transition. Given our truncated Gaussian kernel, increasing the kernel width (smoothing more) pulls in information from the future and past into the firing rate estimate at the current moment in time. In computing latencies, this is highly problematic as it destroys any ability to resolve the absolute timing of signals. With our truncated Gaussian kernel, increasing the smoothing kernel for computing latency simply results in earlier and earlier latency estimates, but only because the firing rate estimate is allowed to peak further and further into the future. For the “visualization” kernel, the latency was actually pre-stimulus (~-100 ms). It is possible to use “causal” filters that can only smooth by averaging past data (not past and future.) This does not solve the core problem though. Increasing the smoothing width in this case simply delays the latency more and more as an increasing amount of the data used to compute the estimate comes from pre-stimulus activity thus adding noise and decreasing sensitivity. This same basic challenge is inherent in all techniques, although it is not always explicit. For example, hidden Markov models essentially use exponential smoothing where the smoothing coefficient is indirectly set by the window durations used for the pre and post-stimulus phases (which is still an experimenter choice).</p><p>Please see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref> for a plot of the full window with the “latency” smoothing kernel. Orange=contralateral, blue = ipsilateral. It’s fairly innocuous and essentially shows the same results as the “visualization” kernel with more high-frequency noise (as expected).</p><fig id="sa2fig1"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-resp-fig1-v1.tif"/></fig><p>We understand why choosing two separate smoothing’s, especially without better justification, warranted scrutiny. In brief, the only point of the “visualization” was to show that classification performance over the course of the trial was well behaved, with chance performance before the stimulus and sustained accurate performance after. For this basic point, a smoother signal with larger time steps seemed appropriate and required less time to compute. Again, the new version uses no smoothing and only has one visualization (see point 15).</p><disp-quote content-type="editor-comment"><p>Temporal dynamics of population activity: why use a 500 ms window, stepped at 100 ms intervals instead of something else?</p></disp-quote><p>Unlike the original latency analysis, for all other analysis we used a 500 ms window size for averaging time series data (also called box-car smoothing). We chose a fixed window size (as opposed to e.g. truncated Gaussian) as the exact bounds of what data was used in analysis is transparent for any particular analysis window. The use of 500 ms is somewhat arbitrary and was chosen as a balance between temporal resolution and noise mitigation. While the exact choice of window size can massage around various metrics (e.g. larger smoothing window can increase R<sup>2</sup>), for anything with decent signal-to-noise, as is the case with our data, the exact choice of smoothing size is fairly inconsequential so long as the same kernel is used when making comparisons between different conditions. The choice of step size is essentially anchored to the choice of smoothing window. We could have stepped at 1ms, but with a 500 ms smoothing window, such a small step is not justified. 100 ms, representing a change in 20% of the data, allows us the ability to temporally localize changes in neural responses while being efficient with our compute time. We have added text to the Materials and methods (“Temporal dynamics of population activity during tactile imagery task: within category”) as well to clarify the choice of time window and step size. The text is copied below.</p><p>“We used a fixed window size for averaging time series data for analysis (box-car smoothing) as it provides straight-forward bounds for the temporal range of data that are included in the analysis for a particular time window. 500 ms was chosen as a good balance between temporal resolution and noise mitigation. We note that although the window size can influence various metrics (e.g., larger smoothing windows can increase coefficients of determination, R<sup>2</sup>) the choice of smoothing size is largely inconsequential as long as the kernel size is kept consistent when making comparisons across conditions. The choice of a 100 ms step size was anchored to the choice of smoothing window. A small step, such as 1 ms would not be justified with a 500 ms time window. We chose 100 ms, representing a change in 20% of the data, to allow us the ability to temporally localize changes in neural response without unnecessarily oversampling a smoothed signal and thus not unnecessarily increasing computation time for analysis.”</p><disp-quote content-type="editor-comment"><p>Temporal dynamics of single unit activity: it is stated that the neurons were restricted to those whose 90th percentile accuracy was at least 50% to ensure only neurons with some degree of significant selectivity were used for the cluster analysis. But why these particular values? Are the results sensitive to this choice? In this section, I'd also suggest providing references for those interested in better understanding the use of Bayesian information criteria. Similarly, it is stated that PCA is a &quot;standard method for describing the behavior of neural populations&quot; – as such it would be nice to provide some relevant references for the reader</p></disp-quote><p>In consideration of the reviewers’ comments, and for simplicity of presentation, we have eliminated the cluster analysis previously presented in Figure 7A. Figure 7B (the PCA analysis) has been moved to Figure 8D. We opted to go with the PCA approach as PCA is more commonly used in the literature and involves fewer assumptions. We have included a reference to the use of PCA in neuroscience, below.</p><p>Cunningham JP, Yu BM. Dimensionality reduction for large-scale neural recordings. Nat Neurosci. 2014;17(11):1500-9.</p><p>While no longer in the manuscript, we briefly explain the choices made for the cluster analysis for completeness. We wanted to ensure that we are applying the classification analysis only to units with a reasonable strength of encoding. The cross-validated classification analysis generates a large matrix of values that, by chance, can sometimes result in large values. We are interested in the maximum classification accuracy but wanted to avoid these chance peaks. We therefore selected the 90<sup>th</sup> percentile to provide a more robust estimate of the peak value. The 50% accuracy number was chosen through a shuffle analysis, in which we found that it reflected greater than the 95<sup>th</sup> percentile of chance outcomes. We performed a basic sensitivity analysis, testing the 80<sup>th</sup>, 85<sup>th</sup> and 90<sup>th</sup> percentile, and threshold values of 55%, 55% and 60% percent. The basic result, with three clusters and relatively similar temporal patterns, were robust to these choices.</p><p>For further reading on Bayesian information criteria:</p><p>Original article:</p><p>G. E. Schwarz, Estimating the Dimension of a Model. <italic>Annals of Statistics</italic><bold>6</bold>, 461–464 (1978).</p><p>For use in clustering, see:</p><p>S. S. Chen, P. S. Gopalakrishnan, Clustering via the Bayesian information criterion with applications in speech recognition. <italic>Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing</italic><bold>2</bold>, 645-648 (1998).</p><disp-quote content-type="editor-comment"><p>3) At the start of the Results section it is stated that the recordings were from &quot;well-isolate and multi-unit neurons&quot;. This seems to contradict the Materials and methods section, which only talks about &quot;sorted&quot; neurons. This needs to be clarified, and if multi-units were included, it should be stated which sections this concerns as it will have implications for the results (e.g. for selectivity for different body parts). In any case, the number of neurons included in different analyses should be evident. There are some numbers in the Materials and methods and sprinkled throughout the Results section, but for some of the analyses (e.g. clustering analysis, which was run only on a responsive subset of neurons) no numbers are provided.</p></disp-quote><p>There is no contradiction, but we understand the confusion. All channels were sorted into putative neurons, which we then categorized as either being single unit or multi-unit neurons. Multi-unit refers to the situation where two or possibly more neurons have sufficiently similar waveforms that they cannot be distinguished. All units were pooled for the analyses presented in the manuscript. To ensure that the pooling did not impact the validity of core results, we performed separate analyses on the single and multi-unit responses based on the cluster “isolation distance” computed during the spike sorting stage and found that the basic conclusions were consistent across single and multi-unit data. We have now included new supplemental figures (Figure 1—figure supplement 2, Figure 2—figure supplement 2, Figure 3—figure supplement 2, Figure 4—figure supplement 1 and Figure 7—figure supplement 1) that show the results for the pooled, single unit, and multi-unit data for representative analyses that may be especially sensitive to mixing response properties from multiple units. As can be seen, the qualitative results are similar for multi and single-unit data. We have included within the Materials and methods (“Data collection and unit selection”) a clarification on unit selection, pooling, the invariance of our results to the pooling of units, and our approach to categorizing units as single units or potentially multi-units.</p><p>Materials and methods:</p><p>“Well isolated single and multi-units were pooled across recording sessions. To ensure that such pooling did not bias the conclusions of this manuscript, we performed core analyses within this manuscript on single units alone, potential multi-units alone and all units together. The results of these analyses, shown as supplemental figures for key results, generally demonstrate that our results were robust to the pooling of all sorted units together. For the separation of spike sorted units into high quality single and multi-units, we used as a threshold the mean across all units of the base-10 logarithm of their cluster isolation distances, based on a previously described method (18, 50). Sorted units for which the cluster isolation distance was above this measure were considered single units, and those with a distance below this threshold were considered potential multi-units. Findings were robust to the exact choice of isolation distance threshold.”</p><disp-quote content-type="editor-comment"><p>4) The linear analysis section needs further details. The coefficients are matched to &quot;conditions&quot; but it is not explained how. I am assuming that each touch location is assigned to a condition c, however the way the model is described suggests that the vector X can in principle have multiple conditions active at the same time. Additionally, could the authors confirm whether it is the significance of the coefficients that determined whether a neuron was classed as responsive as shown in Figure 1? This analysis states a p-value but does give no further information on which test was run and on what data.</p></disp-quote><p>Your assumptions are correct. The description of the linear analysis (Materials and methods, “Linear analysis” relevant for Figures 1, 5 and 7) has been updated to improve clarity. The relevant text is included below:</p><p>“To determine whether a neuron was tuned (i.e., differentially modulated to touch locations), we fit a linear model that describes firing rate as a function of the neuron’s response to each touch location. […] A unit was considered tuned if the F-statistic comparing the β coefficients was significant (<italic>p</italic>&lt;0.05, false discovery rate (FDR) corrected for multiple comparisons).”</p><disp-quote content-type="editor-comment"><p>5) Figure 1C could be converted into a matrix that lists all combinations of RF numbers on either side of the body to highlight whether larger RFs on one side of the body generally imply larger RFs on the other side.</p></disp-quote><p>We have converted Figure 1C (currently Figure 2B) to matrix form. We agree that seeing that larger RFs on one side imply larger RFs on the other side is a nice feature of this presentation.</p><disp-quote content-type="editor-comment"><p>6) I am confused about the interpretation of the coefficient of determination as shown in Figure 2A. In the text this is described as testing the &quot;selectivity&quot; of the neurons. To clarify, I am assuming that the &quot;regression analysis&quot; is referring to the linear model described in a previous section. The authors then presumably took the coefficients from this model for a single side only and tested how well they could predict the responses to the opposite side, as assessed by R<sup>2</sup> (Figure 2C,E). Before that in Figure 2A, they tested how well each single-side model could predict the responses. This is all fine, but the &quot;within&quot; comparison then simply tests how well a linear model can explain the observed responses, and has nothing to do with the selectivity of the neuron. For example, the neuron might be narrowly or broadly selective, but the model might fit equally well.</p></disp-quote><p>I think your core understanding is correct; but our usage of “selectivity” created unnecessary confusion. We understand the confusion and have taken several steps to clarify. First, we were using selectivity here to refer to the ability to accurately differentiate between the different touch locations using the linear model. You are correct that this would have nothing to do with narrow or broad tuning. To avoid this confusion, we have replaced “selective” with “discriminative” throughout the manuscript. Further, we have clarified the text describing what is to be learned from this analysis, including an illustrative schematic, Figure 3—figure supplement 4. The relevant updates (from Materials and methods: “Tests for mirror symmetric neural coding of body locations: single unit analysis” (relevant for Figure 3) are included below:</p><p>“The purpose of this analysis was to assess whether neural responses to one body side were the same as neural responses to the alternate body side on a single unit basis. Heuristically, we used a cross-validation approach, similar in concept to the population correlation, to ask whether the neural responses to one body side are similar to the other body side. […] If the patterns of response are similar, this would lead to data points falling along the identity line. If the patterns are distinct, the data points should fall below the identity line.”</p><disp-quote content-type="editor-comment"><p>7) We computed a cross-validated coefficient of determination (R<sup>2</sup> within) to measure the strength of neuronal selectivity for each body side.</p><p>Even after reading the Materials and methods (further comments below) it is difficult to figure out what all these related measures reveal. At this point in the text it is very difficult to intuit how R<sup>2</sup> would measure selectivity.</p></disp-quote><p>The confusion here is very much related to point 6. Again, we believe we understand the source of the confusion and have replaced “selective” with “discriminative” and have updated the relevant text for clarity (see response to major point 6).</p><disp-quote content-type="editor-comment"><p>8) Regarding the timing analysis, it is not clear to me how the accuracy can top out at 100% as shown in the figure, when the control conditions were included. Additionally, the authors should state the p value and statistic for the comparison of latencies.</p></disp-quote><p>Based on reviewer feedback and additional analysis, we have changed the way latency is computed (see major point 15). In the original manuscript, only the experienced touch conditions were included in the sliding window classification analysis: touch to the shoulder, cheek, and hand. With the three conditions, chance performance is 33% and accuracy can hit 100%, consistent with the previous results.</p><p>A detailed description of the new approach includes a description of how the p-value was computed based on a permutation shuffle test (see major point 15).</p><disp-quote content-type="editor-comment"><p>9) Spatial analysis. Could the authors provide the size of the paintbrush tip that was used in this analysis. Furthermore, as stimulation sites were 2 cm apart, it is not appropriate to specify receptive fields down to millimeter precision.</p></disp-quote><p>The Materials and methods have been updated to include the size of the paintbrush tip (3 mm).</p><p>Materials and methods have been updated to read:</p><p>“Stimuli were presented via a paintbrush (three mm round tip) gently brushed against each location, at a frequency of one brush per second.”</p><p>The millimeter place has been removed.</p><disp-quote content-type="editor-comment"><p>10) Imagery: how many neurons were responsive to both imagery and real touch? Were all neurons that were responsive to imagery also responsive to actual touch? This is left vague and Figure 5 only includes the percentages per condition, but gives no indication of how many neurons responded to several conditions. Whether and how many neurons were responsive to both conditions also determines the ceiling for the correlation analysis in Figure 5D (e.g. if the most neurons are responsive only to actual but not imaginary touch, this will limit the population correlation).</p></disp-quote><p>We now include in Figure 7 (panel D) a Venn diagram that illustrates the number of units that were significantly modulated by experienced touch alone, experienced touch and imagery, and imagery alone. The analysis was restricted to the cheek and shoulder given that touch induced no response on the hand.</p><disp-quote content-type="editor-comment"><p>11) What is added by including both classification and Mahalanobis distance?</p></disp-quote><p>We used classification analysis as the values are readily interpretable and it captures the key feature that we think is important: the ability to discriminate between the different task conditions and whether the decision boundaries generalize between experimental manipulations, e.g. between imagery and experienced touch. However, the discretization process in classification analysis can lead to a loss in sensitivity. The population response might be changing, but not in a way that crosses the decision boundaries established by the classification algorithm. Mahalanobis distance is very sensitive to changes in neural population response. A limitation of Mahalanobis distance is that we, for example, cannot tell whether the changes will affect how e.g., a classifier would interpret the population response. Thinking about this in the context of Figure 8C (previously Figure 6C), the classification analysis tells us that the basic population level response patterns that allow us to distinguish the different classes are generally preserved from the cue through the execution period. The Mahalanobis adds to this picture by showing that there is a clear transition from one point to another in the neural state space, and that this transition occurs at short latency and over a short duration just after the go cue.</p><p>A description motivating the benefit of Mahalanobis distance is included in the Materials and methods (“Temporal dynamics of population activity during tactile imagery task: within category” (relevant for Figure 8)):</p><p>“…to explicitly test whether population activity was changing, we used Mahalanobis distance as our measure. This is necessary as classification involves a discretization step that makes the technique relatively insensitive to changes in neural population activity that do not cross decision thresholds. Mahalanobis distance, being a proper distance measure, is a more sensitive measure of change. To illustrate, imagine that a classifier is trained on time point A and tested on time point B. At time point A, the means of the two classes are 0 and 1 respectively and at time point 2 the means are 0 and 4 respectively. All classes are assumed to have equal but negligible variance (e.g. 0.01) in this example. When trained on time point A, the classifier finds a decision boundary at 0.5. with 100% classification accuracy. When tested on time point B, with the same 0.5 decision boundary, the classifier again is 100%. Naively, this could be interpreted as signifying that no change in the underlying data has occurred, even though the mean of the second distribution has shifted.”</p><disp-quote content-type="editor-comment"><p>Relatedly, information coding evolves for a single unit. Two complimentary analyses were then performed.</p><p>In what sense are they complementary? What is added (besides complexity) by including both cluster analysis and PCA?</p></disp-quote><p>They are complimentary in the sense that while PCA estimates how much of the variability across all units is captured by specific temporal patterns while clustering can show how many units are described by the different patterns. However, aggregating across reviewer responses, and acknowledging that the primary message from both is essentially the same, we have opted to simplify presentation and are removing the cluster analysis.</p><disp-quote content-type="editor-comment"><p>12) Classification was performed using linear discriminant analysis with the following assumptions:</p><p>one, the prior probability across tested task epochs was uniform;</p><p>It is not clear what prior probability this refers to. Just stimulus site?</p><p>two, the conditional probability distribution of each unit on any epoch was normal;</p><p>Is this a reference to firing rate probability conditioned on stimulus site?</p><p>three, only the mean firing rates differ for unit activity during each epoch (covariance of the normal distributions are the same for each);</p><p>four, firing rates for each input are independent (covariance of the normal distribution is diagonal).</p><p>Does this refer to independent firing rates of neurons across stimulus sites? This seem very unlikely, given everything we know about dimensionality of cortex. Perhaps it refers to something else. Cannot all of these assumptions be tested? Were they?</p></disp-quote><p>These assumptions are more about tractability of analysis given limited data than true assumptions about the behavior of neurons. To elaborate, in linear discriminant analysis, the response to each stimulation site is modeled as a Gaussian characterized by a mean and variance. In our experiments, we only acquire 10 repetitions per condition, generally not enough to get a reasonable estimate of variance. Therefore, we compute a pooled estimate of variance based on all conditions to try and get a better variance estimate. Likewise, estimates of covariance require even more data. We sometimes use the Ledoit-Wolf optimal shrinkage estimator for covariance to compute a regularized estimate, but this almost invariably returns the diagonal matrix given our amount of data and thus it feels somewhat disingenuous to claim we are capturing covariance structure between neurons. To validate these choices, we use cross-validation to test how well the models explain held-out data. For on the order of ~10 repetitions per condition, the assumptions above nearly always outperform or at worst match performance for alternative assumptions. As an aside, we have collected data in other experiments where we have on the order of ~80 trials per condition. With this amount of data, allowing separate estimates of variance and a full covariance matrix (sometimes called quadratic discriminant analysis) can improve classification performance, but only marginally. Note that we know a priori that equal variance is unlikely as neurons exhibit Poisson spiking statistics (the variance is proportional to the mean); nonetheless, the regularization through a pooled variance estimate still allows improved generalization and thus is the lesser of two evils. Anyhow, we have updated the Materials and methods for a simplified and better justified.</p><p>Materials and methods :</p><p>“Classification was performed using linear discriminant analysis with the following parameter choices: one, only the mean firing rates differ for unit activity in response to each touch location (covariance of the normal distributions are the same for each condition); and, two, firing rates for each unit are independent (covariance of the normal distribution is diagonal). These choices do not reflect assumptions about the behavior of neurons, but instead, were found to improve cross-validation prediction accuracy on preliminary data. In our experiments, we acquired 10 repetitions per touch location, generally not enough data to robustly estimate the covariance matrix that describes the conditional dependence of the neural behavior on the stimulus. In choosing equal covariance, we are able to pool data across touch locations, achieving a more generalizable approximation of the neural response as verified by cross-validation.”</p><disp-quote content-type="editor-comment"><p>13) We computed the cross-validated coefficient of determination</p><p>(R2 within) to measure how well a neuron's firing rate could be explained by the responses to the sensory fields.</p><p>This needs a better description, and I may be missing the point entirely. I assume it is an analysis of mean firing rate (which should be stated explicitly) and that it uses something like the indicator variable of the linear analysis of individual neuron tuning above. In this case is this is a logistic regression? As it is computed for each side independently, it would appear that there are only four bits to describe the firing of any given neuron. This would seem to be a pretty impoverished statistic, even if the statistical model is accurate.</p></disp-quote><p>You are correct in saying that the model, a function built on indicator variables, is a description of the mean response to each tactile field, with the mean being captured by the continuously valued β coefficient. In comparing across body sides, we are asking whether the mean response to each tactile field computed from one side of the body can predict the single trial responses to each tactile field on the other side of the body. A few clarifications: while the indicator variable is composed of zeros and ones, the β values (means) that scale the indicator variable in the linear model are continuous values. Thus, it is not 4 bits, but instead, 4 continuous values. Further, if we had simply computed the mean values for each side, and then correlated the resulting sets of 4 values, we would not expect especially meaningful results as correlations computed with such a small number of values can by chance cover the whole spectrum of correlations. Instead, we are seeing how well the trial-to-trial responses of one side is explained by the mean responses of the other side. This is summarized as the R2 value. We have revised the description of the linear model for greater clarity, updated the description of the approach, and included a new schematic figure (Figure 3—figure supplement 4) to motivate the approach. This figure along with its caption was shown in response to major point 6.</p><p>The revisions to the relevant text on the linear model can be found in the response to major point 4.</p><p>And clarification of the across body-side regression can be found in the response to major point 6.</p><disp-quote content-type="editor-comment"><p>14) The purpose of computing a specificity index was to quantify the degree to which a neuron was tuned to represent information pertaining to one side of the body over the other.</p><p>This is all pretty hard to follow. The R2 metric itself is a bit mysterious, as noted above. Within and across R2 is fairly straightforward, but adds to the complexity, as does SI, which makes comparisons of three different combinations of these measures across sides. Aside from R2 itself, the math is pretty transparent. However, a better high-level description of what insight all the different combinations provide would help to justify using them all. As is, there is no discussion and virtually no description of the difference across these three scatter plot. The critical point apparently, is that, &quot;nearly all recorded PC-IP neurons demonstrate bilateral coding&quot;. There should be much a more direct way to make this point.</p></disp-quote><p>We have updated the text and streamlined the figure to make this section a little more digestible. These changes can be found in response to major point 6.</p><disp-quote content-type="editor-comment"><p>15) Computing response latency via RF discrimination is rather indirect and assumes that there is significant classification in the first place. I suspect it will add at least some delay beyond more typical tests. Why not a far simpler and more direct test of means in the same sliding window? Alternatively, a change point analysis?</p></disp-quote><p>The original sliding window classification analysis included three conditions: touch to the shoulder, cheek, and hand. The inclusion of the hand, a condition resulting in no significant modulation of the population, should allow for detection of the touch response, even in the absence of RF modulation. However, following your suggestion, we reanalyzed the latency data and have updated our method as outlined below. In brief, we now use a piece wise linear model on the first principal component (1PC) to detect the time the signal rises above the baseline response. A bootstrap procedure is used to find the quartile range of these times. Interestingly, the latency estimates are clearly earlier then what we got for the classification approach. We believe this is likely related to discussion above about Mahalanobis distance versus classification: namely, changes in the underlying neural behavior are only detected once the neural responses cross a decision line which likely results in delays detecting changes in neural behavior.</p><p>Here we opted for the 1PC as it is generally recommended when trying to capture the basic properties of the population response (51). Consistent with this, as shown in <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>, the mean across the population (left) is quite a bit noisier then the first PC (right).</p><fig id="sa2fig2"><label>Author response image 2.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-resp-fig2-v1.tif"/></fig><p>Another nice property of the first PC, is that save for averaging responses in 2ms bins, we did not impose any additional smoothing.We have updated the manuscript to include the new approach. The text from the Results and Materials and methods are copied below for convenience.</p><p>Results:</p><p>“We measured latency as the time at which the response of the neural population rose above the pre-stimulus baseline activity (Figure 6). The neural population response was quantified as the first principal component computed from principal component analysis (PCA) of the activity of all neurons (51, 52). The first principal component was then fit with a piece-wise linear function and latency was computed as the time the linear function crossed the baseline pre-stimulus response. Response latency was short for both body sides and was slightly shorter for contralateral (right) receptive fields (50 ms) than for ipsilateral (left) receptive fields (54 ms) although this difference was not statistically significant (Permutation shuffle test, <italic>p</italic>&gt;0.05). Figure 6A shows the time course of the first principal component relative to time of contact of the touch probe (stepped window; 2 ms window size, stepped at 2 ms, no smoothing) along with the piece-wise linear fit (dashed line). A bootstrap procedure was used to find the inter-quartile range of latency estimates (Figure 6B)”</p><p>Materials and methods:</p><p>“We quantified the neural response latency to touch stimuli at the level of the neural population. […] We used a rank test to compare the true difference in latency estimates against an empirical null distribution of differences in latency estimates generated by shuffling labels and repeating the comparison 2000 times.”</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The reviewers were happy with the vast majority of the extensive revisions that have been implemented relative to the original submission, but felt that the presentation of the results and their discussion was inadequate. While we recognise the enormous amount of work that was poured into the revisions, there are still a few issues, originating from the revisions, that the reviewers felt require further consideration. But beyond these specific considerations that are elaborated below, we all agreed that the paper, at its present form, is too dense with results/interpretation, making it very difficult to read and evaluate. As one of the reviewers summarised:</p><p>&quot;My main high-level concern was the, &quot;extensive and overlapping analyses&quot; that made it difficult to follow and to find a clear takeaway message from the paper. I suggested eliminating a number of figures and clarifying the remainder to improve the impact of the paper. Although a few small panels have disappeared, most of the duplication remains and there are now nine, fairly complex figures (had been eight). It's hard to judge how much longer the text got because the figures are no longer embedded, but that has certainly also increased. The paper has not improved as a consequence&quot;.</p><p>There is a strong need for a “deep clean” (or more precisely deep edit) of the paper. As highlighted in our original review, there's a lot of overlap between analyses/findings that will not be of interest to the average reader. We believe the key innovation of the study – the imagery results – could be presented a lot more concisely with a more focused discussion of the findings and the limitations of the suggested interpretation. Much of the details of the tactile RF properties is of secondary interest and as such should be moved to the supplementary section. I leave the decision of how to achieve this leaner and more focused version to the authors, but please consider the average reader (and their very limited time and attention span) when making the edits. As a rule of thumb, the reviewers estimated you will be likely be able to remove ~50% of the figure panels and 33% of the main text without weakening the key findings.</p></disp-quote><p>We understand the concern and have substantially reduced the amount of text and figures. We have cut the early portion of the text that discusses actual touch in half (from ~1800 words to ~850 words.) In addition we have cut the number of main figures in this section from 5 down to 2. This reduction was accomplished by a combination of removing figure panels (e.g. former panel 1B, 3B, 5C, 5E, portions of 5D and F were removed; we also removed 7C, 9B, and 9C) as well as pushing figures to the supplement (e.g. 3C, 4, and remaining parts of 5). This takes the main figures in the actual touch section from 18 panels down to 5 panels. This new presentation gets the key points across, e.g. neurons have spatially structured tactile receptive fields that are activated at short-latency consistent with processing of tactile sensations, in a more succinct manner.</p><p>This reorganization does leave a number of supplementary figures. However, the text is structured such that these figures are truly supplements, and can be skimmed or skipped without compromising a basic understanding of the primary message. We considered removing additional panels. However, 1) to our knowledge this is the first report of single unit responses in human PPC to tactile stimuli, and we think an (admittedly smaller) group of interested readers will find these analyses essential and 2) we have several upcoming papers what will cite these basic touch responses.</p><disp-quote content-type="editor-comment"><p>1) Perhaps the most exciting innovation of the study relates to the neural responses related to the imagery conditions. Yet, we know from many previous studies in humans that cognitive processes…</p><p>While the Introduction has been much improved, the Discussion still mostly disregards the alternative cognitive processes that are likely to drive the present findings (prediction, attention). The authors seem to downplays the impact of attention considerably. For example, they state:</p><p>&quot;Most studies of pre-stimulus attention report that any modulation of baseline activity is modest at best.&quot;</p><p>But especially when considering the modest effects of imagery, this statement is misleading. The Roland (1981) study that we provided, for example, show a 25% increase in rCBF when subjects attended the index finger without being stimulated. And this increase was spatially specific as it shifted to the lip area when attending to the upper lip instead of the finger. Although the other 3 attention references were looking at the effects of attention while sensory stimulation was present, they still seem relevant to the discussion and show what I'd consider to be greater than modest effects of attention. For example, the Puckett (2017) reference shows clear digit-specific modulation when attending to the different fingertips. Note that despite stimulation being present during this condition, the stimulation was constant (allowing the phasic attention-related signal to be somewhat isolated from the sensory signal). The amplitude of the phasic attention signal was similar to that elicited by phasic stimulation alone (i.e., without endogenous attention).</p><p>There needs to be a more serious consideration that the effects attributed here to imagery are in fact modulated by (or even driven by) related cognitive processes, such as prediction and attention, which are not specifically linked to the auditory cue used in the present study.</p></disp-quote><p>We agree that the precise neural correlate of the activity is unclear. As the reviewer mentioned, imagery is just one possibility, and the manuscript does not state that the responses are the neural correlate of imagery.</p><p>For example, the Abstract states:</p><p>“Our results are the first neuron level evidence of touch encoding in human PPC and its cognitive engagement during tactile imagery, which may reflect semantic processing, attention, sensory anticipation, or imagined touch.”</p><p>Introducing the relevant section of the Discussion we write:</p><p>“While our task identifies dynamic engagement of multiple cognitive processes during tactile imagery, it is inadequate to precisely define the cognitive correlates of the observed neural activity. A number of cognitive processes may be engaged during the tactile imagery task including preparation for and/or execution of imagery, engagement of an internal model of the body, semantic processing of the auditory cue, allocation of attention to the cued body location or nature of the upcoming stimulus, and/or sensory memory for the corresponding actual sensation applied by the experimenter.“</p><p>That said, there are a couple of places where the distinction between the task that is used to evoke activity and the underlying cognitive process which is encoded could be made even more explicit. We have updated the text to more clearly specify that neural activity results from a “tactile imagery task”, e.g. updating the Abstract:</p><p>“We recorded neurons within the PPC of a human clinical trial participant during actual touch presentation and during a tactile imagery task. Neurons encoded actual touch at short latency with bilateral receptive fields, organized by body part, and covered all tested regions. The tactile imagery task evoked body part specific responses that shared a neural substrate with actual touch. Our results are the first neuron level evidence of touch encoding in human PPC and its cognitive engagement during a tactile imagery task, which may reflect semantic processing, attention, sensory anticipation, or imagined touch.”</p><p>We have also updated the portion of the Discussion that explicitly discusses a possible role for attention (We noticed that the references for neuroimaging were misaligned to our purpose in the revision. We had intended to use the citations the reviewer provided (here shown as 1-4). Thank you for references, and we have made the correction.):</p><p>“Hearing an auditory cue can direct the study participant’s attention to the cued body part. […] If our results are interpreted within the framework of attention, our current findings are inconsistent with a simple gain-like mechanism for attention, but instead suggest a richer mechanism by which information is selectively enhanced for further processing (7).”</p><p>This update is similar to the original, but I think the text is a fair accounting, consistent with our reading of the literature. First, we state that attention may be engaged by the task and that attention allocated to the body has been shown to effect neural responses. We are not questioning whether attention alters somatosensory processing. However, critically, this is not the question at hand. What is relevant to the current paper is whether attention generates condition specific changes in single unit neural firing, in the absence of any stimulus. The statement “Most studies of pre-stimulus attention report modest modulation of baseline neural activity“ is, to the best of our knowledge, an accurate statement of reported effects of pre-stimulus attention on measures of single unit activity. This is not a dismissal of attention, it just reflects the majority of studies that have looked at single unit spiking during the pre-stimulus period. In the revised text we go further than I believe necessary by stating that the inability to find a positive result may have been a failure to use sensitive analysis as suggested by the Snyder et al. paper. We then cite the one paper that shows relatively substantive pre-stimulus effects of attention in the firing of single units and state our results are compatible with the attention findings. We go on to interpret our results within the framework of attention. Again, I think the text is a fair accounting, consistent with our reading of the literature.</p><p>The reviewer provided references to bolster the case for attention. Three of the references measure attention effects on stimulus responses. We unequivocally state that “Attention to a stimulated body part has been shown to enhance sensory processing in human neuroimaging (1-4).” We are not questioning whether attention alters sensory processing and have included the recommended references to support a role for attention in the somatosensory system. As we state above however, it is not clear what this would say about the effect of prestimulus attention on spiking activity.</p><p>The reviewer also provides a reference to Roland 1981, which measures a 25% change in rCBF to attended body parts absent a stimulus. Can these changes be clearly attributed to attention-based modulation of single unit firing? To this point, Roland states “The most natural explanation for the rCBF and metabolic increase in the sensory finger region is that they mainly result from the local sum of many EPSPs … [and] a part of the metabolic increase in the sensory finger area may also be due to IPSPs.” (see Discussion). Roland thinks the bulk of the signal is dendritic processing, not a result of action potentials. Please understand that we are not using Roland’s words as a general critique of the ability of neuroimaging methods to measure single unit firing; we know that while they can dissociate, they generally correlate. That said, it is especially something like attention, defined in its modulatory capacity, that could give rise to dendritic computations in the absence of explicit spiking during the pre-stimulus period. Further, looking closer at Roland’s methodology, it is not clear that the rCBF results can clearly be attributed to attention: In Roland’s study, rCBF measurements were made absent an overt stimulus. However, only data in which the subject reported having experienced sensations were included in analysis. These “false alarms or reports of stimuli though none were applied … was considered a sign of high focal attention” otherwise “If no false alarms were reported the test was repeated.”. In this way “high focal attention” is inextricably tied to what might reasonably called imagined sensations, amongst other related cognitive variables. As with our paper, the highly correlated nature of many cognitive variables makes definitive interpretation difficult.</p><p>Taken together, I think that we have handled the possible interpretation of cognitive activity in a responsible manner.</p><disp-quote content-type="editor-comment"><p>2) Figure 4: Several panels would be more effective.</p><p>This figure has changed quite lot, addressing my cosmetic concerns. However, I do not understand this statistical test: If no comparison was significant (FDR corrected), the unit was classified as &quot;single peak.&quot; If at least one of the comparisons was statistically significant, it was characterized as &quot;multi-peak.&quot; I must be missing something fundamental. I took this to be a test of differences of the responses to the different body parts, with respect to the peak response. How is this a single peak? No differences sounds like a flat line. By this definition a neuron with no response whatsoever would be &quot;single peak&quot;. Likewise, the multi-peak definition is a puzzle.</p></disp-quote><p>From our results: “In brief, for each neuron, we found the location of maximal response and asked whether we could find a second local maxima that rose significantly above the neighboring values. If no significant second local maxima was found, the neuron was categorized as single peak, otherwise, the neuron was categorized as multi-peak.”</p><p>We have updated the Materials and methods description for improved clarity, copied below for convenience:</p><p>“We found that many neurons responded to touch to multiple body locations. We wished to further characterize the receptive field structure to determine whether neurons were characterized by single-peaked broad receptive fields or discontinuous receptive fields with multiple peaks. […] The unit was then classified as multi-peak. If no second local maxima was found the unit was classified as single-peak. ”</p><disp-quote content-type="editor-comment"><p>3) What is added by including both classification and Mahalanobis distance?</p><p>&quot;Mahalanobis distance that provides a sensitive measure of change which is masked by the discretization process of classification &quot;</p><p>I don't think the discrete nature of the classifier output is really the biggest issue. By averaging across many instances, it essentially becomes continuous, as in this figure. There are also classifier-related metrics that are by their nature, continuous. The nature of the distance measure they are making is likely more important. In this case, I do not understand why the classification rises only slightly at t=0 as the M distance increases sharply. Subsequently, between 1 and 2.5 s, classifier success drops back below its original level even as distance is stable. The two measures really don't seem to be concordant. What is going on here? I think this concern is not unrelated to my next comment about Figure 8C (now 9C).</p></disp-quote><p>There is a question generated from another question. It may be that only the last portion of this response is needed, but in the interest of clarity, I’ll introduce the topic more generally.</p><p>Neural state-space is encoded as discrete values when using classification. Consider the schematic in <xref ref-type="fig" rid="sa2fig3">Author response image 3</xref> in which the neural state can either be described using the continuous variables of firing rate, or the discrete variables of class label (A or B):</p><fig id="sa2fig3"><label>Author response image 3.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-resp-fig3-v1.tif"/></fig><p>In this example, we see how two transitions (shown as vectors) through neural state space of comparable Mahalanobis distance are dramatically different in terms of classifier output (e.g. the movement started in class B and ended in class B, there is no indication that any movement occurred at all). From this example, it should be clear that Mahalanobis distance is a more sensitive measure of change. At the same time, it can also be significant whether or not the movement crosses significant boundaries. The classification result shows that although there is movement in neural state-space, the transition still leaves the neural state within the same basic class boundaries.Regarding how movement in state-space can give rise to the behavior shown, consider the following in <xref ref-type="fig" rid="sa2fig4">Author response image 4</xref>:</p><fig id="sa2fig4"><label>Author response image 4.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-resp-fig4-v1.tif"/></fig><p>Initially, the neural state moves further from the boundary (improving accuracy[Note that I am showing “mean” trajectories. Single trial results would be quite a bit noisier, accounting for trial-to-trial variability in accuracy]), while increasing Mahalanobis distance from the starting location. Towards the end of the movement, the position in state-space maintains a consistent distance from the starting point while drifting to the boundary. This would lead to a steady-state distance, but dropping accuracy. Other geometries, factoring in mean and variance, could account for the results. However, given that the changes in accuracy are on the order of a couple percentage points, it is not clear that a detailed analysis would be of interest to a general audience.</p><disp-quote content-type="editor-comment"><p>4) Figure 8C: Despite my best efforts, I have no idea…</p><p>&quot;This asymmetry is likely a consequence of the analysis technique and may not be of physiological significance.”</p><p>I agree with the statement, but not its sentiment. Perhaps I'm missing something, but the fact that a single classifier can distinguish between rest state and two very different activation states does nothing to suggest those two states are a general representation of an input. The classification failure in the opposite direction only reinforces that. Presumably, classifying imagined and actual touch would be trivial, at a much higher level of success than rest and imagined touch, suggesting that they are in fact, rather different, even by this metric. If the authors wish to make the claim that their results show more than grossly common receptive fields bilaterally and across modes (which is not an uninteresting finding) they would do well to adopt tools more appropriate for it, like those that have been used by the groups of Shenoy, Churchland, Miller, Kaufman, and others: Canonical correlations, principal angles, subspace overlap.</p></disp-quote><p>I believe there is a misunderstanding here. Perhaps it is best to take a step back.</p><p>Our objective is to test the hypothesis that actual and cognitive representations of touch share a neural substrate at the population level in PPC. We address this by asking whether the neural population representations of the stimulated body part are similar across these two contexts. There are a number of metrics that can be used to measure similarity. In the draft, we use cross-classification accuracy as the metric of similarity. This approach creates a low-dimensional discretized representation of neural space (the decision space defined by the classifier) based on the conditions of one context (e.g. imagery) and asks whether trials from the alternate context map to corresponding regions of neural space. This is a powerful notion of similarity; it says that a decision maker (e.g. the classifier) interprets population level responses across contexts in a similar way.</p><p>Cross-classification is not the only way of computing a meaningful measure of similarity. The reviewer suggests a number of methods, with the implication that these alternate metrics would reveal something more fundamental about the relationship between the two contexts. While I agree that these proposed methods would measure something different, I disagree that they can reveal something more fundamental.</p><p>Consider principal angles. In this approach, we would compute the latent manifold independently for each context using, e.g. PCA. We would then compute the principal angles between these manifolds, thereby quantifying the degree to which population responses in the two contexts live in the same manifold. On the surface, this sounds interesting, and, no doubt, has its place. However, for our purposes, I would argue that it is less stringent and less revealing than something like cross-classification. This is because overlapping manifolds does not imply similar neural encoding. In fact, manifolds can be perfectly aligned in the potentially uninteresting case that the only correspondence between the two contexts is that the same set of neurons are modulated, but in completely unrelated ways. To illustrate, I created a toy problem (full matlab code below) where the two contexts are characterized by independent realizations of a multivariate normal distribution (e.g. X=randn(500,50); Y=randn(500,50)). I then added a multiplier on the first 10 dimensions. As shown in <xref ref-type="fig" rid="sa2fig5">Author response image 5</xref> (left panel) there is no covariance between the two contexts. Due to the multiplier term, there is a ten-dimensional manifold that explains &gt;95% of the variance (<xref ref-type="fig" rid="sa2fig5">Author response image 5</xref> : middle column). Because the multiplier was applied to the same columns of the two contexts (X and Y), we see that the first 10 principal angles are close to 0 (<xref ref-type="fig" rid="sa2fig5">Author response image 5</xref> : right column), indicating that the two manifolds are very similar. As this example illustrates, near perfect alignment of manifolds might say nothing more than that the same neurons modulate in both contexts. This has its place, and may even be necessary to find any meaningful relationship when eg. Using unlabeled data or when temporal considerations prevent a meaningful alignment of the data. However, in our case, we wanted a metric that is able to say whether the same neurons are modulating in similar ways based on task conditions, not just that the same neurons are modulating. Cross-classification gives us this, principal angles do not.</p><p>Matlab code:</p><p>X=randn(500,50); Y=randn(500,50);</p><p>idx=1:10;</p><p>X(:,idx)=X(:,idx)*10; Y(:,idx)=Y(:,idx)*10;</p><p>[coeffX,scoreX,latentX,tsquaredX,explainedX,muX] = pca(X);</p><p>[coeffY,scoreY,latentY,tsquaredY,explainedY,muY] = pca(Y);</p><p>figure; subplot(1,3,1); hold on</p><p>imagesc(corr(X,Y),[-1 1]); colormap('jet');colorbar</p><p>axis image; title('Correlation')</p><p>xlabel('Context 1'); ylabel('Context 2')</p><p>subplot(1,3,2); hold on</p><p>plot(explainedX,'r.-','markersize',10)</p><p>plot(explainedY,'g.-','markersize',10)</p><p>ylabel('Var Explained'); legend({'Context 1','Context 2'})</p><p>theta=subspacea(coeffX(:,1:12),coeffY(:,1:12));</p><p>subplot(1,3,3);</p><p>plot(theta'*180/pi,'.-','markersize',10)</p><p>title('Principal Angle')</p><p>ylabel('Angle (deg)')</p><fig id="sa2fig5"><label>Author response image 5.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-resp-fig5-v1.tif"/></fig><p>Canonical correlation analysis (CCA) is also proposed. Again, CCA has its place but I do not think it is correct to say that it would reveal something more interesting/fundamental. Consider the following example. <xref ref-type="fig" rid="sa2fig6">Author response image 6</xref> shows the response of two neurons in two contexts, color coded by condition. Cross-classification in this scenario would fail to show a similar relationship between labeled data between contexts. In contrast, CCA would show a very strong similarity (correlation values ~.8 in this simulated data). CCA is successful because it finds the linear projection that best equates these two scenarios (in this case, heuristically, by rotating Context 1 clockwise). In effect, CCA computes a measure of similarity, after an arbitrary linear transformation is applied to maximize similarity. This is fine for what it is (and sometimes necessary when e.g. observations from the two contexts might come from different sensors that have no natural correspondence) but I don’t think it would provide deeper insight given that we already show that there is correspondence prior to an optimized linear mapping.</p><fig id="sa2fig6"><label>Author response image 6.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-resp-fig6-v1.tif"/></fig><p>None of this changes the fact that the asymmetries inherent in cross-classification can add complication without any clear benefit. In our case, I believe the asymmetry may not be especially interesting, thus adding complication without benefit. For this reason, we are substituting out cross-classification for cross-correlation. This maintains the benefits of direct tests of whether the condition specific patterns of activation are consistent across contexts without the inherent complications that come from different discretization of neural space depending on the dataset used for training. As can be seen, the basic pattern of results is essentially identical.Results:</p><p>“Cognitive processing during the cue-delay and imagery epochs of the tactile imagery task shares a neural substrate with that for actual touch</p><p>Finally, we look at how encoding patterns through time generalize between the tactile imagery and actual touch conditions. A dynamic correlation analysis was applied both within and across the imagery and actual touch condition types (Figure 6A). In brief, the neural activation pattern elicited to each body location was quantified as a vector, and these vectors were concatenated to form a population response matrix for each condition type and for each point in time. These vectors were then pair-wise correlated in a cross-validated manner so that the strength of correlation between conditions could be assessed relative to the strength of correlation within condition, and across time. We found that the neural population pattern that defined responses to actual touch was similar to population responses both during the cue-delay or the imagery phases of the imagery task (Figure 6A). This implies that cognitive processing prior to active imagery as well as during imagery share a neural substrate with actual touch. Sample neuronal responses that help to understand single unit and population behavior are shown in Figure 6B.”</p><disp-quote content-type="editor-comment"><p>5) Computing response latency via RF discrimination is rather indirect.</p><p>The authors have adopted a more sensible and sensitive test of latency. I do not agree with this statement, however: &quot;We believe this is likely related to discussion above about Mahalanobis distance versus classification: namely, changes in the underlying neural behavior are only detected once the neural responses cross a decision line which likely results in delays detecting changes in neural behavior.&quot; In what fundamental sense is classification significance different from a significant distance in M-space? It seems to me that the more likely explanation is simply that significant modulation precedes significant discrimination.</p></disp-quote><p>The classification involved discrimination between touch to three locations, the hand, shoulder and cheek. Touch to the insensate hand resulted in no neural modulation. For this reason, modulation of cheek and shoulder should enable discrimination against the unmodulated hand condition. Peak accuracy in this case would not be 100% but results should still be significant. The exact reason why classification failed to detect the time of modulation is a timely manner is a legitimate question, but moot given that we have removed the classification-based approach entirely.</p><p>However, to illustrate why the discretization problem (as defined in response 3) could contribute, consider the schematic in <xref ref-type="fig" rid="sa2fig7">Author response image 7</xref>:</p><fig id="sa2fig7"><label>Author response image 7.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-61646-resp-fig7-v1.tif"/></fig><p>Depending on the rate of change of the neural activity, and exact location of the decision boundary, there could be a significant delay between latency as measured by time of modulation and time neural activity crosses a decision threshold.</p></body></sub-article></article>