<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">85069</article-id><article-id pub-id-type="doi">10.7554/eLife.85069</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.85069.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mega-scale movie-fields in the mouse visuo-hippocampal network</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-300477"><name><surname>Purandare</surname><given-names>Chinmay</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9225-0186</contrib-id><email>chinmay.purandare@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="pa1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-137494"><name><surname>Mehta</surname><given-names>Mayank</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2005-2468</contrib-id><email>MayankMehta@ucla.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>Department of Bioengineering, University of California, Los Angeles</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>W.M. Keck Center for Neurophysics, Department of Physics and Astronomy, University of California, Los Angeles</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>Department of Neurology, University of California, Los Angeles</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>Department of Electrical and Computer Engineering, University of California, Los Angeles</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="present-address" id="pa1"><label>†</label><p>Department of Physiology, UCSF, San Francisco, United States</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>01</day><month>11</month><year>2023</year></pub-date><volume>12</volume><elocation-id>RP85069</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2022-12-07"><day>07</day><month>12</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2022-12-07"><day>07</day><month>12</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.12.07.519455"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-02-14"><day>14</day><month>02</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.85069.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-09-15"><day>15</day><month>09</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.85069.2"/></event></pub-history><permissions><copyright-statement>© 2023, Purandare and Mehta</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Purandare and Mehta</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-85069-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-85069-figures-v1.pdf"/><abstract><p>Natural visual experience involves a continuous series of related images while the subject is immobile. How does the cortico-hippocampal circuit process a visual episode? The hippocampus is crucial for episodic memory, but most rodent single unit studies require spatial exploration or active engagement. Hence, we investigated neural responses to a silent movie (Allen Brain Observatory) in head-fixed mice without any task or locomotion demands, or rewards. Surprisingly, a third (33%, 3379/10263) of hippocampal –dentate gyrus, CA3, CA1 and subiculum– neurons showed movie-selectivity, with elevated firing in specific movie sub-segments, termed movie-fields, similar to the vast majority of thalamo-cortical (LGN, V1, AM-PM) neurons (97%, 6554/6785). Movie-tuning remained intact in immobile or spontaneously running mice. Visual neurons had &gt;5 movie-fields per cell, but only ~2 in hippocampus. The movie-field durations in all brain regions spanned an unprecedented 1000-fold range: from 0.02s to 20s, termed mega-scale coding. Yet, the total duration of all the movie-fields of a cell was comparable across neurons and brain regions. The hippocampal responses thus showed greater continuous-sequence encoding than visual areas, as evidenced by fewer and broader movie-fields than in visual areas. Consistently, repeated presentation of the movie images in a fixed, but scrambled sequence virtually abolished hippocampal but not visual-cortical selectivity. The preference for continuous, compared to scrambled sequence was eight-fold greater in hippocampal than visual areas, further supporting episodic-sequence encoding. Movies could thus provide a unified way to probe neural mechanisms of episodic information processing and memory, even in immobile subjects, across brain regions, and species.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>hippocampus</kwd><kwd>learning</kwd><kwd>memory</kwd><kwd>artificial intelligence</kwd><kwd>Alzheimer's</kwd><kwd>place cell</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>1U01MH115746</award-id><principal-award-recipient><name><surname>Mehta</surname><given-names>Mayank</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Neurons in the mouse hippocampus, known as place cells, surprisingly show movie-fields, where they reliably encode distinct segments of a black-and-white, silent movie, even without any task demand or rewards.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In addition to the position and orientation of simple visual cues, like Gabor patches and drifting gratings (<xref ref-type="bibr" rid="bib36">Hubel and Wiesel, 1959</xref>), primary visual cortical responses are also direction selective (<xref ref-type="bibr" rid="bib13">De Valois et al., 1982</xref>), and show predictive coding (<xref ref-type="bibr" rid="bib105">Xu et al., 2012</xref>), suggesting that the temporal sequence of visual cues influences neural firing. Accordingly, these as well as higher visual cortical neurons encode a sequence of visual images, i.e., a movie (<xref ref-type="bibr" rid="bib14">de Vries et al., 2020</xref>; <xref ref-type="bibr" rid="bib107">Yen et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Herikstad et al., 2011</xref>; <xref ref-type="bibr" rid="bib100">Vinje and Gallant, 2000</xref>; <xref ref-type="bibr" rid="bib25">Froudarakis et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Hoseini et al., 2019</xref>; <xref ref-type="bibr" rid="bib33">Herikstad et al., 2011</xref>; <xref ref-type="bibr" rid="bib42">Kampa et al., 2011</xref>). The hippocampus is farthest downstream from the retina in the visual circuit. The rodent hippocampal place cells encode spatial or temporal sequences (<xref ref-type="bibr" rid="bib48">MacDonald et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Mehta et al., 2000</xref>; <xref ref-type="bibr" rid="bib56">Mehta and Wilson, 2000</xref>; <xref ref-type="bibr" rid="bib57">Mehta, 2015</xref>; <xref ref-type="bibr" rid="bib53">Mehta et al., 1997</xref>; <xref ref-type="bibr" rid="bib4">Buzsáki and Moser, 2013</xref>; <xref ref-type="bibr" rid="bib50">Mau et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Kraus et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Kraus et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">O’Keefe and Nadel, 1978</xref>) and episode-like responses (<xref ref-type="bibr" rid="bib71">Pastalkova et al., 2008</xref>; <xref ref-type="bibr" rid="bib59">Moore et al., 2021</xref>; <xref ref-type="bibr" rid="bib5">Buzsáki and Tingley, 2018</xref>). However, these responses typically require active locomotion (<xref ref-type="bibr" rid="bib52">McNaughton et al., 1996</xref>), and they are thought to be non-sensory responses (<xref ref-type="bibr" rid="bib66">O’Keefe and Dostrovsky, 1971</xref>). Primate and human hippocampal responses are selective to specific sets of visual cues, e.g., the objectplace association (<xref ref-type="bibr" rid="bib70">Parkinson et al., 1988</xref>), their short-term (<xref ref-type="bibr" rid="bib90">Scoville and Milber, 1957</xref>) and long-term (<xref ref-type="bibr" rid="bib75">Quiroga et al., 2005</xref>) memories, cognitive boundaries between episodic movies (<xref ref-type="bibr" rid="bib108">Zheng et al., 2022</xref>), and event integration for narrative association (<xref ref-type="bibr" rid="bib9">Cohn-Sheehy et al., 2021</xref>). However, despite strong evidence for the role of hippocampus in episodic memory, the hippocampal encoding of a continuous sequence of images, i.e., a visual episode, is unknown.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Significant movie tuning across cortico-hippocampal areas</title><p>We used a publicly available dataset (Allen Brain Observatory – Neuropixels Visual Coding, 2019 Allen Institute). Mice were monocularly shown a 30-s clip of a continuous segment from the movie <italic>Touch of Evil</italic> (Welles, 1958) (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>; <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and <xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref>). Mice were head-fixed but were free to run on a circular disk. A total of 17,048 broad spiking, active, putatively excitatory neurons were analyzed, recorded using 4–6 Neuropixel probes in 24 sessions from 24 mice (see <italic>Methods</italic>).</p><p>The majority of neurons in the visual areas (lateral geniculate nucleus [LGN], primary visual cortex [V1], higher visual areas: antero-medial and posterior-medial [AM–PM]) were modulated by the movie, consistent with previous reports (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>; <xref ref-type="bibr" rid="bib14">de Vries et al., 2020</xref>; <xref ref-type="bibr" rid="bib107">Yen et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Herikstad et al., 2011</xref>; <xref ref-type="bibr" rid="bib100">Vinje and Gallant, 2000</xref>; <xref ref-type="bibr" rid="bib25">Froudarakis et al., 2014</xref>; <xref ref-type="bibr" rid="bib35">Hoseini et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Kampa et al., 2011</xref>). Surprisingly, neurons from all parts of the hippocampus (dentate gyrus [DG], CA3, CA1, subiculum [SUB]) were also clearly modulated (<xref ref-type="fig" rid="fig1">Figure 1</xref>), with reliable, elevated spiking across many trials in small movie segments. To quantify selectivity in an identical, firing rate- and threshold-independent fashion across brain regions, we computed the <italic>z</italic>-scored sparsity (<xref ref-type="bibr" rid="bib1">Acharya et al., 2016</xref>; <xref ref-type="bibr" rid="bib2">Aghajan et al., 2015</xref>; <xref ref-type="bibr" rid="bib95">Skaggs et al., 1996</xref>; <xref ref-type="bibr" rid="bib72">Purandare et al., 2022</xref>) of neural selectivity (see <italic>Methods</italic>). Cells with <italic>z</italic>-scored sparsity &gt;2 were considered significantly (p &lt; 0.03) modulated. Other metrics of selectivity, like depth of modulation or mutual information, provided qualitatively similar results (<xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>). The areas V1 (97.3%) and AM–PM (97.1%) had the largest percentage of movie-tuned cells. Similarly, the majority of neurons in LGN (89.2%) too showed significant modulation by the movie. This level of selectivity is much higher than reported earlier (<xref ref-type="bibr" rid="bib14">de Vries et al., 2020</xref>) (~40%), perhaps because we analyzed extracellular spikes, while the previous study used calcium imaging. On the other hand, the movie selectivity was greater than the selectivity for classic stimuli, like drifting gratings, in V1, even within calcium imaging data, in agreement of reports of better model fit with natural stimuli for primate visual responses (<xref ref-type="bibr" rid="bib11">David et al., 2004</xref>). Direct quantitative comparison across stimuli is difficult and beyond the scope of this study because the movie frames appeared every 30 ms, and were preceded by similar images, while classic stimuli were presented for 250 ms, in a random order. Thus, the vast majority of thalamo-cortical neurons were significantly modulated by the movie.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Movie frame selectivity in hippocampal neurons.</title><p>(<bold>a</bold>) Raster plots of two different dentate gyrus (DG) neurons as a function of the movie frame (top) over 60 trials, and the corresponding mean firing rate response (bottom). These two cells had significantly increased activity in specific segments of the movie. <italic>Z</italic>-scored sparsity indicating strength of modulation is indicated above. 33.1% of dentate neurons were significantly modulated by the movie (right, green bar), far greater than chance (gray bar). Total active, broad spiking neurons for each brain region indicated at top (<italic>N</italic><sub>tuned</sub> /<italic>N</italic><sub>cells</sub> = 506/1531). (<bold>b</bold>) Same as (<bold>a</bold>), for CA3 (168/969, 17.3%), (<bold>c</bold>) CA1 (2326/6914, 33.6%), and (<bold>d</bold>) subiculum (379/849, 44.6%) neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>The movie.</title><p>The 30-s long, silent, black-and-white, isoluminant movie with frame numbers denoting key episodes in this continuous segment.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Movie selectivity across brain areas.</title><p>(<bold>a</bold>) Similar to <xref ref-type="fig" rid="fig1">Figure 1</xref>, representative single cells from lateral geniculate nucleus (LGN) showing selective movie responses. Strength of modulation, quantified by <italic>z</italic>-scored sparsity is indicated above. The total number of broad spiking cells used (<italic>N</italic>) and the fraction selective are shown by the bar chart on the right. (<bold>b</bold>) Same as that (<bold>a</bold>), for V1 and (<bold>c</bold>) for higher visual areas AM–PM. (<bold>d</bold>) Cumulative distribution of movie selectivity across all broad spiking cells, including significantly (<italic>z</italic> &gt; 2 vertical black line, see <italic>Methods</italic>) tuned cells. The largest prevalence of selectivity in broad spiking neurons was seen in primary visual cortex (V1, 97.3%, 2606 out of 2679) and least in CA3 hippocampus (17.3%, 168 out of 969). (<bold>e</bold>) All brain regions analyzed showed far greater selectivity than the chance level (dashed gray line). There was a clear difference in the strength of movie tuning between visual and hippocampal areas.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>Multiple metrics show significant and comparable movie tuning.</title><p>The percentage of movie-tuned cells, deemed as <italic>z</italic>-scored metric &gt;2, were significantly greater than chance levels (p &lt; 4.9 × 10<sup>−11</sup>), using either sparsity or depth of modulation or mutual information as the metric (see <italic>Methods</italic> for metric definitions). Sparsity yielded higher movie tuning than depth of modulation across all brain regions (p &lt; 1.8 × 10<sup>−3</sup>), putatively because it captures multi-peaked tuning better than depth of modulation, which only relies on the largest and smallest firing rate responses. Similarly, <italic>z</italic>-scored mutual information led to greater tuning than chance levels (p &lt; 4.9 × 10<sup>−11</sup>), but lesser than that with the sparsity metric (p &lt; 1.3 × 10<sup>−5</sup>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp3-v1.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 4.</label><caption><title>Movie tuning is intact during immobility.</title><p>(<bold>a</bold>) Similar to <xref ref-type="fig" rid="fig1">Figure 1</xref>, a representative cell from each of the seven brain regions showing significant modulation movie tuning using only the data when the mouse was immobile, while excluding the data when the mouse was running (stationary data, see <italic>Methods</italic>). (<bold>b</bold>) Fraction of selective neurons was significantly above chance in all brain regions, ranging from 94.7% in V1 up to 7.1% in CA3 in the stationary data. (<bold>c</bold>) To explicitly test the effect of running on movie selectivity, we compared the results in (<bold>b</bold>) with a random subsample of data, of equal duration as the stationary data, that included running and stationary, to control for the loss of data (see <italic>Methods</italic>). Prevalence of movie selectivity was not significantly different (Kolmogorov-Smirnov [KS] - test p &gt; 0.05) in these two subsamples, except in CA1 (p = 0.03, 13.1% in stationary data, 15.0% in the equivalent subsample). Only sessions with at least 300 s of stationary data were used in this analysis to ensure sufficient statistical power. The reduction in fraction tuned neurons in (<bold>b</bold>) and (<bold>c</bold>) for ‘stationary data’, compared to ‘all data’ here and in <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplements 2</xref> and <xref ref-type="fig" rid="fig1s3">3</xref> is because of the reduction in the amount of data, which directly reduces statistical significance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp4-v1.tif"/></fig><fig id="fig1s5" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 5.</label><caption><title>Simultaneously recorded hippocampal cells have different movie tuning.</title><p>Four simultaneously recorded and significantly movie-tuned cells each from (<bold>a</bold>) dentate gyrus, (<bold>b</bold>) CA3, (<bold>c</bold>) CA1, and (<bold>d</bold>) subiculum. Each cell shows different movie selectivity. Average responses are overlaid (on raster plots), and their color corresponds to the different brain regions, described in <xref ref-type="fig" rid="fig1">Figure 1</xref> legend. This further demonstrates that hippocampal movie tuning is not an artifact of nonspecific variables that alter excitability.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp5-v1.tif"/></fig><fig id="fig1s6" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 6.</label><caption><title>Movie tuning in unaffected by the removal of sharp-wave ripple (SWR) events.</title><p>(<bold>a</bold>) Similar to <xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>, a representative cell from each brain region showing significant modulation movie tuning using data after removal of SWR events (14,371 cells from 20 sessions where SWR information was available, see <italic>Methods</italic>). (<bold>b</bold>) Fraction of selective neurons was significantly above chance in all brain regions, ranging from 96.7% in V1 up to 12.3% in CA3 in the SWR removed data. (<bold>c</bold>) To control the loss of data by the removal of SWR, we compared the results with movie tuning in an equivalent subsample of data. Prevalence of movie selectivity was not significantly different (KS-test p &gt; 0.05) in these two subsamples, except in AM–PM (p = 0.02, 97.1% in SWR removed data, 94.6% in the equivalent subsample). As before (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>), due to a reduction in the amount of data, a smaller number of neurons showed significant movie tuning in both SWR removed data as well as equivalent subsampled data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp6-v1.tif"/></fig><fig id="fig1s7" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 7.</label><caption><title>Movie tuning is comparable across sessions with or without prolonged stationary behavior, high or low pupil dilation or theta power.</title><p>(<bold>a</bold>) Three representative cells from sessions with rare stationary periods (% of time in stationary, indicated at the top) and mostly running behavior that showed significant movie tuning. (<bold>b</bold>) Similar to (<bold>a</bold>), three example cells from sessions with mostly running behavior showing significant movie tuning. Movie tuning persisted across all sessions. (<bold>c</bold>) One representative cell each from V1 and CA1, showing comparable movie tuning during dilated (magenta, high pupil area) or constricted (cyan, low pupil area) pupil. Each dot in the scatter (top) corresponds to one spike, and the color corresponds to the pupil area during that spike. Average movie responses for bottom 50 (cyan, pupil constriction) and top 50 (magenta, pupil dilation) percentiles are shown below. This separation based on 50 percentile ensures equal amount of data in both subsegments. (<bold>d</bold>) Similar to (<bold>c</bold>), showing similar movie tuning for data with high (magenta) and low (cyan) theta power. (<bold>e</bold>) Movie tuning in the top as well as bottom 50 percentile of pupil area data was significantly greater than their respective chance levels (p &lt; 1.2 × 10<sup>−8</sup>). Top as well as bottom 50 percentile data did not have significantly different movie tuning prevalence for LGN, DG, and CA3 (p &gt; 0.73, which could be because of smaller number of cells recorded in these brain regions), but dilated pupil corresponds to slightly greater tuning for other brain regions (p &lt; 3.4 × 10<sup>−4</sup>). (<bold>f</bold>) Similar to (<bold>e</bold>), the movie tuning in high as well as low theta power data was significantly greater than chance levels (p &lt; 5.0 × 10<sup>−10</sup>). Movie tuning was greater in data with high theta power for DG and CA1 (p &lt; 2.1 × 10<sup>−6</sup>), but not significantly different for other brain regions (p &gt; 0.07). Both subsegments had equal amounts of data to ensure fair comparison.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp7-v1.tif"/></fig><fig id="fig1s8" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 8.</label><caption><title>Movie presentation did not alter hippocampal firing rates and the mega-scale coding was unrelated to cluster quality.</title><p>(<bold>a</bold>) More than 50% of hippocampal place cells shut down during maze exploration (<xref ref-type="bibr" rid="bib76">Ravassard et al., 2013</xref>). In contrast, there was no consistent pattern of neural activation or shutdown during the movie presentation in all brain areas. To make a more conservative estimate, this comparison was restricted to units whose firing rates did not differ by more than 20% across the two movie blocks. Furthermore, only the data when the animals were immobile was used to avoid confounding effects of running, and the firing rate threshold of 0.5 Hz was removed for this panel. (<bold>b</bold>) The amount of movie tuning was positively correlated with the mean firing rates of the neurons for all brain regions (<italic>r</italic> &gt; 0.14, p &lt; 4.2 × 10<sup>−10</sup>). (<bold>c</bold>) The number of movie-fields was uncorrelated with the mean firing rate of tuned cells in V1, DG, CA1, and SUB (p &gt; 0.12), but positively correlated for LGN, AM–PM, and CA3 (<italic>r</italic> &gt; 0.04, p &lt; 0.01). Note the different <italic>y</italic>-scales for visual and hippocampal brain regions. Since the number of movie-fields is an integer, data along the <italic>y</italic>-axis were slightly jittered for better visualization. (<bold>d</bold>) The mega-scale index was only weakly correlated with the mean firing rate of a neuron in V1 (Pearson’s correlation coefficient <italic>r</italic> = 0.08, p = 7.3 × 10<sup>−5</sup>), CA1 (<italic>r</italic> = −0.14, p = 3.5 × 10<sup>−8</sup>) and subiculum (<italic>r</italic> = −0.14, p = 0.02), and was uncorrelated for other brain regions (p &gt; 0.05). (<bold>e</bold>) The refractory violations index was uncorrelated with the mega-scale index (lower index means better cluster quality; <xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>; <xref ref-type="bibr" rid="bib34">Hill et al., 2011</xref>) for all brain regions (p &gt; 0.05). To remove the potential confounding effect of mean firing rates, we computed the partial correlation coefficient by factoring out the mean firing rate. (<bold>f</bold>) Similar to (<bold>c</bold>), the isolation index (greater isolation index means better cluster quality; <xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>; <xref ref-type="bibr" rid="bib88">Schmitzer-Torbert et al., 2005</xref>) was uncorrelated with the mega-scale index for all brain regions (partial correlation coefficient, by factoring out the mean firing rate, p &gt; 0.12). Factoring out the contribution of mean firing rate is necessary since the isolation index was typically positively correlated (the refractory violations index was typically negatively correlated) with the mean rate. The mega-scale index comparisons were restricted to movie active, tuned neurons with at least two movie peaks. Note-log spaced axes for (<bold>a–d</bold>), except y-axes of <bold>b</bold> and <bold>c</bold>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig1-figsupp8-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-85069-fig1-video1.mp4" id="fig1video1"><label>Figure 1—video 1.</label><caption><title>Sequential movie.</title><p>The 30-s movie clip shown, along with the frame number indicated in the top right corner (updated every second, or every 30 frames). The same movie clip was shown in two blocks of 30 repeats each.</p></caption></media></fig-group><p>Movie selectivity was prevalent in the hippocampal regions too, despite head fixation, dissociation between self-movements and visual cues as well as the absence of rewards, task, or memory demands (<xref ref-type="fig" rid="fig1">Figure 1a–d</xref>). Subiculum, the output region of the hippocampus, farthest removed from the retina, had the largest fraction (44.6%, <xref ref-type="fig" rid="fig1">Figure 1d</xref>) of movie-tuned neurons, followed by the upstream CA1 (33.6%, <xref ref-type="fig" rid="fig1">Figure 1c</xref>) and DG (33.1%, <xref ref-type="fig" rid="fig1">Figure 1a</xref>). However, CA3 movie selectivity was nearly half as much (17.3%, <xref ref-type="fig" rid="fig1">Figure 1b</xref>). This is unlike place cells, where CA3 and CA1 selectivity are comparable (<xref ref-type="bibr" rid="bib41">Jung and McNaughton, 1993</xref>; <xref ref-type="bibr" rid="bib60">Muller, 1996</xref>) and subiculum selectivity is weaker (<xref ref-type="bibr" rid="bib92">Sharp and Green, 1994</xref>).</p></sec><sec id="s2-2"><title>Movie tuning is not an artifact of behavioral or brain state changes</title><p>To confirm these findings, we performed several controls. Running alters neural activity in visual areas (<xref ref-type="bibr" rid="bib63">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib18">Erisken et al., 2014</xref>; <xref ref-type="bibr" rid="bib8">Christensen and Pillow, 2022</xref>; <xref ref-type="bibr" rid="bib47">Lee et al., 2014</xref>) and hippocampus (<xref ref-type="bibr" rid="bib28">Góis and Tort, 2018</xref>; <xref ref-type="bibr" rid="bib102">Wiener et al., 1989</xref>; <xref ref-type="bibr" rid="bib91">Shan et al., 2016</xref>). Hence, we used the data from only the stationary epochs (see <italic>Methods</italic>) and only from sessions with at least 300 s of stationary data (17 sessions, 24,906 cells). Movie tuning was unchanged in these data (<xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>). This is unlike place cells where spatial selectivity is greatly reduced during immobility (<xref ref-type="bibr" rid="bib7">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Foster et al., 1989</xref>). Neurons recorded simultaneously from the same brain region also showed different selectivity patterns (<xref ref-type="fig" rid="fig1s5">Figure 1—figure supplement 5</xref>). Thus, nonspecific effects such as running cannot explain brain-wide movie selectivity. Prolonged immobility could change the brain state, e.g., the emergence of sharp-wave ripples (SWRs). Hence, we removed the data around SWRs and confirmed that movie tuning was unaffected (<xref ref-type="fig" rid="fig1s6">Figure 1—figure supplement 6</xref>). Strong movie-tuned cells were seen in sessions with long bouts of running as well as with predominantly immobile behavior (<xref ref-type="fig" rid="fig1s7">Figure 1—figure supplement 7</xref>), unlike responses to auditory tones, which were lost during running behavior (<xref ref-type="bibr" rid="bib91">Shan et al., 2016</xref>). Place cell selectivity of hippocampal neurons is influenced by theta rhythm (<xref ref-type="bibr" rid="bib23">Foster and Wilson, 2007</xref>; <xref ref-type="bibr" rid="bib83">Royer et al., 2012</xref>; <xref ref-type="bibr" rid="bib37">Huxter et al., 2008</xref>). We compared the movie selectivity during periods of high theta, versus periods of low theta. Significant movie selectivity in both cases (<xref ref-type="fig" rid="fig1s7">Figure 1—figure supplement 7</xref>). To further assess the effect of changes in brain state, we similarly analyzed movie tuning in two equal subsegments of data, corresponding to epochs with high and low pupil dilation, which is a strong correlate of arousal (<xref ref-type="bibr" rid="bib99">Vinck et al., 2015</xref>; <xref ref-type="bibr" rid="bib89">Schröder et al., 2020</xref>; <xref ref-type="bibr" rid="bib19">Fekete et al., 2009</xref>). Movie tuning was above chance levels in both subsegments (<xref ref-type="fig" rid="fig1s7">Figure 1—figure supplement 7</xref>). Hence, locomotion, arousal, or changes in brain states cannot explain the hippocampal movie tuning.</p></sec><sec id="s2-3"><title>Similarities and differences between place-fields and movie-fields</title><p>Hippocampal neurons have one or two place-fields in typical mazes which take a few seconds to traverse (<xref ref-type="bibr" rid="bib68">O’Keefe and Burgess, 1996</xref>). In larger arenas that take tens of seconds to traverse, the number of peaks per cell and the peak duration increases (<xref ref-type="bibr" rid="bib17">Eliav et al., 2021</xref>; <xref ref-type="bibr" rid="bib44">Kjelstrup et al., 2008</xref>; <xref ref-type="bibr" rid="bib31">Harland et al., 2021</xref>; <xref ref-type="bibr" rid="bib79">Rich et al., 2014</xref>). Peak detection for movie tuning is nontrivial because neurons have nonzero background firing rates, and the elevated rates cover a wide range (<xref ref-type="fig" rid="fig1">Figure 1</xref>). We developed a novel algorithm to address this (see <italic>Methods</italic>). On average, V1 neurons had the largest number of movie-fields (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, mean ± standard error of the mean [SEM] = 10.4 ± 0.1, here we use mean instead of median to gain a better resolution for the small and discrete values of number of fields per cell), followed by LGN (8.6 ± 0.3) and AM–PM (6.3 ± 0.07). Hippocampal areas had significantly fewer movie-fields per cell: DG (2.1 ± 0.1), CA3 (2.8 ± 0.3), CA1 (2.0 ± 0.02), and subiculum (2.1 ± 0.05). Thus, the number of movie-fields per cell was smaller than the number of place-fields per cell in comparably long spatial tracks (<xref ref-type="bibr" rid="bib17">Eliav et al., 2021</xref>; <xref ref-type="bibr" rid="bib44">Kjelstrup et al., 2008</xref>; <xref ref-type="bibr" rid="bib31">Harland et al., 2021</xref>; <xref ref-type="bibr" rid="bib79">Rich et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Fenton et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Park et al., 2011</xref>), but a handful of hippocampal cells had more than five movie-fields (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Multi-peaked, mega-scale movie-fields across all brain areas.</title><p>(<bold>a</bold>) Distribution of the number of movie-fields per tuned cell (see <italic>Methods</italic>) in different brain regions (shown by different colors, top line inset, arranged in their hierarchical order). Hippocampal regions (blue-green shades) were significantly different from each other (KS-test p &lt; 0.04), except DG–CA3. All visual regions were significantly different from each other (KS-test p &lt; 7.0 × 10<sup>−11</sup>). All visual–hippocampal region pairwise comparisons were also significantly different (KS-test p &lt; 1.8 × 10<sup>−44</sup>). CA1 had the lowest number of movie-fields per cell (2.0 ± 0.02, mean ± standard error of the mean [SEM]) while V1 had the highest (10.4 ± 0.1). (<bold>b</bold>) Distribution of the durations of movie-fields identified in (<bold>a</bold>), across all tuned neurons from a given brain region. These were significantly different for all brain region pairs (KS-test p &lt; 7.3 × 10<sup>−3</sup>). The longest movie-fields were in subiculum (median ± SEM, here and subsequently, unless otherwise mentioned, 3169.9 ± 169.8 ms), and the shortest in V1 (156.6 ± 9.2 ms). (<bold>c</bold>) Snippets of movie-fields from an example cell from V1, with two of the fields zoomed in, showing 60× difference in duration. Black bar at top indicates 50 ms, and gray bar indicates 1 s. Each frame corresponds to 33.3 ms. Average response (solid trace, <italic>y</italic>-axis on the right) is superimposed on the trial wise spiking response (dots, <italic>y</italic>-axis on the left). Color of dots corresponds to frame numbers as in <xref ref-type="fig" rid="fig1">Figure 1</xref>. (<bold>d</bold>) Same as (<bold>c</bold>), for a CA1 neuron with 54× difference in duration. (<bold>e</bold>) The ratio of longest to shortest field duration within a single cell, i.e., mega-scale index, was largest in V1 (56.7 ± 2.2) and least in subiculum (8.0 ± 9.7). All visual–visual and visual–hippocampal brain region pairs were significantly different on this metric (KS-test p &lt; 0.02). Among the hippocampal–hippocampal pairs, only CA3–SUB were significantly different (p = 0.03). (<bold>f</bold>) For each cell, the total duration of all movie-fields, i.e., cumulative duration of significantly elevated activity, was comparable across brain regions. The largest cumulative duration (10.2 ± 0.46 s, CA3) was only 1.66× of the smallest (6.2 ± 0.09 s) (V1). Visual–hippocampal and visual–visual brain region pairs’ cumulative duration distributions were significantly different (KS-test p &lt; 0.001), but not hippocampal pairs (p &gt; 0.07). (<bold>g</bold>) Distribution of the firing within fields, normalized by that in the shuffle response. All fields from all tuned neurons in a brain region were used. Firing in movie-fields was significantly different across all brain region pairs (KS-test, p &lt; 1.0 × 10<sup>−7</sup>), except DG–CA3. Movie-field firing was largest in V1 (2.9 ± 0.03) and smallest in subiculum (1.14 ± 0.03). (<bold>h</bold>) Snippets of movie-fields from representative tuned cells, from lateral geniculate nucleus (LGN) showing a long movie-field (233 frames, or 7.8 s, panel 1), and from AM–PM and from hippocampus showing short fields (two frames or 66.6 ms wide or less).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Few hippocampal neurons had greater than five movie-fields.</title><p>Only a handful of movie-tuned neurons from dentate gyrus (rows 1 and 2), CA3 (rows 3 and 4), CA1, and subiculum (bottom-right), had more than five distinct movie-fields. Similar format as <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplement 5</xref>. This is in contrast to the visual areas where a large number of movie-fields were common and the average number of movie-fields per cell was greater than 6 (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Mega-scale movie-coding within a single cell is smaller than the ensemble wide mega-scale index in visual, but not hippocampal areas.</title><p>(<bold>a</bold>) Distribution of median duration of movie-fields, computed across all fields of a single neuron. Median movie-field duration was significantly larger in all hippocampal areas compared to all visual areas (KS-test p &lt; 7.1 × 10<sup>−31</sup>). Median field duration between DG–CA3 and DG–CA1 were not significantly different, but all other visual–visual and hippocampal–hippocampal region pairs were significantly different. (KS-test p &lt; 0.04). CA3 had the largest median field duration (6.3 ± 0.48 s), and V1 had the smallest (0.27 ± 0.03 s). Surprisingly, lateral geniculate nucleus (LGN) movie-field durations (0.57 ± 0.13 s) were about twofold longer than V1 (p = 2.5 × 10<sup>−21</sup>); though both were smaller than those in the higher order brain areas (0.71 ± 0.05 s). (<bold>b</bold>) Firing in movie-fields, normalized by that in the shuffled response were used to obtain the median value from all fields of a neuron. This metric of median movie-field activation is significantly different across all brain region pairs (KS-test p &lt; 3.4 × 10<sup>−5</sup>), except DG–CA3, CA3–CA1, and DG–CA1 pairs. The largest median movie-field activation was in V1 (2.5 ± 0.05), and the smallest in subiculum (1.13 ± 0.03). (<bold>c</bold>) Cumulative firing in movie-fields, normalized by that in the shuffle response, obtained by adding the activity within all fields of a neuron was significantly different across all brain region pairs (KS-test p &lt; 3.0 × 10<sup>−7</sup>), except DG–CA3, CA3–CA1, and DG–CA1. V1 response was largest (1.93 ± 0.04), and subiculum was the smallest (1.11 ± 0.02). (<bold>d</bold>) For each brain region, the movie-field duration ratio was recalculated by randomly reassigning the cell ids to all the movie peaks from that brain region. Using this new assignment of movie peaks to a cell, we obtain the expected mega-scale index (largest/smallest peak duration) based on the ensemble behavior. The observed mega-scale index within a cell was smaller than expected from the ensemble in all the visual areas (KS-test p &lt; 3.2 × 10<sup>−3</sup>, median was 77.5%, 56.2%, and 41.7% of chance for LGN, V1, and AM–PM, respectively). This was not the case in hippocampal regions (p &gt; 0.23). Thus, individual cells in the visual, but not hippocampal areas sampled a subset of possible mega-scale coding values of the ensemble. (<bold>e</bold>) Histogram of movie-fields, binned for their durations (log-scaled) and their prominence (also log-scaled). The most prominent fields tended to be wider in most brain areas, and this effect was stronger in hippocampal regions, than visual. Note that the histogram color is also log-scaled.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig2-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Mega-scale structure of movie-fields</title><p>Typical receptive field size increases as one moves away from the retina in the visual hierarchy (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>). A similar effect was seen for movie-field durations. On average, hippocampal movie-fields were longer than visual regions (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). But there were many exceptions –movie-fields of LGN (median ± SEM, here and subsequently, unless stated otherwise, 308.5 ± 33.9 ms) were twice as long as in V1 (156.6 ± 9.2 ms). Movie-fields of subiculum (3169.9 ± 169.8 ms) were significantly longer than CA1 (2786.1 ± 77.5 ms) and nearly threefold longer than the upstream CA3 (979.1 ± 241.1 ms). However, the dentate movie-fields (2113.2 ± 172.4 ms) were twofold longer than the downstream CA3. This is similar to the patterns reported for CA3, CA1, and DG place cells (<xref ref-type="bibr" rid="bib69">Park et al., 2011</xref>). But others have claimed that CA3 place-fields are slightly bigger than CA1 (<xref ref-type="bibr" rid="bib82">Roth et al., 2012</xref>), whereas movie-fields showed the opposite pattern.</p><p>The movie-field durations spanned a 500- to 1000-fold range in every brain region investigated (<xref ref-type="fig" rid="fig2">Figure 2e</xref>). This mega-scale scale is unprecedentedly large, nearly two orders of magnitude greater than previous reports in place cells (<xref ref-type="bibr" rid="bib17">Eliav et al., 2021</xref>; <xref ref-type="bibr" rid="bib31">Harland et al., 2021</xref>). Even individual neurons showed 100-fold mega-scale responses (<xref ref-type="fig" rid="fig2">Figure 2c, d</xref>) compared to less than 10-fold scale within single place cells (<xref ref-type="bibr" rid="bib17">Eliav et al., 2021</xref>; <xref ref-type="bibr" rid="bib31">Harland et al., 2021</xref>). The mega-scale tuning within a neuron was largest in V1 and smallest in subiculum (<xref ref-type="fig" rid="fig2">Figure 2e</xref>). This is partly because the short-duration movie-fields in hippocampal regions were typically neither as narrow nor as prominent as in the visual areas (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p><p>Despite these differences in mega-scale tuning across different brain areas, the total duration of elevated activity, i.e., the cumulative sum of movie-field durations within a single cell, was remarkably conserved across neurons within and across brain regions (<xref ref-type="fig" rid="fig2">Figure 2f</xref>). Unlike movie-field durations, which differed by more than tenfold between hippocampal and visual regions, cumulative durations were quite comparable, ranging from 6.2 s (V1) to 10.2 s (CA3) (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, LGN = 8.8 ± 0.21 s, V1 = 6.2 ± 0.09, AM–PM = 7.8 ± 0.09, DG = 9.4 ± 0.26, CA3 = 10.2 ± 0.46, CA1 = 9.1 ± 0.12, SUB = 9.5 ± 0.27). Thus, hippocampal movie-fields are longer and less multi-peaked than visual areas, such that the total duration of elevated activity was similar across all areas, spanning about a fourth of the movie, comparable to the fraction of large environments in which place cells are active (<xref ref-type="bibr" rid="bib31">Harland et al., 2021</xref>; <xref ref-type="bibr" rid="bib21">Fenton et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Park et al., 2011</xref>). To quantify the net activity in the movie-fields, we computed the total firing in the movie-fields (i.e., the area under the curve for the duration of the movie-fields), normalized by the expected discharge from the shuffled response. Unlike the tenfold variation of movie-field durations, net movie-field discharge was more comparable (&lt;3× variation) across brain areas, but maximal in V1 and least in subiculum (<xref ref-type="fig" rid="fig2">Figure 2g</xref>).</p><p>Many movie-fields showed elevated activity spanning up to several seconds, suggesting rate-code like encoding (<xref ref-type="fig" rid="fig2">Figure 2h</xref>). However, some cells showed movie-fields with elevated spiking restricted to less than 50 ms, similar to responses to briefly flashed stimuli in anesthetized cats (<xref ref-type="bibr" rid="bib107">Yen et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Herikstad et al., 2011</xref>; <xref ref-type="bibr" rid="bib104">Xia et al., 2021</xref>). This is suggestive of a temporal code, characterized by low spike timing jitter (<xref ref-type="bibr" rid="bib38">Ikegaya et al., 2004</xref>). Such short-duration movie-fields were not only common in the thalamus (LGN), but also AM–PM, three synapses away from the retina. A small fraction of cells in the hippocampal areas, more than five synapses away from the retina, showed such temporally coded fields as well (<xref ref-type="fig" rid="fig2">Figure 2h</xref>).</p><p>To determine the stability and temporal-continuity of movie tuning across the neural ensembles we computed the population vector overlap between even and odd trials (<xref ref-type="bibr" rid="bib78">Resnik et al., 2012</xref>) (see <italic>Methods</italic>). Population response stability was significantly greater for tuned than for untuned neurons (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The population vector overlap around the diagonal was broader in hippocampal regions than visual cortical and LGN, indicating longer temporal-continuity, reflective of their longer movie-fields. Furthermore, the population vector overlap away from the diagonal was larger around frames 400–800 in all brain areas due to the longer movie-fields in that movie segment (see below).</p></sec><sec id="s2-5"><title>Relationship between movie image content and neural movie tuning</title><p>Are all movie frames represented equally by all brain areas? The duration and density of movie-fields varied as a function of the movie frame and brain region (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). We hypothesized that this variation could correspond to the change in visual content from one frame to the next. Hence, we quantified the similarity between adjacent movie frames as the correlation coefficient between corresponding pixels and termed it as frame-to-frame (F2F) image correlation. For comparison, we also quantified the similarity between the neural responses to adjacent frames (F2F neural correlation), as the correlation coefficient between the firing rate response of neuronal ensembles between adjacent frames. For all brain regions, the neural F2F was correlated with image F2F, but this correlation was weaker in hippocampal output regions (CA1 and SUB) than visual regions like LGN and V1. The majority of brain regions had substantially reduced density of movie-fields between the movie frames 400–800, but the movie-fields were longer in this region. This effect as well was greater in the visual regions than hippocampal regions. Using significantly tuned neurons, we computed the average neural activity in each brain region at each point in the movie (see <italic>Methods</italic>). Although movie-fields (<xref ref-type="fig" rid="fig3">Figure 3a</xref>), or just the strongest movie-field per cell (<xref ref-type="fig" rid="fig3">Figure 3b</xref>), covered the entire movie, the peak normalized, ensemble activity level of all brain regions showed significant overrepresentation, i.e., deviation from the uniformity, in certain parts of the movie (<xref ref-type="fig" rid="fig3">Figure 3c</xref>, see <italic>Methods</italic>). This was most pronounced in V1 and the higher visual areas AM–PM. The number of movie frames with elevated ensemble activity was higher in visual cortical areas than hippocampal regions (<xref ref-type="fig" rid="fig3">Figure 3d</xref>), and also this modulation (see <italic>Methods</italic>) was smaller in hippocampus and LGN, compared to the visual cortical regions (<xref ref-type="fig" rid="fig3">Figure 3e</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Population averaged movie tuning varies across brain areas.</title><p>(<bold>a</bold>) Stack plot of all the movie-fields detected from all tuned neurons of a brain region. Color indicates relative firing rate, normalized by the maximum firing rate in that movie-field. The movie-fields were sorted according to the frame with the maximal response. Note accumulation of fields in certain parts of the movie, especially in subiculum and AM–PM. (<bold>b</bold>) Similar to (<bold>a</bold>), but using only a single, tallest movie-field peak from each neuron showing a similar pattern, with pronounced overrepresentation of some portions of the movie in most brain areas. Each neuron’s response was normalized by its maximum firing rate. The average firing rate of non-peak frames, which was inversely related to the depth of modulation, was smallest (0.35× of the average peak response across all neurons) for V1, followed by AM–PM 0.37, leading to blue shades. Average non-peak responses were higher for other regions (0.57× the peak for LGN, CA3 – 0.61, DG – 0.62, CA1 – 0.64, and SUB – 0.76), leading to warmer off-diagonal colors. (<bold>c</bold>) Multiple single-unit activity (MSUA) in a given brain region, obtained as the average response across all tuned cells, by using maxima-normalized response for each cell from (<bold>b</bold>). Gray lines indicate mean ± 4*std response from the shuffle data corresponding to p = 0.025 after Bonferroni correction for multiple comparisons (see <italic>Methods</italic>). AM–PM had the largest MSUA modulation (sparsity = 0.01) and CA1 had the smallest (sparsity = 1.8 × 10<sup>−4</sup>). The MSUA modulation across several brain region pairs – AM&amp;PM–DG, V1–CA3, DG–CA3, CA3–CA1, and CA1–SUB were not significantly correlated (Pearson correlation coefficient p &gt; 0.05). Some brain region pairs, DG–LGN, DG–V1, AM&amp;PM–CA3, LGN–CA1, V1–CA1, DG–SUB, and CA3–SUB, were significantly negatively correlated (<italic>r</italic> &lt; −0.18, p &lt; 4.0 × 10<sup>−7</sup>). All other brain region pairs were significantly positively correlated (<italic>r</italic> &gt; 0.07, p &lt; 0.03). (<bold>d</bold>) Number of frames for which the observed MSUA deviates from the <italic>z</italic> = ±4 range from (<bold>c</bold>), termed significant deviation. V1 and AM–PM had the largest positive deviant frames (289), and CA3 had the least (zero). Unlike CA3, the low number of deviant frames for LGN could not be explained by sample size, because there were more tuned cells in LGN than SUB. (<bold>e</bold>) Firing in deviant frames above (or below) chance level, as a percentage of the average response. Above chance level deviation was greater or equal to that below, for all brain regions except DG, with the largest positive deviation in AM–PM (9.3%), largest negative deviation in V1 (6.0%), and least in CA3 (zero each). (<bold>f</bold>) Total firing rate response of visual regions across tuned neurons. All regions had significant negative correlation (<italic>r</italic> &lt; −0.39, p &lt; 3.4 × 10<sup>−34</sup>) between the ensemble response and the frame-to-frame (F2F) image correlation (gray line, <italic>y</italic>-axis on the left) across movie frames. (<bold>g</bold>) Similar to (<bold>f</bold>), for hippocampal regions. CA3 response were not significantly correlated with the F2F correlation, dentate gyrus (<italic>r</italic> = 0.26, p = 4.0 × 10<sup>−15</sup>) and CA1 (<italic>r</italic> = 0.21, p = 1.5 × 10<sup>−10</sup>) responses were positively correlated, and subiculum response was negatively correlated (<italic>r</italic> = −0.44, p = 2.2 × 10<sup>−43</sup>). Note the substantially higher mean firing rates of LGN in (<bold>f</bold>) and subiculum neurons in (<bold>g</bold>) (colored lines closer to the top) compared to other brain areas.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Population vector overlap is wider in hippocampus than visual areas.</title><p>(<bold>a</bold>) Population vector overlap between even and odd trials for the population of tuned neurons show highest overlap along the diagonal (i.e., for the same movie frame) for all brain regions. Each neuron’s response was normalized by its mean rate and the average response in even as well as odd trials was smoothed by a Gaussian window of two frames (66.6 ms, see <italic>Methods</italic>). Dashed black lines indicate the −300 and +300 frames away from the diagonal. Notice large correlations (close to unity, horizontal color bar) indicating stable responses. The correlations decay quickly to smaller values for the visual areas but more slowly for hippocampal areas, due to their broader movie-fields. (<bold>b</bold>) Same as (<bold>a</bold>), but for untuned neurons, resulting in a salt and pepper overlap pattern and low values of correlation, indicating lesser stability than the tuned neurons. Since the majority of cells in the visual areas were tuned, the untuned population was smaller, leading to more variable population vector overlap. (<bold>c</bold>) The average population vector overlap, computed across all frames, as a function of the number of movie frames away from the diagonal in (<bold>a</bold>). It had a large value in visual regions for the 0th diagonal (colored lines) indicating stable responses, whereas the untuned neuron population (gray lines) were unstable, with values near zero, or chance level. The highest population vector overlap in hippocampal regions was smaller than visual areas but persisted for more frames, due to their broader movie-fields (full width at half maximum of the peak −17.3 frames for LGN, 22.7 – V1, 39.0 – AM&amp;PM, 49.8 – DG, 57.4 – CA3, 64.7 – CA1, and 59.2 – subiculum).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Movie-field properties strongly reflect the frame-to-frame correlation structure of the movie in the visual but not hippocampal areas.</title><p>(<bold>a</bold>) The adjacent movie frame (frame<sub><italic>n</italic></sub>,frame<sub><italic>n</italic>+1</sub>) correlation coefficient, indicating the similarity of two consecutive frames, termed F2F image correlation, is shown in gray. Similarly, the correlation coefficient between the population vector of neural responses between adjacent frames was termed F2F neural correlation, computed separately for each brain region is shown in color. The relationship between F2F image, and F2F neural correlation across brain regions is shown in the matrix on the right. Diagonal entries indicate correlation between F2F image and F2F neural, with largest correlation for LGN (+0.82), followed by V1 (+0.75), CA3 (+0.56), DG (+0.52), AM&amp;PM (+0.38), CA1 (+0.14), and SUB (+0.07). All correlations were significant (p &lt; 1.1 × 10<sup>−3</sup>). Above diagonal entries indicate the correlation coefficient between brain region pairs. Below diagonal entries indicate the same but using partial correlations that factor out the F2F image correlation. All partial correlations were significant (p &lt; 5.4 × 10<sup>−3</sup>), except V1–CA1 and AM&amp;PM–CA3. (<bold>b</bold>) Histogram of the number of movie-field peaks (i.e., movie-field density) across all tuned neurons in a brain region, as a function of the movie frame. This distribution was significantly non-uniform (Chi-square goodness-of-fit test for uniform distribution, p &lt; 3.8 × 10<sup>−6</sup>) for all brain regions. All distributions were significantly negatively correlated with F2F image correlation (p &lt; 10<sup>−7</sup>). These correlations were much stronger in visual (LGN −0.77, V1 −0.73, AM–PM −0.71) areas than hippocampal areas (DG −0.23, CA3 −0.70, CA1 −0.18, SUB −0.27). The largest partial correlation after factoring out the F2F image correlation was between LGN–V1 and V1–CA3 (0.89) and the least between LGN–DG (0.16). All partial correlations were significant (p &lt; 1.2 × 10<sup>−6</sup>). (<bold>c</bold>) Same as (<bold>b</bold>), but for the median duration of movie-fields. F2F image correlation shown in gray, with larger correlation between consecutive frames between frames 400 and 800 clearly reflected in larger movie-field durations in visual areas. All distributions were significantly non-uniform (Chi-square goodness-of-fit test, p &lt; 10<sup>−100</sup>) and all distributions were significantly positively correlated with F2F image correlation (<italic>r</italic> &gt; 0.24, p &lt; 2 × 10<sup>−13</sup>), with greater values for visual areas (LGN +0.61, V1 +0.51, AM–PM +0.55) than hippocampal (DG +0.39, CA3 +0.58, CA1 +0.42, SUB +0.24). Note that the <italic>y</italic>-axes for the histogram are log-scaled and show larger median durations for hippocampal regions than visual. The largest correlation was between AM&amp;PM–CA3 (0.81) and the least between CA3–SUB (−0.03). All partial correlations were significant (p &lt; 4.4 × 10<sup>−4</sup>), except LGN–CA1 (p = 0.11) and CA3–SUB (p = 0.39). (<bold>d</bold>) Total firing rate across all broad spiking neurons in different brain regions, showing similar non-uniformity as <xref ref-type="fig" rid="fig3">Figure 3c</xref>. All brain regions had significantly negative correlation with the F2F image correlation (<italic>r</italic> &lt; −0.08, p &lt; 0.03), except DG, which was significantly positively correlated (<italic>r</italic> = 0.21, p = 2.4 × 10<sup>−10</sup>). The largest number of above chance (gray lines) deviations were seen for AM–PM (340 frames), and least for CA3 (57 frames), which could be due to the low cell count in CA3. Below chance level deviations were least common in LGN (25 frames), and most common in AM–PM (441 frames). The largest partial correlation among brain region pairs was between DG–CA1 (0.76) and the least between V1–DG (−0.1) after factoring out the F2F image correlation. All partial correlations were significant (p &lt; 3.2 × 10<sup>−3</sup>), except LGN–DG (p = 0.81). Similar to <xref ref-type="fig" rid="fig3">Figure 3c–e</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig3-figsupp2-v1.tif"/></fig></fig-group><p>Using the significantly tuned neurons, we also computed the average neural activity in each brain region corresponding to each frame in the movie, without peak rate normalization (see <italic>Methods</italic>). The degree of continuity between the movie frames, quantified as above (F2F image correlation), was inversely correlated with the ensemble rate modulation in all areas except DG, CA3, and CA1 (<xref ref-type="fig" rid="fig3">Figure 3f, g</xref>). As expected for a continuous movie, this F2F image correlation was close to unity for most frames, but highest in the latter part of the movie where the images changed more slowly. The population wide elevated firing rates, as well as the smallest movie-fields, occurred during the earlier parts (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Thus, the movie-code was stronger in the segments with greatest change across movie frames, in agreement with recent reports of visual cortical encoding of flow stimuli (<xref ref-type="bibr" rid="bib15">Dyballa et al., 2018</xref>). These results show differential population representation of the movie across brain regions.</p></sec><sec id="s2-6"><title>Differential neural encoding of sequential versus scrambled movie in visual and hippocampal areas</title><p>If these responses were purely visual, a movie made of scrambled sequence of images would generate equally strong or even stronger selectivity due to the even larger change across movie frames, despite the absence of similarity between adjacent frames. To explore this possibility, we investigated neural selectivity when the same movie frames were presented in a fixed but scrambled sequence (scrambled movie, <xref ref-type="video" rid="fig4video1">Figure 4—video 1</xref>). The within frame and the total visual content were identical between the continuous and scrambled movies, and the same sequence of images was repeated many times in both experiments (see <italic>Methods</italic>). But there was no correlation between adjacent frames, i.e., visual continuity, in the latter (<xref ref-type="fig" rid="fig4">Figure 4a</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Larger reduction of selectivity in hippocampal than visual regions due to scrambled presentation.</title><p>(<bold>a</bold>) Similarity between the visual content of one frame with the subsequent one, quantified as the <italic>Pearson</italic> correlation coefficient between pixel–pixel across adjacent frames for the continuous movie (pink) and the scrambled sequence (lavender), termed F2F image correlation. Similar to <xref ref-type="fig" rid="fig3">Figure 3g</xref>. For the scrambled movie, the frame number here corresponded to the chronological frame sequence, as presented. (<bold>b</bold>) Fraction of broad spiking neurons significantly modulated by the continuous movie (red) or the scrambled sequence (blue) using <italic>z</italic>-scored sparsity measures (similar to <xref ref-type="fig" rid="fig1">Figure 1</xref>, see <italic>Methods</italic>). For all brain regions, continuous movie generated greater selectivity than scrambled sequence (KS-test p &lt; 7.4 × 10<sup>−4</sup>). (<bold>c</bold>) Percentage change in the magnitude of tuning between the continuous and scrambled movies for cells significantly modulated by either continuous or scrambled movie, termed visual continuity index. The largest drop in selectivity due to scrambled movie occurred in CA1 (90.3 ± 2.0%), and least in V1 (−1.5 ± 0.6%). Visual continuity index was significantly different between all brain region pairs (KS-test p &lt; 0.03) and significantly greater for hippocampal areas than visual (8.2-fold, p &lt; 10<sup>−100</sup>). (<bold>d</bold>) Raster plots (top) and mean rate responses (color, bottom) showing increased spiking responses to only one or two scrambled movie frames, lasting about 50 ms. Tuned responses to scrambled movie were found in all brain regions, but these were the least frequent in DG and CA1. (<bold>e</bold>) One representative cell each from V1 (left) and CA1 (right), where the frame rearrangement of scrambled responses resulted in a response with high correlation to the continuous movie response for V1, but not CA1. Pearson correlation coefficient values of continuous movie and rearranged scrambled responses are indicated on top. (<bold>f</bold>) Average decoding error for observed data (see <italic>Methods</italic>), over 60 trials for continuous movie (maroon), was significantly lower than shuffled data (gray) (KS-test p &lt; 1.2 × 10<sup>−22</sup>). Solid line – mean error across 60 trials using all tuned cells from a brain region, shaded box – standard error of the mean (SEM), green dots – mean error across all trials using a random subsample of 150 cells from each brain region. Decoding error was lowest for V1 (30.9 frames) and highest in DG (241.2) and significantly different between all brain regions pairs (p &lt; 1.9 × 10<sup>−4</sup>), except CA3–CA1, CA3–subiculum, and CA1–subiculum (p &gt; 0.63). (<bold>g</bold>) Similar to (<bold>f</bold>), decoding of scrambled movie was significantly worse than that for the continuous movie (KS-test p &lt; 2.6 × 10<sup>−3</sup>). Scrambled responses, in their ‘as is’, chronological order were used herein. Lateral geniculate nucleus (LGN) decoding error for scrambled presentation was 6.5× greater than that for continuous movie, whereas the difference in errors was least for V1 (1.04×). Scrambled movie decoding error for all visual areas and for CA1 and subiculum was significantly smaller than chance level (KS-test p &lt; 2.6 × 10<sup>−3</sup>), but not DG and CA3 (p &gt; 0.13). The middle 20 trials of the continuous movie were used for comparison with the scrambled movie since the scrambled movie was only presented 20 times. Middle trials of the continuous movie were chosen as the appropriate subset since they were chronologically closest to the scrambled movie presentation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Scrambled movie elicits narrower but more movie-fields per cell than the continuous movie in all the visual regions.</title><p>(<bold>a</bold>) Cumulative distribution of the total number of fields per cell for the scrambled movie shows the largest number of fields in LGN (mean ± standard error of the mean [SEM], 31.8 ± 2.0), followed by V1 (24.0 ± 0.38) and last AM–PM (11.1 ± 2.1). All three brain regions were significantly different from each other (KS-test p &lt; 2.0 × 10<sup>−5</sup>). (<bold>b</bold>) The median scrambled movie-field duration was shortest in LGN (43.9 ± 131.2 ms), intermediate in V1 (46.2 ± 24.8), and widest in AM–PM (77.6 ± 40.1 ms), and differences were significant (p &lt; 7.0 × 10<sup>−4</sup>). This was much smaller than for the continuous movie (<xref ref-type="fig" rid="fig2">Figure 2</xref>). (<bold>c</bold>) Durations of fields for scrambled sequence across all fields of all neurons from a brain region. These were narrowest in LGN (31.3 ± 6.5 ms), followed by V1 (38.6 ± 0.2) and last AM–PM (64.3 ± 6.7). All differences were significant (KS-test p &lt; 7.2 × 10<sup>−136</sup>). (<bold>d</bold>) Despite these differences, the cumulative duration of movie-fields was comparable across the three brain regions (1.69 ± 0.05 s for V1, 2.03 ± 0.07 for AM–PM, and 2.4 ± 0.2 for LGN), but significantly different (p &lt; 1.7 × 10<sup>−5</sup>). Note the linear scale on the <italic>x</italic>-axis in this panel compared to the log-scale in other panels. (<bold>e</bold>) Ratio of field durations, i.e., mega-scale index, for the scrambled movie was smallest in V1 (15.5 ± 1.6), intermediate in LGN (16.3 ± 5.4), and largest in AM–PM (23.4 ± 2.1), and not significantly different between V1 and LGN (p = 0.28). V1–AM&amp;PM and LGN–AM&amp;PM were significantly different (p &lt; 5.7 × 10<sup>−5</sup>). (<bold>f</bold>) Cumulative spiking activity, summed across all movie-fields of a given neuron was largest in V1 (3.8 ± 0.1), intermediate in LGN (2.3 ± 0.1), and smallest in AM–PM (2.0 ± 0.07), and significantly different between all brain region pairs (p &lt; 0.02).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Cell by cell comparison of continuous versus scrambled movie responses.</title><p>Data for only those visual area neurons that were significantly modulated by both the continuous and scrambled movie were used. (<bold>a</bold>) The number of movie-fields per cell for the continuous movie was significantly smaller than that for scrambled sequence in all brain areas (LGN – continuous mean ± standard error of the mean [SEM] = 10.7 ± 0.42, scrambled = 31.8 ± 2.0, KS-test p = 2.0 × 10<sup>−23</sup>, V1 −10.8 ± 0.11 vs. 24.0 ± 0.38, KS-test p <italic>=</italic> 3 .7 × 10<sup>−210</sup>, AM&amp;PM −6.9 ± 0.07, vs. 11.1 ± 0.21, KS-test p = 1.3 × 10<sup>−57</sup>). Data are additionally scattered by a small random number for the ease of visualization. (<bold>b</bold>) Median duration of movie-fields for a cell was significantly larger for continuous movie, compared to scrambled sequence in all visual regions. (LGN continuous = 0.46 ± 0.08 s, scrambled = 0.04 ± 0.13 s, KS-test p = 7.1 × 10<sup>−65</sup>, V1 −0.25 ± 0.03 vs. 0.04 ± 0.02 s, KS-test p <italic>&lt;</italic> 10<sup>−150</sup>, AM&amp;PM 0.65 ± 0.04 vs. 0.08 ± 0.04 s, KS-test p &lt; 10<sup>−150</sup>). (<bold>c</bold>) Cumulative duration of all movie-fields for a cell was significantly larger for continuous movie, compared to scrambled sequence in all visual regions (LGN continuous = 8.9 ± 0.23 s, scrambled = 2.4 ± 0.19 s, KS-test p = 3.2 × 10<sup>−69</sup>, V1 −6.1 ± 0.09 vs. 1.69 ± 0.05 s, KS-test p <italic>=</italic> 3.3 × 10<sup>−296</sup>, AM–PM 7.8±0.1 s, vs. 2.0 ± 0.07, KS-test p = 9.0 × 10<sup>−318</sup>). (<bold>d</bold>) Histogram of number of fields per cell, for continuous and scrambled movies. (<bold>e</bold>) Logarithmically spaced histogram of median field durations was significantly different between continuous and scrambled sequence. (<bold>f</bold>) Similar to (<bold>e</bold>), histogram of cumulative duration of movie-fields for each cell. (<bold>g</bold>) The ratio of number of fields per cell between continuous and scrambled movies was biased to smaller than unity values for all brain regions, with the largest bias for LGN (0.46 ± 0.08), intermediate for V1 (0.5 ± 0.04), and least for AM–PM (0.77 ± 0.05). (<bold>h</bold>) The median field duration ratio was biased to values greater than unity, with the largest bias for LGN (7.4 ± 1.4), least for V1 (4.5 ± 0.68), and intermediate for AM–PM (5.5 ± 0.82). (<bold>i</bold>) The cumulative field duration ratio was also biased to values greater than unity, with similar biases for LGN (3.37 ± 0.36), V1 (3.1 ± 0.3), and AM–PM (3.3 ± 0.67).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Multiple single-unit activity (MSUA) across all movie-tuned neurons in a brain region shows greater modulation than chance for the scrambled sequence in all visual areas.</title><p>(<bold>a</bold>) Stack plot of tuned responses to the scrambled movie presentation from each brain region, sorted according to the frame with peak response. Each firing rate profile is normalized by the peak response causing the diagonal to be unity. The average firing rate of non-peak frames (similar to <xref ref-type="fig" rid="fig3">Figure 3b</xref>, legend) was smallest (0.50× of the average peak response across all neurons) for V1, followed by AM&amp;PM – 0.56 and largest for LGN – 0.65. (<bold>b</bold>) Colored trace – average response, across all tuned responses from (<bold>a</bold>), gray trace – chance level, <italic>z</italic> = ±4, corresponding to the p = 0.025 level after Bonferroni correction. (<bold>c</bold>) Number of frames for which the observed response exceeds (or falls below) <italic>z</italic> = ±4 cutoff from (<bold>b</bold>), called significantly deviant frames. V1 had the largest number of positive (279 frames) and negative (297) deviant frames, similar to the continuous movie (<xref ref-type="fig" rid="fig3">Figure 3d</xref>, and 289 positive and 324 negative). AM–PM had intermediate (225 and 235) deviant frames for the scrambled movie, which was lower than the continuous movie (285 and 454). LGN had the least number of significantly deviant frames (31 and 29), larger than the continuous movie (12 and 0). (<bold>d</bold>) Firing rate deviation above chance levels, corresponding to the significant frames, as identified in (<bold>c</bold>), normalized by the mean rate of the MSUA. Largest deviation was observed in V1 (above – 3.1 and below – 2.7%), and least in LGN (1.1% and 0.45%). Compare with <xref ref-type="fig" rid="fig3">Figure 3</xref>. (<bold>e</bold>) Frame-to-frame (F2F) image correlation, from <xref ref-type="fig" rid="fig4">Figure 4a</xref> for comparison. This had no structure and values hovered around zero (unlike the continuous movie) and was not significantly correlated with the MSUA responses in (<bold>b</bold>), for any of the brain regions (Pearson correlation coefficient LGN p = 0.71, V1 p = 0.06, AM–PM p = 0.21). Despite this, the MSUA shows significant modulation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Latency of responses to the scrambled-sequence corresponds to the anatomical hierarchy of visual areas.</title><p>(<bold>a</bold>) Average response for one representative cell from each visual region, that had high similarity between the continuous movie and the rearranged scrambled sequence responses (see <italic>Methods</italic>). Gray response in background corresponds to the chronological scrambled sequence. (<bold>b</bold>) Cumulative histogram of <italic>z</italic>-scored correlation between continuous and scrambled-rearranged tuning responses (see <italic>Methods</italic>). Dotted black line indicates significance threshold of <italic>z</italic> &gt; 2. (<bold>c</bold>) The latency at which continuous and scrambled-rearranged responses were maximally correlated showed high values (heuristically above 0.25) in a short range of positive latencies for LGN, V1, and AM–PM neurons. This analysis was restricted to neurons tuned in continuous as well as scrambled movies. Similar analysis for hippocampal regions resulted in almost no correlations above 0.25. (<bold>d</bold>) Cumulative histogram of latencies, when the continuous and scrambled-rearranged responses were maximally correlated, was the smallest for LGN (59.5 ± 4.6 ms), and largest for higher visual areas, AM–PM (91.6 ± 1.6 ms). Hippocampal regions were excluded, owing to lack of data with correlation above 0.25.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig4-figsupp4-v1.tif"/></fig><fig id="fig4s5" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 5.</label><caption><title>Movie tuning in hippocampal neurons remains near chance level even after rearranging scrambled movie frames.</title><p>Histogram showing percentage of tuned cells for movie presentation in the continuous (red), scrambled order, taken as is (light blue), or the scrambled order but rearranged (dark blue). Movie tuning was significantly higher for the continuous presentation (p &lt; 3.5 × 10<sup>–3</sup>) than the scrambled as is condition or scrambled rearranged condition (p &lt; 2.6 × 10<sup>–6</sup>), in all brain regions. Movie tuning for the scrambled presentation taken as is, or after rearrangement was not significantly different for all brain regions (p &gt; 0.08), except LGN (p = 1.3 × 10<sup>–5</sup>) and V1 (p = 0.001), although the prevalence of tuning was comparable (63.7% and 64.3% – LGN and 90.1% and 90.0% – V1).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig4-figsupp5-v1.tif"/></fig><fig id="fig4s6" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 6.</label><caption><title>Population vector overlap was narrower for the scrambled compared to the continuous movie.</title><p>(<bold>a</bold>) Population vector overlap between even and odd trials for tuned neurons showing higher overlap along the diagonal for all brain regions. Black lines indicate the −300 and +300 diagonal, whereas the main diagonal is the 0th diagonal. (<bold>b</bold>) Same as (<bold>a</bold>) but for untuned neurons, resulting in a salt and pepper overlap without higher correlation around the diagonal. (<bold>c</bold>) The average overlap along diagonals had a large value in visual regions for the 0th diagonal, which was not true for the untuned neuron population. Average correlation in hippocampal regions was broader and lesser in magnitude compared to visual regions. Similar to <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. Full width at half maximum of the peak – 4.4 frames for LGN, 4.8 – V1, 5.2 – AM&amp;PM, 7.6 – DG, 5.7 – CA3, 10.8 – CA1, and 15.1 – subiculum, even though consecutive frames in the scrambled presentation were largely uncorrelated.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-85069-fig4-figsupp6-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-85069-fig4-video1.mp4" id="fig4video1"><label>Figure 4—video 1.</label><caption><title>Scrambled movie.</title><p>Frames from the sequential video clip (<xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref>) were presented in a scrambled sequence, with the same sequence repeated 20 times (2 blocks of 10 trials each). Frame numbers in the scrambled sequence are indicated in the top right corner.</p></caption></media></fig-group><p>For all brain regions investigated, the continuous movie generated significantly greater modulation of neural activity than the scrambled sequence (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). Middle 20 trials of the continuous movie were chosen as the appropriate subset for comparison since they were chronologically closest to the scrambled movie presentation. This choice ensured that other long-term effects, such as behavioral state change, instability of single-unit measurement and representational (<xref ref-type="bibr" rid="bib12">Deitch et al., 2021</xref>) or behavioral (<xref ref-type="bibr" rid="bib85">Sadeh and Clopath, 2022</xref>) drift could not account for the differences in neural responses to continuous and scrambled movie presentation. This preference for continuous over scrambled movie was the greatest in hippocampal regions where the percentage of significantly tuned neurons (4.4%, near chance level of 2.3%) reduced more than fourfold compared to the continuous movie (17.8%, after accounting for the lesser number of trials, see <italic>Methods</italic>). This was unlike visual areas where the scrambled (80.4%) and the continuous movie (92.4%) generated similar prevalence levels of selectivity (<xref ref-type="fig" rid="fig4">Figure 4b</xref>). The few hippocampal cells which had significant selectivity to the scrambled sequence, did not have long-duration responses, but only very short, ~50-ms long responses (<xref ref-type="fig" rid="fig4">Figure 4d</xref>), reminiscent of, but even sharper than human hippocampal responses to flashed images (<xref ref-type="bibr" rid="bib75">Quiroga et al., 2005</xref>). To estimate the effect of continuous movie compared to the scrambled sequence on individual cells, we computed the normalized difference between the continuous and scrambled movie selectivity for cells which were selective in either condition (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, see <italic>Methods</italic>). This visual continuity index was more than eightfold higher in hippocampal areas (median values across all four hippocampal regions = 87.8%) compared to the visual areas (median = 10.6% across visual regions).</p><p>The pattern of increasing visual continuity index as we moved up the visual hierarchy, largely paralleled the anatomic organization (<xref ref-type="bibr" rid="bib20">Felleman and Van Essen, 1991</xref>), with the greatest sensitivity to visual continuity in the hippocampal output regions, CA1 and subiculum, but there were notable exceptions. The primary visual cortical neurons showed the least reduction in selectivity due to the loss of temporally contiguous content, whereas LGN neurons, the primary source of input to the visual cortex and closer to the periphery, showed far greater sensitivity (<xref ref-type="fig" rid="fig4">Figure 4c</xref>).</p><p>Many visual cortical neurons were significantly modulated by the scrambled sequence, but their number of movie-fields per cell was greater and their duration was shorter than during the continuous movie (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref> and <xref ref-type="fig" rid="fig4s2">2</xref>). This could occur due to the loss of F2F correlation in the scrambled sequence. The average activity of the neural population in V1 and AM–PM showed significant deviation even with the scrambled movie, comparable to the continuous movie, but this multi-unit ensemble response was uncorrelated with the F2F correlation in the scrambled sequence (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). A substantial fraction of visual cortical and LGN responses to the scrambled sequence could be rearranged to resemble continuous movie responses (<xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>, see <italic>Methods</italic>). The latency needed to shift the responses was least in LGN and largest in AM–PM, as expected from the feed-forward anatomy of visual information processing (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>; <xref ref-type="bibr" rid="bib20">Felleman and Van Essen, 1991</xref>; <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>). Unlike visual areas, such rearrangement did not resemble the continuous movie responses in the hippocampal regions (example cells in <xref ref-type="fig" rid="fig4">Figure 4e</xref>, also see <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref> for statistics and details). Furthermore, even after rearranging the hippocampal responses, their selectivity to the scrambled movie presentation remained near chance levels (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>).</p><p>Population vector decoding of the ensemble of a few hundred place cells is sufficient to decode the rat’s position using place cells (<xref ref-type="bibr" rid="bib103">Wilson and McNaughton, 1993</xref>), and the position of a passively moving object (<xref ref-type="bibr" rid="bib72">Purandare et al., 2022</xref>). Using similar methods, we decoded the movie frame number (see <italic>Methods</italic>). Continuous movie decoding was better than chance in all brain regions analyzed (<xref ref-type="fig" rid="fig4">Figure 4f</xref>). Upon accounting for the number of tuned neurons from different brain regions, the decoding was most accurate in V1, and least in DG. Scrambled movie decoding was significantly weaker yet above chance level (based on shuffles, see <italic>Methods</italic>) in visual areas, but not in CA3 and DG. But CA1 and subiculum neuronal ensembles could be used to decode scrambled movie frame number slightly above chance levels (<xref ref-type="fig" rid="fig4">Figure 4g</xref>). Similarly, the population overlap between even and odd trials for the scrambled sequence was strong for visual areas, and weaker in hippocampal regions, but significantly greater than untuned neurons in hippocampal regions (<xref ref-type="fig" rid="fig4s6">Figure 4—figure supplement 6</xref>). Combined with the handful of neurons in hippocampus whose movie selectivity persisted to the scrambled presentation, this suggests that loss of correlations between adjacent frames in the scrambled sequence abolishes most, but not all of the hippocampal selectivity to visual sequences.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Movie tuning in the visual areas</title><p>To understand how neurons encode a continuously unfolding visual episode, we investigated the neural responses in the head-fixed mouse brain to an isoluminant, black-and-white, silent human movie, without any task demands or rewards. As expected, neural activity showed significant modulation in all thalamo-cortical visual areas, with elevated activity in response to specific parts of the movie, termed movie-fields. Most (96.6%, 6554/6785) of thalamo-cortical neurons showed significant movie tuning. This is nearly double that reported for the classic stimuli such as Gabor patches in the same dataset (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>), although a direct comparison is difficult due to the differences in experimental and analysis methods. For example, the classic stimuli were presented for 250 ms, preceded by a blank background whereas the images changed every 30 ms in a movie. On the other hand, significant tuning of the vast majority of visual neurons to movies is consistent with other reports (<xref ref-type="bibr" rid="bib14">de Vries et al., 2020</xref>; <xref ref-type="bibr" rid="bib107">Yen et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Herikstad et al., 2011</xref>; <xref ref-type="bibr" rid="bib25">Froudarakis et al., 2014</xref>; <xref ref-type="bibr" rid="bib104">Xia et al., 2021</xref>; <xref ref-type="bibr" rid="bib15">Dyballa et al., 2018</xref>; <xref ref-type="bibr" rid="bib12">Deitch et al., 2021</xref>; <xref ref-type="bibr" rid="bib85">Sadeh and Clopath, 2022</xref>). Thus, movies are a reliable method to probe the function of the visual brain and its role in cognition.</p></sec><sec id="s3-2"><title>Movie tuning in hippocampal areas</title><p>Remarkably, a third of hippocampal neurons (32.9%, 3379/10,263) were also movie tuned, comparable to the fraction of neurons with significant spatial selectivity in mice (<xref ref-type="bibr" rid="bib40">Jun et al., 2020</xref>) and bats (<xref ref-type="bibr" rid="bib106">Yartsev et al., 2011</xref>), and far greater than significant place cells in the primate hippocampus (<xref ref-type="bibr" rid="bib80">Rolls and O’Mara, 1995</xref>; <xref ref-type="bibr" rid="bib81">Rolls, 2023</xref>; <xref ref-type="bibr" rid="bib49">Mao et al., 2021</xref>). While the hippocampus is implicated in episodic memory (<xref ref-type="bibr" rid="bib98">Vargha-Khadem et al., 1997</xref>), rodent hippocampal responses are largely studied in the context of spatial maps or place cells (<xref ref-type="bibr" rid="bib67">O’Keefe and Nadel, 1978</xref>) , and more recently in other tasks which requires active locomotion or active engagement (<xref ref-type="bibr" rid="bib3">Aronov et al., 2017</xref>; <xref ref-type="bibr" rid="bib10">Danjo et al., 2018</xref>). However, unlike place cells (<xref ref-type="bibr" rid="bib7">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Foster et al., 1989</xref>), movie tuning remained intact during immobility in all brain areas studied, which could be because self-motion causes consistent changes in multisensory cues during spatial exploration but not during movie presentation. This dissociation of the effect of mobility on spatial and movie selectivity agrees with the recent reports of dissociated mechanisms of episodic encoding and spatial navigation in human amnesia (<xref ref-type="bibr" rid="bib51">McAvan et al., 2022</xref>). Our results are broadly consistent with prior studies that found movie selectivity in human hippocampal single neurons (<xref ref-type="bibr" rid="bib27">Gelbard-Sagiv et al., 2008</xref>). However, that study relied on famous, very familiar movie clips, similar to the highly familiar image selectivity (<xref ref-type="bibr" rid="bib75">Quiroga et al., 2005</xref>) to probe episodic memory recall. In contrast, mice in our study had seen this black-and-white, human movie clip only in two prior habituation sessions and it is very unlikely that they understood the episodic content of the movie. Recent studies found human hippocampal activation in response to abrupt changes between different movie clips (<xref ref-type="bibr" rid="bib108">Zheng et al., 2022</xref>; <xref ref-type="bibr" rid="bib9">Cohn-Sheehy et al., 2021</xref>; <xref ref-type="bibr" rid="bib77">Reagh and Ranganath, 2023</xref>), which is broadly consistent with our findings. Future studies can investigate the nature of hippocampal activation in mice in response to familiar movies to probe episodic memory and recall. These observations support the hypothesis that specific visual cues can create reliable representations in all parts of hippocampus in rodents (<xref ref-type="bibr" rid="bib7">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib1">Acharya et al., 2016</xref>; <xref ref-type="bibr" rid="bib72">Purandare et al., 2022</xref>), nonhuman primates (<xref ref-type="bibr" rid="bib80">Rolls and O’Mara, 1995</xref>; <xref ref-type="bibr" rid="bib49">Mao et al., 2021</xref>), and humans (<xref ref-type="bibr" rid="bib39">Jacobs et al., 2010</xref>; <xref ref-type="bibr" rid="bib16">Ekstrom et al., 2003</xref>), unlike spatial selectivity which requires consistent information from multisensory cues (<xref ref-type="bibr" rid="bib59">Moore et al., 2021</xref>; <xref ref-type="bibr" rid="bib2">Aghajan et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Ravassard et al., 2013</xref>).</p></sec><sec id="s3-3"><title>Mega-scale nature of movie-fields</title><p>Across all brain regions, neurons showed a mega-scale encoding by movie-fields varying in duration by up to 1000-fold, similar to, but far greater than recent reports of 10-fold multi-scale responses in the hippocampus (<xref ref-type="bibr" rid="bib17">Eliav et al., 2021</xref>; <xref ref-type="bibr" rid="bib44">Kjelstrup et al., 2008</xref>; <xref ref-type="bibr" rid="bib31">Harland et al., 2021</xref>; <xref ref-type="bibr" rid="bib79">Rich et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Fenton et al., 2008</xref>; <xref ref-type="bibr" rid="bib69">Park et al., 2011</xref>; <xref ref-type="bibr" rid="bib30">Harland et al., 2018</xref>). While neural selectivity to movies has been studied in visual areas, such mega-scale coding has not been reported. Remarkably, mega-scale movie-coding was found not only across the population but even individual LGN and V1 neurons could show two different movie-fields, one lasting less than 100 ms and other exceeding 10,000 ms. The speed at which visual content changed across movie frames could explain a part, but not all of this effect. The mechanisms governing the mega-scale encoding would require additional studies. For example, the average duration of the movie-field increased along the feed-forward hierarchy, consistent with the hierarchy of response lags during language processing (<xref ref-type="bibr" rid="bib6">Chang et al., 2022</xref>). Paradoxically, the mega-scale coding of movie-field meant the opposite pattern also existed, with 10-s long movie-fields in some LGN cells while less than 100 ms long movie-fields in subiculum.</p></sec><sec id="s3-4"><title>Continuous versus scrambled movie responses</title><p>The analysis of scrambled movie-sequence allowed us to compute the neural response latency to movie frames. This was highest in AM–PM (91 ms) than V1 (74 ms) and least in LGN (60 ms), thus following the visual hierarchy. The pattern of movie tuning properties was also broadly consistent between V1 and AM/PM (<xref ref-type="fig" rid="fig2">Figure 2</xref>). However, several aspects of movie tuning did not follow the feed-forward anatomical hierarchy. For example, all metrics of movie selectivity (<xref ref-type="fig" rid="fig2">Figure 2</xref>) to the continuous movie showed a pattern that was the inconsistent to the feed-forward anatomical hierarchy: V1 had stronger movie tuning, higher number of movie-fields per cell, narrower movie-field widths, larger mega-scale structure, and better decoding than LGN. V1 was also more robust to scrambled sequence than LGN. One possible explanation is that there are other sources of inputs to V1, beyond LGN, that contribute significantly to movie tuning (<xref ref-type="bibr" rid="bib96">Spacek et al., 2022</xref>). Among the hippocampal regions, the tuning properties of CA3 neurons (field durations, mega-chronicity index, visual continuity index, and several measures of population modulation) were closest to that of visual regions, even though the prevalence of tuning in CA3 was lesser than that in other hippocampal as well as visual areas.</p></sec><sec id="s3-5"><title>Emergence of episode-like movie code in hippocampus</title><p>Temporal integration window (<xref ref-type="bibr" rid="bib65">Norman-Haignere et al., 2022</xref>; <xref ref-type="bibr" rid="bib26">Gauthier et al., 2012</xref>; <xref ref-type="bibr" rid="bib32">Hasson et al., 2008</xref>) as well as intrinsic timescale of firing (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>) increase along the anatomical hierarchy in the cortex, with the hippocampus being farthest removed from the retina (<xref ref-type="bibr" rid="bib20">Felleman and Van Essen, 1991</xref>). This hierarchical anatomical organization, with visual areas being upstream of hippocampus could explain the longer movie-fields, the strength of tuning, number of movie peaks, their width, and decoding accuracy in hippocampal regions. This could also explain the several fold greater preference for the continuous movie over scrambled sequence in the hippocampus compared to the upstream visual areas. But, unlike reports of image-association memory in the inferior temporal cortex for unrelated images (<xref ref-type="bibr" rid="bib86">Sakai and Miyashita, 1991</xref>; <xref ref-type="bibr" rid="bib58">Miyashita, 1988</xref>), only a handful hippocampal neurons showed selective responses to the scrambled sequence. These results, along with the longer duration of hippocampal movie-fields could mediate visual-chunking or binding of a sequence of events. In fact, evidence for episodic-like chunking of visual information was found in all visual areas as well, where the scrambled-sequence not only reduced neural selectivity but caused fragmentation of movie-fields (<xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>).</p></sec><sec id="s3-6"><title>No evidence of nonspecific effects</title><p>Could the brain-wide mega-scale tuning be an artifact of poor unit isolation, e.g., due to an erroneous mixing of two neurons, one with very short and another with very long movie-fields? This is unlikely since the LGN and visual cortical neural selectivity to classic stimuli (Gabor patches, drifting gratings, etc.) in the same dataset was similar to that reported in most studies (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>) whereas poor unit isolation should reduce these selective responses. However, to directly test this possibility, we calculated the correlation between the unit isolation index (or fraction of refractory violations) and the mega-scale index of the cell, while factoring out the contribution of mean firing rate (<xref ref-type="fig" rid="fig1s8">Figure 1—figure supplement 8</xref>). This correlation was not significant (p &gt; 0.05) for any brain areas.</p></sec><sec id="s3-7"><title>Movie-fields versus place-fields</title><p>Do the movie-fields arise from the same mechanism as place-fields? Studies have shown that when rodents are passively moved along a linear track that they had explored (<xref ref-type="bibr" rid="bib22">Foster et al., 1989</xref>), or when the images of the environment around a linear track was played back to them (<xref ref-type="bibr" rid="bib7">Chen et al., 2013</xref>), some hippocampal neurons generated spatially selective activity. Since the movie clip involved change of spatial view, one could hypothesize that the movie-fields are just place-fields generated by passive viewing. This is unlikely for several reasons. Mega-scale movie-fields were found in the vast majority of all visual areas including LGN, far greater than spatially modulated neurons in the visual cortex during virtual navigation (<xref ref-type="bibr" rid="bib29">Haggerty and Ji, 2015</xref>; <xref ref-type="bibr" rid="bib87">Saleem et al., 2018</xref>). Furthermore, in prior passive viewing experiments, the rodents were shown the same narrow linear track, like a tunnel, that they had previously explored actively to get food rewards at specific places. In contrast, in current experiments, these mice had never actively explored the space shown in the movie, nor obtained any rewards. Active exploration of a maze, combined with spatially localized rewards engages multisensory mechanisms resulting in increased place cell activation (<xref ref-type="bibr" rid="bib53">Mehta et al., 1997</xref>; <xref ref-type="bibr" rid="bib59">Moore et al., 2021</xref>; <xref ref-type="bibr" rid="bib54">Mehta and McNaughton, 1997</xref>) which are entirely missing in these experiments during passive viewing of a movie, presented monocularly, without any other multisensory stimuli and without any rewards. Compared to their spontaneous activity, about half of CA1 and CA3 neurons shutdown during spatial exploration and this shutdown is even greater in the DG. Furthermore, compared to the exploration of a real-world maze, exploration of a visually identical virtual world causes 60% reduction in CA1 place cell activation (<xref ref-type="bibr" rid="bib76">Ravassard et al., 2013</xref>). In contrast, there was no evidence of neural shutdown during the movie presentation compared to gray screen spontaneous epochs (<xref ref-type="fig" rid="fig1s8">Figure 1—figure supplement 8</xref>). Similarly, the number of place-fields (in CA1) per cell on a long track is positively correlated with the mean firing rate of the cell (<xref ref-type="bibr" rid="bib79">Rich et al., 2014</xref>), which was not seen here for CA1 movie-fields.</p><p>A recent study showed that CA1 neurons encode the distance, angle, and movement direction of motion of a vertical bar of light (<xref ref-type="bibr" rid="bib72">Purandare et al., 2022</xref>), consistent with the position of hippocampus in the visual circuitry (<xref ref-type="bibr" rid="bib20">Felleman and Van Essen, 1991</xref>). Do those findings predict the movie tuning herein? There are indeed some similarities between the two experimental protocols – purely passive optical motion without any self-motion or rewards. However, there are significant differences too; similar to place cells in the real and virtual worlds (<xref ref-type="bibr" rid="bib2">Aghajan et al., 2015</xref>), all the cells tuned to the moving bar of light had single receptive fields with elevated responses lasting a few seconds; there were neither punctate responses nor even 10-fold variation in neural field durations, let alone the 1000-fold change reported here. Finally, those results were reported only in area CA1, while the results presented here cover nearly all the major stations of the visual hierarchy.</p><p>Notably, hippocampal neurons did not encode Gabor patches or drifting gratings in the same dataset, indicating the importance of temporally continuous sequences of images for hippocampal activation (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>). This is consistent with the hypothesis that the hippocampus is involved in coding spatial sequences (<xref ref-type="bibr" rid="bib57">Mehta, 2015</xref>; <xref ref-type="bibr" rid="bib5">Buzsáki and Tingley, 2018</xref>; <xref ref-type="bibr" rid="bib24">Foster and Knierim, 2012</xref>). However, unlike place cells that degrade in immobile rats, hippocampal movie tuning was unchanged in the immobile mouse. Furthermore, the scrambled sequence too was presented in the same sequence many times, yet movie tuning dropped to chance level in the hippocampal areas. Unlike visual areas, scrambled sequence response of hippocampal neurons could not be rearranged to obtain the continuous movie response. This shows the importance of continuous, episodic content instead of mere sequential recurrence of unrelated content for rodent hippocampal activation. We hypothesize that similar to place cells, movie-field responses without task demand would play a role, to be determined, in episodic memory. Further work involving a behavior report for the episodic content can potentially differentiate between the sequence coding described here and the contribution of episodically meaningful content. However, the nature of movie selectivity tested so far in humans was different (recall of famous, short movie clips [<xref ref-type="bibr" rid="bib27">Gelbard-Sagiv et al., 2008</xref>], or at event boundaries [<xref ref-type="bibr" rid="bib108">Zheng et al., 2022</xref>]) than in rodents here (human movie, selectivity to specific movie segments).</p></sec><sec id="s3-8"><title>Broader outlook</title><p>Our findings open up the possibility of studying thalamic, cortical, and hippocampal brain regions in a simple, passive, and purely visual experimental paradigm and extend comparable convolutional neural networks (<xref ref-type="bibr" rid="bib14">de Vries et al., 2020</xref>) to have the hippocampus at the apex (<xref ref-type="bibr" rid="bib20">Felleman and Van Essen, 1991</xref>). Furthermore, our results here bridge the long-standing gap between the hippocampal rodent and human studies (<xref ref-type="bibr" rid="bib108">Zheng et al., 2022</xref>; <xref ref-type="bibr" rid="bib84">Rutishauser et al., 2006</xref>; <xref ref-type="bibr" rid="bib94">Silson et al., 2021</xref>; <xref ref-type="bibr" rid="bib43">King et al., 2021</xref>), where natural movies can be decoded from fMRI (functional magnetic resonance imaging) signals in immobile humans (<xref ref-type="bibr" rid="bib64">Nishimoto et al., 2011</xref>). This brain-wide mega-scale encoding of a human movie episode and enhanced preference for visual continuity in the hippocampus compared to visual areas supports the hypothesis that the rodent hippocampus is involved in non-spatial episodic memories, consistent with classic findings in humans (<xref ref-type="bibr" rid="bib90">Scoville and Milber, 1957</xref>) and in agreement with a more generalized, representational framework (<xref ref-type="bibr" rid="bib62">Nadel and Peterson, 2013</xref>; <xref ref-type="bibr" rid="bib61">Nadel and Hardt, 2011</xref>) of episodic memory where it encodes temporal patterns. Similar responses are likely across different species, including primates. Thus, movie-coding can provide a unified platform to investigate the neural mechanisms of episodic coding, learning, and memory.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Experiments</title><p>We used the Allen Brain Observatory – Neuropixels Visual Coding dataset (2019 Allen Institute, <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>). This website and related publication (<xref ref-type="bibr" rid="bib93">Siegle et al., 2021</xref>) contain detailed experimental protocol, neural recording techniques, spike sorting etc. Data from 24 mice (16 males, <italic>n</italic> = 13 C57BL/6J wild-type, <italic>n</italic> = 2 Pvalb-IRES-Cre×Ai32, <italic>n</italic> = 6 Sst-IRES-Cre×Ai32, and <italic>n</italic> = 3 Vip-IRES-Cre×Ai32) from the ‘Functional connectivity’ dataset were analyzed herein. Prior to implantation with Neuropixel probes, mice passively viewed the entire range of images including drifting gratings, Gabor patches and movies of interest here. Videos of the body and eye movements were obtained at 30 Hz and synced to the neural data and stimulus presentation using a photodiode. Movies were presented monocularly on an LCD monitor with a refresh rate of 60 Hz, positioned 15 cm away from the mouse’s right eye and spanned 120<sup>o</sup> × 95<sup>o</sup>. Thirty trials of the continuous movie presentation were followed by 10 trials of the scrambled movie. Next was a presentation of drifting gratings, followed by a quiet period of 30 min where the screen was blank. Then the second block of drifting gratings, scrambled movie and continuous movie was presented. After surgery, all mice were single housed and maintained on a reverse 12 hr light cycle in a shared facility with room temperatures between 20 and 22°C and humidity between 30% and 70%. All experiments were performed during the dark cycle.</p><p>Neural spiking data were sampled at 30 kHz with a 500-Hz high pass filter. Spike sorting was automated using Kilosort2 (<xref ref-type="bibr" rid="bib97">Stringer et al., 2019</xref>). Output of Kilosort2 was post-processed to remove noise units, characterized by unphysiological waveforms. Neuropixel probes were registered to a common co-ordinate framework (<xref ref-type="bibr" rid="bib101">Wang, 2020</xref>). Each recorded unit was assigned to a recording channel corresponding to the maximum spike amplitude and then to the corresponding brain region. Broad spiking units identified as those with average spike waveform duration (peak to trough) between 0.45 and 1.5 ms and those with mean firing rates above 0.5 Hz were analyzed throughout, except <xref ref-type="fig" rid="fig1s8">Figure 1—figure supplement 8</xref>.</p></sec><sec id="s4-2"><title>Movie tuning quantification</title><p>The movie consisted of 900 frames: 30 s total, 30 Hz refresh rate, 33.3 ms per frame. At the first level of analysis, spike data were split into 900 bins, each 33.3 ms wide (the bin size was later varied systematically to detect mega-scale tuning, see below). The resulting tuning curves were smoothed with a Gaussian window of <italic>σ</italic> = 66.6 ms or two frames. The degree of modulation and its significance was estimated by the sparsity <italic>s</italic> as below, and as previously described (<xref ref-type="bibr" rid="bib72">Purandare et al., 2022</xref>; <xref ref-type="bibr" rid="bib76">Ravassard et al., 2013</xref>).<disp-formula id="equ1"><mml:math id="m1"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <italic>r<sub>n</sub></italic> is the firing rate in the <italic>n</italic>th frame or bin and <italic>N</italic> = 900 is the total number of bins. This is equivalent to ‘lifetime sparseness’, used previously (<xref ref-type="bibr" rid="bib14">de Vries et al., 2020</xref>; <xref ref-type="bibr" rid="bib100">Vinje and Gallant, 2000</xref>), except for the normalization factor of (1 − 1/<italic>N</italic>), which is close to unity, when <italic>N</italic> is close to 900 as in the case of movies. Statistical significance of sparsity was computed using a bootstrapping procedure, which does not assume a normal distribution. Briefly, for each cell, the spike train as a function of the frame number from each trial was circularly shifted by different amounts and the sparsity of the randomized data computed. This procedure was repeated 100 times with different amounts of random shifts. The mean value and standard deviation of the sparsity of randomized data were used to compute the <italic>z</italic>-scored sparsity of observed data using the function <italic>z</italic>-score in MATLAB. The observed sparsity was considered statistically significant if the <italic>z</italic>-scored sparsity of the observed spike train was greater 2, which corresponds to p &lt; 0.023 in a one-tailed <italic>t</italic>-test. A similar method was used to quantify significance of the scrambled movie tuning, as well as for the subset of data with only stationary epochs, or its equivalent subsample (see below). Middle 20 trials of the continuous movie were used in comparisons with the scrambled movie in <xref ref-type="fig" rid="fig4">Figure 4</xref>, to ensure a fair comparison by using same number of trials, with similar time delays across measurements.</p><p>In addition to sparsity, we quantified movie tuning using two other measures.</p><p>Depth of modulation = (<inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> − <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>)/(<inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> + <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), where <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the largest and lowest firing rates across movie frames, respectively.</p><p>Mutual information<disp-formula id="equ2"><mml:math id="m2"><mml:mfenced separators="|"><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mfenced close="|" separators="|"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>C</mml:mi><mml:mo>∨</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where<disp-formula id="equ3"><mml:math id="m3"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>.</mml:mo><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>and <inline-formula><mml:math id="inf7"><mml:mi>C</mml:mi></mml:math></inline-formula> is the average spike count in 0.033-s window which corresponds to 1 movie frame. <inline-formula><mml:math id="inf8"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> is 1/900, as all frames were presented equal number of times. Statistical significance of these alternative measures of selectivity was computed similar to that for sparsity and is detailed in <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref>.</p></sec><sec id="s4-3"><title>Stationary epoch and SWR-free epoch identification</title><p>To eliminate the confounding effects of changes in behavioral state associated with running, we repeated our analysis in stationary epochs, defined as epochs when the running speed remained less than 2 cm/s for this period, as well as for at least 5 s before and after this period. Analysis was further restricted to sessions with at least 5 total minutes of these epochs during the 60 trials of continuous movie presentation. To account for using lesser data of the stationary epochs, we compared the tuning using a random subsample of data, regardless of running or stopping and compared the two results for difference in selectivity.</p><p>Similarly, to remove epochs of SWRs, we first computed band passed power in the hippocampal (CA1) recording sites in the 150–250 Hz range. SWR occurrence was noted if any of the best five sites in CA1 (those with highest theta (5–12 Hz) to delta (1–4 Hz) ratio), or the median SWR across all CA1 sites exceeded their respective 3 standard deviations of power. To remove SWRs, we removed frames corresponding to ±0.5-s around the SWR occurrence and recomputed movie tuning in the remaining data. Similar to the stationary epoch calculation above, we compared tuning to an equivalent random subset to account for loss of data.</p></sec><sec id="s4-4"><title>Pupil dilation and theta power comparisons</title><p>To assess the contribution of arousal state on movie tuning, we re-calculated <italic>z</italic>-scored sparsity in epochs with high versus low pupil dilation. The pupil was tracked at a 30-Hz sampling rate, and the height and width of the elliptical fit as provided in the publicly available dataset was used. For each session, the pupil area thus calculated was split into two equal halves, by using data above and below the 50th percentile. The resultant <italic>z</italic>-scored sparsity is reported in <xref ref-type="fig" rid="fig1s7">Figure 1—figure supplement 7</xref>.</p><p>Similarly, the theta power computed from the band passed local field potential signal in the 5–12 Hz range was split into two equal data subsegments. The channel from CA1, with the highest average theta to delta (1–4 Hz) power ratio was nominated as the channel to be used for these calculations. Movie tuning in data with high and low theta power thus separated is reported in <xref ref-type="fig" rid="fig1s7">Figure 1—figure supplement 7</xref>.</p></sec><sec id="s4-5"><title>Mega-scale movie-field detection in tuned neurons</title><p>For neurons with significant movie-sparsity, i.e., movie tuned, the movie response was first recalculated at a higher resolution of 3.33 ms (10 times the frame rate of 33.3 ms). The <italic>findpeaks</italic> function in MATLAB was used to obtain peaks with <italic>prominence</italic> larger than 110% (1.1×) the range of firing variation obtained by chance, as determined from a sample shuffled response. This calculation was repeated at different smoothing values (logarithmically spaced in 10 Gaussian smoothing schemes with <italic>σ</italic> ranging from 6.7 to 3430 ms), to ensure that long as well as short movie-fields were reliably detected and treated equally. For frames where overlapping peaks were found at different smoothing levels, we employed a comparative algorithm to only select the peak(s) with higher prominence score. This score was obtained as the ratio of the peak’s prominence to the range of fluctuations in the correspondingly smoothed shuffle. This procedure was conducted iteratively, in increasing order of smoothing. If a broad peak overlapped with multiple narrow ones, the sum of scores of the narrow ones was compared with the broad one. To ensure that peaks at the beginning as well as the end of the movie frames were reliably detected, we circularly wrapped the movie response, for the observed as well as shuffle data.</p></sec><sec id="s4-6"><title>Identifying frames with significant deviations in multiple single-unit activity</title><p>First, the average response across tuned neurons for each brain region was computed for each movie frame, after normalizing the response of each cell by the peak firing response. This average response was used as the observed ‘Multiple single-unit activity (MSUA)’ in <xref ref-type="fig" rid="fig3">Figure 3</xref>. To compute chance level, individual neuron responses were circularly shifted with respect to the movie frames to break the frame to firing rate association but maintain overall firing rate modulation. 100 such shuffles were used, and for each shuffle, the shuffled MSUA response was computed by averaging across neurons. Across these 100 shuffles, mean and standard deviation was obtained for all frames, and used to compute the z-score of the observed MSUA. To obtain significance at p = 0.025 level, Bonferroni correction was applied, and the appropriate <italic>z</italic>-score (4.04) level was chosen. The number of frames in the observed MSUA above (and below) this level is further quantified in <xref ref-type="fig" rid="fig3">Figure 3</xref>. The firing deviation for these frames was computed as the ratio between the mean observed MSUA and the mean shuffled MSUA, reported as a percentage, for frames corresponding to <italic>z</italic>-score greater than +4 or less than −4. To obtain a total firing rate report, where each spike gets equal vote, we computed the total firing response by computing the total rate across all tuned neurons (and averaging by the number of neurons) in <xref ref-type="fig" rid="fig3">Figure 3</xref> and across all neurons in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>.</p></sec><sec id="s4-7"><title>Population vector overlap</title><p>To evaluate the properties of a population of cells, movie presentations were divided into alternate trials, yielding even and odd blocks (<xref ref-type="bibr" rid="bib78">Resnik et al., 2012</xref>). Population vector overlap was computed between the movie responses calculated separately for these two blocks of trials. Population vector overlap between frames <italic>x</italic> of the even trials and frame <italic>y</italic> of the odd trials was defined as the Pearson correlation coefficient between the vectors (<italic>R</italic><sub>1,</sub><italic><sub>x</sub>, R</italic><sub>2,</sub><italic><sub>x</sub></italic>, <italic>… R<sub>N</sub></italic><sub>,</sub><italic><sub>x</sub></italic>) and (<italic>R</italic><sub>1,</sub><italic><sub>y</sub></italic>, <italic>R</italic><sub>2,</sub><italic><sub>y</sub></italic>, <italic>… R</italic><sub><italic>N</italic>,</sub><italic><sub>y</sub></italic>), where <italic>R<sub>n</sub></italic><sub>,</sub><italic><sub>x</sub></italic> is the mean firing rate response of the <italic>n</italic>th neuron to the <italic>x</italic>th movie frame. <italic>N</italic> is the total number of neurons used, for each brain region. This calculation was done for <italic>x</italic> and <italic>y</italic> ranging from 1 to 900, corresponding to the 900 movie frames. The same method was used for tuned and untuned neurons in continuous movie responses in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, and for scrambled sequence responses in <xref ref-type="fig" rid="fig4s6">Figure 4—figure supplement 6</xref>.</p></sec><sec id="s4-8"><title>Decoding analysis</title><p>Methods similar to those previously described were used (<xref ref-type="bibr" rid="bib72">Purandare et al., 2022</xref>; <xref ref-type="bibr" rid="bib103">Wilson and McNaughton, 1993</xref>). For tuned cells, the 60 trials of continuous movie were each decoded using all other trials. Mean firing rate responses in the 59 trials for 900 frames were used to compute a ‘look-up’ matrix. Each neuron’s response was normalized between 0 and 1. At each frame in the ‘observed’ trial, the correlation coefficient was computed between the population vector response in this trial and the look-up matrix. The frame corresponding to the maximal correlation was denoted as the decoded frame. Decoding error was computed as the average of the absolute difference between actual and decoded frames, across the 900 frames of the movie. For comparison, shuffle data were generated by randomly shuffling the cell–cell pairing of the look-up matrix and ‘observed response’. To enable a fair comparison of decoding accuracy across brain regions, the tuned cells from each brain region were subsampled, and a random selection of 150 cells was used. A similar procedure was used for the 20 trials of the scrambled sequence, and the corresponding middle 20 trials of the continuous movie were used here for comparison.</p></sec><sec id="s4-9"><title>Rearranged scrambled movie analysis</title><p>To differentiate the effects of visual content versus visual continuity between consecutive frames, we compared the responses of the same neuron to the continuous movie and the scrambled sequence. In the scrambled movie, the same visual frames as the continuous movie were used, but they were shuffled in a pseudo random fashion. The same scrambled sequence was repeated for 20 trials. The neural response was first computed at each frame of the scrambled sequence, keeping the frames in the chronological order of presentation. Then the scrambled sequence of frames was rearranged to recreate the continuous movie and the corresponding neural responses computed. To address the latency between movie frame presentation and its evoked neural response, which can differ across brain regions and neurons, this calculation was repeated for rearranged scrambled sequences with variable delays between <italic>τ</italic> = −500 to +500 ms (i.e., −150 to +150 frames of 3.33 ms resolution, in steps of five frames or 16.6 ms). The correlation coefficient was computed between the continuous movie response and this variable delayed response at each delay as <italic>r</italic><sub>measured</sub>(<italic>τ</italic>) = corrcoef(<italic>R</italic><sub>continuous</sub>, <italic>R</italic><sub>scramble-rearranged</sub>(<italic>τ</italic>)). <italic>R</italic><sub>continuous</sub> is the continuous movie response, obtained at 3.33-ms resolution and similarly, <italic>R</italic><sub>scramble-rearranged</sub> corresponds to the scrambled response after rearrangement, at the latency <italic>τ</italic>. The latency <italic>τ</italic> yielding the largest correlation between the continuous and rearranged scrambled movie was designated as the putative response latency for that neuron. This was used in <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>. The value of <italic>r</italic><sub>measured</sub>(<italic>τ</italic><sub>max</sub>) was bootstrapped using 100 randomly generated frame reassignments, and this was used to <italic>z</italic>-score <italic>r</italic><sub>measured</sub>(<italic>τ</italic><sub>max</sub>), with <italic>z</italic>-score &gt;2 as criterion for significance. The resultant <italic>z</italic>-score is reported in <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>.</p><p>The latency <italic>τ</italic> was rounded off for use with 33 ms bins and used to rearrange actual as well as shuffled data to compute the strength of tuning for scrambled presentation. <italic>Z</italic>-scored sparsity was computed as described above. This was compared with the <italic>z</italic>-scored sparsity of continuous movie as well as the scrambled movie data, without the rearrangement, and shown in <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>.</p></sec><sec id="s4-10"><title>Code availability</title><p>All analyses were performed using custom-written code in MATLAB version R2020a. Codes written for analysis and visualization are available on GitHub, at <ext-link ext-link-type="uri" xlink:href="https://github.com/cspurandare/ELife_MovieTuning">https://github.com/cspurandare/ELife_MovieTuning</ext-link> (<xref ref-type="bibr" rid="bib73">Purandare, 2023a</xref>, copy archived at <xref ref-type="bibr" rid="bib74">Purandare, 2023b</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>No human subjects involved.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-85069-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data are publicly available at the Allen Brain Observatory - Neuropixels Visual Coding dataset (2019 Allen Institute, <ext-link ext-link-type="uri" xlink:href="https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels">https://portal.brain-map.org/explore/circuits/visual-coding-neuropixels</ext-link>).</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Durand</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Neuropixel</data-title><source>Registry of Open Data on AWS</source><pub-id pub-id-type="accession" xlink:href="https://registry.opendata.aws/allen-brain-observatory">allen-brain-observatory</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank the Allen Brain Institute for provision of the dataset, Dr. Josh Siegle for help with the dataset, Dr. Krishna Choudhary for proof-reading of the text, and Dr. Massimo Scanziani for input and feedback. This work was supported by grants to MRM by the National Institutes of Health NIH 1U01MH115746.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acharya</surname><given-names>L</given-names></name><name><surname>Aghajan</surname><given-names>ZM</given-names></name><name><surname>Vuong</surname><given-names>C</given-names></name><name><surname>Moore</surname><given-names>JJ</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Causal influence of visual cues on hippocampal directional selectivity</article-title><source>Cell</source><volume>164</volume><fpage>197</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.12.015</pub-id><pub-id pub-id-type="pmid">26709045</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aghajan</surname><given-names>ZM</given-names></name><name><surname>Acharya</surname><given-names>L</given-names></name><name><surname>Moore</surname><given-names>JJ</given-names></name><name><surname>Cushman</surname><given-names>JD</given-names></name><name><surname>Vuong</surname><given-names>C</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Impaired spatial selectivity and intact phase precession in two-dimensional virtual reality</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>121</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1038/nn.3884</pub-id><pub-id pub-id-type="pmid">25420065</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Nevers</surname><given-names>R</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mapping of a non-spatial dimension by the hippocampal-entorhinal circuit</article-title><source>Nature</source><volume>543</volume><fpage>719</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1038/nature21692</pub-id><pub-id pub-id-type="pmid">28358077</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Memory, navigation and theta rhythm in the hippocampal-entorhinal system</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>130</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nn.3304</pub-id><pub-id pub-id-type="pmid">23354386</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Tingley</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Space and time: the hippocampus as a sequence generator</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>853</fpage><lpage>869</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.07.006</pub-id><pub-id pub-id-type="pmid">30266146</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CHC</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Information flow across the cortical timescale hierarchy during narrative construction</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2209307119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2209307119</pub-id><pub-id pub-id-type="pmid">36508677</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>King</surname><given-names>JA</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How vision and movement combine in the hippocampal place code</article-title><source>PNAS</source><volume>110</volume><fpage>378</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215834110</pub-id><pub-id pub-id-type="pmid">23256159</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>AJ</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Reduced neural activity but improved coding in rodent higher-order visual cortex during locomotion</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>1676</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-29200-z</pub-id><pub-id pub-id-type="pmid">35354804</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohn-Sheehy</surname><given-names>BI</given-names></name><name><surname>Delarazan</surname><given-names>AI</given-names></name><name><surname>Reagh</surname><given-names>ZM</given-names></name><name><surname>Crivelli-Decker</surname><given-names>JE</given-names></name><name><surname>Kim</surname><given-names>K</given-names></name><name><surname>Barnett</surname><given-names>AJ</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The hippocampus constructs narrative memories across distant events</article-title><source>Current Biology</source><volume>31</volume><fpage>4935</fpage><lpage>4945</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.09.013</pub-id><pub-id pub-id-type="pmid">34592172</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danjo</surname><given-names>T</given-names></name><name><surname>Toyoizumi</surname><given-names>T</given-names></name><name><surname>Fujisawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spatial representations of self and other in the hippocampus</article-title><source>Science</source><volume>359</volume><fpage>213</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1126/science.aao3898</pub-id><pub-id pub-id-type="pmid">29326273</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>David</surname><given-names>SV</given-names></name><name><surname>Vinje</surname><given-names>WE</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Natural stimulus statistics alter the receptive field structure of v1 neurons</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>6991</fpage><lpage>7006</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1422-04.2004</pub-id><pub-id pub-id-type="pmid">15295035</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deitch</surname><given-names>D</given-names></name><name><surname>Rubin</surname><given-names>A</given-names></name><name><surname>Ziv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Representational drift in the mouse visual cortex</article-title><source>Current Biology</source><volume>31</volume><fpage>4327</fpage><lpage>4339</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.07.062</pub-id><pub-id pub-id-type="pmid">34433077</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Valois</surname><given-names>RL</given-names></name><name><surname>Yund</surname><given-names>EW</given-names></name><name><surname>Hepler</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>The orientation and direction selectivity of cells in macaque visual cortex</article-title><source>Vision Research</source><volume>22</volume><fpage>531</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(82)90112-2</pub-id><pub-id pub-id-type="pmid">7112953</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vries</surname><given-names>SEJ</given-names></name><name><surname>Lecoq</surname><given-names>JA</given-names></name><name><surname>Buice</surname><given-names>MA</given-names></name><name><surname>Groblewski</surname><given-names>PA</given-names></name><name><surname>Ocker</surname><given-names>GK</given-names></name><name><surname>Oliver</surname><given-names>M</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Cain</surname><given-names>N</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Millman</surname><given-names>D</given-names></name><name><surname>Roll</surname><given-names>K</given-names></name><name><surname>Garrett</surname><given-names>M</given-names></name><name><surname>Keenan</surname><given-names>T</given-names></name><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Olsen</surname><given-names>S</given-names></name><name><surname>Thompson</surname><given-names>C</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Waters</surname><given-names>J</given-names></name><name><surname>Williams</surname><given-names>D</given-names></name><name><surname>Barber</surname><given-names>C</given-names></name><name><surname>Berbesque</surname><given-names>N</given-names></name><name><surname>Blanchard</surname><given-names>B</given-names></name><name><surname>Bowles</surname><given-names>N</given-names></name><name><surname>Caldejon</surname><given-names>SD</given-names></name><name><surname>Casal</surname><given-names>L</given-names></name><name><surname>Cho</surname><given-names>A</given-names></name><name><surname>Cross</surname><given-names>S</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Dolbeare</surname><given-names>T</given-names></name><name><surname>Edwards</surname><given-names>M</given-names></name><name><surname>Galbraith</surname><given-names>J</given-names></name><name><surname>Gaudreault</surname><given-names>N</given-names></name><name><surname>Gilbert</surname><given-names>TL</given-names></name><name><surname>Griffin</surname><given-names>F</given-names></name><name><surname>Hargrave</surname><given-names>P</given-names></name><name><surname>Howard</surname><given-names>R</given-names></name><name><surname>Huang</surname><given-names>L</given-names></name><name><surname>Jewell</surname><given-names>S</given-names></name><name><surname>Keller</surname><given-names>N</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Larkin</surname><given-names>JD</given-names></name><name><surname>Larsen</surname><given-names>R</given-names></name><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Lee</surname><given-names>E</given-names></name><name><surname>Lee</surname><given-names>F</given-names></name><name><surname>Leon</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Long</surname><given-names>F</given-names></name><name><surname>Luviano</surname><given-names>J</given-names></name><name><surname>Mace</surname><given-names>K</given-names></name><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>Perkins</surname><given-names>J</given-names></name><name><surname>Robertson</surname><given-names>M</given-names></name><name><surname>Seid</surname><given-names>S</given-names></name><name><surname>Shea-Brown</surname><given-names>E</given-names></name><name><surname>Shi</surname><given-names>J</given-names></name><name><surname>Sjoquist</surname><given-names>N</given-names></name><name><surname>Slaughterbeck</surname><given-names>C</given-names></name><name><surname>Sullivan</surname><given-names>D</given-names></name><name><surname>Valenza</surname><given-names>R</given-names></name><name><surname>White</surname><given-names>C</given-names></name><name><surname>Williford</surname><given-names>A</given-names></name><name><surname>Witten</surname><given-names>DM</given-names></name><name><surname>Zhuang</surname><given-names>J</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Farrell</surname><given-names>C</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A large-scale standardized physiological survey reveals functional organization of the mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>138</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0550-9</pub-id><pub-id pub-id-type="pmid">31844315</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dyballa</surname><given-names>L</given-names></name><name><surname>Hoseini</surname><given-names>MS</given-names></name><name><surname>Dadarlat</surname><given-names>MC</given-names></name><name><surname>Zucker</surname><given-names>SW</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Flow stimuli reveal ecologically appropriate responses in mouse visual cortex</article-title><source>PNAS</source><volume>115</volume><fpage>11304</fpage><lpage>11309</lpage><pub-id pub-id-type="doi">10.1073/pnas.1811265115</pub-id><pub-id pub-id-type="pmid">30327345</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name><name><surname>Caplan</surname><given-names>JB</given-names></name><name><surname>Fields</surname><given-names>TA</given-names></name><name><surname>Isham</surname><given-names>EA</given-names></name><name><surname>Newman</surname><given-names>EL</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Cellular networks underlying human spatial navigation</article-title><source>Nature</source><volume>425</volume><fpage>184</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1038/nature01964</pub-id><pub-id pub-id-type="pmid">12968182</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eliav</surname><given-names>T</given-names></name><name><surname>Maimon</surname><given-names>SR</given-names></name><name><surname>Aljadeff</surname><given-names>J</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Ginosar</surname><given-names>G</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Multiscale representation of very large environments in the hippocampus of flying bats</article-title><source>Science</source><volume>372</volume><elocation-id>eabg4020</elocation-id><pub-id pub-id-type="doi">10.1126/science.abg4020</pub-id><pub-id pub-id-type="pmid">34045327</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erisken</surname><given-names>S</given-names></name><name><surname>Vaiceliunaite</surname><given-names>A</given-names></name><name><surname>Jurjut</surname><given-names>O</given-names></name><name><surname>Fiorini</surname><given-names>M</given-names></name><name><surname>Katzner</surname><given-names>S</given-names></name><name><surname>Busse</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Effects of locomotion extend throughout the mouse early visual system</article-title><source>Current Biology</source><volume>24</volume><fpage>2899</fpage><lpage>2907</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.10.045</pub-id><pub-id pub-id-type="pmid">25484299</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fekete</surname><given-names>T</given-names></name><name><surname>Pitowsky</surname><given-names>I</given-names></name><name><surname>Grinvald</surname><given-names>A</given-names></name><name><surname>Omer</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Arousal increases the representational capacity of cortical tissue</article-title><source>Journal of Computational Neuroscience</source><volume>27</volume><fpage>211</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1007/s10827-009-0138-6</pub-id><pub-id pub-id-type="pmid">19326198</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname><given-names>DJ</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title><source>Cerebral Cortex</source><volume>1</volume><fpage>1</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1093/cercor/1.1.1-a</pub-id><pub-id pub-id-type="pmid">1822724</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fenton</surname><given-names>AA</given-names></name><name><surname>Kao</surname><given-names>HY</given-names></name><name><surname>Neymotin</surname><given-names>SA</given-names></name><name><surname>Olypher</surname><given-names>A</given-names></name><name><surname>Vayntrub</surname><given-names>Y</given-names></name><name><surname>Lytton</surname><given-names>WW</given-names></name><name><surname>Ludvig</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Unmasking the CA1 ensemble place code by exposures to small and large environments: more place cells and multiple, irregularly arranged, and expanded place fields in the larger space</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>11250</fpage><lpage>11262</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2862-08.2008</pub-id><pub-id pub-id-type="pmid">18971467</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>TC</given-names></name><name><surname>Castro</surname><given-names>CA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Spatial selectivity of rat hippocampal neurons: dependence on preparedness for movement</article-title><source>Science</source><volume>244</volume><fpage>1580</fpage><lpage>1582</lpage><pub-id pub-id-type="doi">10.1126/science.2740902</pub-id><pub-id pub-id-type="pmid">2740902</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal theta sequences</article-title><source>Hippocampus</source><volume>17</volume><fpage>1093</fpage><lpage>1099</lpage><pub-id pub-id-type="doi">10.1002/hipo.20345</pub-id><pub-id pub-id-type="pmid">17663452</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sequence learning and the role of the hippocampus in rodent navigation</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>294</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2011.12.005</pub-id><pub-id pub-id-type="pmid">22226994</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Froudarakis</surname><given-names>E</given-names></name><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Cotton</surname><given-names>RJ</given-names></name><name><surname>Sinz</surname><given-names>FH</given-names></name><name><surname>Yatsenko</surname><given-names>D</given-names></name><name><surname>Saggau</surname><given-names>P</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Population code in mouse V1 facilitates readout of natural scenes through increased sparseness</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>851</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1038/nn.3707</pub-id><pub-id pub-id-type="pmid">24747577</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gauthier</surname><given-names>B</given-names></name><name><surname>Eger</surname><given-names>E</given-names></name><name><surname>Hesselmann</surname><given-names>G</given-names></name><name><surname>Giraud</surname><given-names>AL</given-names></name><name><surname>Kleinschmidt</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Temporal tuning properties along the human ventral visual stream</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>14433</fpage><lpage>14441</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2467-12.2012</pub-id><pub-id pub-id-type="pmid">23055513</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gelbard-Sagiv</surname><given-names>H</given-names></name><name><surname>Mukamel</surname><given-names>R</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internally generated reactivation of single neurons in human hippocampus during free recall</article-title><source>Science</source><volume>322</volume><fpage>96</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1126/science.1164685</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Góis</surname><given-names>ZHTD</given-names></name><name><surname>Tort</surname><given-names>ABL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Characterizing speed cells in the rat hippocampus</article-title><source>Cell Reports</source><volume>25</volume><fpage>1872</fpage><lpage>1884</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.10.054</pub-id><pub-id pub-id-type="pmid">30428354</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haggerty</surname><given-names>DC</given-names></name><name><surname>Ji</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Activities of visual cortical and hippocampal neurons co-fluctuate in freely moving rats during spatial behavior</article-title><source>eLife</source><volume>4</volume><elocation-id>e08902</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08902</pub-id><pub-id pub-id-type="pmid">26349031</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harland</surname><given-names>B</given-names></name><name><surname>Contreras</surname><given-names>M</given-names></name><name><surname>Fellous</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A role for the longitudinal axis of the hippocampus in multiscale representations of large and complex spatial environments and mnemonic hierarchies</article-title><source>The Hippocampus - Plasticity and Functions</source><elocation-id>68877</elocation-id><pub-id pub-id-type="doi">10.5772/intechopen.68877</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harland</surname><given-names>B</given-names></name><name><surname>Contreras</surname><given-names>M</given-names></name><name><surname>Souder</surname><given-names>M</given-names></name><name><surname>Fellous</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dorsal CA1 hippocampal place cells form a multi-scale representation of megaspace</article-title><source>Current Biology</source><volume>31</volume><fpage>2178</fpage><lpage>2190</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.03.003</pub-id><pub-id pub-id-type="pmid">33770492</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A hierarchy of temporal receptive windows in human cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>2539</fpage><lpage>2550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5487-07.2008</pub-id><pub-id pub-id-type="pmid">18322098</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herikstad</surname><given-names>R</given-names></name><name><surname>Baker</surname><given-names>J</given-names></name><name><surname>Lachaux</surname><given-names>JP</given-names></name><name><surname>Gray</surname><given-names>CM</given-names></name><name><surname>Yen</surname><given-names>SC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Natural movies evoke spike trains with low spike time variability in cat primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>15844</fpage><lpage>15860</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5153-10.2011</pub-id><pub-id pub-id-type="pmid">22049428</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>DN</given-names></name><name><surname>Mehta</surname><given-names>SB</given-names></name><name><surname>Kleinfeld</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Quality metrics to accompany spike sorting of extracellular signals</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>8699</fpage><lpage>8705</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0971-11.2011</pub-id><pub-id pub-id-type="pmid">21677152</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoseini</surname><given-names>MS</given-names></name><name><surname>Wright</surname><given-names>NC</given-names></name><name><surname>Xia</surname><given-names>J</given-names></name><name><surname>Clawson</surname><given-names>W</given-names></name><name><surname>Shew</surname><given-names>W</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dynamics and sources of response variability and its coordination in visual cortex</article-title><source>Visual Neuroscience</source><volume>36</volume><elocation-id>E012</elocation-id><pub-id pub-id-type="doi">10.1017/S0952523819000117</pub-id><pub-id pub-id-type="pmid">31840629</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Receptive fields of single neurones in the cat’s striate cortex</article-title><source>The Journal of Physiology</source><volume>148</volume><fpage>574</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1959.sp006308</pub-id><pub-id pub-id-type="pmid">14403679</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huxter</surname><given-names>JR</given-names></name><name><surname>Senior</surname><given-names>TJ</given-names></name><name><surname>Allen</surname><given-names>K</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Theta phase-specific codes for two-dimensional position, trajectory and heading in the hippocampus</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>587</fpage><lpage>594</lpage><pub-id pub-id-type="doi">10.1038/nn.2106</pub-id><pub-id pub-id-type="pmid">18425124</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ikegaya</surname><given-names>Y</given-names></name><name><surname>Aaron</surname><given-names>G</given-names></name><name><surname>Cossart</surname><given-names>R</given-names></name><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Lampl</surname><given-names>I</given-names></name><name><surname>Ferster</surname><given-names>D</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Synfire chains and cortical songs: temporal modules of cortical activity</article-title><source>Science</source><volume>304</volume><fpage>559</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1126/science.1093173</pub-id><pub-id pub-id-type="pmid">15105494</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>J</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Mollison</surname><given-names>MV</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A sense of direction in human entorhinal cortex</article-title><source>PNAS</source><volume>107</volume><fpage>6487</fpage><lpage>6492</lpage><pub-id pub-id-type="doi">10.1073/pnas.0911213107</pub-id><pub-id pub-id-type="pmid">20308554</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>H</given-names></name><name><surname>Bramian</surname><given-names>A</given-names></name><name><surname>Soma</surname><given-names>S</given-names></name><name><surname>Saito</surname><given-names>T</given-names></name><name><surname>Saido</surname><given-names>TC</given-names></name><name><surname>Igarashi</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Disrupted place cell remapping and impaired grid cells in a knockin model of alzheimer’s disease</article-title><source>Neuron</source><volume>107</volume><fpage>1095</fpage><lpage>1112</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.06.023</pub-id><pub-id pub-id-type="pmid">32697942</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Spatial selectivity of unit activity in the hippocampal granular layer</article-title><source>Hippocampus</source><volume>3</volume><fpage>165</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1002/hipo.450030209</pub-id><pub-id pub-id-type="pmid">8353604</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kampa</surname><given-names>BM</given-names></name><name><surname>Roth</surname><given-names>MM</given-names></name><name><surname>Göbel</surname><given-names>W</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Representation of visual scenes by local neuronal populations in layer 2/3 of mouse visual cortex</article-title><source>Frontiers in Neural Circuits</source><volume>5</volume><elocation-id>18</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2011.00018</pub-id><pub-id pub-id-type="pmid">22180739</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>JR</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>King</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The Human Brain Encodes a Chronicle of Visual Events at Each Instant of Time Through the Multiplexing of Traveling Waves</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>7224</fpage><lpage>7233</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2098-20.2021</pub-id><pub-id pub-id-type="pmid">33811150</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kjelstrup</surname><given-names>KB</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Brun</surname><given-names>VH</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Finite scale of spatial representation in the hippocampus</article-title><source>Science</source><volume>321</volume><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1126/science.1157086</pub-id><pub-id pub-id-type="pmid">18599792</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraus</surname><given-names>BJ</given-names></name><name><surname>Robinson</surname><given-names>RJ</given-names></name><name><surname>White</surname><given-names>JA</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal “time cells”: time versus path integration</article-title><source>Neuron</source><volume>78</volume><fpage>1090</fpage><lpage>1101</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.04.015</pub-id><pub-id pub-id-type="pmid">23707613</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraus</surname><given-names>BJ</given-names></name><name><surname>Brandon</surname><given-names>MP</given-names></name><name><surname>Robinson</surname><given-names>RJ</given-names></name><name><surname>Connerney</surname><given-names>MA</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>During running in place, grid cells integrate elapsed time and distance run</article-title><source>Neuron</source><volume>88</volume><fpage>578</fpage><lpage>589</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.031</pub-id><pub-id pub-id-type="pmid">26539893</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AM</given-names></name><name><surname>Hoy</surname><given-names>JL</given-names></name><name><surname>Bonci</surname><given-names>A</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name><name><surname>Niell</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Identification of a brainstem circuit regulating visual cortical state in parallel with locomotion</article-title><source>Neuron</source><volume>83</volume><fpage>455</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.06.031</pub-id><pub-id pub-id-type="pmid">25033185</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacDonald</surname><given-names>CJ</given-names></name><name><surname>Lepage</surname><given-names>KQ</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal “time cells” bridge the gap in memory for discontiguous events</article-title><source>Neuron</source><volume>71</volume><fpage>737</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.012</pub-id><pub-id pub-id-type="pmid">21867888</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>D</given-names></name><name><surname>Avila</surname><given-names>E</given-names></name><name><surname>Caziot</surname><given-names>B</given-names></name><name><surname>Laurens</surname><given-names>J</given-names></name><name><surname>Dickman</surname><given-names>JD</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Spatial modulation of hippocampal activity in freely moving macaques</article-title><source>Neuron</source><volume>109</volume><fpage>3521</fpage><lpage>3534</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.032</pub-id><pub-id pub-id-type="pmid">34644546</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mau</surname><given-names>W</given-names></name><name><surname>Sullivan</surname><given-names>DW</given-names></name><name><surname>Kinsky</surname><given-names>NR</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Same Hippocampal CA1 Population Simultaneously Codes Temporal Information over Multiple Timescales</article-title><source>Current Biology</source><volume>28</volume><fpage>1499</fpage><lpage>1508</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.03.051</pub-id><pub-id pub-id-type="pmid">29706516</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAvan</surname><given-names>AS</given-names></name><name><surname>Wank</surname><given-names>AA</given-names></name><name><surname>Rapcsak</surname><given-names>SZ</given-names></name><name><surname>Grilli</surname><given-names>MD</given-names></name><name><surname>Ekstrom</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Largely intact memory for spatial locations during navigation in an individual with dense amnesia</article-title><source>Neuropsychologia</source><volume>170</volume><elocation-id>108225</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2022.108225</pub-id><pub-id pub-id-type="pmid">35367237</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>Gerrard</surname><given-names>JL</given-names></name><name><surname>Gothard</surname><given-names>K</given-names></name><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name><name><surname>Kudrimoti</surname><given-names>H</given-names></name><name><surname>Qin</surname><given-names>Y</given-names></name><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>Suster</surname><given-names>M</given-names></name><name><surname>Weaver</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Deciphering the hippocampal polyglot: the hippocampus as a path integration system</article-title><source>The Journal of Experimental Biology</source><volume>199</volume><fpage>173</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1242/jeb.199.1.173</pub-id><pub-id pub-id-type="pmid">8576689</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Experience-dependent, asymmetric expansion of hippocampal place fields</article-title><source>PNAS</source><volume>94</volume><fpage>8918</fpage><lpage>8921</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.16.8918</pub-id><pub-id pub-id-type="pmid">9238078</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Expansion and shift of hippocampal place fields: evidence for synaptic potentiation during behavior</article-title><source>Computational Neuroscience</source><fpage>741</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1007/978-1-4757-9800-5</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name><name><surname>Quirk</surname><given-names>MC</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Experience-dependent asymmetric shape of hippocampal receptive fields</article-title><source>Neuron</source><volume>25</volume><fpage>707</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)81072-7</pub-id><pub-id pub-id-type="pmid">10774737</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>From hippocampus to V1: Effect of LTP on spatio-temporal dynamics of receptive fields</article-title><source>Neurocomputing</source><volume>32–33</volume><fpage>905</fpage><lpage>911</lpage><pub-id pub-id-type="doi">10.1016/S0925-2312(00)00259-9</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>From synaptic plasticity to spatial maps and sequence learning</article-title><source>Hippocampus</source><volume>25</volume><fpage>756</fpage><lpage>762</lpage><pub-id pub-id-type="doi">10.1002/hipo.22472</pub-id><pub-id pub-id-type="pmid">25929239</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyashita</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Neuronal correlate of visual associative long-term memory in the primate temporal cortex</article-title><source>Nature</source><volume>335</volume><fpage>817</fpage><lpage>820</lpage><pub-id pub-id-type="doi">10.1038/335817a0</pub-id><pub-id pub-id-type="pmid">3185711</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>JJ</given-names></name><name><surname>Cushman</surname><given-names>JD</given-names></name><name><surname>Acharya</surname><given-names>L</given-names></name><name><surname>Popeney</surname><given-names>B</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Linking hippocampal multiplexed tuning, hebbian plasticity and navigation</article-title><source>Nature</source><volume>599</volume><fpage>442</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03989-z</pub-id><pub-id pub-id-type="pmid">34671157</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A quarter of A century of place cells</article-title><source>Neuron</source><volume>17</volume><fpage>813</fpage><lpage>822</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)80214-7</pub-id><pub-id pub-id-type="pmid">8938115</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadel</surname><given-names>L</given-names></name><name><surname>Hardt</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Update on memory systems and processes</article-title><source>Neuropsychopharmacology</source><volume>36</volume><fpage>251</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1038/npp.2010.169</pub-id><pub-id pub-id-type="pmid">20861829</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadel</surname><given-names>L</given-names></name><name><surname>Peterson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The hippocampus: part of an interactive posterior representational system spanning perceptual and memorial systems</article-title><source>Journal of Experimental Psychology. General</source><volume>142</volume><fpage>1242</fpage><lpage>1254</lpage><pub-id pub-id-type="doi">10.1037/a0033690</pub-id><pub-id pub-id-type="pmid">23895347</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nishimoto</surname><given-names>S</given-names></name><name><surname>Vu</surname><given-names>AT</given-names></name><name><surname>Naselaris</surname><given-names>T</given-names></name><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>B</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Reconstructing visual experiences from brain activity evoked by natural movies</article-title><source>Current Biology</source><volume>21</volume><fpage>1641</fpage><lpage>1646</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.08.031</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman-Haignere</surname><given-names>SV</given-names></name><name><surname>Long</surname><given-names>LK</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>Doyle</surname><given-names>W</given-names></name><name><surname>Irobunda</surname><given-names>I</given-names></name><name><surname>Merricks</surname><given-names>EM</given-names></name><name><surname>Feldstein</surname><given-names>NA</given-names></name><name><surname>McKhann</surname><given-names>GM</given-names></name><name><surname>Schevon</surname><given-names>CA</given-names></name><name><surname>Flinker</surname><given-names>A</given-names></name><name><surname>Mesgarani</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Multiscale temporal integration organizes hierarchical computation in human auditory cortex</article-title><source>Nature Human Behaviour</source><volume>6</volume><fpage>455</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1038/s41562-021-01261-y</pub-id><pub-id pub-id-type="pmid">35145280</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Dostrovsky</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>The hippocampus as a spatial map: preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><volume>34</volume><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id><pub-id pub-id-type="pmid">5124915</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The hippocampus as a cognitive map</source><publisher-name>Clarendon Press</publisher-name></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Geometric determinants of the place fields of hippocampal neurons</article-title><source>Nature</source><volume>381</volume><fpage>425</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1038/381425a0</pub-id><pub-id pub-id-type="pmid">8632799</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>E</given-names></name><name><surname>Dvorak</surname><given-names>D</given-names></name><name><surname>Fenton</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ensemble place codes in hippocampus: CA1, CA3, and dentate gyrus place cells have multiple place fields in large environments</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e22349</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0022349</pub-id><pub-id pub-id-type="pmid">21789250</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parkinson</surname><given-names>JK</given-names></name><name><surname>Murray</surname><given-names>EA</given-names></name><name><surname>Mishkin</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>A selective mnemonic role for the hippocampus in monkeys: memory for the location of objects</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>4159</fpage><lpage>4167</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-11-04159.1988</pub-id><pub-id pub-id-type="pmid">3183716</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pastalkova</surname><given-names>E</given-names></name><name><surname>Itskov</surname><given-names>V</given-names></name><name><surname>Amarasingham</surname><given-names>A</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Internally generated cell assembly sequences in the rat hippocampus</article-title><source>Science</source><volume>321</volume><fpage>1322</fpage><lpage>1327</lpage><pub-id pub-id-type="doi">10.1126/science.1159775</pub-id><pub-id pub-id-type="pmid">18772431</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purandare</surname><given-names>CS</given-names></name><name><surname>Dhingra</surname><given-names>S</given-names></name><name><surname>Rios</surname><given-names>R</given-names></name><name><surname>Vuong</surname><given-names>C</given-names></name><name><surname>To</surname><given-names>T</given-names></name><name><surname>Hachisuka</surname><given-names>A</given-names></name><name><surname>Choudhary</surname><given-names>K</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Moving bar of light evokes vectorial spatial selectivity in the immobile rat hippocampus</article-title><source>Nature</source><volume>602</volume><fpage>461</fpage><lpage>467</lpage><pub-id pub-id-type="doi">10.1038/s41586-022-04404-x</pub-id><pub-id pub-id-type="pmid">35140401</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Purandare</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023a</year><data-title>Code and Datasets generated and needed to reproduce results in upcoming Elife paper</data-title><version designator="3.0">3.0</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/cspurandare/ELife_MovieTuning">https://github.com/cspurandare/ELife_MovieTuning</ext-link></element-citation></ref><ref id="bib74"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Purandare</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023b</year><data-title>Elife_Movietuning</data-title><version designator="swh:1:rev:2153deb7b9f2fa2b570c4a2264d464c93768516e">swh:1:rev:2153deb7b9f2fa2b570c4a2264d464c93768516e</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:3b56b105f8aafd53a6f1bfb0cdbf1b8b64a48bef;origin=https://github.com/cspurandare/ELife_MovieTuning;visit=swh:1:snp:19d64a8daa436a5ae0c2aa4558fe8147a847fa6e;anchor=swh:1:rev:2153deb7b9f2fa2b570c4a2264d464c93768516e">https://archive.softwareheritage.org/swh:1:dir:3b56b105f8aafd53a6f1bfb0cdbf1b8b64a48bef;origin=https://github.com/cspurandare/ELife_MovieTuning;visit=swh:1:snp:19d64a8daa436a5ae0c2aa4558fe8147a847fa6e;anchor=swh:1:rev:2153deb7b9f2fa2b570c4a2264d464c93768516e</ext-link></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Reddy</surname><given-names>L</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Invariant visual representation by single neurons in the human brain</article-title><source>Nature</source><volume>435</volume><fpage>1102</fpage><lpage>1107</lpage><pub-id pub-id-type="doi">10.1038/nature03687</pub-id><pub-id pub-id-type="pmid">15973409</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravassard</surname><given-names>P</given-names></name><name><surname>Kees</surname><given-names>A</given-names></name><name><surname>Willers</surname><given-names>B</given-names></name><name><surname>Ho</surname><given-names>D</given-names></name><name><surname>Aharoni</surname><given-names>DA</given-names></name><name><surname>Cushman</surname><given-names>J</given-names></name><name><surname>Aghajan</surname><given-names>ZM</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory control of hippocampal spatiotemporal selectivity</article-title><source>Science</source><volume>340</volume><fpage>1342</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1126/science.1232655</pub-id><pub-id pub-id-type="pmid">23641063</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reagh</surname><given-names>ZM</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Flexible reuse of cortico-hippocampal representations during encoding and recall of naturalistic events</article-title><source>Nature Communications</source><volume>14</volume><elocation-id>1279</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-36805-5</pub-id><pub-id pub-id-type="pmid">36890146</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resnik</surname><given-names>E</given-names></name><name><surname>McFarland</surname><given-names>JM</given-names></name><name><surname>Sprengel</surname><given-names>R</given-names></name><name><surname>Sakmann</surname><given-names>B</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The effects of GluA1 deletion on the hippocampal population code for position</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>8952</fpage><lpage>8968</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6460-11.2012</pub-id><pub-id pub-id-type="pmid">22745495</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rich</surname><given-names>PD</given-names></name><name><surname>Liaw</surname><given-names>HP</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Place cells: large environments reveal the statistical structure governing hippocampal representations</article-title><source>Science</source><volume>345</volume><fpage>814</fpage><lpage>817</lpage><pub-id pub-id-type="doi">10.1126/science.1255635</pub-id><pub-id pub-id-type="pmid">25124440</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>O’Mara</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>View-responsive neurons in the primate hippocampal complex</article-title><source>Hippocampus</source><volume>5</volume><fpage>409</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1002/hipo.450050504</pub-id><pub-id pub-id-type="pmid">8773254</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Hippocampal spatial view cells for memory and navigation, and their underlying connectivity in humans</article-title><source>Hippocampus</source><volume>33</volume><fpage>533</fpage><lpage>572</lpage><pub-id pub-id-type="doi">10.1002/hipo.23467</pub-id><pub-id pub-id-type="pmid">36070199</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roth</surname><given-names>ED</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Rao</surname><given-names>G</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Functional differences in the backward shifts of CA1 and CA3 place fields in novel and familiar environments</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e36035</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0036035</pub-id><pub-id pub-id-type="pmid">22558316</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Royer</surname><given-names>S</given-names></name><name><surname>Zemelman</surname><given-names>BV</given-names></name><name><surname>Losonczy</surname><given-names>A</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Chance</surname><given-names>F</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Control of timing, rate and bursts of hippocampal place cells by dendritic and somatic inhibition</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>769</fpage><lpage>775</lpage><pub-id pub-id-type="doi">10.1038/nn.3077</pub-id><pub-id pub-id-type="pmid">22446878</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rutishauser</surname><given-names>U</given-names></name><name><surname>Mamelak</surname><given-names>AN</given-names></name><name><surname>Schuman</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Single-trial learning of novel stimuli by individual neurons of the human hippocampus-amygdala complex</article-title><source>Neuron</source><volume>49</volume><fpage>805</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.02.015</pub-id><pub-id pub-id-type="pmid">16543129</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sadeh</surname><given-names>S</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Contribution of behavioural variability to representational drift</article-title><source>eLife</source><volume>11</volume><elocation-id>e77907</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.77907</pub-id><pub-id pub-id-type="pmid">36040010</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakai</surname><given-names>K</given-names></name><name><surname>Miyashita</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Neural organization for the long-term memory of paired associates</article-title><source>Nature</source><volume>354</volume><fpage>152</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1038/354152a0</pub-id><pub-id pub-id-type="pmid">1944594</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Diamanti</surname><given-names>EM</given-names></name><name><surname>Fournier</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Coherent encoding of subjective spatial position in visual cortex and hippocampus</article-title><source>Nature</source><volume>562</volume><fpage>124</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0516-1</pub-id><pub-id pub-id-type="pmid">30202092</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmitzer-Torbert</surname><given-names>N</given-names></name><name><surname>Jackson</surname><given-names>J</given-names></name><name><surname>Henze</surname><given-names>D</given-names></name><name><surname>Harris</surname><given-names>K</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Quantitative measures of cluster quality for use in extracellular recordings</article-title><source>Neuroscience</source><volume>131</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2004.09.066</pub-id><pub-id pub-id-type="pmid">15680687</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schröder</surname><given-names>S</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Krumin</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Rizzi</surname><given-names>M</given-names></name><name><surname>Lagnado</surname><given-names>L</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Arousal modulates retinal output</article-title><source>Neuron</source><volume>107</volume><fpage>487</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.04.026</pub-id><pub-id pub-id-type="pmid">32445624</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scoville</surname><given-names>WB</given-names></name><name><surname>Milber</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1957">1957</year><article-title>Loss of recent memory after bilateral hippocampal lesions</article-title><source>Journal of Neurology, Neurosurgery, and Psychiatry</source><volume>20</volume><fpage>11</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1136/jnnp.20.1.11</pub-id><pub-id pub-id-type="pmid">13406589</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shan</surname><given-names>KQ</given-names></name><name><surname>Lubenov</surname><given-names>EV</given-names></name><name><surname>Papadopoulou</surname><given-names>M</given-names></name><name><surname>Siapas</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spatial tuning and brain state account for dorsal hippocampal CA1 activity in a non-spatial learning task</article-title><source>eLife</source><volume>5</volume><elocation-id>e14321</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.14321</pub-id><pub-id pub-id-type="pmid">27487561</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharp</surname><given-names>PE</given-names></name><name><surname>Green</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Spatial correlates of firing patterns of single cells in the subiculum of the freely moving rat</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>2339</fpage><lpage>2356</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-04-02339.1994</pub-id><pub-id pub-id-type="pmid">8158272</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Durand</surname><given-names>S</given-names></name><name><surname>Gale</surname><given-names>S</given-names></name><name><surname>Bennett</surname><given-names>C</given-names></name><name><surname>Graddis</surname><given-names>N</given-names></name><name><surname>Heller</surname><given-names>G</given-names></name><name><surname>Ramirez</surname><given-names>TK</given-names></name><name><surname>Choi</surname><given-names>H</given-names></name><name><surname>Luviano</surname><given-names>JA</given-names></name><name><surname>Groblewski</surname><given-names>PA</given-names></name><name><surname>Ahmed</surname><given-names>R</given-names></name><name><surname>Arkhipov</surname><given-names>A</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Billeh</surname><given-names>YN</given-names></name><name><surname>Brown</surname><given-names>D</given-names></name><name><surname>Buice</surname><given-names>MA</given-names></name><name><surname>Cain</surname><given-names>N</given-names></name><name><surname>Caldejon</surname><given-names>S</given-names></name><name><surname>Casal</surname><given-names>L</given-names></name><name><surname>Cho</surname><given-names>A</given-names></name><name><surname>Chvilicek</surname><given-names>M</given-names></name><name><surname>Cox</surname><given-names>TC</given-names></name><name><surname>Dai</surname><given-names>K</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>de Vries</surname><given-names>SEJ</given-names></name><name><surname>Dietzman</surname><given-names>R</given-names></name><name><surname>Esposito</surname><given-names>L</given-names></name><name><surname>Farrell</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Galbraith</surname><given-names>J</given-names></name><name><surname>Garrett</surname><given-names>M</given-names></name><name><surname>Gelfand</surname><given-names>EC</given-names></name><name><surname>Hancock</surname><given-names>N</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Howard</surname><given-names>R</given-names></name><name><surname>Hu</surname><given-names>B</given-names></name><name><surname>Hytnen</surname><given-names>R</given-names></name><name><surname>Iyer</surname><given-names>R</given-names></name><name><surname>Jessett</surname><given-names>E</given-names></name><name><surname>Johnson</surname><given-names>K</given-names></name><name><surname>Kato</surname><given-names>I</given-names></name><name><surname>Kiggins</surname><given-names>J</given-names></name><name><surname>Lambert</surname><given-names>S</given-names></name><name><surname>Lecoq</surname><given-names>J</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Lee</surname><given-names>JH</given-names></name><name><surname>Leon</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Liang</surname><given-names>E</given-names></name><name><surname>Long</surname><given-names>F</given-names></name><name><surname>Mace</surname><given-names>K</given-names></name><name><surname>Melchior</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>D</given-names></name><name><surname>Mollenkopf</surname><given-names>T</given-names></name><name><surname>Nayan</surname><given-names>C</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Ngo</surname><given-names>K</given-names></name><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>North</surname><given-names>K</given-names></name><name><surname>Ocker</surname><given-names>GK</given-names></name><name><surname>Ollerenshaw</surname><given-names>D</given-names></name><name><surname>Oliver</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Perkins</surname><given-names>J</given-names></name><name><surname>Reding</surname><given-names>M</given-names></name><name><surname>Reid</surname><given-names>D</given-names></name><name><surname>Robertson</surname><given-names>M</given-names></name><name><surname>Ronellenfitch</surname><given-names>K</given-names></name><name><surname>Seid</surname><given-names>S</given-names></name><name><surname>Slaughterbeck</surname><given-names>C</given-names></name><name><surname>Stoecklin</surname><given-names>M</given-names></name><name><surname>Sullivan</surname><given-names>D</given-names></name><name><surname>Sutton</surname><given-names>B</given-names></name><name><surname>Swapp</surname><given-names>J</given-names></name><name><surname>Thompson</surname><given-names>C</given-names></name><name><surname>Turner</surname><given-names>K</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Whitesell</surname><given-names>JD</given-names></name><name><surname>Williams</surname><given-names>D</given-names></name><name><surname>Williford</surname><given-names>A</given-names></name><name><surname>Young</surname><given-names>R</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Naylor</surname><given-names>S</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Olsen</surname><given-names>SR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title><source>Nature</source><volume>592</volume><fpage>86</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-03171-x</pub-id><pub-id pub-id-type="pmid">33473216</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Zeidman</surname><given-names>P</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Representation of contralateral visual space in the human hippocampus</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>2382</fpage><lpage>2392</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1990-20.2020</pub-id><pub-id pub-id-type="pmid">33500275</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Theta phase precession in hippocampal neuronal populations and the compression of temporal sequences</article-title><source>Hippocampus</source><volume>6</volume><fpage>149</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1996)6:2&lt;149::AID-HIPO6&gt;3.0.CO;2-K</pub-id><pub-id pub-id-type="pmid">8797016</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spacek</surname><given-names>MA</given-names></name><name><surname>Crombie</surname><given-names>D</given-names></name><name><surname>Bauer</surname><given-names>Y</given-names></name><name><surname>Born</surname><given-names>G</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Katzner</surname><given-names>S</given-names></name><name><surname>Busse</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Robust effects of corticothalamic feedback and behavioral state on movie responses in mouse dLGN</article-title><source>eLife</source><volume>11</volume><elocation-id>e70469</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.70469</pub-id><pub-id pub-id-type="pmid">35315775</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stringer</surname><given-names>C</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Reddy</surname><given-names>CB</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title><source>Science</source><volume>364</volume><elocation-id>255</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id><pub-id pub-id-type="pmid">31000656</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vargha-Khadem</surname><given-names>F</given-names></name><name><surname>Gadian</surname><given-names>DG</given-names></name><name><surname>Watkins</surname><given-names>KE</given-names></name><name><surname>Connelly</surname><given-names>A</given-names></name><name><surname>Van Paesschen</surname><given-names>W</given-names></name><name><surname>Mishkin</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Differential effects of early hippocampal pathology on episodic and semantic memory</article-title><source>Science</source><volume>277</volume><fpage>376</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1126/science.277.5324.376</pub-id><pub-id pub-id-type="pmid">9219696</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname><given-names>M</given-names></name><name><surname>Batista-Brito</surname><given-names>R</given-names></name><name><surname>Knoblich</surname><given-names>U</given-names></name><name><surname>Cardin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id><pub-id pub-id-type="pmid">25892300</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinje</surname><given-names>WE</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Sparse coding and decorrelation in primary visual cortex during natural vision</article-title><source>Science</source><volume>287</volume><fpage>1273</fpage><lpage>1276</lpage><pub-id pub-id-type="doi">10.1126/science.287.5456.1273</pub-id><pub-id pub-id-type="pmid">10678835</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The Allen Mouse Brain common coordinate framework: A 3D reference atlas</article-title><source>Cell</source><volume>181</volume><fpage>936</fpage><lpage>953</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.04.007</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiener</surname><given-names>SI</given-names></name><name><surname>Paul</surname><given-names>CA</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Spatial and behavioral correlates of hippocampal neuronal activity</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>2737</fpage><lpage>2763</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-08-02737.1989</pub-id><pub-id pub-id-type="pmid">2769364</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Dynamics of the hippocampal ensemble code for space</article-title><source>Science</source><volume>261</volume><fpage>1055</fpage><lpage>1058</lpage><pub-id pub-id-type="doi">10.1126/science.8351520</pub-id><pub-id pub-id-type="pmid">8351520</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>J</given-names></name><name><surname>Marks</surname><given-names>TD</given-names></name><name><surname>Goard</surname><given-names>MJ</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Stable representation of a naturalistic movie emerges from episodic activity with gain variability</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>5170</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-25437-2</pub-id><pub-id pub-id-type="pmid">34453045</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>S</given-names></name><name><surname>Jiang</surname><given-names>W</given-names></name><name><surname>Poo</surname><given-names>MM</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Activity recall in a visual cortical ensemble</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>449</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1038/nn.3036</pub-id><pub-id pub-id-type="pmid">22267160</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname><given-names>MM</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells without theta oscillations in the entorhinal cortex of bats</article-title><source>Nature</source><volume>479</volume><fpage>103</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1038/nature10583</pub-id><pub-id pub-id-type="pmid">22051680</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yen</surname><given-names>SC</given-names></name><name><surname>Baker</surname><given-names>J</given-names></name><name><surname>Gray</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Heterogeneity in the responses of adjacent neurons to natural stimuli in cat striate cortex</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>1326</fpage><lpage>1341</lpage><pub-id pub-id-type="doi">10.1152/jn.00747.2006</pub-id><pub-id pub-id-type="pmid">17079343</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>J</given-names></name><name><surname>Schjetnan</surname><given-names>AGP</given-names></name><name><surname>Yebra</surname><given-names>M</given-names></name><name><surname>Gomes</surname><given-names>BA</given-names></name><name><surname>Mosher</surname><given-names>CP</given-names></name><name><surname>Kalia</surname><given-names>SK</given-names></name><name><surname>Valiante</surname><given-names>TA</given-names></name><name><surname>Mamelak</surname><given-names>AN</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Rutishauser</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neurons detect cognitive boundaries to structure episodic memories in humans</article-title><source>Nature Neuroscience</source><volume>25</volume><fpage>358</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1038/s41593-022-01020-w</pub-id><pub-id pub-id-type="pmid">35260859</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85069.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Texas at Austin</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This manuscript analyzes large-scale Neuropixels recordings from visual areas and hippocampus of mice passively viewing repeated clips of a movie and reports that neurons respond with elevated firing activities to specific, continuous sequences of movie frames. The <bold>important</bold> results support a role of rodent hippocampal neurons in general episode encoding and advance understanding of visual information processing across different brain regions. The strength of evidence for the primary conclusion was found to be <bold>convincing</bold>.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85069.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Taking advantage of a publicly available dataset, neuronal responses in both the visual and hippocampal areas to passive presentation of a movie are analyzed in this manuscript. Since the visual responses have been described in a number of previous studies (e.g., see Refs. 11-13), the value of this manuscript lies mostly on the hippocampal responses, especially in the context of how hippocampal neurons encode episodic memories. Previous human studies show that hippocampal neurons display selective responses to short (5 s) video clips (e.g. see Gelbard-Sagiv et al, Science 322: 96-101, 2008). The hippocampal responses in head-fixed mice to a longer (30 s) movie as studied in this manuscript could potentially offer important evidence that the rodent hippocampus encodes visual episodes.</p><p>The analysis strategy is mostly well designed and executed. A number of factors and controls, including baseline firing, locomotion, frame-to-frame visual content variation, are carefully considered. The inclusion of neuronal responses to scrambled movie frames in the analysis is a powerful method to reveal the modulation of a key element in episodic events, temporal continuity, on the hippocampal activity. The properties of movie fields are comprehensively characterized in the manuscript.</p><p>Comments on latest version:</p><p>The new analysis on how behavioral states and hippocampal ripples impacted the tuning of movie fields makes the main finding substantially more convincing. Other relatively minor concerns on the methodology and interpretation are also improved. I do not have further concerns.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85069.3.sa2</article-id><title-group><article-title>Reviewer #3 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In their study, Purandare &amp; Mehta analyze large-scale single unit recordings from the visual system (LGN, V1, extrastriate regions AM and PM) and hippocampal system (DG, CA3, CA1 and subiculum) while mice monocularly viewed repeats of a 30s movie clip. The data were part of a larger release of publicly available recordings from the Allen Brian Observatory. The authors found that cells in all regions exhibited tuning to specific segments of the movie (i.e. &quot;movie fields&quot;) ranging in duration from 20ms to 20s. The largest fractions of movie-responsive cells were in visual regions, though analyses of scrambled movie frames indicated that visual neurons were driven more strongly by visual features of the movie images themselves. Cells in the hippocampal system, on the other hand, tended to exhibit fewer &quot;movie fields&quot;, which on average were a few seconds in duration, but could range from &gt;50ms to as long as 20s. Unlike the visual system &quot;movie fields&quot; in the hippocampal system disappeared when the frames of the movie were scrambled, indicating that the cells encoded more complex (episodic) content, rather than merely passively reading out visual input.</p><p>The paper is conceptually novel since it specifically aims to remove any behavioral or task engagement whatsoever in the head-fixed mice, a setup typically used as an open-loop control condition in virtual reality-based navigational or decision making tasks (e.g. Harvey et al., 2012). Because the study specifically addresses this aspect of encoding (i.e. exploring effects of pure visual content rather than something task-related), and because of the widespread use of video-based virtual reality paradigms in different sub-fields, the paper should be of interest to those studying visual processing as well as those studying visual and spatial coding in the hippocampal system.</p><p>Comments on latest version:</p><p>The revised manuscript by Purandare et al. has been improved with the inclusion of additional analyses and discussion, and the changes mainly satisfy the concerns raised in the initial version of the manuscript.</p><p>Regarding the methods, it was particularly helpful that the authors took measures to consider the impact of different states of arousal (pupil diameter), mobility, and SWRs on the expression and significance of movie field tuning, considering the lack of a task structure or behavioral report. Relatedly, the additional metrics applied (information rate and depth of movie field modulation) substantiate the results as based on z-scored sparsity. The explanation of lifetime sparseness as used here vs. in the work of de Vries et al. 2020 was also helpful.</p><p>The addition of more clearly tuned cells also helps the study feel more rooted in solid ground. For clarity, and consistency with the rest of the paper, it would be helpful to add the sparseness metrics above the newly added neural data in the Figure supplements.</p><p>The Discussion also contains elements that help balance both it and the paper as a whole. It draws a clearer distinction between the representation of visual scenes rather than encoding the contents of episodic memory, clarifying that hippocampal neurons were more likely doing the former than the latter. It is also appreciated that the authors added discussion acknowledging that the cortical processing did not quite follow an apparent hierarchical order.</p><p>As a last observation, though the authors assert in their rebuttal that analysis of the visual content encoded in the movie fields is beyond the scope of the study, this would add an interesting dimension to the work. Because, to my awareness, much less is known regarding how the visual and hippocampal systems in rodents encode visual information when the visual input is dynamic and chunked, as with movies. It would prove an interesting addition to the more extensive work on the processing of static visual scenes.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.85069.3.sa3</article-id><title-group><article-title>Author Response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Purandare</surname><given-names>Chinmay</given-names></name><role specific-use="author">Author</role><aff><institution>UCSF</institution><addr-line><named-content content-type="city">San Francisco</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Mehta</surname><given-names>Mayank</given-names></name><role specific-use="author">Author</role><aff><institution>UCLA</institution><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>eLife assessment</bold></p><p>This manuscript analyzes large-scale Neuropixels recordings from visual areas and hippocampus of mice passively viewing repeated clips of a movie and reports that neurons respond with elevated firing activities to specific, continuous sequences of movie frames. The important results support a role of rodent hippocampal neurons in general episode encoding and advance understanding of visual information processing across different brain regions. The strength of evidence for the primary conclusion is solid, but some technical limitations of the study were identified that merit further analyses.</p></disp-quote><p>We thank the editors and reviews for the assessment and reviews. We have provided clarifications and updated the manuscripts to address the seeming technical limitations that are perhaps due to some misunderstanding, please see below. We provide additional results that isolate the contribution of pupil diameter, sharpwave ripple and theta power to show that movie tuning cannot be explained by these nonspecific effects. Nor are these mere time cells or some other internally generated patterns due to many differences highlighted below.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>Taking advantage of a publicly available dataset, neuronal responses in both the visual and hippocampal areas to passive presentation of a movie are analyzed in this manuscript. Since the visual responses have been described in a number of previous studies (e.g., see Refs. 11-13), the value of this manuscript lies mostly on the hippocampal responses, especially in the context of how hippocampal neurons encode episodic memories. Previous human studies show that hippocampal neurons display selective responses to short (5 s) video clips (e.g. see Gelbard-Sagiv et al, Science 322: 96-101, 2008). The hippocampal responses in head-fixed mice to a longer (30 s) movie as studied in this manuscript could potentially offer important evidence that the rodent hippocampus encodes visual episodes.</p></disp-quote><p>We have now included citations to Gelbard-Sagiv et al. Science 2008 paper and many other references too, thank you for pointing that out. There are major differences between that study and ours.</p><p>a. The movies used in previous study contained very familiar, famous people and famous events, and the experiment was about the patient’s ability to recall those famous movie episodes. In our case the mice had seen this movie clip only in two habituation sessions before.</p><p>b. They did not look at the fine structure of neural responses below half a second whereas we looked at the mega-scale representations from 30ms to 30s.</p><p>c. The movie clips in that study were in full color with audio, we used an isoluminant, black-and-white, silent movie clip.</p><p>d. Their movie clips contained humans and was observed by humans, whereas our study mice observed a movie clip with humans and no mice or other animals.</p><disp-quote content-type="editor-comment"><p>The analysis strategy is mostly well designed and executed. A number of factors and controls, including baseline firing, locomotion, frame-to-frame visual content variation, are carefully considered. The inclusion of neuronal responses to scrambled movie frames in the analysis is a powerful method to reveal the modulation of a key element in episodic events, temporal continuity, on the hippocampal activity. The properties of movie fields are comprehensively characterized in the manuscript.</p></disp-quote><p>Thank you.</p><disp-quote content-type="editor-comment"><p>Although the hippocampal movie fields appear to be weaker than the visual ones (Fig. 2g, Ext. Fig. 6b), the existence of consistent hippocampal responses to movie frames is supported by the data shown. Interestingly, in my opinion, a strong piece of evidence for this is a &quot;negative&quot; result presented in Ext. Fig. 13c, which shows higher than chance-level correlations in hippocampal responses to same scrambled frames between even and odd trials (and higher than correlations with neighboring scrambled frames). The conclusion that hippocampal movie fields depend on continuous movie frames, rather than a pure visual response to visual contents in individual frames, is supported to some degree by their changed properties after the frame scrambling (Fig. 4).</p></disp-quote><p>Yes, hippocampal selectivity is not entirely abolished with scrambled movie, as we show in several figures (Figure 4d,g and Figure 4- figure supplement 6), but it is greatly reduced, far more than that in the afferent visual cortices. The fraction of tuned cells for scrambled movies dropped to 4.5% in hippocampus, which is close to the chance level of 3%. In contrast, in visual areas selectivity was still above 80%.</p><p>Significant overlap between even and odd trials is to be expected for the tuned cells. Without a significant overlap, i.e. a stable representation, they will not be tuned. Despite this, the correlation between even and odd trials for the (only 4.5% of) tuned cells in the hippocampus was more than 2-fold smaller than (more than 80% of) cells in visual cortices. This strongly supports our hypothesis that unlike visual cortices, hippocampal subfields depended very strongly on the continuity of visual information. We have now clarified this in the main text.</p><disp-quote content-type="editor-comment"><p>However, there are two potential issues that could complicate this main conclusion.</p><p>One issue is related to the effect of behavioral variation or brain state. First, although the authors show that the movie fields are still present during low-speed stationary periods, there is a large drop in the movie tuning score (Z), especially in the hippocampal areas, as shown in Ext. Fig. 3b (compared to Ext. Fig. 2d). This result suggests a potentially significant enhancement by active behavior.</p></disp-quote><p>There seems to be some misunderstanding here. There was no major reduction in movie tuning during immobility or active running. As we wrote in the manuscript, the drop in selectivity during purely immobile epochs is because of reduction in the amount of data, not reduction in selectivity per se. Specifically, as the amount data reduces, the statistical strength of tuning (z-scored sparsity) reduces. For example, if we split the total of 60 trials worth of data into two parts, the amount of data reduces to about half in each part, leading to a seeming reduction in selectivity in both halves. Figure 1-figure supplement 4c shows nearly identical tuning in all brain regions during immobility (red bars) and equivalent subsamples (yellow-orange) chosen randomly from the entire data, including mobility and immobility. We also show that the movie tuning persists in sessions with and without prolonged running behavior (Figure 1-figure supplement 7), as well as by splitting the data based on pupil dilation or theta power. Please see below for more details.</p><disp-quote content-type="editor-comment"><p>Second, a general, hard-to-tackle concern is that neuronal responses could be greatly affected by changes in arousal or brain state (including drowsy or occasional brief slow-wave sleep state) in head-fixed animals without a task. Without the analysis of pupil size or local field potentials (LFPs), the arousal states during the experiment are difficult to know.</p></disp-quote><p>In the revised manuscript we show that the behavioral state effects cannot explain movie tuning. Specifically:</p><p>a. We compared sessions in which the mouse was mostly immobile versus sessions in which the mouse was mostly running. Movie tuned cells were found in both these cases (Figure 1-figure supplement 7).</p><p>b. We detected and removed all data around sharp-wave ripples (SWR). Movie tuning was unchanged in the remaining data. (Figure 1-figure supplement 6).</p><p>c. As a further control, we quantified arousal by two standard metrics. First within a session, we split the data into two groups, segments with high theta power and segments with low theta power. Significant movie tuning persisted in both.</p><p>d. Finally, pupil dilation is another common method to estimate arousal, so data within a session were split into two parts: those with pupil dilation versus constriction. Movie tuning remained significant in both parts. See the new Figure 1-figure supplement 7.</p><disp-quote content-type="editor-comment"><p>Many example movie fields in the presented raw data (e.g., Fig. 1c, Ext. Fig. 4) are broad with low-quality tuning, which could be due to broad changes in brain states. This concern is especially important for hippocampal responses, since the hippocampus can enter an offline mode indicated by the occurrence of LFP sharp-wave ripples (SWRs) while animals simply stay immobile. It is believed that the ripple-associated hippocampal activity is driven mainly by internal processing, not a direct response to external input (e.g., Foster and Wilson, Nature 440: 680, 2006). The &quot;actual&quot; hippocampal movie fields during a true active hippocampal network state, after the removal of SWR time periods, could have different quantifications that impact the main conclusion in the manuscript.</p></disp-quote><p>We included the broadly tuned hippocampal neurons to demonstrate the movie-field broadening compared to those in visual areas. We now include more examples with sharp movie fields in the hippocampal regions (Figure 1a-d right column, 2d and h, Figure 1-figure supplement 5 and Figure 2-figure supplement 1). Further, as stated above, we detected sharp-wave ripples and removed one second of data around SWR. Movie tuning was unchanged in the remaining data. Thus, movie tuning is not generated internally via SWR (Figure 1-figure supplement 6). See also Figure 1-figure supplement 7 and Figure 2-figure supplement 8 and the response above.</p><disp-quote content-type="editor-comment"><p>Another issue is related to the relative contribution of direct visual response versus the response to temporal continuity in movie fields. First, the data in Ext. Fig. 8 show that rapid frame-to-frame changes in visual contents contribute largely to hippocampal movie fields (similarly to visual movie fields).</p></disp-quote><p>There seems to be some misunderstanding here. That figure showed that the frame-to-frame changes in the visual content had the highest effect on visual areas MSUA and much weaker in hippocampus (Extended Data Fig. 8, as per previous version, now Figure3-figure supplement 2). For example, the depth of modulation (max – min) / (max + min) for MSUA was 21% and 24% for V1 but below 6% for hippocampal regions. Similarly, the MSUA was more strongly (negatively) correlated with F2F correlation for visual areas (r=0.48 to 0.56) than hippocampal (0.07 to 0.3). Similarly, comparing the number of peaks or their median widths, visual regions showed stronger correlation with F2F, and largest depth of modulation than hippocampal regions, barring handful exceptions (like CA3 correlation between F2F and median peak duration). This strongly supports our claim that visual regions generated far greater response of the frame-to-frame changes in the movie than hippocampal regions.</p><disp-quote content-type="editor-comment"><p>Interestingly, the data show that movie-field responses are correlated across all brain areas including the hippocampal ones.</p></disp-quote><p>In Figure 3c we compared the MSUA responses with normalization between brain regions. Amongst the 21 possible brain region pairs, 5 were uncorrelated, 7 were significantly negatively correlated and 9 were significantly positively correlated.</p><p>The changes in population overlap, number and widths of peaks are strongly correlated only between visual areas and some of the hippocampal region pairs. The correlation is much weaker for hippocampal-visual area pairs, but often significantly different from chance. This is quantified explicitly in the revised text Figure 3-figure supplement 2 with an additional correlation matrix at the right.</p><disp-quote content-type="editor-comment"><p>This could be due to heightened behavioral arousal caused by the changing frames as mentioned above, or due to enhanced neuronal responses to visual transients, which supports a component of direct visual response in hippocampal movie fields.</p></disp-quote><p>As shown in Figure 1-figure supplements 4,5,6 and 7 and described above, the effect of arousal as quantified by theta power of pupil diameter (or by accounting for running behavior or SWR occurrences) cannot explain the results in hippocampal areas and the correlations in multiunit responses are unrelated across many brain areas.</p><disp-quote content-type="editor-comment"><p>Second, the data in Ext. Fig. 13c show a significant correlation in hippocampal responses to same scrambled frames between even and odd trials, which also suggests a significant component of direct visual response.</p></disp-quote><p>This is plausible. The fraction of hippocampal cells which were significantly tuned for the scrambled presentation (4.5%) was close to chance level (3%), and this small subset of cells was used to compute the population overlap between even and odd trials in Figure 4-figure supplement 6 (Ext Fig. 13 with old numbering). As described above, this significant but small amount of tuning could generate significant population overlap, which is to be expected by construction.</p><disp-quote content-type="editor-comment"><p>Is there a significant component purely due to the temporal continuity of movie frames in hippocampal movie fields? To support that this is indeed the case, the authors have presented data that hippocampal movie fields largely disappear after movie frames are scrambled. However, this could be caused by the movie-field detection method (it is unclear whether single-frame field could be detected).</p></disp-quote><p>As described in the methods section, the movie-field detection algorithm had a resolution of 3.3ms resolution, which ensured that we could detect single frame fields. As reported, we did find such short movie fields in several cells in the visual areas. The sparsity metric used is agnostic to the ordering of the responses, and hence single frame field, and the resultant significant movie-tuning, if present, can be detected by our methods.</p><disp-quote content-type="editor-comment"><p>Another concern in the analysis is that movie-fields are not analyzed on re-arranged neural responses to scrambled movie frames. The raw data in Fig. 4e seem quite convincing. Unfortunately, the quantifications of movie fields in this case are not compared to those with the original movie.</p></disp-quote><p>We saw very few (3.6-4.9%) cells with significant movie tuning for scrambled presentation in the hippocampus. Hence, we did not quantify this earlier. This is now provided in new Figure 4-figure supplement 5. The amount of movie tuning for the scrambled presentation taken as-is, or after rearranging the frames is below 5% for all hippocampal brain regions and not significantly different between the two.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Purandare and Mehta investigated the neural activities modulated by continuous and sequential visual stimuli composed of natural images, termed &quot;movie-tuning,&quot; measured along the visuo-hippocampal network when the animals passively viewed a movie without any task demand. Neurons selectively responded to some specific parts of the movie, and their activity timescales ranged from tens of milliseconds to seconds and tiled the entire movie with their movie-fields. The movie-tuning was lost in the hippocampus but not in the visual cortices when the image frames were temporally scrambled, implying that the rodent hippocampus encoded the specific sequence of images.</p><p>The authors have concluded that the neurons in the thalamo-cortical visual areas and the hippocampus commonly encode continuous visual stimuli with their firing fields spanning the mega-scale, but they respond to different aspects of the visual stimuli (i.e., visual contents of the image versus a sequence of the images). The conclusion of the study is fairly supported by the data, but some remaining concerns should be addressed.</p><p>1. Care should be taken in interpreting the results since the animal's behavior was not controlled during the physiological recording.</p></disp-quote><p>This was done intentionally since plenty of research shows that task demand (e.g., Aronov and Tank, Nature 2017) can not only modulate hippocampal responses but also dramatically alter them. We have now provided additional figures (Figure 1-figure supplement 6 and 7) where we quantified the effects of the behavioral states (sharp wave ripples, theta power and pupil diameter), as well as the effect of locomotion (Figure 1-figure supplement 4). Movie tuning remained unaffected with these manipulations. Thus, movie tuning cannot be attributed to behavioral effects.</p><disp-quote content-type="editor-comment"><p>It has been reported that some hippocampal neuronal activities are modulated by locomotion, which may still contribute to some of the results in the current study. Although the authors claimed that the animal's locomotion did not influence the movie-tuning by showing the unaltered proportion of movie-tuned cells with stationary epochs only, the effects of locomotion should be tested in a more specific way (e.g., comparing changes in the strength of movie-tuning under certain locomotion conditions at the single-cell level).</p></disp-quote><p>Single cell analysis of the effect of locomotion and visual stimulation is underway, and beyond the scope of the current work. As detailed in Figure 1-figure supplement 4, we have ensured that in spite of the removal of running or stationary epochs, as well as removal of sharp wave ripple events (Figure 1-figure supplement 6) movie tuning persists. Further, we now provide examples of strongly tuned cells from sessions with predominantly running or predominantly stationary behavior (Figure 1-figure supplement 7).</p><disp-quote content-type="editor-comment"><p>1. The mega-scale spanning of movie-fields needs to be further examined with a more controlled stimulus for reasonable comparison with the traditional place fields. This is because the movie used in the current study consists of a fast-changing first half and a slow-changing second half, and such varying and ununified composition of the movie might have largely affected the formation of movie-fields. According to Fig. 3, the mega-scale spanning appears to be driven by the changes in frame-to-frame correlation within the movie. That is, visual stimuli changing quickly induced several short fields while persisting stimuli with fewer changes elongated the fields.</p></disp-quote><p>Please note that a strong correlation between the speed at which the movie scene changed across frames was correlated with movie-field width in the visual areas, but that correlation was much weaker in the hippocampal areas correlation values - (LGN +0.61, V1 +0.51, AM-PM +0.55 vs. DG +0.39, CA3 +0.58, CA1 +0.42, SUB +0.24). Please see Figure 3-figure supplement 2 and the quantification of correlation between frame-to-frame changes in the movie and the properties of movie fields.</p><disp-quote content-type="editor-comment"><p>The presentation of persisting visual input for a long time is thought to be similar to staying in one place for a long time, and the hippocampal activities have been reported to manifest in different ways between running and standing still (i.e., theta-modulated vs. sharp wave ripple-based). Therefore, it should be further examined whether the broad movie-fields are broadly tuned to the continuous visual inputs or caused by other brain states.</p></disp-quote><p>As shown in Figure 1-figure supplement 6, movie field properties are largely unchanged when SWR are removed from the data, or when the effect of pupil diameter or theta power were factored for (Figure 1-figure supplement 7).</p><disp-quote content-type="editor-comment"><p>1. The population activities of the hippocampal movie-tuned cells in Fig. 3a-b look like those of time cells, tiling the movie playback period. It needs to be clarified whether the hippocampal cells are actively coding the visual inputs or just filling the duration.</p></disp-quote><p>Tiling patterns would be observed when the maxima are sorted in any data, even for random numbers. This alone does not make them time cells. The following observations suggest that movie fields cannot be explained as being time cells.</p><p>a. Time cells mostly cluster at the beginning of a running epoch (Pastalkova et al. Science 2008, MacDonald et al. Neuron 2011) and they taper off towards the end. Such large clustering is not visible in these tiling plots for movie tuned cells.</p><p>b. Time fields become wider as the temporal duration progresses (Pastalkova et al. Science 2008, MacDonald et al. Neuron 2011) as the encoded temporal duration increases. This is not evident in any movie fields.</p><p>c. Widths of movie fields in visual areas, and to a smaller extent in the hippocampal areas, were clearly modulated by the visual content, like the change from one frame to the next (F2F correlation, Figure 3-figure supplement 2).</p><p>d. Tiling pattern of movie fields was found in visual areas too, with qualitatively similar pattern as hippocampus. Clearly, visual area responses are not time cells, as shown by the scrambled stimulus experiment. Here, neural selectivity could be recovered by rearranging them based on the visual content of the continuous movie, and not the passage of time.</p><disp-quote content-type="editor-comment"><p>The scrambled condition in which the sequence of the images was randomly permutated made the hippocampal neurons totally lose their selective responses, failing to reconstruct the neural responses to the original sequence by rearrangement of the scrambled sequence. This result indirectly addressed that the substantial portion of the hippocampal cells did not just fill the duration but represented the contents and temporal order of the images. However, it should be directly confirmed whether the tiling pattern disappeared with the population activities in the scrambled condition (as shown in Extended Data Fig. 11, but data were not shown for the hippocampus).</p></disp-quote><p>As stated above for the continuous movie, tiling pattern alone does not mean those are time cells. Further, tuning, and tiling pattern remained intact with scrambled movie in the visual cortices but not in hippocampus. We now added a new supplement figure – Figure 4-figure supplement 5 where we compared the movie tuning for scrambled presentation with and without rearranging the frames. Hippocampal tuning remains at chance levels.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>In their study, Purandare &amp; Mehta analyze large-scale single unit recordings from the visual system (LGN, V1, extrastriate regions AM and PM) and hippocampal system (DG, CA3, CA1 and subiculum) while mice monocularly viewed repeats of a 30s movie clip. The data were part of a larger release of publicly available recordings from the Allen Brian Observatory. The authors found that cells in all regions exhibited tuning to specific segments of the movie (i.e. &quot;movie fields&quot;) ranging in duration from 20ms to 20s. The largest fractions of movie-responsive cells were in visual regions, though analyses of scrambled movie frames indicated that visual neurons were driven more strongly by visual features of the movie images themselves. Cells in the hippocampal system, on the other hand, tended to exhibit fewer &quot;movie fields&quot;, which on average were a few seconds in duration, but could range from &gt;50ms to as long as 20s. Unlike the visual system &quot;movie fields&quot; in the hippocampal system disappeared when the frames of the movie were scrambled, indicating that the cells encoded more complex (episodic) content, rather than merely passively reading out visual input.</p><p>The paper is conceptually novel since it specifically aims to remove any behavioral or task engagement whatsoever in the head-fixed mice, a setup typically used as an open-loop control condition in virtual reality-based navigational or decision making tasks (e.g. Harvey et al., 2012). Because the study specifically addresses this aspect of encoding (i.e. exploring effects of pure visual content rather than something task-related), and because of the widespread use of video-based virtual reality paradigms in different sub-fields, the paper should be of interest to those studying visual processing as well as those studying visual and spatial coding in the hippocampal system. However, the task-free approach of the experiments (including closely controlling for movement-related effects) presents a Catch-22, since there is no way that the animal subjects can report actually recognizing or remembering any of the visual content we are to believe they do.</p></disp-quote><p>Our claim is that these are movie scene evoked responses. We make no claims about the animal’s ability to recognize or remember the movie content. That would require entirely different set of experiments. Meanwhile, we have shown that these results are not an artifact of brain states such as sharp wave ripples, theta power or pupil diameter (Figure1-figure supplement 6 and 7) or running behavior (Figure 1-figure supplement 4). Please see above for a detailed response.</p><disp-quote content-type="editor-comment"><p>We must rely on above-chance-level decoding of movie segments, and the requirement that the movie is played in order rather than scrambled, to indicate that the hippocampal system encodes episodic content of the movie. So the study represents an interesting conceptual advance, and the analyses appear solid and support the conclusion, but there are methodological limitations.</p></disp-quote><p>It is important to emphasize that these responses could constitute episodic responses but does not prove episodic memory, just as place cell responses constitute spatial responses but that does not prove spatial memory. The link between place cells and place memory is not entirely clear. For example, mice lacking NMDA receptors have intact place cells, but are impaired in spatial memory task (McHugh et al. Cell 1996), whereas spatial tuning was virtually destroyed in mice lacking GluR1 receptors, but they could still do various spatial memory tasks (Resnik et al. J. Neuro 2012).</p><p>The experiments about episodic memory would require an entirely different set of experiments that involve task demand and behavioral response, which in turn would modify hippocampal responses substantially, as shown by many studies. Our hypothesis here, is that just like place cells, these episodic responses without task demand would play a role, to be determined, in episodic memory. We have emphasized this point in the main text (Ln 391-393 in the revised manuscript).</p><disp-quote content-type="editor-comment"><p>Major concerns:</p><p>1. A lot hinges on hinges on the cells having a z-scored sparsity &gt;2, the cutoff for a cell to be counted as significantly modulated by the movie. What is the justification of this criterion?</p></disp-quote><p>The z-scored sparsity (z&gt;2) corresponds to p&lt;0.03. This would mean that 3% of the results could appear by chance. Hence, z&gt;2 is a standard method used in many publications. Another advantage of z-scored sparsity is that it is relatively insensitive to the number of spikes generated by a neuron (i.e. the mean firing rate of the neuron and the duration of the experiment). In contrast, sparsity is strongly dependent on the number of spikes which makes it difficult to compare across neurons, brain regions and conditions (See Supplement S5 Acharya et al. Cell 2016).</p><p>To further address this point, we compared our z-scored sparsity measure with 2 other commonly used metrics to quantify neural selectivity, depth of modulation and mutual information (Figure 1-figure supplement 3). Comparable movie tuning was obtained from all 3 metrics, upon z-scoring in an identical fashion.</p><disp-quote content-type="editor-comment"><p>It should be stated in the Results. Relatedly, it appears the formula used for calculating sparseness in the present study is not the same as that used to calculate lifetime sparseness in de Vries et al. 2020 quoted in the results (see the formula in the Methods of the de Vries 2020 paper immediately under the sentence: &quot;Lifetime sparseness was computed using the definition in Vinje and Gallant&quot;).</p></disp-quote><p>The definition of sparsity we used is used commonly by most hippocampal scientists (Treves and Rolls 1991, Skaggs et al. 1996, Ravassard et al. 2013). Lifetime sparseness equation used by de Vries et al. 2020, differs from us by just one constant factor (1-1/N) where N=900 is the number of frames in the movie. This constant factor equals (1-1/900)=0.999. Hence, there is no difference between the sparsity obtained by these two methods. Further, z-scored sparsity is entirely unaffected by such constant factors. We have clarified this in the methods of the revised manuscript.</p><disp-quote content-type="editor-comment"><p>To rule out systematic differences between studies beyond differences in neural sampling (single units vs. calcium imaging), it would be nice to see whether calculating lifetime sparseness per de Vries et al. changed the fraction &quot;movie&quot; cells in the visual and hippocampal systems.</p></disp-quote><p>As stated above, the two definitions of sparsity are virtually identical and we obtained similar results using two other commonly used metrics, which are detailed in Figure 1-figure supplement 3.</p><disp-quote content-type="editor-comment"><p>1. In Figures 1, 2 and the supplementary figures-the sparseness scores should be reported along with the raw data for each cell, so the readers can be apprised of what types of firing selectivity are associated with which sparseness scores-as would be shown for metrics like gridness or Raleigh vector lengths for head direction cells. It would be helpful to include this wherever there are plots showing spike rasters arranged by frame number &amp; the trial-averaged mean rate.</p></disp-quote><p>As shown in several papers (Aghajan et al Nature Neuroscience 2015, Acharya et al., Cell 2016) raw sparsity (or information content) are strongly dependent on the number of spikes of a neuron. This makes the raw values of these numbers impossible to compare across cells, brain regions and conditions. (Please see Supplement S5 from Acharya et al., Cell 2016 for details). Including the data of sparsity would thus cause undue confusion. Hence, we provide z-scored sparsity. This metric is comparable across cells and brain regions, and now provided above each example cell in Figure 1 and Figure 1-figure supplement 2.</p><disp-quote content-type="editor-comment"><p>1. The examples shown on the right in Figures 1b and c are not especially compelling examples of movie-specific tuning; it would be helpful in making the case for &quot;movie&quot; cells if cleaner / more robust cells are shown (like the examples on the left in 1b and c).</p></disp-quote><p>We did not put the most strongly tuned hippocampal neurons in the main figures so that these cells are representative of the ensemble and not the best possible ones, so as to include examples with broad tuning responses. We have clarified in the legend that these cells are some of the best tuned cells. Although not the cleanest looking, the z-scored sparsity mentioned above the panels now indicates how strongly they are modulated compared to chance levels. Additional examples, including those with sharply tuned responses are shown in Figure 1-figure supplement 5 and Figure 2-figure supplement 1.</p><disp-quote content-type="editor-comment"><p>1. The scrambled movie condition is an essential control which, along with the stability checks in Supplementary Figure 7, provide the most persuasive evidence that the movie fields reflect more than a passive readout of visual images on a screen. However, in reference to Figure 4c, can the authors offer an explanation as to why V1 is substantially less affected by the movie scrambling than it's main input (LGN) and the cortical areas immediately downstream of it? This seems to defy the interpretation that &quot;movie coding&quot; follows the visual processing hierarchy.</p></disp-quote><p>This is an important point, one that we find very surprising as well. Perhaps this is related to other surprising observations in our manuscript, such as more neurons appeared to be tuned to the movie than the classic stimuli. A direct comparison between movie responses versus fixed images is not possible at this point due to several additional differences such as the duration of image presentations and their temporal history.</p><p>The latency required to rearrange the scrambled responses (60ms for LGN, 74ms for V1, 91ms for AM/PM) supports the anatomical hierarchy. The pattern of movie tuning properties was also broadly consistent between V1 and AM/PM (Figure 2).</p><p>However, all metrics of movie selectivity (Figure 2) to the continuous movie showed a consistent pattern that was the exact opposite pattern of the simple anatomical hierarchy: V1 had stronger movie tuning, higher number of movie fields per cell, narrower movie-field widths, larger mega-scale structure, and better decoding than LGN. V1 was also more robust to the scrambled sequence than LGN. One possible explanation is that there are other sources of inputs to V1, beyond LGN, that contribute significantly to movie tuning. This is an important insight and we have modified the discussion (Ln 315-325) to highlight this.</p><disp-quote content-type="editor-comment"><p>Relatedly, the hippocampal data do not quite fit with visual hierarchical ordering either, with CA3 being less sensitive to scrambling than DG. Since the data (especially in V1) seem to defy hierarchical visual processing, why not drop that interpretation? It is not particularly convincing as is.</p></disp-quote><p>The anatomical organization is well established and an important factor. Even when observations do not fit the anatomical hierarchy, it provides important insights about the mechanisms. All properties of movie tuning (Figure 2) –the strength of tuning, number of movie peaks, their width and decoding accuracy firmly put visual areas upstream of hippocampal regions. But, just like visual cortex there are consistent patterns that do not support a simple feed-forward anatomical hierarchy. We have pointed out these patterns so that future work can build upon it.</p><disp-quote content-type="editor-comment"><p>1. In the Discussion, the authors argue that the mice encode episodic content from the movie clip as a human or monkey would. This is supported by the (crucial) data from the scrambled movie condition, but is nevertheless difficult to prove empirically since the animals cannot give a behavioral report of recognition and, without some kind of reinforcement, why should a segment from a movie mean anything to a head-fixed, passively viewing mouse?</p></disp-quote><p>We emphasize once again that our claim is about the nature of encoding of the movie across these neurons. We make no claims about whether this forms a memory or whether the mouse is able to recognize the content or remember it. Despite decades of research, similar claims are difficult to prove for place cells, with plenty of counter examples (See the points above). The important point here is that despite any cognitive component, we see remarkably tuned responses in these brain areas. Their role in cognition would take a lot more effort and is beyond the scope of the current work.</p><disp-quote content-type="editor-comment"><p>Would the authors also argue that hippocampal cells would exhibit &quot;song&quot; fields if segments of a radio song-equally arbitrary for a mouse-were presented repeatedly? (reminiscent of the study by Aronov et al. 2017, but if sound were presented outside the context of a task). How can one distinguish between mere sequence coding vs. encoding of episodically meaningful content? One or a few sentences on this should be added in the Discussion.</p></disp-quote><p>Aronov et al 2017, found the encoding of an audio sweep in hippocampus when the animals were doing a task (release the lever at a specific frequency to obtain a reward). However, without a task demand they found that hippocampal neurons did not encode the audio sequence beyond chance levels. This is at odds with our findings with the movie where we see strong tuning despite any task demand or reward. These results are consistent with but go far beyond our recent findings that hippocampal (CA1) neurons can encode the position and direction of motion of a revolving bar of light (Purandare et al. Nature 2022). Please see Ln 373-382 for related discussion.</p><p>These responses are unlikely to be mere sequence responses since the scrambled sequence was also fixed sequence that was presented many times and it elicited reliable responses in visual areas, but not in hippocampus. Hence, we hypothesize that hippocampal areas encode temporally related information, i.e. episodic content. We have modified the discussion to address these points.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>1. Are LFP data available in the data set? If so, can SWRs identified and removed to refine the quantification of movie fields?</p></disp-quote><p>Done, see Figure 1-figure supplement 6.</p><disp-quote content-type="editor-comment"><p>1. Can movie fields be analyzed in re-arranged neural responses (Fig. 4e) and compared to those in other cases already shown (Fig. 4b, c)?</p></disp-quote><p>Done, even after rearrangement the strength of movie tuning for the scrambled presentation was low, and below 5% in all hippocampal regions. See Figure 4-figure supplement 5 for details.</p><disp-quote content-type="editor-comment"><p>1. It seems the authors are not fully committed to a main conclusion in the present manuscript. The title and abstract seem to emphasize the similar movie responses across visual and hippocampal areas, but the introduction and discussion emphasize the episode encoding of hippocampal neurons. The writing could be more consistent and the main message could be clearer.</p></disp-quote><p>Selective responses to the continuous movie showed similar patterns (prevalence of tuning, multi-peaked nature, relation with frame to frame changes in visual images) between visual and hippocampal regions. But the visual responses to scrambled presentation could be rearranged, and the latency for rearrangement increased from LGN to V1 to AM-PM. On the other hand, selectivity to the scrambled presentation was virtually abolished in hippocampus, and responses could not be rearranged to resemble the continuous movie sequences. To reconcile these differences, we have hypothesized here that the hippocampal responses are episodic in nature, and rely on temporal continuity, whereas the visual regions rely directly on the visual content in the images.</p><disp-quote content-type="editor-comment"><p>1. Line #158: &quot;Net movie-field discharges was also comparable across brain areas...&quot;. This statement is not supported by Fig. 2g, which shows a wide range of median values across brain areas.</p></disp-quote><p>Thank you for pointing this out. The normalized firing in movie-fields used in that figure are within 3x between V1 and subiculum. We have modified the text to contrast this with the 10x difference between movie-field durations.</p><disp-quote content-type="editor-comment"><p>1. Line #253: What the two numbers (87.8%, 10.6%) mean is unclear (mean or median values). These numbers also appear inconsistent with the mean+-se values in Fig. 4 legend.</p></disp-quote><p>The numbers mentioned on Ln253, in the main text reflect the median visual continuity index, combining across cells from hippocampal or visual regions. On the other hand, values reported in the Fig 4 legend are for V1 and subiculum, which are the regions with smallest and largest visual continuity index, respectively. We have re-written the main text, and legends for better clarity.</p><disp-quote content-type="editor-comment"><p>1. The Gelbard-Sagiv et al paper (Science 322: 96-101, 2008) could be cited and its relevance to the present study could be discussed.</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>1. Are there neurons recorded from a non-visual sensory or motor cortical area in the same experiment? This may provide a key negative control for the non-specific modulation caused by behavioral states or visual transients.</p></disp-quote><p>Owing to the nature of the experiments where the Allen Institute intended to study visual processing, we could not find any of the recorded brain regions without movie selectivity.</p><disp-quote content-type="editor-comment"><p>1. The differences in hippocampal and visual move fields between active and stationary time periods could be explicitly quantified.</p></disp-quote><p>We have shown several raster plots where the responses are quite similar during immobile and moving epochs. Our goal is to show that there is indeed comparable movie tuning when the animals is immobile versus any random state. Doing specific analysis of behavioral dependency is difficult because in many sessions the amount of time the mice ran in many sessions was very little. A thorough analysis overcoming these, and other challenges is beyond the scope of this paper.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>1. The methods to determine the boundaries of the movie-fields should be clarified, and the detected peaks and boundaries should be indicated in the relevant figures (e.g., Fig. 2c, 2d, and 2h) to help readers clearly understand how the movie-fields were defined and how the shapes of the movie-fields look like.</p></disp-quote><p>Done.</p><disp-quote content-type="editor-comment"><p>1. When testing the influence of locomotion on movie-tuning in Extended Data Fig. 3, a single cell-based analysis is further needed. For example, you need to check whether the z-scored sparsity within one cell varies or not depending on locomotion conditions (as in Extended Data Fig. 10a-c). In addition, it is recommended to exclude the cells significantly modulated by locomotion (e.g., running velocity) before defining the movie-tuned cells.</p></disp-quote><p>We now show example cells from sessions with or without prolonged running bouts in Figure 1-figure supplement 7 that have strong movie selectivity. We have also assessed the effects of theta power and pupil dilation on movie tuning in that figure. A more thorough analysis of the combined effects of locomotion and movie tuning is underway, but beyond the scope of the current work.</p><disp-quote content-type="editor-comment"><p>1. Regarding the time-cell-related issue raised in the public review, it would be nice if the authors confirm whether the tiling patterns of hippocampal subregions have been weakened by presenting the population activities for the scrambled condition as in the visual cortices in Extended Data Fig. 11a.</p></disp-quote><p>We have clarified in the earlier responses, please see above.</p><disp-quote content-type="editor-comment"><p>1. In Fig. 4 and Extended Data Fig. 3, the proportion of movie-tuned cells in the hippocampus seems to drop significantly after only a portion of trials under specific conditions were extracted. Although the authors addressed the stability issue by comparing the neural responses between even and odd trials, the concern about whether the movie-tuning is driven by a certain portion of trials still remains. To avoid such misunderstanding, as mentioned in comment no.2, tracking the changes in the z-scored sparsity of one cell between continuous and scrambled conditions should be provided. In addition, according to the methods, the scrambled condition was divided into two blocks of 10 trials each, possibly causing premature movie-tuned activities. Thus, it should be more appropriate to compare with the first 10 trials of each block in the continuous condition.</p></disp-quote><p>Done.</p><disp-quote content-type="editor-comment"><p>1. Explanations related to statistical analysis should be added to the methods sections. In Fig. 2a (and related figures with similar analysis), when comparing three or more groups, the Kruskal-Wallis test should be performed first to check whether there is a difference between the groups, and then pairwise comparisons should follow with adjusted p-values for multiple comparisons. Also, in Fig. 4b (and related figures), it seems that the K-S test was performed to test the changes in cell proportion by combining all brain regions, as far as I understand. However, it would be more appropriate to test the proportional changes by a Chi-square test within each region since the total numbers of cells should differ across the regions.</p></disp-quote><p>Yes, we have used the KS test throughout the analyses, unless otherwise mentioned or appropriate.</p><disp-quote content-type="editor-comment"><p>1. The labeling for firing rate is 'FR (sp/sec)' in Fig. 1, 2, and 4, but it is 'Firing rate (Hz)' in Fig. 3.</p></disp-quote><p>This has been fixed now, and only Firing rate (Hz), is used throughout. Thank you for pointing this out.</p><disp-quote content-type="editor-comment"><p>1. There is a typo in Extended Data Fig. 11b. &quot;... across all tuned responses from (b).&quot; It should be (a) instead of (b).</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>While the study presents an interesting dataset and conceptual approach, there are ways in which the manuscript should be strengthened.</p><p>Minor concerns:</p><p>1. Related to point (5) above, what content did the hippocampal &quot;movie fields&quot; encode? It would add a substantive dimension to the paper if the authors included examples of what segments of the movie the cells responded to. Are there &quot;pan left&quot; cells, or &quot;man gets in the car&quot; cells? Or was it more arbitrary than that? What is an example of a movie feature lasting 50ms that is stably encoded by a mouse hippocampal neuron?</p></disp-quote><p>We show example cells with very sharply tuned neural responses (Figure 2h). A thorough analysis of the visual content is in progress but beyond the scope of this paper.</p><disp-quote content-type="editor-comment"><p>1. Line 24-seems like it should read &quot;Consistent presentation of the movie...&quot; , with &quot;ly&quot; dropped from &quot;consistent&quot;.</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>1. Line 43-seems to be missing the article &quot;a&quot;, and should read &quot;...despite strong evidence for A hippocampal role in...&quot;.</p></disp-quote><p>We rewrote this sentence for better clarity</p><disp-quote content-type="editor-comment"><p>1. Line 54-to clarify, the higher visual areas recorded were the anteromedial (AM) and posterior-medial (PM) areas? The text additionally indicates a &quot;medio-lateral&quot; extrastriate area, but there is no such area. Can the text be revised to clear this up?</p></disp-quote><p>Sorry about this confusion, indeed we meant posterior-medial (PM). Thank you for pointing this out.</p><disp-quote content-type="editor-comment"><p>1. Line 84, &quot;rate&quot; should be pluralized to &quot;rates&quot;.</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>1. Line 108- the extra &quot;But&quot; at the start of the sentence should be removed.</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>1. Figure 2h-was there any particular arrangement for the cells in this sub-panel? If not, could they be grouped by sub-region (or proximity between sub-regions) so it appears less arbitrary?</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>1. Extended data 2 figure legend for (b) is missing a &quot;that&quot;: &quot;Fraction of selective neurons that was significantly above chance.... Ranging from 7.1% in CA</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>1. Line 144-145, there is an extra &quot;and&quot; in the sentence: &quot;.... were typically neither as narrow AND nor as prominent....&quot;</p></disp-quote><p>Done</p><disp-quote content-type="editor-comment"><p>1. Line 203-the first word in the line should be &quot;frames&quot; (plural).</p></disp-quote><p>Done, thank you for pointing this out</p><disp-quote content-type="editor-comment"><p>1. Line 281-in &quot;...scrambled sequence&quot;-&quot;sequence&quot; should be plural. It looks like the same is true in line 882, in the legend title for Extended Data Fig. 11.</p></disp-quote><p>Since we only showed one scrambled sequence (which was repeated 20 times), we rewrote the relevant lines to be “the scrambled sequence”</p><disp-quote content-type="editor-comment"><p>1. Line 923-the first sentence of the legend for Extended Data Fig. 14-to what data or study are the authors referring to in saying that &quot;More than 50% of hippocampal place cells shut down during maze exploration.&quot;? This was confusing, please clarify.</p></disp-quote><p>This reference has now been added.</p></body></sub-article></article>