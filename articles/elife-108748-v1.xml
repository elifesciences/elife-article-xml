<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">108748</article-id><article-id pub-id-type="doi">10.7554/eLife.108748</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108748.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Medicine</subject></subj-group></article-categories><title-group><article-title>Are peer reviewers influenced by their work being cited?</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Barnett</surname><given-names>Adrian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6339-0374</contrib-id><email>a.barnett@qut.edu.au</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03pnv4752</institution-id><institution>School of Public Health and Social Work, Queensland University of Technology</institution></institution-wrap><addr-line><named-content content-type="city">Brisbane</named-content></addr-line><country>Australia</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Rodgers</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04rjz5883</institution-id><institution>eLife</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Rodgers</surname><given-names>Peter</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04rjz5883</institution-id><institution>eLife</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>23</day><month>12</month><year>2025</year></pub-date><volume>14</volume><elocation-id>RP108748</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2025-08-14"><day>14</day><month>08</month><year>2025</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2025-08-19"><day>19</day><month>08</month><year>2025</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.31219/osf.io/wdvr9_v2"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-09-22"><day>22</day><month>09</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.108748.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-11-20"><day>20</day><month>11</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.108748.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-11-28"><day>28</day><month>11</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.108748.3"/></event></pub-history><permissions><copyright-statement>© 2025, Barnett</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Barnett</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-108748-v1.pdf"/><abstract><p>Peer reviewers sometimes comment that their own journal articles should be cited by the journal article under review. Comments concerning relevant articles can be justified, but comments can also be unrelated coercive citations. Here, we used a matched observational study design to explore how citations influence the peer review process. We used a sample of more than 37,000 peer reviews from four journals that use open peer review and make all article versions available. We find that reviewers who were cited in versions after version 1 were more likely to make a favourable recommendation (odds ratio = 1.61; adjusted 99.4% CI: 1.16–2.23), whereas being cited in the first version did not improve their recommendation (odds ratio = 0.84; adjusted 99.4% CI: 0.69–1.03). For all versions of the articles, the reviewers who commented that their own articles should be cited were less likely to recommend approval compared to the reviewers who did not, with the strongest association after the first version (odds ratio = 0.15; adjusted 99.4% CI: 0.08–0.30). Reviewers who included a citation to their own articles were much more likely to approve a revised article that cited their articles compared to a revised article that did not (odds ratio = 3.5; 95% CI: 2.0–6.1). Some reviewers’ recommendations depend on whether they are cited or want to be cited. Reviewer citation requests can turn peer review into a transaction rather than an objective critique of the article.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>Peer review is an integral part of scientific publishing in which active researchers – who may also serve as editors at scientific journals – review and assess the standard of submitted research. Peer review is therefore central to science, as it determines which articles are published in high-profile journals, and in turn, influences the careers of scientists.</p><p>Reviewers are expected to be relevant experts in the field of research they are reviewing. But this can sometimes create a conflict of interest as the reviewers’ own articles may be cited in the manuscript under review, which could influence their peer review. Conversely, reviewers whose work is not cited may feel that relevant work has been overlooked and may suggest their own papers be added – a practice that has been exploited in the past.</p><p>To find out whether citations influence peer review recommendations, Barnett analysed more than 37,000 peer reviews from four journals that operate fully open peer review, making all versions of submitted manuscripts and reviews publicly available. Using a matched design, he compared two or more reviewers who evaluated the same manuscript.</p><p>The analysis showed that being cited in the first round of review did not increase the likelihood of a favourable recommendation. However, in the second round of review, reviewers who were cited were more likely to approve the article. Contrary, reviewers who requested a citation to their own work were much less likely to approve the article.</p><p>However, a similar pattern was observed for reviewers who suggested citing work other than their own. This indicates that some citation requests may reflect legitimate concerns about missing context rather than purely self-serving behaviour.</p><p>These findings provide valuable insights into how the peer review process can be improved. Some journals – including those analysed by Barnett have already taken steps to reduce inappropriate requests for citations from reviewers. Other journals could consider implementing automated systems to flag self-citation requests, which could help improve the fairness and integrity of peer review systems, ultimately benefiting both scientists and science.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>peer review</kwd><kwd>meta-research</kwd><kwd>citations</kwd><kwd>research misconduct</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><funding-statement>No external funding was received for this work.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Some requests by reviewers to cite their own publications are coercive and can unnecessarily delay indexation and publication.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In 2024, a published peer-reviewed article included this remarkable sentence: ‘As strongly requested by the reviewers, here we cite some references (35-47) although they are completely irrelevant to the present work’ (<xref ref-type="bibr" rid="bib65">Yang et al., 2024</xref>). This was a rare public example of coerced citations, where a reviewer exploits the peer review process to increase their citation counts and hence further their own career (<xref ref-type="bibr" rid="bib46">Seeber et al., 2019</xref>; <xref ref-type="bibr" rid="bib17">Cranford, 2020</xref>; <xref ref-type="bibr" rid="bib12">Burton et al., 2024</xref>). Reviewers should be relevant experts, so some suggestions to cite their articles will be appropriate. However, excessive citation requests or requests to cite unrelated articles are unethical (<xref ref-type="bibr" rid="bib56">Teixeira da Silva, 2017</xref>; <xref ref-type="bibr" rid="bib16">Committee on Publication Ethics, 2019</xref>; <xref ref-type="bibr" rid="bib64">Wren et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">Hamilton et al., 2020</xref>; <xref ref-type="bibr" rid="bib34">Mehregan and Moghiman, 2024</xref>). Coerced citations can also come from editors trying to boost their journal’s ranking (<xref ref-type="bibr" rid="bib33">Martin, 2013</xref>; <xref ref-type="bibr" rid="bib29">Heneberg, 2016</xref>; <xref ref-type="bibr" rid="bib24">Fong et al., 2023</xref>).</p><p>Coerced citations are reported as a common problem in peer review. In author surveys, two-thirds reported pressure from peer reviewers to cite unrelated articles (<xref ref-type="bibr" rid="bib49">Singh Chawla, 2019b</xref>) and 23% had experienced a reviewer that ‘required them to include unnecessary references to their publication(s)’ (<xref ref-type="bibr" rid="bib41">Resnik et al., 2008</xref>). Publishers have investigated whether ‘hundreds of researchers’ have manipulated the peer review process to increase their own citations (<xref ref-type="bibr" rid="bib48">Singh Chawla, 2019a</xref>). Some reviewers may be exploiting their power over authors who ‘have a strong incentive to […] accept all “suggestions” by the referees even if one knows that they are misleading or even incorrect’ (<xref ref-type="bibr" rid="bib26">Frey et al., 2009</xref>).</p><p>As reviewers are often in the same field as the article’s authors, they may already be cited in the article without the need for coerced citations. Reviewers who are cited may give a more favourable peer review and be more willing to overlook flaws (<xref ref-type="bibr" rid="bib45">Schriger et al., 2016</xref>; <xref ref-type="bibr" rid="bib51">Stelmakh et al., 2023</xref>). Some authors may try to exploit this using ‘referee baiting’ (<xref ref-type="bibr" rid="bib17">Cranford, 2020</xref>) or ‘flattery citations’ (<xref ref-type="bibr" rid="bib25">Frandsen and Nicolaisen, 2011</xref>) by favourably citing a reviewer’s work.</p><p>The interactions during peer review between authors and reviewers can determine whether an article is accepted (<xref ref-type="bibr" rid="bib50">Smith, 2006</xref>) and what results are included in the published version (<xref ref-type="bibr" rid="bib10">Bohorquez et al., 2025</xref>). Given the importance of peer review for science, studies that examine how peer review works in practice are needed (<xref ref-type="bibr" rid="bib32">Lee et al., 2013</xref>; <xref ref-type="bibr" rid="bib44">Schmidt et al., 2018</xref>; <xref ref-type="bibr" rid="bib57">Tennant and Ross-Hellauer, 2020</xref>; <xref ref-type="bibr" rid="bib1">Aczel et al., 2025</xref>; <xref ref-type="bibr" rid="bib62">Vendé et al., 2025</xref>). Here, we examine interactions between peer reviewers and authors using four journals that publish all article versions and all peer reviews. We had two research questions:</p><list list-type="order" id="list1"><list-item><p>Do peer reviewers give a more or less favourable recommendation when they are cited in the article?</p></list-item><list-item><p>Do peer reviewers give a more or less favourable recommendation when their review includes a citation to their own articles?</p></list-item></list></sec><sec id="s2" sec-type="results"><title>Results</title><p>A flow chart of the included reviews is shown in <xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>. The final sample size was over 37,000 reviews. There were more than 3500 articles that were not included because they had not yet been peer reviewed, especially recent articles. More than 2000 reviewers did not have a record in <italic>OpenAlex</italic> and so could not be included. These missing reviewers were more likely to be from older articles and more likely to be co-reviewers.</p><p>Descriptive statistics on the included reviews are in <xref ref-type="table" rid="table1">Table 1</xref>. The reviewers were cited at least once in 13% of the articles and 6% of the reviews included a self-citation. Most reviews recommended ‘Approved’ (54%), with only 8% recommending ‘Not approved’ which is low compared with many journals; however, 40–50% of submissions are rejected before articles are sent for peer review (personal communication, <italic>F1000</italic> staff).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Descriptive statistics for the articles and peer reviews.</title><p>Q1 = first quartile, Q3 = third quartile.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Variable</th><th align="left" valign="bottom">Level/statistics</th><th align="left" valign="bottom">Result</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of reviews</td><td align="left" valign="bottom"><italic>n</italic></td><td align="left" valign="bottom">37,332</td></tr><tr><td align="left" valign="bottom">Year</td><td align="left" valign="bottom">Median [<italic>Q</italic>1, <italic>Q</italic>3]</td><td align="left" valign="bottom">2022 [2019, 2024]</td></tr><tr><td align="left" valign="bottom">Journal, <italic>n</italic> (%)</td><td align="left" valign="bottom">F1000Research</td><td align="left" valign="bottom">24,132 (65)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Wellcome Open Research</td><td align="left" valign="bottom">8697 (23)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Open Research Europe</td><td align="left" valign="bottom">2789 (7)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Gates Open Research</td><td align="left" valign="bottom">1714 (5)</td></tr><tr><td align="left" valign="bottom">Role, <italic>n</italic> (%)</td><td align="left" valign="bottom">Reviewer</td><td align="left" valign="bottom">34,904 (93)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Co-reviewer</td><td align="left" valign="bottom">2428 (7)</td></tr><tr><td align="left" valign="bottom">Reviewer’s recommendation, <italic>n</italic> (%)</td><td align="left" valign="bottom">Approved</td><td align="left" valign="bottom">19,984 (54)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Reservations</td><td align="left" valign="bottom">14,379 (38)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Not approved</td><td align="left" valign="bottom">2969 (8)</td></tr><tr><td align="left" valign="bottom">Article version, <italic>n</italic> (%)</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">26,474 (71)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">2</td><td align="left" valign="bottom">8995 (24)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">3+</td><td align="left" valign="bottom">1863 (5)</td></tr><tr><td align="left" valign="bottom">Number of papers cited in article</td><td align="left" valign="bottom">Median [<italic>Q</italic>1, <italic>Q</italic>3]</td><td align="left" valign="bottom">24 [14, 38]</td></tr><tr><td align="left" valign="bottom">Any citations to reviewer, <italic>n</italic> (%)</td><td align="left" valign="bottom">No</td><td align="left" valign="bottom">32,375 (87)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Yes</td><td align="left" valign="bottom">4957 (13)</td></tr><tr><td align="left" valign="bottom">Any papers cited by reviewer, <italic>n</italic> (%)</td><td align="left" valign="bottom">No</td><td align="left" valign="bottom">31,546 (84)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Yes</td><td align="left" valign="bottom">5786 (16)</td></tr><tr><td align="left" valign="bottom">Any citations to the reviewer’s articles</td><td align="left" valign="bottom">No</td><td align="left" valign="bottom">35,023 (94)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Yes</td><td align="left" valign="bottom">2309 (6)</td></tr><tr><td align="left" valign="bottom">Reviewer’s publication count</td><td align="left" valign="bottom">Median [<italic>Q</italic>1, <italic>Q</italic>3]</td><td align="left" valign="bottom">55 [24, 118]</td></tr><tr><td align="left" valign="bottom">Reviewer’s country (top five only)</td><td align="left" valign="bottom">USA</td><td align="left" valign="bottom">7655 (21%)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">United Kingdom</td><td align="left" valign="bottom">4137 (11%)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">India</td><td align="left" valign="bottom">2472 (7%)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Italy</td><td align="left" valign="bottom">1368 (4%)</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Australia</td><td align="left" valign="bottom">1349 (4%)</td></tr><tr><td align="left" valign="bottom">Number of words in the review</td><td align="left" valign="bottom">Median [<italic>Q</italic>1, <italic>Q</italic>3]</td><td align="left" valign="bottom">202 [67, 411]</td></tr></tbody></table></table-wrap><p>The reviewers were relatively experienced, with a median number of papers of 55.</p><p>The binary predictor for citations of ‘any versus none’ had a generally better fit to the data compared to the linear predictor (<xref ref-type="table" rid="app3table1">Appendix 3—table 1</xref>). This indicates that for most reviewers, receiving any citation is important, and there is no linear increase for two or more citations. The following results are for the binary predictor ‘any versus none’, with the results using a linear predictor in <xref ref-type="fig" rid="app4fig1">Appendix 4—figure 1</xref>.</p><p>Reviewers who were cited were more likely to approve the article, but only after version 1 (<xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="table" rid="table2">Table 2</xref>). If a reviewer was cited in any versions after version 1, the odds ratio for recommending Approved versus Reservations or Not approved was 1.61 (adjusted 99.4% CI 1.16–2.23).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Odds ratios and probabilities for reviewers giving a more or less favourable recommendation depending on whether they were cited in the article.</title><p>Top left: Odds ratios for reviewers giving a more favourable (Approved) or less favourable (Reservations or Not approved) recommendation depending on whether they were cited in the article. Reviewers cited in later versions (blue) were more likely to make a favourable recommendation (odds ratio = 1.61; adjusted 99.4% CI: 1.16–2.23), whereas being cited in the first version (green) did not improve their recommendation (odds ratio = 0.84; adjusted 99.4% CI: 0.69–1.03). Top right: Same results as top left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which they are not cited (0.51; adjusted 99.4% CI: 0.49–0.52); a version 1 article in which they are cited (0.46; adjusted 99.4% CI: 0.41–0.51); a version 2 (or higher) article in which they are not cited (0.48; adjusted 99.4% CI: 0.45–0.51); and a version 2 (or higher) article in which they are cited (0.60; adjusted 99.4% CI: 0.53–0.65). Bottom left: Same estimates as top left except that a more favourable recommendation is now Approved or Reservations and a less favourable is Not approved. There was no clear association for cited reviewers in version 1 (odds ratio = 0.84; adjusted 99.4% CI: 0.57–1.23) or later versions (odds ratio = 1.12; adjusted 99.4% CI: 0.59–2.13). Bottom right: Same results as bottom left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which they are not cited (0.51; adjusted 99.4% CI: 0.48–0.53); a version 1 article in which they are cited (0.47; adjusted 99.4% CI: 0.35–0.55); a version 2 (or higher) article in which they are not cited (0.50; adjusted 99.4% CI: 0.43–0.55); and a version 2 (or higher) article in which they are cited (0.53; adjusted 99.4% CI: 0.34–0.63). This figure is based on an analysis of 12,051 articles and 24,677 reviews for version 1 and 6090 articles and 10,196 reviews for version 2+. In all panels, a dot or square represents a mean, and a horizontal line represents an adjusted 99.4% confidence interval.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-fig1-v1.tif"/></fig><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Odds ratios for reviewers giving a more (OR &gt;1) or less (OR &lt;1) favourable recommendation depending on whether they were cited in the article (question 1) or included citations to their own articles (question 2).</title><p>All models were split by article version.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Research question</th><th align="left" valign="bottom">Article version</th><th align="left" valign="bottom">Outcome</th><th align="left" valign="bottom">OR (adjusted 99.4% CI)</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="4">Reviewer cited by authors</td><td align="left" valign="bottom">Version = 1</td><td align="left" valign="bottom">Approved vs Reservations/Not approved</td><td align="left" valign="bottom">0.84 (0.69, 1.03)</td></tr><tr><td align="left" valign="bottom">Version = 1</td><td align="left" valign="bottom">Approved/Reservations vs Not approved</td><td align="left" valign="bottom">0.84 (0.57, 1.23)</td></tr><tr><td align="left" valign="bottom">Versions = 2+</td><td align="left" valign="bottom">Approved vs Reservations/Not approved</td><td align="left" valign="bottom">1.61 (1.16, 2.23)</td></tr><tr><td align="left" valign="bottom">Versions = 2+</td><td align="left" valign="bottom">Approved/Reservations vs Not approved</td><td align="left" valign="bottom">1.12 (0.59, 2.13)</td></tr><tr><td align="left" valign="bottom" rowspan="4">Reviewer cited their own articles</td><td align="left" valign="bottom">Version = 1</td><td align="left" valign="bottom">Approved vs Reservations/Not approved</td><td align="left" valign="bottom">0.57 (0.44, 0.73)</td></tr><tr><td align="left" valign="bottom">Version = 1</td><td align="left" valign="bottom">Approved/Reservations vs Not approved</td><td align="left" valign="bottom">1.11 (0.77, 1.60)</td></tr><tr><td align="left" valign="bottom">Versions = 2+</td><td align="left" valign="bottom">Approved vs Reservations/Not approved</td><td align="left" valign="bottom">0.15 (0.08, 0.30)</td></tr><tr><td align="left" valign="bottom">Versions = 2+</td><td align="left" valign="bottom">Approved/Reservations vs Not approved</td><td align="left" valign="bottom">0.80 (0.37, 1.74)</td></tr></tbody></table></table-wrap><p>Reviewers who included a citation to their own articles were much less likely to approve the article for all versions (<xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="table" rid="table2">Table 2</xref>). The odds ratio for recommending Approved versus Reservations or Not approved was 0.57 (99.4% CI 0.44–0.73) for version 1 and strengthened to 0.15 (99.4% CI 0.08–0.30) for versions 2+. The less favourable recommendation was only for the approval of the article and the odds ratios for Approved or Reservations versus Not approved were much closer to 1.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Odds ratios and probabilities for reviewers giving a more or less favourable recommendation if they included a citation to their own articles in their review.</title><p>Top left: Odds ratios for reviewers giving a more favourable (Approved) or less favourable (Reservations or Not approved) recommendation depending on whether their review included a citation to their own articles. Reviewers including a citation to their own articles were less likely to make a favourable recommendation for version 1 (green; odds ratio = 0.57; adjusted 99.4% CI: 0.44–0.73) and later versions (blue; odds ratio = 0.15; adjusted 99.4% CI: 0.08–0.30). Top right: Same results as top left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not include a citation (0.51; adjusted 99.4% CI: 0.50–0.53); a version 1 article in which in which their review included a citation (0.37; adjusted 99.4% CI: 0.29–0.44); a version 2 (or higher) article in which their review did not include a citation (0.51; adjusted 99.4% CI: 0.49–0.53); and a version 2 (or higher) article in which in which their review included a citation (0.14; adjusted 99.4% CI: 0.01–0.30). Bottom left: Same estimates as top left except that a more favourable recommendation is now Approved or Reservations and a less favourable is Not approved. There was no clear association for reviewers who included a citation to their own articles in version 1 (odds ratio = 1.11; adjusted 99.4% CI: 0.77–1.60) or later versions (odds ratio = 0.80; adjusted 99.4% CI: 0.37–1.74). Bottom right: Same results as bottom left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not include a citation (0.50; adjusted 99.4% CI: 0.48–0.52); a version 1 article in which their review included a citation (0.53; adjusted 99.4% CI: 0.43–0.60); a version 2 (or higher) article in which their review did not include a citation (0.51; adjusted 99.4% CI: 0.46–0.54); and a version 2 (or higher) article in which they included a citation (0.45; adjusted 99.4% CI: 0.12–0.61). This figure is based on an analysis of 12,078 articles and 24,732 reviews for version 1 and 6101 articles and 10,213 reviews for version 2+. In all panels, a dot or square represents a mean, and a horizontal line represents an adjusted 99.4% confidence interval.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-fig2-v1.tif"/></fig><p>In an unplanned analysis, we examined the behaviour of reviewers in the first two versions of the article. We examined the 441 reviews where the reviewer was not cited in version 1 of the article and included a citation to their own articles in their first review. The reviewers who were then cited in version 2 recommended approval for 92% compared to 76% for reviewers who were not cited (odds ratio = 3.5, 95% CI: 2.0–6.1). This analysis did not use matching.</p><p>In an unplanned analysis, we examined whether the reviewers’ recommendations depended on whether their review included citations to articles other than their own. Reviewers who included citations in their review were much more likely not to approve the article (<xref ref-type="fig" rid="fig3">Figure 3</xref>), which was similar to the association with citations to reviewers’ own articles (<xref ref-type="fig" rid="fig2">Figure 2</xref>). However, reviewers who included citations to articles other than their own were also much more likely to recommend ‘Not approved’, as shown by the lower odds of ‘Approved’ or ‘Reservations’ versus ‘Not approved’. This association was not seen using citations to reviewers’ own articles (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Odds ratios and probabilities for reviewers giving a more or less favourable recommendation depending on if they included citations to articles other than their own in their review.</title><p>Top left: Odds ratios for reviewers giving a more favourable (Approved) or less favourable (Reservations or Not approved) recommendation depending on whether their review included a citation to articles other than their own. Reviewers including citations to other articles were less likely to make a favourable recommendation for version 1 (green; odds ratio = 0.53; adjusted 99.4% CI: 0.44–0.64) and later versions (blue; odds ratio = 0.18; adjusted 99.4% CI: 0.10–0.30). Top right: Same results as top left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not cite other articles (0.53; adjusted 99.4% CI: 0.51–0.54); a version 1 article in which their review cited other articles (0.37; adjusted 99.4% CI: 0.31–0.42); a version 2 (or higher) article in which their review did not cite other articles (0.52; adjusted 99.4% CI: 0.50–0.54); and a version 2 (or higher) article in which in which their review cited other articles (0.17; adjusted 99.4% CI: 0.02–0.30). Bottom left: Same estimates as top left except that a more favourable recommendation is now Approved or Reservations and a less favourable is Not approved. Reviewers including citations to other articles were less likely to make a favourable recommendation for version 1 (odds ratio = 0.62; adjusted 99.4% CI: 0.46–0.84) and later versions (odds ratio = 0.34; adjusted 99.4% CI: 0.16–0.73). Bottom right: Same results as bottom left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not cite other articles (0.52; adjusted 99.4% CI: 0.49–0.54); a version 1 article in which their review cited other articles (0.41; adjusted 99.4% CI: 0.31–0.48); a version 2 (or higher) article in which their review did not cite other articles (0.52; adjusted 99.4% CI: 0.47–0.55); and a version 2 (or higher) article in which their review cited other articles (0.27; adjusted 99.4% CI: 0.02–0.45). This figure is based on an analysis of 12,078 articles and 24,732 reviews for version 1 and 6101 articles and 10,213 reviews for version 2+. In all panels, a dot or square represents a mean, and a horizontal line represents an adjusted 99.4% confidence interval.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-fig3-v1.tif"/></fig><sec id="s2-1"><title>Sensitivity analyses</title><p>The odds ratios when including co-reviewers with reviewers were similar to the odds ratios when using reviewers only (<xref ref-type="fig" rid="app5fig1">Appendix 5—figures 1</xref> and <xref ref-type="fig" rid="app5fig2">2</xref>).</p><p>We found no evidence that the reviewers’ publication numbers or country confounded the associations between citations and recommendations (<xref ref-type="fig" rid="app6fig1">Appendix 6—figures 1</xref>–<xref ref-type="fig" rid="app6fig4">4</xref>).</p></sec><sec id="s2-2"><title>Text analyses of reviewers’ comments</title><p>A random sample of how reviewers included citations to their own articles found some vague justifications (<xref ref-type="table" rid="app7table1">Appendix 7—table 1</xref>); for example, ‘Here are some additional publications you might consider referencing’. Other sentences adhered to the publisher’s guidelines for reviewers, as specific reasoning was provided for citations to their own articles (<xref ref-type="bibr" rid="bib64">Wren et al., 2019</xref>). One reviewer thanked the authors for a previous citation. Three reviews did not have a relevant sentence. One reviewer likely used AI to write their review as it included the phrase ‘Certainly! Here are some potential review questions for the manuscript’ (<xref ref-type="bibr" rid="bib35">Monadhel et al., 2023</xref>); this review included six self-citations with no justifications.</p><p>Reviewers who included a citation to their own articles or other articles were more likely to use the words ‘need’ and ‘please’ when not approving the article (<xref ref-type="fig" rid="fig4">Figure 4</xref>). In contrast, the words ‘genome’ and ‘well’ were the most strongly associated with the reviewers’ approval.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Words in the reviewers’ comments that were associated with approving the article or not for reviewers who included a citation to their own articles (<inline-formula><alternatives><mml:math id="inf1"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2025</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$n=2025$\end{document}</tex-math></alternatives></inline-formula>) and reviewers who included citations to other articles (<inline-formula><alternatives><mml:math id="inf2"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>4350</mml:mn></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}$n=4350$\end{document}</tex-math></alternatives></inline-formula>).</title><p>The words were selected using an elastic net that started with the 100 most commonly used review words. The estimates from the elastic net are shown as empty circles and the mean estimates and 95% credible intervals from a Bayesian model are shown as a solid circle and horizontal line. Words are shown if the probability of a non-zero mean was over 0.95 for either reviewers who cited their own articles or reviewers who cited other articles. Four words were selected by the elastic net for the reviewers who cited other articles but not by the elastic net for reviewers who cited their own articles. The axis label shows the stemmed word and most common whole word in brackets.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-fig4-v1.tif"/></fig><p>To examine how often open peer reviews were viewed, we took a random sample of 200 reviews from the four journals and found that, on average, they were viewed just 1.2 times per year (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our results provide evidence that some reviewers have a transactional view of peer review, with their final approval dependent on citations to their work. Some reviewers may be exploiting the pressure on authors to ‘publish or perish’. Under this pressure, many authors may oblige and add the suggested citations, especially since adding another citation may only require a minor edit to their article (<xref ref-type="bibr" rid="bib36">Oviedo-García, 2024</xref>). Both sides gain from this transaction, as the authors get an indexed publication and the reviewer gets a citation.</p><p>A key question is whether citations to a reviewer’s own articles are justified as they may highlight important errors or missing context in the article. Citations to a reviewer’s own articles can be justified when the authors have made a ‘large scholarly oversight’ (<xref ref-type="bibr" rid="bib28">Hamilton et al., 2020</xref>). To investigate this, we compared the recommendations and wording of reviewers who included citations to their own articles to reviewers who included citations to other articles. The language used by the reviewers of these two groups was similar, with a higher use of ‘please’ and ‘need’ when not approving the article (<xref ref-type="fig" rid="fig4">Figure 4</xref>). However, there was a difference between groups in their recommendations, as reviewers including citations to other articles were more likely to recommend ‘Not approved’ (<xref ref-type="fig" rid="fig3">Figure 3</xref>) whereas this association was not observed for reviewers including citations to their own articles (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This indicates that missing citations to other articles were considered more serious than missing citations to the reviewer’s articles. Reviewers who cited their own articles may have been more inclined to give authors a chance to update their article and thus potentially include the ‘missing’ citation(s).</p><p>Examining the context of the citations to reviewers’ own articles, we found vague or non-existent justifications (<xref ref-type="table" rid="app7table1">Appendix 7—table 1</xref>), showing that some reviewers ignored the journals’ guidelines to state their reasoning when including citations to their own articles. However, these examples of poor justifications do not mean that all self-citations are coercive.</p><p>For both research questions, the effects were stronger for the second and later versions of the article than for the first version. Reviewers may understand that authors may be more willing to compromise on later versions when they are closer to obtaining an indexed publication. Most researchers understand that the peer review system is imperfect and that they sometimes have to make compromises to be successful (<xref ref-type="bibr" rid="bib50">Smith, 2006</xref>; <xref ref-type="bibr" rid="bib2">Anderson et al., 2007</xref>). Another difference to consider is that later versions will include more articles with disagreements between reviewers and more that were not ‘Approved’ in the first version, as articles where two or more reviewers recommended ‘Approved’ may not have needed a second version.</p><sec id="s3-1"><title>Potential improvements to peer review</title><p>Journals could give stronger guidance to reviewers and authors on coercive citations (<xref ref-type="bibr" rid="bib12">Burton et al., 2024</xref>). However, given the limited time for peer review and the many differences in guidelines between journals (<xref ref-type="bibr" rid="bib47">Seeber, 2020</xref>), most authors may not read peer review instructions. Hence, guidance alone may have limited impact.</p><p>One suggestion is that reviewers declare to editors when they have recommended citations to their own work (<xref ref-type="bibr" rid="bib59">Thombs and Razykov, 2012</xref>). A useful innovation would be for all reviews that contain citations to the reviewer’s own articles to be automatically flagged to the editors who could check if the citations are justified. We are aware of one journal where this is already happening (personal communication, Benno Torgler).</p><p><italic>F1000</italic> has recently introduced checks to prevent reviewers from publishing a review with three or more citations to the reviewer’s own articles. If the reviewers continue to request more than three, then the review is examined, and if the citations are deemed inappropriate and the reviewer declines to remove them, then the review is declined.</p><p>Open peer review has been suggested as a way to reduce coercive citations (<xref ref-type="bibr" rid="bib59">Thombs and Razykov, 2012</xref>; <xref ref-type="bibr" rid="bib64">Wren et al., 2019</xref>). However, our results from four journals that use open review show that it is not a perfect antidote, although the problem could be worse in journals using blinded peer review. The transparency of open peer review should prevent reviewers from leaving self-serving comments; however, we found some dubious justifications for self-citations and blatant use of AI (<xref ref-type="table" rid="app7table1">Appendix 7—table 1</xref>). These reviewers may have rationalised that although their words are public, they are rarely scrutinised (<xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref>); hence, it was worth the risk. The assumed additional quality assurance from open peer review (<xref ref-type="bibr" rid="bib42">Ross-Hellauer et al., 2017</xref>) may often be absent.</p><p>A more radical change to peer review is that the reviewers initially see a version of the article with all references blinded and no reference list; for example, ‘A strong association between increased cleaning and reduced hospital infection is well established [x]’. Reviewers are asked to give an initial recommendation and comments, and then are shown the version with the full references and asked if they need to update their recommendation or provide additional comments. However, this involves more administrative work and demands more from peer reviewers. This approach could be used for particularly consequential or controversial articles. Some journals already require authors to partially blind their articles to maintain anonymous peer review; for example, the instructions from <italic>Taylor &amp; Francis</italic> include blinding the authors’ names in the reference list (<xref ref-type="bibr" rid="bib55">Taylor and Francis, 2025</xref>).</p><p>An argument could be made for using large language models to provide peer review that is unmoved by citation flattery. However, peer review is an inherently human task by peers, and instead, we need to improve peer review rather than abdicating this often difficult and time-consuming task to machines (<xref ref-type="bibr" rid="bib8">Bergstrom and Bak-Coleman, 2025</xref>).</p></sec><sec id="s3-2"><title>Related research</title><p>Previous cross-sectional studies of self-citations in reviews found at least one self-citation in 3% at a journal that used blinded peer review (<xref ref-type="bibr" rid="bib45">Schriger et al., 2016</xref>), 12% at a journal that used blinded peer review (<xref ref-type="bibr" rid="bib60">Thombs et al., 2015</xref>), and 12% at a journal that used open peer review (<xref ref-type="bibr" rid="bib38">Peebles et al., 2020</xref>). A related study found that 15% of reviews included a self-citation and that the self-citations were highest when the reviewer recommended ‘major revisions’ (<xref ref-type="bibr" rid="bib52">Sugimoto and Cronin, 2013</xref>). These figures are comparable with the 6% found here and indicate that most reviews do not include self-citations.</p><p>Previous surveys estimated that 14% and 20% of authors had experienced a coercive citation request from an editor (<xref ref-type="bibr" rid="bib23">Fong and Wilhite, 2017</xref>; <xref ref-type="bibr" rid="bib63">Wilhite and Fong, 2012</xref>), and 7% and 23% had experienced coercive citation pressure from a reviewer (<xref ref-type="bibr" rid="bib30">Ho et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Resnik et al., 2008</xref>). The frequency with which researchers interact with peer review means that many will encounter coercive citations at some point in their career.</p><p>A study of conference submissions estimated that reviewers who were cited gave submissions much higher scores (<xref ref-type="bibr" rid="bib51">Stelmakh et al., 2023</xref>). A study of journal peer review estimated that cited reviewers scored the article higher, but with potential confounding by the quality of the article (<xref ref-type="bibr" rid="bib45">Schriger et al., 2016</xref>).</p><p>A survey of authors concluded that accepting an editor’s request for citations improved the chances of being accepted (<xref ref-type="bibr" rid="bib24">Fong et al., 2023</xref>). Requests in later versions were more strongly associated with acquiescence, and we found a related pattern in our analysis, with reviewers who included citations to their own articles being much less likely to recommend approval for later versions (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><p>A study examining open peer review found that requests to cite the reviewer’s articles were more likely to be included than other suggested citations, indicating that many authors wanted to please the reviewer or felt pressure to do so (<xref ref-type="bibr" rid="bib38">Peebles et al., 2020</xref>).</p><p>A survey of journal editors found that only 5% objected to reviewers citing their own articles, and that this should be expected as reviewers are likely to have done related work (<xref ref-type="bibr" rid="bib28">Hamilton et al., 2020</xref>).</p><p>A cross-sectional study found that reviewers' citations to their own articles were more likely to have no rationale compared to other citations, suggesting that they are more likely to be unwarranted (<xref ref-type="bibr" rid="bib60">Thombs et al., 2015</xref>).</p></sec><sec id="s3-3"><title>Strengths and limitations</title><p>This is an observational study, meaning we cannot rule out unmeasured confounding and should be cautious in interpreting the results.</p><p>To our knowledge, this is the first analysis to use a matched design and analysis when examining reviewer citations, and hence strongly control for any confounding by the characteristics of the authors or articles. We compared reviewers who examined an identical article; hence, the differences we found should be due to the reviewers.</p><p>Our models include measurement error, as some citations to the reviewers’ work will be missed by our data collection, and some captured citations will be inaccurate (<xref ref-type="bibr" rid="bib37">Pavlovic et al., 2021</xref>). We performed random data checks that showed good accuracy (<xref ref-type="fig" rid="app9fig1">Appendix 9—figure 1</xref>); however, we also found valid citations that were not captured by our data extraction for conference proceedings and technical reports, which are less likely to have a DOI. This measurement error would most likely underestimate a true association, as it reduced the variance in citation counts and created a regression dilution (<xref ref-type="bibr" rid="bib14">Clarke et al., 1999</xref>). Our estimates will be biased if the associations between citations and reviewers’ recommendations are different for publications that do not have a DOI. Reviewers should be equally happy with any citation to their work; however, some reviewers may prefer citations to indexed articles, as these are more likely to count towards their h-indices (<xref ref-type="bibr" rid="bib22">Fire and Guestrin, 2019</xref>).</p><p>We examined whether citing a reviewer altered their recommendation, but did not examine the sentiment of the citation (<xref ref-type="bibr" rid="bib53">Tahamtan and Bornmann, 2019</xref>). Some citations would likely have been critical of the reviewer’s articles, and we would expect these to reduce the chances of a favourable recommendation. An analysis that included the sentiment of the citation would be useful, although previous research found that most citations are neutral or positive (<xref ref-type="bibr" rid="bib53">Tahamtan and Bornmann, 2019</xref>).</p><p>We did not examine the authors’ responses to the reviewers, but these could include important information on why a citation was included or not in a revised version of the article. A detailed analysis examining the text used in the interactions between authors and reviewers could provide valuable information about the peer review process.</p><p>Our results may not be generalisable to journals that use blinded peer review or journals that use the traditional peer review model rather than the publish–review–curate model studied here.</p><p>A previous study found that asking reviewers to consent to an open review had no important effect on the quality of the review or the reviewers’ recommendation (<xref ref-type="bibr" rid="bib61">van Rooyen et al., 1999</xref>).</p><p>Another potential difference is that the journals in our sample often asked the authors to suggest peer reviewers; however, this is relatively common in other journals (<xref ref-type="bibr" rid="bib28">Hamilton et al., 2020</xref>).</p><p>We found a bias in our sample, as co-reviewers and reviewers from older articles were more likely to be excluded due to not having an <italic>OpenAlex</italic> record (<xref ref-type="fig" rid="app2fig1">Appendix 2—figure 1</xref>). We therefore lost more junior reviewers who were less likely to be cited. The percentage of reviews lost was 5% (2026 of 39,113), which is hopefully small enough to avoid a large bias.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Journal selection</title><p>We studied journals from the publisher <italic>F1000</italic> as their journals use open peer review with signed reviewers. <italic>F1000</italic> journals use a publish–review–curate model (<xref ref-type="bibr" rid="bib19">Currie, 2024</xref>), meaning all versions of the article are publicly available, including versions updated after peer review. This allowed us to examine the interactions between authors and reviewers throughout the peer review process. We selected four <italic>F1000</italic> journals that each had over 100 articles. Some characteristics of the four journals are given in <xref ref-type="table" rid="table3">Table 3</xref>. Three journals were created to support funders.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Brief information about the four included journals from the publisher <italic>F1000</italic>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Journal title</th><th align="left" valign="bottom">Year started</th><th align="left" valign="bottom">Field(s) of research</th><th align="left" valign="bottom">Articles must concern research funded by</th></tr></thead><tbody><tr><td align="left" valign="bottom">F1000Research</td><td align="char" char="." valign="bottom">2012</td><td align="left" valign="bottom">All disciplines</td><td align="left" valign="bottom"><italic>No restriction</italic></td></tr><tr><td align="left" valign="bottom">Wellcome Open Research</td><td align="char" char="." valign="bottom">2016</td><td align="left" valign="bottom">Medicine, Genomics</td><td align="left" valign="bottom">Wellcome</td></tr><tr><td align="left" valign="bottom">Gates Open Research</td><td align="char" char="." valign="bottom">2017</td><td align="left" valign="bottom">Medicine</td><td align="left" valign="bottom">The Gates Foundation</td></tr><tr><td align="left" valign="bottom">Open Research Europe</td><td align="char" char="." valign="bottom">2021</td><td align="left" valign="bottom">All disciplines</td><td align="left" valign="bottom">European Commission</td></tr></tbody></table></table-wrap><p>The peer review process used by <italic>F1000</italic> journals differs from most standard journals. The journals do not use academic editors, but do have in-house editors who manage articles but do not make editorial decisions. This means that most interactions during peer review are between authors and reviewers directly. In-house editors perform checks prior to the first version of the article being published and at <italic>F1000Research</italic> this results in 40–50% submissions being rejected (personal communication, <italic>F1000</italic> staff).</p><p>Up to mid-2024, authors were asked to identify potential reviewers who were qualified experts with no competing interests (<xref ref-type="bibr" rid="bib20">F1000Research, 2025a</xref>). Since mid-2024, reviewer identification is made in-house, although authors can suggest reviewers.</p><p>Reviewers are asked to recommend one of three categories: Approved, Approved with reservations, and Not approved. For brevity, we refer to ‘Approved with Reservations’ as ‘Reservations’. An article is indexed once it receives two ‘Approved’ or two ‘Reservations’ and one ‘Approved’. The guidelines for recommending Approved are: ‘the aims and research methods are adequate; results are presented accurately, and the conclusions are justified and supported by the presented data’ (<xref ref-type="bibr" rid="bib21">F1000Research, 2025b</xref>). Peer reviewers are asked to assess the validity of an article’s content, rather than novelty or interest levels, an approach designed to combat publication bias (<xref ref-type="bibr" rid="bib7">Begg and Berlin, 1988</xref>).</p><p>All four journals have a peer reviewer code of conduct and state that reviewers should familiarise themselves with the ethical guidelines for peer reviewers by the <xref ref-type="bibr" rid="bib15">Committee on Publication, 2017</xref>. The journals’ guidelines for reviewers include the following: ‘reviewers should explicitly state their reasoning when asking authors to cite their own work’.</p></sec><sec id="s4-2"><title>Data extraction</title><p>We extracted data on authors and articles from the <italic>OpenAlex</italic> database (<ext-link ext-link-type="uri" xlink:href="https://openalex.org/">https://openalex.org/</ext-link>) and directly from the four journals. <italic>OpenAlex</italic> combines scholarly data from multiple sources, including <italic>ORCID</italic> – a unique identifier for researchers, <italic>Microsoft Academic</italic>, <italic>Crossref</italic> and <italic>PubMed</italic>. A recent study compared <italic>OpenAlex</italic> with the two commonly used proprietary bibliometric databases of <italic>Web of Science</italic> and <italic>Scopus</italic> for the years 2015–2022 (<xref ref-type="bibr" rid="bib18">Culbert et al., 2025</xref>). The results were mixed, but <italic>OpenAlex</italic> had better <italic>ORCID</italic> coverage and covered more Digital Object Identifiers (DOIs) – the unique identifier for publications. We accessed <italic>OpenAlex</italic> using the <italic>openalexR</italic> package (<xref ref-type="bibr" rid="bib39">Priem et al., 2022</xref>; <xref ref-type="bibr" rid="bib3">Aria et al., 2024</xref>). We used each journal’s application programming interface (API) to extract data on the articles and peer reviews. The data were extracted in four stages:</p><list list-type="order" id="list2"><list-item><p>Searches were made using the APIs of the four journals to find all articles published between 1 Jan 2012 and 28 May 2025, with the start date to capture all potential articles.</p></list-item><list-item><p>For each article, the following data were downloaded in XML format:</p><list list-type="bullet" id="list2subList1"><list-item><p>The article’s publication date and version number</p></list-item><list-item><p>The reviewers’ names and <italic>ORCIDs</italic> (if available)</p></list-item><list-item><p>The text of all reviews and the reviewers’ recommendations</p></list-item><list-item><p>The DOIs and PMIDs (<italic>PubMed</italic> IDs) from the article’s reference list</p></list-item><list-item><p>The DOIs and PMIDs of any articles cited by the reviewers. The online peer review system at <italic>F1000</italic> journals includes the DOI of any article cited in the review, which facilitates the identification of citations to the reviewers’ articles.</p></list-item></list></list-item><list-item><p>Articles were excluded if:</p><list list-type="bullet" id="list2subList2"><list-item><p>They were not peer reviewed or had yet to receive any reviews</p></list-item><list-item><p>The reference list was empty</p></list-item></list></list-item><list-item><p>The reviewers’ publication histories were collected from <italic>OpenAlex</italic> using their name, institution and <italic>ORCID</italic> (if available). Reviews were excluded if there was no record for the reviewer in <italic>OpenAlex</italic>, or if the reviewer had no published articles as there was no potential for them to be cited or request a citation to their own articles.</p></list-item></list></sec><sec id="s4-3"><title>Study design</title><p>We used two predictor variables about the reviewer:</p><list list-type="bullet" id="list3"><list-item><p>The number of times they were cited in the article (0, 1, 2, …).</p></list-item><list-item><p>The number of times they included citations to their own articles in their review (0, 1, 2, …).</p></list-item></list><p>We fitted both predictors as linear, but reviewers may behave differently with any citation rather than a linear change, and hence we also fitted both predictors as a binary ‘none versus any’ (0 versus 1, 2, …). We compared the linear and binary alternatives using the Akaike Information Criterion (AIC) to find the parameterisation that best fitted the data (<xref ref-type="bibr" rid="bib11">Burnham and Anderson, 2002</xref>).</p><p>We matched on article and version to control for confounding by any characteristics of the article (<xref ref-type="bibr" rid="bib9">Bland and Altman, 1994</xref>); for example, the article’s topic or writing style. Hence, we compared two or more independent reviewers who considered the same article.</p><p>All analyses were stratified by article version, using the first version only or the second and subsequent versions. This is because the reviewers are unknown to the authors for the first version, but from the second version onwards, the authors will know the reviewers as the journals use signed peer reviews. This knowledge could alter the behaviour of authors and reviewers.</p><p>The study design is summarised in <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Graphical summary of the study design for research question 1 showing a dummy article and two reviews.</title><p>In the first version of the article, the reviewer Smith (blue) is cited whilst Jones (purple) is not. For the second version of the article, the authors are now aware that Jones is a reviewer and Jones has been cited. The reviewers’ recommendations are the outcome and are colour-coded as Not approved (red), Reservations (orange) and Approved (green). We tested whether citations to the reviewer in the article influenced their recommendation. The matched design means that only reviewers of the same article are compared (here, Smith and Jones) and the overall effect is estimated by aggregating over multiple matched comparisons. Research question 2 used the same design but examined citations to the reviewers’ articles in their reviews.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-fig5-v1.tif"/></fig></sec><sec id="s4-4"><title>Statistical methods</title><p>We used conditional logistic regression to examine the associations between the citations to the reviewer and their ordinal recommendation (Approved → Reservations → Not approved) while matching the article and the version (<xref ref-type="bibr" rid="bib31">Hosmer et al., 2013</xref>). Conditional logistic regression requires a binary dependent variable; hence, we fitted two related models that examined the odds of:</p><list list-type="order" id="list4"><list-item><p>‘Approved’ compared with ‘Reservations’ or ‘Not approved’.</p></list-item><list-item><p>‘Approved’ or ‘Reservations’ compared with ‘Not approved’.</p></list-item></list><p>These two models tested the same hypothesis; hence, we adjusted for multiple testing. We also used repeated testing due to the stratification by article version and the two formulations of the predictors (linear or none versus any). Since we used 8 (2 × 2 × 2) tests, we displayed all the results using 99.4% confidence intervals instead of 95.0% intervals, which is a 5% type I error divided by eight tests.</p><p>In an unplanned analysis, we examined the association between the reviewer’s recommendation and whether they included citations to work other than their own articles. This was added to examine differences between reviewers’ citations to their own articles and other articles.</p><p>Outliers were not excluded. No data were missing in the analysis data set.</p><p>The sample size calculation is in Appendix 1.</p></sec><sec id="s4-5"><title>Text analysis</title><p>We examined how reviewers’ citations to their own articles or other articles were justified and whether their wording differed according to their recommendation. For an initial view of citations to their own articles, we randomly selected 20 reviews and extracted the most relevant sentence concerning the citation.</p><p>To analyse the review text, we first extracted the 100 most commonly used words in all reviews. To standardise the text, all words were transformed into tokens, with stop-words removed and then stemmed. We then tested which of the 100 words were associated with recommending Approved versus Reservations or Not approved amongst those reviewers who included a citation to their own articles and those who included a citation to other articles. We chose the set of words using an elastic net with 10-fold cross-validation and selected a parsimonious model by using the lambda within one standard error of the minimum cross-validated error (<xref ref-type="bibr" rid="bib66">Zou and Hastie, 2005</xref>; <xref ref-type="bibr" rid="bib54">Tay et al., 2023</xref>). To get uncertainty intervals for the estimates, we fitted a Bayesian model with the set of words selected by the elastic net and using a sceptical Normal prior centred on zero to create shrinkage.</p></sec><sec id="s4-6"><title>Reproducibility</title><p>Research question 1 was pre-registered using <italic>As Predicted</italic> on 20 May 2024 (<xref ref-type="bibr" rid="bib4">Barnett, 2024</xref>). Research question 2 was formulated during data collection but before any data analysis and used the same study design and statistical methods as question 1.</p><p>All data extraction and analyses were conducted using <italic>R</italic> version 4.4.1 (<xref ref-type="bibr" rid="bib40">R Development Core Team, 2024</xref>). The data and <italic>R</italic> code are available on <italic>GitHub</italic> (<xref ref-type="bibr" rid="bib5">Barnett, 2025a</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Visualization, Methodology, Writing – original draft</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All data used are openly available and published with the expectation of post-publication scrutiny.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-108748-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All raw and analysis data used in this article are openly available here: <ext-link ext-link-type="uri" xlink:href="https://github.com/agbarnett/cited_reviewers">https://github.com/agbarnett/cited_reviewers</ext-link>, copy archived at <xref ref-type="bibr" rid="bib6">Barnett, 2025b</xref>.</p></sec><ack id="ack"><title>Acknowledgements</title><p>Thanks to all four journals for making all their data openly available and easily accessible. Thanks to Robin Blythe, staff from F1000 and Paper-Wizard <ext-link ext-link-type="uri" xlink:href="https://paper-wizard.com/">https://paper-wizard.com/</ext-link> for providing helpful feedback on a draft of this paper.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aczel</surname><given-names>B</given-names></name><name><surname>Barwich</surname><given-names>AS</given-names></name><name><surname>Diekman</surname><given-names>AB</given-names></name><name><surname>Fishbach</surname><given-names>A</given-names></name><name><surname>Goldstone</surname><given-names>RL</given-names></name><name><surname>Gomez</surname><given-names>P</given-names></name><name><surname>Gundersen</surname><given-names>OE</given-names></name><name><surname>von Hippel</surname><given-names>PT</given-names></name><name><surname>Holcombe</surname><given-names>AO</given-names></name><name><surname>Lewandowsky</surname><given-names>S</given-names></name><name><surname>Nozari</surname><given-names>N</given-names></name><name><surname>Pestilli</surname><given-names>F</given-names></name><name><surname>Ioannidis</surname><given-names>JPA</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>The present and future of peer review: Ideas, interventions, and evidence</article-title><source>PNAS</source><volume>122</volume><elocation-id>2401232121</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2401232121</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>MS</given-names></name><name><surname>Ronning</surname><given-names>EA</given-names></name><name><surname>De Vries</surname><given-names>R</given-names></name><name><surname>Martinson</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The perverse effects of competition on scientists’ work and relationships</article-title><source>Science and Engineering Ethics</source><volume>13</volume><fpage>437</fpage><lpage>461</lpage><pub-id pub-id-type="doi">10.1007/s11948-007-9042-5</pub-id><pub-id pub-id-type="pmid">18030595</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aria</surname><given-names>M</given-names></name><name><surname>Le</surname><given-names>T</given-names></name><name><surname>Cuccurullo</surname><given-names>C</given-names></name><name><surname>Belfiore</surname><given-names>A</given-names></name><name><surname>Choe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>openalexR: An R-tool for collecting bibliometric data from OpenAlex</article-title><source>The R Journal</source><volume>15</volume><fpage>167</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.32614/RJ-2023-089</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>F1000research – reviewer citation study (#175,812)</article-title><ext-link ext-link-type="uri" xlink:href="https://aspredicted.org/rn8vg.pdf">https://aspredicted.org/rn8vg.pdf</ext-link><date-in-citation iso-8601-date="2024-05-01">May 1, 2024</date-in-citation></element-citation></ref><ref id="bib5"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2025">2025a</year><data-title>Code and data for the analysis of the association between citations and peer review recommendations</data-title><version designator="fe8c687">fe8c687</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/agbarnett/cited_reviewers">https://github.com/agbarnett/cited_reviewers</ext-link></element-citation></ref><ref id="bib6"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2025">2025b</year><data-title>Cited_reviewers</data-title><version designator="swh:1:rev:fe8c687d4dd2cffffaa01441abe442dc696d68d7">swh:1:rev:fe8c687d4dd2cffffaa01441abe442dc696d68d7</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:2433c75bfc80c6182c41cf69d1f2673269a5f4dc;origin=https://github.com/agbarnett/cited_reviewers;visit=swh:1:snp:65208c76dcab8d88f0207ab5ab4655fd7ff22b5a;anchor=swh:1:rev:fe8c687d4dd2cffffaa01441abe442dc696d68d7">https://archive.softwareheritage.org/swh:1:dir:2433c75bfc80c6182c41cf69d1f2673269a5f4dc;origin=https://github.com/agbarnett/cited_reviewers;visit=swh:1:snp:65208c76dcab8d88f0207ab5ab4655fd7ff22b5a;anchor=swh:1:rev:fe8c687d4dd2cffffaa01441abe442dc696d68d7</ext-link></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Begg</surname><given-names>CB</given-names></name><name><surname>Berlin</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Publication bias: a problem in interpreting medical data</article-title><source>Journal of the Royal Statistical Society. Series A</source><volume>151</volume><elocation-id>419</elocation-id><pub-id pub-id-type="doi">10.2307/2982993</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bergstrom</surname><given-names>CT</given-names></name><name><surname>Bak-Coleman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>AI, peer review and the human activity of science</article-title><source>Nature</source><volume>227</volume><elocation-id>01839-w</elocation-id><pub-id pub-id-type="doi">10.1038/d41586-025-01839-w</pub-id><pub-id pub-id-type="pmid">40562909</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bland</surname><given-names>JM</given-names></name><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Statistics notes: Matching</article-title><source>BMJ</source><volume>309</volume><elocation-id>1128</elocation-id><pub-id pub-id-type="doi">10.1136/bmj.309.6962.1128</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohorquez</surname><given-names>NG</given-names></name><name><surname>Weerasuriya</surname><given-names>S</given-names></name><name><surname>Brain</surname><given-names>D</given-names></name><name><surname>Senanayake</surname><given-names>S</given-names></name><name><surname>Kularatna</surname><given-names>S</given-names></name><name><surname>Barnett</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Health and medical researchers are willing to trade their results for journal impact factors: results from a discrete choice experiment</article-title><source>Prometheus</source><volume>40</volume><elocation-id>40002</elocation-id><pub-id pub-id-type="doi">10.13169/prometheus.40.4.0002</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Burnham</surname><given-names>K</given-names></name><name><surname>Anderson</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach</source><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Basil</surname><given-names>DZ</given-names></name><name><surname>Soboleva</surname><given-names>A</given-names></name><name><surname>Nesbit</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Cite me! Perspectives on coercive citation in reviewing</article-title><source>Journal of Services Marketing</source><volume>38</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1108/JSM-08-2024-0387</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campos-Arceiz</surname><given-names>A</given-names></name><name><surname>Primack</surname><given-names>RB</given-names></name><name><surname>Koh</surname><given-names>LP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reviewer recommendations and editors’ decisions for a conservation journal: Is it just a crapshoot? And do Chinese authors get a fair shot?</article-title><source>Biological Conservation</source><volume>186</volume><fpage>22</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/j.biocon.2015.02.025</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname><given-names>R</given-names></name><name><surname>Shipley</surname><given-names>M</given-names></name><name><surname>Lewington</surname><given-names>S</given-names></name><name><surname>Youngman</surname><given-names>L</given-names></name><name><surname>Collins</surname><given-names>R</given-names></name><name><surname>Marmot</surname><given-names>M</given-names></name><name><surname>Peto</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Underestimation of risk associations due to regression dilution in long-term follow-up of prospective studies</article-title><source>American Journal of Epidemiology</source><volume>150</volume><fpage>341</fpage><lpage>353</lpage><pub-id pub-id-type="doi">10.1093/oxfordjournals.aje.a010013</pub-id><pub-id pub-id-type="pmid">10453810</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="book"><person-group person-group-type="author"><collab>Committee on Publication</collab></person-group><year iso-8601-date="2017">2017</year><source>Ethical Guidelines for Peer Reviewers</source><publisher-name>COPE</publisher-name><pub-id pub-id-type="doi">10.24318/cope.2019.1.9</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><collab>Committee on Publication Ethics</collab></person-group><year iso-8601-date="2019">2019</year><source>Citation Manipulation</source><publisher-name>COPE</publisher-name><pub-id pub-id-type="doi">10.24318/cope.2019.3.1</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cranford</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>C.R.E.A.M: Citations Rule Everything Around Me</article-title><source>Matter</source><volume>2</volume><fpage>1343</fpage><lpage>1347</lpage><pub-id pub-id-type="doi">10.1016/j.matt.2020.04.025</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Culbert</surname><given-names>JH</given-names></name><name><surname>Hobert</surname><given-names>A</given-names></name><name><surname>Jahn</surname><given-names>N</given-names></name><name><surname>Haupka</surname><given-names>N</given-names></name><name><surname>Schmidt</surname><given-names>M</given-names></name><name><surname>Donner</surname><given-names>P</given-names></name><name><surname>Mayr</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Reference coverage analysis of OpenAlex compared to Web of Science and Scopus</article-title><source>Scientometrics</source><volume>130</volume><fpage>2475</fpage><lpage>2492</lpage><pub-id pub-id-type="doi">10.1007/s11192-025-05293-3</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="web"><person-group person-group-type="author"><name><surname>Currie</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Open science: What is publish, review, curate?</article-title><ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/inside-elife/dc24a9cd/open-science-what-is-publish-review-curate">https://elifesciences.org/inside-elife/dc24a9cd/open-science-what-is-publish-review-curate</ext-link><date-in-citation iso-8601-date="2025-10-01">October 1, 2025</date-in-citation></element-citation></ref><ref id="bib20"><element-citation publication-type="web"><person-group person-group-type="author"><collab>F1000Research</collab></person-group><year iso-8601-date="2025">2025a</year><article-title>Guidelines for article reviewers</article-title><ext-link ext-link-type="uri" xlink:href="https://f1000research.com/for-referees/guidelines">https://f1000research.com/for-referees/guidelines</ext-link><date-in-citation iso-8601-date="2025-04-22">April 22, 2025</date-in-citation></element-citation></ref><ref id="bib21"><element-citation publication-type="web"><person-group person-group-type="author"><collab>F1000Research</collab></person-group><year iso-8601-date="2025">2025b</year><article-title>Finding article reviewers</article-title><ext-link ext-link-type="uri" xlink:href="https://f1000research.com/for-authors/tips-for-finding-referees">https://f1000research.com/for-authors/tips-for-finding-referees</ext-link><date-in-citation iso-8601-date="2025-06-09">June 9, 2025</date-in-citation></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fire</surname><given-names>M</given-names></name><name><surname>Guestrin</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Over-optimization of academic publishing metrics: observing Goodhart’s Law in action</article-title><source>GigaScience</source><volume>8</volume><elocation-id>giz053</elocation-id><pub-id pub-id-type="doi">10.1093/gigascience/giz053</pub-id><pub-id pub-id-type="pmid">31144712</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fong</surname><given-names>EA</given-names></name><name><surname>Wilhite</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Authorship and citation manipulation in academic research</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0187394</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0187394</pub-id><pub-id pub-id-type="pmid">29211744</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fong</surname><given-names>EA</given-names></name><name><surname>Patnayakuni</surname><given-names>R</given-names></name><name><surname>Wilhite</surname><given-names>AW</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Accommodating coercion: Authors, editors, and citations</article-title><source>Research Policy</source><volume>52</volume><elocation-id>104754</elocation-id><pub-id pub-id-type="doi">10.1016/j.respol.2023.104754</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frandsen</surname><given-names>TF</given-names></name><name><surname>Nicolaisen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Praise the bridge that carries you over: Testing the flattery citation hypothesis</article-title><source>Journal of the American Society for Information Science and Technology</source><volume>62</volume><fpage>807</fpage><lpage>818</lpage><pub-id pub-id-type="doi">10.1002/asi.21503</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>BS</given-names></name><name><surname>Eichenberger</surname><given-names>R</given-names></name><name><surname>Frey</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Editorial Ruminations: Publishing Kyklos</article-title><source>Kyklos</source><volume>62</volume><fpage>151</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1111/j.1467-6435.2009.00428.x</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomez</surname><given-names>CJ</given-names></name><name><surname>Herman</surname><given-names>AC</given-names></name><name><surname>Parigi</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Leading countries in global science increasingly receive more citations than other countries doing similar research</article-title><source>Nature Human Behaviour</source><volume>6</volume><fpage>919</fpage><lpage>929</lpage><pub-id pub-id-type="doi">10.1038/s41562-022-01351-5</pub-id><pub-id pub-id-type="pmid">35637294</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>DG</given-names></name><name><surname>Fraser</surname><given-names>H</given-names></name><name><surname>Hoekstra</surname><given-names>R</given-names></name><name><surname>Fidler</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Meta-Research: Journal policies and editors’ opinions on peer review</article-title><source>eLife</source><volume>09</volume><elocation-id>e62529</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.62529</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heneberg</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>From excessive journal self-cites to citation stacking: analysis of journal self-citation kinetics in search for journals, which boost their scientometric indicators</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0153730</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0153730</pub-id><pub-id pub-id-type="pmid">27088862</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ho</surname><given-names>RCM</given-names></name><name><surname>Mak</surname><given-names>KK</given-names></name><name><surname>Tao</surname><given-names>R</given-names></name><name><surname>Lu</surname><given-names>Y</given-names></name><name><surname>Day</surname><given-names>JR</given-names></name><name><surname>Pan</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Views on the peer review system of biomedical journals: an online survey of academics from high-ranking universities</article-title><source>BMC Medical Research Methodology</source><volume>13</volume><elocation-id>74</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2288-13-74</pub-id><pub-id pub-id-type="pmid">23758823</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hosmer</surname><given-names>D</given-names></name><name><surname>Lemeshow</surname><given-names>S</given-names></name><name><surname>Sturdivant</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Applied Logistic Regression</source><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>CJ</given-names></name><name><surname>Sugimoto</surname><given-names>CR</given-names></name><name><surname>Zhang</surname><given-names>G</given-names></name><name><surname>Cronin</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Bias in peer review</article-title><source>Journal of the American Society for Information Science and Technology</source><volume>64</volume><fpage>2</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1002/asi.22784</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Whither research integrity? Plagiarism, self-plagiarism and coercive citation in an age of research assessment</article-title><source>Research Policy</source><volume>42</volume><fpage>1005</fpage><lpage>1014</lpage><pub-id pub-id-type="doi">10.1016/j.respol.2013.03.011</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehregan</surname><given-names>M</given-names></name><name><surname>Moghiman</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The unnoticed issue of coercive citation behavior for authors</article-title><source>Publishing Research Quarterly</source><volume>40</volume><fpage>164</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1007/s12109-024-09994-0</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monadhel</surname><given-names>H</given-names></name><name><surname>Abbas</surname><given-names>AR</given-names></name><name><surname>Mohammed</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>COVID-19 vaccine: predicting vaccine types and assessing mortality risk through ensemble learning algorithms</article-title><source>F1000Research</source><volume>12</volume><elocation-id>1200</elocation-id><pub-id pub-id-type="doi">10.12688/f1000research.140395.2</pub-id><pub-id pub-id-type="pmid">38799245</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oviedo-García</surname><given-names>MÁ</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The review mills, not just (self-)plagiarism in review reports, but a step further</article-title><source>Scientometrics</source><volume>129</volume><fpage>5805</fpage><lpage>5813</lpage><pub-id pub-id-type="doi">10.1007/s11192-024-05125-w</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlovic</surname><given-names>V</given-names></name><name><surname>Weissgerber</surname><given-names>T</given-names></name><name><surname>Stanisavljevic</surname><given-names>D</given-names></name><name><surname>Pekmezovic</surname><given-names>T</given-names></name><name><surname>Milicevic</surname><given-names>O</given-names></name><name><surname>Lazovic</surname><given-names>JM</given-names></name><name><surname>Cirkovic</surname><given-names>A</given-names></name><name><surname>Savic</surname><given-names>M</given-names></name><name><surname>Rajovic</surname><given-names>N</given-names></name><name><surname>Piperac</surname><given-names>P</given-names></name><name><surname>Djuric</surname><given-names>N</given-names></name><name><surname>Madzarevic</surname><given-names>P</given-names></name><name><surname>Dimitrijevic</surname><given-names>A</given-names></name><name><surname>Randjelovic</surname><given-names>S</given-names></name><name><surname>Nestorovic</surname><given-names>E</given-names></name><name><surname>Akinyombo</surname><given-names>R</given-names></name><name><surname>Pavlovic</surname><given-names>A</given-names></name><name><surname>Ghamrawi</surname><given-names>R</given-names></name><name><surname>Garovic</surname><given-names>V</given-names></name><name><surname>Milic</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>How accurate are citations of frequently cited papers in biomedical literature?</article-title><source>Clinical Science</source><volume>135</volume><fpage>671</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1042/CS20201573</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peebles</surname><given-names>E</given-names></name><name><surname>Scandlyn</surname><given-names>M</given-names></name><name><surname>Hesp</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A retrospective study investigating requests for self-citation during open peer review in a general medicine journal</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0237804</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0237804</pub-id><pub-id pub-id-type="pmid">32817699</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Priem</surname><given-names>J</given-names></name><name><surname>Piwowar</surname><given-names>H</given-names></name><name><surname>Orr</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Openalex: a fully-open index of scholarly works, authors, venues, institutions, and concepts</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2205.01833</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="software"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group><year iso-8601-date="2024">2024</year><data-title>R: a language and environment for statistical computing</data-title><publisher-loc>Vienna, Austria</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name><ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resnik</surname><given-names>DB</given-names></name><name><surname>Gutierrez-Ford</surname><given-names>C</given-names></name><name><surname>Peddada</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Perceptions of ethical problems with scientific journal peer review: an exploratory study</article-title><source>Science and Engineering Ethics</source><volume>14</volume><fpage>305</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1007/s11948-008-9059-4</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross-Hellauer</surname><given-names>T</given-names></name><name><surname>Deppe</surname><given-names>A</given-names></name><name><surname>Schmidt</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Survey on open peer review: Attitudes and experience amongst editors, authors and reviewers</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0189311</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0189311</pub-id><pub-id pub-id-type="pmid">29236721</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Royston</surname><given-names>P</given-names></name><name><surname>Ambler</surname><given-names>G</given-names></name><name><surname>Sauerbrei</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The use of fractional polynomials to model continuous risk variables in epidemiology</article-title><source>International Journal of Epidemiology</source><volume>28</volume><fpage>964</fpage><lpage>974</lpage><pub-id pub-id-type="doi">10.1093/ije/28.5.964</pub-id><pub-id pub-id-type="pmid">10597998</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>B</given-names></name><name><surname>Ross-Hellauer</surname><given-names>T</given-names></name><name><surname>van Edig</surname><given-names>X</given-names></name><name><surname>Moylan</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Ten considerations for open peer review</article-title><source>F1000Research</source><volume>7</volume><elocation-id>969</elocation-id><pub-id pub-id-type="doi">10.12688/f1000research.15334.1</pub-id><pub-id pub-id-type="pmid">30135731</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schriger</surname><given-names>DL</given-names></name><name><surname>Kadera</surname><given-names>SP</given-names></name><name><surname>von Elm</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Are reviewers’ scores influenced by citations to their own work? an analysis of submitted manuscripts and peer reviewer reports</article-title><source>Annals of Emergency Medicine</source><volume>67</volume><fpage>401</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1016/j.annemergmed.2015.09.003</pub-id><pub-id pub-id-type="pmid">26518378</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeber</surname><given-names>M</given-names></name><name><surname>Cattaneo</surname><given-names>M</given-names></name><name><surname>Meoli</surname><given-names>M</given-names></name><name><surname>Malighetti</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Self-citations as strategic response to the use of metrics for career decisions</article-title><source>Research Policy</source><volume>48</volume><fpage>478</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1016/j.respol.2017.12.004</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seeber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>How do journals of different rank instruct peer reviewers? Reviewer guidelines in the field of management</article-title><source>Scientometrics</source><volume>122</volume><fpage>1387</fpage><lpage>1405</lpage><pub-id pub-id-type="doi">10.1007/s11192-019-03343-1</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh Chawla</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>Elsevier investigates hundreds of peer reviewers for manipulating citations</article-title><source>Nature</source><volume>573</volume><elocation-id>174</elocation-id><pub-id pub-id-type="doi">10.1038/d41586-019-02639-9</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh Chawla</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>Two-thirds of researchers report ‘pressure to cite’ in Nature poll</article-title><source>Nature</source><volume>01</volume><elocation-id>02922-9</elocation-id><pub-id pub-id-type="doi">10.1038/d41586-019-02922-9</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Peer review: a flawed process at the heart of science and journals</article-title><source>Journal of the Royal Society of Medicine</source><volume>99</volume><fpage>178</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1177/014107680609900414</pub-id><pub-id pub-id-type="pmid">16574968</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stelmakh</surname><given-names>I</given-names></name><name><surname>Rastogi</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>R</given-names></name><name><surname>Chawla</surname><given-names>S</given-names></name><name><surname>Echenique</surname><given-names>F</given-names></name><name><surname>Shah</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Cite-seeing and reviewing: A study on citation bias in peer review</article-title><source>PLOS ONE</source><volume>18</volume><elocation-id>e0283980</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0283980</pub-id><pub-id pub-id-type="pmid">37418377</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugimoto</surname><given-names>CR</given-names></name><name><surname>Cronin</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Citation gamesmanship: testing for evidence of ego bias in peer review</article-title><source>Scientometrics</source><volume>95</volume><fpage>851</fpage><lpage>862</lpage><pub-id pub-id-type="doi">10.1007/s11192-012-0845-z</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tahamtan</surname><given-names>I</given-names></name><name><surname>Bornmann</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>What do citation counts measure? An updated review of studies on citations in scientific documents published between 2006 and 2018</article-title><source>Scientometrics</source><volume>121</volume><fpage>1635</fpage><lpage>1684</lpage><pub-id pub-id-type="doi">10.1007/s11192-019-03243-4</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tay</surname><given-names>JK</given-names></name><name><surname>Narasimhan</surname><given-names>B</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Elastic net regularization paths for all generalized linear models</article-title><source>Journal of Statistical Software</source><volume>106</volume><fpage>1</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.18637/jss.v106.i01</pub-id><pub-id pub-id-type="pmid">37138589</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="book"><person-group person-group-type="author"><collab>Taylor and Francis</collab></person-group><year iso-8601-date="2025">2025</year><source>Anonymous Peer Review: How to Make Your Article Ready for Double-Anonymous Peer Review</source><publisher-name>Taylor and Francis</publisher-name></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Teixeira da Silva</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The ethics of peer and editorial requests for self-citation of their work and journal</article-title><source>Medical Journal Armed Forces India</source><volume>73</volume><fpage>181</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1016/j.mjafi.2016.11.008</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tennant</surname><given-names>JP</given-names></name><name><surname>Ross-Hellauer</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The limitations to our understanding of peer review</article-title><source>Research Integrity and Peer Review</source><volume>5</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.1186/s41073-020-00092-1</pub-id><pub-id pub-id-type="pmid">32368354</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Therneau</surname><given-names>T</given-names></name><name><surname>Grambsch</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Modeling Survival Data: Extending the Cox Model</source><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thombs</surname><given-names>BD</given-names></name><name><surname>Razykov</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A solution to inappropriate self-citation via peer review</article-title><source>Canadian Medical Association Journal</source><volume>184</volume><elocation-id>1864</elocation-id><pub-id pub-id-type="doi">10.1503/cmaj.120597</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thombs</surname><given-names>BD</given-names></name><name><surname>Levis</surname><given-names>AW</given-names></name><name><surname>Razykov</surname><given-names>I</given-names></name><name><surname>Syamchandra</surname><given-names>A</given-names></name><name><surname>Leentjens</surname><given-names>AFG</given-names></name><name><surname>Levenson</surname><given-names>JL</given-names></name><name><surname>Lumley</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Potentially coercive self-citation by peer reviewers: a cross-sectional study</article-title><source>Journal of Psychosomatic Research</source><volume>78</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/j.jpsychores.2014.09.015</pub-id><pub-id pub-id-type="pmid">25300537</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Rooyen</surname><given-names>S</given-names></name><name><surname>Godlee</surname><given-names>F</given-names></name><name><surname>Evans</surname><given-names>S</given-names></name><name><surname>Black</surname><given-names>N</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Effect of open peer review on quality of reviews and on reviewers’ recommendations: a randomised trial</article-title><source>BMJ</source><volume>318</volume><fpage>23</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1136/bmj.318.7175.23</pub-id><pub-id pub-id-type="pmid">9872878</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vendé</surname><given-names>B</given-names></name><name><surname>Barberousse</surname><given-names>A</given-names></name><name><surname>Ruphy</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>From 2015 to 2023, eight years of empirical research on research integrity: a scoping review</article-title><source>Research Integrity and Peer Review</source><volume>10</volume><elocation-id>5</elocation-id><pub-id pub-id-type="doi">10.1186/s41073-025-00163-1</pub-id><pub-id pub-id-type="pmid">40301940</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilhite</surname><given-names>AW</given-names></name><name><surname>Fong</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Coercive citation in academic publishing</article-title><source>Science</source><volume>335</volume><fpage>542</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1126/science.1212540</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wren</surname><given-names>JD</given-names></name><name><surname>Valencia</surname><given-names>A</given-names></name><name><surname>Kelso</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reviewer-coerced citation: case report, update on journal policy and suggestions for future prevention</article-title><source>Bioinformatics</source><volume>35</volume><fpage>3217</fpage><lpage>3218</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz071</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>FX</given-names></name><name><surname>Zhu</surname><given-names>YF</given-names></name><name><surname>Cao</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>CM</given-names></name><name><surname>Ma</surname><given-names>YJ</given-names></name><name><surname>Yang</surname><given-names>R</given-names></name><name><surname>Hu</surname><given-names>QM</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>RETRACTION: Origin of the distinct site occupations of H atom in hcp Ti and Zr/Hf</article-title><source>International Journal of Hydrogen Energy</source><volume>91</volume><fpage>933</fpage><lpage>941</lpage><pub-id pub-id-type="doi">10.1016/j.ijhydene.2024.10.197</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>H</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Regularization and variable selection via the elastic net</article-title><source>Journal of the Royal Statistical Society Series B</source><volume>67</volume><fpage>301</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Sample size</title><p>We aimed for a sample size of approximately 5000 articles and assumed that half would be the first version, giving a sample size of 2500 articles for the analysis using the first version only (<xref ref-type="bibr" rid="bib4">Barnett, 2024</xref>). In 1000 simulations, this gave an 89.1% power to detect an odds ratio of 1.5 using conditional logistic regression for a reviewer who recommended a higher category (Approved → Reservations → Not approved) when they were cited. We assumed that 15% of articles would include a citation to the reviewer. Eighty per cent of the simulated articles had two reviews, and the remaining 20% had three reviews. Based on preliminary data from two journals, we assumed that the reviewers’ recommendations would have a ratio for Approved:Reservations:Not approved of 70:24:6.</p></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Included and excluded reviews</title><fig id="app2fig1" position="float"><label>Appendix 2—figure 1.</label><caption><title>Flow chart of included reviews.</title><p>‘<italic>N</italic>’ is the number of articles and ‘<italic>n</italic>’ is the number of reviews.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app2-fig1-v1.tif"/></fig><p>The flow chart shows the loss of articles and reviews during the data collection process. More than 3500 articles did not have reviewers as they had yet to be peer reviewed or were Faculty Reviews that were commissioned and used a different peer review model.</p><p>More than 2000 reviewers did not have an <italic>OpenAlex</italic> record and therefore were excluded from the analyses. We examined the potential bias in the lost reviews by comparing their characteristics with those of the retained reviews. We used a multiple regression model with reviewer lost (yes/no) as the binary dependent variable and predictors of article version, article date, referee or co-referee, and reviewer’s country. We expected many of these predictors to have little effect; therefore, we used an elastic net to reduce the number of predictors (<xref ref-type="bibr" rid="bib66">Zou and Hastie, 2005</xref>). We used the ‘glmnet’ package in <xref ref-type="bibr" rid="bib54">Tay et al., 2023</xref>. For the binary dependent variable, 39,455 reviews were retained and 2082 (5%) were lost.</p><p>The elastic net retained two predictors. The date of the article had an odds ratio of 1.09 per year increase, which means that more recent articles were more likely to be retained, likely because the reviewer’s information was more current. Referees were more likely to be retained compared to co-referees with an odds ratio of 1.79, likely because co-referees were often relatively junior and some may not have any publications.</p></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Model fit</title><table-wrap id="app3table1" position="float"><label>Appendix 3—table 1.</label><caption><title>Comparing the two alternatives for the citation predictor variables using either a linear variable or a binary ‘any versus none’ variable.</title><p>A vs R/N = Approved vs Reservations/Not approved, A/R vs N = Approved/Reservations vs Not approved.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Co-reviewers included</th><th align="left" valign="bottom">Version</th><th align="left" valign="bottom">Outcome</th><th align="left" valign="bottom" colspan="3">AIC</th></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Linear</td><td align="left" valign="bottom">Binary</td><td align="left" valign="bottom">Difference</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">5940.9</td><td align="char" char="." valign="bottom">5937.4</td><td align="char" char="." valign="bottom">3.6</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">1930.3</td><td align="char" char="." valign="bottom">1929.8</td><td align="char" char="." valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">1952.4</td><td align="char" char="." valign="bottom">1941.9</td><td align="char" char="." valign="bottom">10.5</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">572.1</td><td align="char" char="." valign="bottom">571.9</td><td align="char" char="." valign="bottom">0.2</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">5978.4</td><td align="char" char="." valign="bottom">5975.4</td><td align="char" char="." valign="bottom">3.0</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">1941.1</td><td align="char" char="." valign="bottom">1940.8</td><td align="char" char="." valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">1963.1</td><td align="char" char="." valign="bottom">1951.4</td><td align="char" char="." valign="bottom">11.7</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">572.6</td><td align="char" char="." valign="bottom">572.8</td><td align="char" char="." valign="bottom">–0.2</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">5932.3</td><td align="char" char="." valign="bottom">5911.1</td><td align="char" char="." valign="bottom">21.2</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">1934.1</td><td align="char" char="." valign="bottom">1935.6</td><td align="char" char="." valign="bottom">–1.5</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">1881.4</td><td align="char" char="." valign="bottom">1876.0</td><td align="char" char="." valign="bottom">5.4</td></tr><tr><td align="left" valign="bottom">No</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">573.4</td><td align="char" char="." valign="bottom">572.8</td><td align="char" char="." valign="bottom">0.6</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">5967.9</td><td align="char" char="." valign="bottom">5944.9</td><td align="char" char="." valign="bottom">23.0</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">1945.4</td><td align="char" char="." valign="bottom">1946.6</td><td align="char" char="." valign="bottom">–1.2</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A vs R/N</td><td align="char" char="." valign="bottom">1917.3</td><td align="char" char="." valign="bottom">1904.1</td><td align="char" char="." valign="bottom">13.2</td></tr><tr><td align="left" valign="bottom">Yes</td><td align="char" char="." valign="bottom">2+</td><td align="left" valign="bottom">A/R vs N</td><td align="char" char="." valign="bottom">573.1</td><td align="char" char="." valign="bottom">573.5</td><td align="char" char="." valign="bottom">–0.5</td></tr></tbody></table></table-wrap><p>The AIC (Akaike Information Criterion) is a trade-off of model fit and complexity. The smaller the AIC, the better the fit. Differences of 10 are considered large (<xref ref-type="bibr" rid="bib11">Burnham and Anderson, 2002</xref>).</p><p>In most cases, the difference between the linear and binary variables was small (under 5). There were four comparisons out of 16 in which the linear variable had a smaller AIC than the binary variable and all differences were small (under 2). There were four comparisons where the AIC for the binary variable was over 10 units smaller than the linear variable, indicating a large difference in model fit. In summary, using a binary predictor variable is a generally better fit to the data than using a linear variable.</p></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>Results from using a linear predictor</title><p>The figure shows the estimates for the two research questions using a linear dose–response for citation counts instead of the binary predictor of any citation versus none. The strongest effect was a greatly reduced odds of ‘Approved’ for increasing citations to the reviewer’s own articles. However, these estimates should be viewed with caution, as the binary predictor generally better fits the data (Supplement Model fit).</p><fig id="app4fig1" position="float"><label>Appendix 4—figure 1.</label><caption><title>Estimated odds ratios for using linear citations as the predictor.</title><p>The reference point is zero citations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app4-fig1-v1.tif"/></fig></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s12"><title>Including co-reviewers</title><p>Some reviews were performed by reviewers together with co-reviewers, who were usually less experienced. Our primary analysis excluded co-reviewers, but we included them in a sensitivity analysis where we created combined versions of the two independent variables using the sum of citations to reviewers and co-reviewers, and the sum of citations to their own articles from the reviewers and co-reviewers. The results examining whether the reviewers gave a more favourable recommendation when cited (research question 1) were very similar (<xref ref-type="fig" rid="app5fig1">Appendix 5—figure 1</xref>).</p><fig id="app5fig1" position="float"><label>Appendix 5—figure 1.</label><caption><title>Results with or without co-reviewers for research question 1.</title><p>Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation if they were cited. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version. The plot is designed to directly compare paired odds ratios with or without co-reviewers.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app5-fig1-v1.tif"/></fig><p>The results examining whether the reviewers gave a more favourable recommendation when they included citations to their own articles (research question 2) were mostly very similar (<xref ref-type="fig" rid="app5fig2">Appendix 5—figure 2</xref>). Two noticeable differences were two odds ratios where including co-reviewers somewhat reduced the strength of the association. This was for article versions 2+ and examining Approved vs Reservations or Not approved. Despite the noticeable change in the odds ratio, the interpretation remains similar in that there was a strong reduction in the odds of a favourable recommendation when the reviewers included citations to their own articles.</p><fig id="app5fig2" position="float"><label>Appendix 5—figure 2.</label><caption><title>Results with or without co-reviewers for research question 2.</title><p>Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they included a citation to their own articles. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version. The plot is designed to directly compare paired odds ratios with or without co-reviewers.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app5-fig2-v1.tif"/></fig></sec></app><app id="appendix-6"><title>Appendix 6</title><sec sec-type="appendix" id="s13"><title>Potential confounding by the reviewers’ characteristics</title><p>Any confounding by the characteristics of the articles was controlled by the matched design, but confounding by the characteristics of the reviewers remains possible (<xref ref-type="bibr" rid="bib51">Stelmakh et al., 2023</xref>). We considered the potential confounders of the reviewer’s experience and reviewer’s country. More experienced reviewers will likely be cited more often (on average) and could be more or less strict in their recommendations. The reviewer’s country is a potential confounder due to large differences in citation counts by country (<xref ref-type="bibr" rid="bib27">Gomez et al., 2022</xref>) and potential differences in recommendations by country (<xref ref-type="bibr" rid="bib13">Campos-Arceiz et al., 2015</xref>).</p><sec sec-type="appendix" id="s13-1"><title>Reviewers’ experience</title><p>We used the reviewer’s number of published articles as a proxy for their experience. This association could be non-linear; for example, a diminishing effect for more experienced reviewers, so we examined six fractional polynomials of the reviewers’ number of articles and used the AIC to select the best fit (<xref ref-type="bibr" rid="bib43">Royston et al., 1999</xref>). For most models, the best fit was achieved using a log-transformation.</p><p>There was little evidence of any confounding by the reviewers’ publication counts as the odds ratios were similar for both research questions (<xref ref-type="fig" rid="app6fig1">Appendix 6—figure 1</xref>; <xref ref-type="fig" rid="app6fig2">Appendix 6—figure 2</xref>). A fractional polynomial of −2 tended to show the largest difference compared to the odds ratios with no confounders; however, this transformation was not the best fit and the differences were relatively small.</p><fig id="app6fig1" position="float"><label>Appendix 6—figure 1.</label><caption><title>Examining potential confounding by reviewers’ publication counts for research question 1.</title><p>Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they were cited. We used fractional polynomials to examine a potentially non-linear association between reviewers’ publication counts and recommendation. The results for ‘None’ are the results without the potential confounder. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version. Results are missing when the model did not converge.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app6-fig1-v1.tif"/></fig><fig id="app6fig2" position="float"><label>Appendix 6—figure 2.</label><caption><title>Examining potential confounding by reviewers’ publication counts for research question 2.</title><p>Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they included a citation to their own articles. We used fractional polynomials to examine a potentially non-linear association between reviewers’ publication counts and recommendation. The results for ‘None’ are the results without the potential confounder. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version. Results are missing when the model did not converge.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app6-fig2-v1.tif"/></fig></sec><sec sec-type="appendix" id="s13-2"><title>Reviewers’ countries</title><p>We planned to use a frailty model to test for confounding by the reviewers’ countries (<xref ref-type="bibr" rid="bib58">Therneau and Grambsch, 2013</xref>). However, this model often failed to converge, potentially because there were many countries and some countries had relatively small numbers of reviewers. Hence, we instead used a leave-one-out analysis for each of the top 10 most common countries and determined if the results were noticeably different.</p><p>The results were generally similar regardless of which country was left out. Leaving out the USA, which was the largest country, had a relatively large effect on the odds of recommending Approved or Reservations vs Not approved for versions 2+ when using the “none vs any citations” predictor (<xref ref-type="fig" rid="app6fig3">Appendix 6—figure 3</xref>) and on the odds of recommending Approved or Reservations vs Not approved for versions 2+when using the “none vs any citations” predictor (<xref ref-type="fig" rid="app6fig4">Appendix 6—figure 4</xref>). However, neither change was substantively different from the results including all countries.</p><fig id="app6fig3" position="float"><label>Appendix 6—figure 3.</label><caption><title>Leave-one-country-out sensitivity analyses for research question 1.</title><p>Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they were cited. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app6-fig3-v1.tif"/></fig><fig id="app6fig4" position="float"><label>Appendix 6—figure 4.</label><caption><title>Leave-one-country-out sensitivity analyses for research question 2.</title><p>Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they included a citation to their own articles. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app6-fig4-v1.tif"/></fig></sec></sec></app><app id="appendix-7"><title>Appendix 7</title><sec sec-type="appendix" id="s14"><title>Examples of reviewers’ requests to cite their own articles</title><table-wrap id="app7table1" position="float"><label>Appendix 7—table 1.</label><caption><title>Example sentences that reviewers used when suggesting citations to their own articles using a random sample of 20 reviews.</title><p>The first column shows the number of citations suggested. We have removed any references to names using [xxxx]. The results are ordered by text length.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Citations suggested</th><th align="left" valign="top">Reviewer’s text</th></tr></thead><tbody><tr><td align="left" valign="top">3</td><td align="left" valign="top">Also, the introduction, main discussion, and conclusion must be redrawn to highlight NO as a treatment option, the clinical trials discussion, the use of several NORMS (NORM-1, NORM-2, etc.), the effect of NO-carriage system, Natural NO-sources, synthetic NO-sources with limitations, Inorganic versus organic forms, etc. (e.g., in the review publications as given).</td></tr><tr><td align="char" char="." valign="top">1</td><td align="left" valign="top">The term ‘true bugs’ applies to the monophyletic Heteroptera, which does include the species presented here (Acanthosoma haemorrhoidale), while aphids and mealybugs belong to the distinct lineage Sternorrhyncha, sometimes (formerly) regarded as a part of the paraphyletic Homoptera (see, for example, <xref ref-type="fig" rid="fig2">Figure 2</xref> in: [xxxx]).</td></tr><tr><td align="left" valign="top">1</td><td align="left" valign="top">On a side note: There is already published work on population genomics of the European plaice showing that two large chromosomal rearrangements (two putative inversions) segregate in northern plaice populations (North Sea, Baltic Sea, Barents Sea, and Iceland) and distinguish different plaice populations.</td></tr><tr><td align="char" char="." valign="top">1</td><td align="left" valign="top">There is some observational clinical data on how the detrusor compensates for the growing prostate and the-by consequence-increase in bladder outflow obstruction, in addition to the animal studies referred to in the commentary, to explain the pathophysiology.</td></tr><tr><td align="left" valign="top">1</td><td align="left" valign="top">I would like to thank the authors for including references to the work done in the [xxxx] project; I would recommend to remove the reference ([xxxx] et al., 2019b) and replace it with a reference to a much more recent and related article ([xxxx] et al.):</td></tr><tr><td align="char" char="." valign="top">2</td><td align="left" valign="top">The cited literature is incomplete; it does not include all reports of studies on the presence of the snail in Colombia, and studies with relevant findings of nematodes with or without pathogenic potential in animals are omitted e.g.:</td></tr><tr><td align="left" valign="top">1</td><td align="left" valign="top">In the last 2 decades, our group has developed a brief instrument to assess the presence and the severity of sensory phenomena (the University of [xxxx]) to investigate OCD phenotypic subtypes and its relationship with TS/CTD.</td></tr><tr><td align="char" char="." valign="top">5</td><td align="left" valign="top">The authors can find the following relevant articles to enhance their Materials and Methods section and incorporate citations to support their revised manuscript.</td></tr><tr><td align="left" valign="top">3</td><td align="left" valign="top">The authors should consider references from high impact journal publications on crop yield prediction. For example, the following articles by this reviewer</td></tr><tr><td align="char" char="." valign="top">1</td><td align="left" valign="top">No mention to more rigorous rankings such as the Leiden Ranking are made nor to what exactly rankings are portraying. See for instance [xxxx].</td></tr><tr><td align="left" valign="top">1</td><td align="left" valign="top">Maybe ‘manifest’ and ’not manifest’ would work better for example we used this terminology in [xxxx].</td></tr><tr><td align="char" char="." valign="top">1</td><td align="left" valign="top">This is especially useful if you have multiple data sets – see, for example, the [xxxx] package.</td></tr><tr><td align="left" valign="top">3</td><td align="left" valign="top">I would suggest the authors include some of the results of a large-scale project in Europe.</td></tr><tr><td align="char" char="." valign="top">2</td><td align="left" valign="top">Please refer to some further references to revise the relevant description:</td></tr><tr><td align="left" valign="top">1</td><td align="left" valign="top">Here are a few additional publications you might consider referencing.</td></tr><tr><td align="char" char="." valign="top">1</td><td align="left" valign="top">However, genomics resources are limited, except for parasitoid wasps.</td></tr><tr><td align="left" valign="top">1</td><td align="left" valign="top">Refer to this recent literature review.</td></tr><tr><td align="char" char="." valign="top">4</td><td align="left" valign="top"><italic>No relevant sentence</italic></td></tr><tr><td align="left" valign="top">1</td><td align="left" valign="top"><italic>No relevant sentence</italic></td></tr><tr><td align="char" char="." valign="top">6</td><td align="left" valign="top"><italic>No relevant sentence</italic></td></tr></tbody></table></table-wrap></sec></app><app id="appendix-8"><title>Appendix 8</title><sec sec-type="appendix" id="s15"><title>Views of reviews</title><p>We randomly sampled 200 reviews from our sample and collected the number of times the review had been viewed online. A histogram of view counts is shown in <xref ref-type="fig" rid="app8fig1">Appendix 8—figure 1</xref>, which had a strong positive skew with most reviews having 10 or fewer views. We used a Poisson model to estimate the annual number of views per year, accounting for the reviews’ publication dates. The mean number of views per year was 1.24 with a 95% credible interval of 1.20–1.28.</p><fig id="app8fig1" position="float"><label>Appendix 8—figure 1.</label><caption><title>Histogram of online view counts of published reviews.</title><p>The bins are in tens starting at [0, 10).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app8-fig1-v1.tif"/></fig></sec></app><app id="appendix-9"><title>Appendix 9</title><sec sec-type="appendix" id="s16"><title>Data validation</title><p>We randomly selected reviews from our analysis data and manually verified the accuracy of our automated data extraction. We checked the accuracy of:</p><list list-type="bullet" id="list5"><list-item><p>Reviewers that were cited</p></list-item><list-item><p>Reviewers that were not cited</p></list-item><list-item><p>Reviewers that included citation(s) to their own articles in their review</p></list-item></list><p>We used a Bayesian calculation to estimate the error rates of our data extraction. We started with a vaguely informative Beta(1, 3.32) prior, which had a 90% probability that the error rate was under 0.5. This vague prior was used to exclude high error rates which were unlikely given our testing of the code during the construction of the data extraction. We created posterior estimates for the error rates using the observed counts of errors from manual checks. We calculated the 90% limits for the posterior distributions as an upper estimate of the error rates.</p><p>The distributions are plotted in <xref ref-type="fig" rid="app9fig1">Appendix 9—figure 1</xref> and the error rates are shown in <xref ref-type="table" rid="app9table1">Appendix 9—table 1</xref>. The errors are proportions, with 0 for no errors and 1 for all errors. The highest error rate was for citation(s) to their own articles.</p><fig id="app9fig1" position="float"><label>Appendix 9—figure 1.</label><caption><title>Distributions of the error rates.</title><p>Vaguely informative prior and posteriors for errors for not cited reviewers, cited reviewers, and self-citations. The dashed vertical lines are at Pr(error <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mo>≤</mml:mo><mml:mi>x</mml:mi></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$\leq x$\end{document}</tex-math></alternatives></inline-formula>) = 90%.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-108748-app9-fig1-v1.tif"/></fig><table-wrap id="app9table1" position="float"><label>Appendix 9—table 1.</label><caption><title>Number of errors found in our data extraction algorithm from manual checks and the estimated 90% limit for the error rate.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Check</th><th align="left" valign="bottom">Number checked</th><th align="left" valign="bottom">Errors found</th><th align="left" valign="bottom">Pr(Error rate ≤<italic>x</italic>) = 90%</th></tr></thead><tbody><tr><td align="left" valign="bottom">Reviewer not cited</td><td align="char" char="." valign="bottom">100</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">0.051</td></tr><tr><td align="left" valign="bottom">Reviewer cited</td><td align="char" char="." valign="bottom">100</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">0.037</td></tr><tr><td align="left" valign="bottom">Reviewer’s citation to their own articles</td><td align="char" char="." valign="bottom">80</td><td align="char" char="." valign="bottom">4</td><td align="char" char="." valign="bottom">0.094</td></tr></tbody></table></table-wrap><p>The two errors for reviewers not being cited were for citations to a book and a conference paper that did not have a DOI. All four errors in capturing self-citations were where the number captured was fewer than the true number; for example, we extracted 1 self-citation when the true number was 3.</p></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.108748.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Rodgers</surname><given-names>Peter</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>eLife</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This <bold>important</bold> study explored a number of issues related to citations in the peer review process. An analysis of more than 37000 peer reviews at four journals found that: (i) during the first round of review, reviewers were less likely to recommend acceptance if the article under review cited the reviewer's own articles; (ii) during the second and subsequent rounds of review, reviewers were more likely to recommend acceptance if the article cited the reviewer's own articles; (iii) during all rounds of review, reviewers who asked authors to cite the reviewer's own articles (a practice known as 'coercive citation') were less likely to recommend acceptance. However, when an author agreed to cite work by the reviewer, the reviewer was more likely to recommend acceptance of the revised article. The evidence to support these claims is <bold>convincing</bold>.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.108748.4.sa1</article-id><title-group><article-title>Joint Public Review:</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>From Reviewer 3 previously: Barnett examines a pressing question regarding citing behavior of authors during the peer review process. In particular, the author studies the interaction between reviewers and authors, focusing on the odds of acceptance, and how this may be affected by whether or not the authors cited the reviewers' prior work, whether the reviewer requested such citations be added, and whether the authors complied/how that affected the reviewer decision-making.</p><p>Key findings are (a) that reviewers were more likely to approve an article if cited in the submission, (b) reviewers who requested a citation in an updated version were less likely to approve, and (c) reviewers who requested and received a citation were more likely to approve the revised version.</p><p>Comment from the Reviewing Editor about the latest version:</p><p>This is the third version of this article. Comments made during the peer review of the second version, along with author's responses to these comments, are available below.</p><p>Comments made during the peer review of the first version, along with author's responses to these comments, are available with previous versions of the article.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.108748.4.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Barnett</surname><given-names>Adrian</given-names></name><role specific-use="author">Author</role><aff><institution>Queensland University of Technology</institution><addr-line><named-content content-type="city">Brisbane</named-content></addr-line><country>Australia</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Editors comments:</bold></p><p>I would encourage you to submit a revised version that addresses the following two points:</p><p>[a] The point from Reviewer #1 about a possible major confounding factor. The following article might be germane here: Baas and Fennell, 2019: <ext-link ext-link-type="uri" xlink:href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3339568">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3339568</ext-link></p></disp-quote><p>I don’t believe that the point raised by reviewer 1 is a confounder, see my response below.</p><p>This article highlighted was in my reading list, but I did not cite it because I was confused by its methods.</p><disp-quote content-type="editor-comment"><p>The point from Reviewer #4 about the abstract. It is important that the abstract says something about how reviewers reacted to the original versions of articles in which they were cited (ie, the odds ratio = 0.84, etc result), before going on to discuss how they reacted to revised articles (ie, the odds ratio = 1.61, etc result). I would suggest doing this along the following lines - but please feel free to reword the passage &quot;but this effect was not strong/conclusive&quot;:</p><p>When reviewers were cited in the original version of the article under review, they were less likely to approve the article compared with reviewers who were not cited, but this effect was not strong/conclusive (odds ratio = 0.84; adjusted 99.4% CI: 0.69-1.03). However, when reviewers were cited in the revised version of the article, they were more likely to approve compared with reviewers who were not cited (odds ratio = 1.61; adjusted 99.4% CI: 1.16-2.23).</p></disp-quote><p>I have changed the abstract to include the odds ratios for version 1 and have used the same wording as from the main text.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>The work used open peer reviews and followed them through a succession of reviews and author revisions. It assessed whether a reviewer had requested the author include additional citations and references to the reviewers' work. It then assessed whether the author had followed these suggestions and what the probability of acceptance was based on the authors decision. Reviewers who were cited were more likely to recommend the article for publication when compared with reviewers that were not cited. Reviewers who requested and received a citation were much likely to accept than reviewers that requested and did not receive a citation.</p><p>Strengths and weaknesses:</p><p>The work's strengths are the in-depth and thorough statistical analysis it contains and the very large dataset it uses. The methods are robust and reported in detail.</p><p>I am still concerned that there is a major confounding factor: if you ignore the reviewers requests for citations are you more likely to have ignored all their other suggestions too? This has now been mentioned briefly and slightly circuitously in the limitations section. I would still like this (I think) major limitation to be given more consideration and discussion, although I am happy that it cannot be addressed directly in the analysis.</p></disp-quote><p>This is likely to happen, but I do not think it’s a confounder. A confounder needs to be associated with both the outcome and the exposure of interest. If we consider forthright authors who are more likely to rebuff all suggestions, then they would receive just as many citation and self-citation requests as authors who were more compliant. The behaviour of forthright authors would likely only reduce the association seen in most authors which would be reflected in the odds ratios.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>This article examines reviewer coercion in the form of requesting citations to the reviewer's own work as a possible trade for acceptance and shows that, under certain conditions, this happens.</p><p>Strengths:</p><p>The methods are well done and the results support the conclusions that some reviewers &quot;request&quot; self-citations and may be making acceptance decisions based on whether an author fulfills that request.</p><p>Weakness:</p><p>I thank the author for addressing my comments about the original version.</p><p><bold>Reviewer #3 (Public review):</bold></p><p>Summary:</p><p>In this article, Barnett examines a pressing question regarding citing behavior of authors during the peer review process. In particular, the author studies the interaction between reviewers and authors, focusing on the odds of acceptance, and how this may be affected by whether or not the authors cited the reviewers' prior work, whether the reviewer requested such citations be added, and whether the authors complied/how that affected the reviewer decision-making.</p><p>Strengths:</p><p>The author uses a clever analytical design, examining four journals that use the same open peer review system, in which the identities of the authors and reviewers are both available and linkable to structured data. Categorical information about the approval is also available as structured data. This design allows a large scale investigation of this question.</p><p>Weaknesses:</p><p>My original concerns have been largely addressed. Much more detail is provided about the number of documents under consideration for each analysis, which clarifies a great deal.</p><p>Much of the observed reviewer behavior disappears or has much lower effect sizes depending on whether &quot;Accept with Reservations&quot; is considered an Accept or a Reject. This is acknowledged in the results text. Language has been toned down in the revised version.</p><p>The conditional analysis on the 441 reviews (lines 224-228) does support the revised interpretation as presented.</p><p>No additional concerns are noted.</p><p><bold>Reviewer #4 (Public review):</bold></p><p>Summary:</p><p>This work investigates whether a citation to a referee made by a paper is associated with a more positive evaluation by that referee for that paper. It provides evidence supporting this hypothesis. The work also investigates the role of self-citations by referees where the referee would ask authors to cite the referee's paper.</p><p>Strengths:</p><p>This is an important problem: referees for scientific papers must provide their impartial opinions rooted in core scientific principles. Any undue influence due to the role of citations breaks this requirement. This work studies the possible presence and extent of this.</p><p>The methods are solid and well done. The work uses a matched pair design which controls for article-level confounding and further investigates robustness to other potential confounds.</p><p>Weaknesses:</p><p>The authors have addressed most concerns in the initial review. The only remaining concern is the asymmetric reporting and highlighting of version 1 (null result) versus version 2 (rejecting null). For example the abstract says &quot;We find that reviewers who were cited in the article under review were more likely to recommend approval, but only after the first version (odds ratio = 1.61; adjusted 99.4% CI: 1.16 to 2.23)&quot; instead of a symmetric sentence &quot;We find ... in version 1 and ... in version 2&quot;.</p></disp-quote><p>The latest version now includes the results for both versions.</p></body></sub-article></article>