<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">89873</article-id><article-id pub-id-type="doi">10.7554/eLife.89873</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89873.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Multi-level processing of emotions in life motion signals revealed through pupil responses</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Yuan</surname><given-names>Tian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8570-1484</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Wang</surname><given-names>Li</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2204-5192</contrib-id><email>wangli@psych.ac.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Jiang</surname><given-names>Yi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5746-7301</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/034t30j35</institution-id><institution>State Key Laboratory of Brain and Cognitive Science, Institute of Psychology, Chinese Academy of Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/034t30j35</institution-id><institution>Department of Psychology, University of Chinese Academy of Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Zhang</surname><given-names>Xilin</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>South China Normal University</institution></institution-wrap><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>Beijing Normal University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>14</day><month>10</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP89873</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-06-16"><day>16</day><month>06</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-07-19"><day>19</day><month>07</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.18.549471"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-08-31"><day>31</day><month>08</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89873.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-30"><day>30</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.89873.2"/></event></pub-history><permissions><copyright-statement>© 2023, Yuan et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Yuan et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-89873-v1.pdf"/><abstract><p>Perceiving emotions from the movements of other biological entities is critical for human survival and interpersonal interactions. Here, we report that emotional information conveyed by point-light biological motion (BM) triggered automatic physiological responses as reflected in pupil size. Specifically, happy BM evoked larger pupil size than neutral and sad BM, while sad BM induced a smaller pupil response than neutral BM. Moreover, this happy over sad pupil dilation effect is negatively correlated with individual autistic traits. Notably, emotional BM with only local motion features retained could also exert modulations on pupils. Compared with intact BM, both happy and sad local BM evoked stronger pupil responses than neutral local BM starting from an earlier time point, with no difference between the happy and sad conditions. These results revealed a fine-grained pupil-related emotional modulation induced by intact BM and a coarse but rapid modulation by local BM, demonstrating multi-level processing of emotions in life motion signals. Taken together, our findings shed new light on BM emotion processing, and highlight the potential of utilizing the emotion-modulated pupil response to facilitate the diagnosis of social cognitive disorders.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>pupil size</kwd><kwd>biological motion</kwd><kwd>emotion processing</kwd><kwd>local</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>2021ZD0203800</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002855</institution-id><institution>Ministry of Science and Technology of the People's Republic of China</institution></institution-wrap></funding-source><award-id>2022ZD0205100</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Li</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32430043</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>Interdisciplinary Innovation Team</institution></institution-wrap></funding-source><award-id>JCTD-2021-06</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>Fundamental Research Funds for Central Universities</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>32371106</award-id><principal-award-recipient><name><surname>Wang</surname><given-names>Li</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution>Key Research and Development Program of Guangdong, China</institution></institution-wrap></funding-source><award-id>2023B0303010004</award-id><principal-award-recipient><name><surname>Jiang</surname><given-names>Yi</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Intact and local emotional biological motion exerted distinct influences on pupil responses, wherein the emotional modulation observed in intact biological motion is linked to individual autistic traits.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Perceiving and interpreting emotions from various social signals is critical for human social functioning, which enables us to infer the intentions of our conspecifics and further facilitates interpersonal interactions. Facial expressions present the most common non-verbal social communicative signals regarding others’ affective states and intentions (<xref ref-type="bibr" rid="bib30">Frith, 2009</xref>). In addition to faces, the movement of biological organisms serves as another essential type of social signal carrying significant emotional information, and this information remained salient even from a far distance (<xref ref-type="bibr" rid="bib22">de Gelder, 2006</xref>). The human visual system is highly sensitive to such signals that we can readily decipher emotions from biological motion (BM), even when it was portrayed by several point lights attached to the major joints (<xref ref-type="bibr" rid="bib41">Johansson, 1973</xref>; <xref ref-type="bibr" rid="bib76">Troje, 2008</xref>). Moreover, it has been found that happy point-light walkers were recognized faster and more accurately than sad, angry, or neutral walkers, demonstrating a happiness superiority (<xref ref-type="bibr" rid="bib52">Lee and Kim, 2017</xref>; <xref ref-type="bibr" rid="bib73">Spencer et al., 2016</xref>). While these studies provided some insights into the emotion processing mechanism of BM, they relied mainly on the explicit identification and active evaluation of BM emotions. Importantly, the encoding of emotional information also involves a rather automatic and implicit process that is independent of the participant’s explicit identifications (<xref ref-type="bibr" rid="bib19">Critchley, 2000</xref>; <xref ref-type="bibr" rid="bib51">Lange et al., 2003</xref>; <xref ref-type="bibr" rid="bib60">Okon-Singer et al., 2013</xref>; <xref ref-type="bibr" rid="bib70">Shafer et al., 2012</xref>). Notably, this implicit aspect of emotion processing could be even more effective in probing individual differences and social deficits (<xref ref-type="bibr" rid="bib44">Kana et al., 2016</xref>; <xref ref-type="bibr" rid="bib46">Keifer et al., 2020</xref>; <xref ref-type="bibr" rid="bib50">Kovarski et al., 2019</xref>; <xref ref-type="bibr" rid="bib85">Wong et al., 2008</xref>), as it requires the intuitive processing of emotions that could not be learned (<xref ref-type="bibr" rid="bib29">Frith, 2004</xref>). For example, research has shown that individuals with autistic disorders showed altered neural activities during implicit but not explicit emotion processing of natural scenes (<xref ref-type="bibr" rid="bib44">Kana et al., 2016</xref>). These observations highlighted the importance of using objective measurements to investigate the implicit and automatic aspect of BM emotion processing.</p><p>The pupil response hence serves as a promising approach for reliably unfolding the implicit emotion processing of BM as it adds no extra task requirements to the cognitive process (<xref ref-type="bibr" rid="bib13">Burley et al., 2017</xref>). In particular, pupil size is related to the activity of the automatic nervous system mediated by the locus coeruleus norepinephrine, which not only responds to physical light, but also reflects the underlying cognitive state (<xref ref-type="bibr" rid="bib43">Joshi and Gold, 2020</xref>). Moreover, it could spontaneously capture the current subjective state and is thus useful for revealing the time course of the related cognitive processing (<xref ref-type="bibr" rid="bib21">de Gee et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Graves et al., 2021</xref>; <xref ref-type="bibr" rid="bib48">Kloosterman et al., 2015</xref>; <xref ref-type="bibr" rid="bib61">Oliva and Anikin, 2018</xref>). Recently, this measurement has been introduced to the field of emotion perception, and emerging evidence has suggested that emotions conveyed by social signals (e.g., faces, voices) could modulate pupil responses. For instance, happy and angry dynamic faces elicited a pupil dilation effect as compared with sad and neutral faces (<xref ref-type="bibr" rid="bib14">Burley and Daughters, 2020</xref>; <xref ref-type="bibr" rid="bib67">Prunty et al., 2022</xref>). Noticeably, the point-light BM, as another critical type of social signal, also conveyed salient affective information. Besides, its emotion processing mechanism is closely connected with that of faces (<xref ref-type="bibr" rid="bib3">Alaerts et al., 2011</xref>; <xref ref-type="bibr" rid="bib8">Becker et al., 2011</xref>; <xref ref-type="bibr" rid="bib52">Lee and Kim, 2017</xref>; <xref ref-type="bibr" rid="bib88">Yuan et al., 2024</xref>). However, it remains unequivocal whether the pupil also responds to the emotional information carried by the minimalistic point-light walker display. Such physiological observation can faithfully uncover the implicit emotion processing of BM, and it also expands the existing line of inquiry on the emotion processing of social cues.</p><p>To fill this gap, the current study implemented the pupil recording technique together with the passive viewing paradigm to explore the automatic and implicit emotion processing of BM. We first investigated the pupil responses to point-light walkers with different emotions (i.e., happy, sad, and neutral). In addition to intact emotional BM sequences, we also tested scrambled emotional BM sequences, which lack the gestalt of a global figure but preserve the same local motion components as the intact walkers. Recent studies have shown that such local motion signals play an essential role in conveying biologically salient information such as animacy, and walking direction (<xref ref-type="bibr" rid="bib16">Chang and Troje, 2008</xref>; <xref ref-type="bibr" rid="bib17">Chang and Troje, 2009</xref>; <xref ref-type="bibr" rid="bib75">Troje and Westhoff, 2006</xref>). This study went further to investigate whether this local BM signal could convey emotional information and elicit corresponding pupil responses. Moreover, given that emotion perception from social signals is generally impaired in individuals with autism (<xref ref-type="bibr" rid="bib36">Harms et al., 2010</xref>; <xref ref-type="bibr" rid="bib39">Hubert et al., 2007</xref>), we also took the individual autistic traits into consideration by measuring the autistic tendencies in normal populations with the autistic quotient (AQ) questionnaire (<xref ref-type="bibr" rid="bib6">Baron-Cohen et al., 2001</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experiments 1a and 1b: intact emotional BM</title><p>In Experiment 1a, we investigated whether emotional BM could automatically exert influences on pupil responses. Specifically, participants were instructed to passively view the intact happy/sad/neutral BM with their pupil responses being recorded simultaneously (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). A cluster-based permutation analysis was applied to illustrate the time course of emotional modulations on pupil responses. Results showed that the happy BM induced a significant pupil dilation effect than the neutral BM from 1750 to 3200 ms (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). Conversely, the sad BM evoked a significantly smaller pupil response than the neutral BM, which starts from 1850 ms until the end of the stimulus presentation (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). Moreover, the happy BM evoked a significantly larger pupil response as compared to the sad BM in a longstanding time window, ranging from 1200 ms until the disappearance of the display (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Schematic representation of the experimental procedure and the stimuli in Experiment 1a.</title><p>A happy/sad/neutral biological motion (BM) walker turning 45° leftwards or rightwards was presented at the center of the screen for 4000 ms. Participants were instructed to maintain their fixation on the BM stimuli during stimulus presentation and to continue the procedure through key pressing.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-fig1-v1.tif"/></fig><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Time course of pupil responses to happy, sad, and neutral biological motion (BM) in Experiments 1–4.</title><p>Solid lines represent pupil diameter under each emotional condition as a function of time (happy: red; sad: blue; neutral: gray); shaded areas represent the standard error of the mean (SEM) between participants (N = 24); colored horizontal lines indicate periods during which there are statistically significant differences among conditions at p &lt; 0.05; and black horizontal lines indicate significant differences after cluster-based permutation correction. All the pupil data are in arbitrary units (a.u.) (<bold>A</bold>) In Experiment 1a, the happy BM evoked larger pupil response as compared to the sad and neutral BM, and the sad BM evoked smaller pupil size than the neutral BM. (<bold>B</bold>) In Experiment 2, the inverted BM failed to produce such emotional modulation effects. (<bold>C</bold>) In Experiment 3, the emotional BM that is deprived of the local motion feature exerted no emotional modulation on pupil responses. (<bold>D</bold>) In Experiment 4, both the happy and sad local BM induced a larger pupil response than the neutral local BM, and such dilation effect started from a relatively early time point.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-fig2-v1.tif"/></fig><p>We then computed the mean pupil size by collapsing the pupillometry across all time points, ranging from the onset of the stimuli to the end of the stimuli presentation. A one-way repeated measures analysis of variance (ANOVA) was conducted on the mean pupil size for each emotional condition (happy, sad, neutral), and the results showed a significant main effect of emotional condition (<italic>F</italic>(1.4, 32.2) = 8.92, p = 0.002, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.28; Greenhouse–Geisser corrected, <xref ref-type="fig" rid="fig3">Figure 3A</xref>). On average, the happy BM induced a significantly larger pupil response than the neutral BM (<italic>t</italic>(23) = 2.73, p = 0.024, Cohen’s <italic>d</italic> = 0.56, 95% confidence interval (CI) for the mean difference = [0.04, 0.27]; Holm-corrected, p = 0.036 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3A</xref>). In contrast, the sad BM evoked a significantly smaller pupil size than the neutral BM (sad vs. neutral: <italic>t</italic>(23) = −2.43, p = 0.024, Cohen’s <italic>d</italic> = 0.50, 95% CI for the mean difference = [−0.35, −0.03]; Holm-corrected, p = 0.071 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3A</xref>). Moreover, the happy BM evoked a significantly larger pupil size than the sad BM (<italic>t</italic>(23) = 3.34, p = 0.009, Cohen’s <italic>d</italic> = 0.68, 95% CI for the mean difference = [0.13, 0.55]; Holm-corrected, p = 0.009 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3A</xref>), which echoes with former studies showing a happiness advantage in BM processing (<xref ref-type="bibr" rid="bib1">Actis-Grosso et al., 2015</xref>; <xref ref-type="bibr" rid="bib52">Lee and Kim, 2017</xref>; <xref ref-type="bibr" rid="bib73">Spencer et al., 2016</xref>; <xref ref-type="bibr" rid="bib87">Yuan et al., 2023</xref>). Importantly, the observed happy over sad dilation effect is negatively correlated with the individual autistic traits (<italic>r</italic>(22) = −0.47, p = 0.022, 95% CI for the mean difference = [−0.73, −0.08], <xref ref-type="fig" rid="fig4">Figure 4A</xref>), indicating a compromised ability to perceive emotions from BM among individuals with higher autism tendencies. No significant correlations were found between AQ and other pupil modulation effects (<xref ref-type="fig" rid="fig4">Figure 4B, C</xref>). Additionally, no significant correlations were observed between AQ and the original pupil responses induced by happy/neutral/sad BM (see <xref ref-type="fig" rid="fig5">Figure 5A</xref>). This is potentially because the original pupil response is a mixed result of stimuli perception and emotion perception, while the pupil changes across emotional conditions could more faithfully reflect individual sensitivities to emotions in BM (<xref ref-type="bibr" rid="bib13">Burley et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Pomè et al., 2020</xref>; <xref ref-type="bibr" rid="bib77">Turi et al., 2018</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Normalized mean pupil responses using the neutral condition as baseline, plotted against happy and sad conditions.</title><p>(<bold>A</bold>) In Experiment 1a, the group average pupil response to happy intact biological motion (BM) is significantly larger than that to sad and neutral BM, while the pupil size induced by sad BM is significantly smaller than that evoked by neutral BM. (<bold>B, C</bold>) Moreover, such an emotional modulation on pupil sizes was again identified in the test and retest of the replication experiment (Experiment 1b). (<bold>D</bold>) In Experiment 2, no significant differences in pupil responses were observed for inverted BM. (<bold>E</bold>) In Experiment 3, when the biological characteristic was deprived from the emotional BM, it failed to induce any modulations on pupil sizes. (<bold>F</bold>) In Experiment 4, both the happy and sad local BM induced a significantly larger pupil size than neutral local BM, with no significant difference between the happy and sad condition. All the pupil data are in arbitrary units (a.u.). Each point represents one individual data. Error bars showed standard errors of the mean (N = 24). *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-fig3-v1.tif"/></fig><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Correlation results for pupil modulations and autistic quotient (AQ) scores in Experiment 1a and its replication experiment (Experiment 1b).</title><p>(<bold>A</bold>) In Experiment 1a, a significant negative correlation was found between the happy over sad pupil dilation effect and individual AQ. (<bold>B, C</bold>) No other significant correlations were found. (<bold>D–F</bold>) The first test of Experiment 1b replicated the negative correlation between happy over sad pupil dilation effect and AQ. Similarly, no other significant correlations were found. (<bold>G</bold>) In the second test, the negative correlation between happy over sad pupil dilation effect and AQ was similarly observed and even stronger. (<bold>H, I</bold>) Moreover, we have additionally observed a significant positive correlation between AQ and the happy minus neutral pupil dilation effect, and a significant negative correlation between AQ and the sad minus neutral pupil constriction effect. Dots in the scatter plot indicate the individual data and the shaded region indicates the 95% confidence interval (N = 24).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-fig4-v1.tif"/></fig><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Correlation results for autistic quotient (AQ) scores and pupil responses toward happy, sad, and neutral biological motion (BM) across four experiments.</title><p>No significant correlations were observed. Dots in the scatter plot indicate the individual data and the shaded region indicates the 95% confidence interval (N = 24).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-fig5-v1.tif"/></fig><p>To strengthen the correlation results, we conducted a replication experiment (Experiment 1b) and added a test–retest examination to further assess the reliability of our measurements. Specifically, a new group of participants were recruited to perform the identical task, and they were asked to return to the lab for a retest. The results again revealed the main effect of emotional condition in both the first test (<italic>F</italic>(2, 46) = 12.0, p &lt; 0.001, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.34, <xref ref-type="fig" rid="fig3">Figure 3B</xref>) and the second test (<italic>F</italic>(2, 46) = 14.8, p &lt; 0.001, <italic>η</italic><sub>p</sub><sup>2</sup>=0.39, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). The happy BM induced a significantly larger pupil response than the neutral BM (first test: <italic>t</italic>(23) = 2.60, p = 0.022, Cohen’s <italic>d</italic> = 0.53, 95% CI for the mean difference = [0.02, 0.14], Holm-corrected, p = 0.048 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3B</xref>; second test: <italic>t</italic>(23) = 3.36, p = 0.005, Cohen’s <italic>d</italic> = 0.69, 95% CI for the mean difference = [0.06, 0.24], Holm-corrected, p = 0.008 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). On the contrary, the sad BM induced a significantly smaller pupil response than the neutral BM (first test: <italic>t</italic>(23) = −2.77, p = 0.022, Cohen’s <italic>d</italic> = 0.57, 95% CI for the mean difference = [−0.19, −0.03], Holm-corrected, p = 0.033 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3B</xref>; second test: <italic>t</italic>(23) = −3.19, p = 0.005, Cohen’s <italic>d</italic> = 0.65, 95% CI for the mean difference = [−0.24, −0.05], Holm-corrected, p = 0.012 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). Besides, the happy BM induced significantly larger pupil response than the sad BM (first test: <italic>t</italic>(23) = 4.23, p &lt; 0.001, Cohen’s <italic>d</italic> = 0.86, 95% CI for the mean difference = [0.10, 0.28], Holm-corrected, p &lt; 0.001 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3B</xref>; second test: <italic>t</italic>(23) = 4.26, p &lt; 0.001, Cohen’s <italic>d</italic> = 0.87, 95% CI for the mean difference = [0.15, 0.44], Holm-corrected, p &lt; 0.001 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). The results of the cluster-based permutation analysis were also similar. The first test of Experiment 1b revealed that the happy BM induced significantly larger pupil responses than the neutral BM from 3250 to 4000 ms, and the sad BM evoked significantly smaller pupil response than the neutral BM from 2950 to 4000 ms. Additionally, the happy BM evoked a significantly larger pupil response as compared to the sad BM from 1450 to 4000 ms (see <xref ref-type="fig" rid="fig6">Figure 6A</xref>). Results of the second test revealed that the happy BM induced a significant pupil dilation effect than the neutral BM from 1900 to 4000 ms, and the sad BM evoked a significantly smaller pupil response than the neutral BM from 2450 to 4000 ms. Additionally, the happy BM evoked larger pupil responses as compared to the sad BM from from 1200 to 4000 ms (see <xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Time course of pupil responses to happy, sad, and neutral biological motion (BM) in Experiment 1b.</title><p>Solid lines represent pupil diameter under each emotional condition as a function of time (happy: red; sad: blue; neutral: gray); shaded areas represent the standard error of the mean (SEM) between participants (N = 24); colored horizontal lines indicate periods during which there are statistically significant differences among conditions at p &lt; 0.05; and black horizontal lines indicate significant differences after cluster-based permutation correction. All the pupil data are in arbitrary units (a.u.). (<bold>A</bold>) In the first test of Experiment 1b, we successfully replicated the results of Experiment 1a: the happy BM evoked larger pupil response as compared to the sad and neutral BM, and the sad BM evoked smaller pupil size than the neutral BM. (<bold>B</bold>) Such results were similarly observed in the retest.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-fig6-v1.tif"/></fig><p>Notably, we successfully replicated the negative correlation between the happy over sad dilation effect and individual autistic traits (<italic>r</italic>(22) = −0.46, p = 0.023, 95% CI for the mean difference = [−0.73, −0.07], <xref ref-type="fig" rid="fig4">Figure 4D</xref>) in the first test of Experiment 1b. No other significant correlations were found (see <xref ref-type="fig" rid="fig4">Figures 4E, F</xref> and <xref ref-type="fig" rid="fig5">Figure 5B, C</xref>). Moreover, in the second test, such a correlation was similarly found and was even stronger (<italic>r</italic>(22) = −0.61, p = 0.002, 95% CI for the mean difference = [−0.81, −0.27], <xref ref-type="fig" rid="fig4">Figure 4G</xref>). A test–retest reliability analysis was performed on the happy over sad pupil dilation effect and the AQ score, and the results showed robust correlations (<italic>r</italic>(happy–sad pupil size) = 0.56; <italic>r</italic>(AQ) = 0.90) and strong test–retest reliabilities (<italic>α</italic>(happy–sad pupil size) = 0.60; <italic>α</italic>(AQ) = 0.82). Furthermore, in the second test, we have additionally observed a significant negative correlation between AQ and the happy minus neutral pupil dilation effect (<italic>r</italic>(22) = −0.44, p = 0.032, 95% CI for the mean difference = [−0.72, −0.04], <xref ref-type="fig" rid="fig4">Figure 4H</xref>), and a significant positive correlation between the sad minus neutral pupil size and AQ (<italic>r</italic>(22) = 0.50, p = 0.014, 95% CI for the mean difference = [0.12, 0.75], <xref ref-type="fig" rid="fig4">Figure 4I</xref>). This indicated that the overall correlation between happy over sad dilation effect and AQ was the aggregate outcome of the diminished pupil modulations by happy and sad BM for high AQ individuals.</p><p>Overall, these results demonstrated a robust and replicable modulation of emotions embedded in the minimized point-light walker on pupil sizes: the happy BM evoked a larger pupil response than the neutral BM, while the sad BM evoked a smaller pupil size as compared to the neutral one. Importantly, a significant negative correlation between AQ and happy over sad pupil dilation effect was consistently found, and such effect was caused by a general attenuation in BM emotion perception sensitivity among individuals with high autistic tendencies.</p></sec><sec id="s2-2"><title>Experiment 2: inverted emotional BM</title><p>To rule out the possibility that the difference in low-level visual features rather than the emotional information per se might account for the obtained emotional modulation effect, we presented observers with the inverted BM stimuli that shared the exact perceptual features with their upright counterparts in Experiment 2. The cluster-based permutation analysis observed no significantly different time points among three emotional conditions (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). An identical one-way repeated measures ANOVA was conducted, while no significant main effect of emotional condition on pupil responses was observed in inverted BM (<italic>F</italic>(2, 46) = 0.95, p = 0.396, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.04, <xref ref-type="fig" rid="fig3">Figure 3D</xref>). Besides, no significant correlations between AQ and pupil modulations were found (AQ with happy–sad pupil size: <italic>r</italic>(22) = 0.14, p = 0.512, 95% CI for the mean difference = [−0.28, 0.52]; AQ with happy–neutral pupil size: <italic>r</italic>(22) = 0.26, p = 0.227, 95% CI for the mean difference = [−0.16, 0.60]; AQ with sad-neutral pupil size: <italic>r</italic>(22) = 0.19, p = 0.376, 95% CI for the mean difference = [−0.23, 0.55]). No other correlations were observed (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). Critically, the mixed 2 (orientation: upright, inverted) × 3 (emotional condition: happy, sad, neutral) ANOVA on the average pupil size obtained in Experiments 1a and 2 showed a significant interaction between orientation and emotional condition (<italic>F</italic>(2, 92) = 4.53, p = 0.013, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.09), which could be attributed to the diminishment of emotional modulation in inverted BM. This indicated that the observed emotional modulation of pupil responses did not arise from low-level visual differences.</p></sec><sec id="s2-3"><title>Experiment 3: non-biological motion</title><p>Given the ample evidence showing that local motion feature is essential for the perception of biologically significant information from BM (<xref ref-type="bibr" rid="bib16">Chang and Troje, 2008</xref>; <xref ref-type="bibr" rid="bib17">Chang and Troje, 2009</xref>; <xref ref-type="bibr" rid="bib75">Troje and Westhoff, 2006</xref>; <xref ref-type="bibr" rid="bib82">Wang and Jiang, 2012</xref>), we moved forward to explore the role of local motion feature in the emotion processing of BM. In Experiment 3, we presented observers with non-BM stimuli, which were derived from the fragments identical to emotional BM but with critical local characteristics removed (<xref ref-type="bibr" rid="bib17">Chang and Troje, 2009</xref>). The permutation analysis found no significantly different time points in pupil responses to the happy, sad, and neutral conditions (see <xref ref-type="fig" rid="fig2">Figure 2D</xref>). Results of the one-way repeated ANOVA on the average pupil sizes also showed no significant main effect of emotional condition (<italic>F</italic>(1.6, 35.7) = 0.02, p = 0.964, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.00; Greenhouse–Geisser corrected, see <xref ref-type="fig" rid="fig3">Figure 3C</xref>). Similarly, no pupil modulation effects significantly correlated with AQ (AQ with happy–sad pupil size: <italic>r</italic>(22) = −0.03, p = 0.896, 95% CI for the mean difference = [−0.43, 0.38]; AQ with happy–neutral pupil size: <italic>r</italic>(22) = 0.01, p = 0.956, 95% CI for the mean difference = [−0.39, 0.41]; AQ with sad–neutral pupil size: <italic>r</italic>(22) = 0.06, p = 0.777, 95% CI for the mean difference = [−0.35, 0.45]). No correlations were observed between AQ scores and pupil responses toward happy, sad, and neutral BM (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). Moreover, combining the results obtained from Experiments 1a and 3, we found a significant interaction between stimulus type (intact, non-biological) and emotional condition (happy, sad, neutral) (<italic>F</italic>(2, 92) = 3.22, p = 0.045, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.07), which was caused by the lack of emotional modulation in non-biological stimuli. These findings together showed that the removal of local characteristics greatly disrupted the emotional modulations on observers’ pupil responses, providing conceivable evidence for the critical contribution of local motion features in emotion perception from the BM signal.</p></sec><sec id="s2-4"><title>Experiment 4: local emotional BM</title><p>In Experiment 4, we went further to examine whether local BM alone could carry emotional information and exert a similar modulation effect on pupil size. In particular, we adopted the well-established local BM stimuli, the scrambled BM, whose local motion feature was retained while the global configuration information was completely disrupted. Both the explicit and implicit emotion processing of the scrambled BM were investigated to provide a thorough view of emotion perception from local BM. Specifically, a group of observers viewed the scrambled BM and made explicit behavioral judgments on the emotional information contained in the scrambled BM. The results showed that observers could successfully recognize the emotions contained in scrambled BMs with the average accuracy reaching significantly above 50% (<italic>M</italic> ± standard error of mean [SEM] = 83 ± 2.9%, p &lt; 0.001). This indicated that scrambled BM conveyed recognizable emotional information.</p><p>Furthermore, we investigated the pupil responses to scrambled happy, sad, and neutral BMs to explore the automatic and implicit processing of local emotional BM. The consecutive cluster-based permutation analysis further showed that both the scrambled happy and sad BM evoked larger pupil sizes than the scrambled neutral BM. Importantly, such effect appeared in a rather early time window and could last for a quite long time (happy vs. neutral: 450–3550 ms; sad vs. neutral: 350–4000 ms, see <xref ref-type="fig" rid="fig2">Figure 2D</xref>). The one-way repeated measures ANOVA on the mean pupil size indicated a significant main effect of emotional condition (<italic>F</italic>(2, 46) = 6.47, p = 0.003, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.22, <xref ref-type="fig" rid="fig3">Figure 3F</xref>). Follow-up analysis showed that the scrambled happy BM induced a significantly larger pupil response than the scrambled neutral BM (<italic>t</italic>(23) = 3.22, p = 0.008, Cohen’s <italic>d</italic> = 0.66, 95% CI for the mean difference = [0.12, 0.53]; Holm-corrected, p = 0.011 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3F</xref>), which is similar to that observed in Experiments 1a and 1b. Notably, the scrambled sad BM also induced a larger pupil size than the neutral one (<italic>t</italic>(23) = 3.41, p = 0.007, Cohen’s <italic>d</italic> = 0.70, 95% CI for the mean difference = [0.12, 0.51]; Holm-corrected, p = 0.007 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3F</xref>). Moreover, no difference in pupil size is observed between the happy and sad conditions (<italic>t</italic>(23) = −0.07, p = 0.948, Cohen’s <italic>d</italic> = 0.01, 95% CI for the mean difference = [−0.23, 0.24]; Holm-corrected, p <italic>=</italic> 1.000 after Bonferroni correction, <xref ref-type="fig" rid="fig3">Figure 3F</xref>). The observed effect could not be accounted for by perceptual differences (e.g., speed), as the happy and sad scrambled BM differed the most in low-level features, whereas they induced similar dilation effects on pupil sizes. Again, no significant correlations were observed between AQ and pupil modulation effects (AQ with happy–sad pupil size: <italic>r</italic>(22) = −0.21, p = 0.32, 95% CI for the mean difference = [−0.57, 0.21]; AQ with happy–neutral pupil size: <italic>r</italic>(22) = −0.13, p = 0.56, 95% CI for the mean difference = [−0.50, 0.29]; AQ with sad–neutral pupil size: <italic>r</italic>(22) = 0.13, p = 0.56, 95% CI for the mean difference = [−0.29, 0.50]). No other correlations were observed (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). Importantly, a mixed 2 (BM type: intact, local) × 3 (emotional condition: happy, sad, neutral) ANOVA on average pupil size was conducted to examine whether or not this emotional modulation effect of local BM varied from that of intact BM reported in Experiments 1a. Results revealed a significant interaction between BM type and emotional condition (<italic>F</italic>(2, 92) = 7.76, p &lt; 0.001, <italic>η</italic><sub>p</sub><sup>2</sup> = 0.14), indicating that emotions in intact and local BM exerted differential modulations on pupil size. This interaction is primarily driven by the vanishment of pupil modulation between happy and sad local BM. Overall, these findings showed that the local BM could convey significant emotional information, which could induce a pupil dilation effect regardless of its exact type. As compared to the intact BM, the emotional modulation observed in local BM is different because it occurs faster and is rather coarse.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Life motion signals convey salient emotional information that is crucial for human survival and social interactions (<xref ref-type="bibr" rid="bib41">Johansson, 1973</xref>; <xref ref-type="bibr" rid="bib76">Troje, 2008</xref>). Here, we reported that such emotional clues carried by the point-light BM walker could exert a modulation effect on pupil responses. Specifically, the happy BM significantly dilated pupils as compared to the neutral BM, and the sad BM evoked smaller pupil responses than the neutral BM, showing distinct emotional modulations on pupil responses that depend on the emotional contents. Moreover, this emotional modulation of pupil responses could not be explained by the low-level differences, as viewing inverted BMs failed to induce such effects. Importantly, when the emotional BM was deprived of the local motion feature through the removal of accelerations, it failed to induce any modulation on pupil responses. Furthermore, the scrambled emotional BM with only the local motion feature retained could still produce a modulation effect on pupil size. Noticeably, this modulation is rapid but rather coarse: viewing the scrambled happy and sad BM would evoke greater pupil size than the scrambled neutral BM in a relatively early time window, while no significant difference was observed between the scrambled happy and sad BM. Taken together, these findings revealed multi-level processing of emotions in life motion signals: the global emotional BM-modulated pupil size in a fine-grained manner that discriminates each type of emotion, and the local emotional BM exerted a coarse but rapid modulation on pupil size.</p><p>The emotion processing of BM has been investigated in former studies using explicit behavioral detection and recognition paradigm. It has been reported that happy BM is more rapidly identified and detected as compared to sad and neutral BM (<xref ref-type="bibr" rid="bib1">Actis-Grosso et al., 2015</xref>; <xref ref-type="bibr" rid="bib52">Lee and Kim, 2017</xref>; <xref ref-type="bibr" rid="bib73">Spencer et al., 2016</xref>), while other research observed no such superiority (<xref ref-type="bibr" rid="bib18">Chouchourelou et al., 2006</xref>). Here, the present study adopted the novel and objective pupillometry index to investigate the emotion processing of BM from a physiological aspect. The pupil index, as a direct reflection of individual arousal level and cognitive state, served as a powerful tool for faithfully and automatically reflecting the implicit processing of emotions in BM. Previous studies have reported larger pupil responses toward emotional images as compared to neutral images, with no significant differences observed between the positive and negative conditions (<xref ref-type="bibr" rid="bib11">Bradley and Lang, 2015</xref>; <xref ref-type="bibr" rid="bib10">Bradley et al., 2008</xref>; <xref ref-type="bibr" rid="bib72">Snowden et al., 2016</xref>). However, these studies mostly adopted complex emotional scene images that conveyed rather general emotional information. When it comes to the specific emotion cues (e.g., happy, sad) delivered by our conspecifics through biologically salient signals (e.g., faces, gestures, voices), the results became intermixed. Some studies reported pupil dilatory effects toward fearful, disgusted, angry, sad faces but not happy faces (<xref ref-type="bibr" rid="bib13">Burley et al., 2017</xref>). On the contrary, other studies observed larger pupil responses for happy as compared to sad, fearful, and surprised faces (<xref ref-type="bibr" rid="bib2">Aktar et al., 2018</xref>; <xref ref-type="bibr" rid="bib14">Burley and Daughters, 2020</xref>; <xref ref-type="bibr" rid="bib40">Jessen et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Prunty et al., 2022</xref>). These conflicting results could be due to the low-level confounds of emotional faces (e.g., eye size) (<xref ref-type="bibr" rid="bib15">Carsten et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Harrison et al., 2006</xref>). Similar to faces, BM also conveyed salient clues concerning the emotional states of our interactive partners. However, they were highly simplified, and deprived of various irrelevant visual confounders (e.g., body shape). Here, we reported that the happy BM induced a stronger pupil response than the neutral and sad BM, lending support to the happy dilation effect observed with faces (<xref ref-type="bibr" rid="bib14">Burley and Daughters, 2020</xref>; <xref ref-type="bibr" rid="bib67">Prunty et al., 2022</xref>). Moreover, it helps ameliorate the concern regarding the low-level confounding factors by identifying similar pupil modulations in another type of social signal with distinctive perceptual features.</p><p>It has long been documented that pupil size reflects the degree of cognitive effort and attention input (<xref ref-type="bibr" rid="bib43">Joshi and Gold, 2020</xref>; <xref ref-type="bibr" rid="bib78">van der Wel and van Steenbergen, 2018</xref>), and indexes the noradrenalin activity in emotion processing structures like amygdala (<xref ref-type="bibr" rid="bib20">Dal Monte et al., 2015</xref>; <xref ref-type="bibr" rid="bib37">Harrison et al., 2006</xref>; <xref ref-type="bibr" rid="bib53">Liddell et al., 2005</xref>). Thus, the happy dilation effect suggests that the happy BM may be more effective in capturing attention and evoking emotional arousal than the neutral and sad BM, which echoes with the happiness superiority reported in the explicit processing of BM (<xref ref-type="bibr" rid="bib52">Lee and Kim, 2017</xref>; <xref ref-type="bibr" rid="bib73">Spencer et al., 2016</xref>; <xref ref-type="bibr" rid="bib87">Yuan et al., 2023</xref>). Instead, the sad constriction effect potentially indicates a disadvantage for sad BM in attracting visual attention and evoking emotional arousal than neutral BM. In line with this, it has been found that infants looked more at the happy BM walker when displayed in pair with the neutral walker, whereas they attended less to the sad walker as compared to the neutral one (<xref ref-type="bibr" rid="bib59">Ogren et al., 2019</xref>). Besides, it has been revealed by neural studies that, the happy emotion evoked stronger activities in emotionally relevant brain regions including the amygdala, the extrastriate body area, and the fusiform body area, while the sad emotion failed to induce such effects (<xref ref-type="bibr" rid="bib63">Peelen et al., 2007</xref>; <xref ref-type="bibr" rid="bib69">Ross et al., 2019</xref>). Still, future studies are needed to provide further evidence regarding the happy advantage and the sad disadvantage in attracting visual attention. For example, in addition to pupil size, the microsaccades also provided valuable insights into attention processes (<xref ref-type="bibr" rid="bib7">Baumeler et al., 2020</xref>; <xref ref-type="bibr" rid="bib24">Engbert and Kliegl, 2003</xref>; <xref ref-type="bibr" rid="bib56">Meyberg et al., 2017</xref>), and potentially involved shared neural circuits with pupil responses (<xref ref-type="bibr" rid="bib33">Hafed et al., 2009</xref>; <xref ref-type="bibr" rid="bib34">Hafed and Krauzlis, 2012</xref>; <xref ref-type="bibr" rid="bib81">Wang et al., 2012</xref>). Future studies could combine the microsaccade index with pupil size to provide a more thorough understanding of BM emotion processing.</p><p>Notably, the happy over sad dilation effect was negatively correlated with autistic traits: individuals with greater autistic tendencies showed decreased sensitivities to emotions in BM. In fact, the perception of BM has long been considered an important hallmark of social cognition, and abundant studies reported that individuals with social cognitive deficits (e.g., autism spectrum disorder, ASD) were impaired in BM perception (<xref ref-type="bibr" rid="bib9">Blake et al., 2003</xref>; <xref ref-type="bibr" rid="bib28">Freitag et al., 2008</xref>; <xref ref-type="bibr" rid="bib47">Klin et al., 2009</xref>; <xref ref-type="bibr" rid="bib57">Nackaerts et al., 2012</xref>). More recently, it has been pointed out that the extraction of more complex social information (e.g., emotions, intentions) from BM, as compared to basic BM recognitions, could be more effective in detecting ASDs (<xref ref-type="bibr" rid="bib27">Federici et al., 2020</xref>; <xref ref-type="bibr" rid="bib49">Koldewyn et al., 2010</xref>; <xref ref-type="bibr" rid="bib62">Parron et al., 2008</xref>; <xref ref-type="bibr" rid="bib74">Todorova et al., 2019</xref>). Specifically, a meta-analysis found that the effect size expanded nearly twice when the task required emotion recognition as compared to simple perception/detection (<xref ref-type="bibr" rid="bib74">Todorova et al., 2019</xref>). However, for the high-functioning ASD individuals, it has been reported that they showed comparable performance with the control group in explicitly labeling BM emotions, while their responses were rather delayed (<xref ref-type="bibr" rid="bib54">Mazzoni et al., 2022</xref>). This suggests that ASD individuals could adopt compensatory strategies to complete the explicit BM labeling task, while their automatic responses remained impaired. Such an observation highlights the importance of using more objective measures that do not rely on subjective reports to investigate the intrinsic perception of emotions from BM and its relationship with ASD-related social deficits. The current study thus introduced pupil size measurement to this field, and we combined it with the passive viewing task to investigate the more automatic aspect of BM emotion processing. In addition to diagnostic ASDs, the non-clinical general population also manifested autistic tendencies that followed normal distribution and demonstrated substantial heritability (<xref ref-type="bibr" rid="bib38">Hoekstra et al., 2007</xref>). Here, we focused on the autistic tendencies in the general population, and our results showed that the automatic emotion processing of BM stimuli was impaired in individuals with high autistic tendencies, lending support to previous studies (<xref ref-type="bibr" rid="bib39">Hubert et al., 2007</xref>; <xref ref-type="bibr" rid="bib57">Nackaerts et al., 2012</xref>; <xref ref-type="bibr" rid="bib62">Parron et al., 2008</xref>). The more detailed test–retest examination further confirmed such a correlation and illustrated a general diminishment in BM emotion perception ability (happy and sad) for high AQ individuals. Given that pupil measurement does not require any explicit verbal reports, it is easily attainable in children and even infants. Thus, the pupil modulation effect obtained here may serve as a sensitive and reliable physiological marker for detecting early social cognitive disorders in both clinical and non-clinical populations.</p><p>Remarkably, our findings highlighted the central role of local motion feature in modulating pupil responses toward emotional information contained in BM. Previous studies have shown that human visual system is highly sensitive to the local BM stimulus, whose global configural information is completely deprived through spatially scrambling (<xref ref-type="bibr" rid="bib75">Troje and Westhoff, 2006</xref>). For example, it has been demonstrated that scrambled BM could perform as intact BM in lengthening subjective temporal perception (<xref ref-type="bibr" rid="bib82">Wang and Jiang, 2012</xref>). Besides, such local motion feature also served as a basic pre-attentive feature in visual search (<xref ref-type="bibr" rid="bib80">Wang et al., 2010</xref>) and could further induce a significant reflexive attentional effect (<xref ref-type="bibr" rid="bib83">Wang et al., 2014</xref>; <xref ref-type="bibr" rid="bib86">Yu et al., 2020</xref>). Moreover, the deprivation of the local BM feature would greatly disrupt the perception of the contained biologically salient information, such as animacy and walking direction (<xref ref-type="bibr" rid="bib16">Chang and Troje, 2008</xref>; <xref ref-type="bibr" rid="bib17">Chang and Troje, 2009</xref>; <xref ref-type="bibr" rid="bib86">Yu et al., 2020</xref>). Here, we extended this line of research to the emotional domain by demonstrating that the local BM component is also critical for the processing of emotional information: when the local BM feature is disrupted, the modulation of emotions on pupil size completely disappears. Furthermore, the emotional BM that retained only local motion features could still exert a salient modulation effect on pupil size. In particular, the happy and sad local BM induced a significant pupil dilation effect as compared to the neutral local BM stimuli. Intriguingly, this dilation effect is independent of the specific emotion category but reflects a general activation caused by the affective salient information. In addition, this non-selective pupil dilation effect in local BM appeared in a relatively early time window, indicating that the extraction of emotions from local BM is rapid. Taken together, these findings identified a coarse but rapid emotion processing mechanism in local BM that could promptly detect the emotional information therein without the aid of the global shape.</p><p>Moreover, our findings revealed the existence of distinct emotional modulations in intact and local BM, respectively, as evidenced by variations in pupil responses. In particular, the happy intact BM induced a significant pupil dilation effect as compared to the neutral one, whereas the sad intact BM led to pupil constriction. Interestingly, both the happy and sad local BM resulted in pupil dilation effects relative to the neutral local BM, and such effect occurred at a relatively early time point. This distinctive pupil modulation effects observed in intact and local BM could be elucidated by a multi-level emotion processing mechanism. Specifically, even though both the intact and local BM conveyed important life information, the local BM is deprived of the global configural information (<xref ref-type="bibr" rid="bib16">Chang and Troje, 2008</xref>; <xref ref-type="bibr" rid="bib17">Chang and Troje, 2009</xref>; <xref ref-type="bibr" rid="bib71">Simion et al., 2008</xref>). Thus, its emotion processing potentially occurred at a more basic and preliminary level, responding to the general affective salient information without engaging in further detailed analysis. Importantly, similar dissociated emotion processing phenomenon has been observed in another important type of emotional signal with analogous function (i.e., facial expression). For example, happy and fearful faces induced differential amygdala activations when perceived consciously, yet they induced comparable amygdala activations when suppressed (<xref ref-type="bibr" rid="bib84">Williams et al., 2004</xref>). Moreover, it has been argued that there exist two parallel pathways for facial expression processing: a slow route that conveys fine-grained facial features along cortical areas to the amygdala, and a rapid subcortical pathway that directly transfers emotional information to amygdala without detailed analysis, which is known as the ‘quick and dirty’ route (<xref ref-type="bibr" rid="bib31">Garrido et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Johnson, 2005</xref>; <xref ref-type="bibr" rid="bib55">Méndez-Bértolo et al., 2016</xref>; <xref ref-type="bibr" rid="bib79">Vuilleumier et al., 2003</xref>). It is probable that the emotion processing of the local and intact point-light BM potentially functions in a manner similar to that of the faces, with the former serving as a primary detection mechanism that automatically captures emotionally significant information conveyed by animate agents without detailed analysis, and the latter aiding in more specific emotion identification based on fine-grained analyses of their motion pattern and global shape. Compatible with this view, recent studies have reported that the emotion processing of face and BM was very similar. For example, they both showed a happiness superiority in visual detection (<xref ref-type="bibr" rid="bib8">Becker et al., 2011</xref>; <xref ref-type="bibr" rid="bib52">Lee and Kim, 2017</xref>; <xref ref-type="bibr" rid="bib57">Nackaerts et al., 2012</xref>) and guiding social attention (<xref ref-type="bibr" rid="bib87">Yuan et al., 2023</xref>). Moreover, their emotion processing involved potentially overlapping brain regions, such as amygdala, superior temporal sulcus (STS) (<xref ref-type="bibr" rid="bib4">Alaerts et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Engell and Haxby, 2007</xref>; <xref ref-type="bibr" rid="bib63">Peelen et al., 2007</xref>; <xref ref-type="bibr" rid="bib65">Pessoa and Adolphs, 2010</xref>). Overall, our findings, together with the former evidence, suggest <xref ref-type="video" rid="video1">Video 1</xref> dissociated emotion processing for BM in the human brain akin to the dual-route model reported in faces, and further imply a general ‘emotional brain’ that can be shared by different types of social signals. Still, future studies are needed to implement neuroimaging techniques to directly identify the brain regions involved in the emotion processing of local and global BM signals.</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-89873-video1.mp4" id="video1"><label>Video 1.</label><caption><title>Demonstration of motion stimuli used in Experiments 1–4.</title></caption></media><p>To conclude, the current study clearly demonstrated that the emotional information conveyed by point-light BM-modulated pupil responses. The intact BM exerted a fine-grained emotional modulation on pupil sizes, while disrupting the contained local motion characteristic would deteriorate the observed modulations. Moreover, BM with only local motion features retained could exert a fast but rather coarse modulation on pupillometry. These findings together highlight the critical role of local motion feature in BM emotion processing, and further reveal the multi-level emotion processing of BM. Notably, the observed emotional modulation in intact BM is associated with individual autistic traits, suggesting the potential of utilizing the emotion-modulated pupil responses to facilitate the diagnosis of social cognitive disorders.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Participants</title><p>A total of 144 participants (50 males, 94 females) ranging from 18 to 30 years old (<italic>M</italic> ± standard deviation [SD] = 23.1 ± 2.5) were recruited, with 24 in Experiment 1a, 24 in Experiment 1b, 24 in Experiment 2, 24 in Experiment 3, 24 in the behavioral part of Experiment 4, and 24 in the eye recoding part of Experiment 4. All of the participants had normal or corrected-to-normal vision and gave written informed consent in accordance with the procedure and protocols approved by the institutional review board of the Institute of Psychology, Chinese Academy of Sciences. They were all naive to the purpose of the experiments. Prior power analyses (<italic>F</italic> tests, repeated measures, within factors) using G*Power (Version 3.1.9.4; <xref ref-type="bibr" rid="bib26">Faul et al., 2007</xref>) indicated that a sample size of 24 participants would afford 80% power with alpha at 0.05 to detect a moderate main effect (<italic>f</italic> = 0.27). This sample size was comparable to previous studies with similar designs (<xref ref-type="bibr" rid="bib58">Nakakoga et al., 2020</xref>). We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures following JARS (<xref ref-type="bibr" rid="bib45">Kazak, 2018</xref>).</p></sec><sec id="s4-2"><title>Stimuli</title><p>Stimuli were displayed using MATLAB (Mathworks, Inc) together with the Psychtoolbox extensions (<xref ref-type="bibr" rid="bib12">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib64">Pelli, 1997</xref>) on a 23-inch LED monitor (1920 × 1080 at 60 Hz) with gray background (red-green-blue [RGB]: 100, 100, 100). The BM stimuli were adopted from <xref ref-type="bibr" rid="bib76">Troje, 2008</xref>. Each comprised 15 point-light dots depicting the motions of the head, pelvis, thorax, and major joints (i.e., shoulders, elbows, wrists, hips, knees, and ankles). Its emotional state was indexed by a normalized <italic>Z</italic> score on an axis that reflects the differences between happy and sad walkers in terms of a linear classifier. The scores were computed within a 10-dimensional sub-space spanned by the first 10 principal components based on a Fourier-based representation of observers’ emotional ratings of 80 actual walkers (half male) (<xref ref-type="bibr" rid="bib76">Troje, 2008</xref>). We adopted the neutral walker that scored 0 on the linear axis, together with the happy walker 6 SDs into the happy part of the axis and the sad walker 6 SDs into the sad part of the axis (see <ext-link ext-link-type="uri" xlink:href="https://www.biomotionlab.ca/html5-bml-walker/">https://www.biomotionlab.ca/html5-bml-walker/</ext-link> for an interactive animation). Besides, we turned the BM walkers 45° leftwards or rightwards to maximize the visibility of expressive bodily cues (<xref ref-type="bibr" rid="bib68">Roether et al., 2009</xref>). In Experiments 1a and 1b, the upright emotional (happy, sad, or neutral) BM walkers with two walking directions (45° leftwards or rightwards) were used. The velocity was 5.76 pixels/frame for the happy BM, 4.14 pixels/frame for the neutral BM, and 3.21 pixels/frame for the sad BM. This difference in velocity profile was considered an important signature for conveying emotional information, as the happy walker was characterized by a larger step pace and longer arm swing, and the sad walker would instead exhibit a slouching gait with short slow strides and smaller arm movement (<xref ref-type="bibr" rid="bib5">Barliya et al., 2013</xref>; <xref ref-type="bibr" rid="bib18">Chouchourelou et al., 2006</xref>; <xref ref-type="bibr" rid="bib35">Halovic and Kroos, 2018</xref>; <xref ref-type="bibr" rid="bib68">Roether et al., 2009</xref>). In Experiment 2, the stimuli were replaced with their inverted counterparts created by mirror flipping the upright BM vertically. In Experiment 3, we presented observers with the non-BM stimuli whose local BM characteristic was disrupted through acceleration removal. More specifically, each individual dot moved along the original path with a constant speed equal to the average speed of the dot (<xref ref-type="bibr" rid="bib17">Chang and Troje, 2009</xref>). Such manipulation disrupted the local motion feature of the BM stimuli but kept the trajectories of individual point lights unchanged. In Experiment 4, observers viewed the scrambled BM stimuli, which were created by randomly relocating the point-light dots within the region occupied by the original BM walker. In this manner, the local motion feature was preserved while the global configuration of the BM stimulus was entirely disrupted (<xref ref-type="bibr" rid="bib75">Troje and Westhoff, 2006</xref>) (see <xref ref-type="video" rid="video1">Video 1</xref> for stimuli demonstration).</p></sec><sec id="s4-3"><title>Procedure</title><p>Participants were seated at a viewing distance of 60 cm to the computer screen with their heads on a chinrest to minimize their head movements. Their pupil size and eye position of the left eye were recorded using a video-based iView X Hi-Speed system (SMI, Berlin, Germany) at 500 Hz. In Experiment 1a, each trial began with a central fixation cross (0.2° × 0.2°) with variable duration (800–1200 ms), followed by an upright happy/sad/neutral point-light walker (half leftwards and half rightwards) presented centrally for 4000 ms. Participants were required to passively view the BM stimulus and continue the procedure by pressing the space bar. After that, a blank screen was displayed for 3000 ms (<xref ref-type="fig" rid="fig1">Figure 1</xref>). There were 4 blocks of 30 trials, and participants were given a short break after every block. Besides, we also administered a 9-point calibration of the eye-tracker followed by a validation stage before each experimental block to ensure the data quality. Participants were told to maintain fixation on the center of the screen and not to blink during the stimuli presentation. Importantly, a replication experiment of Experiment 1a (Experiment 1b) was conducted, which followed the same protocol, with the change being that participants were asked to return to the lab for a retest after at least 7 days. Experiment 2 is identical to Experiment 1a, except that the BM stimuli were changed to their inverted counterparts. In Experiment 3, we instead presented participants with the non-BM displays whose local motion feature was deprived through acceleration removal. In Experiment 4, we adopted the scrambled emotional BM stimuli, and investigated both the explicit and the implicit emotion processing of scrambled BM. Note that a group of participants was recruited to perform emotional judgments on the scrambled BM in order to investigate whether the emotional information carried by local BM signals could be explicitly identified. Another group of participants was enrolled for the pupil recording experiment, which followed the identical experimental procedure of Experiments 1–3. At the end of all experiments, participants were required to complete the 50-point autism-spectrum questionnaire (AQ), which measured the degree of autistic traits in the normal population (<xref ref-type="bibr" rid="bib6">Baron-Cohen et al., 2001</xref>).</p></sec><sec id="s4-4"><title>Data analysis</title><p>The raw pupil data for each trial were first screened to remove eye blinks (either replaced by linear interpolation or with this trial discarded). Then, trials with pupil size deviating ±3 SDs from the mean were excluded from further analysis. Finally, the pupil size data were down-sampled to 20 Hz and baseline-corrected for each trial by subtracting the mean pupil size during the 200 ms pre-stimulus period. We computed the average pupil size for each emotional condition (happy, sad, or neutral) obtained by collapsing the pupillometry across all time points. Besides, to depict the time course of pupil responses toward emotional BM, we further conducted a consecutive paired-sample <italic>t</italic>-test across all time points comparing different emotional conditions. The cluster-based permutation analysis was applied to avoid potential problems brought about by multiple comparisons (<xref ref-type="bibr" rid="bib23">Einhäuser et al., 2008</xref>). In this analysis, the computed <italic>t</italic>-values neighboring in time that exceeded a threshold (p &lt; 0.05) were defined as clusters, and then summed to produce a cluster mass. The cluster mass was compared with a null distribution, which was generated by 2000 random permutations of the pupil data from different conditions. If the cluster mass fell beyond 95% of the null distribution (<italic>α</italic> = 0.05), it was deemed to be statistically significantly different (<xref ref-type="bibr" rid="bib23">Einhäuser et al., 2008</xref>). The pupil size was analyzed and reported in arbitrary units without transforming into the actual unit (mm), as the relative change of the pupil size was of main interest.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All procedures contributing to this work comply with the ethical standards of the relevant national and institutional committees on human experiments and with the Helsinki Declaration of 1975, as revised in 2008. Written informed consent, and consent to publish, was obtained from participants. The institutional review board of the Institute of Psychology, Chinese Academy of Sciences has approved this study (reference number for approval: H18029).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-89873-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data, materials, and analysis code used in the current study could be accessed at Science Data Bank (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57760/sciencedb.psych.00125">https://doi.org/10.57760/sciencedb.psych.00125</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>Wang</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Data from: Multi-level processing of emotions in life motion signals revealed through pupil responses</data-title><source>Science Data Bank</source><pub-id pub-id-type="doi">10.57760/sciencedb.psych.00125</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This research was supported by grants from STI2030-Major Projects (No. 2021ZD0203800 and 2022ZD0205100), the National Natural Science Foundation of China (No. 32430043 and 32371106), the Interdisciplinary Innovation Team of the Chinese Academy of Sciences (JCTD-2021-06), the Key Research and Development Program of Guangdong, China (2023B0303010004), and the Fundamental Research Funds for the Central Universities. We thank Professor Nikolaus F Troje for kindly providing us with the visual stimuli.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Actis-Grosso</surname><given-names>R</given-names></name><name><surname>Bossi</surname><given-names>F</given-names></name><name><surname>Ricciardelli</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Emotion recognition through static faces and moving bodies: a comparison between typically developed adults and individuals with high level of autistic traits</article-title><source>Frontiers in Psychology</source><volume>6</volume><elocation-id>1570</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2015.01570</pub-id><pub-id pub-id-type="pmid">26557101</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aktar</surname><given-names>E</given-names></name><name><surname>Mandell</surname><given-names>DJ</given-names></name><name><surname>de Vente</surname><given-names>W</given-names></name><name><surname>Majdandžić</surname><given-names>M</given-names></name><name><surname>Oort</surname><given-names>FJ</given-names></name><name><surname>van Renswoude</surname><given-names>DR</given-names></name><name><surname>Raijmakers</surname><given-names>MEJ</given-names></name><name><surname>Bögels</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Parental negative emotions are related to behavioral and pupillary correlates of infants’ attention to facial expressions of emotion</article-title><source>Infant Behavior &amp; Development</source><volume>53</volume><fpage>101</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.infbeh.2018.07.004</pub-id><pub-id pub-id-type="pmid">30139506</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alaerts</surname><given-names>K</given-names></name><name><surname>Nackaerts</surname><given-names>E</given-names></name><name><surname>Meyns</surname><given-names>P</given-names></name><name><surname>Swinnen</surname><given-names>SP</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Action and emotion recognition from point light displays: an investigation of gender differences</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e20989</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0020989</pub-id><pub-id pub-id-type="pmid">21695266</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alaerts</surname><given-names>Kaat</given-names></name><name><surname>Woolley</surname><given-names>DG</given-names></name><name><surname>Steyaert</surname><given-names>J</given-names></name><name><surname>Di Martino</surname><given-names>A</given-names></name><name><surname>Swinnen</surname><given-names>SP</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Underconnectivity of the superior temporal sulcus predicts emotion recognition deficits in autism</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>9</volume><fpage>1589</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1093/scan/nst156</pub-id><pub-id pub-id-type="pmid">24078018</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barliya</surname><given-names>A</given-names></name><name><surname>Omlor</surname><given-names>L</given-names></name><name><surname>Giese</surname><given-names>MA</given-names></name><name><surname>Berthoz</surname><given-names>A</given-names></name><name><surname>Flash</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Expression of emotion in the kinematics of locomotion</article-title><source>Experimental Brain Research</source><volume>225</volume><fpage>159</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1007/s00221-012-3357-4</pub-id><pub-id pub-id-type="pmid">23250443</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baron-Cohen</surname><given-names>S</given-names></name><name><surname>Wheelwright</surname><given-names>S</given-names></name><name><surname>Skinner</surname><given-names>R</given-names></name><name><surname>Martin</surname><given-names>J</given-names></name><name><surname>Clubley</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The autism-spectrum quotient (AQ): evidence from Asperger syndrome/high-functioning autism, males and females, scientists and mathematicians</article-title><source>Journal of Autism and Developmental Disorders</source><volume>31</volume><fpage>5</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1023/a:1005653411471</pub-id><pub-id pub-id-type="pmid">11439754</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baumeler</surname><given-names>D</given-names></name><name><surname>Schönhammer</surname><given-names>JG</given-names></name><name><surname>Born</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Microsaccade dynamics in the attentional repulsion effect</article-title><source>Vision Research</source><volume>170</volume><fpage>46</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2020.03.009</pub-id><pub-id pub-id-type="pmid">32247899</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>DV</given-names></name><name><surname>Anderson</surname><given-names>US</given-names></name><name><surname>Mortensen</surname><given-names>CR</given-names></name><name><surname>Neufeld</surname><given-names>SL</given-names></name><name><surname>Neel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The face in the crowd effect unconfounded: happy faces, not angry faces, are more efficiently detected in single- and multiple-target visual search tasks</article-title><source>Journal of Experimental Psychology. General</source><volume>140</volume><fpage>637</fpage><lpage>659</lpage><pub-id pub-id-type="doi">10.1037/a0024060</pub-id><pub-id pub-id-type="pmid">21744984</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blake</surname><given-names>R</given-names></name><name><surname>Turner</surname><given-names>LM</given-names></name><name><surname>Smoski</surname><given-names>MJ</given-names></name><name><surname>Pozdol</surname><given-names>SL</given-names></name><name><surname>Stone</surname><given-names>WL</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Visual recognition of biological motion is impaired in children with autism</article-title><source>Psychological Science</source><volume>14</volume><fpage>151</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.01434</pub-id><pub-id pub-id-type="pmid">12661677</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Miccoli</surname><given-names>L</given-names></name><name><surname>Escrig</surname><given-names>MA</given-names></name><name><surname>Lang</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The pupil as a measure of emotional arousal and autonomic activation</article-title><source>Psychophysiology</source><volume>45</volume><fpage>602</fpage><lpage>607</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2008.00654.x</pub-id><pub-id pub-id-type="pmid">18282202</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bradley</surname><given-names>MM</given-names></name><name><surname>Lang</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Memory, emotion, and pupil diameter: Repetition of natural scenes</article-title><source>Psychophysiology</source><volume>52</volume><fpage>1186</fpage><lpage>1193</lpage><pub-id pub-id-type="doi">10.1111/psyp.12442</pub-id><pub-id pub-id-type="pmid">25943211</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burley</surname><given-names>DT</given-names></name><name><surname>Gray</surname><given-names>NS</given-names></name><name><surname>Snowden</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>As far as the eye can see: relationship between psychopathic traits and pupil response to affective stimuli</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0167436</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0167436</pub-id><pub-id pub-id-type="pmid">28118366</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burley</surname><given-names>DT</given-names></name><name><surname>Daughters</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The effect of oxytocin on pupil response to naturalistic dynamic facial expressions</article-title><source>Hormones and Behavior</source><volume>125</volume><elocation-id>104837</elocation-id><pub-id pub-id-type="doi">10.1016/j.yhbeh.2020.104837</pub-id><pub-id pub-id-type="pmid">32750332</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carsten</surname><given-names>T</given-names></name><name><surname>Desmet</surname><given-names>C</given-names></name><name><surname>Krebs</surname><given-names>RM</given-names></name><name><surname>Brass</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Pupillary contagion is independent of the emotional expression of the face</article-title><source>Emotion</source><volume>19</volume><fpage>1343</fpage><lpage>1352</lpage><pub-id pub-id-type="doi">10.1037/emo0000503</pub-id><pub-id pub-id-type="pmid">30265081</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>DHF</given-names></name><name><surname>Troje</surname><given-names>NF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Perception of animacy and direction from local biological motion signals</article-title><source>Journal of Vision</source><volume>8</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.1167/8.5.3</pub-id><pub-id pub-id-type="pmid">18842074</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>DHF</given-names></name><name><surname>Troje</surname><given-names>NF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Acceleration carries the local inversion effect in biological motion perception</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>19</elocation-id><pub-id pub-id-type="doi">10.1167/9.1.19</pub-id><pub-id pub-id-type="pmid">19271889</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chouchourelou</surname><given-names>A</given-names></name><name><surname>Matsuka</surname><given-names>T</given-names></name><name><surname>Harber</surname><given-names>K</given-names></name><name><surname>Shiffrar</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The visual analysis of emotional actions</article-title><source>Social Neuroscience</source><volume>1</volume><fpage>63</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1080/17470910600630599</pub-id><pub-id pub-id-type="pmid">18633776</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Critchley</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Explicit and implicit neural mechanisms for processing of social information from facial expressions: a functional magnetic resonance imaging study</article-title><source>Human Brain Mapping</source><volume>9</volume><fpage>93</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1097-0193(200002)9:2&lt;93::AID-HBM4&gt;3.0.CO;2-Z</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dal Monte</surname><given-names>O</given-names></name><name><surname>Costa</surname><given-names>VD</given-names></name><name><surname>Noble</surname><given-names>PL</given-names></name><name><surname>Murray</surname><given-names>EA</given-names></name><name><surname>Averbeck</surname><given-names>BB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Amygdala lesions in rhesus macaques decrease attention to threat</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>10161</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms10161</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decision-related pupil dilation reflects upcoming choice and individual bias</article-title><source>PNAS</source><volume>111</volume><fpage>E618</fpage><lpage>E625</lpage><pub-id pub-id-type="doi">10.1073/pnas.1317557111</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gelder</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Towards the neurobiology of emotional body language</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>242</fpage><lpage>249</lpage><pub-id pub-id-type="doi">10.1038/nrn1872</pub-id><pub-id pub-id-type="pmid">16495945</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Einhäuser</surname><given-names>W</given-names></name><name><surname>Stout</surname><given-names>J</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Carter</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Pupil dilation reflects perceptual selection and predicts subsequent stability in perceptual rivalry</article-title><source>PNAS</source><volume>105</volume><fpage>1704</fpage><lpage>1709</lpage><pub-id pub-id-type="doi">10.1073/pnas.0707727105</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engbert</surname><given-names>R</given-names></name><name><surname>Kliegl</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Microsaccades uncover the orientation of covert attention</article-title><source>Vision Research</source><volume>43</volume><fpage>1035</fpage><lpage>1045</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(03)00084-1</pub-id><pub-id pub-id-type="pmid">12676246</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engell</surname><given-names>AD</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Facial expression and gaze-direction in human superior temporal sulcus</article-title><source>Neuropsychologia</source><volume>45</volume><fpage>3234</fpage><lpage>3241</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2007.06.022</pub-id><pub-id pub-id-type="pmid">17707444</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faul</surname><given-names>F</given-names></name><name><surname>Erdfelder</surname><given-names>E</given-names></name><name><surname>Lang</surname><given-names>AG</given-names></name><name><surname>Buchner</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>G*Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title><source>Behavior Research Methods</source><volume>39</volume><fpage>175</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.3758/bf03193146</pub-id><pub-id pub-id-type="pmid">17695343</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Federici</surname><given-names>A</given-names></name><name><surname>Parma</surname><given-names>V</given-names></name><name><surname>Vicovaro</surname><given-names>M</given-names></name><name><surname>Radassao</surname><given-names>L</given-names></name><name><surname>Casartelli</surname><given-names>L</given-names></name><name><surname>Ronconi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Anomalous perception of biological motion in autism: a conceptual review and meta-analysis</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>61252-3</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-61252-3</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freitag</surname><given-names>CM</given-names></name><name><surname>Konrad</surname><given-names>C</given-names></name><name><surname>Häberlen</surname><given-names>M</given-names></name><name><surname>Kleser</surname><given-names>C</given-names></name><name><surname>von Gontard</surname><given-names>A</given-names></name><name><surname>Reith</surname><given-names>W</given-names></name><name><surname>Troje</surname><given-names>NF</given-names></name><name><surname>Krick</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Perception of biological motion in autism spectrum disorders</article-title><source>Neuropsychologia</source><volume>46</volume><fpage>1480</fpage><lpage>1494</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2007.12.025</pub-id><pub-id pub-id-type="pmid">18262208</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frith</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Emanuel Miller lecture: confusions and controversies about Asperger syndrome</article-title><source>Journal of Child Psychology and Psychiatry, and Allied Disciplines</source><volume>45</volume><fpage>672</fpage><lpage>686</lpage><pub-id pub-id-type="doi">10.1111/j.1469-7610.2004.00262.x</pub-id><pub-id pub-id-type="pmid">15056300</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frith</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Role of facial expressions in social interactions</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>364</volume><fpage>3453</fpage><lpage>3458</lpage><pub-id pub-id-type="doi">10.1098/rstb.2009.0142</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrido</surname><given-names>MI</given-names></name><name><surname>Barnes</surname><given-names>GR</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Functional evidence for a dual route to amygdala</article-title><source>Current Biology</source><volume>22</volume><fpage>129</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2011.11.056</pub-id><pub-id pub-id-type="pmid">22209532</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>JE</given-names></name><name><surname>Egré</surname><given-names>P</given-names></name><name><surname>Pressnitzer</surname><given-names>D</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>An implicit representation of stimulus ambiguity in pupil size</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2107997118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2107997118</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafed</surname><given-names>ZM</given-names></name><name><surname>Goffart</surname><given-names>L</given-names></name><name><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A neural mechanism for microsaccade generation in the primate superior colliculus</article-title><source>Science</source><volume>323</volume><fpage>940</fpage><lpage>943</lpage><pub-id pub-id-type="doi">10.1126/science.1166112</pub-id><pub-id pub-id-type="pmid">19213919</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafed</surname><given-names>ZM</given-names></name><name><surname>Krauzlis</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Similarity of superior colliculus involvement in microsaccade and saccade generation</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>1904</fpage><lpage>1916</lpage><pub-id pub-id-type="doi">10.1152/jn.01125.2011</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halovic</surname><given-names>S</given-names></name><name><surname>Kroos</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Not all is noticed: Kinematic cues of emotion-specific gait</article-title><source>Human Movement Science</source><volume>57</volume><fpage>478</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.1016/j.humov.2017.11.008</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harms</surname><given-names>MB</given-names></name><name><surname>Martin</surname><given-names>A</given-names></name><name><surname>Wallace</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Facial emotion recognition in autism spectrum disorders: a review of behavioral and neuroimaging studies</article-title><source>Neuropsychology Review</source><volume>20</volume><fpage>290</fpage><lpage>322</lpage><pub-id pub-id-type="doi">10.1007/s11065-010-9138-6</pub-id><pub-id pub-id-type="pmid">20809200</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>NA</given-names></name><name><surname>Singer</surname><given-names>T</given-names></name><name><surname>Rotshtein</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Critchley</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Pupillary contagion: central mechanisms engaged in sadness processing</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>1</volume><fpage>5</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1093/scan/nsl006</pub-id><pub-id pub-id-type="pmid">17186063</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoekstra</surname><given-names>RA</given-names></name><name><surname>Bartels</surname><given-names>M</given-names></name><name><surname>Verweij</surname><given-names>CJH</given-names></name><name><surname>Boomsma</surname><given-names>DI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Heritability of autistic traits in the general population</article-title><source>Archives of Pediatrics &amp; Adolescent Medicine</source><volume>161</volume><elocation-id>372</elocation-id><pub-id pub-id-type="doi">10.1001/archpedi.161.4.372</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubert</surname><given-names>B</given-names></name><name><surname>Wicker</surname><given-names>B</given-names></name><name><surname>Moore</surname><given-names>DG</given-names></name><name><surname>Monfardini</surname><given-names>E</given-names></name><name><surname>Duverger</surname><given-names>H</given-names></name><name><surname>Da Fonséca</surname><given-names>D</given-names></name><name><surname>Deruelle</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Brief report: recognition of emotional and non-emotional biological motion in individuals with autistic spectrum disorders</article-title><source>Journal of Autism and Developmental Disorders</source><volume>37</volume><fpage>1386</fpage><lpage>1392</lpage><pub-id pub-id-type="doi">10.1007/s10803-006-0275-y</pub-id><pub-id pub-id-type="pmid">17160459</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jessen</surname><given-names>S</given-names></name><name><surname>Altvater-Mackensen</surname><given-names>N</given-names></name><name><surname>Grossmann</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupillary responses reveal infants’ discrimination of facial emotions independent of conscious perception</article-title><source>Cognition</source><volume>150</volume><fpage>163</fpage><lpage>169</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2016.02.010</pub-id><pub-id pub-id-type="pmid">26896901</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johansson</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Visual perception of biological motion and a model for its analysis</article-title><source>Perception &amp; Psychophysics</source><volume>14</volume><fpage>201</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.3758/BF03212378</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Subcortical face processing</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>766</fpage><lpage>774</lpage><pub-id pub-id-type="doi">10.1038/nrn1766</pub-id><pub-id pub-id-type="pmid">16276354</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil size as a window on neural substrates of cognition</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>466</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.005</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kana</surname><given-names>RK</given-names></name><name><surname>Patriquin</surname><given-names>MA</given-names></name><name><surname>Black</surname><given-names>BS</given-names></name><name><surname>Channell</surname><given-names>MM</given-names></name><name><surname>Wicker</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Altered medial frontal and superior temporal response to implicit processing of emotions in autism</article-title><source>Autism Research</source><volume>9</volume><fpage>55</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1002/aur.1496</pub-id><pub-id pub-id-type="pmid">25962831</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kazak</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Editorial: journal article reporting standards</article-title><source>The American Psychologist</source><volume>73</volume><fpage>1</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1037/amp0000263</pub-id><pub-id pub-id-type="pmid">29345483</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keifer</surname><given-names>CM</given-names></name><name><surname>Mikami</surname><given-names>AY</given-names></name><name><surname>Morris</surname><given-names>JP</given-names></name><name><surname>Libsack</surname><given-names>EJ</given-names></name><name><surname>Lerner</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Prediction of social behavior in autism spectrum disorders: Explicit versus implicit social cognition</article-title><source>Autism</source><volume>24</volume><fpage>1758</fpage><lpage>1772</lpage><pub-id pub-id-type="doi">10.1177/1362361320922058</pub-id><pub-id pub-id-type="pmid">32484000</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klin</surname><given-names>A</given-names></name><name><surname>Lin</surname><given-names>DJ</given-names></name><name><surname>Gorrindo</surname><given-names>P</given-names></name><name><surname>Ramsay</surname><given-names>G</given-names></name><name><surname>Jones</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Two-year-olds with autism orient to non-social contingencies rather than biological motion</article-title><source>Nature</source><volume>459</volume><fpage>257</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1038/nature07868</pub-id><pub-id pub-id-type="pmid">19329996</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kloosterman</surname><given-names>NA</given-names></name><name><surname>Meindertsma</surname><given-names>T</given-names></name><name><surname>van Loon</surname><given-names>AM</given-names></name><name><surname>Lamme</surname><given-names>VAF</given-names></name><name><surname>Bonneh</surname><given-names>YS</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Pupil size tracks perceptual content and surprise</article-title><source>The European Journal of Neuroscience</source><volume>41</volume><fpage>1068</fpage><lpage>1078</lpage><pub-id pub-id-type="doi">10.1111/ejn.12859</pub-id><pub-id pub-id-type="pmid">25754528</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koldewyn</surname><given-names>K</given-names></name><name><surname>Whitney</surname><given-names>D</given-names></name><name><surname>Rivera</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The psychophysics of visual motion and global form processing in autism</article-title><source>Brain</source><volume>133</volume><fpage>599</fpage><lpage>610</lpage><pub-id pub-id-type="doi">10.1093/brain/awp272</pub-id><pub-id pub-id-type="pmid">19887505</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kovarski</surname><given-names>K</given-names></name><name><surname>Mennella</surname><given-names>R</given-names></name><name><surname>Wong</surname><given-names>SM</given-names></name><name><surname>Dunkley</surname><given-names>BT</given-names></name><name><surname>Taylor</surname><given-names>MJ</given-names></name><name><surname>Batty</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Enhanced early visual responses during implicit emotional faces processing in autism spectrum disorder</article-title><source>Journal of Autism and Developmental Disorders</source><volume>49</volume><fpage>871</fpage><lpage>886</lpage><pub-id pub-id-type="doi">10.1007/s10803-018-3787-3</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lange</surname><given-names>K</given-names></name><name><surname>Williams</surname><given-names>LM</given-names></name><name><surname>Young</surname><given-names>AW</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name><name><surname>Brammer</surname><given-names>MJ</given-names></name><name><surname>Williams</surname><given-names>SCR</given-names></name><name><surname>Gray</surname><given-names>JA</given-names></name><name><surname>Phillips</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Task instructions modulate neural responses to fearful facial expressions</article-title><source>Biological Psychiatry</source><volume>53</volume><fpage>226</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1016/s0006-3223(02)01455-5</pub-id><pub-id pub-id-type="pmid">12559655</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Facilitating effects of emotion on the perception of biological motion: evidence for a happiness superiority effect</article-title><source>Perception</source><volume>46</volume><fpage>679</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1177/0301006616681809</pub-id><pub-id pub-id-type="pmid">27903922</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liddell</surname><given-names>BJ</given-names></name><name><surname>Brown</surname><given-names>KJ</given-names></name><name><surname>Kemp</surname><given-names>AH</given-names></name><name><surname>Barton</surname><given-names>MJ</given-names></name><name><surname>Das</surname><given-names>P</given-names></name><name><surname>Peduto</surname><given-names>A</given-names></name><name><surname>Gordon</surname><given-names>E</given-names></name><name><surname>Williams</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A direct brainstem-amygdala-cortical “alarm” system for subliminal signals of fear</article-title><source>NeuroImage</source><volume>24</volume><fpage>235</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.08.016</pub-id><pub-id pub-id-type="pmid">15588615</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazzoni</surname><given-names>N</given-names></name><name><surname>Ricciardelli</surname><given-names>P</given-names></name><name><surname>Actis-Grosso</surname><given-names>R</given-names></name><name><surname>Venuti</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Difficulties in recognising dynamic but not static emotional body movements in autism spectrum disorder</article-title><source>Journal of Autism and Developmental Disorders</source><volume>52</volume><fpage>1092</fpage><lpage>1105</lpage><pub-id pub-id-type="doi">10.1007/s10803-021-05015-7</pub-id><pub-id pub-id-type="pmid">33866488</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Méndez-Bértolo</surname><given-names>C</given-names></name><name><surname>Moratti</surname><given-names>S</given-names></name><name><surname>Toledano</surname><given-names>R</given-names></name><name><surname>Lopez-Sosa</surname><given-names>F</given-names></name><name><surname>Martínez-Alvarez</surname><given-names>R</given-names></name><name><surname>Mah</surname><given-names>YH</given-names></name><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Gil-Nagel</surname><given-names>A</given-names></name><name><surname>Strange</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A fast pathway for fear in human amygdala</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1041</fpage><lpage>1049</lpage><pub-id pub-id-type="doi">10.1038/nn.4324</pub-id><pub-id pub-id-type="pmid">27294508</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyberg</surname><given-names>S</given-names></name><name><surname>Sinn</surname><given-names>P</given-names></name><name><surname>Engbert</surname><given-names>R</given-names></name><name><surname>Sommer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Revising the link between microsaccades and the spatial cueing of voluntary attention</article-title><source>Vision Research</source><volume>133</volume><fpage>47</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2017.01.001</pub-id><pub-id pub-id-type="pmid">28163059</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nackaerts</surname><given-names>E</given-names></name><name><surname>Wagemans</surname><given-names>J</given-names></name><name><surname>Helsen</surname><given-names>W</given-names></name><name><surname>Swinnen</surname><given-names>SP</given-names></name><name><surname>Wenderoth</surname><given-names>N</given-names></name><name><surname>Alaerts</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Recognizing biological motion and emotions from point-light displays in autism spectrum disorders</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e44473</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0044473</pub-id><pub-id pub-id-type="pmid">22970227</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakakoga</surname><given-names>S</given-names></name><name><surname>Higashi</surname><given-names>H</given-names></name><name><surname>Muramatsu</surname><given-names>J</given-names></name><name><surname>Nakauchi</surname><given-names>S</given-names></name><name><surname>Minami</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Asymmetrical characteristics of emotional responses to pictures and sounds: Evidence from pupillometry</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0230775</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0230775</pub-id><pub-id pub-id-type="pmid">32251474</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ogren</surname><given-names>M</given-names></name><name><surname>Kaplan</surname><given-names>B</given-names></name><name><surname>Peng</surname><given-names>Y</given-names></name><name><surname>Johnson</surname><given-names>KL</given-names></name><name><surname>Johnson</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Motion or emotion: infants discriminate emotional biological motion based on low-level visual information</article-title><source>Infant Behavior &amp; Development</source><volume>57</volume><elocation-id>101324</elocation-id><pub-id pub-id-type="doi">10.1016/j.infbeh.2019.04.006</pub-id><pub-id pub-id-type="pmid">31112859</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okon-Singer</surname><given-names>H</given-names></name><name><surname>Lichtenstein-Vidne</surname><given-names>L</given-names></name><name><surname>Cohen</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Dynamic modulation of emotional processing</article-title><source>Biological Psychology</source><volume>92</volume><fpage>480</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1016/j.biopsycho.2012.05.010</pub-id><pub-id pub-id-type="pmid">22676964</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oliva</surname><given-names>M</given-names></name><name><surname>Anikin</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupil dilation reflects the time course of emotion recognition in human vocalizations</article-title><source>Scientific Reports</source><volume>8</volume><elocation-id>4871</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-018-23265-x</pub-id><pub-id pub-id-type="pmid">29559673</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parron</surname><given-names>C</given-names></name><name><surname>Da Fonseca</surname><given-names>D</given-names></name><name><surname>Santos</surname><given-names>A</given-names></name><name><surname>Moore</surname><given-names>DG</given-names></name><name><surname>Monfardini</surname><given-names>E</given-names></name><name><surname>Deruelle</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Recognition of biological motion in children with autistic spectrum disorders</article-title><source>Autism</source><volume>12</volume><fpage>261</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1177/1362361307089520</pub-id><pub-id pub-id-type="pmid">18445735</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peelen</surname><given-names>MV</given-names></name><name><surname>Atkinson</surname><given-names>AP</given-names></name><name><surname>Andersson</surname><given-names>F</given-names></name><name><surname>Vuilleumier</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Emotional modulation of body-selective visual areas</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>2</volume><fpage>274</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1093/scan/nsm023</pub-id><pub-id pub-id-type="pmid">18985133</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1997">1997</year><source>The videotoolbox software for visual psychophysics: transforming numbers into movies</source><publisher-name>Spatial Vision</publisher-name><pub-id pub-id-type="doi">10.1163/156856897X00366</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pessoa</surname><given-names>L</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Emotion processing and the amygdala: from a “low road” to “many roads” of evaluating biological significance</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>773</fpage><lpage>783</lpage><pub-id pub-id-type="doi">10.1038/nrn2920</pub-id><pub-id pub-id-type="pmid">20959860</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pomè</surname><given-names>A</given-names></name><name><surname>Binda</surname><given-names>P</given-names></name><name><surname>Cicchini</surname><given-names>GM</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupillometry correlates of visual priming, and their dependency on autistic traits</article-title><source>Journal of Vision</source><volume>20</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.1167/jovi.20.3.3</pub-id><pub-id pub-id-type="pmid">32181859</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prunty</surname><given-names>JE</given-names></name><name><surname>Keemink</surname><given-names>JR</given-names></name><name><surname>Kelly</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Infants show pupil dilatory responses to happy and angry facial expressions</article-title><source>Developmental Science</source><volume>25</volume><elocation-id>e13182</elocation-id><pub-id pub-id-type="doi">10.1111/desc.13182</pub-id><pub-id pub-id-type="pmid">34633123</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roether</surname><given-names>CL</given-names></name><name><surname>Omlor</surname><given-names>L</given-names></name><name><surname>Christensen</surname><given-names>A</given-names></name><name><surname>Giese</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Critical features for the perception of emotion from gait</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>15</elocation-id><pub-id pub-id-type="doi">10.1167/9.6.15</pub-id><pub-id pub-id-type="pmid">19761306</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>P</given-names></name><name><surname>de Gelder</surname><given-names>B</given-names></name><name><surname>Crabbe</surname><given-names>F</given-names></name><name><surname>Grosbras</surname><given-names>M-H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Emotion modulation of the body-selective areas in the developing brain</article-title><source>Developmental Cognitive Neuroscience</source><volume>38</volume><elocation-id>100660</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2019.100660</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafer</surname><given-names>AT</given-names></name><name><surname>Matveychuk</surname><given-names>D</given-names></name><name><surname>Penney</surname><given-names>T</given-names></name><name><surname>O’Hare</surname><given-names>AJ</given-names></name><name><surname>Stokes</surname><given-names>J</given-names></name><name><surname>Dolcos</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Processing of emotional distraction is both automatic and modulated by attention: evidence from an event-related fMRI investigation</article-title><source>Journal of Cognitive Neuroscience</source><volume>24</volume><fpage>1233</fpage><lpage>1252</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00206</pub-id><pub-id pub-id-type="pmid">22332805</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simion</surname><given-names>F</given-names></name><name><surname>Regolin</surname><given-names>L</given-names></name><name><surname>Bulf</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A predisposition for biological motion in the newborn baby</article-title><source>PNAS</source><volume>105</volume><fpage>809</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1073/pnas.0707021105</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snowden</surname><given-names>RJ</given-names></name><name><surname>O’Farrell</surname><given-names>KR</given-names></name><name><surname>Burley</surname><given-names>D</given-names></name><name><surname>Erichsen</surname><given-names>JT</given-names></name><name><surname>Newton</surname><given-names>NV</given-names></name><name><surname>Gray</surname><given-names>NS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The pupil’s response to affective pictures: Role of image duration, habituation, and viewing mode</article-title><source>Psychophysiology</source><volume>53</volume><fpage>1217</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1111/psyp.12668</pub-id><pub-id pub-id-type="pmid">27172997</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spencer</surname><given-names>JMY</given-names></name><name><surname>Sekuler</surname><given-names>AB</given-names></name><name><surname>Bennett</surname><given-names>PJ</given-names></name><name><surname>Giese</surname><given-names>MA</given-names></name><name><surname>Pilz</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Effects of aging on identifying emotions conveyed by point-light walkers</article-title><source>Psychology and Aging</source><volume>31</volume><fpage>126</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1037/a0040009</pub-id><pub-id pub-id-type="pmid">26765748</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todorova</surname><given-names>GK</given-names></name><name><surname>Hatton</surname><given-names>REM</given-names></name><name><surname>Pollick</surname><given-names>FE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Biological motion perception in autism spectrum disorder: a meta-analysis</article-title><source>Molecular Autism</source><volume>10</volume><elocation-id>49</elocation-id><pub-id pub-id-type="doi">10.1186/s13229-019-0299-8</pub-id><pub-id pub-id-type="pmid">31890147</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Troje</surname><given-names>NF</given-names></name><name><surname>Westhoff</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The inversion effect in biological motion perception: evidence for a “life detector”?</article-title><source>Current Biology</source><volume>16</volume><fpage>821</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2006.03.022</pub-id><pub-id pub-id-type="pmid">16631591</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Troje</surname><given-names>NF</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Retrieving information from human movement patterns</source><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turi</surname><given-names>M</given-names></name><name><surname>Burr</surname><given-names>DC</given-names></name><name><surname>Binda</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupillometry reveals perceptual differences that are tightly linked to autistic traits in typical adults</article-title><source>eLife</source><volume>7</volume><elocation-id>e32399</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32399</pub-id><pub-id pub-id-type="pmid">29506652</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Wel</surname><given-names>P</given-names></name><name><surname>van Steenbergen</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pupil dilation as an index of effort in cognitive control tasks: A review</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>25</volume><fpage>2005</fpage><lpage>2015</lpage><pub-id pub-id-type="doi">10.3758/s13423-018-1432-y</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vuilleumier</surname><given-names>P</given-names></name><name><surname>Armony</surname><given-names>JL</given-names></name><name><surname>Driver</surname><given-names>J</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Distinct spatial frequency sensitivities for processing faces and emotional expressions</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>624</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1038/nn1057</pub-id><pub-id pub-id-type="pmid">12740580</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name><name><surname>He</surname><given-names>S</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Searching for life motion signals</article-title><source>Psychological Science</source><volume>21</volume><fpage>1083</fpage><lpage>1089</lpage><pub-id pub-id-type="doi">10.1177/0956797610376072</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>CA</given-names></name><name><surname>Boehnke</surname><given-names>SE</given-names></name><name><surname>White</surname><given-names>BJ</given-names></name><name><surname>Munoz</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Microstimulation of the monkey superior colliculus induces pupil dilation without evoking saccades</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3629</fpage><lpage>3636</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5512-11.2012</pub-id><pub-id pub-id-type="pmid">22423086</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Life motion signals lengthen perceived temporal duration</article-title><source>PNAS</source><volume>109</volume><fpage>E673</fpage><lpage>E677</lpage><pub-id pub-id-type="doi">10.1073/pnas.1115515109</pub-id><pub-id pub-id-type="pmid">22215595</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>X</given-names></name><name><surname>Shi</surname><given-names>J</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The feet have it: local biological motion cues trigger reflexive attentional orienting in the brain</article-title><source>NeuroImage</source><volume>84</volume><fpage>217</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.041</pub-id><pub-id pub-id-type="pmid">23994124</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>MA</given-names></name><name><surname>Morris</surname><given-names>AP</given-names></name><name><surname>McGlone</surname><given-names>F</given-names></name><name><surname>Abbott</surname><given-names>DF</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Amygdala responses to fearful and happy facial expressions under conditions of binocular suppression</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>2898</fpage><lpage>2904</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4977-03.2004</pub-id><pub-id pub-id-type="pmid">15044528</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>TKW</given-names></name><name><surname>Fung</surname><given-names>PCW</given-names></name><name><surname>Chua</surname><given-names>SE</given-names></name><name><surname>McAlonan</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Abnormal spatiotemporal processing of emotional facial expressions in childhood autism: dipole source analysis of event-related potentials</article-title><source>The European Journal of Neuroscience</source><volume>28</volume><fpage>407</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2008.06328.x</pub-id><pub-id pub-id-type="pmid">18702712</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Ji</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cross-modal social attention triggered by biological motion cues</article-title><source>Journal of Vision</source><volume>20</volume><elocation-id>21</elocation-id><pub-id pub-id-type="doi">10.1167/jov.20.10.21</pub-id><pub-id pub-id-type="pmid">33112938</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>T</given-names></name><name><surname>Ji</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Happy is stronger than sad: Emotional information modulates social attention</article-title><source>Emotion</source><volume>23</volume><fpage>1061</fpage><lpage>1074</lpage><pub-id pub-id-type="doi">10.1037/emo0001145</pub-id><pub-id pub-id-type="pmid">35980685</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Jiang</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Cross-channel adaptation reveals shared emotion representation from face and biological motion</article-title><source>Emotion</source><volume>1</volume><elocation-id>emo0001409</elocation-id><pub-id pub-id-type="doi">10.1037/emo0001409</pub-id><pub-id pub-id-type="pmid">39325400</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89873.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Xilin</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>South China Normal University</institution><country>China</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This <bold>important</bold> study provides <bold>convincing</bold> evidence that emotional information in biological motion can induce different patterns of pupil responses, which could serve as a behavioral marker of an autistic trait. These results broaden our understanding of how emotional biological motion can automatically trigger physiological changes and reveal the potential of using emotional-modulated pupil response to facilitate the diagnosis of social cognitive disorders. The work will be of broad interest to cognitive neuroscience, psychology, affective neuroscience, and vision science.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89873.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Tian et al. investigated the effects of emotional signals in biological motion on pupil responses. In this study, subjects were presented with point-light biological motion stimuli with happy, neutral, and sad emotions. Their pupil responses were recorded with an eye tracker. Throughout the study, emotion type (i.e., happy/sad/neutral) and BM stimulus type (intact/inverted/non-BM/local) were systematically manipulated. For intact BM stimuli, happy BM induced a larger pupil diameter than neutral BM, and neutral BM also induced a larger pupil diameter than sad BM. Importantly, the diameter difference between happy and sad BM correlated with the autistic trait of individuals. These effects disappeared for the inverted BM and non-BM stimuli. Interestingly, both happy and sad emotions show superiority in pupil diameter.</p><p>Strengths:</p><p>(1) The experimental conditions and results are very easy to understand.</p><p>(2) The writing and data presentation are clear.</p><p>(3) The methods are sound. I have no problems with the experimental design and results.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89873.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Through a serial of four experiments, Yuan, Wang and Jiang examined pupil size responses to emotion signals in point-light motion stimuli. Experiment 1 examined upright happy, sad and neutral point-light biological motion (BM) walkers. The happy BM induced a significantly larger pupil response than the neutral, whereas the sad BM evoked a significantly smaller pupil size than the neutral BM. Experiment 2 examined inverted BM walkers. Experiment 3 examined BM stimuli with acceleration removed. No significant effects of emotion were found in neither Experiment 2 nor Experiment 3. Experiment 4 examined scrambled BM stimuli, in which local motion features were preserved while the global configuration was disrupted. Interestingly, the scrambled happy and sad BM led to significant greater pupil size than the scrambled neutral BM at a relatively early time, while no significant difference between the scrambled happy and sad BM was found. Thus, the authors argue that these results suggest multi-level processing of emotions in life motion signals.</p><p>Strengths:</p><p>The experiments were carefully designed and well-executed, with point-light stimuli that eliminate many potential confounding effects of low-level visual features such as luminance, contrast, and spatial frequency.</p><p>Overall, I think this is a well-written paper with solid experimental results that support the claim of the authors, i.e., the human visual system may process emotional information in biological motion at multiple levels. Given the key role of emotion processing in normal social cognition, the results will be of interest not only to basic scientists who study visual perception, but also to clinical researchers who work with patients of social cognitive disorders. In addition, this paper suggests that examining pupil size responses could be a very useful methodological tool to study brain mechanisms underlying emotion processing.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89873.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The overarching goal of the authors was to understand whether emotional information conveyed through point-light biological motion can trigger automatic physiological responses, as reflected in pupil size.</p><p>Strengths:</p><p>This manuscript has several noticeable strengths: it addresses an intriguing research question that fills that gap in existing literature, presents a clear and accurate presentation of the current literature, and conducts a series of experiments and control experiments with adequete sample size. Yet, it also entails several noticeable limitations - especially in the study design and statistical analyses.</p><p>Assessment of the revision:</p><p>The authors have done a thorough job revising the manuscript, effectively addressing all of my previous concerns.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.89873.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Yuan</surname><given-names>Tian</given-names></name><role specific-use="author">Author</role><aff><institution>Institute of Psychology, Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Li</given-names></name><role specific-use="author">Author</role><aff><institution>Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Jiang</surname><given-names>Yi</given-names></name><role specific-use="author">Author</role><aff><institution>Chinese Academy of Sciences</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>eLife assessment:</bold></p><p>This study presents an important finding on the implicit and automatic emotion perception from biological motion (BM). The evidence supporting the claims of the authors is solid, although inclusion of a larger number of samples and more evidence for the discrepancy between Intact and local emotional BMs would have strengthened the study. The work will be of broad interest to perceptual and cognitive neuroscience.</p></disp-quote><p>We express our sincere gratitude for the positive and constructive evaluation of our manuscript. We have now included more participants and conducted a replication experiment to strengthen our results.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>Tian et al. investigated the effects of emotional signals in biological motion on pupil responses. In this study, subjects were presented with point-light biological motion stimuli with happy, neutral, and sad emotions. Their pupil responses were recorded with an eye tracker. Throughout the study, emotion type (i.e., happy/sad/neutral) and BM stimulus type (intact/inverted/non-BM/local) were systematically manipulated. For intact BM stimuli, happy BM induced a larger pupil diameter than neutral BM, and neutral BM also induced a larger pupil diameter than sad BM. Importantly, the diameter difference between happy and sad BM correlated with the autistic trait of individuals. These effects disappeared for the inverted BM and non-BM stimuli. Interestingly, both happy and sad emotions show superiority in pupil diameter.</p><p>Strengths:</p><p>(1) The experimental conditions and results are very easy to understand.</p><p>(2) The writing and data presentation are clear.</p><p>(3) The methods are sound. I have no problems with the experimental design and results.</p><p>Weaknesses:</p><p>(1) My main concern is the interpretation of the intact and local condition results. The processing advantage of happy emotion is not surprising given a number of existing studies. However, the only difference here seems to be the smaller (or larger) pupil diameter for sad compared to neutral in the intact (or local, respectively) condition. The current form only reports this effect but lacks in-depth discussions and explanations as to why this is the case.</p></disp-quote><p>Thanks for pointing this out, our apology for not making this point clear. It has long been documented that pupil size reflects the degree of cognitive effort and attention input (Joshi &amp; Gold, 2019; van der Wel &amp; van Steenbergen, 2018), and indexes the noradrenalin activity in emotion processing structures like amygdala (Dal Monte et al., 2015; Harrison et al., 2006; Liddell et al., 2005). Accordingly, we proposed that the smaller pupil response observed under the sad condition as compared to the neutral condition is because the sad biological motion (BM) could be less efficient in attracting visual attention and evoking emotional arousal. In line with this, it has been found that infants looked more at the neutral point-light walker when displayed in pair with the sad walker (Ogren et al., 2019), suggesting that the sad BM is less effective in capturing visual attention than the neutral BM. Besides, neural studies have revealed that, compared with other emotions (anger, happiness, disgust, and fear), the processing of sad emotion failed to evoke heightened activities in any emotionally relevant brain regions including the amygdala, the extrastriate body area (EBA) and the fusiform body area (FBA) (Peelen et al., 2007)(Peelen et al., 2007). The current study echoed with these previous findings by demonstrating a disadvantage for intact sad BM in evoking pupil responses. Notably, different from the intact sad BM, the local sad BM would instead induce stronger pupil responses than the neutral local BM. This distinctive pupil modulation effect observed in intact and local sad BM could be explained as a multi-level emotion processing model of BM. Specifically, even though both the intact and local BM conveyed important life information (Chang &amp; Troje, 2008, 2009; Simion et al., 2008), the latter is deprived of the global form feature. Hence, the processing of emotions in local BM may occur at a more basic and preliminary level, responding to the general affective salient emotion information (happy and sad) without detailed analysis. In fact, similar dissociated emotion processing phenomenon has been observed in another important type of emotional signal with analogous function (i.e., facial expression). For example, happy and fearful faces elicited differential amygdala activations when perceived consciously. However, they elicited comparable amygdala activations when suppressed (Williams et al., 2004). Moreover, it has been proposed that there exist two parallel routes for facial expression processing: a quick but coarse subcortical route that detects affective salient information without detailed analysis, and a fine-grained but slow cortical route that discriminates the exact emotion type. Similarly, the dissociated emotion processing in local and intact BM may function in the same manner, with the former serving as a primary emotion detection mechanism and the latter serving as a detailed emotion discrimination mechanism. Still, future studies adopting more diverse experimental paradigms and neuroimaging techniques were needed to further investigate this issue. We have added these points and more thoroughly discussed the potential mechanism in the revised text (see lines 329-339, 405-415, 418-420).</p><p>References:</p><p>Chang, D. H. F., &amp; Troje, N. F. (2008). Perception of animacy and direction from local biological motion signals. Journal of Vision, 8(5), 3. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/8.5.3">https://doi.org/10.1167/8.5.3</ext-link></p><p>Chang, D. H. F., &amp; Troje, N. F. (2009). Characterizing global and local mechanisms in biological motion perception. Journal of Vision, 9(5), 8–8. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.5.8">https://doi.org/10.1167/9.5.8</ext-link></p><p>Dal Monte, O., Costa, V. D., Noble, P. L., Murray, E. A., &amp; Averbeck, B. B. (2015). Amygdala lesions in rhesus macaques decrease attention to threat. Nature Communications, 6(1). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ncomms10161">https://doi.org/10.1038/ncomms10161</ext-link></p><p>Harrison, N. A., Singer, T., Rotshtein, P., Dolan, R. J., &amp; Critchley, H. D. (2006). Pupillary contagion: central mechanisms engaged in sadness processing. Social Cognitive and Affective Neuroscience, 1(1), 5–17. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/scan/nsl006">https://doi.org/10.1093/scan/nsl006</ext-link></p><p>Joshi, S., &amp; Gold, J. I. (2019). Pupil size as a window on neural substrates of cognition. Trends in Cognitive Sciences, 24(6), 466–480. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.31234/osf.io/dvsme">https://doi.org/10.31234/osf.io/dvsme</ext-link></p><p>Liddell, B. J., Brown, K. J., Kemp, A. H., Barton, M. J., Das, P., Peduto, A., Gordon, E., &amp; Williams, L. M. (2005). A direct brainstem–amygdala–cortical ‘alarm’ system for subliminal signals of fear. NeuroImage, 24(1), 235–243.</p><p>Ogren, M., Kaplan, B., Peng, Y., Johnson, K. L., &amp; Johnson, S. P. (2019). Motion or emotion: infants discriminate emotional biological motion based on low-level visual information. Infant Behavior and Development, 57, 101324. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.infbeh.2019.04.006">https://doi.org/10.1016/j.infbeh.2019.04.006</ext-link></p><p>Peelen, M. V., Atkinson, A. P., Andersson, F., &amp; Vuilleumier, P. (2007). Emotional modulation of body-selective visual areas. Social Cognitive and Affective Neuroscience, 2(4), 274–283. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/scan/nsm023">https://doi.org/10.1093/scan/nsm023</ext-link></p><p>Simion, F., Regolin, L., &amp; Bulf, H. (2008). A predisposition for biological motion in the newborn baby. Proceedings of the National Academy of Sciences, 105(2), 809–813. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0707021105">https://doi.org/10.1073/pnas.0707021105</ext-link></p><p>van der Wel, P., &amp; van Steenbergen, H. (2018). Pupil dilation as an index of effort in cognitive control tasks: a review. Psychonomic Bulletin &amp; Review, 25(6), 2005–2015. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13423-018-1432-y">https://doi.org/10.3758/s13423-018-1432-y</ext-link></p><p>Williams, M. A., Morris, A. P., McGlone, F., Abbott, D. F., &amp; Mattingley, J. B. (2004). Amygdala responses to fearful and happy facial expressions under conditions of binocular suppression. Journal of Neuroscience, 24(12), 2898-2904.</p><disp-quote content-type="editor-comment"><p>(2) I also found no systematic discussion and theoretical contributions regarding the correlation with the autistic traits. If the main point of this paper is to highlight an implicit and objective behavioral marker of the autistic trait, more interpretation and discussion of the links between the results and existing findings in ASD are needed.</p></disp-quote><p>We thank the reviewer for this insightful suggestion. The perception of biological motion (BM) has long been considered an important hallmark of social cognition. Abundant studies reported that individuals with social cognitive deficits (e.g., ASD) were impaired in BM perception (Blake et al., 2003; Freitag et al., 2008; Klin et al., 2009; Nackaerts et al., 2012). More recently, it has been pointed out that the extraction of more complex social information (e.g., emotions, intentions) from BM, as compared to basic BM recognitions, could be more effective in detecting ASDs (Federici et al., 2020; Koldewyn et al., 2009; Parron et al., 2008; Todorova et al., 2019). Specifically, a meta-analysis found that the effect size expanded nearly twice when the task required emotion recognition as compared to simple perception/detection (Todorova et al., 2019). However, for the high-functioning ASD individuals, it has been reported that they showed comparable performance with the control group in explicitly labelling BM emotions, while their responses were rather delayed (Mazzoni et al., 2021). This suggested that ASD individuals could adopt compensatory strategies to complete the explicit BM labelling task, while their automatic behavioural responses remained impaired. This highlights the importance of using more objective measures that do not rely on active reports to investigate the intrinsic perception of emotions from BM and its relationship with ASD-related social deficits. The current study thus introduced the pupil size measurement to this field, and we combined it with the passive viewing task to investigate the more automatic aspect of BM emotion processing. More importantly, in addition to diagnostic ASDs, the non-clinical general population also manifested autistic tendencies that followed normal distribution and demonstrated substantial heritability (Hoekstra et al., 2007). Here, we focused on the autistic tendencies in the general population, and our results showed that pupil modulations by BM emotions were indicative of individual autistic traits. Specifically, passively viewing the happy BMs evoked larger pupil responses than the sad BMs, while such emotional modulation diminished with the increase of autistic tendencies. More detailed test-retest examination further illustrated such a correlation was driven by the general diminishment in pupil modulation effects by emotional BM (happy or sad) for individuals with high autistic tendencies. This finding demonstrated that the automatic emotion processing of BM stimuli was impaired in individuals with high autistic tendencies, lending support to previous studies (Hubert et al., 2006; Nackaerts et al., 2012; Parron et al., 2008). This indicated the utility of emotional BM stimuli and pupil measurement in identifying ASD-related tendencies in both clinical and non-clinical populations. We have added these points to the revised text (see lines 347-375).</p><p>References:</p><p>Blake, R., Turner, L. M., Smoski, M. J., Pozdol, S. L., &amp; Stone, W. L. (2003). Visual recognition of biological motion is impaired in children with autism. Psychological Science, 14(2), 151–157. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/1467-9280.01434">https://doi.org/10.1111/1467-9280.01434</ext-link></p><p>Federici, A., Parma, V., Vicovaro, M., Radassao, L., Casartelli, L., &amp; Ronconi, L. (2020). Anomalous perception of biological motion in autism: a conceptual review and meta-analysis. Scientific Reports, 10(1). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-020-61252-3">https://doi.org/10.1038/s41598-020-61252-3</ext-link></p><p>Freitag, C. M., Konrad, C., Häberlen, M., Kleser, C., von Gontard, A., Reith, W., Troje, N. F., &amp; Krick, C. (2008). Perception of biological motion in autism spectrum disorders. Neuropsychologia, 46(5), 1480–1494. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2007.12.025">https://doi.org/10.1016/j.neuropsychologia.2007.12.025</ext-link></p><p>Hoekstra, R. A., Bartels, M., Verweij, C. J. H., &amp; Boomsma, D. I. (2007). Heritability of autistic traits in the general population. Archives of Pediatrics &amp; Adolescent Medicine, 161(4), 372. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1001/archpedi.161.4.372">https://doi.org/10.1001/archpedi.161.4.372</ext-link></p><p>Hubert, B., Wicker, B., Moore, D. G., Monfardini, E., Duverger, H., Fonséca, D. D., &amp; Deruelle, C. (2006). Brief report: recognition of emotional and non-emotional biological motion in individuals with autistic spectrum disorders. Journal of Autism and Developmental Disorders, 37(7), 1386–1392. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10803-006-0275-y">https://doi.org/10.1007/s10803-006-0275-y</ext-link></p><p>Klin, A., Lin, D. J., Gorrindo, P., Ramsay, G., &amp; Jones, W. (2009). Two-year-olds with autism orient to non-social contingencies rather than biological motion. Nature, 459(7244), 257–261. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature07868">https://doi.org/10.1038/nature07868</ext-link></p><p>Koldewyn, K., Whitney, D., &amp; Rivera, S. M. (2009). The psychophysics of visual motion and global form processing in autism. Brain, 133(2), 599–610. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/brain/awp272">https://doi.org/10.1093/brain/awp272</ext-link></p><p>Mazzoni, N., Ricciardelli, P., Actis-Grosso, R., &amp; Venuti, P. (2021). Difficulties in recognising dynamic but not static emotional body movements in autism spectrum disorder. Journal of Autism and Developmental Disorders, 52(3), 1092–1105. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10803-021-05015-7">https://doi.org/10.1007/s10803-021-05015-7</ext-link></p><p>Nackaerts, E., Wagemans, J., Helsen, W., Swinnen, S. P., Wenderoth, N., &amp; Alaerts, K. (2012). Recognizing biological motion and emotions from point-light displays in autism spectrum disorders. PLoS ONE, 7(9), e44473. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0044473">https://doi.org/10.1371/journal.pone.0044473</ext-link></p><p>Parron, C., Da Fonseca, D., Santos, A., Moore, D. G., Monfardini, E., &amp; Deruelle, C. (2008). Recognition of biological motion in children with autistic spectrum disorders. Autism, 12(3), 261–274. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/1362361307089520">https://doi.org/10.1177/1362361307089520</ext-link></p><p>Todorova, G. K., Hatton, R. E. M., &amp; Pollick, F. E. (2019). Biological motion perception in autism spectrum disorder: a meta-analysis. Molecular Autism, 10(1). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s13229-019-0299-8">https://doi.org/10.1186/s13229-019-0299-8</ext-link></p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>Through a series of four experiments, Yuan, Wang and Jiang examined pupil size responses to emotion signals in point-light motion stimuli. Experiment 1 examined upright happy, sad and neutral point-light biological motion (BM) walkers. The happy BM induced a significantly larger pupil response than the neutral, whereas the sad BM evoked a significantly smaller pupil size than the neutral BM. Experiment 2 examined inverted BM walkers. Experiment 3 examined BM stimuli with acceleration removed. No significant effects of emotion were found in neither Experiment 2 nor Experiment 3. Experiment 4 examined scrambled BM stimuli, in which local motion features were preserved while the global configuration was disrupted. Interestingly, the scrambled happy and sad BM led to significantly greater pupil size than the scrambled neutral BM at a relatively early time, while no significant difference between the scrambled happy and sad BM was found. Thus, the authors argue that these results suggest multi-level processing of emotions in life motion signals.</p><p>Strengths:</p><p>The experiments were carefully designed and well-executed, with point-light stimuli that eliminate many potential confounding effects of low-level visual features such as luminance, contrast, and spatial frequency.</p><p>Weaknesses:</p><p>Correlation results with limited sample size should be interpreted with extra caution.</p></disp-quote><p>Thanks for pointing this out. To strengthen the correlation results, we have conducted a replication experiment (Exp.1b) and added a test-retest examination to further assess the reliability of our measurements. Specifically, a new group of 24 participants (16 females, 8 males) were recruited to perform the identical experiment procedure as in Experiment 1. Then, after at least seven days, they were asked to return to the lab for a retest. The results successfully replicated the previously reported main effect of emotional condition in both the first test (F(2, 46) = 12.0, p &lt; .001, ηp2 = 0.34, Author response image 1A) and the second test (F(2, 46) = 14.8, p &lt; .001, ηp2 = 0.39, Author response image 1B). The happy BM induced a significantly larger pupil response than the neutral BM (First Test: t(23) = 2.60, p = .022, Cohen’s d = 0.53, 95% CI for the mean difference = [0.02, 0.14], Holm-corrected, p = .048 after Bonferroni correction, Author response image 1A; Second Test: t(23) = 3.36, p = .005, Cohen’s d = 0.68, 95% CI for the mean difference = [0.06, 0.24], Holm-corrected, p = .008 after Bonferroni correction, Author response image 1B). On the contrary, the sad BM induced a significantly smaller pupil response than the neutral BM (First Test: t(23) = -2.77, p = .022, Cohen’s d = 0.57, 95% CI for the mean difference = [-0.19, -0.03], Holm-corrected, p = .033 after Bonferroni correction; Second Test: t(23) = -3.19, p = .005, Cohen’s d = 0.65, 95% CI for the mean difference = [-0.24, -0.05], Holm-corrected, p = .012 after Bonferroni correction, Author response image 1B). Besides, the happy BM induced significantly larger pupil response than the sad BM (first test: t(23) = 4.23, p &lt; .001, Cohen’s d = 0.86, 95% CI for the mean difference = [0.10, 0.28], Holm-corrected, p &lt; .001 after Bonferroni correction, Author response image 1A; second test: t(23) = 4.26, p &lt; .001, Cohen’s d = 0.87, 95% CI for the mean difference = [0.15, 0.44], Holm-corrected, p &lt; .001 after Bonferroni correction, Author response image 1B). The results of the cluster-based permutation analysis were also similar (see Supplementary Material for more details).</p><fig id="sa4fig1" position="float"><label>Author response image 1.</label><caption><title>Normalized mean pupil responses in the replication experiment (Experiment 1b) of Experiment 1a and its retest, using the neutral condition as baseline, plotted against happy and sad conditions.</title><p>(A) In the first test, the group average pupil response to happy intact BM is significantly larger than that to sad and neutral BM, while the pupil response induced by sad BM is significantly smaller than that evoked by neutral BM, replicating the results of Experiment 1a. (B) Moreover, such results were similarly found in the second test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-sa4-fig1-v1.tif"/></fig><p>Notably, we successfully replicated the negative correlation between the happy over sad dilation effect and individual autistic traits in the first test (r(23) = -0.46, p = .023, 95% CI for the mean difference = [-0.73, -0.07], Author response image 2A). No other significant correlations were found (see Author response image 2B-C). Moreover, in the second test, such a correlation was similarly found and was even stronger (r(23) = -0.61, p = .002, 95% CI for the mean difference = [-0.81, -0.27], Author response image 2D). We‘ve also performed a test-retest reliability analysis on the happy over sad pupil dilation effect and the AQ score. The results showed robust correlations. See Author response table 1 for more details.</p><table-wrap id="sa4table1" position="float"><label>Author response table 1.</label><caption><title>Reliability of pupil size and AQ indices.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="bottom">Measurements</th><th valign="bottom">First Test</th><th valign="bottom">Second Test</th><th valign="bottom">Test-retest</th><th valign="bottom"/></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">M(SD)</td><td align="left" valign="bottom"/><td align="left" valign="bottom">alpha</td><td align="left" valign="bottom">r</td></tr><tr><td align="left" valign="bottom">happy-sad pupil size</td><td align="char" char="." valign="bottom">0.19(0.22)</td><td align="char" char="." valign="bottom">0.30(0.34)</td><td align="char" char="." valign="bottom">0.60</td><td align="left" valign="bottom">0.61^(****)</td></tr><tr><td align="left" valign="bottom">AQ score</td><td align="char" char="." valign="bottom">19.4(5.6)</td><td align="char" char="." valign="bottom">19.9(6.2)</td><td align="char" char="." valign="bottom">0.82</td><td align="left" valign="bottom">0.90^(cdots)</td></tr></tbody></table></table-wrap><p>Importantly, in the second test, we’ve also observed a significant negative correlation between AQ and the happy minus neutral pupil dilation effect (r(23) = -0.44, p = .032, 95% CI for the mean difference = [-0.72, -0.04], Author response image 2E), and a significant positive correlation between the sad minus neutral pupil size and AQ (r(23) = 0.50, p = .014, 95% CI for the mean difference = [0.12, 0.75], Author response image 2F). This indicated that the overall correlation between happy over sad dilation effect and AQ was driven both by the diminished happy dilation effect as well as the sad constriction effect. Overall, our replication experiment consistently found a significant negative correlation between AQ and happy over sad dilation effect both in the test and the retest. Moreover, it revealed that such an effect was contributed by both a negative correlation between AQ and happy-neutral pupil response and a positive correlation between AQ and sad-neutral pupil response, demonstrating a general impairment in BM emotion perception (happy or sad) for individuals with high autistic tendencies. This also indicated the utility of adopting a test-retest pupil examination to more precisely detect individual autistic tendencies. We have added these points in the revised text (see lines 135-173, lines 178-180).</p><fig id="sa4fig2" position="float"><label>Author response image 2.</label><caption><title>Correlation results for pupil modulation effects and AQ scores in the replication experiment (Experiment 1b) of Experiment 1a and its retest.</title><p>(A) We replicated the negative correlation between the happy over sad pupil dilation effect and AQ in the first test. (B-C) No other significant correlations were found. (D) In the second test, the negative correlation between the happy over sad pupil dilation effect and AQ was similarly observed and even stronger. (E-F) Moreover, the happy vs. neutral pupil dilation effect and the sad vs. neutral pupil constriction effect respectively correlate with AQ in the second test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-sa4-fig2-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>It would be helpful to add discussions as a context to compare the current results with pupil size reactions to emotion signals in picture stimuli.</p></disp-quote><p>Thanks for this this thoughtful comment. The modulation of emotional information on pupil responses has been mostly investigated using picture stimuli. Bradley et al. (2008) first demonstrated that humans showed larger pupil responses towards emotional images as compared to neutral images, while no difference was observed between the positive and negative images. This was regarded as the result of increased sympathetic activity induced by emotional arousal that is independent of the emotional valence. Similar results have been replicated with different presentation durations, repetition settings, and tasks (Bradley &amp; Lang, 2015; Snowden et al., 2016). However, the emotional stimuli adopted in these studies were mostly complicated scene images that conveyed rather general emotional information. When it comes to the specific emotion cues (e.g., fear, anger, happy, sad) delivered by our conspecifics through biologically salient signals (e.g., faces, gestures, voices), the results became intermixed. Some studies demonstrated that fearful, disgusted, and angry static faces induced larger pupil sizes than the neutral face, while sad and happy faces failed to induce such pupil dilatory effects (Burley et al., 2017). In contrast, other studies observed larger pupil responses for happy faces as compared to sad and fearful faces (Aktar et al., 2018; Burley &amp; Daughters, 2020; Jessen et al., 2016). These conflicting results could be due to the low-level confounds of emotional faces (e.g., eye size) (Carsten et al., 2019; Harrison et al., 2006). Similar to faces, BM also conveyed salient clues concerning the emotional states of our interactive partners. However, they were highly simplified, deprived of various irrelevant visual confounders (e.g., body shape). Here, we reported that the happy BM induced a stronger pupil response than the neutral and sad BM, lending support to the happy dilation effect observed with faces (Burley &amp; Daughters, 2020; Prunty et al., 2021). Moreover, it helps ameliorate the concern regarding the low-level confounding factors by identifying similar pupil modulations in another type of social signal with distinctive perceptual features. We have added these points to the revised text (see lines 301-321).</p><p>References:</p><p>Aktar, E., Mandell, D. J., de Vente, W., Majdandžić, M., Oort, F. J., van Renswoude, D. R., Raijmakers, M. E. J., &amp; Bögels, S. M. (2018). Parental negative emotions are related to behavioral and pupillary correlates of infants’ attention to facial expressions of emotion. Infant Behavior and Development, 53, 101–111. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.infbeh.2018.07.004">https://doi.org/10.1016/j.infbeh.2018.07.004</ext-link></p><p>Bradley, M. M., &amp; Lang, P. J. (2015). Memory, emotion, and pupil diameter: repetition of natural scenes. Psychophysiology, 52(9), 1186–1193. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/psyp.12442">https://doi.org/10.1111/psyp.12442</ext-link></p><p>Bradley, M. M., Miccoli, L., Escrig, M. A., &amp; Lang, P. J. (2008). The pupil as a measure of emotional arousal and autonomic activation. Psychophysiology, 45(4), 602–607. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1469-8986.2008.00654.x">https://doi.org/10.1111/j.1469-8986.2008.00654.x</ext-link></p><p>Burley, D. T., &amp; Daughters, K. (2020). The effect of oxytocin on pupil response to naturalistic dynamic facial expressions. Hormones and Behavior, 125, 104837. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.yhbeh.2020.104837">https://doi.org/10.1016/j.yhbeh.2020.104837</ext-link></p><p>Burley, D. T., Gray, N. S., &amp; Snowden, R. J. (2017). As far as the eye can see: relationship between psychopathic traits and pupil response to affective stimuli. PLOS ONE, 12(1), e0167436. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0167436">https://doi.org/10.1371/journal.pone.0167436</ext-link></p><p>Carsten, T., Desmet, C., Krebs, R. M., &amp; Brass, M. (2019). Pupillary contagion is independent of the emotional expression of the face. Emotion, 19(8), 1343–1352. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/emo0000503">https://doi.org/10.1037/emo0000503</ext-link></p><p>Harrison, N. A., Singer, T., Rotshtein, P., Dolan, R. J., &amp; Critchley, H. D. (2006). Pupillary contagion: central mechanisms engaged in sadness processing. Social Cognitive and Affective Neuroscience, 1(1), 5–17. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/scan/nsl006">https://doi.org/10.1093/scan/nsl006</ext-link></p><p>Jessen, S., Altvater-Mackensen, N., &amp; Grossmann, T. (2016). Pupillary responses reveal infants’ discrimination of facial emotions independent of conscious perception. Cognition, 150, 163–169. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2016.02.010">https://doi.org/10.1016/j.cognition.2016.02.010</ext-link></p><p>Prunty, J. E., Keemink, J. R., &amp; Kelly, D. J. (2021). Infants show pupil dilatory responses to happy and angry facial expressions. Developmental Science, 25(2). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.11">https://doi.org/10.11</ext-link></p><p>11/desc.13182</p><p>Snowden, R. J., O’Farrell, K. R., Burley, D., Erichsen, J. T., Newton, N. V., &amp; Gray, N. S. (2016). The pupil’s response to affective pictures: role of image duration, habituation, and viewing mode. Psychophysiology, 53(8), 1217–1223. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/psyp.12668">https://doi.org/10.1111/psyp.12668</ext-link></p><disp-quote content-type="editor-comment"><p>Overall, I think this is a well-written paper with solid experimental results that support the claim of the authors, i.e., the human visual system may process emotional information in biological motion at multiple levels. Given the key role of emotion processing in normal social cognition, the results will be of interest not only to basic scientists who study visual perception, but also to clinical researchers who work with patients of social cognitive disorders. In addition, this paper suggests that examining pupil size responses could be a very useful methodological tool to study brain mechanisms underlying emotion processing.</p><p><bold>Reviewer #3 (Public Review):</bold></p><p>Summary:</p><p>The overarching goal of the authors was to understand whether emotional information conveyed through point-light biological motion can trigger automatic physiological responses, as reflected in pupil size.</p><p>Strengths:</p><p>This manuscript has several noticeable strengths: it addresses an intriguing research question that fills that gap in existing literature, presents a clear and accurate presentation of the current literature, and conducts a series of experiments and control experiments with adequate sample size. Yet, it also entails several noticeable limitations - especially in the study design and statistical analyses.</p><p>Weaknesses:</p><p>(1) Study design:</p><p>(1.1) Dependent variable:</p><p>Emotional attention is known to modulate both microsaccades and pupil size. Given the existing pupillometry data that the authors have collected, it would be both possible and valuable to determine whether the rate of microsaccades is also influenced by emotional biological motion.</p></disp-quote><p>We thank the reviewer for this advice. Microsaccades functioned as a mechanism to maintain visibility by continuously shifting the retinal image to overcome visual adaptation (Martinez-Conde et al., 2006). Moreover, it was found to be sensitive to attention processes (Baumeler et al., 2020; Engbert &amp; Kliegl, 2003b; Meyberg et al., 2017), and could reflect the activity of superior colliculus (SC) and other related brain areas (Martinez-Conde et al., 2009, 2013). Previous studies have found that, compared with neutral and pleasant images, unpleasant images significantly inhibit early microsaccade rates (Kashihara, 2020; Kashihara et al., 2013). This is regarded as the result of retaining previous crucial information at the sacrifice of updating new visual input. We agree with the reviewer that it would be valuable to investigate whether emotional information conveyed by BM could modulate microsaccades. However, it should be noted that our data collection and experimental design are not optimized for this purpose. This is because we have only recorded the left eye’s data, while abundant methodological studies have doubted the reliability of using only one eye’s data to analyze microsaccades (Fang et al., 2018; Hauperich et al., 2020; Nyström et al., 2017) and suggested that the microsaccades should be defined by spontaneous binocular eye movement (Engbert &amp; Kliegl, 2003a, 2003b). Besides, according to Kashihara et al. (2013), participants showed differential microsaccade rates after the stimuli disappeared so as to maintain the previously observed different emotional information. However, in the current study, we discarded the data after the stimuli disappeared, making it impossible to analyze the microsaccade data after the stimuli disappeared. Despite these disadvantages, we have attempted to analyze the microsaccade rate during the stimuli presentation using only the left eye’s data. Specifically, we applied the algorithm developed by Otero-Millan et al. (2014) (minimum duration = 6 ms, maximum amplitude = 1.5 degrees, maximum velocity = 150 degrees/sec) to the left eye’s data from 100 ms before to 4000 ms after stimulus onset. Subsequently, we calculated the microsaccade rates using a moving window of 100 ms (stepped in 1 ms) (Engbert &amp; Kliegl, 2003b; Kashihara et al., 2013). The microsaccade rate displayed a typical curve, with suppression shortly after stimulus appearance (inhibition phase), followed by an increased rate of microsaccade occurrence (rebound phase). The cluster-based permutation analysis was then applied to explore the modulation of BM emotions on microsaccade rates. However, no significant differences among different emotional conditions (happy, sad, neutral) were found for the four experiments.</p><fig id="sa4fig3" position="float"><label>Author response image 3.</label><caption><title>Time-series change in the microsaccade rates to happy, sad, and neutral BM in Experiments 1-4.</title><p>Solid lines represent microsaccade rates under each emotional condition as a function of time (happy: red; sad: blue; neutral: gray); shaded areas represent the SEM between participants. No significant differences were found after cluster-based permutation correction for the four experiments.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-sa4-fig3-v1.tif"/></fig><p>It is important to note that the microsaccade rate analysis was conducted on only the left eye’s data and that the experiment design is not optimized for this analysis, thus, extra caution should be exercised in interpreting the results. Still, we found it very innovative and important to combine the microsaccade index with the pupil size to holistically investigate the processing of emotional information in BM, and future studies are highly needed to adopt more suitable recording techniques and experiment designs to further probe this issue. We have discussed this issue in the revised text (see lines 339-344).</p><p>References:</p><p>Baumeler, D., Schönhammer, J. G., &amp; Born, S. (2020). Microsaccade dynamics in the attentional repulsion effect. Vision Research, 170, 46–52. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2020.03.009">https://doi.org/10.1016/j.visres.2020.03.009</ext-link></p><p>Engbert, R., &amp; Kliegl, R. (2003a). Binocular coordination in microsaccades. In The Mind’s Eye (pp. 103–117). Elsevier. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/b978-044451020-4/50007-4">https://doi.org/10.1016/b978-044451020-4/50007-4</ext-link></p><p>Engbert, R., &amp; Kliegl, R. (2003b). Microsaccades uncover the orientation of covert attention. Vision Research, 43(9), 1035–1045. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/s0042-6989(03)00084-1">https://doi.org/10.1016/s0042-6989(03)00084-1</ext-link></p><p>Fang, Y., Gill, C., Poletti, M., &amp; Rucci, M. (2018). Monocular microsaccades: do they really occur? Journal of Vision, 18(3), 18. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/18.3.18">https://doi.org/10.1167/18.3.18</ext-link></p><p>Hauperich, A.-K., Young, L. K., &amp; Smithson, H. E. (2020). What makes a microsaccade? a review of 70 years research prompts a new detection method. Journal of Eye Movement Research, 12(6). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.16910/jemr.12.6.13">https://doi.org/10.16910/jemr.12.6.13</ext-link></p><p>Kashihara, K. (2020). Microsaccadic modulation evoked by emotional events. Journal of Physiological Anthropology, 39(1). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s40101-020-00238-6">https://doi.org/10.1186/s40101-020-00238-6</ext-link></p><p>Kashihara, K., Okanoya, K., &amp; Kawai, N. (2013). Emotional attention modulates microsaccadic rate and direction. Psychological Research, 78(2), 166–179. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00426-013-0490-z">https://doi.org/10.1007/s00426-013-0490-z</ext-link></p><p>Martinez-Conde, S., Macknik, S. L., Troncoso, X. G., &amp; Dyar, T. A. (2006). Microsaccades counteract visual fading during fixation. Neuron, 49(2), 297–305. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.11.033">https://doi.org/10.1016/j.neuron.2005.11.033</ext-link></p><p>Martinez-Conde, S., Macknik, S. L., Troncoso, X. G., &amp; Hubel, D. H. (2009). Microsaccades: a neurophysiological analysis. Trends in Neurosciences, 32(9), 463–475. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2009.05.006">https://doi.org/10.1016/j.tins.2009.05.006</ext-link></p><p>Martinez-Conde, S., Otero-Millan, J., &amp; Macknik, S. L. (2013). The impact of microsaccades on vision: towards a unified theory of saccadic function. Nature Reviews Neuroscience, 14(2), 83–96. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn3405">https://doi.org/10.1038/nrn3405</ext-link></p><p>Meyberg, S., Sinn, P., Engbert, R., &amp; Sommer, W. (2017). Revising the link between microsaccades and the spatial cueing of voluntary attention. Vision Research, 133, 47–60. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2017.01.001">https://doi.org/10.1016/j.visres.2017.01.001</ext-link></p><p>Nyström, M., Andersson, R., Niehorster, D. C., &amp; Hooge, I. (2017). Searching for monocular microsaccades – a red hering of modern eye trackers? Vision Research, 140, 44–54. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2017.07.012">https://doi.org/10.1016/j.visres.2017.07.012</ext-link></p><p>Otero-Millan, J., Castro, J. L. A., Macknik, S. L., &amp; Martinez-Conde, S. (2014). Unsupervised clustering method to detect microsaccades. Journal of Vision, 14(2), 18–18. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/14.2.18">https://doi.org/10.1167/14.2.18</ext-link></p><disp-quote content-type="editor-comment"><p>(1.2) Stimuli:</p><p>It appears that the speed of the emotional biological motion stimuli mimics the natural pace of the emotional walker. What is the average velocity of the biological motion stimuli for each condition?</p></disp-quote><p>Thanks for pointing out this issue. The neutral and emotional (sad or happy) BM stimuli are equal in walking speed (one step for one second, 1Hz). We have also computed their physical velocity by calculating the Euclidean distance in pixel space of each key point between adjacent frames (Poyo Solanas et al., 2020). The velocity was 5.76 pixels/frame for the happy BM, 4.14 pixels/frame for the neutral BM, and 3.21 pixels/frame for the sad BM. This difference in velocity profile was considered an important signature for conveying emotional information, as the happy walker was characterized by a larger step pace and longer arm swing and the sad walker would instead exhibit a slouching gait with short slow strides and smaller arm movement (Barliya et al., 2012; Chouchourelou et al., 2006; Halovic &amp; Kroos, 2018; Roether et al., 2009). More importantly, our current results could not be explained by the differences in velocities. This is because the inverted emotional BM with identical velocity characteristics failed to induce any modulations on pupil responses. Furthermore, the local sad and happy BM differed the most in velocity feature, while they induced similar modulations on pupil sizes. We have added these points in the revised text (see lines 254-257, 484-491).</p><p>References:</p><p>Barliya, A., Omlor, L., Giese, M. A., Berthoz, A., &amp; Flash, T. (2012). Expression of emotion in the kinematics of locomotion. Experimental Brain Research, 225(2), 159–176. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-012-3357-4">https://doi.org/10.1007/s00221-012-3357-4</ext-link></p><p>Chouchourelou, A., Matsuka, T., Harber, K., &amp; Shiffrar, M. (2006). The visual analysis of emotional actions. Social Neuroscience, 1(1), 63–74. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/17470910600630599">https://doi.org/10.1080/17470910600630599</ext-link></p><p>Halovic, S., &amp; Kroos, C. (2018). Not all is noticed: kinematic cues of emotion-specific gait. Human Movement Science, 57, 478–488. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.humov.2017.11.008">https://doi.org/10.1016/j.humov.2017.11.008</ext-link></p><p>Poyo Solanas, M., Vaessen, M. J., &amp; de Gelder, B. (2020). The role of computational and subjective features in emotional body expressions. Scientific Reports, 10(1). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-020-63125-1">https://doi.org/10.1038/s41598-020-63125-1</ext-link></p><p>Roether, C. L., Omlor, L., Christensen, A., &amp; Giese, M. A. (2009). Critical features for the perception of emotion from gait. Journal of Vision, 9(6), 15–15. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.6.15">https://doi.org/10.1167/9.6.15</ext-link></p><disp-quote content-type="editor-comment"><p>When the authors used inverted biological motion stimuli, they didn't observe any modulation in pupil size. Could there be a difference in microsaccades when comparing inverted emotional biological motion stimuli?</p></disp-quote><p>Thanks for this consideration. Both microsaccades and pupil size can provide valuable insights into the underlying neural dynamics of attention and cognitive control (Baumeler et al., 2020; Engbert &amp; Kliegl, 2003; Meyberg et al., 2017). Notably, previous studies have shown that the microsaccades and pupil sizes could be similar and highly correlated in reflecting various cognitive processes, such as multisensory integration, inhibitory control, and cognitive load (Krejtz et al., 2018; Wang et al., 2017; Wang &amp; Munoz, 2021). Moreover, the generation of both microsaccades and pupil responses would involve shared neural circuits, including the midbrain structure superior colliculus (SC) and the noradrenergic system (Hafed et al., 2009; Hafed &amp; Krauzlis, 2012; Wang et al., 2012). However, the pupil size could be more sensitive than microsaccade rates in contexts such as affective priming (Krejtz et al., 2020) and decision formation (Strauch et al., 2018). Moreover, abundant former studies have all shown that inversion would significantly disrupt the perception of emotions from BM (Atkinson et al., 2007; Dittrich et al., 1996; Spencer et al., 2016; Yuan et al., 2022, 2023). Overall, it is unlikely for the microsaccade rates to show significant differences when comparing inverted emotional biological motion stimuli. Besides, we have attempted to analyze the microsaccade rate in the inverted BM situation, while our results showed no significant differences (see also Point 1.1, Author response image 3). Still, it is needed for future studies to combine the microsaccade index and pupil size to provide a thorough understanding of BM emotion processing. We have discussed this issue in the revised text (see lines 339-344).</p><p>References:</p><p>Atkinson, A. P., Tunstall, M. L., &amp; Dittrich, W. H. (2007). Evidence for distinct contributions of form and motion information to the recognition of emotions from body gestures. Cognition, 104(1), 59–72. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2006.05.005">https://doi.org/10.1016/j.cognition.2006.05.005</ext-link></p><p>Baumeler, D., Schönhammer, J. G., &amp; Born, S. (2020). Microsaccade dynamics in the attentional repulsion effect. Vision Research, 170, 46–52. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2020.03.009">https://doi.org/10.1016/j.visres.2020.03.009</ext-link></p><p>Dittrich, W., Troscianko, T., Lea, S., &amp; Morgan, D. (1996). Perception of emotion from dynamic point-light displays represented in dance. Perception, 25(6), 727–738. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1068/p250727">https://doi.org/10.1068/p250727</ext-link></p><p>Engbert, R., &amp; Kliegl, R. (2003). Microsaccades uncover the orientation of covert attention. Vision Research, 43(9), 1035–1045. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/s0042-6989(03)00084-1">https://doi.org/10.1016/s0042-6989(03)00084-1</ext-link></p><p>Hafed, Z. M., Goffart, L., &amp; Krauzlis, R. J. (2009). A neural mechanism for microsaccade generation in the primate superior colliculus. Science, 323(5916), 940–943. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1166112">https://doi.org/10.1126/science.1166112</ext-link></p><p>Hafed, Z. M., &amp; Krauzlis, R. J. (2012). Similarity of superior colliculus involvement in microsaccade and saccade generation. Journal of neurophysiology, 107(7), 1904-1916.</p><p>Krejtz, K., Duchowski, A. T., Niedzielska, A., Biele, C., &amp; Krejtz, I. (2018). Eye tracking cognitive load using pupil diameter and microsaccades with fixed gaze. Plos One, 13(9), e0203629. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0203629">https://doi.org/10.1371/journal.pone.0203629</ext-link></p><p>Krejtz, K., Żurawska, J., Duchowski, A., &amp; Wichary, S. (2020). Pupillary and microsaccadic responses to cognitive effort and emotional arousal during complex decision making. Journal of Eye Movement Research, 13(5). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.16910/jemr.13.5.2">https://doi.org/10.16910/jemr.13.5.2</ext-link></p><p>Meyberg, S., Sinn, P., Engbert, R., &amp; Sommer, W. (2017). Revising the link between microsaccades and the spatial cueing of voluntary attention. Vision Research, 133, 47–60. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.visres.2017.01.001">https://doi.org/10.1016/j.visres.2017.01.001</ext-link></p><p>Spencer, J. M. Y., Sekuler, A. B., Bennett, P. J., Giese, M. A., &amp; Pilz, K. S. (2016). Effects of aging on identifying emotions conveyed by point-light walkers. Psychology and Aging, 31(1), 126–138. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0040009">https://doi.org/10.1037/a0040009</ext-link></p><p>Strauch, C., Greiter, L., &amp; Huckauf, A. (2018). Pupil dilation but not microsaccade rate robustly reveals decision formation. Scientific Reports, 8(1). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-018-31551-x">https://doi.org/10.1038/s41598-018-31551-x</ext-link></p><p>Wang, C.-A., Blohm, G., Huang, J., Boehnke, S. E., &amp; Munoz, D. P. (2017). Multisensory integration in orienting behavior: pupil size, microsaccades, and saccades. Biological Psychology, 129, 36–44. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.biopsycho.2017.07.024">https://doi.org/10.1016/j.biopsycho.2017.07.024</ext-link></p><p>Wang, C.-A., Boehnke, S. E., White, B. J., &amp; Munoz, D. P. (2012). Microstimulation of the monkey superior colliculus induces pupil dilation without evoking saccades. Journal of Neuroscience, 32(11), 3629–3636. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/jneurosci.5512-11.2012">https://doi.org/10.1523/jneurosci.5512-11.2012</ext-link></p><p>Wang, C.-A., &amp; Munoz, D. P. (2021). Differentiating global luminance, arousal and cognitive signals on pupil size and microsaccades. European Journal of Neuroscience, 54(10), 7560–7574. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/ejn.15508">https://doi.org/10.1111/ejn.15508</ext-link></p><p>Yuan, T., Ji, H., Wang, L., &amp; Jiang, Y. (2022). Happy is stronger than sad: emotional information modulates social attention. Emotion. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/emo0001145">https://doi.org/10.1037/emo0001145</ext-link></p><p>Yuan, T., Wang, L., &amp; Jiang, Y. (2023). Cross-channel adaptation reveals shared emotion representation from face and biological motion. In Emotion (p. In Press).</p><disp-quote content-type="editor-comment"><p>(2) Statistical analyses</p><p>(2.1) Multiple comparisons:</p><p>There are many posthoc comparisons throughout the manuscript. The authors should consider correction for multiple comparisons. Take Experiment 1 for example, it is important to note that the happy over neutral BM effect and the sad over neutral BM effect are no longer significant after Bonferroni correction, which is worth noting.</p></disp-quote><p>Thanks for this suggestion. In our original analysis, we applied the Holm post-hoc corrections for multiple comparisons. The Holm correction is a step-down correction method and is more powerful but less conservative than the Bonferroni correction. We have now conducted the stricter Bonferroni post-hoc correction. In Experiment 1, the happy over neutral, and happy over sad BM effect is still significant after the Bonferroni post-hoc correction (happy vs. neutral: p = .036; happy vs. sad: p = .009), and the sad over neutral comparison remains marginally significant after the Bonferroni post-hoc correction (p = .071). Importantly, the test-retest replication experiment also yielded significant results for the comparisons between happy and neutral (First Test: p = .022, Holm-corrected, p = .048, Bonferroni-corrected; Second Test: p = .005, Holm-corrected, p = .008, Bonferroni-corrected), sad and neutral (First Test: p = .022, Holm-corrected, p = .033, Bonferroni-corrected; Second Test: p = .005, Holm-corrected, p = .012, Bonferroni-corrected, Author response image 1B), and happy and sad BM (First test: p &lt; .001, Holm-corrected, p &lt; .001, Bonferroni-corrected; Second test: p &lt; .001, Holm-corrected, p &lt; .001, Bonferroni-corrected). These results provided support for the replicability and consistency of the reported significant contrasts. See also Point 2.3.</p><p>In Experiment 4, the significance levels of all comparisons remained the same after Bonferroni post-hoc correction (happy vs. neutral: p = .011; sad vs. neutral: p = .007; happy vs. sad: p = 1.000). We have now added these results in the main text (See lines 119, 122, 124, 143, 145, 148, 150, 153, 155, 248, 251, 254).</p><disp-quote content-type="editor-comment"><p>(2.2) The authors present the correlation between happy over sad dilation effect and the autistic traits in Experiment 1, but do not report such correlations in Experiments 2-4. Did the authors collect the Autistic Quotient measure in Experiments 2-4? It would be informative if the authors could demonstrate the reproducibility (or lack thereof) of this happy-sad index in Experiments 2-4.</p></disp-quote><p>We apologize for not making it clear. We have collected the AQ scores in Experiments 2-4. However, it should be pointed out that the happy over sad pupil dilation effect was only observed in Experiment 1. Moreover, we’ve again identified such happy over sad pupil dilation effect in the replication experiment (Experiment 1b) as well as its correlation with AQ. Instead, no significant correlations between AQ and the happy-sad pupil index were found in Experiments 2-4, see Author response image 4 for more details. We have reported these correlations in the main text (see lines 157-173, 190-194, 212-216, 257-262).</p><fig id="sa4fig4" position="float"><label>Author response image 4.</label><caption><title>Correlations between the happy over sad pupil dilation effect and AQ scores.</title><p>(A) The happy over sad pupil dilation effect correlated negatively with individual autistic scores. (B-C) Such correlation was similarly observed in the test and retest of the replication experiment. (D-F) No such correlations were found for the inverted, nonbiological, and local BM stimuli.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-sa4-fig4-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(2.3) The observed correlation between happy over sad dilation effect and the autistic traits in Experiment 1 seems rather weak. It could be attributed to the poor reliability of the Autistic Quotient measure or the author-constructed happy-sad index. Did the authors examine the test-retest reliability of their tasks or the Autistic Quotient measure?</p></disp-quote><p>Thanks for this suggestion. We have now conducted a test-retest replication study to further confirm the observed significant correlations. Specifically, we recruited a new group of 24 participants (16 females, 8 males) to perform the identical procedure as in Experiment 1, and they were asked to return to the lab for a retest after at least seven days. We’ve replicated the significant main effect of emotional conditions in both the first test (F(2, 46) = 12.0, p &lt; .001, ηp2 = 0.34) and the second test (F(2, 46) = 14.8, p &lt; .001, ηp2 = 0.39). Besides, we also replicated the happy minus neutral pupil dilation effect (First Test: t(23) = 2.60, p = .022, Cohen’s d = 0.53, 95% CI for the mean difference = [0.02, 0.14], Holm-corrected, p = .048 after Bonferroni correction; Second Test: t(23) = 3.36, p = .005, Cohen’s d = 0.68, 95% CI for the mean difference = [0.06, 0.24], Holm-corrected, p = .008 after Bonferroni correction), and the sad minus neutral pupil constriction effect (First Test: t(23) = -2.77, p = .022, Cohen’s d = 0.57, 95% CI for the mean difference = [-0.19, -0.03], Holm-corrected, p = .033 after Bonferroni correction; Second Test: t(23) = -3.19, p = .005, Cohen’s d = 0.65, 95% CI for the mean difference = [-0.24, -0.05], Holm-corrected, p = .012 after Bonferroni correction). Additionally, the happy BM still induced a significantly larger pupil response than the sad BM (first test: t(23) = 4.23, p &lt; .001, Cohen’s d = 0.86, 95% CI for the mean difference = [0.10, 0.28], Holm-corrected, p &lt; .001 after Bonferroni correction; second test: t(23) = 4.26, p &lt; .001, Cohen’s d = 0.87, 95% CI for the mean difference = [0.15, 0.44], Holm-corrected, p &lt; .001 after Bonferroni correction).</p><p>Notably, we’ve successfully replicated the negative correlation between the happy over sad dilation effect and individual autistic traits (r(23) = -0.46, p = .023, 95% CI for the mean difference = [-0.73, -0.07]). Such a correlation was similarly found and was even stronger in the retest (r(23) = -0.61, p = .002, 95% CI for the mean difference = [-0.81, -0.27]). A test-retest reliability analysis was conducted on the happy over sad pupil dilation effect and the AQ score. The results showed robust correlations (r(happy-sad pupil size) = 0.56; r(AQ) = 0.90) and strong test-retest reliabilities (α(happy-sad pupil size) = 0.60; α(AQ) = 0.82). We have added these results to the main text (see lines 135-173). See also Response to Reviewer #2 Response 1 for more details.</p><disp-quote content-type="editor-comment"><p>(2.4) Relatedly, the happy over sad dilation effect is essentially a subtraction index. Without separately presenting the pipul size correlation with happy and sad BM in supplemental figures, it becomes challenging to understand what's primarily driving the observed correlation.</p></disp-quote><p>Thanks for pointing this out. We have now presented the separate correlations between AQ and the pupil response towards happy and sad BM in Experiment 1 (see Author response image 5A), and the test-retest replication experiment of Experiment 1 (see Author response image 5B-C). No significant correlations were found. This is potentially because the raw pupil response is a mixed result of BM perception and emotion perception, while the variations in pupil sizes across emotional conditions could more faithfully reflect individual sensitivities to emotions in BM (Burley et al., 2017; Pomè et al., 2020; Turi et al., 2018).</p><fig id="sa4fig5" position="float"><label>Author response image 5.</label><caption><title>No significant correlations between AQ and pupil response towards happy and sad intact BM were found in Experiment 1a and the test-retest replication experiment (Experiment 1b).</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-sa4-fig5-v1.tif"/></fig><p>To probe what's primarily driving the observed correlation between happy-sad pupil size and AQ, we instead used the neutral as the baseline and separately correlated AQ with the happy-neutral and the sad-neutral pupil modulation effects. No significant correlation was found in Experiment 1a (Author response image 6A-B) and the first test of the replication experiment (Experiment 1b) (Author response image 6C-D). Importantly, in the second test of the replication experiment, we found a significant negative correlation between AQ and the happy-neutral pupil size (r(23) = -0.44, p = .032, 95% CI for the mean difference = [-0.72, -0.04], Author response image 6E), and a significant positive correlation between AQ and the sad-neutral pupil size (r(23) = 0.50, p = .014, 95% CI for the mean difference = [0.12, 0.75], Author response image 6F). This suggested that the overall correlation between AQ and the happy over sad dilation effect was driven by diminished pupil modulations towards both the happy and sad BM for high AQ individuals, demonstrating a general deficiency in BM emotion perception (happy or sad) among individuals with high autistic tendencies. It further revealed the potential of adopting a test-retest pupil examination to more precisely detect individual autistic tendencies. We have reported these results in the main text (see lines 166-173).</p><fig id="sa4fig6" position="float"><label>Author response image 6.</label><caption><title>Correlation results for pupil modulations and AQ scores.</title><p>(A-B) In Experiment 1a, no significant correlation was observed between AQ and the happy pupil modulation effect, as well as between AQ and the sad pupil modulation effect. (C-D) Similarly, no significant correlations were found in the first test of the replication experiment (Experiment 1b). (E-F) Importantly, in the second test of Experiment 1b, the happy vs. neutral pupil dilation effect was positively correlated with AQ, and the sad vs. neutral pupil constriction effect was positively correlated with AQ.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-89873-sa4-fig6-v1.tif"/></fig><p>References:</p><p>Burley, D. T., Gray, N. S., &amp; Snowden, R. J. (2017). As Far as the Eye Can See: Relationship between Psychopathic Traits and Pupil Response to Affective Stimuli. PLOS ONE, 12(1), e0167436. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0167436">https://doi.org/10.1371/journal.pone.0167436</ext-link></p><p>Pomè, A., Binda, P., Cicchini, G. M., &amp; Burr, D. C. (2020). Pupillometry correlates of visual priming, and their dependency on autistic traits. Journal of vision, 20(3), 3-3.</p><p>Turi, M., Burr, D. C., &amp; Binda, P. (2018). Pupillometry reveals perceptual differences that are tightly linked to autistic traits in typical adults. eLife, 7. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/elife.32399">https://doi.org/10.7554/elife.32399</ext-link></p><disp-quote content-type="editor-comment"><p>(2.5) For the sake of transparency, it is important to report all findings, not just the positive results, throughout the paper.</p></disp-quote><p>Thanks for this suggestion. We have now reported all the correlations results between AQ and pupil modulation effects (happy-sad, happy-neutral, sad-neutral) in the main text (see lines 130-131, 157-162, 166-170, 190-194, 212-216, 257-262). Given that no significant correlations were observed between AQ and the raw pupil responses across four experiments, we reported their correlations with AQ in the supplementary material. We have stated this point in the main text (see lines 132-134).</p><disp-quote content-type="editor-comment"><p>(3) Structure</p><p>(3.1) The Results section immediately proceeds to the one-way repeated measures ANOVA. This section could be more reader-friendly by including a brief overview of the task procedures and variables, e.g., shifting Fig. 3 to this section.</p></disp-quote><p>Thanks for this advice. We have now added a brief overview of the task procedures and variables and we have also shifted the figure position (see lines 101-103).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>(1) I suggest that the authors first explain the task (i.e., Fig. 3) at the beginning of the results. And it seems more appropriate to show the time course figures (Fig. 2) and before the bar plots (Fig. 1). If I understand correctly, the bar plots reflect the averaged data from the time course plots. Also, please clearly state the time window used to average the data. The results of the correlation analysis can be displayed in the last step.</p></disp-quote><p>Thanks for this suggestion. We have now added a concise explanation of the task at the beginning of the results (see lines 101-103). We have also adjusted the figure positions and adjusted the order of our results according to the reviewer’s suggestion. The time window we used to average the data was from the onset of the stimuli until the end of the stimuli presentation. We have now clearly stated these issues in the revised text (see lines 111-112).</p><disp-quote content-type="editor-comment"><p>(2) According to the above, I think a more reasonable arrangement should be Fig. 3, 2, and 1.</p></disp-quote><p>Thanks for this suggestion. We have adjusted the figure positions accordingly.</p><disp-quote content-type="editor-comment"><p>(3) Please include each subject's data points in the bar plots in Fig. 1.</p></disp-quote><p>We have now presented each subject’s individual data point in the bar plot.</p><disp-quote content-type="editor-comment"><p>(4) Lines 158-160 and 199-202 report interaction effects of the two-way ANOVA. This is good, but the direction of interaction effect should also be reported.</p></disp-quote><p>We thank the reviewer for this suggestion. We have now reported the direction of the interaction effect. The significant interaction observed across Experiment 1 and Experiment 2 was mainly due to the diminishment of emotional modulation in inverted BM. The significant interaction crossing Experiment 1 and Experiment 3 was similarly caused by the lack of emotional modulation in nonbiological stimuli. With regard to the significant interaction across Experiment 1 and Experiment 4, it could be primarily attributed to the vanishment of pupil modulation effect between happy and sad local BM. We have specified these points in the revised text, see lines 198-199, 219-220, 267-269.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>(1) Number of experiments:</p><p>As stated in the Methods section, this study seems to consist of five experiments (120/24=5) according to the description below. However, the current manuscript only reports findings from four of these experiments. Can the authors clarify on this matter?</p><p>&quot;A total of 120 participants (44 males, 76 females) ranging from 18 to 29 years old (M ± SD = 23.1 ± 2.5) were recruited, with 24 in each experiment.&quot;</p></disp-quote><p>We apologize for not making it clear. This referred to a pure behavior explicit emotion classification experiment (N=24) that served as a prior test to confirm that the local BM stimuli conveyed recognizable emotional information. We have now more carefully stated this issue in the revised text, see lines 456-458.</p><disp-quote content-type="editor-comment"><p>(2) Emotion processing mechanism of BM</p><p>&quot;Mechanism&quot; is a very strong word, suggesting a causal relationship. In the setting of a passive viewing task that lacks any behavioral report, it is possible that the observed changes in pupil size could be epiphenomenal, rather than serving as the underlying mechanism.</p></disp-quote><p>Thanks for this suggestion. We have now either changed “mechanism” into “phenomenon” or deleted it. We have also carefully discussed the potential implications for future studies to incorporate variant behavioral, physiological and neural indexes to yield more robust causal evidence to unveil the potential mechanism serving the observed multi-level BM emotion processing phenomenon.</p><disp-quote content-type="editor-comment"><p>(3) Data sharing</p><p>The authors could improve their efforts in promoting data transparency to ensure a comprehensive view of the results. This implies sharing deidentified raw data instead of summary data in an Excel spreadsheet.</p></disp-quote><p>Thanks for this suggestion. We have now uploaded the deidentified raw data. (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57760/sciencedb.psych.00125">https://doi.org/10.57760/sciencedb.psych.00125</ext-link>).</p></body></sub-article></article>