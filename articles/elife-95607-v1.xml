<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">95607</article-id><article-id pub-id-type="doi">10.7554/eLife.95607</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95607.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Generation of biophysical neuron model parameters from recorded electrophysiological responses</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kim</surname><given-names>Jimin</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5597-5142</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Peng</surname><given-names>Minxian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0419-3543</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Shuqi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0003-9744-6964</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Liu</surname><given-names>Qiang</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9232-1420</contrib-id><email>qiangliuemail@gmail.com</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Shlizerman</surname><given-names>Eli</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3136-4531</contrib-id><email>shlizee@uw.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>Department of Electrical and Computer Engineering, University of Washington</institution></institution-wrap><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03q8dnn23</institution-id><institution>Department of Neuroscience, City University of Hong Kong</institution></institution-wrap><addr-line><named-content content-type="city">Hong Kong</named-content></addr-line><country>Hong Kong</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>Department of Applied Mathematics, University of Washington</institution></institution-wrap><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03gf8rp76</institution-id><institution>National Centre for Biological Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Bengaluru</named-content></addr-line><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution></institution-wrap><addr-line><named-content content-type="city">Heraklion</named-content></addr-line><country>Greece</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>24</day><month>11</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP95607</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-01-29"><day>29</day><month>01</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-12-20"><day>20</day><month>12</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.12.19.572452"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-06-13"><day>13</day><month>06</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95607.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-02-13"><day>13</day><month>02</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95607.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-08-21"><day>21</day><month>08</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95607.3"/></event></pub-history><permissions><copyright-statement>© 2024, Kim et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Kim et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-95607-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-95607-figures-v1.pdf"/><abstract><p>Recent advances in connectomics, biophysics, and neuronal electrophysiology warrant modeling of neurons with further details in both network interaction and cellular dynamics. Such models may be referred to as ElectroPhysiome, as they incorporate the connectome and individual neuron electrophysiology to simulate neuronal activities. The nervous system of <italic>Caenorhabditis elegans</italic> is considered a viable framework for such ElectroPhysiome studies due to advances in connectomics of its somatic nervous system and electrophysiological recordings of neuron responses. In order to achieve a simulated ElectroPhysiome, the set of parameters involved in modeling individual neurons needs to be estimated from electrophysiological recordings. Here, we address this challenge by developing a deep generative estimation method called ElectroPhysiomeGAN (EP-GAN), which, once trained, can instantly generate parameters associated with the Hodgkin–Huxley neuron model (HH-model) for multiple neurons with graded potential response. The method combines generative adversarial network (GAN) architecture with recurrent neural network encoder and can generate an extensive number of parameters (&gt;170) given the neuron’s membrane potential responses and steady-state current profiles. We validate our method by estimating HH-model parameters for 200 simulated neurons with graded membrane potential followed by nine experimentally recorded neurons (where six of them are newly recorded) in the nervous system of <italic>C. elegans</italic>. Comparison of EP-GAN with existing estimation methods shows EP-GAN's advantage in the accuracy of estimated parameters and inference speed for both small and large numbers of parameters being inferred. In addition, the architecture of EP-GAN permits input with arbitrary clamping protocols, allowing inference of parameters even when partial membrane potential and steady-state currents profiles are given as inputs. EP-GAN is designed to leverage the generative capability of GAN to align with the dynamical structure of the HH-model and thus is able to achieve such performance.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neuron electrophysiology</kwd><kwd>parameter inference</kwd><kwd>Hodgkin–Huxley model</kwd><kwd>deep generative models</kwd><kwd>in silico nervous system</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>C. elegans</italic></kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/021nxhr62</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>CRCNS IIS-2113003</award-id><principal-award-recipient><name><surname>Kim</surname><given-names>Jimin</given-names></name><name><surname>Shlizerman</surname><given-names>Eli</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/021nxhr62</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>CRCNS IIS-2113120</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00kztt736</institution-id><institution>The Kavli Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03q8dnn23</institution-id><institution>City University of Hong Kong</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>CityU New Research Initiatives</institution></institution-wrap></funding-source><award-id>9610587</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00djwmt25</institution-id><institution>Hong Kong Research Grants Council RGC</institution></institution-wrap></funding-source><award-id>CityU 21103522</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00djwmt25</institution-id><institution>Hong Kong Research Grants Council RGC</institution></institution-wrap></funding-source><award-id>CityU 11104123</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00djwmt25</institution-id><institution>Hong Kong Research Grants Council RGC</institution></institution-wrap></funding-source><award-id>CityU 11100524</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01jdyfj45</institution-id><institution>NIH Office of Research Infrastructure Programs</institution></institution-wrap></funding-source><award-id>P40 OD010440</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Qiang</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A deep generative approach learns the translation from neurons’ electrophysiological recordings to the biophysical parameters of neuron models, assisting in the development of a detailed nervous system model.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Models of the nervous system aim to achieve biologically detailed simulations of large-scale neuronal activity through the incorporation of both structural connectomes (connectivity maps) and individual neural dynamics. The nervous system of <italic>Caenorhabditis elegans </italic>is considered a framework for such a model as the connectome of its somatic nervous system for multiple types of interaction is mapped (<xref ref-type="bibr" rid="bib64">White et al., 1986</xref>; <xref ref-type="bibr" rid="bib60">Varshney et al., 2011</xref>; <xref ref-type="bibr" rid="bib12">Cook et al., 2019</xref>). In addition to the connectome, advances in electrophysiological methodology allow the recording of whole-cell responses of individual neurons. These advances provide biophysically relevant details of individual neuro-dynamical properties and warrant a type of model for the <italic>C. elegans</italic> nervous system incorporating both the connectomes and individual biophysical processes of neurons. Such a model could be referred to as <italic>ElectroPhysiome</italic>, as it incorporates a layer of individual neural dynamics on top of the layer of inter-cellular interactions facilitated by the connectome.</p><p>The development of nervous system models that are further biophysically descriptive for each neuron, that is, modeling neurons using the Hodgkin–Huxley type equations (HH-model), requires fitting a large number of parameters associated with ion channels found in the system. For a typical single neuron, these parameters could be tuned via local optimizations of individual ion channel parameters estimated separately to fit their respective in vivo channel recordings such as activation/inactivation curves (<xref ref-type="bibr" rid="bib24">Hodgkin and Huxley, 1952</xref>; <xref ref-type="bibr" rid="bib66">Willms, 2002</xref>; <xref ref-type="bibr" rid="bib65">Willms et al., 1999</xref>; <xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>; <xref ref-type="bibr" rid="bib33">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Jiang et al., 2022</xref>). Such a method requires multiple experiments to collect each channel data, and when such experiments are infeasible, the parameters are often estimated through hand-tuning. In the context of developing the ElectroPhysiome of <italic>C. elegans</italic>, the method would have to model approximately 300 neurons each including an order of hundreds of parameters associated with up to 15 to 20 ionic current terms (with some of them having unknown ion channel composition), which would require large experimental studies (<xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>). Furthermore, the fitted model may not be the unique solution as different HH-parameters can produce similar neuron activity (<xref ref-type="bibr" rid="bib35">Marder and Goaillard, 2006</xref>; <xref ref-type="bibr" rid="bib36">Marder and Taylor, 2011</xref>; <xref ref-type="bibr" rid="bib47">Prinz et al., 2003</xref>; <xref ref-type="bibr" rid="bib48">Prinz et al., 2004</xref>). As these limitations also apply for general neuron modeling tasks beyond <italic>C. elegans</italic> neurons, there has been an increasing search for alternative fitting methods requiring less experimental data and manual interventions.</p><p>A promising direction in associating model parameters with neurons has been the simultaneous estimation of all parameters of an individual neuron given only electrophysiological responses of cells, such as membrane potential responses and steady-state current profiles. Such an approach requires significantly less experimental data per neuron and offers more flexibility with respect to trainable parameters. The primary aim of this approach is to model macroscopic cell behaviors in an automated fashion. Indeed, several methods adopting the approach have been introduced. <xref ref-type="bibr" rid="bib8">Buhry et al., 2012</xref> and <xref ref-type="bibr" rid="bib30">Laredo et al., 2022</xref> utilized the differential evolution (DE) method to simultaneously estimate the parameters of a 3-channel HH-model given the whole-cell membrane potential responses recording (<xref ref-type="bibr" rid="bib8">Buhry et al., 2012</xref>; <xref ref-type="bibr" rid="bib30">Laredo et al., 2022</xref>). <xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref> further developed the DE approach and introduced the multi-objective differential evolution (DEMO) method to estimate 22 HH-parameters of three non-spiking neurons in <italic>C. elegans</italic> given their whole-cell membrane potential responses and steady-state current profiles (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>). The study was a significant step toward modeling whole-cell behaviors of <italic>C. elegans</italic> neurons in a systematic manner. From a statistical standpoint, <xref ref-type="bibr" rid="bib63">Wang et al., 2022</xref> used the Markov Chain–Monte Carlo method to obtain the posterior distribution of channel parameters for HH-models featuring three and eight ion channels (two and nine parameters, respectively) given the simulated membrane potential responses data (<xref ref-type="bibr" rid="bib63">Wang et al., 2022</xref>). From an analytic standpoint, Valle et al. 2022 suggested an iterative gradient descent-based method that directly manipulates the HH-model to infer three conductance parameters and three exponents of activation functions given the measurements of membrane potential responses (<xref ref-type="bibr" rid="bib58">Valle and Madureira, 2022</xref>). Recent advances in machine learning gave rise to deep learning-based methods which infer steady-state activation functions and posterior distributions of three-channel HH-model parameters inferred by an artificial neural network model given the membrane potential responses data (<xref ref-type="bibr" rid="bib17">Gonçalves et al., 2020</xref>; <xref ref-type="bibr" rid="bib16">Estienne, 2021</xref>).</p><p>While these methods suggest that simultaneous parameter estimation from macroscopic cell data is indeed possible through a variety of techniques, it is largely unclear whether they can be extended to fit more detailed HH-models featuring a large number of channels and parameters (e.g., <italic>C. elegans</italic> neurons) (<xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>). Furthermore, for most of the above methods, the algorithms require an independent (from scratch) optimization process for fitting each individual neuron, making it difficult to scale up the task toward a large number of neurons.</p><p>Here, we propose a new machine learning approach that aims to address these aspects for the class of non-spiking neurons, which constitute the majority of neurons in <italic>C. elegans</italic> nervous system (<xref ref-type="bibr" rid="bib19">Goodman et al., 1998</xref>). Specifically, we develop a deep generative neural network model (GAN) combined with a recurrent neural network (RNN) Encoder called ElectroPhysiomeGAN (EP-GAN), which directly maps electrophysiological recordings of a neuron, for example, membrane potential responses and steady-state current profiles, to HH-model parameters of arbitrary dimensions (<xref ref-type="fig" rid="fig1">Figure 1</xref>). EP-GAN can be trained with simulation data informed by a generic HH-model encompassing a large set of arbitrary ionic current terms and thus can generalize its modeling capability to multiple neurons. Unlike typical GAN architecture trained solely with adversarial losses, we propose to implement an additional regression loss for reconstructing the given membrane potential responses and current profiles from generated parameters, thus improving the accuracy of the generative model. In addition, due to the RNN component of EP-GAN, the approach supports input data with missing features such as incomplete membrane potential responses and current profiles.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Estimation of HH-model parameters from membrane potential and steady-state current profiles.</title><p>Given the membrane potential responses (V) and steady-state current profiles (IV) of a neuron, the task is to predict biophysical parameters of the Hodgkin–Huxley-type neuron model (left). We use the Encoder-Generator approach to predict the parameters (right).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig1-v1.tif"/></fig><p>We validate our method to estimate HH-model parameters of 200 simulated non-spiking neurons followed by applying it to three previously recorded non-spiking neurons of <italic>C. elegans</italic>, namely RIM, AFD, and AIY. Studies have shown that membrane potential responses of these neurons can be well modeled with typical HH-model formulations with 22 parameters (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>; <xref ref-type="bibr" rid="bib37">Naudin et al., 2021</xref>). We show that when trained with a more detailed HH-model consisting of 16 ionic current terms resulting in 175 trainable parameters, EP-GAN can predict parameters reproducing their membrane potential responses with higher accuracy in the reconstruction of membrane potential with significantly faster inference speed than existing algorithms such as differential evolution and genetic algorithms. Through ablation studies on input data, we show that EP-GAN retains its prediction capability when provided with incomplete membrane potential responses and steady-state current profiles. We also perform ablation studies on EP-GAN architecture components to elucidate each component’s contributions toward the accuracy of the predicted parameters. To further test EP-GAN, we estimate HH-model parameters for six newly recorded non-spiking <italic>C. elegans</italic> neurons: AWB, AWC, URX, RIS, DVC, and HSN, whose membrane potential responses were not previously modeled.</p><p>Our results suggest that EP-GAN can learn a translation from electrophysiologically recorded responses and propose projections of them to parameter space. EP-GAN method is currently limited to non-spiking neurons in <italic>C. elegans</italic> as it was designed and trained with the HH-model describing the ion channels of these neurons. EP-GAN applications can potentially be extended toward resolving neuron parameters in other organisms since non-spiking neurons are found within animals across different species (<xref ref-type="bibr" rid="bib28">Koch et al., 2006</xref>; <xref ref-type="bibr" rid="bib52">Roberts and Bush, 1981</xref>; <xref ref-type="bibr" rid="bib13">Davis and Stretton, 1989a</xref>; <xref ref-type="bibr" rid="bib14">Davis and Stretton, 1989b</xref>; <xref ref-type="bibr" rid="bib9">Burrows et al., 1988</xref>; <xref ref-type="bibr" rid="bib31">Laurent and Burrows, 1989a</xref>; <xref ref-type="bibr" rid="bib32">Laurent and Burrows, 1989b</xref>; <xref ref-type="bibr" rid="bib38">Naudin, 2022a</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We evaluate EP-GAN with respect to four existing evolutionary algorithms introduced for general parameter estimation: NSGA2, DEMO, GDE3, and NSDE. Specifically, NSGA2 is a variant of the Genetic Algorithm (GA) that uses a non-dominated sorting survival strategy and is a commonly used benchmark algorithm for multi-objective optimization problems that include HH-model fitting (<xref ref-type="bibr" rid="bib15">Deb et al., 2000</xref>; <xref ref-type="bibr" rid="bib22">Hay et al., 2011</xref>; <xref ref-type="bibr" rid="bib59">van Geit et al., 2008</xref>). DEMO, GDE3, and NSDE are variants of Differential Evolution (DE) algorithms that combine DE mutation with Pareto-based ranking and crowding distance sorting applied in NSGA2’s survival strategy (<xref ref-type="bibr" rid="bib53">Robič and Filipič, 2005</xref>; <xref ref-type="bibr" rid="bib29">Kukkonen and Lampinen, 2005</xref>; <xref ref-type="bibr" rid="bib1">Angira and Babu, 2005</xref>). These methods have been proposed as more effective methods than direct DE for the estimation of HH-model parameters (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>; <xref ref-type="bibr" rid="bib54">Rumbell et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Octeau et al., 2019</xref>; <xref ref-type="bibr" rid="bib7">Buhry et al., 2009</xref>). In particular, DEMO has been successfully applied to estimate HH-model parameters for non-spiking neurons in <italic>C. elegans</italic> (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>). All four methods support multi-objective optimization over the large parameter space, allowing them to have similar setups as EP-GAN. All four methods were implemented in Python where DEMO uses the algorithm proposed in <xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref> whereas NSGA2, GDE3, and NSDE were implemented using Pymoo package (<xref ref-type="bibr" rid="bib4">Blank and Deb, 2020</xref>).</p><p>For the HH-model to be estimated, we use the formulation introduced in <xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref>. The model features 16 ion channels that were found in <italic>C. elegans</italic> and other organisms expressing homologous channels and is considered the most detailed neuron model for the organism (see ‘Ionic currents modeling’ for the mathematical description of channels). The model has a total of 203 parameters, of which we identify 175 of them have the approximate ranges with lower and upper bounds that can be inferred from the literature (<xref ref-type="bibr" rid="bib33">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Naudin et al., 2021</xref>; <xref ref-type="bibr" rid="bib25">Izhikevich, 2007</xref>). We thus target these 175 parameters as trainable parameters for all methods. For a detailed list of all 203 parameters included in the HH-model and 175 parameters used for training, see <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref> and the included table <italic>predicted parameters</italic> in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>.</p><sec id="s2-1"><title>Predictions on simulated neurons</title><p>We first validate EP-GAN by training and testing using simulated neurons. Each simulated neuron training sample consists of two inputs: (i) simulated membrane potential traces concatenated with associated external stimuli traces and (ii) steady-state currents across 18 voltage points. For each neuron, the output is the set of 175 HH-parameters to be inferred. Each membrane potential trace is simulated for 15 s for a given stimulus according to the current-clamp protocol where the stimulation is applied for 5 s at [5, 10] s and no stimulation is applied at <inline-formula><alternatives><mml:math id="inf1"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}${t = [0,5)}$\end{document}</tex-math></alternatives></inline-formula> (pre-activation) and <inline-formula><alternatives><mml:math id="inf2"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>15</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}${t = (10,15]}$\end{document}</tex-math></alternatives></inline-formula> (post-activation). These time intervals are chosen to ensure sufficient stabilization periods before and after stimulation. For the membrane potential input, the responses during <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>11</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}${t = [4, 11]}$\end{document}</tex-math></alternatives></inline-formula> interval are used consistent with the time interval used by experimental recordings. Similarly, steady-state currents are computed across 18 voltage states according to voltage-clamp protocol (see Table 4 for detailed current/voltage clamp protocols used for simulated neurons). The output HH-parameters are of the simulated neurons chosen randomly from lower and upper bounds as previously described. For training EP-GAN, we simulate a total of 32,000 (32k) neurons where EP-GAN achieves both good predictive performance and training time. Specifically, 32k is a training data size in which membrane potential errors from the test set (<inline-formula><alternatives><mml:math id="inf4"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}${N = 200}$\end{document}</tex-math></alternatives></inline-formula>) are within the average root mean square error (RMSE) recording error (4.8 mV, averaged over pre-, mid-, post-activation periods) obtained from experimental neurons with multiple membrane potential recording data. For more details on generating simulated neuron training samples, see ‘Generating training data’.</p><p>To initially test EP-GAN performance, we evaluate EP-GAN predicted parameters for 200 simulated neurons outside of the training set (test set). To emulate <italic>C. elegans</italic>’ neuronal diversity, neurons in the test set are divided into three response types: (i) transient outward rectifier type, (ii) outward rectifier type, and (iii) bistable type – that are currently found in non-spiking neurons of <italic>C. elegans</italic> according to their steady-state responses (<xref ref-type="fig" rid="fig2">Figure 2</xref>; <xref ref-type="bibr" rid="bib33">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>). For a given neuron being evaluated, EP-GAN predicted HH-parameters are obtained as follows: for each training epoch, EP-GAN generates a set of HH-parameters for the neuron and at the end of the training, the parameter set which achieved the lowest RMSE of membrane potential responses averaged across three time intervals – pre-activation [4, 5) s, mid-activation [5, 10] s, and post-activation (10, 11] s – with respect to ground truths is reported (detailed descriptions of its calculation provided in Appendix 1 andFigure 5A). In the case of multiple <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}${N}$\end{document}</tex-math></alternatives></inline-formula>-neurons being evaluated, the same procedure is followed except EP-GAN generates <inline-formula><alternatives><mml:math id="inf6"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft6">\begin{document}${N}$\end{document}</tex-math></alternatives></inline-formula>-parameter sets in parallel at each epoch. Such multi-neuron inference is possible due to EP-GAN being a neural network, where parallel processing of inputs can be done with minimal impact on inference speed. Using these procedures, EP-GAN predicted HH-parameters result in mean membrane potential RMSE error of 2.37 mV for the test set (see <xref ref-type="fig" rid="fig2">Figure 2</xref> for representative samples and <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref> for the detailed breakdown of the errors). These errors are within the mean recording RMSE error of 4.8 mV obtained from experimental neurons, and their distributions were skewed unimodal type, where the majority of the errors fall within 4 mV (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>ElectroPhysiomeGAN (EP-GAN) (32k) predictions on simulated neurons.</title><p>(<bold>A</bold>) EP-GAN predicted membrane potential traces and steady-state currents (red) overlaid on top of groundtruth counterparts (black) for transient outward rectifier neuron type. (<bold>B</bold>) Outward rectifier neuron type. (<bold>C</bold>) Bistable neuron type.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Root mean square error (RMSE) error distribution (averaged over pre-, mid-, post-activation time periods) for the simulated neurons (<inline-formula><alternatives><mml:math id="inf7"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}${n = 200}$\end{document}</tex-math></alternatives></inline-formula>) in test set.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig2-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Predictions on experimental neurons</title><p>We apply EP-GAN trained and tested on simulated data to predict HH-parameters for nine experimentally recorded non-spiking neurons found in <italic>C. elegans</italic>: RIM, AFD, AIY, AWB, AWC, URX, RIS, DVC, and HSN. Among these neurons, AWB, AWC, URX, RIS, DVC, and HSN are novel recording data and were not previously modeled, whereas RIM, AIY, and AFD neurons are publicly available and their modeling descriptions were elaborated by previous works (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>; <xref ref-type="bibr" rid="bib37">Naudin et al., 2021</xref>; <xref ref-type="bibr" rid="bib40">Naudin et al., 2022c</xref>). Similar to the prediction scenario on simulated neurons, we categorize experimental neurons into different response types according to their steady-state current responses. In particular, we classify (RIM, DVC, HSN) as transient outward rectifier type, (AIY, URX, RIS) as outward rectifier type, and (AFD, AWB, AWC) as bistable type. For all experimental neurons, simulation protocols outlined in Table 4 are used to generate membrane potential and steady-state responses of predicted parameters.</p><p>We compare the performance of EP-GAN with four existing parameter inference methods: NSGA2, DEMO, GDE3, and NSDE. Unlike EP-GAN, which can optimize multiple neurons in parallel, these are evolutionary methods where the optimization is done <bold>from scratch</bold> for each neuron. We therefore evaluate their respective performances relative to EP-GAN by normalizing the <italic>total number of simulated neuron samples</italic> during the entire optimization task. Specifically, for all methods, we set the maximum number of neuron samples used during optimization to equal sizes. For example if EP-GAN is trained with 32k neuron samples to predict nine neurons, NSGA2, DEMO, GDE3, and NSDE are each allocated up to 3.5k samples during the search phase of HH-parameters for each neuron, thus adding up to a total of 32k samples for all nine neurons. To test how the performance of each method scales with the amount of samples during optimization, we evaluate each method with both 32k and 64k total neuron samples.</p><p>The parameter selection process for NSGA2, DEMO, GDE3, and NSDE is as follows: during the search phase for each neuron, the parameter set candidates (i.e., population) are recorded at each iteration. At the end of the search phase, the steady-state current profile of each parameter set candidate is evaluated with respect to the experimentally known bifurcation structure (i.e., <inline-formula><alternatives><mml:math id="inf8"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft8">\begin{document}${dI/dV}$\end{document}</tex-math></alternatives></inline-formula>) of the neuron being inferred (e.g., bistable type). Upon evaluation, only the parameter sets satisfying the <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}${dI/dV}$\end{document}</tex-math></alternatives></inline-formula> bound constraints (<inline-formula><alternatives><mml:math id="inf10"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>98</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft10">\begin{document}${\sim 98\%}$\end{document}</tex-math></alternatives></inline-formula> confidence interval) are kept. Such an initial selection process is similar to the ones employed by previous methods utilizing evolutionary algorithms (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>). The <inline-formula><alternatives><mml:math id="inf11"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft11">\begin{document}${dI/dV}$\end{document}</tex-math></alternatives></inline-formula> bound constraints are also used for generating EP-GAN training data (see ‘Generating training data’ for more detail). The final parameter set is then chosen by selecting the one with the lowest RMSE membrane potential responses error averaged across pre-, mid-, and post-activation periods identical to that of the EP-GAN parameter selection process. For DE methods (DEMO, GDE3, and NSDE), we follow the same configurations used in the literature to set their optimization scheme (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>). Specifically, we set the crossover parameter CR and scale factor F to 0.3 and 1.5, respectively. For all four methods, NP (population size) is set to 600 with a total of 6 and 12 iterations (i.e., <inline-formula><alternatives><mml:math id="inf12"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>3.6</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft12">\begin{document}${\sim 3.6k}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>6.2</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}${\sim 6.2k}$\end{document}</tex-math></alternatives></inline-formula> samples per neuron for 32k and 64k total neuron samples, respectively). For all methods, loss functions identical to the ones used for EP-GAN training (mean absolute errors, see ‘Materials and methods’ for detail) are used to calculate the errors for membrane potential responses and steady-state currents for multi-objective optimization.</p><sec id="s2-2-1"><title>Small HH-model scenarios (47 parameters)</title><p>We first test EP-GAN and existing methods with a ‘smaller’ version of the HH-model of 47 parameters where the individual channel parameters (<inline-formula><alternatives><mml:math id="inf14"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>129</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft14">\begin{document}${n = 129}$\end{document}</tex-math></alternatives></inline-formula>) are frozen to default values given by <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref>. The considered parameters consist of 16 conductance parameters of each channel (<inline-formula><alternatives><mml:math id="inf15"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft15">\begin{document}${g_{Ch}}$\end{document}</tex-math></alternatives></inline-formula>), 4 reversal potentials for calcium, potassium, sodium, and leak channels (<inline-formula><alternatives><mml:math id="inf16"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft16">\begin{document}${V_{Ca}, V_K, V_{Na}, V_{L}}$\end{document}</tex-math></alternatives></inline-formula>), 1 cell capacitance <inline-formula><alternatives><mml:math id="inf17"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft17">\begin{document}${C}$\end{document}</tex-math></alternatives></inline-formula>, and 26 initial conditions for membrane potential <inline-formula><alternatives><mml:math id="inf18"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft18">\begin{document}${V_0}$\end{document}</tex-math></alternatives></inline-formula> and channel activation variables (<inline-formula><alternatives><mml:math id="inf19"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}${m_0, h_0}$\end{document}</tex-math></alternatives></inline-formula>). Such a parameter set is commonly targeted when fitting HH-models for individual neurons (<xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref>). For all methods, we test both 32k and 64k total sample sizes for the inference of nine experimental neurons. <xref ref-type="fig" rid="fig3">Figure 3</xref> illustrates that EP-GAN can reconstruct membrane potential responses close to ground truth responses. Indeed, upon inspecting the RMSE error for membrane potential responses (averaged over pre-, mid-, and post-activation), EP-GAN (32k) median error of 2.5 mV over nine neurons is <inline-formula><alternatives><mml:math id="inf20"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>50</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}${\sim 50\%}$\end{document}</tex-math></alternatives></inline-formula> lower than that of NSGA2 (64k) 4.3 mV followed by DEMO (64k) 4.8 mV, NSDE (64k) 5.5 mV, and GDE3 (64k) 6.0 mV (<xref ref-type="table" rid="table1">Table 1</xref>, <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref>, Figure 5B).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>ElectroPhysiomeGAN (EP-GAN) (32k) prediction on experimental neurons (small HH-model).</title><p>(<bold>A</bold>) EP-GAN predicted membrane potential traces and steady-state currents (red) overlaid on top of groundtruth counterparts (black) for transient outward rectifier neuron type (RIM, DVC, HSN). (<bold>B</bold>) Outward rectifier neuron type (AIY, URX, RIS). (<bold>C</bold>) Bistable neuron type (AFD, AWB, AWC).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Small HH-model GDE3, NSDE, DEMO, NSGA2 predictions (sample size = 32k) on experimental neurons.</title><p>(<bold>A</bold>) Predicted membrane potential traces (red) overlaid on top of ground truth (black) for all nine experimental neurons. (<bold>B</bold>) Predicted steady-state current traces (red) overlaid on top of ground truth (black) for all nine experimental neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig3-figsupp1-v1.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Small HH-model scenarios root mean square error (RMSE) errors for predicted membrane potential responses and steady-state currents.</title><p>Each method is tested with 32k or 64k total sample sizes, where the top row shows membrane potential responses RMSE errors averaged across pre-activation, mid-activation, post-activation periods, and the bottom row shows steady-state currents RMSE errors across 18 voltage values. The lowest membrane potential responses RMSE error is marked bold for each neuron.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Method</th><th align="left" valign="bottom">Sample size</th><th align="left" valign="bottom">Median error</th><th align="left" valign="bottom">RIM</th><th align="left" valign="bottom">DVC</th><th align="left" valign="bottom">HSN</th><th align="left" valign="bottom">AIY</th><th align="left" valign="bottom">URX</th><th align="left" valign="bottom">RIS</th><th align="left" valign="bottom">AFD</th><th align="left" valign="bottom">AWB</th><th align="left" valign="bottom">AWC</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="4">GDE3</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">16.9 mV</td><td align="left" valign="bottom">20.9</td><td align="left" valign="bottom">58.1</td><td align="left" valign="bottom">8.9</td><td align="left" valign="bottom">13.0</td><td align="left" valign="bottom">16.9</td><td align="left" valign="bottom">25.4</td><td align="left" valign="bottom">6.3</td><td align="left" valign="bottom">32.5</td><td align="left" valign="bottom">4.7</td></tr><tr><td align="left" valign="bottom">5.9 pA</td><td align="left" valign="bottom">5.8</td><td align="left" valign="bottom">5.8</td><td align="left" valign="bottom">19.8</td><td align="left" valign="bottom">4.8</td><td align="left" valign="bottom">2.4</td><td align="left" valign="bottom">5.9</td><td align="left" valign="bottom">19.1</td><td align="left" valign="bottom">7.2</td><td align="left" valign="bottom">11.9</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">6.0 mV</td><td align="left" valign="bottom">11.5</td><td align="left" valign="bottom">24.1</td><td align="left" valign="bottom">13.7</td><td align="left" valign="bottom">6.0</td><td align="left" valign="bottom">5.1</td><td align="left" valign="bottom">7.1</td><td align="left" valign="bottom">4.1</td><td align="left" valign="bottom">5.6</td><td align="left" valign="bottom">3.6</td></tr><tr><td align="left" valign="bottom">7.9 pA</td><td align="left" valign="bottom">7.5</td><td align="left" valign="bottom">4.6</td><td align="left" valign="bottom">6.8</td><td align="left" valign="bottom">7.2</td><td align="left" valign="bottom">18.7</td><td align="left" valign="bottom">7.9</td><td align="left" valign="bottom">42.1</td><td align="left" valign="bottom">17.6</td><td align="left" valign="bottom">46.7</td></tr><tr><td align="left" valign="bottom" rowspan="4">NSDE</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">7.1 mV</td><td align="left" valign="bottom">38.7</td><td align="left" valign="bottom">8.3</td><td align="left" valign="bottom">20.2</td><td align="left" valign="bottom">5.7</td><td align="left" valign="bottom">7.1</td><td align="left" valign="bottom">11.0</td><td align="left" valign="bottom">5.5</td><td align="left" valign="bottom">6.3</td><td align="left" valign="bottom">6.6</td></tr><tr><td align="left" valign="bottom">13.6 pA</td><td align="left" valign="bottom">3.1</td><td align="left" valign="bottom">21.5</td><td align="left" valign="bottom">9.7</td><td align="left" valign="bottom">13.6</td><td align="left" valign="bottom">14.2</td><td align="left" valign="bottom">5.7</td><td align="left" valign="bottom">24.7</td><td align="left" valign="bottom">9.6</td><td align="left" valign="bottom">14.5</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">5.5 mV</td><td align="left" valign="bottom">15.4</td><td align="left" valign="bottom">8.7</td><td align="left" valign="bottom">20.2</td><td align="left" valign="bottom">13.5</td><td align="left" valign="bottom">5.2</td><td align="left" valign="bottom">5.5</td><td align="left" valign="bottom">4.9</td><td align="left" valign="bottom">4.9</td><td align="left" valign="bottom">4.0</td></tr><tr><td align="left" valign="bottom">9.7 pA</td><td align="left" valign="bottom">2.6</td><td align="left" valign="bottom">5.9</td><td align="left" valign="bottom">9.7</td><td align="left" valign="bottom">3.4</td><td align="left" valign="bottom">11.7</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">64.4</td><td align="left" valign="bottom">12.4</td><td align="left" valign="bottom">19.0</td></tr><tr><td align="left" valign="bottom" rowspan="4">DEMO</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">6.7 mV</td><td align="left" valign="bottom">35.9</td><td align="left" valign="bottom">14.1</td><td align="left" valign="bottom">5.8</td><td align="left" valign="bottom">13.2</td><td align="left" valign="bottom">9.0</td><td align="left" valign="bottom">6.7</td><td align="left" valign="bottom">5.0</td><td align="left" valign="bottom">4.9</td><td align="left" valign="bottom">3.8</td></tr><tr><td align="left" valign="bottom">11.5 pA</td><td align="left" valign="bottom">6.5</td><td align="left" valign="bottom">13.8</td><td align="left" valign="bottom">14.6</td><td align="left" valign="bottom">5.2</td><td align="left" valign="bottom">5.4</td><td align="left" valign="bottom">9.7</td><td align="left" valign="bottom">23.8</td><td align="left" valign="bottom">11.5</td><td align="left" valign="bottom">18.7</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">4.8 mV</td><td align="left" valign="bottom">12.3</td><td align="left" valign="bottom">10.5</td><td align="left" valign="bottom">5.8</td><td align="left" valign="bottom">10.2</td><td align="left" valign="bottom">4.8</td><td align="left" valign="bottom">4.7</td><td align="left" valign="bottom"><bold>3.1</bold></td><td align="left" valign="bottom">4.4</td><td align="left" valign="bottom">2.9</td></tr><tr><td align="left" valign="bottom">14.6 pA</td><td align="left" valign="bottom">4.4</td><td align="left" valign="bottom">6.5</td><td align="left" valign="bottom">14.6</td><td align="left" valign="bottom">4.1</td><td align="left" valign="bottom">15.2</td><td align="left" valign="bottom">10.3</td><td align="left" valign="bottom">41.0</td><td align="left" valign="bottom">23.1</td><td align="left" valign="bottom">17.8</td></tr><tr><td align="left" valign="bottom" rowspan="4">NSGA2</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">7.5 mV</td><td align="left" valign="bottom">12.4</td><td align="left" valign="bottom">15.4</td><td align="left" valign="bottom">2.6</td><td align="left" valign="bottom">9.8</td><td align="left" valign="bottom">6.1</td><td align="left" valign="bottom">6.4</td><td align="left" valign="bottom">7.5</td><td align="left" valign="bottom">9.4</td><td align="left" valign="bottom">6.6</td></tr><tr><td align="left" valign="bottom">10 pA</td><td align="left" valign="bottom">4.0</td><td align="left" valign="bottom">7.4</td><td align="left" valign="bottom">14.3</td><td align="left" valign="bottom">4.6</td><td align="left" valign="bottom">16.6</td><td align="left" valign="bottom">5.0</td><td align="left" valign="bottom">14.4</td><td align="left" valign="bottom">11.9</td><td align="left" valign="bottom">10.0</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">4.3 mV</td><td align="left" valign="bottom">10.5</td><td align="left" valign="bottom">19.0</td><td align="left" valign="bottom">5.2</td><td align="left" valign="bottom">13.3</td><td align="left" valign="bottom">3.5</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">4.2</td><td align="left" valign="bottom">4.3</td><td align="left" valign="bottom">3.1</td></tr><tr><td align="left" valign="bottom">8.4 pA</td><td align="left" valign="bottom">8.4</td><td align="left" valign="bottom">1.8</td><td align="left" valign="bottom">5.2</td><td align="left" valign="bottom">2.3</td><td align="left" valign="bottom">21.2</td><td align="left" valign="bottom">6.5</td><td align="left" valign="bottom">26.6</td><td align="left" valign="bottom">12.6</td><td align="left" valign="bottom">49.4</td></tr><tr><td align="left" valign="bottom" rowspan="4"><bold>EP-GAN</bold><break/><bold>(ours)</bold></td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">2.5 mV</td><td align="left" valign="bottom">3.4</td><td align="left" valign="bottom">2.4</td><td align="left" valign="bottom">1.6</td><td align="left" valign="bottom">2.5</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">1.7</td><td align="left" valign="bottom">4.9</td><td align="left" valign="bottom">2.5</td><td align="left" valign="bottom"><bold>2.0</bold></td></tr><tr><td align="left" valign="bottom">13.8 pA</td><td align="left" valign="bottom">4.0</td><td align="left" valign="bottom">13.8</td><td align="left" valign="bottom">10.3</td><td align="left" valign="bottom">10.7</td><td align="left" valign="bottom">38.9</td><td align="left" valign="bottom">16.8</td><td align="left" valign="bottom">48.0</td><td align="left" valign="bottom">9.6</td><td align="left" valign="bottom">28.9</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom"><bold>2.4 mV</bold></td><td align="left" valign="bottom"><bold>3.4</bold></td><td align="left" valign="bottom"><bold>2.4</bold></td><td align="left" valign="bottom"><bold>1.6</bold></td><td align="left" valign="bottom"><bold>2.4</bold></td><td align="left" valign="bottom"><bold>2.9</bold></td><td align="left" valign="bottom"><bold>1.4</bold></td><td align="left" valign="bottom">3.4</td><td align="left" valign="bottom"><bold>2.5</bold></td><td align="left" valign="bottom">2.1</td></tr><tr><td align="left" valign="bottom">13.1 pA</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">13.9</td><td align="left" valign="bottom">2.5</td><td align="left" valign="bottom">9.8</td><td align="left" valign="bottom">16.5</td><td align="left" valign="bottom">13.1</td><td align="left" valign="bottom">49.7</td><td align="left" valign="bottom">11.6</td><td align="left" valign="bottom">27.9</td></tr></tbody></table></table-wrap><p>Among all nine neurons being inferred, EP-GAN (32k) showed the best accuracy for HSN with 1.6 mV and the lowest accuracy for AFD with 4.9 mV. With EP-GAN (64k), the median error further decreased (<inline-formula><alternatives><mml:math id="inf21"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>2.5</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>2.4</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft21">\begin{document}${2.5 {\rm mV} \rightarrow 2.4 {\rm mV}}$\end{document}</tex-math></alternatives></inline-formula>), where URX and RIS errors improved by 0.3 mV and AFD error improved by 1.5 mV over their 32k counterparts. Interestingly, we note that the high accuracy of EP-GAN in predicting membrane potential is not necessarily complemented with steady-state currents (<xref ref-type="table" rid="table1">Table 1</xref>, Figure 5B). EP-GAN’s overall steady-state current errors are generally higher than those of existing methods. A possible reason could be that the majority of these errors stem from lower and upper voltage ranges where the recording variations are high, thus potentially causing a conflict with membrane potential responses optimization. Such a competitive nature between membrane potential vs. steady-state current optimizations has indeed been reported in previous works (<xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>).</p></sec><sec id="s2-2-2"><title>Large HH-model scenarios (175 parameters)</title><p>We expand the domain of parameters being inferred by testing with respect to all 175 HH-model’s trainable parameters including the 47 parameters from the previous scenario + 129 channel parameters. The inclusion of channel parameters allows methods to further fine-tune the HH-model. The minimum and maximum values for channel parameters are set to ±50% from their default values (see ‘Generating training data’ for more detail). Such a task introduces further challenges as the methods need to estimate ×3 more parameters compared to the small HH-model scenario. From <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig5">5B</xref>, <xref ref-type="table" rid="table2">Table 2</xref>, and <xref ref-type="table" rid="app1table3">Appendix 1—table 3</xref>, we see that while EP-GAN (32k) median membrane potential error increases slightly from 2.5 mV to 2.7 mV, its performance gaps over existing methods widen with <inline-formula><alternatives><mml:math id="inf22"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>∼</mml:mo><mml:mn>60</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft22">\begin{document}${\sim 60\%}$\end{document}</tex-math></alternatives></inline-formula> lower error than NSGA2 (64k) 7.5 mV, followed by NSDE (64k) 8.6 mV and DEMO (64k), GDE3 (64k) 10.5 mV. EP-GAN trained for large HH-model also slightly improved overall steady-state current error (<inline-formula><alternatives><mml:math id="inf23"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>13.8</mml:mn><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>12.4</mml:mn><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft23">\begin{document}${13.8{\rm pA} \rightarrow 12.4{\rm pA}}$\end{document}</tex-math></alternatives></inline-formula>) alongside membrane potential errors for RIM (<inline-formula><alternatives><mml:math id="inf24"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>3.4</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>3.2</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft24">\begin{document}${3.4{\rm mV} \rightarrow 3.2{\rm mV}}$\end{document}</tex-math></alternatives></inline-formula>) and URX (<inline-formula><alternatives><mml:math id="inf25"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>3.2</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>3.0</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft25">\begin{document}${3.2{\rm mV} \rightarrow 3.0 {\rm mV}}$\end{document}</tex-math></alternatives></inline-formula>), indicating different selectivity for individual neurons for small vs. large HH-model. Further increasing the sample size to 64k improved median errors of both membrane potential (<inline-formula><alternatives><mml:math id="inf26"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>2.7</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>2.6</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft26">\begin{document}${2.7{\rm mV} \rightarrow 2.6{\rm mV}}$\end{document}</tex-math></alternatives></inline-formula>) and steady-states responses (<inline-formula><alternatives><mml:math id="inf27"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>12.4</mml:mn><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>8.6</mml:mn><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft27">\begin{document}${12.4{\rm pA} \rightarrow 8.6{\rm pA}}$\end{document}</tex-math></alternatives></inline-formula>). Taken together, these results show EP-GAN’s predicting capabilities for HH-parameters with higher membrane potential responses accuracy and its ability to generalize to a larger parameter space with minimal performance loss.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>ElectroPhysiomeGAN (EP-GAN) (32k) prediction on experimental neurons (large HH-model).</title><p>(<bold>A</bold>) EP-GAN predicted membrane potential traces and steady-state currents (red) overlaid on top of groundtruth counterparts (black) for transient outward rectifier neuron type (RIM, DVC, HSN). (<bold>B</bold>) Outward rectifier neuron type (AIY, URX, RIS). (<bold>C</bold>) Bistable neuron type (AFD, AWB, AWC).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Large HH-model GDE3, NSDE, DEMO, NSGA2 predictions (sample size = 32k) on experimental neurons.</title><p>(<bold>A</bold>) Predicted membrane potential traces (red) overlaid on top of ground truth (black) for all nine experimental neurons. (<bold>B</bold>) Predicted steady-state current traces (red) overlaid on top of ground truth (black) for all nine experimental neurons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig4-figsupp1-v1.tif"/></fig></fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Bar plot showing the average root mean square error (RMSE) errors for membrane potential responses (pre-, mid-, post-activation periods, mean error) and steady-state currents for nine experimental neurons.</title><p>(<bold>A</bold>) Membrane potential responses (left) and steady-state currents (right) diagrams showing the time and voltage intervals of which the RMSE errors are computed. (<bold>B</bold>) Bar plots showing RMSE errors (n = 9, 95% confidence level using t-test) for membrane potential responses and steady-state currents for small HH-model prediction scenarios (top) and large HH-model prediction scenarios (bottom). All methods use a 32k sample size for both scenarios.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig5-v1.tif"/></fig><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Large HH-model scenarios root mean square error (RMSE) errors for predicted membrane potential responses and steady-state currents.</title><p>Each method is tested with 32k or 64k total sample sizes, where the top row shows membrane potential responses RMSE errors averaged across pre-activation, mid-activation, post-activation periods, and the bottom row shows steady-state currents RMSE errors across 18 voltage values. The lowest membrane potential responses RMSE error is marked bold for each neuron.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Method</th><th align="left" valign="bottom">Sample size</th><th align="left" valign="bottom">Median error</th><th align="left" valign="bottom">RIM</th><th align="left" valign="bottom">DVC</th><th align="left" valign="bottom">HSN</th><th align="left" valign="bottom">AIY</th><th align="left" valign="bottom">URX</th><th align="left" valign="bottom">RIS</th><th align="left" valign="bottom">AFD</th><th align="left" valign="bottom">AWB</th><th align="left" valign="bottom">AWC</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="4">GDE3</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">12.8 mV</td><td align="left" valign="bottom">14.0</td><td align="left" valign="bottom">12.5</td><td align="left" valign="bottom">12.8</td><td align="left" valign="bottom">19.4</td><td align="left" valign="bottom">9.0</td><td align="left" valign="bottom">15.2</td><td align="left" valign="bottom">29.4</td><td align="left" valign="bottom">10.8</td><td align="left" valign="bottom">9.2</td></tr><tr><td align="left" valign="bottom">9.6 pA</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">23.5</td><td align="left" valign="bottom">12.8</td><td align="left" valign="bottom">10.2</td><td align="left" valign="bottom">6.3</td><td align="left" valign="bottom">6.0</td><td align="left" valign="bottom">7.9</td><td align="left" valign="bottom">18.1</td><td align="left" valign="bottom">9.6</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">10.5 mV</td><td align="left" valign="bottom">14.0</td><td align="left" valign="bottom">11.0</td><td align="left" valign="bottom">10.5</td><td align="left" valign="bottom">11.7</td><td align="left" valign="bottom">12.4</td><td align="left" valign="bottom">9.0</td><td align="left" valign="bottom">5.0</td><td align="left" valign="bottom">9.5</td><td align="left" valign="bottom">4.7</td></tr><tr><td align="left" valign="bottom">4.9 pA</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">6.5</td><td align="left" valign="bottom">7.4</td><td align="left" valign="bottom">3.8</td><td align="left" valign="bottom">4.8</td><td align="left" valign="bottom">4.0</td><td align="left" valign="bottom">16.9</td><td align="left" valign="bottom">14.8</td><td align="left" valign="bottom">4.9</td></tr><tr><td align="left" valign="bottom" rowspan="4">NSDE</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">16.1 mV</td><td align="left" valign="bottom">31.5</td><td align="left" valign="bottom">19.0</td><td align="left" valign="bottom">8.7</td><td align="left" valign="bottom">12.1</td><td align="left" valign="bottom">8.6</td><td align="left" valign="bottom">23.8</td><td align="left" valign="bottom">9.8</td><td align="left" valign="bottom">27.1</td><td align="left" valign="bottom">16.1</td></tr><tr><td align="left" valign="bottom">7.2 pA</td><td align="left" valign="bottom">7.8</td><td align="left" valign="bottom">8.0</td><td align="left" valign="bottom">9.6</td><td align="left" valign="bottom">6.8</td><td align="left" valign="bottom">5.1</td><td align="left" valign="bottom">4.2</td><td align="left" valign="bottom">18.2</td><td align="left" valign="bottom">7.2</td><td align="left" valign="bottom">6.2</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">8.6 mV</td><td align="left" valign="bottom">33.9</td><td align="left" valign="bottom">8.6</td><td align="left" valign="bottom">12.4</td><td align="left" valign="bottom">5.9</td><td align="left" valign="bottom">8.6</td><td align="left" valign="bottom">8.0</td><td align="left" valign="bottom">16.6</td><td align="left" valign="bottom">12.5</td><td align="left" valign="bottom">4.6</td></tr><tr><td align="left" valign="bottom">8.1 pA</td><td align="left" valign="bottom">4.0</td><td align="left" valign="bottom">29.6</td><td align="left" valign="bottom">8.1</td><td align="left" valign="bottom">4.7</td><td align="left" valign="bottom">5.1</td><td align="left" valign="bottom">4.3</td><td align="left" valign="bottom">9.1</td><td align="left" valign="bottom">15.0</td><td align="left" valign="bottom">14.9</td></tr><tr><td align="left" valign="bottom" rowspan="4">DEMO</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">16.6 mV</td><td align="left" valign="bottom">28.0</td><td align="left" valign="bottom">17.8</td><td align="left" valign="bottom">16.6</td><td align="left" valign="bottom">10.2</td><td align="left" valign="bottom">22.9</td><td align="left" valign="bottom">18.1</td><td align="left" valign="bottom">6.0</td><td align="left" valign="bottom">13.1</td><td align="left" valign="bottom">5.1</td></tr><tr><td align="left" valign="bottom">11.9 pA</td><td align="left" valign="bottom">7.6</td><td align="left" valign="bottom">11.9</td><td align="left" valign="bottom">21.4</td><td align="left" valign="bottom">7.2</td><td align="left" valign="bottom">11.1</td><td align="left" valign="bottom">6.8</td><td align="left" valign="bottom">18.2</td><td align="left" valign="bottom">11.9</td><td align="left" valign="bottom">30.9</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">10.5 mV</td><td align="left" valign="bottom">10.5</td><td align="left" valign="bottom">29.5</td><td align="left" valign="bottom">11.0</td><td align="left" valign="bottom">10.2</td><td align="left" valign="bottom">6.8</td><td align="left" valign="bottom">18.4</td><td align="left" valign="bottom">6.0</td><td align="left" valign="bottom">13.1</td><td align="left" valign="bottom">4.4</td></tr><tr><td align="left" valign="bottom">8.0 pA</td><td align="left" valign="bottom">7.4</td><td align="left" valign="bottom">2.6</td><td align="left" valign="bottom">21.3</td><td align="left" valign="bottom">7.2</td><td align="left" valign="bottom">8.0</td><td align="left" valign="bottom">7.0</td><td align="left" valign="bottom">51.1</td><td align="left" valign="bottom">11.9</td><td align="left" valign="bottom">9.8</td></tr><tr><td align="left" valign="bottom" rowspan="4">NSGA2</td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">13.4 mV</td><td align="left" valign="bottom">13.4</td><td align="left" valign="bottom">16.1</td><td align="left" valign="bottom">29.2</td><td align="left" valign="bottom">11.3</td><td align="left" valign="bottom">8.6</td><td align="left" valign="bottom">13.5</td><td align="left" valign="bottom">8.2</td><td align="left" valign="bottom">11.2</td><td align="left" valign="bottom">13.6</td></tr><tr><td align="left" valign="bottom">7.6 pA</td><td align="left" valign="bottom">6.6</td><td align="left" valign="bottom">7.6</td><td align="left" valign="bottom">5.8</td><td align="left" valign="bottom">8.7</td><td align="left" valign="bottom">5.1</td><td align="left" valign="bottom">2.7</td><td align="left" valign="bottom">24.1</td><td align="left" valign="bottom">10.9</td><td align="left" valign="bottom">7.6</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom">7.5 mV</td><td align="left" valign="bottom">10.6</td><td align="left" valign="bottom">16.0</td><td align="left" valign="bottom">22.5</td><td align="left" valign="bottom">7.5</td><td align="left" valign="bottom">4.6</td><td align="left" valign="bottom">13.4</td><td align="left" valign="bottom">5.4</td><td align="left" valign="bottom">6.9</td><td align="left" valign="bottom">6.6</td></tr><tr><td align="left" valign="bottom">4.9 pA</td><td align="left" valign="bottom">4.9</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">3.7</td><td align="left" valign="bottom">1.2</td><td align="left" valign="bottom">9.5</td><td align="left" valign="bottom">3.1</td><td align="left" valign="bottom">24.7</td><td align="left" valign="bottom">13.7</td><td align="left" valign="bottom">6.9</td></tr><tr><td align="left" valign="bottom" rowspan="4"><bold>EP-GAN</bold><break/><bold>(ours)</bold></td><td align="left" valign="bottom" rowspan="2">32k</td><td align="left" valign="bottom">2.7 mV</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom"><bold>2.5</bold></td><td align="left" valign="bottom">3.0</td><td align="left" valign="bottom">2.7</td><td align="left" valign="bottom"><bold>3.0</bold></td><td align="left" valign="bottom">1.8</td><td align="left" valign="bottom">4.5</td><td align="left" valign="bottom">2.6</td><td align="left" valign="bottom"><bold>2.1</bold></td></tr><tr><td align="left" valign="bottom">12.4 pA</td><td align="left" valign="bottom">3.2</td><td align="left" valign="bottom">12.4</td><td align="left" valign="bottom">17.4</td><td align="left" valign="bottom">10.5</td><td align="left" valign="bottom">36.6</td><td align="left" valign="bottom">21.9</td><td align="left" valign="bottom">43.2</td><td align="left" valign="bottom">9.3</td><td align="left" valign="bottom">8.4</td></tr><tr><td align="left" valign="bottom" rowspan="2">64k</td><td align="left" valign="bottom"><bold>2.6 mV</bold></td><td align="left" valign="bottom"><bold>3.2</bold></td><td align="left" valign="bottom">2.9</td><td align="left" valign="bottom"><bold>2.5</bold></td><td align="left" valign="bottom"><bold>2.6</bold></td><td align="left" valign="bottom">3.4</td><td align="left" valign="bottom"><bold>1.8</bold></td><td align="left" valign="bottom"><bold>4.4</bold></td><td align="left" valign="bottom"><bold>2.6</bold></td><td align="left" valign="bottom">2.2</td></tr><tr><td align="left" valign="bottom">8.6 pA</td><td align="left" valign="bottom">3.6</td><td align="left" valign="bottom">8.6</td><td align="left" valign="bottom">3.3</td><td align="left" valign="bottom">4.9</td><td align="left" valign="bottom">37.9</td><td align="left" valign="bottom">9.2</td><td align="left" valign="bottom">31.8</td><td align="left" valign="bottom">5.1</td><td align="left" valign="bottom">10.2</td></tr></tbody></table></table-wrap></sec></sec><sec id="s2-3"><title>Ablation studies</title><p>EP-GAN architecture also allows its membrane potential inputs to have arbitrary current-clamp protocol due to its RNN encoder component. To test the robustness of EP-GAN when incomplete input data is given, we provide the model with membrane potential responses and steady-state current inputs with missing data points. For each membrane potential responses and current profile, the data is reduced by 25%, 50%, and 75% each. For membrane potential responses data, the ablation is done on stimulus space where a 50% reduction corresponds to removing the upper half of the membrane potential response traces each associated with a stimulus. For the steady-state current profile, we remove the first <inline-formula><alternatives><mml:math id="inf28"><mml:mi>n</mml:mi></mml:math><tex-math id="inft28">\begin{document}${n}$\end{document}</tex-math></alternatives></inline-formula>-data points where they are instead extrapolated using linear interpolation with existing data points.</p><p>Our results show that EP-GAN largely preserves accuracy even when both membrane potential and steady-state current inputs are masked (<xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> [predicted steady-state currents], <xref ref-type="table" rid="table3">Table 3</xref>). In particular, EP-GAN preserves median membrane potential error (<inline-formula><alternatives><mml:math id="inf29"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>3.3</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft29">\begin{document}${3.3{\rm mV}}$\end{document}</tex-math></alternatives></inline-formula>) up to 50% remaining in its inputs but becomes less accurate when up to 25% input remains (<inline-formula><alternatives><mml:math id="inf30"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>3.3</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>5.4</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft30">\begin{document}${3.3{\rm mV} \rightarrow 5.4{\rm mV}}$\end{document}</tex-math></alternatives></inline-formula>). Surprisingly, AFD neuron membrane potential error is improved when only 50% of input data is considered (<inline-formula><alternatives><mml:math id="inf31"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>5.2</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo><mml:mn>4.5</mml:mn><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">V</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft31">\begin{document}${5.2{\rm mV} \rightarrow 4.5{\rm mV}}$\end{document}</tex-math></alternatives></inline-formula>). These results could be attributed to the random input masking employed during EP-GAN training (see ‘Materials and methods’ for detail), which allows EP-GAN to make robust predictions even when conditioned with varying degrees of masked inputs.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Input data ablation on ElectroPhysiomeGAN (EP-GAN) (32k, Large HH-model).</title><p>Left: reconstructed membrane potential responses for RIM, AIY, and AFD when given with incomplete membrane potential responses data. Percentages in parentheses represent the remaining portion of input membrane potential responses trajectories. Right: reconstructed membrane potential responses for RIM, AIY, and AFD when given with incomplete steady-state current input.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Input data ablation on ElectroPhysiomeGAN (EP-GAN) (32k, Large HH-model).</title><p>Left: reconstructed steady-state currents when given with incomplete membrane potential responses data. Percentages in parentheses represent the remaining portion of input membrane potential responses trajectories. Right: reconstructed steady-state currents when given with incomplete steady-state current input.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig6-figsupp1-v1.tif"/></fig></fig-group><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Ablation studies.</title><p>Top: membrane potential responses and steady-state current errors achieved for EP-GAN (32k, Large HH-model) when provided with incomplete input data. Bottom: membrane potential responses and steady-state current errors achieved for EP-GAN (32k, Large HH-model) upon using only adversarial loss (Adv) and using adversarial + current reconstruction loss (Adv + steady state) and all three loss components (Adv + steady state + membrane potential).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Input Data Ablation</th><th align="left" valign="bottom">Sample size</th><th align="left" valign="bottom">Median Error</th><th align="left" valign="bottom">RIM</th><th align="left" valign="bottom">AIY</th><th align="left" valign="bottom">AFD</th></tr></thead><tbody><tr><td align="left" valign="bottom">EP-GAN (25% membrane potential)</td><td align="char" char="." valign="bottom">32k</td><td align="char" char="." valign="bottom">5.4 mV<break/>14.9 pA</td><td align="char" char="." valign="bottom">3.8<break/>2.8</td><td align="char" char="." valign="bottom">5.4<break/>14.9</td><td align="char" char="." valign="bottom">8.9<break/>34.4</td></tr><tr><td align="left" valign="bottom">EP-GAN (75% steady-state)</td><td align="char" char="." valign="bottom">32k</td><td align="char" char="." valign="bottom">3.5 mV<break/>15.6 pA</td><td align="char" char="." valign="bottom">3.3<break/>3.7</td><td align="char" char="." valign="bottom">3.5<break/>15.6</td><td align="char" char="." valign="bottom">5.1<break/>68.9</td></tr><tr><td align="left" valign="bottom">EP-GAN (50% steady-state)</td><td align="char" char="." valign="bottom">32k</td><td align="char" char="." valign="bottom">3.5 mV<break/>15.5 pA</td><td align="char" char="." valign="bottom">3.3<break/>3.7</td><td align="char" char="." valign="bottom">3.5<break/>15.5</td><td align="char" char="." valign="bottom">5.1<break/>68.9</td></tr><tr><td align="left" valign="bottom">EP-GAN (25% steady-state)</td><td align="char" char="." valign="bottom">32k</td><td align="char" char="." valign="bottom">3.5 mV<break/>15.6 pA</td><td align="char" char="." valign="bottom">3.3<break/>3.7</td><td align="char" char="." valign="bottom">3.5<break/>15.6</td><td align="char" char="." valign="bottom">5.1<break/>68.9</td></tr><tr><td align="left" valign="bottom">EP-GAN (75% membrane potential)</td><td align="char" char="." valign="bottom">32k</td><td align="char" char="." valign="bottom">3.4 mV<break/>11.3 pA</td><td align="char" char="." valign="bottom">3.4<break/>3.6</td><td align="char" char="." valign="bottom">2.7<break/>11.3</td><td align="char" char="." valign="bottom">4.9<break/>44.0</td></tr><tr><td align="left" valign="bottom">EP-GAN (full)</td><td align="char" char="." valign="bottom">32k</td><td align="char" char="." valign="bottom">3.3 mV<break/>10.5 pA</td><td align="char" char="." valign="bottom">3.3<break/>3.2</td><td align="char" char="." valign="bottom">2.7<break/>10.5</td><td align="char" char="." valign="bottom">5.2<break/>39.5</td></tr><tr><td align="left" valign="bottom">EP-GAN (50% membrane potential)</td><td align="char" char="." valign="bottom">32k</td><td align="char" char="." valign="bottom">3.3 mV<break/>13.5 pA</td><td align="char" char="." valign="bottom">3.3<break/>3.4</td><td align="char" char="." valign="bottom">2.9<break/>13.5</td><td align="char" char="." valign="bottom">4.5<break/>43.2</td></tr><tr><th align="left" valign="bottom">Loss ablation</th><th align="left" valign="bottom">Sample size</th><th align="left" valign="bottom">Median Error</th><th align="left" valign="bottom">RIM</th><th align="left" valign="bottom">AIY</th><th align="left" valign="bottom">AFD</th></tr><tr><td align="left" valign="bottom">EP-GAN (Adv)</td><td align="left" valign="bottom">32k</td><td align="left" valign="bottom">14.4 mV<break/>20.3 pA</td><td align="left" valign="bottom">14.4<break/>3.1</td><td align="left" valign="bottom">6.1<break/>20.3</td><td align="left" valign="bottom">24.5<break/>75.4</td></tr><tr><td align="left" valign="bottom">EP-GAN (Adv + steady state)</td><td align="left" valign="bottom">32k</td><td align="left" valign="bottom">6.0 mV<break/>19.1 pA</td><td align="left" valign="bottom">5.7<break/>2.8</td><td align="left" valign="bottom">6.0<break/>19.1</td><td align="left" valign="bottom">3.9<break/>23.1</td></tr><tr><td align="left" valign="bottom">EP-GAN (Adv + steady state + membrane potential)</td><td align="left" valign="bottom">32k</td><td align="left" valign="bottom">3.3 mV<break/>10.5 pA</td><td align="left" valign="bottom">3.3<break/>3.2</td><td align="left" valign="bottom">2.7<break/>10.5</td><td align="left" valign="bottom">5.2<break/>39.5</td></tr></tbody></table></table-wrap><p>We also perform ablation studies on EP-GAN architecture by removing each loss component of the Generator module, allowing us to evaluate their relative contributions to accuracy. For all loss ablation scenarios, simulation protocols outlined in <xref ref-type="table" rid="table4">Table 4</xref> are used to generate membrane potential and steady-state responses of predicted parameters. From <xref ref-type="table" rid="table3">Table 3</xref> bottom, we see that removing the membrane potential loss term (V) results in a loss in performance for RIM and AIY but increases in accuracy for AFD. The result is consistent with input data ablation scenarios indicating AFD’s higher dependence on steady-state responses for good EP-GAN prediction. Upon removing the steady-state current reconstruction loss term (IV) in addition to the membrane potential reconstruction loss, we see a further reduction in overall performance. These results highlight the significance of the reconstruction losses in aligning the Generator to produce the desired outputs (<xref ref-type="table" rid="table3">Table 3</xref>).</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Simulation protocols for simulated and experimental neurons.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Neuron</th><th align="left" valign="bottom">Duration (s)</th><th align="left" valign="bottom">Current-clamp (min:step:max)</th><th align="left" valign="bottom">Stimulation period (s)</th><th align="left" valign="bottom">Voltage-clamp (min:step:max)</th></tr></thead><tbody><tr><td align="left" valign="bottom">Simulated</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–15 pA:5 pA:35 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">RIM</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–15 pA:5 pA:35 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">DVC</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–2 pA:1 pA:8 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">HSN</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–2 pA:1 pA:8 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">AIY</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–15 pA:5 pA:35 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">URX</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–4 pA:2 pA:16 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">RIS</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–4 pA:2 pA:16 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">AFD</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–15 pA:5 pA:35 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">AWB</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–4 pA:2 pA:16 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr><tr><td align="left" valign="bottom">AWC</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">–4 pA:2 pA:16 pA</td><td align="char" char="ndash" valign="bottom">5–10</td><td align="char" char="." valign="bottom">–120 mV:10 mV:50 mV</td></tr></tbody></table></table-wrap></sec><sec id="s2-4"><title>Parameter inference time</title><p>We also evaluate EP-GAN for its scalability by assessing its overall inference time and computational cost and comparing these to existing methods. Indeed, for estimation tasks involving many neurons, it is essential that the method is scalable so that the predictions are done within a reasonable time. In particular, for EP-GAN, the total time <inline-formula><alternatives><mml:math id="inf32"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft32">\begin{document}${T}$\end{document}</tex-math></alternatives></inline-formula> needed for modeling <inline-formula><alternatives><mml:math id="inf33"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft33">\begin{document}${N}$\end{document}</tex-math></alternatives></inline-formula> neurons including data generation and training time can be written as<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mrow><mml:mi>T</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mspace width="0.1667em"/><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="t1">\begin{document}$$\displaystyle {T(N) \sim T_{Data \, generation} + T_{Train} + T_{Inference}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>whereas for existing methods, the <inline-formula><alternatives><mml:math id="inf34"><mml:mrow><mml:mi>T</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo form="postfix" stretchy="false" lspace="0em" rspace="0em">)</mml:mo></mml:mrow></mml:math><tex-math id="inft34">\begin{document}${T(N)}$\end{document}</tex-math></alternatives></inline-formula> follows the form<disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mrow><mml:mi>T</mml:mi><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="t2">\begin{document}$$\displaystyle {T(N) \sim N \cdot T_{Inference} }$$\end{document}</tex-math></alternatives></disp-formula></p><p>which increases linearly as <inline-formula><alternatives><mml:math id="inf35"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft35">\begin{document}${N}$\end{document}</tex-math></alternatives></inline-formula> increases. Since <inline-formula><alternatives><mml:math id="inf36"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft36">\begin{document}${T_{Inference}}$\end{document}</tex-math></alternatives></inline-formula> for EP-GAN is nearly instantaneous, it has a strong advantage in parameter prediction tasks involving multiple neurons. As an example, given a hypothetical task of modeling all 279 somatic neurons in the <italic>C. elegans</italic> nervous system, it would take DEMO, GDE3, NSDE, or NSGA2 more than 44 days (assuming 7.2k samples per neuron and our available computing environment) whereas, for EP-GAN, the process would be done within a day under a similar training setup. For a larger number of neurons, the computational requirement of existing methods would grow linearly while EP-GAN would require constant time to complete the inference. Such scalability largely benefits from EP-GAN learning a parameter estimation strategy that is applicable for multiple neuron classes and its neural network structure being an inherently parallel architecture, allowing it to take multiple neuron profiles and output corresponding parameters in a single forward pass (<xref ref-type="bibr" rid="bib68">Zou et al., 2009</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this work, we introduce a novel deep generative method and system called EP-GAN, for estimating HH-model parameters given the recordings of neurons with graded membrane potential (non-spiking). The proposed system encompasses the RNN encoder layer to process the neural recordings information such as membrane potential responses and steady-state current profiles and the Generator layer to generate a large number of HH-model parameters (<inline-formula><alternatives><mml:math id="inf37"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>N</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>175</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft37">\begin{document}${N \gt 175}$\end{document}</tex-math></alternatives></inline-formula>). The system can be trained entirely on simulation data informed by an arbitrary HH-model. When applied to neurons in <italic>C. elegans</italic>, EP-GAN generates parameters of HH-model which membrane potential responses are closer to ground truth responses than the existing methods such as differential evolution and genetic algorithms. The advantage of EP-GAN is in the accuracy and inference speed achieved through fewer training samples than existing methods and is generic such that it does not depend on the number of neurons for which inference is to be performed (<xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>; <xref ref-type="bibr" rid="bib39">Naudin et al., 2022b</xref>; <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref>). In addition, the method largely preserves performance when provided with input data with partial information such as missing membrane potential responses (up to 50% missing) or steady-state current traces (up to 75% missing).</p><p>While EP-GAN is a step forward toward the ElectroPhysiome model of <italic>C. elegans</italic>, its inability to support neurons with spiking membrane potential responses remains a limitation. The reason stems from the fact that neurons with spiking membrane potential responses are rare during the generation of training data of 16 ionic channels HH-model without the spike-associated neuron channels. The relative sparsity of spiking responses makes their translation strategies to parameter space difficult to learn. A similar limitation is present with bistable membrane potential responses, for example, AFD, AWB, and AWC, although to a lesser extent. While the limitations for these profiles can be partially remedied through more training samples of their neuron types, their relative sparseness in the training data tends to cause lower quality of predicted parameters. Indeed, previous studies of <italic>C. elegans</italic> nervous system found that the majority of neurons exhibit graded membrane potential response instead of spiking (<xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>; <xref ref-type="bibr" rid="bib19">Goodman et al., 1998</xref>). Furthermore, the limitation could lie within the current architecture of EP-GAN as it processes data directly without a component that discerns and processes spiking membrane potential responses. Improving the sampling strategy for training data alongside the enhancement of the network architecture could address these limitations in the future.</p><p>As discussed in ‘Materials and methods’, it is worth noting that EP-GAN does not necessarily recover the ground truth parameters that are associated with the input membrane potential responses and steady-state current profiles. This is mainly due to the fact that there may exist multiple parameter regimes for the HH-model that support the given inputs (<xref ref-type="bibr" rid="bib66">Willms, 2002</xref>; <xref ref-type="bibr" rid="bib35">Marder and Goaillard, 2006</xref>; <xref ref-type="bibr" rid="bib36">Marder and Taylor, 2011</xref>; <xref ref-type="bibr" rid="bib47">Prinz et al., 2003</xref>; <xref ref-type="bibr" rid="bib48">Prinz et al., 2004</xref>; <xref ref-type="bibr" rid="bib58">Valle and Madureira, 2022</xref>; <xref ref-type="bibr" rid="bib49">Raba et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Naudin, 2023</xref>). The parameters generated by a single forward pass of EP-GAN (i.e., a single flow of information from the input to the output) could thus be interpreted as a one-time sampling from such a regime, and a perturbation to inputs may result in a different set of parameters. Such sensitivity to perturbation could be adjusted by supplementing the training samples or inputs with additional recording data (e.g., multiple recording data per neuron).</p><p>EP-GAN allows additional modifications to accommodate different configurations of the problem. For instance, an update to the HH-model would only require retraining of the network without changes to its architecture. Indeed, the neuronal genome of <italic>C. elegans</italic> indicates additional voltage-gated channels that could be further incorporated into the HH-models introduced in <xref ref-type="bibr" rid="bib42">Nicoletti et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref> to improve its modeling accuracy of membrane potential dynamics (<xref ref-type="bibr" rid="bib23">Hobert, 2018</xref>). Extending the inputs to include additional data, for example, channel activation profiles, can also be done in a straightforward manner by concatenating them to the input vectors of the Encoder network. Extending EP-GAN prediction capabilities to new neuron types can also be done by incorporating additional constraints during training data generation.</p><p>Despite its primary focus on <italic>C. elegans</italic> neurons, we believe EP-GAN and its future extensions could be viable for modeling a variety of neurons in other organisms. Indeed, there are increasing advances in resolving connectomes of more complex organisms and techniques for recording large-scale neural activities (<xref ref-type="bibr" rid="bib6">Brooks et al., 2022</xref>; <xref ref-type="bibr" rid="bib67">Winding et al., 2023</xref>; <xref ref-type="bibr" rid="bib45">Oh et al., 2014</xref>; <xref ref-type="bibr" rid="bib57">Sofroniew et al., 2016</xref>). As neurons in these organisms can be described by a generic HH-model or similar differential equation model, EP-GAN is expected to be applicable and contribute to the development of biologically detailed nervous system models of neurons in these organisms.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>We divide the materials and methods section into three parts. In the first part, we describe the detailed architecture of the EP-GAN including its sub-modules with the simulation protocol used during training. In the second part, we describe the mathematical description for the ionic currents in the HH-model used for neuron modeling. In the third part, we describe the dataset and experimental protocol of novel neuron recordings of AWB, AWC, URX, RIS, DVC, and HSN from <italic>C. elegans</italic> nervous system.</p><sec id="s4-1"><title>Architecture of EP-GAN</title><sec id="s4-1-1"><title>Deep generative model for parameter prediction</title><p>EP-GAN receives neuronal recording data such as membrane potential responses and steady-state current profiles and generates a set of parameters that are associated with them in terms of simulating the inferred HH-model and comparing the simulated result with the inputs (<xref ref-type="fig" rid="fig1">Figures 1</xref> and <xref ref-type="fig" rid="fig7">7</xref>). We choose a deep generative model approach, specifically Generative Adversarial Network (GAN) as a base architecture of EP-GAN. The key advantage of GAN is in its ability to generate artificial data that closely resembles real data. The generative nature of GAN is advantageous for addressing the one-to-many nature of our problem, where there exist multiple parameter solutions for a given neuron recording. Indeed, several computational works attempting to solve an inverse HH-model noted the ill-posed nature of the parameter solutions (<xref ref-type="bibr" rid="bib66">Willms, 2002</xref>; <xref ref-type="bibr" rid="bib35">Marder and Goaillard, 2006</xref>; <xref ref-type="bibr" rid="bib36">Marder and Taylor, 2011</xref>; <xref ref-type="bibr" rid="bib47">Prinz et al., 2003</xref>; <xref ref-type="bibr" rid="bib48">Prinz et al., 2004</xref>; <xref ref-type="bibr" rid="bib58">Valle and Madureira, 2022</xref>; <xref ref-type="bibr" rid="bib49">Raba et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Naudin, 2023</xref>). Our approach is therefore leveraging GAN to learn a <italic>domain of parameter sets</italic> compatible with neuron recordings instead of mapping directly onto a single solution. GAN consists of two separate networks, Generator and Discriminator. The goal of the Generator is to generate outputs that are indistinguishable from real data, whereas the Discriminator’s goal is to distinguish outputs that are generated by the Generator against real data. Throughout training, the Generator and the Discriminator engage in a zero-sum game until they both converge to optimal states (i.e. Nash equilibrium) (<xref ref-type="bibr" rid="bib18">Goodfellow et al., 2020</xref>). The particular architecture we use is Wasserstein GAN with gradient penalty (WGAN-GP), a variant of GAN architecture offering more stable training and faster convergence (<xref ref-type="bibr" rid="bib2">Arjovsky et al., 2017</xref>).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Architecture of ElectroPhysiomeGAN (EP-GAN).</title><p>The architecture consists of an Encoder, Generator, and Discriminator. Encoder compresses the membrane potential responses into a 1D vector (i.e., latent space) that is then concatenated with 1D steady-state current profile to be used as an input to both Generator and Discriminator. Generator translates the latent space vector into a vector of parameters <inline-formula><alternatives><mml:math id="inf38"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft38">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula> and the Discriminator outputs a scalar measuring the similarity between generated parameters (<inline-formula><alternatives><mml:math id="inf39"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft39">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula>) and ground truths (<inline-formula><alternatives><mml:math id="inf40"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft40">\begin{document}${\boldsymbol{\vec{p}}}$\end{document}</tex-math></alternatives></inline-formula>). The Generator is trained with adversarial loss supplemented by reconstruction losses for both membrane potential responses and steady-state current profiles. The Discriminator is trained with Discriminator adversarial loss only. Generator and Discriminator follow the architecture of Wasserstein GAN with gradient penalty (WGAN-GP) for more stable learning. During training, random masking is applied to input membrane potential responses where its masking rate gradually decreases as the training continues.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig7-v1.tif"/></fig></sec><sec id="s4-1-2"><title>Encoder module</title><p>In addition to Generator and Discriminator, we implement an Encoder module that pre-processes the input membrane potential responses for Generator and Discriminator (<xref ref-type="fig" rid="fig7">Figure 7</xref>, left). Specifically, the encoder serves two roles: (i) compression of membrane potential responses traces along the stimulus space, thus reducing its dimension from two-dimensional to one-dimensional, and (ii) translation of membrane potential responses traces into a latent space which encodes a meaningful internal representation for the Discriminator and Generator. The Encoder module uses Gated Recurrent Unit (GRU) architecture, a variant of RNN to perform this task (<xref ref-type="bibr" rid="bib11">Cho et al., 2014</xref>). Each input sequence to a GRU cell at step <inline-formula><alternatives><mml:math id="inf41"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft41">\begin{document}${k}$\end{document}</tex-math></alternatives></inline-formula> corresponds to the entire membrane potential response of size 350 (i.e., 350 time points, representing <inline-formula><alternatives><mml:math id="inf42"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>4</mml:mn><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mn>11</mml:mn><mml:mi>s</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft42">\begin{document}${t = [4s,11s]}$\end{document}</tex-math></alternatives></inline-formula>) concatenated with the associated stimulus trace of equal size of 350. Since GRU is agnostic to the number of steps in an input sequence, such input structure allows EP-GAN to process a set of membrane potential traces with arbitrary current-clamp protocol. The output of the Encoder is a latent space vector of size 1024 encoding membrane potential responses information. The latent space vector is then concatenated with a 1D vector representing steady-state current profile which is used as an input to both Generator and Discriminator. During training, we randomly mask membrane potential traces to assist in better generalization in prediction (<xref ref-type="bibr" rid="bib10">Chang et al., 2022</xref>; <xref ref-type="bibr" rid="bib34">Liu et al., 2024</xref>). Specifically, we initially set the masking rate to 75% (i.e., 75% of membrane potential traces are randomly masked) and linearly decrease to 0% toward the end of training (<xref ref-type="fig" rid="fig7">Figure 7</xref>).</p></sec><sec id="s4-1-3"><title>Discriminator module</title><p>The goal of the Discriminator is given the input membrane potential responses and current profiles, to distinguish generated parameters from real ground truth parameters. The Discriminator receives as input the latent space vector from the Encoder concatenated with a generated or ground truth parameter vector and outputs a scalar representing the relative distance between two parameter sets (<xref ref-type="fig" rid="fig7">Figure 7</xref>, <xref ref-type="disp-formula" rid="equ3">Equation 1</xref>). Such a quantity is called Wasserstein distance or Wasserstein loss and differs from a vanilla GAN Discriminator, which only outputs between 0 and 1. Wasserstein loss is known to remedy several common issues that arise from a vanilla GAN such as vanishing gradient and mode collapse, leading to more stable training (<xref ref-type="bibr" rid="bib2">Arjovsky et al., 2017</xref>). To further improve the training of the WGAN architecture, we supplement Wasserstein loss with a gradient penalty term, which ensures that the gradients of the Discriminator’s output with respect to the input have unit norms (<xref ref-type="bibr" rid="bib20">Gulrajani et al., 2017</xref>). This condition is called Lipschitz continuity and prevents Discriminator outputs from having large variations when there are only small variations in the inputs (<xref ref-type="bibr" rid="bib20">Gulrajani et al., 2017</xref>; <xref ref-type="bibr" rid="bib61">Virmaux and Scaman, 2018</xref>). Combined together, the Discriminator is trained with the following loss:<disp-formula id="equ3"><label>(1)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle J_D = \mathbb{E}[D(\vec{\widetilde{p}})] - \mathbb{E}[D(\vec{p})] + \lambda \mathbb{E}[(\|\nabla_{\hat{p}} D(\hat{p})\|_2 - 1)^2]$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf43"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft43">\begin{document}${\mathbb{E}[D(\boldsymbol{\vec{\widetilde{p}}})]}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf44"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft44">\begin{document}${\mathbb{E}[D(\boldsymbol{\vec{p}})]}$\end{document}</tex-math></alternatives></inline-formula> are the mean values of Discriminator outputs with respect to generated samples <inline-formula><alternatives><mml:math id="inf45"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft45">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula> and real samples <inline-formula><alternatives><mml:math id="inf46"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft46">\begin{document}${\boldsymbol{\vec{p}}}$\end{document}</tex-math></alternatives></inline-formula>, respectively, and <inline-formula><alternatives><mml:math id="inf47"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft47">\begin{document}${\lambda \mathbb{E}[(||\nabla_{\hat{\boldsymbol{p}}}D(\hat{\boldsymbol{p}})||_{2} - 1)^{2}]}$\end{document}</tex-math></alternatives></inline-formula> is the gradient penalty term modulated by <inline-formula><alternatives><mml:math id="inf48"><mml:mi>λ</mml:mi></mml:math><tex-math id="inft48">\begin{document}${\lambda}$\end{document}</tex-math></alternatives></inline-formula> where <inline-formula><alternatives><mml:math id="inf49"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft49">\begin{document}${\hat{\boldsymbol{p}} = t\boldsymbol{\vec{\widetilde{p}}} + (1-t)\boldsymbol{\vec{p}}}$\end{document}</tex-math></alternatives></inline-formula> is the interpolation between generated and real samples with <inline-formula><alternatives><mml:math id="inf50"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft50">\begin{document}${0 \leq t \leq 1}$\end{document}</tex-math></alternatives></inline-formula>.</p></sec><sec id="s4-1-4"><title>Generator module</title><p>Being an adversary network of Discriminator, the goal of the Generator is to fool the Discriminator by generating parameters that are indistinguishable from the real parameters. The Generator receives as input the concatenated vector from the Encoder and outputs a parameter vector (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The module consists of four fully connected layers with layer normalization applied after the first two layers for improved model convergence (<xref ref-type="bibr" rid="bib3">Ba et al., 2016</xref>). Each parameter in the output vector is scaled between –1 and 1, which is then scaled back to the parameters’ original scales. The module is trained using three loss terms: (i) Generator adversarial loss, (ii) membrane potential responses reconstruction loss, and (iii) steady-state current reconstruction loss as follows:<disp-formula id="equ4"><label>(2)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi>p</mml:mi><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi>V</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi>I</mml:mi><mml:mi>V</mml:mi></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle J_G = -\mathbb{E}[D(\vec{\widetilde{p}})] + J_{\vec{V}} + J_{\vec{IV}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ5"><label>(3)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  J_{\boldsymbol{\vec{V}}}= \sum_{i=1}^{n}|\boldsymbol{\vec{V}}_{ground truth}- \boldsymbol{\vec{V}}_{reconstructed}|$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ6"><label>(4)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  J_{\boldsymbol{\vec{IV}}}= \sum_{i=1}^{n}|\boldsymbol{\vec{IV}}_{ground truth}- \boldsymbol{\vec{IV}}_{reconstructed}|$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf51"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft51">\begin{document}${-\mathbb{E}[D(\boldsymbol{\vec{\widetilde{p}}})]}$\end{document}</tex-math></alternatives></inline-formula> is Generator adversarial loss, which is the reciprocal of the mean Discriminator outputs with respect to generated samples, and <inline-formula><alternatives><mml:math id="inf52"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft52">\begin{document}${J_{\boldsymbol{\vec{V}}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf53"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft53">\begin{document}${J_{\boldsymbol{\vec{IV}}}}$\end{document}</tex-math></alternatives></inline-formula> are <inline-formula><alternatives><mml:math id="inf54"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft54">\begin{document}${L_{1}}$\end{document}</tex-math></alternatives></inline-formula> regression loss for reconstructed membrane potential responses and steady-state current profiles, respectively. It is important to note that <inline-formula><alternatives><mml:math id="inf55"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft55">\begin{document}${J_{\boldsymbol{\vec{V}}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf56"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft56">\begin{document}${J_{\boldsymbol{\vec{IV}}}}$\end{document}</tex-math></alternatives></inline-formula> are part of Generator’s computation graph and thus force Generator to optimize them on top of adversarial loss (<xref ref-type="fig" rid="fig8">Figure 8</xref>). The composite loss function of Generator makes EP-GAN a ‘model-informed’ GAN as the HH-model itself becomes part of the training process. Such networks have been shown to be more data-efficient during training as they do not rely solely on training data to learn an effective strategy (<xref ref-type="bibr" rid="bib27">Karniadakis et al., 2021</xref>; <xref ref-type="bibr" rid="bib51">Raissi et al., 2019</xref>). The mathematical description of membrane potential responses and steady-state current reconstruction from generated parameter set <inline-formula><alternatives><mml:math id="inf57"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft57">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula> is as follows:<disp-formula id="equ7"><label>(5)</label><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle \boldsymbol{\vec{V}}_{reconstructed}(t) = \nabla^{-1}\left(\frac{d\boldsymbol{\vec{V}}}{dt}(\boldsymbol{\vec{V}}, t, \boldsymbol{\vec{\widetilde{p}}})\right), \; \boldsymbol{\vec{IV}}_{reconstructed}(V) = IV(\boldsymbol{\vec{V}}, \boldsymbol{\vec{\widetilde{p}}})$$\end{document}</tex-math></alternatives></disp-formula></p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Description of membrane potential responses and steady-state current reconstruction losses for the Generator.</title><p>Generated parameter vector <inline-formula><alternatives><mml:math id="inf58"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft58">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula> is used to evaluate membrane potential responses derivatives <inline-formula><alternatives><mml:math id="inf59"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft59">\begin{document}${dV/dt}$\end{document}</tex-math></alternatives></inline-formula> at <inline-formula><alternatives><mml:math id="inf60"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft60">\begin{document}${n}$\end{document}</tex-math></alternatives></inline-formula> time points sampled with fixed interval given the ground truth <inline-formula><alternatives><mml:math id="inf61"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft61">\begin{document}${\boldsymbol{\vec{V}}}$\end{document}</tex-math></alternatives></inline-formula> at those time points. The evaluated membrane potential responses derivatives are then used to reconstruct <inline-formula><alternatives><mml:math id="inf62"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft62">\begin{document}${\boldsymbol{\vec{V}}}$\end{document}</tex-math></alternatives></inline-formula> using the forward integration operation <inline-formula><alternatives><mml:math id="inf63"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msup><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft63">\begin{document}${\nabla^{-1}}$\end{document}</tex-math></alternatives></inline-formula>. The reconstructed <inline-formula><alternatives><mml:math id="inf64"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft64">\begin{document}${\boldsymbol{\vec{V}}}$\end{document}</tex-math></alternatives></inline-formula> is then compared with ground truth <inline-formula><alternatives><mml:math id="inf65"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft65">\begin{document}${\boldsymbol{\vec{V}}}$\end{document}</tex-math></alternatives></inline-formula> to evaluate the membrane potential responses reconstruction loss <inline-formula><alternatives><mml:math id="inf66"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft66">\begin{document}${J_{\boldsymbol{\vec{V}}}}$\end{document}</tex-math></alternatives></inline-formula>. Steady-state current reconstruction is computed in a similar way via evaluating the currents at defined voltage points <inline-formula><alternatives><mml:math id="inf67"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft67">\begin{document}${V}$\end{document}</tex-math></alternatives></inline-formula> given generated parameters <inline-formula><alternatives><mml:math id="inf68"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft68">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula> as inputs.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig8-v1.tif"/></fig><p>Here, <inline-formula><alternatives><mml:math id="inf69"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft69">\begin{document}${\frac{d\boldsymbol{\vec{V}}}{dt}(\boldsymbol{\vec{V}},t,\boldsymbol{\vec{\widetilde{p}}})}$\end{document}</tex-math></alternatives></inline-formula> is the right-hand-side function of the HH-model, which computes the membrane potential responses derivative at time <inline-formula><alternatives><mml:math id="inf70"><mml:mi>t</mml:mi></mml:math><tex-math id="inft70">\begin{document}${t}$\end{document}</tex-math></alternatives></inline-formula> given the membrane potential responses <inline-formula><alternatives><mml:math id="inf71"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft71">\begin{document}${\boldsymbol{\vec{V}}}$\end{document}</tex-math></alternatives></inline-formula> and parameter set <inline-formula><alternatives><mml:math id="inf72"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft72">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf73"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>I</mml:mi><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft73">\begin{document}${IV(\boldsymbol{\vec{V}}, \boldsymbol{\vec{\widetilde{p}}})}$\end{document}</tex-math></alternatives></inline-formula> is the function that evaluates the neuron’s steady-state current <inline-formula><alternatives><mml:math id="inf74"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft74">\begin{document}${I}$\end{document}</tex-math></alternatives></inline-formula> given the voltage states <inline-formula><alternatives><mml:math id="inf75"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft75">\begin{document}${\boldsymbol{\vec{V}}}$\end{document}</tex-math></alternatives></inline-formula> and parameter set <inline-formula><alternatives><mml:math id="inf76"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft76">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula>. Membrane potential responses are reconstructed by first evaluating their derivatives with respect to ground truth membrane potential responses and generated parameters <inline-formula><alternatives><mml:math id="inf77"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft77">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula> at regularly sampled time points. This is followed by the forward integration operation <inline-formula><alternatives><mml:math id="inf78"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msup><mml:mi mathvariant="normal">∇</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft78">\begin{document}${\nabla^{-1}}$\end{document}</tex-math></alternatives></inline-formula> similar to Euler’s method to approximate <inline-formula><alternatives><mml:math id="inf79"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft79">\begin{document}${\boldsymbol{\vec{V}}}$\end{document}</tex-math></alternatives></inline-formula> at sampled time points given the initial condition <inline-formula><alternatives><mml:math id="inf80"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft80">\begin{document}${\boldsymbol{\vec{V}}_{init}}$\end{document}</tex-math></alternatives></inline-formula>:<disp-formula id="equ8"><label>(6)</label><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="thickmathspace"/><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle \boldsymbol{\vec{V}}_{t+1}= \boldsymbol{\vec{V}}_{t}+ h\boldsymbol{\vec{V}}'(t), \; \boldsymbol{\vec{V}}_{t = 0}= \boldsymbol{\vec{V}}_{init}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf81"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft81">\begin{document}${h}$\end{document}</tex-math></alternatives></inline-formula> is the time interval between sampled derivatives. <inline-formula><alternatives><mml:math id="inf82"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft82">\begin{document}${\boldsymbol{\vec{V}}_{init}}$\end{document}</tex-math></alternatives></inline-formula> can be selected at any time point within the ground truth membrane potential state (e.g., pre-activation, mid-activation, post-activation) to reconstruct different membrane potential features. Notably, all computation steps consisting of the forward integration process are expected to be differentiable. This is necessary to incorporate the forward integration process as part of the generator network that requires full differentiability and thus is trainable via the back-propagation algorithm (<xref ref-type="bibr" rid="bib55">Rumelhart et al., 1986</xref>). Computationally, we achieve this by manually implementing the forward integration process with discrete array operations that support auto-differentiation and vectorization (e.g., PyTorch Tensors) instead of simulating the membrane potential with ODE solvers (<xref ref-type="bibr" rid="bib46">Paszke et al., 2019</xref>). The variable <inline-formula><alternatives><mml:math id="inf83"><mml:mi>h</mml:mi></mml:math><tex-math id="inft83">\begin{document}${h}$\end{document}</tex-math></alternatives></inline-formula> can also be adjusted to increase the accuracy of the membrane potential responses reconstruction in exchange for the increased computational cost. The current profile is reconstructed by directly evaluating <inline-formula><alternatives><mml:math id="inf84"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>I</mml:mi><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft84">\begin{document}${IV(\boldsymbol{\vec{V}}, \boldsymbol{\vec{p}})}$\end{document}</tex-math></alternatives></inline-formula> ,which uses the generated parameter set <inline-formula><alternatives><mml:math id="inf85"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mover><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo mathvariant="bold">~</mml:mo></mml:mover></mml:mrow><mml:mo mathvariant="bold" stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft85">\begin{document}${\boldsymbol{\vec{\widetilde{p}}}}$\end{document}</tex-math></alternatives></inline-formula> over the range of voltage values. We show in <xref ref-type="table" rid="table3">Table 3</xref> that reconstruction losses are essential for the accuracy of predicted parameters.</p></sec><sec id="s4-1-5"><title>Generating training data</title><p>For a successful training of a neural network model, the training data must be of a sufficient number of samples, denoised, and diverse. To ensure these conditions are met with a simulated dataset, we employ a three-step process for generating training data (<xref ref-type="fig" rid="fig9">Figure 9</xref>).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Training data generation.</title><p>In Step 1, each parameter is initially sampled from biologically plausible ranges using both skewed Gaussian (channel conductance) and uniform sampling. A parameter set consists of 175 parameters spanning 16 known ion channels in <italic>C. elegans</italic> and similar organisms. In Steps 2 and 3, steady-state currents and membrane potential responses are evaluated for each parameter set to ensure they satisfy the predefined constraints such as bifurcation structure represented by <inline-formula><alternatives><mml:math id="inf86"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft86">\begin{document}${dI/dV}$\end{document}</tex-math></alternatives></inline-formula> bounds and minimum-maximum membrane potential across current-clamp protocols. Only parameter sets that meet both constraints are included in the training set.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95607-fig9-v1.tif"/></fig></sec><sec id="s4-1-6"><title>Step 1</title><p>Randomly generate parameter sets by sampling each parameter within a predefined distribution. This distribution is the skewed normal distribution for channel conductance parameters and uniform distributions for other parameters. The range is determined according to the biologically feasible ranges reported in the literature (see table <italic>predicted parameters</italic> in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for an explicit range used for each parameter) (<xref ref-type="bibr" rid="bib33">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Naudin et al., 2021</xref>; <xref ref-type="bibr" rid="bib25">Izhikevich, 2007</xref>). In particular, search ranges for channel parameters are set to baseline ±50% where baseline parameters are default parameters given by <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref>.</p></sec><sec id="s4-1-7"><title>Step 2</title><p>Simulate steady-state current traces for each sampled parameter set followed by imposing bifurcation structure constraints on each of them. This is done by calculating the first derivative of the currents <inline-formula><alternatives><mml:math id="inf87"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft87">\begin{document}${dI/dV}$\end{document}</tex-math></alternatives></inline-formula> with respect to voltage states and ensuring they are within the 98% confidence intervals of experimentally obtained <inline-formula><alternatives><mml:math id="inf88"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft88">\begin{document}${dI/dV}$\end{document}</tex-math></alternatives></inline-formula> bounds. Specifically, we evaluate each parameter set with respect to the three neuron types that are found within <italic>C. elegans</italic> non-spiking neurons – Type 1: transient outward rectifier (RIM, DVC, HSN); type 2: outward rectifier type (AIY, URX, RIS); and type 3: bistable type (AFD, AWB, AWC). During data generation, approximately the same number of neurons are generated for each type to ensure balance between all neuron types. The step can be further extended with new neuron types by incorporating additional <inline-formula><alternatives><mml:math id="inf89"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft89">\begin{document}${dI/dV}$\end{document}</tex-math></alternatives></inline-formula> bounds.</p></sec><sec id="s4-1-8"><title>Step 3</title><p>Impose (minimum, maximum) constraints on the membrane potential response across the current-clamp protocol. These values are set to (–100 mV, 150 mV) respectively for (–15 pA, 35 pA) current-clamp range. Parameter sets that do not satisfy the steady-state currents (Step 2) and membrane potential responses constraints are then removed from the training set. These constraints serve two purposes: (i) remove parameter sets that result in non-realistic membrane potential responses/steady-state current profiles from the training set and (ii) serve as an initial data augmentation process for EP-GAN training. The constraints can also be extended or adjusted if deemed necessary for the improvement of the training process. Once constraints are applied, Gaussian noise is added to the membrane potential responses training data to mimic the measurement noises in experimental membrane potential responses recording data.</p></sec></sec><sec id="s4-2"><title>Ionic currents modeling</title><p>The general equation describing the membrane potential dynamics of a single-compartment neuron is<disp-formula id="equ9"><label>(7)</label><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle C_{m}\frac{dV}{dt}= -I_{ion}+ I_{Ext}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf90"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft90">\begin{document}${I_{ion}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf91"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft91">\begin{document}${I_{Ext}}$\end{document}</tex-math></alternatives></inline-formula> represent the ionic and external currents applied to a neuron, respectively. The HH-model we consider has a total of 16 ionic current terms comprised of 11 voltage/calcium-gated potassium currents (<inline-formula><alternatives><mml:math id="inf92"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft92">\begin{document}${I_{K^{+}}}$\end{document}</tex-math></alternatives></inline-formula>), 3 voltage-gated calcium currents (<inline-formula><alternatives><mml:math id="inf93"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft93">\begin{document}${I_{Ca^{2+}}}$\end{document}</tex-math></alternatives></inline-formula>), leakage currents (<inline-formula><alternatives><mml:math id="inf94"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft94">\begin{document}${I_{Leak}}$\end{document}</tex-math></alternatives></inline-formula>), and sodium leakage currents (<inline-formula><alternatives><mml:math id="inf95"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft95">\begin{document}${I_{Na^{+}}}$\end{document}</tex-math></alternatives></inline-formula>) (<xref ref-type="table" rid="table5">Table 5</xref>). Consequently, the ionic current term <inline-formula><alternatives><mml:math id="inf96"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft96">\begin{document}${I_{ion}}$\end{document}</tex-math></alternatives></inline-formula> of the considered HH-model can be written as<disp-formula id="equ10"><label>(8)</label><alternatives><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t10">\begin{document}$$\displaystyle I_{ion}= I_{K^{+}}+ I_{Ca^{2+}}+ I_{Leak}+ I_{Na^{+}}$$\end{document}</tex-math></alternatives></disp-formula></p><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>List of ion channels included in the estimated HH-models.</title><p>Ion selectivity for each channel and the number of ElectroPhysiomeGAN (EP-GAN) trained parameters (not including reversal potentials) for both small and large HH-models are listed.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Ion channel</th><th align="left" valign="bottom">Ion selectivity</th><th align="left" valign="bottom"># of parameters(small HH-model)</th><th align="left" valign="bottom"># of parameters(large HH-model)</th></tr></thead><tbody><tr><td align="left" valign="bottom">SHL1</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">4</td><td align="left" valign="bottom">22</td></tr><tr><td align="left" valign="bottom">SHK1</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">14</td></tr><tr><td align="left" valign="bottom">EGL2</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">8</td></tr><tr><td align="left" valign="bottom">IRK1/3</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">10</td></tr><tr><td align="left" valign="bottom">UNC103</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">15</td></tr><tr><td align="left" valign="bottom">KQT1</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">17</td></tr><tr><td align="left" valign="bottom">EXP2</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">15</td></tr><tr><td align="left" valign="bottom">SLO1</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">SLO1-CaV</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom">SLO2</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">2</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">SLO2-CaV</td><td align="left" valign="bottom">K<sup>+</sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">3</td></tr><tr><td align="left" valign="bottom">EGL19</td><td align="left" valign="bottom">Ca<sup>+</sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">23</td></tr><tr><td align="left" valign="bottom">UNC2</td><td align="left" valign="bottom">Ca<sup><italic>+</italic></sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">18</td></tr><tr><td align="left" valign="bottom">CCA1</td><td align="left" valign="bottom">Ca<sup><italic>+</italic></sup></td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom">15</td></tr><tr><td align="left" valign="bottom">Leak</td><td align="left" valign="bottom">Leak</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">1</td></tr><tr><td align="left" valign="bottom">NCA</td><td align="left" valign="bottom">Na<sup><italic>+</italic></sup></td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom">1</td></tr></tbody></table></table-wrap><p>Each <inline-formula><alternatives><mml:math id="inf97"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft97">\begin{document}${ith}$\end{document}</tex-math></alternatives></inline-formula> ionic current can be modeled according to the HH-type formulation as follows:<disp-formula id="equ11"><label>(9)</label><alternatives><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle I_{ion}^{i}= g_{i}\cdot m_{i}^{p}\cdot h_{i}^{p}\cdot (V - E_{rev})$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf98"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft98">\begin{document}${g_i}$\end{document}</tex-math></alternatives></inline-formula> <italic>is</italic> the maximum conductance and <inline-formula><alternatives><mml:math id="inf99"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft99">\begin{document}${E_{rev}}$\end{document}</tex-math></alternatives></inline-formula> is the reversal potential of the channel. <inline-formula><alternatives><mml:math id="inf100"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msubsup><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft100">\begin{document}${m_{i}^p}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf101"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft101">\begin{document}${h_{i}^p }$\end{document}</tex-math></alternatives></inline-formula> each represent the activation and inactivation variables of the channel with the following equations:<disp-formula id="equ12"><label>(10)</label><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle \frac{dm_{i}}{dt}= \frac{m_{i,\infty}- m_{i}}{\tau_{i, m}}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ13"><label>(11)</label><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle \frac{dh_{i}}{dt}= \frac{h_{i,\infty}- h_{i}}{\tau_{i, h}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf102"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft102">\begin{document}${m_{i,\infty}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf103"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft103">\begin{document}${h_{i,\infty}}$\end{document}</tex-math></alternatives></inline-formula> each represent the steady-state activation and inactivation values, and <inline-formula><alternatives><mml:math id="inf104"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft104">\begin{document}${\tau_{i, m}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf105"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft105">\begin{document}${\tau_{i, h}}$\end{document}</tex-math></alternatives></inline-formula> represent the activation and inactivation time constants. Note that each ionic channel may have a different mathematical description and parameters for variables <inline-formula><alternatives><mml:math id="inf106"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft106">\begin{document}${m_{i,\infty}}$\end{document}</tex-math></alternatives></inline-formula><italic>,</italic> <inline-formula><alternatives><mml:math id="inf107"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft107">\begin{document}${h_{i,\infty}}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf108"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft108">\begin{document}${\tau_{i, m}}$\end{document}</tex-math></alternatives></inline-formula><italic>,</italic> and <inline-formula><alternatives><mml:math id="inf109"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft109">\begin{document}${\tau_{i, h}}$\end{document}</tex-math></alternatives></inline-formula> according to their dynamics and dependencies. While the majority of these variables are dependent on membrane potential, some channels are dependent on intracellular calcium (e.g., SLO1/2) or independent (e.g., <inline-formula><alternatives><mml:math id="inf110"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft110">\begin{document}${\tau_{i, h}}$\end{document}</tex-math></alternatives></inline-formula> of SHK1).</p><p>Leakage and sodium leakage currents are modeled with the following equations:<disp-formula id="equ14"><label>(12)</label><alternatives><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t14">\begin{document}$$\displaystyle I_{Leak}= g_{Leak}(V - E_{Leak})$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ15"><label>(13)</label><alternatives><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t15">\begin{document}$$\displaystyle I_{Na^{+}}= g_{NCA}(V - E_{NCA})$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf111"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft111">\begin{document}${g_{Leak}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf112"><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft112">\begin{document}${g_{NCA}}$\end{document}</tex-math></alternatives></inline-formula> each represent the conductance values for the leakage and sodium leakage currents. For the exact mathematical equations describing each individual channel, please refer to the supplementary materials of <xref ref-type="bibr" rid="bib43">Nicoletti et al., 2024</xref>.</p></sec><sec id="s4-3"><title>Experimental protocol</title><sec id="s4-3-1"><title><italic>C. elegans</italic> culture and strains</title><p>All animals used in this study were maintained at room temperature (22°C–23°C) on nematode growth medium (NGM) plates seeded with <italic>Escherichia coli</italic> OP50 bacteria as a food source (<xref ref-type="bibr" rid="bib5">Brenner, 1974</xref>). The strains used in this study were CX7893 kyIs405 (AWB), CX3695 kyIs140 (AWC), ZG611 iaIs19 (URX), EG1285 lin-15B(n765);oxIs12 (RIS), UL2650 leEx2650 (DVC), and CX4857 kyIs179 (HSN).</p></sec><sec id="s4-3-2"><title>Electrophysiology</title><p>Electrophysiological recordings were performed on young adult hermaphrodites (∼3 days old) at room temperature as previously described (<xref ref-type="bibr" rid="bib33">Liu et al., 2018</xref>). The gluing and dissection were performed under an Olympus SZX16 stereomicroscope equipped with a 1× Plan Apochromat objective and widefield 10× eyepieces. Briefly, an adult animal was immobilized on a Sylgard-coated (Sylgard 184, Dow Corning) glass coverslip in a small drop of DPBS (D8537; Sigma) by applying a cyanoacrylate adhesive (Vetbond tissue adhesive; 3M) along one side of the body. A puncture in the cuticle away from the incision site was made to relieve hydrostatic pressure. A small longitudinal incision was then made using a diamond dissecting blade (type M-DL 72029 L; EMS) along the glue line adjacent to the neuron of interest. The cuticle flap was folded back and glued to the coverslip with GLUture Topical Adhesive (Abbott Laboratories), exposing the neuron to be recorded. The coverslip with the dissected preparation was then placed into a custom-made open recording chamber (∼1.5 ml volume) and treated with 1 mg/ml collagenase (type IV; Sigma) for ∼10 s by hand pipetting. The recording chamber was subsequently perfused with the standard extracellular solution using a custom-made gravity-feed perfusion system for ∼10 ml.</p><p>All electrophysiological recordings were performed with the bath at room temperature under an upright microscope (Axio Examiner; Carl Zeiss, Inc) equipped with a 40× water immersion lens and 16× eyepieces. Neurons of interest were identified by fluorescent markers and their anatomical positions. Preparations were then switched to the differential interference contrast (DIC) setting for patch-clamp. Electrodes with resistance (RE) of 15–25 MΩ were made from borosilicate glass pipettes (BF100-58-10; Sutter Instruments) using a laser pipette puller (P-2000; Sutter Instruments) and fire-polished with a microforge (MF-830; Narishige). We used a motorized micromanipulator (PatchStar Micromanipulator; Scientifica) to control the electrodes back filled with standard intracellular solution. The standard pipette solution was (all concentrations in mM) [K-gluconate 115; KCl 15; KOH 10; MgCl<sub>2</sub> 5; CaCl<sub>2</sub> 0.1; Na<sub>2</sub>ATP 5; NaGTP 0.5; Na-cGMP 0.5; cAMP 0.5; BAPTA 1; HEPES 10; sucrose 50], with pH adjusted with KOH to 7.2, osmolarity 320–330 mOsm. The standard extracellular solution was [NaCl 140; NaOH 5; KCl 5; CaCl<sub>2</sub> 2; MgCl<sub>2</sub> 5; sucrose 15; HEPES 15; dextrose 25], with pH adjusted with NaOH to 7.3, osmolarity 330–340 mOsm. Liquid junction potentials were calculated and corrected before recording. Whole-cell current clamp and voltage-clamp experiments were conducted on an EPC-10 amplifier (EPC-10 USB; Heka) using PatchMaster software (Heka). Two-component capacitive compensation was optimized at rest, and series resistance was compensated to 50%. Analog data were filtered at 2 kHz and digitized at 10 kHz. Current-injection and voltage-clamp steps were applied through the recording electrode.</p></sec></sec><sec id="s4-4"><title>Data and code availability</title><p>The membrane potentials and steady-state currents recording data for nine experimental neurons can be found in Mendeley Data, <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17632/g5kcjp7jsk.1">https://doi.org/10.17632/g5kcjp7jsk.1</ext-link>.</p><p>Generated HH-model parameters of all nine experimental neurons considered in the study (small and large HH-models, using EP-GAN (32k)) as well as minimum and maximum values for each parameter used during inference are deposited in supporting files 1.</p><p>Pre-trained PyTorch EP-GAN (64k) models for both small and large HH-models and the Jupyter Notebook testing the models with respect to nine experimental <italic>C. elegans</italic> neurons studied in the paper are available at the Github repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/shlizee/epgan">https://github.com/shlizee/epgan</ext-link> copy archived at <xref ref-type="bibr" rid="bib56">Shlizerman, 2025</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation</p></fn><fn fn-type="con" id="con3"><p>Data curation</p></fn><fn fn-type="con" id="con4"><p>Data curation, Supervision, Funding acquisition, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-95607-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Table of EP-GAN(32k) generated parameters (Small, Large).</title></caption><media xlink:href="elife-95607-supp1-v1.zip" mimetype="application" mime-subtype="zip"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Membrane potential dynamics and steady-state current responses of all 9 experimental neurons considered in the study are deposited in Mendeley Data. Generated HH-model parameters of all 9 experimental neurons considered in the study (small and large HH-models), minimum and maximum values for each parameter used during inference, and parameter values predicted by EP-GAN are deposited in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>.Pre-trained EP-GAN models (64k sample size) for estimating small and large HH-models are deposited in Github.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>ElectroPhysiomeGAN: Generation of Biophysical Neuron Model Parameters from Recorded Electrophysiological Responses</data-title><source>Mendeley Data</source><pub-id pub-id-type="doi">10.17632/g5kcjp7jsk.1</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported in part by National Science Foundation grant CRCNS IIS-2113003 (JK,ES), Washington Research Fund (ES), CRCNS IIS-2113120 (QL), Kavli NSI Pilot Grant (QL), CityU New Research Initiatives/Infrastructure Support from Central APRC 9610587 (QL), the General Research Fund (GRF) and Early Career Scheme (ECS) Award from Hong Kong Research Grants Council RGC (CityU 21103522, CityU 11104123, CityU 11100524) (QL), and Chan Zuckerberg Initiative (to Cori Bargmann). The authors also acknowledge the partial support by the Departments of Electrical and Computer Engineering (JK, ES), Applied Mathematics (ES), the Center of Computational Neuroscience (ES), and the eScience Institute (ES, JK) at the University of Washington. In addition, we thank Cori Bargmann and Ian Hope for <italic>C. elegans</italic> strains. Some strains were provided by the CGC, which is funded by the NIH Office of Research Infrastructure Programs (P40 OD010440). We thank Saba Heravi for discussions regarding parameter inference for electrophysiological recordings.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Angira</surname><given-names>R</given-names></name><name><surname>Babu</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Non-dominated sorting differential evolution (NSDE): an extension of differential evolution for multi-objective optimization</article-title><conf-name>IICAI</conf-name><fpage>1428</fpage><lpage>1443</lpage></element-citation></ref><ref id="bib2"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Arjovsky</surname><given-names>M</given-names></name><name><surname>Chintala</surname><given-names>S</given-names></name><name><surname>Bottou</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Wasserstein generative adversarial networks</article-title><conf-name>International conference on machine learning</conf-name><fpage>214</fpage><lpage>223</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ba</surname><given-names>JL</given-names></name><name><surname>Kiros</surname><given-names>JR</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Layer Normalization</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1607.06450</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blank</surname><given-names>J</given-names></name><name><surname>Deb</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pymoo: multi-objective optimization in python</article-title><source>IEEE Access</source><volume>8</volume><fpage>89497</fpage><lpage>89509</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2990567</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brenner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>The genetics of <italic>Caenorhabditis elegans</italic></article-title><source>Genetics</source><volume>77</volume><fpage>71</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1093/genetics/77.1.71</pub-id><pub-id pub-id-type="pmid">4366476</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>P</given-names></name><name><surname>Champion</surname><given-names>A</given-names></name><name><surname>Costa</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Mapping of the zebrafish brain takes shape</article-title><source>Nature Methods</source><volume>19</volume><fpage>1345</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1038/s41592-022-01637-6</pub-id><pub-id pub-id-type="pmid">36280716</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Buhry</surname><given-names>L</given-names></name><name><surname>Giremus</surname><given-names>A</given-names></name><name><surname>Grivel</surname><given-names>E</given-names></name><name><surname>Saïghi</surname><given-names>S</given-names></name><name><surname>Renaud</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>New variants of the differential evolution algorithm: application for neuroscientists</article-title><conf-name>17th european signal processing conference</conf-name><fpage>2352</fpage><lpage>2356</lpage></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buhry</surname><given-names>L</given-names></name><name><surname>Pace</surname><given-names>M</given-names></name><name><surname>Saïghi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Global parameter estimation of an Hodgkin–Huxley formalism using membrane voltage recordings: Application to neuro-mimetic analog integrated circuits</article-title><source>Neurocomputing</source><volume>81</volume><fpage>75</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2011.11.002</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burrows</surname><given-names>M</given-names></name><name><surname>Laurent</surname><given-names>GJ</given-names></name><name><surname>Field</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Proprioceptive inputs to nonspiking local interneurons contribute to local reflexes of a locust hindleg</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>3085</fpage><lpage>3093</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-08-03085.1988</pub-id><pub-id pub-id-type="pmid">3411369</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Jiang</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Freeman</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>MaskGIT: Masked Generative Image Transformer</article-title><conf-name>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</conf-name><fpage>11315</fpage><lpage>11325</lpage><pub-id pub-id-type="doi">10.1109/CVPR52688.2022.01103</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>K</given-names></name><name><surname>van Merrienboer</surname><given-names>B</given-names></name><name><surname>Gulcehre</surname><given-names>C</given-names></name><name><surname>Bahdanau</surname><given-names>D</given-names></name><name><surname>Bougares</surname><given-names>F</given-names></name><name><surname>Schwenk</surname><given-names>H</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning Phrase Representations Using RNN Encoder–Decoder for Statistical Machine Translation</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1406.1078</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>SJ</given-names></name><name><surname>Jarrell</surname><given-names>TA</given-names></name><name><surname>Brittin</surname><given-names>CA</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Bloniarz</surname><given-names>AE</given-names></name><name><surname>Yakovlev</surname><given-names>MA</given-names></name><name><surname>Nguyen</surname><given-names>KCQ</given-names></name><name><surname>Tang</surname><given-names>LTH</given-names></name><name><surname>Bayer</surname><given-names>EA</given-names></name><name><surname>Duerr</surname><given-names>JS</given-names></name><name><surname>Bülow</surname><given-names>HE</given-names></name><name><surname>Hobert</surname><given-names>O</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Emmons</surname><given-names>SW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Whole-animal connectomes of both <italic>Caenorhabditis elegans</italic> sexes</article-title><source>Nature</source><volume>571</volume><fpage>63</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1352-7</pub-id><pub-id pub-id-type="pmid">31270481</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>RE</given-names></name><name><surname>Stretton</surname><given-names>AO</given-names></name></person-group><year iso-8601-date="1989">1989a</year><article-title>Passive membrane properties of motorneurons and their role in long-distance signaling in the nematode Ascaris</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>403</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-02-00403.1989</pub-id><pub-id pub-id-type="pmid">2918369</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>RE</given-names></name><name><surname>Stretton</surname><given-names>AO</given-names></name></person-group><year iso-8601-date="1989">1989b</year><article-title>Signaling properties of Ascaris motorneurons: graded active responses, graded synaptic transmission, and tonic transmitter release</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>415</fpage><lpage>425</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-02-00415.1989</pub-id><pub-id pub-id-type="pmid">2563763</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Deb</surname><given-names>K</given-names></name><name><surname>Agrawal</surname><given-names>S</given-names></name><name><surname>Pratap</surname><given-names>A</given-names></name><name><surname>Meyarivan</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A fast elitist non-dominated sorting genetic algorithm for multi-objective optimization: NSGA-II</article-title><conf-name>Parallel problem solving from nature PPSN VI: 6th international conference paris, france, september 18-20, 2000 proceedings 6</conf-name><fpage>849</fpage><lpage>858</lpage></element-citation></ref><ref id="bib16"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Estienne</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Towards an Hybrid Hodgkin-Huxley Action Potential Generation Model</article-title><conf-name>2021 XIX Workshop on Information Processing and Control (RPIC)</conf-name><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1109/RPIC53795.2021.9648523</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonçalves</surname><given-names>PJ</given-names></name><name><surname>Lueckmann</surname><given-names>JM</given-names></name><name><surname>Deistler</surname><given-names>M</given-names></name><name><surname>Nonnenmacher</surname><given-names>M</given-names></name><name><surname>Öcal</surname><given-names>K</given-names></name><name><surname>Bassetto</surname><given-names>G</given-names></name><name><surname>Chintaluri</surname><given-names>C</given-names></name><name><surname>Podlaski</surname><given-names>WF</given-names></name><name><surname>Haddad</surname><given-names>SA</given-names></name><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Greenberg</surname><given-names>DS</given-names></name><name><surname>Macke</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Training deep neural density estimators to identify mechanistic models of neural dynamics</article-title><source>eLife</source><volume>9</volume><elocation-id>e56261</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56261</pub-id><pub-id pub-id-type="pmid">32940606</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Pouget-Abadie</surname><given-names>J</given-names></name><name><surname>Mirza</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>B</given-names></name><name><surname>Warde-Farley</surname><given-names>D</given-names></name><name><surname>Ozair</surname><given-names>S</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Generative adversarial networks</article-title><source>Communications of the ACM</source><volume>63</volume><fpage>139</fpage><lpage>144</lpage><pub-id pub-id-type="doi">10.1145/3422622</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>MB</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Avery</surname><given-names>L</given-names></name><name><surname>Lockery</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Active currents regulate sensitivity and dynamic range in <italic>C. elegans</italic> neurons</article-title><source>Neuron</source><volume>20</volume><fpage>763</fpage><lpage>772</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)81014-4</pub-id><pub-id pub-id-type="pmid">9581767</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gulrajani</surname><given-names>I</given-names></name><name><surname>Ahmed</surname><given-names>F</given-names></name><name><surname>Arjovsky</surname><given-names>M</given-names></name><name><surname>Dumoulin</surname><given-names>V</given-names></name><name><surname>Courville</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Improved training of wasserstein gans</article-title><conf-name>Advances in neural information processing systems</conf-name></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Wieser</surname><given-names>E</given-names></name><name><surname>Taylor</surname><given-names>J</given-names></name><name><surname>Berg</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>NJ</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Picus</surname><given-names>M</given-names></name><name><surname>Hoyer</surname><given-names>S</given-names></name><name><surname>van Kerkwijk</surname><given-names>MH</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Haldane</surname><given-names>A</given-names></name><name><surname>Del Río</surname><given-names>JF</given-names></name><name><surname>Wiebe</surname><given-names>M</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Gérard-Marchant</surname><given-names>P</given-names></name><name><surname>Sheppard</surname><given-names>K</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Abbasi</surname><given-names>H</given-names></name><name><surname>Gohlke</surname><given-names>C</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Array programming with NumPy</article-title><source>Nature</source><volume>585</volume><fpage>357</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id><pub-id pub-id-type="pmid">32939066</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hay</surname><given-names>E</given-names></name><name><surname>Hill</surname><given-names>S</given-names></name><name><surname>Schürmann</surname><given-names>F</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name><name><surname>Segev</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Models of neocortical layer 5b pyramidal cells capturing a wide range of dendritic and perisomatic active properties</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1002107</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002107</pub-id><pub-id pub-id-type="pmid">21829333</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hobert</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The neuronal genome of <italic>Caenorhabditis elegans</italic></article-title><source>WormBook: The Online Review of C. elegans Biology</source><volume>1</volume><elocation-id>11611</elocation-id><pub-id pub-id-type="doi">10.1895/wormbook.1.161.1</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hodgkin</surname><given-names>AL</given-names></name><name><surname>Huxley</surname><given-names>AF</given-names></name></person-group><year iso-8601-date="1952">1952</year><article-title>A quantitative description of membrane current and its application to conduction and excitation in nerve</article-title><source>The Journal of Physiology</source><volume>117</volume><fpage>500</fpage><lpage>544</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1952.sp004764</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Izhikevich</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2007">2007</year><source>Dynamical Systems in Neuroscience</source><publisher-name>MIT press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/2526.001.0001</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Su</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>R</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Tao</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title><italic>C. elegans</italic> enteric motor neurons fire synchronized action potentials underlying the defecation motor program</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>2783</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-30452-y</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karniadakis</surname><given-names>GE</given-names></name><name><surname>Kevrekidis</surname><given-names>IG</given-names></name><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Perdikaris</surname><given-names>P</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Yang</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Physics-informed machine learning</article-title><source>Nature Reviews Physics</source><volume>3</volume><fpage>422</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1038/s42254-021-00314-5</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>K</given-names></name><name><surname>McLean</surname><given-names>J</given-names></name><name><surname>Segev</surname><given-names>R</given-names></name><name><surname>Freed</surname><given-names>MA</given-names></name><name><surname>Berry</surname><given-names>MJ</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name><name><surname>Sterling</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>How much the eye tells the brain</article-title><source>Current Biology</source><volume>16</volume><fpage>1428</fpage><lpage>1434</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2006.05.056</pub-id><pub-id pub-id-type="pmid">16860742</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kukkonen</surname><given-names>S</given-names></name><name><surname>Lampinen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>GDE3: The third Evolution Step of Generalized Differential Evolution</article-title><conf-name>2005 IEEE Congress on Evolutionary Computation</conf-name><fpage>443</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1109/CEC.2005.1554717</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Laredo</surname><given-names>JJL</given-names></name><name><surname>Naudin</surname><given-names>L</given-names></name><name><surname>Corson</surname><given-names>N</given-names></name><name><surname>Fernandes</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A methodology for determining ion channels from membrane potential neuronal recordings</article-title><conf-name>Applications of evolutionary computation: 25th european conference, EvoApplications 2022, held as part of EvoStar 2022, madrid, spain, april 20-22, 2022, proceedings</conf-name><fpage>15</fpage><lpage>29</lpage></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laurent</surname><given-names>G</given-names></name><name><surname>Burrows</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989a</year><article-title>Distribution of intersegmental inputs to nonspiking local interneurons and motor neurons in the locust</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>3019</fpage><lpage>3029</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-09-03019.1989</pub-id><pub-id pub-id-type="pmid">2795150</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laurent</surname><given-names>G</given-names></name><name><surname>Burrows</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1989">1989b</year><article-title>Intersegmental interneurons can control the gain of reflexes in adjacent segments of the locust by their action on nonspiking local interneurons</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>3030</fpage><lpage>3039</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-09-03030.1989</pub-id><pub-id pub-id-type="pmid">2795151</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Kidd</surname><given-names>PB</given-names></name><name><surname>Dobosiewicz</surname><given-names>M</given-names></name><name><surname>Bargmann</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title><italic>C. elegans</italic> AWA olfactory neurons fire calcium-mediated all-or-none action potentials</article-title><source>Cell</source><volume>175</volume><fpage>57</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.08.018</pub-id><pub-id pub-id-type="pmid">30220455</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Su</surname><given-names>K</given-names></name><name><surname>Shlizerman</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Tell What You Hear from What You See–Video to Audio Generation through Text</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/html/2411.05679v3">https://arxiv.org/html/2411.05679v3</ext-link></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marder</surname><given-names>E</given-names></name><name><surname>Goaillard</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Variability, compensation and homeostasis in neuron and network function</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>563</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1038/nrn1949</pub-id><pub-id pub-id-type="pmid">16791145</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marder</surname><given-names>E</given-names></name><name><surname>Taylor</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multiple models to capture the variability in biological neurons and networks</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>133</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1038/nn.2735</pub-id><pub-id pub-id-type="pmid">21270780</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naudin</surname><given-names>L</given-names></name><name><surname>Corson</surname><given-names>N</given-names></name><name><surname>Aziz-Alaoui</surname><given-names>MA</given-names></name><name><surname>Jiménez Laredo</surname><given-names>JL</given-names></name><name><surname>Démare</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>On the Modeling of the Three Types of Non-spiking Neurons of the <italic>Caenorhabditis elegans</italic></article-title><source>International Journal of Neural Systems</source><volume>31</volume><elocation-id>2050063</elocation-id><pub-id pub-id-type="doi">10.1142/S012906572050063X</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naudin</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022a</year><article-title>Biological emergent properties in non-spiking neural networks</article-title><source>AIMS Mathematics</source><volume>7</volume><fpage>19415</fpage><lpage>19439</lpage><pub-id pub-id-type="doi">10.3934/math.20221066</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naudin</surname><given-names>L</given-names></name><name><surname>Jiménez Laredo</surname><given-names>JL</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Corson</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022b</year><article-title>Systematic generation of biophysically detailed models with generalization capability for non-spiking neurons</article-title><source>PLOS ONE</source><volume>17</volume><elocation-id>e0268380</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0268380</pub-id><pub-id pub-id-type="pmid">35560186</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naudin</surname><given-names>L</given-names></name><name><surname>Laredo</surname><given-names>JLJ</given-names></name><name><surname>Corson</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022c</year><article-title>A simple model of nonspiking neurons</article-title><source>Neural Computation</source><volume>34</volume><fpage>2075</fpage><lpage>2101</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01531</pub-id><pub-id pub-id-type="pmid">36027796</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naudin</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Different parameter solutions of a conductance-based model that behave identically are not necessarily degenerate</article-title><source>Journal of Computational Neuroscience</source><volume>51</volume><fpage>201</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1007/s10827-023-00848-w</pub-id><pub-id pub-id-type="pmid">36905484</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicoletti</surname><given-names>M</given-names></name><name><surname>Loppini</surname><given-names>A</given-names></name><name><surname>Chiodo</surname><given-names>L</given-names></name><name><surname>Folli</surname><given-names>V</given-names></name><name><surname>Ruocco</surname><given-names>G</given-names></name><name><surname>Filippi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Biophysical modeling of <italic>C. elegans</italic> neurons: Single ion currents and whole-cell dynamics of AWCon and RMD</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0218738</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0218738</pub-id><pub-id pub-id-type="pmid">31260485</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nicoletti</surname><given-names>M</given-names></name><name><surname>Chiodo</surname><given-names>L</given-names></name><name><surname>Loppini</surname><given-names>A</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Folli</surname><given-names>V</given-names></name><name><surname>Ruocco</surname><given-names>G</given-names></name><name><surname>Filippi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Biophysical modeling of the whole-cell dynamics of <italic>C. elegans</italic> motor and interneurons families</article-title><source>PLOS ONE</source><volume>19</volume><elocation-id>e0298105</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0298105</pub-id><pub-id pub-id-type="pmid">38551921</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Octeau</surname><given-names>JC</given-names></name><name><surname>Gangwani</surname><given-names>MR</given-names></name><name><surname>Allam</surname><given-names>SL</given-names></name><name><surname>Tran</surname><given-names>D</given-names></name><name><surname>Huang</surname><given-names>S</given-names></name><name><surname>Hoang-Trong</surname><given-names>TM</given-names></name><name><surname>Golshani</surname><given-names>P</given-names></name><name><surname>Rumbell</surname><given-names>TH</given-names></name><name><surname>Kozloski</surname><given-names>JR</given-names></name><name><surname>Khakh</surname><given-names>BS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Transient, consequential increases in extracellular potassium ions accompany channelrhodopsin2 excitation</article-title><source>Cell Reports</source><volume>27</volume><fpage>2249</fpage><lpage>2261</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2019.04.078</pub-id><pub-id pub-id-type="pmid">31116972</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oh</surname><given-names>SW</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Winslow</surname><given-names>B</given-names></name><name><surname>Cain</surname><given-names>N</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Lau</surname><given-names>C</given-names></name><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Henry</surname><given-names>AM</given-names></name><name><surname>Mortrud</surname><given-names>MT</given-names></name><name><surname>Ouellette</surname><given-names>B</given-names></name><name><surname>Nguyen</surname><given-names>TN</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Slaughterbeck</surname><given-names>CR</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Ho</surname><given-names>A</given-names></name><name><surname>Nicholas</surname><given-names>E</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Joines</surname><given-names>KM</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name><name><surname>Hawrylycz</surname><given-names>MJ</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Hohmann</surname><given-names>JG</given-names></name><name><surname>Wohnoutka</surname><given-names>P</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Dang</surname><given-names>C</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A mesoscale connectome of the mouse brain</article-title><source>Nature</source><volume>508</volume><fpage>207</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1038/nature13186</pub-id><pub-id pub-id-type="pmid">24695228</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name><name><surname>Gross</surname><given-names>S</given-names></name><name><surname>Massa</surname><given-names>F</given-names></name><name><surname>Lerer</surname><given-names>A</given-names></name><name><surname>Bradbury</surname><given-names>J</given-names></name><name><surname>Chanan</surname><given-names>G</given-names></name><name><surname>Killeen</surname><given-names>T</given-names></name><name><surname>Lin</surname><given-names>Z</given-names></name><name><surname>Gimelshein</surname><given-names>N</given-names></name><name><surname>Antiga</surname><given-names>L</given-names></name><name><surname>Desmaison</surname><given-names>A</given-names></name><name><surname>Köpf</surname><given-names>A</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>DeVito</surname><given-names>Z</given-names></name><name><surname>Raison</surname><given-names>M</given-names></name><name><surname>Tejani</surname><given-names>A</given-names></name><name><surname>Chilamkurthy</surname><given-names>S</given-names></name><name><surname>Steiner</surname><given-names>B</given-names></name><name><surname>Fang</surname><given-names>L</given-names></name><name><surname>Bai</surname><given-names>J</given-names></name><name><surname>Chintala</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Pytorch: An Imperative Style, High-Performance Deep Learning Library</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.48550/arXiv.1912.01703">https://doi.org/10.48550/arXiv.1912.01703</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prinz</surname><given-names>AA</given-names></name><name><surname>Billimoria</surname><given-names>CP</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Alternative to hand-tuning conductance-based models: construction and analysis of databases of model neurons</article-title><source>Journal of Neurophysiology</source><volume>90</volume><fpage>3998</fpage><lpage>4015</lpage><pub-id pub-id-type="doi">10.1152/jn.00641.2003</pub-id><pub-id pub-id-type="pmid">12944532</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prinz</surname><given-names>AA</given-names></name><name><surname>Bucher</surname><given-names>D</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Similar network activity from disparate circuit parameters</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>1345</fpage><lpage>1352</lpage><pub-id pub-id-type="doi">10.1038/nn1352</pub-id><pub-id pub-id-type="pmid">15558066</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raba</surname><given-names>AE</given-names></name><name><surname>Cordeiro</surname><given-names>JM</given-names></name><name><surname>Antzelevitch</surname><given-names>C</given-names></name><name><surname>Beaumont</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Extending the conditions of application of an inversion of the Hodgkin-Huxley gating model</article-title><source>Bulletin of Mathematical Biology</source><volume>75</volume><fpage>752</fpage><lpage>773</lpage><pub-id pub-id-type="doi">10.1007/s11538-013-9832-7</pub-id><pub-id pub-id-type="pmid">23595789</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rackauckas</surname><given-names>C</given-names></name><name><surname>Nie</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>DifferentialEquations.jl – A performant and feature-rich ecosystem for solving differential equations in Julia</article-title><source>Journal of Open Research Software</source><volume>5</volume><elocation-id>151</elocation-id><pub-id pub-id-type="doi">10.5334/jors.151</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raissi</surname><given-names>M</given-names></name><name><surname>Perdikaris</surname><given-names>P</given-names></name><name><surname>Karniadakis</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</article-title><source>Journal of Computational Physics</source><volume>378</volume><fpage>686</fpage><lpage>707</lpage><pub-id pub-id-type="doi">10.1016/j.jcp.2018.10.045</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Roberts</surname><given-names>A</given-names></name><name><surname>Bush</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="1981">1981</year><source>Neurones without Impulses: Their Significance for Vertebrate and Invertebrate Nervous Systems</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib53"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Robič</surname><given-names>T</given-names></name><name><surname>Filipič</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Differential evolution for multiobjective optimization</article-title><conf-name>Evolutionary multi-criterion optimization: third international conference, EMO 2005, guanajuato, mexico, march 9-11, 2005. Proceedings 3</conf-name><fpage>520</fpage><lpage>533</lpage></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumbell</surname><given-names>TH</given-names></name><name><surname>Draguljić</surname><given-names>D</given-names></name><name><surname>Yadav</surname><given-names>A</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name><name><surname>Luebke</surname><given-names>JI</given-names></name><name><surname>Weaver</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Automated evolutionary optimization of ion channel conductances and kinetics in models of young and aged rhesus monkey pyramidal neurons</article-title><source>Journal of Computational Neuroscience</source><volume>41</volume><fpage>65</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1007/s10827-016-0605-9</pub-id><pub-id pub-id-type="pmid">27106692</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Williams</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Learning representations by back-propagating errors</article-title><source>Nature</source><volume>323</volume><fpage>533</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1038/323533a0</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Shlizerman</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Epgan</data-title><version designator="swh:1:rev:e3d686c84e43b3d2fb3e438e9164839a1eb254c9">swh:1:rev:e3d686c84e43b3d2fb3e438e9164839a1eb254c9</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:48c4048f305ec237019d680e60a549f22ec56956;origin=https://github.com/shlizee/epgan;visit=swh:1:snp:6f37d93fa20d7a7adc64c6a672531a61d56308bd;anchor=swh:1:rev:e3d686c84e43b3d2fb3e438e9164839a1eb254c9">https://archive.softwareheritage.org/swh:1:dir:48c4048f305ec237019d680e60a549f22ec56956;origin=https://github.com/shlizee/epgan;visit=swh:1:snp:6f37d93fa20d7a7adc64c6a672531a61d56308bd;anchor=swh:1:rev:e3d686c84e43b3d2fb3e438e9164839a1eb254c9</ext-link></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sofroniew</surname><given-names>NJ</given-names></name><name><surname>Flickinger</surname><given-names>D</given-names></name><name><surname>King</surname><given-names>J</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A large field of view two-photon mesoscope with subcellular resolution for in vivo imaging</article-title><source>eLife</source><volume>5</volume><elocation-id>e14472</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.14472</pub-id><pub-id pub-id-type="pmid">27300105</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valle</surname><given-names>JAM</given-names></name><name><surname>Madureira</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Parameter identification problem in the hodgkin-huxley model</article-title><source>Neural Computation</source><volume>34</volume><fpage>939</fpage><lpage>970</lpage><pub-id pub-id-type="doi">10.1162/neco_a_01487</pub-id><pub-id pub-id-type="pmid">35231934</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Geit</surname><given-names>W</given-names></name><name><surname>de Schutter</surname><given-names>E</given-names></name><name><surname>Achard</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Automated neuron model optimization techniques: a review</article-title><source>Biological Cybernetics</source><volume>99</volume><fpage>241</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0257-6</pub-id><pub-id pub-id-type="pmid">19011918</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varshney</surname><given-names>LR</given-names></name><name><surname>Chen</surname><given-names>BL</given-names></name><name><surname>Paniagua</surname><given-names>E</given-names></name><name><surname>Hall</surname><given-names>DH</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Structural properties of the <italic>Caenorhabditis elegans</italic> neuronal network</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1001066</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1001066</pub-id><pub-id pub-id-type="pmid">21304930</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Virmaux</surname><given-names>A</given-names></name><name><surname>Scaman</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Lipschitz regularity of deep neural networks: analysis and efficient estimation</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1805.10965</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>van der Walt</surname><given-names>SJ</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>KJ</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Carey</surname><given-names>CJ</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Henriksen</surname><given-names>I</given-names></name><name><surname>Quintero</surname><given-names>EA</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>van Mulbregt</surname><given-names>P</given-names></name><collab>SciPy 1.0 Contributors</collab></person-group><year iso-8601-date="2020">2020</year><article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id><pub-id pub-id-type="pmid">32015543</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>YC</given-names></name><name><surname>Rudi</surname><given-names>J</given-names></name><name><surname>Velasco</surname><given-names>J</given-names></name><name><surname>Sinha</surname><given-names>N</given-names></name><name><surname>Idumah</surname><given-names>G</given-names></name><name><surname>Powers</surname><given-names>RK</given-names></name><name><surname>Heckman</surname><given-names>CJ</given-names></name><name><surname>Chardon</surname><given-names>MK</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Multimodal parameter spaces of a complex multi-channel neuron model</article-title><source>Frontiers in Systems Neuroscience</source><volume>16</volume><elocation-id>999531</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2022.999531</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>JG</given-names></name><name><surname>Southgate</surname><given-names>E</given-names></name><name><surname>Thomson</surname><given-names>JN</given-names></name><name><surname>Brenner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>The structure of the nervous system of the nematode <italic>Caenorhabditis elegans</italic></article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>314</volume><fpage>1</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1098/rstb.1986.0056</pub-id><pub-id pub-id-type="pmid">22462104</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willms</surname><given-names>AR</given-names></name><name><surname>Baro</surname><given-names>DJ</given-names></name><name><surname>Harris-Warrick</surname><given-names>RM</given-names></name><name><surname>Guckenheimer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>An improved parameter estimation method for Hodgkin-Huxley models</article-title><source>Journal of Computational Neuroscience</source><volume>6</volume><fpage>145</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1023/a:1008880518515</pub-id><pub-id pub-id-type="pmid">10333160</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willms</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>NEUROFIT: software for fitting Hodgkin-Huxley models to voltage-clamp data</article-title><source>Journal of Neuroscience Methods</source><volume>121</volume><fpage>139</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1016/s0165-0270(02)00227-3</pub-id><pub-id pub-id-type="pmid">12468004</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winding</surname><given-names>M</given-names></name><name><surname>Pedigo</surname><given-names>BD</given-names></name><name><surname>Barnes</surname><given-names>CL</given-names></name><name><surname>Patsolic</surname><given-names>HG</given-names></name><name><surname>Park</surname><given-names>Y</given-names></name><name><surname>Kazimiers</surname><given-names>T</given-names></name><name><surname>Fushiki</surname><given-names>A</given-names></name><name><surname>Andrade</surname><given-names>IV</given-names></name><name><surname>Khandelwal</surname><given-names>A</given-names></name><name><surname>Valdes-Aleman</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>F</given-names></name><name><surname>Randel</surname><given-names>N</given-names></name><name><surname>Barsotti</surname><given-names>E</given-names></name><name><surname>Correia</surname><given-names>A</given-names></name><name><surname>Fetter</surname><given-names>RD</given-names></name><name><surname>Hartenstein</surname><given-names>V</given-names></name><name><surname>Priebe</surname><given-names>CE</given-names></name><name><surname>Vogelstein</surname><given-names>JT</given-names></name><name><surname>Cardona</surname><given-names>A</given-names></name><name><surname>Zlatic</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The connectome of an insect brain</article-title><source>Science</source><volume>379</volume><elocation-id>eadd9330</elocation-id><pub-id pub-id-type="doi">10.1126/science.add9330</pub-id><pub-id pub-id-type="pmid">36893230</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>J</given-names></name><name><surname>Han</surname><given-names>Y</given-names></name><name><surname>So</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Artificial Neural Networks</article-title><source>Artificial Neural Networks: Methods and Applications</source><volume>1</volume><fpage>14</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1007/978-1-60327-101-1_2</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Error calculation</title><p>The overall errors between predicted membrane potential traces and their ground truth counterparts are computed using RMSE formula as follows:<disp-formula id="equ16"><alternatives><mml:math id="m16"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:mo fence="true" form="prefix">(</mml:mo><mml:msubsup><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:msubsup><mml:mo form="prefix" stretchy="false">(</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo separator="true">,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>/</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo fence="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:math><tex-math id="t16">\begin{document}$$\displaystyle {V_{error} = \sqrt{\frac{\sum_{t=1}^{T}\left(\sum_{k = 1}^{N_{stim}}(V^{pred}_{k,t}- V^{gt}_{k,t})^{2}/{N_{stim}}\right)}{N_{T}}}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Voltage with upper subscripts <italic>pred</italic> and <italic>gt</italic> represents reconstructed membrane potential values at trace <inline-formula><alternatives><mml:math id="inf113"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft113">\begin{document}${k}$\end{document}</tex-math></alternatives></inline-formula> and time <inline-formula><alternatives><mml:math id="inf114"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft114">\begin{document}${t}$\end{document}</tex-math></alternatives></inline-formula> using predicted HH-parameters and ground truth variables, respectively. <inline-formula><alternatives><mml:math id="inf115"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft115">\begin{document}${N_{stim}}$\end{document}</tex-math></alternatives></inline-formula> corresponds to a total number of stimulus values associated with current-clamp protocol. <inline-formula><alternatives><mml:math id="inf116"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft116">\begin{document}${N_{T}}$\end{document}</tex-math></alternatives></inline-formula> represents the total number of time points in which voltage traces are defined.</p><p>The error is computed for each of three intervals: pre-activation [4–5 s), mid-activation [5–10 s], and post-activation (10–11 s], which are then averaged to compute the overall error.</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Root mean square error (RMSE) errors for membrane potential responses (top) and steady-state currents (bottom) for test neurons (n=200) considered in prediction on simulated neurons scenario.</title><p>Membrane potential responses errors are ordered as pre-activation error [4–5 s), mid-activation error [5–10 s], and post-activation periods error (10–11 s].</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Method</th><th align="left" valign="bottom">Simulation #</th><th align="left" valign="bottom">Test neurons</th></tr></thead><tbody><tr><td align="left" valign="bottom">EPGAN</td><td align="left" valign="bottom">32k</td><td align="left" valign="bottom">1.33 mV | 3.63 mV | 2.15 mV</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">8.41 pA</td></tr></tbody></table></table-wrap></sec><sec sec-type="appendix" id="s9"><title>Numerical simulation of HH-model</title><p>For efficient simulations of HH-model membrane potential dynamics, we use Julia ODE solver KenCarp47 algorithm supplemented by high-performance computing packages such as NumPy and SciPy (<xref ref-type="bibr" rid="bib50">Rackauckas and Nie, 2017</xref>; <xref ref-type="bibr" rid="bib21">Harris et al., 2020</xref>; <xref ref-type="bibr" rid="bib62">Virtanen et al., 2020</xref>). Both relative and absolute tolerances for the ODE solver have been set to 1e-8 to ensure the accuracy of the simulations.</p><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>Small HH-model root mean square error (RMSE) errors (sample size = 32k) for membrane potential responses and steady-state currents for <italic>predictions on small HH-model scenarios</italic>.</title><p>For each neuron, top row shows the RMSE errors for three time intervals – pre-activation [4–5s), mid-activation [5–10s], and post-activation (10–11s] and bottom row shows the RMSE error for steady-state currents across 18 voltage points.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Method</th><th align="left" valign="bottom" colspan="9">Neurons</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="9">GDE3</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">5.63 mV</td><td align="left" valign="bottom">53.09 mV</td><td align="left" valign="bottom">3.92 mV</td><td align="left" valign="bottom">47.39 mV</td><td align="left" valign="bottom">79.42 mV</td><td align="left" valign="bottom">47.34 mV</td><td align="left" valign="bottom">2.8 mV</td><td align="left" valign="bottom">14.76 mV</td><td align="left" valign="bottom">8.98 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">5.78 pA</td><td align="left" valign="bottom" colspan="3">5.78 pA</td><td align="left" valign="bottom" colspan="3">19.84 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">9.75 mV</td><td align="left" valign="bottom">17.41 mV</td><td align="left" valign="bottom">11.75 mV</td><td align="left" valign="bottom">14.89 mV</td><td align="left" valign="bottom">25.19 mV</td><td align="left" valign="bottom">10.61 mV</td><td align="left" valign="bottom">28.39 mV</td><td align="left" valign="bottom">19.52 mV</td><td align="left" valign="bottom">28.18 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">4.82 pA</td><td align="left" valign="bottom" colspan="3">2.42 pA</td><td align="left" valign="bottom" colspan="3">5.94 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">0.66 mV</td><td align="left" valign="bottom">17.37 mV</td><td align="left" valign="bottom">0.93 mV</td><td align="left" valign="bottom">36.72 mV</td><td align="left" valign="bottom">26.7 mV</td><td align="left" valign="bottom">34.21 mV</td><td align="left" valign="bottom">0.56 mV</td><td align="left" valign="bottom">12.42 mV</td><td align="left" valign="bottom">1.2 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">19.13 pA</td><td align="left" valign="bottom" colspan="3">7.22 pA</td><td align="left" valign="bottom" colspan="3">11.92 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9">NSDE</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">33.29 mV</td><td align="left" valign="bottom">51.33 mV</td><td align="left" valign="bottom">31.54 mV</td><td align="left" valign="bottom">0.86 mV</td><td align="left" valign="bottom">19.88 mV</td><td align="left" valign="bottom">4.29 mV</td><td align="left" valign="bottom">9.76 mV</td><td align="left" valign="bottom">41.66 mV</td><td align="left" valign="bottom">9.22 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">3.14 pA</td><td align="left" valign="bottom" colspan="3">21.47 pA</td><td align="left" valign="bottom" colspan="3">9.7 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">0.46 mV</td><td align="left" valign="bottom">11.84 mV</td><td align="left" valign="bottom">4.69 mV</td><td align="left" valign="bottom">1.35 mV</td><td align="left" valign="bottom">15.19 mV</td><td align="left" valign="bottom">4.61 mV</td><td align="left" valign="bottom">5.86 mV</td><td align="left" valign="bottom">21.26 mV</td><td align="left" valign="bottom">5.96 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">13.63 pA</td><td align="left" valign="bottom" colspan="3">14.2 pA</td><td align="left" valign="bottom" colspan="3">5.68 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">1.74 mV</td><td align="left" valign="bottom">13.16 mV</td><td align="left" valign="bottom">1.49 mV</td><td align="left" valign="bottom">0.5 mV</td><td align="left" valign="bottom">15.88 mV</td><td align="left" valign="bottom">2.39 mV</td><td align="left" valign="bottom">0.74 mV</td><td align="left" valign="bottom">17.47 mV</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom" colspan="3">24.73 pA</td><td align="left" valign="bottom" colspan="3">9.55 pA</td><td align="left" valign="bottom" colspan="3">14.49 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9">DEMO</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">32.73 mV</td><td align="left" valign="bottom">43.2 mV</td><td align="left" valign="bottom">31.84 mV</td><td align="left" valign="bottom">7.92 mV</td><td align="left" valign="bottom">27.06 mV</td><td align="left" valign="bottom">7.24 mV</td><td align="left" valign="bottom">1.18 mV</td><td align="left" valign="bottom">14.5 mV</td><td align="left" valign="bottom">1.59 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">6.52 pA</td><td align="left" valign="bottom" colspan="3">13.77 pA</td><td align="left" valign="bottom" colspan="3">14.63 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">7.26 mV</td><td align="left" valign="bottom">26.04 mV</td><td align="left" valign="bottom">6.27 mV</td><td align="left" valign="bottom">1.7 mV</td><td align="left" valign="bottom">22.14 mV</td><td align="left" valign="bottom">3.09 mV</td><td align="left" valign="bottom">1.29 mV</td><td align="left" valign="bottom">15.55 mV</td><td align="left" valign="bottom">3.26 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">5.16 pA</td><td align="left" valign="bottom" colspan="3">5.39 pA</td><td align="left" valign="bottom" colspan="3">9.68 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">0.85 mV</td><td align="left" valign="bottom">13.06 mV</td><td align="left" valign="bottom">1.08 mV</td><td align="left" valign="bottom">0.05 mV</td><td align="left" valign="bottom">14.41 mV</td><td align="left" valign="bottom">0.21 mV</td><td align="left" valign="bottom">0.8 mV</td><td align="left" valign="bottom">9.44 mV</td><td align="left" valign="bottom">1.23 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">23.84 pA</td><td align="left" valign="bottom" colspan="3">11.47 pA</td><td align="left" valign="bottom" colspan="3">18.7 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9">NSGA2</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">3.1 mV</td><td align="left" valign="bottom">26.28 mV</td><td align="left" valign="bottom">7.88 mV</td><td align="left" valign="bottom">16.15 mV</td><td align="left" valign="bottom">21.63 mV</td><td align="left" valign="bottom">8.39 mV</td><td align="left" valign="bottom">0.48 mV</td><td align="left" valign="bottom">6.67 mV</td><td align="left" valign="bottom">0.64 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">3.97 pA</td><td align="left" valign="bottom" colspan="3">7.39 pA</td><td align="left" valign="bottom" colspan="3">14.29 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">3.58 mV</td><td align="left" valign="bottom">22.2 mV</td><td align="left" valign="bottom">3.71 mV</td><td align="left" valign="bottom">2.36 mV</td><td align="left" valign="bottom">10.37 mV</td><td align="left" valign="bottom">5.46 mV</td><td align="left" valign="bottom">2.88 mV</td><td align="left" valign="bottom">13.94 mV</td><td align="left" valign="bottom">2.36 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">4.59 pA</td><td align="left" valign="bottom" colspan="3">16.55</td><td align="left" valign="bottom" colspan="3">5.01</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">2.24 mV</td><td align="left" valign="bottom">17.99 mV</td><td align="left" valign="bottom">2.37 mV</td><td align="left" valign="bottom">0.52 mV</td><td align="left" valign="bottom">19.49 mV</td><td align="left" valign="bottom">8.32 mV</td><td align="left" valign="bottom">1.9 mV</td><td align="left" valign="bottom">14.82 mV</td><td align="left" valign="bottom">2.98 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">14.38 pA</td><td align="left" valign="bottom" colspan="3">11.86 pA</td><td align="left" valign="bottom" colspan="3">9.98 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9"><bold>EP-GAN</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">0.33 mV</td><td align="left" valign="bottom">8.23 mV</td><td align="left" valign="bottom">1.52 mV</td><td align="left" valign="bottom">0.19 mV</td><td align="left" valign="bottom">5.74 mV</td><td align="left" valign="bottom">1.22 mV</td><td align="left" valign="bottom">0.18 mV</td><td align="left" valign="bottom">4.02 mV</td><td align="left" valign="bottom">0.49 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">4.03 pA</td><td align="left" valign="bottom" colspan="3">13.8 pA</td><td align="left" valign="bottom" colspan="3">10.29 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">0.66 mV</td><td align="left" valign="bottom">6.41 mV</td><td align="left" valign="bottom">0.55 mV</td><td align="left" valign="bottom">1.66 mV</td><td align="left" valign="bottom">5.07 mV</td><td align="left" valign="bottom">2.82 mV</td><td align="left" valign="bottom">0.74 mV</td><td align="left" valign="bottom">3.77 mV</td><td align="left" valign="bottom">0.59 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">10.7 pA</td><td align="left" valign="bottom" colspan="3">16.84 pA</td><td align="left" valign="bottom" colspan="3">13.8 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">3.15 mV</td><td align="left" valign="bottom">8.66 mV</td><td align="left" valign="bottom">2.87 mV</td><td align="left" valign="bottom">0.04 mV</td><td align="left" valign="bottom">7.23 mV</td><td align="left" valign="bottom">0.33 mV</td><td align="left" valign="bottom">0.66 mV</td><td align="left" valign="bottom">4.71 mV</td><td align="left" valign="bottom">0.72 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">47.97 pA</td><td align="left" valign="bottom" colspan="3">9.64 pA</td><td align="left" valign="bottom" colspan="3">28.86 pA</td></tr></tbody></table></table-wrap><table-wrap id="app1table3" position="float"><label>Appendix 1—table 3.</label><caption><title>Large HH-model root mean square error (RMSE) errors (sample size = 32k) for membrane potential responses and steady-state currents for <italic>predictions on large HH-model scenarios</italic>.</title><p>For each neuron, the top row shows the RMSE errors for three time intervals – pre-activation [4–5s), mid-activation [5–10s], and post-activation (10–11s], and the bottom row shows the RMSE error for steady-state currents across 18 voltage points.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Method</th><th align="left" valign="bottom" colspan="9">Neurons</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="9">GDE3</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">2.31 mV</td><td align="left" valign="bottom">30.01 mV</td><td align="left" valign="bottom">9.71 mV</td><td align="left" valign="bottom">3.08 mV</td><td align="left" valign="bottom">27.0 mV</td><td align="left" valign="bottom">7.54 mV</td><td align="left" valign="bottom">3.4 mV</td><td align="left" valign="bottom">31.0 mV</td><td align="left" valign="bottom">4.09 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">3.15 pA</td><td align="left" valign="bottom" colspan="3">23.53 pA</td><td align="left" valign="bottom" colspan="3">12.75 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">16.88 mV</td><td align="left" valign="bottom">25.85 mV</td><td align="left" valign="bottom">15.51 mV</td><td align="left" valign="bottom">3.79 mV</td><td align="left" valign="bottom">20.27 mV</td><td align="left" valign="bottom">2.97 mV</td><td align="left" valign="bottom">6.54 mV</td><td align="left" valign="bottom">32.36 mV</td><td align="left" valign="bottom">6.61 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">10.24 pA</td><td align="left" valign="bottom" colspan="3">6.32 pA</td><td align="left" valign="bottom" colspan="3">5.99 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">33.71 mV</td><td align="left" valign="bottom">20.5 mV</td><td align="left" valign="bottom">33.86 mV</td><td align="left" valign="bottom">3.8 mV</td><td align="left" valign="bottom">24.56 mV</td><td align="left" valign="bottom">4.14 mV</td><td align="left" valign="bottom">8.05 mV</td><td align="left" valign="bottom">11.58 mV</td><td align="left" valign="bottom">8.04 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">7.85 pA</td><td align="left" valign="bottom" colspan="3">18.08 pA</td><td align="left" valign="bottom" colspan="3">9.55 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9">NSDE</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">27.97 mV</td><td align="left" valign="bottom">40.68 mV</td><td align="left" valign="bottom">25.98 mV</td><td align="left" valign="bottom">13.33 mV</td><td align="left" valign="bottom">30.91 mV</td><td align="left" valign="bottom">12.46 mV</td><td align="left" valign="bottom">5.03 mV</td><td align="left" valign="bottom">15.31 mV</td><td align="left" valign="bottom">5.73 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">7.75 pA</td><td align="left" valign="bottom" colspan="3">8.03 pA</td><td align="left" valign="bottom" colspan="3">9.58 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">6.81 mV</td><td align="left" valign="bottom">22.46 mV</td><td align="left" valign="bottom">7.05 mV</td><td align="left" valign="bottom">0.19 mV</td><td align="left" valign="bottom">21.14 mV</td><td align="left" valign="bottom">4.45 mV</td><td align="left" valign="bottom">24.54 mV</td><td align="left" valign="bottom">22.72 mV</td><td align="left" valign="bottom">24.22 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">6.82 pA</td><td align="left" valign="bottom" colspan="3">5.06 pA</td><td align="left" valign="bottom" colspan="3">4.17 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">24.96 mV</td><td align="left" valign="bottom">2.09 mV</td><td align="left" valign="bottom">18.19 mV</td><td align="left" valign="bottom">31.41 mV</td><td align="left" valign="bottom">21.6 mV</td><td align="left" valign="bottom">28.39 mV</td><td align="left" valign="bottom">12.25 mV</td><td align="left" valign="bottom">22.77 mV</td><td align="left" valign="bottom">13.38 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">14.73 pA</td><td align="left" valign="bottom" colspan="3">7.24 pA</td><td align="left" valign="bottom" colspan="3">6.18 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9">DEMO</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">8.91 mV</td><td align="left" valign="bottom">63.94 mV</td><td align="left" valign="bottom">11.11 mV</td><td align="left" valign="bottom">16.01 mV</td><td align="left" valign="bottom">21.32 mV</td><td align="left" valign="bottom">15.96 mV</td><td align="left" valign="bottom">11.8 mV</td><td align="left" valign="bottom">26.0 mV</td><td align="left" valign="bottom">12.11 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">7.57 pA</td><td align="left" valign="bottom" colspan="3">11.89 pA</td><td align="left" valign="bottom" colspan="3">21.4 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">1.46 mV</td><td align="left" valign="bottom">25.9 mV</td><td align="left" valign="bottom">3.21 mV</td><td align="left" valign="bottom">23.15 mV</td><td align="left" valign="bottom">18.16 mV</td><td align="left" valign="bottom">27.24 mV</td><td align="left" valign="bottom">19.32 mV</td><td align="left" valign="bottom">15.3 mV</td><td align="left" valign="bottom">19.8 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">7.24 pA</td><td align="left" valign="bottom" colspan="3">11.14 pA</td><td align="left" valign="bottom" colspan="3">6.81 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">2.29 mV</td><td align="left" valign="bottom">11.92 mV</td><td align="left" valign="bottom">3.79 mV</td><td align="left" valign="bottom">7.0 mV</td><td align="left" valign="bottom">24.03 mV</td><td align="left" valign="bottom">8.3 mV</td><td align="left" valign="bottom">1.03 mV</td><td align="left" valign="bottom">10.97 mV</td><td align="left" valign="bottom">3.22 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">18.17 pA</td><td align="left" valign="bottom" colspan="3">11.9 pA</td><td align="left" valign="bottom" colspan="3">30.85 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9">NSGA2</td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">3.58 mV</td><td align="left" valign="bottom">32.89 mV</td><td align="left" valign="bottom">3.63 mV</td><td align="left" valign="bottom">7.55 mV</td><td align="left" valign="bottom">33.6 mV</td><td align="left" valign="bottom">7.06 mV</td><td align="left" valign="bottom">31.5 mV</td><td align="left" valign="bottom">24.36 mV</td><td align="left" valign="bottom">31.81 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">6.57 pA</td><td align="left" valign="bottom" colspan="3">7.63 pA</td><td align="left" valign="bottom" colspan="3">5.75 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">0.38 mV</td><td align="left" valign="bottom">14.99 mV</td><td align="left" valign="bottom">18.39 mV</td><td align="left" valign="bottom">3.61 mV</td><td align="left" valign="bottom">20.4 mV</td><td align="left" valign="bottom">1.87 mV</td><td align="left" valign="bottom">11.87 mV</td><td align="left" valign="bottom">17.09 mV</td><td align="left" valign="bottom">11.45 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">8.68 pA</td><td align="left" valign="bottom" colspan="3">5.13 pA</td><td align="left" valign="bottom" colspan="3">2.74 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">0.8 mV</td><td align="left" valign="bottom">22.68 mV</td><td align="left" valign="bottom">1.14 mV</td><td align="left" valign="bottom">1.14 mV</td><td align="left" valign="bottom">30.38 mV</td><td align="left" valign="bottom">2.11 mV</td><td align="left" valign="bottom">5.12 mV</td><td align="left" valign="bottom">32.47 mV</td><td align="left" valign="bottom">3.17 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">24.07 pA</td><td align="left" valign="bottom" colspan="3">10.9 pA</td><td align="left" valign="bottom" colspan="3">7.55 pA</td></tr><tr><td align="left" valign="bottom" rowspan="9"><bold>EP-GAN</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIM</bold></td><td align="left" valign="bottom" colspan="3"><bold>DVC</bold></td><td align="left" valign="bottom" colspan="3"><bold>HSN</bold></td></tr><tr><td align="left" valign="bottom">0.24 mV</td><td align="left" valign="bottom">7.78 mV</td><td align="left" valign="bottom">1.65 mV</td><td align="left" valign="bottom">0.30 mV</td><td align="left" valign="bottom">5.90 mV</td><td align="left" valign="bottom">1.39 mV</td><td align="left" valign="bottom">0.46 mV</td><td align="left" valign="bottom">6.62 mV</td><td align="left" valign="bottom">2.02 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">3.21 pA</td><td align="left" valign="bottom" colspan="3">12.35 pA</td><td align="left" valign="bottom" colspan="3">17.44 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AIY</bold></td><td align="left" valign="bottom" colspan="3"><bold>URX</bold></td><td align="left" valign="bottom" colspan="3"><bold>RIS</bold></td></tr><tr><td align="left" valign="bottom">0.43 mV</td><td align="left" valign="bottom">6.57 mV</td><td align="left" valign="bottom">1.12 mV</td><td align="left" valign="bottom">0.74 mV</td><td align="left" valign="bottom">4.58 mV</td><td align="left" valign="bottom">3.78 mV</td><td align="left" valign="bottom">0.27 mV</td><td align="left" valign="bottom">3.42 mV</td><td align="left" valign="bottom">1.78 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">10.52 pA</td><td align="left" valign="bottom" colspan="3">36.64 pA</td><td align="left" valign="bottom" colspan="3">21.86 pA</td></tr><tr><td align="left" valign="bottom" colspan="3"><bold>AFD</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWB</bold></td><td align="left" valign="bottom" colspan="3"><bold>AWC</bold></td></tr><tr><td align="left" valign="bottom">1.68 mV</td><td align="left" valign="bottom">9.99 mV</td><td align="left" valign="bottom">1.86 mV</td><td align="left" valign="bottom">0.37 mV</td><td align="left" valign="bottom">7.24 mV</td><td align="left" valign="bottom">0.31 mV</td><td align="left" valign="bottom">0.57 mV</td><td align="left" valign="bottom">4.93 mV</td><td align="left" valign="bottom">0.84 mV</td></tr><tr><td align="left" valign="bottom" colspan="3">43.20 pA</td><td align="left" valign="bottom" colspan="3">9.27 pA</td><td align="left" valign="bottom" colspan="3">8.35 pA</td></tr></tbody></table></table-wrap></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95607.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>National Centre for Biological Sciences</institution><country>India</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This study is a <bold>valuable</bold> contribution to the field of neuronal modeling by way of providing a method for rapidly obtaining neuronal physiology parameters from electrophysiological recordings. The method is <bold>solid</bold> as the generated models reproduce both ground-truth simulated data and empirical data, and there is now a quantitative comparison with other approaches.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95607.4.sa1</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Developing biophysically detailed computational models that accurately capture the characteristic physiological properties of neurons across diverse cell types is a key challenge in computational neuroscience. A major obstacle lies in determining the large number of model parameters, which are notoriously difficult to fit such that the model faithfully reproduces the empirically observed electrophysiological responses. Existing approaches require substantial computational resources to generate models for even a single neuron. Generating models for additional neurons typically requires starting from scratch, with no reuse of previous computations - making the process just as computationally expensive each time.</p><p>Kim et al. introduce an innovative approach based on a Generative Adversarial Network (GAN) to overcome these limitations. Once trained, the network takes empirically observed electrophysiological responses as input and predicts the biophysical parameters with which a Hodgkin-Huxley model can reproduce these responses. The authors demonstrate this for nine non-spiking neurons in <italic>C. elegans</italic>. The resulting models generally provide a good fit to the empirical data. As the GAN has learned general relationships between biophysical parameters and the resulting electrophysiology, it can be used to generate models of diverse cell types without retraining - enabling model generation at low computational cost.</p><p>Strengths:</p><p>The authors address an important and technically challenging problem. A noteworthy strength of their approach is that, once trained, the GAN can generate models from new empirical data at low computational cost. The generated models reproduce the responses to current injections well.</p><p>The authors have addressed all of my previous major concerns and have significantly improved their method:</p><p>(1) Most importantly, the generated models reproduce both ground-truth simulated and empirical data well. Responses - including resting membrane potentials - are now well captured.</p><p>(2) The comparison with other approaches has been extended to be more quantitative and rigorous.</p><p>(3) The authors now convincingly demonstrate that the improved EP-GAN is relatively robust to data ablation.</p><p>Weaknesses:</p><p>Slow dynamics (e.g., slow ramps) are still not reliably captured. However, as the approach excels at other frontiers - the generation of models for diverse cell types at low computational cost - I consider this to be a relatively minor limitation.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95607.4.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kim</surname><given-names>Jimin</given-names></name><role specific-use="author">Author</role><aff><institution>University of Washington</institution><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Peng</surname><given-names>Minxian</given-names></name><role specific-use="author">Author</role><aff><institution>City University of Hong Kong</institution><addr-line><named-content content-type="city">Kowloon</named-content></addr-line><country>Hong Kong</country></aff></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Shuqi</given-names></name><role specific-use="author">Author</role><aff><institution>City University of Hong Kong</institution><addr-line><named-content content-type="city">Kowloon</named-content></addr-line><country>Hong Kong</country></aff></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Qiang</given-names></name><role specific-use="author">Author</role><aff><institution>City University of Hong Kong</institution><addr-line><named-content content-type="city">Kowloon</named-content></addr-line><country>Hong Kong</country></aff></contrib><contrib contrib-type="author"><name><surname>Shlizerman</surname><given-names>Eli</given-names></name><role specific-use="author">Author</role><aff><institution>University of Washington</institution><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public review):</bold></p><p>(1) The bad equilibria of the model still remain a concern, as well as other features like the transient overshoots that do not match with the data. I think they could achieve more accuracy here by assigning more weight to such specific features, through adding these as separate objectives for the generator explicitly. The traces contain a five-second current steps, and one second before and one second after the training step. This means that in the RMSE, the current step amplitude will dominate as a feature, as this is simply the state for which the data trace contains most time-points. Note that this is further exacerbated by using the IV curve as an auxiliary objective. I believe a better exploration of specific response features, incorporated as independently weighted loss terms for the generator, could improve the fit. E.g. an auxiliary term could be the equilibrium before and after the current step, another term could penalise response traces that do not converge back to their initial equilibrium, etc.</p></disp-quote><p>We thank the reviewer for the suggestion. We supplemented the membrane potential regression loss with errors computed for 3 intervals: pre- post- and mid- stimulation time intervals, improving the accuracy of EP-GAN for baseline membrane potential responses (Figure 2, 3, Table S2, S3). We also changed the simulation protocols for generated parameters by allowing a longer simulation time of 15 seconds, where the stimulation is applied during [5, 10] seconds and no stimulation at t = [0, 5) (pre-stimulation) and t = (10, 15] (post-stimulation). These time intervals are chosen to ensure sufficient stabilization periods before and after stimulation.</p><disp-quote content-type="editor-comment"><p>(2) The explanation of what the authors mean with 'inverse gradient operation' is clear now. However, this term is mathematically imprecise, as the inverse gradient does not exist because the gradient operator is not injective. The method is simply forward integration under the assumption that the derivate of the voltage is known at the grid time-points, and should be described as such.</p></disp-quote><p>We thank the reviewer for the clarification on inverse gradient operation terminology. In the Methods section, we changed the term describing the inverse gradient operation to ‘forward integration’ which is a more accurate description describing the process.</p><disp-quote content-type="editor-comment"><p>(3) I appreciate that the authors' method provides parameters of models at a minimal computational cost compared to running an evolutionary optimization for every new recording. I also believe that with some tweaking of the objective, the method could improve in accuracy. However, I share reviewer 2's concerns that the evolutionary baseline methods are not sufficiently explored, as these methods have been used to successfully fit considerably more complex response patterns. One way out of the dilemma is to show that the EP-GAN estimated parameters provide an initial guess that considerably narrows the search space for the evolutionary algorithm. In this context, the authors should also discuss the recent gradient based methods such as Deistler et al. (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2024.08.21.608979">https://doi.org/10.1101/2024.08.21.608979</ext-link>) or Jones et al (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.48550/arXiv.2407.04025">https://doi.org/10.48550/arXiv.2407.04025</ext-link>).</p></disp-quote><p>We supplemented the optimization setup for existing methods (GDE3, NSDE, DEMO, and NSGA2) by incorporating steady-state response constraints as the initial selection process. The process is similar to that of EP-GAN training data generation and DEMO parameter selection process [16] (see Results section, page 6 for detail). We also expanded the testing scenarios by evaluating all methods with respect to both small and large HH-model estimation. The small HH-model scenario estimates 47 parameters consisting of channel conductance, reversal potentials and initial conditions with the channel parameters (n = 129) frozen to default values in [41]. Large HH-model includes estimating channel parameters (i.e. 129) in addition to the 47 parameters by considering +-50% variations from their default values. For both small and large HH-model scenarios, we test total sample sizes of both 32k and 64k for all methods to evaluate their scalability with the number of simulated samples given during optimization. The results show that existing methods show good performances for small HH-model scenarios that scale with sample size consistent with literature. EP-GAN on the other hand shows overall better performance in predicting membrane potential responses on both small and large HH-model scenarios.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Major 1: Models do not faithfully capture empirical responses. While the models generated with EPGAN reproduce the average voltage during current injections reasonably well, the dynamics of the response are generally not well captured. For example, for the neuron labeled RIM (Figure 2), the most depolarized voltage traces show an initial 'overshoot' of depolarization, i.e. they depolarize strongly within the first few hundred milliseconds but then fall back to a less depolarized membrane potential. In contrast, the empirical recording shows no such overshoot. Similarly, for the neuron labeled AFD, all empirically recorded traces slowly ramp up over time. In contrast, the simulated traces are mostly flat. Furthermore, all empirical traces return to the pre-stimulus membrane potential, but many of the simulated voltage traces remain significantly depolarized, far outside of the ranges of empirically observed membrane potentials. The authors trained an additional GAN (EPGAN Extended) to improve the fit to the resting membrane potential. Interestingly, for one neuron (AWB), this improved the response during stimulation, which now reproduced the slowly raising membrane potentials observed empirically, however, the neuron still does not reliably return to its resting membrane potential. For the other two neurons, the authors report a decrease in accuracy in comparison to EP-GAN. While such deviations may appear small in the Root mean Square Error (RMSE), they likely indicate a large mismatch between the model and the electrophysiological properties of the biological neuron. The authors added a second metric during the revision - percentages of predicted membrane potential trajectories within empirical range. I appreciate this additional analysis. As the empirical ranges across neurons are far larger than the magnitude of dynamical properties of the response ('slow ramps', etc.), this metric doesn't seem to be well suited to quantify to which degree these dynamical properties are captured by the models.</p></disp-quote><p>We made improvements to the training data generation and architecture of EP-GAN to improve its overall accuracy with predicted membrane potential responses. In particular, we divided training data generation into three neuron types found in <italic>C. elegans</italic> non-spiking neurons: (1) Transient outward rectifier, (2) Outward rectifier and (3) Bistable [8, 16]. Each randomly generated training sample is categorized into one of 3 types by evaluating its steady-state currents with respect to experimental dI/dV bound constraints (See generating training data section under Methods for more detail). The process is then followed by imposing minimum-maximum constraints on simulated membrane potential responses. The setup allows generations of training samples that are of closer distribution to experimentally recorded neurons. This is further described in Section Methods page 15 in the revised manuscript.</p><p>We also improved the EP-GAN training process by incorporating random masking of input membrane potential responses. The masking forces EP-GAN to make predictions even with missing voltage traces, improving overall accuracy and allowing EP-GAN to use membrane potential inputs with arbitrary clamping protocol (see Methods page 13 for more detail). For the training loss functions, we further supplemented the membrane potential regression loss with errors computed for 2 intervals: pre- and post-stimulation time intervals to improve EP-GAN prediction capabilities for baseline membrane potentials.</p><p>Taken together, these modifications improved EP-GAN’s overall ability to better capture empirical membrane potential responses and we show the results in Figure 2 – 5, Table S2, S3.</p><disp-quote content-type="editor-comment"><p>Major 2: Comparison with other approaches is potentially misleading. Throughout the manuscript, the authors claim that their approach outperforms the other approaches tested. But compare the responses of the models in the present manuscript (neurons RIM, AFD, AIY) to the ones provided for the same neurons in Naudin et al. 2022 (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal">https://doi.org/10.1371/journal</ext-link>. pone.0268380). Naudin et al. present models that seem to match empirical data far more accurately than any model presented in the current study. Naudin et al. achieved this using DEMO, an algorithm that in the present manuscript is consistently shown to be among the worst of all algorithms tested. I therefore strongly disagree with the authors claim that a &quot;Comparison of EP-GAN with existing estimation methods shows EP-GAN advantage in the accuracy of estimated parameters&quot;. This may be true in the context of the benchmark performed in the study (i.e., a condition of very limited compute resources - 18 generations with a population size of 600, compare that to 2000 generations recommended in Naudin et al.), but while EP-GAN wins under these specific conditions (and yes, here the authors convincingly show that their EP-GAN produces by far the best results!), other approaches seem to win with respect to the quality of the models they can ultimately generate.</p></disp-quote><p>We thank the reviewer for the feedback regarding the comparison with existing methods. We have revised the optimization setup for existing methods (GDE3, NSDE, DEMO, and NSGA2) by incorporating steady-state response constraints as the initial selection process. The process is similar to that of EP-GAN training data generation and DEMO parameter selection process [16] (see Results section, page 6 for detail). Incorporating this process has improved the accuracy of existing methods especially for small HH-model scenarios where DEMO stood out with the best performance alongside NSGA2 (Figure 5, Table 1, 2).</p><p>We also expanded the testing scenarios by evaluating all methods with respect to both small and large HH-model estimation. The small HH-model scenario estimates 47 parameters consisting of channel conductance, reversal potentials and initial conditions with the channel parameters (n = 129) frozen to default values in [41]. Large HH-model includes estimating channel parameters (i.e. 129) in addition to the 47 parameters by considering +-50% variations from their default values. For both small and large HH-model scenarios, we test total sample sizes of both 32k and 64k for all methods to evaluate their scalability with the number of simulated samples given during optimization. The results show that existing methods show good performances for small HH-model scenarios that scale with sample size. EP-GAN on the other hand shows overall better performance in predicting membrane potential responses on both small and large HH-model scenarios.</p><p>In particular, with extended membrane potential error including pre-, mid- , post-activation periods, EP-GAN (trained with 32k samples, large HH-model, 9 neurons) mean membrane potential responses error of 2.82mV was lower than that of DEMO (12.2mV, 64k samples) trained on identical setup (Table 2) and DEMO (7.78mV, using 36,000k samples, 3 neurons) applied to simpler HHmodel in [16]. With respect to DEMO performance in [16], under identical simulation protocol (i.e., no stimulation during (0, 5s), (10, 15s) and stimulation during (5, 10s)), EP-GAN predicted RIM (large HH-model) showed membrane potential accuracy on par with that of DEMO (simpler HH-model) and EP-GAN predicted AFD showed better accuracy for post-activation membrane potential response where DEMO predicted membrane potentials overshoot above the baseline (not shown in the paper).</p><disp-quote content-type="editor-comment"><p>Major 3: As long as the quality of the models generated by the EP-GAN cannot be significantly improved, I am doubtful that it indeed can contribute to the 'ElectroPhysiome', as it seems likely that dynamics that are currently poorly captured, like slow ramps, or the ability of the neuron to return to its resting membrane potential, will critically affect network computations. If the authors want to motivate their study based on this very ambitious goal, they should illustrate that single neuron model generation with their approach is robust enough to warrant well-constrained network dynamics. Based on the currently presented results, I find the framing of the manuscript far too bold.</p></disp-quote><p>We thank the reviewer for the feedback regarding the paper's scope. With revised methods, the overall quality of EP-GAN models is improved with the most significant improvements in baseline membrane potential accuracy. While high quality neuron models could be attained with existing methods given sufficient sample size, our results suggest EP-GAN can predict models with enhanced quality with significantly fewer sample size without a need for retraining, thus complementing the main drawback of evolutionary based methods. While EP-GAN still has limitations (e.g., difficulty in predicting slow ramps) that need to be addressed in the future, we believe its overall performance combined with fast inference speed and flexibility in its input data format (e.g., missing membrane potential traces) is a step forward in the large-scale neuron modeling tasks that can contribute to network models.</p><disp-quote content-type="editor-comment"><p>Major 4: The conclusion of the ablation study 'In addition the architecture of EP-GAN permits inference of parameters even when partial membrane potential and steady-state currents profile are given as inputs' does not seem to be justified given the voltage traces shown in Figure 3. For example, for RIM, the resting membrane potential stays around 0 mV, but all empirical traces are around -40mV. For AFD, all simulated traces have a negative slope during the depolarizing stimuli, but a positive slope in all empirically observed traces. For AIY, the shape of hyperpolarized traces is off. While it may be that by their metric neurons in the 25% category are classified as 'preserving baseline accuracy', this doesn't seem justified given the voltage traces presented in the manuscript. It appears the metric is not strict enough.</p></disp-quote><p>We improved EP-GAN’s training process by incorporating random masking of input membrane potential responses. The masking forces EP-GAN to make predictions even with missing voltage traces, improving overall accuracy and allowing EP-GAN to use membrane potential inputs with arbitrary clamping protocol.</p><p>Such input masking during training has improved the results with ablation studies where EP-GAN now retains baseline membrane potential error (3.3mV, averaged across pre-, mid-, post-activation periods) up to 50% of membrane potential inputs remaining (3.5mV) and up to 25% of steady-state currents remaining (3.5mV).</p></body></sub-article></article>