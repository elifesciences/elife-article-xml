<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="discussion" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">eLife</journal-id><journal-id journal-id-type="hwp">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">00452</article-id><article-id pub-id-type="doi">10.7554/eLife.00452</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Feature Article</subject></subj-group><subj-group subj-group-type="sub-display-channel"><subject>Point Of View</subject></subj-group></article-categories><title-group><article-title>Faculty appointments and the record of scholarship</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-3354"><name><surname>Brand</surname><given-names>Amy</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4208-1000</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="conf1"/><aff id="aff1"><x> is Assistant Provost for Faculty Appointments and Information at </x><institution>Harvard University</institution><x>, where she manages the review of faculty appointments University-wide. Her career spans academia, publishing and scholarly communication technologies. She was program manager of the Harvard Office for Scholarly Communication from 2008 to 2009, and before that held long-term positions as an executive editor at the MIT Press, and as director of business and product development at CrossRef. She is also on the board of directors for ORCID.</x><email>amy_brand@harvard.edu</email></aff></contrib></contrib-group><pub-date date-type="pub" publication-format="electronic"><day>08</day><month>01</month><year>2013</year></pub-date><pub-date pub-type="collection"><year>2013</year></pub-date><volume>2</volume><elocation-id>e00452</elocation-id><permissions><copyright-statement>© 2013, Brand</copyright-statement><copyright-year>2013</copyright-year><copyright-holder>Brand</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/3.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-00452-v1.pdf"/><abstract><p>Academic review committees would benefit from more details about the contributions made by individual researchers to papers with multiple authors, and also from more information about other types of scholarly communication.</p></abstract><kwd-group kwd-group-type="author-keywords"><title>Author keywords</title><kwd>Point of view</kwd><kwd>publishing</kwd><kwd>academic career</kwd><kwd>contributorship</kwd><kwd>ORCID</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>elife-xml-version</meta-name><meta-value>2</meta-value></custom-meta></custom-meta-group></article-meta></front><body><p>Have you noticed that conversations about scholarly communication and academic careers often conclude with someone saying: ‘Well, until university provosts flip the switch and start taking papers in open-access journals, the publication of data and code, digital monographs and so on into account when making decisions about promotion and tenure, traditional publications and metrics will continue to hold us all hostage’?</p><p>I have lost count of the number of times I've heard arguments to this effect at academic library and publishing conferences, and I confess it is part of what drew me toward my current post as assistant provost for faculty appointments and information at Harvard. If the provost's office is where change in the dissemination of scholarship can be ignited, that's where I want to be.</p><p>With a few years of first-hand experience in the administration of faculty appointments under my belt, I can report back—from the inside, as it were—that there is no such switch. It is much more complicated than a consensus on the part of university provosts to expand the set of works and measures that constitute solid evidence of academic distinction. That said, there is growing awareness that the search and review committees that appoint and promote academic staff have traditionally relied on information sources that may fail to portray the full picture. This is especially true when the candidate's key contributions are not published in book or journal form, or when he/she publishes mainly or exclusively co-authored works.</p><sec id="s1"><title>The importance of peers</title><p>It would be imprudent to generalize about Harvard's criteria for the appointment and promotion of faculty since the policies and procedures of the different Schools within the University all differ to a degree. And as Richard Zare, former chair of the chemistry department at Stanford University, described in a recent article (<xref ref-type="bibr" rid="bib6">Zare, 2012</xref>), elite research institutions in the United States, seemingly unlike most of the world's universities, are not overly dependent on citation-based measures of impact such as impact factors for journals or h-indices for individuals. Rather, their appointment processes are time-intensive, more qualitative than quantitative or formulaic, and rely most heavily on peer review (both internal and external) to identify excellence. This type of peer review involves collecting confidential letters from a well-chosen set of peers: the purpose of these letters is to help academic review committees assemble a robust qualitative picture of a scholar's originality, independence, intellectual leadership and potential for future productivity and impact.</p><p>In 2010, <italic>Nature</italic> carried out a survey in which it asked readers about the use of metrics in decisions about new hires and tenure (<xref ref-type="bibr" rid="bib1">Abbott et al., 2010</xref>). Three-quarters of the 150 readers who replied thought that metrics were being used in hiring decisions. However, provosts and other administrators contacted by <italic>Nature</italic> painted a different picture: ‘Metrics are not used a great deal,’ said Alex Halliday, head of the mathematical, physical and life sciences division at Oxford University. ‘The most important things are the letters, the interview and the CV, and our opinions of the papers published.’ Claude Canizares, vice president for research and associate provost at the Massachusetts Institute of Technology, had a similar message: ‘We pay very little attention, almost zero, to citation indices and counting numbers of publications’.</p><p>While the letters that inform faculty appointments usually succeed in bringing the key considerations to light, I believe we could make the work of search and review committees easier and more reliable if we enhanced our sources of information about scholarship and contribution in ways that I describe below.<disp-quote><p>We could make the work of search and review committees easier and more reliable if we enhanced our sources of information about scholarship and contribution.</p></disp-quote></p></sec><sec id="s2"><title>A broader record of scholarship</title><p>When a scholar's portfolio includes works outside of the published record of books, journal articles and conference proceedings, search and review committees often have to dig deeper to gauge the academic impact of those works. In the visual arts, for example, they may consult exhibition histories and published critiques, in addition to external reviews from a wider set of peers that might include curators and fellow artists. In the sciences, a candidate may have contributed meaningfully to his or her field by making data or software code widely available. In such cases, there is no choice at present but to rely on peer testimony to weigh the significance of the contribution.</p><p>Researchers and review committees alike would benefit greatly from the development of standards for the identification and citation of an extended set of scholarly works including data, software and code, multimedia and internet communications, so that such contributions are more readily integrated into our evolving digital scholarly ecosystem. The just-launched ORCID network [<ext-link ext-link-type="uri" xlink:href="http://www.orcid.org">http://www.orcid.org</ext-link>], which aims to provide every researcher in the world with a unique identifier linked to academic outputs and activities (see <xref ref-type="fig" rid="fig1">Figure 1</xref>), may provide a new way for scholars to associate themselves within this ecosystem with a wider array of scholarly contributions. In the sciences, standard methods for citing data and attributing credit for the generation of quantitative data are near-term priorities (<xref ref-type="bibr" rid="bib2">Altman and King, 2007</xref>; <xref ref-type="bibr" rid="bib5">National Research Council, 2012</xref>).<fig id="fig1" position="float"><label>Figure 1.</label><caption><p>The ORCID (Open Researcher and Contributor ID) initiative aims to provide every researcher in the world with a unique identifier linked to his or her academic outputs and activities. This figure shows Amy Brand's ORCID page.</p></caption><graphic xlink:href="elife-00452-fig1-v1.tif"/></fig></p></sec><sec id="s3"><title>Contributorship versus authorship</title><p>For the purposes of academic review, the traditional publication list is especially problematic when it comes to scholars with many multi-authored works. This is because author lists don't provide clear information about who contributed what in large-scale research and writing collaborations, which are increasingly common in the physical and life sciences. Author lists take a complex network of collaboration and effectively reduce it to a one-dimensional information source, where all we have to go by is order of names to convey author role and rank. Different fields of scholarship have adopted different practices around author order, but middle authors are always at the greatest risk of losing out on attribution and credit because their <italic>perceived</italic> contribution is diminished relative to first and last authors in collaborative works. In fields that list author names in journal articles alphabetically, such as economics, it has even been observed that you are more likely to get tenured in a top department if your surname begins with a letter earlier in the alphabet (<xref ref-type="bibr" rid="bib3">Einav and Yariv, 2006</xref>). The unintended consequences of our authorship practices are far from benign for researchers and for science.</p><p>There is growing interest among researchers, funding agencies, academic institutions, editors and publishers in increasing the transparency of research contributions, and in more fine-grained tracking of attribution and associated credit. Many publishers now require contribution disclosures upon article submission—some in structured form, some in free-text form. There is now a clear need for a standard vocabulary of contributor roles that captures what each named author contributed to a particular publication—for example, conceptual framework, methodological design, data collection, data curation, experimental procedures, programming, software, statistical analysis, investigation, instrumentation, writing, illustration, project management, funding, laboratory head and so on. With the development of contributor role vocabularies and tagging mechanisms, the review committee of the future reading a tenure application from, say, a biostatistician who is usually a middle author in multi-authored works, will more readily be able to detect that the individual consistently contributes innovative methodologies to his or her research collaborations (<xref ref-type="bibr" rid="bib4">IWCSA, 2012</xref>).</p><p>Imagine how the academic appointment process might change if search and review committees had access—within an appropriately tagged or linked online CV, for example, or via the ORCID system—to information about the specific contributions made by a candidate to each of his/her works, including contributions that might not otherwise have qualified for ‘authorship’ status? While a future scheme of standardized contributor roles integrated with the ORCID identifier system may lead to the development of new quantitative metrics, I am much more interested in having more precise information about researcher contribution made transparent in our information resources. On-going developments in academic publishing, along with the semantic capabilities of the web, should make this possible before too long.</p></sec></body><back><fn-group content-type="competing-interest"><fn fn-type="conflict" id="conf1"><label>Competing interests:</label><p>The author declares that no competing interests exist</p></fn></fn-group><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>A</given-names></name><etal/></person-group><year>2010</year><article-title>Do metrics matter?</article-title><source>Nature</source><volume>465</volume><fpage>860</fpage><lpage>862</lpage><pub-id pub-id-type="doi">10.1038/465860a</pub-id><ext-link ext-link-type="uri" xlink:href="http://www.nature.com/nature/newspdf/metrics_survey.pdf">http://www.nature.com/nature/newspdf/metrics_survey.pdf</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altman</surname><given-names>M</given-names></name><name><surname>King</surname><given-names>G</given-names></name></person-group><year>2007</year><article-title>A proposed standard for the citation of quantitative data</article-title><source>D-Lib Magazine</source><volume>13</volume><pub-id pub-id-type="doi">10.1045/march2007-altman</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Einav</surname><given-names>L</given-names></name><name><surname>Yariv</surname><given-names>L</given-names></name></person-group><year>2006</year><article-title>What's in a surname? The effects of surname initials on academic success</article-title><source>J Economic Perspectives</source><volume>20</volume><fpage>175</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1257/089533006776526085</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="book"><person-group person-group-type="author"><collab>IWCSA Report</collab></person-group><year>2012</year><source>Report on the International Workshop on Contributorship and Scholarly Attribution, May 16, 2012</source><publisher-name>Harvard University and the Wellcome Trust</publisher-name><ext-link ext-link-type="uri" xlink:href="http://projects.iq.harvard.edu/attribution_workshop">http://projects.iq.harvard.edu/attribution_workshop</ext-link></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><collab>National Research Council</collab></person-group><year>2012</year><source>For Attribution – Developing Data Attribution and Citation Practices and Standards: Summary of an International Workshop</source><publisher-name>The National Academies Press</publisher-name><publisher-loc>Washington, DC</publisher-loc><ext-link ext-link-type="uri" xlink:href="http://www.nap.edu/catalog.php?record_id=13564">http://www.nap.edu/catalog.php?record_id=13564</ext-link></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zare</surname><given-names>RN</given-names></name></person-group><year>2012</year><article-title>Assessing academic researchers</article-title><source>Angew Chemie Intl Edn</source><volume>51</volume><fpage>7338</fpage><lpage>7339</lpage><pub-id pub-id-type="doi">10.1002/anie.201201011</pub-id></element-citation></ref></ref-list></back></article>