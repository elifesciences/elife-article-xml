<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">99997</article-id>
<article-id pub-id-type="doi">10.7554/eLife.99997</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99997.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Tripartite organization of brain state dynamics underlying spoken narrative comprehension</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1448-9009</contrib-id>
<name>
<surname>Lanfang</surname>
<given-names>Liu</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6335-391X</contrib-id>
<name>
<surname>Jiahao</surname>
<given-names>Jiang</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Hehui</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Ding</surname>
<given-names>Guosheng</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<email>dinggsh@bnu.edu.cn</email>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, School of Arts and Sciences, Beijing Normal University at Zhuhai</institution>, <city>Zhuhai</city>, <country>China</country>;</aff>
<aff id="a2"><label>2</label><institution>Center for Cognition and Neuroergonomics, State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University at Zhuhai</institution>, <city>Zhuhai</city>, <country>China</country>;</aff>
<aff id="a3"><label>3</label><institution>State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University &amp; IDG/McGovern Institute for Brain Research</institution>, <city>Beijing</city>, <country>China</country>;</aff>
<aff id="a4"><label>4</label><institution>Center for Brain Disorders and Cognitive Sciences, Shenzhen University</institution>, <city>Shenzhen</city> <country>China</country>;</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Martin</surname>
<given-names>Andrea E</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Psycholinguistics</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Shinn-Cunningham</surname>
<given-names>Barbara G</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Carnegie Mellon University</institution>
</institution-wrap>
<city>Pittsburgh</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-10-08">
<day>08</day>
<month>10</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP99997</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-06-12">
<day>12</day>
<month>06</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-13">
<day>13</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.06.13.598625"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Lanfang et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Lanfang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-99997-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Speech comprehension involves the dynamic interplay of multiple cognitive processes, from basic sound perception, to linguistic encoding, and finally to complex semantic-conceptual interpretations. How the brain handles the diverse streams of information processing remains poorly understood. Applying Hidden Markov Modeling to fMRI data obtained during spoken narrative comprehension, we reveal that the whole brain networks predominantly oscillate within a tripartite latent state space. These states are respectively characterized by high activities in the sensory-motor (State #1), bilateral temporal (State #2), and DMN (State #3) regions, with State #2 acting as a transitional hub. The three states are selectively modulated by the acoustic, word-level semantic and clause-level semantic properties of the narrative. Moreover, the alignment with the best performer in brain state expression can predict participants’ narrative comprehension scores. These results are reproducible with different brain network atlas and generalizable to two independent datasets consisting of young and older adults. Our study suggests that the brain underlies narrative comprehension by switching through a tripartite state space, with each state probably dedicated to a specific component of language faculty, and effective narrative comprehension relies on engaging those states in a timely manner.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>When listening to a speech, one adaptively samples information from external sound streams, converting them to linguistic expressions stored in the mental lexicon, and integrating those mental expressions with the internalized “mental world” to infer the semantic-pragmatic interpretations and intentions (<xref ref-type="bibr" rid="c3">Berwick, Friederici, Chomsky, &amp; Bolhuis, 2013</xref>). Crucially, those cognitive processes do not occur one after another in a fixed sequence, but are interwoven and occur in a fluid, dynamic manner. At one moment, you might detect the auditory cues such as volume and pitch in the speech. At another, you might recall memories or knowledge in relation to certain words just heard. To effectively understand the speech, you must flexibly and adaptively switch among those cognitive processes. The neural mechanism behind it is still elusive.</p>
<p>An emerging view suggests that flexible and adaptive cognitive functions arise from the dynamic brain which transiently activates and coordinates distributed neural circuits in response to the changes in external environment and internal demands (<xref ref-type="bibr" rid="c12">Honey, Newman, &amp; Schapiro, 2018</xref>; <xref ref-type="bibr" rid="c15">Kelso, 2012</xref>). To capture the complex neural dynamics occurring across large-scale systems of the brain, researchers have conceptualized the brain’s activity as operating on a low-dimensional neural manifold. The dynamics of brain activity can then be modeled as a temporal trajectory within a latent state space, with each latent state characterized by a distinct pattern of brain activities and network connectivities (<xref ref-type="bibr" rid="c16">Langdon, Genkin, &amp; Engel, 2023</xref>). Employing statistical techniques for modeling dynamic systems such as Hidden Markov Modeling (HMM), recent studies have begun to explore the brain dynamics involved in narrative comprehension (<xref ref-type="bibr" rid="c1">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="c23">Song, Park, Park, &amp; Shim, 2021</xref>; <xref ref-type="bibr" rid="c27">Tang et al., 2023</xref>) or movie viewing (<xref ref-type="bibr" rid="c18">Meer, Breakspear, Chang, Sonkusare, &amp; Cocchi, 2020</xref>; <xref ref-type="bibr" rid="c24">Song, Shim, &amp; Rosenberg, 2023</xref>). It has been found that the whole brain systematically switches among a limited number of temporal clusters or latent states with distinct spatial features. Moreover, the switching of brain states was modulated by the time-varying stimuli features including event boundary(<xref ref-type="bibr" rid="c1">Baldassano et al., 2017</xref>) and movie annotations(<xref ref-type="bibr" rid="c18">Meer et al., 2020</xref>), and subjective experience including engagement (<xref ref-type="bibr" rid="c18">Meer et al., 2020</xref>), attention fluctuations(<xref ref-type="bibr" rid="c24">Song et al., 2023</xref>), emotional changes (<xref ref-type="bibr" rid="c26">Tan, Liu, &amp; Zhang, 2022</xref>) and narrative integration (<xref ref-type="bibr" rid="c23">Song et al., 2021</xref>). Those findings demonstrate the functional relevance of brain state dynamics. Nevertheless, how neural state dynamics contribute to the different streams of cognitive processing that ebb and flow with the unfolding of speech is still elusive.</p>
<p>In this study, we explored how language comprehension arises from the dynamic interplay of large-scale brain networks. According to the psycholinguistic theory, the basic design of language faculty mainly comprises three modules (components): an external sensory-motor module, an internal conceptual-intentional module, and a basic linguistic module which represents mental expressions formed by syntactic rules and connects the other two modules (<xref ref-type="bibr" rid="c3">Berwick et al., 2013</xref>). Built upon this theory, we hypothesize that brain dynamics underlying narrative comprehensions would predominantly oscillate within a tripartite latent state space, with each latent state primarily dedicated to a specific component of language faculty. Furthermore, we hypothesize that effective speech comprehension would rely on engaging these states in a timely manner.</p>
<p>To test the above tripartite-state-space hypothesis, we collected fMRI data from 64 young adults as they listened to 10-min real-life narratives. The HMM was applied to model the dynamics of whole-brain network activities. We expect the dynamics of whole-brain network activities would be optimally characterized by three latent states with distinct activity patterns. Specifically, one state would mainly activate the auditory and sensory-motor areas, contributing to the perceptual alalyses of external sound streams. The second state would mainly activate the language network and frontal-parietal network, contributing to linguistic encoding and information integration. The third state would mainly activate the default mode networks (DMN), contributing to internalized semantic-conceptual processing. Moreover, according to the proposed architecture of language components, we expect both the externally-oriented and internally-oriented states would be more likely to transit to the second state than directly transiting between each other. To further validate the functional nature of the three states, we investigated how the dynamic changes of state expression probabilities would be modulated by the temporal variation of speech properties. Three stimuli properties were targeted which assumably reflected an increasingly deeper level of information conveyed by the narrative, including voice amplitudes, word-level semantic coherence and clause-level semantic coherence. We expect the three narrative properties would selectively modulate the three distinct brain states. Finally, to probe the behavioral significance of the timing of brain states, we examined whether the alignment of a participant with the best performer in the time courses of brain state expression could predict his/her narrative comprehension score. To validate the robustness of results, we also conducted all the analyses using an independent dataset consisting of older adults.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The brain reliably and robustly switches through three latent states</title>
<p>We applied the HMM to infer hidden brain states in 64 participants as they listened to one of three 10-min narratives. The observed variables were BOLD signal time series of nine networks obtained employing a state-of-the-art technique for cortical network communities detection (<xref ref-type="bibr" rid="c13">Ji et al., 2019</xref>) (See supplementary material for details). Two criteria were comprehensively considered to determine the optimal number of latent states for the HMM. The first was the effectiveness of a model in capturing and separating patterns in the data, which was assessed by the clustering performance of the model. The second was the degree to which it aligns with prior knowledge about the data, which was evaluated by the model’s ability to classify the three narratives. The dual criteria ensure that the selected model would be both statistically robust and cognitively sensible (<xref ref-type="bibr" rid="c21">Pohle, Langrock, Van Beest, &amp; Schmidt, 2017</xref>).</p>
<p>Across a range of candidate models with K from 2 to 10, the model’s clustering performance tended to decrease with larger K, whereas the accuracy in classifying narrative contents tended to increase. The HMM model with K=3 achieved the best overall performance (quantified by summed <italic>z</italic> scores) (<xref rid="fig1" ref-type="fig">Fig.1</xref>). When applying a different whole-brain parcellation scheme (Yeo-7 Networks atlas) to extract brain time series used for HMM inference, we also found the model with K =3 to be the optimal (Fig.S2). Moreover, when examining the independent dataset wherein participants’ age, narrative contents as well as scanning duration differed substantially from those of the main dataset, we again found the model with K =3 to be optimal (<xref rid="figs3" ref-type="fig">Fig. S3</xref>). The robustness of findings suggests the tripartite state space likely captured some fundamental processes of the brain involved in narrative comprehension.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Identifying the optimal number of brain latent states based on the criterion of statistical robustness and cognitive sensibility.</title>
<p>(<bold>a</bold>) For each candidate K ranging from 2 to 10, we trained an HMM model on n-1 subjects and applied it to decode the time course of state expression for the test subject. The decoded time course was then used to compute a Calinski-Harabasz score, with a larger value indicating better clustering performance, and to decipher which narrative (out of three) was heard by the subject. The two measurements were first assessed at the individual level and then averaged across participants. <bold>(b)</bold> Model performance as a function of K. With the increase of K, the model’s clustering performance tended to decline while the ability to decipher narrative contents tended to improve. We combined the two indices by converting them independently to <italic>z</italic> scores and summed them up. Notably, at K=3, the summed <italic>z</italic> score reached its highest point, therefore it was set as the optimal number of latent states.</p></caption>
<graphic xlink:href="598625v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To further establish that the above tripartite-state organization was not trivial, we examined whether the three states would be reconstructed from smaller, more transient states. To this end, we applied a hierarchical clustering algorithm to the transition probability matrix derived from HMM models with 4, 10, and 12 states, and obtained three clusters for each. Those model orders were examined since they have been reported to be the optimal number in previous studies (<xref ref-type="bibr" rid="c18">Meer et al., 2020</xref>; <xref ref-type="bibr" rid="c23">Song et al., 2021</xref>; <xref ref-type="bibr" rid="c24">Song et al., 2023</xref>; <xref ref-type="bibr" rid="c28">Vidaurre, Smith, &amp; Woolrich, 2017</xref>). In this approach, states assigned to the same cluster were more likely to switch within themselves than switching to states belonging to other clusters, and such clusters have been called metastates in the literature (<xref ref-type="bibr" rid="c28">Vidaurre et al., 2017</xref>). We then examined whether there was significant and exclusive correspondence between the clustered states and the three target states (from the HMM with K=3). As anticipated, those clusters overlapped well with the target states in terms of both spatial activity patterns and the timing of state expression (<xref rid="figs4" ref-type="fig">Fig. S4</xref>), suggesting the tripartite-state organization is not trivial, but may reflect some fundamental processes of brain dynamics.</p>
</sec>
<sec id="s2b">
<title>Three latent brain states have distinct spatial features</title>
<p>For each state, the HMM estimated its activity loadings on the nine networks and a functional connectivity matrix between these networks. We found the three latent states exhibited distinct activity patterns corresponding to the neural substrates for the three language components as suggested by the theory (<xref ref-type="bibr" rid="c3">Berwick et al., 2013</xref>). The first state (State #1) was characterized by relatively high activities in the auditory and somatomotor networks, along with low activities in the DMN and the cognitive control network (<xref rid="fig2" ref-type="fig">Fig.2</xref>). This state seems to be associated with the external sensory-motor module of language faculty. The second state (State #2) was characterized by relatively high activities in the language and the frontal-parietal networks whereas low activities in the somatomotor and auditory networks, seemingly being associated with the basic linguistic component. The third state (State #3) was characterized by relatively high activities in the DMN and frontal-parietal networks whereas low activities in the auditory and language networks, seemingly being associated with the internal conceptual-intentional component. We observed similar activity patterns of latent states when using the Yeo-7 network atlas for brain parcellation (Fig.S2), and on the independent dataset consisting of older adults (Fig.S3).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Spatial and temporal features of latent states revealed by HMM.</title>
<p>(<bold>a)</bold>. The activity loadings of each state on the nine networks. For visualization purpose, the spatial map was normalized to the range [2, 10] with min-max normalization. (<bold>b)</bold>. The ebb and flow of state expression over the time course of narrative understanding, plotted using data from a representative participant. The curves of the three states are stacked showing the relative strength of activation probability at each time interval. (<bold>c)</bold>. Between-state transition probabilities. Both State #1 and #3 were more likely to switch to State #2 than switching directly to each other. The differences in transition probabilities were larger than most of the instances from surrogate data. (<bold>d)</bold>. Topological properties of whole-brain networks when occupied by each of the three states. Brain occupied by State #2 demonstrated the highest global efficiency (G) and the lowest modularity (Q). The upper panel shows the results of graph constructed using state-specific time series extracted from individual participants. The lower panel shows results of graph constructed using FC matrix derived from the HMM. *<italic>p</italic> &lt; 0.05, **<italic>p</italic> &lt;0.01, ***<italic>p</italic>&lt;0.0005 for <italic>t</italic>-tests.</p></caption>
<graphic xlink:href="598625v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>State #2 acts as a “transitional hub” with high functional integration</title>
<p>According to the linguistic theory, the module for linguistic representation is located in the middle of the external and internal modules, having direct interactions with the other two modules (<xref ref-type="bibr" rid="c3">Berwick et al., 2013</xref>). If the hypothesis that the three brain states were associated with each module of the language faculty holds, we expect State #1 and #3 would be more likely to switch to State #2 than switching directly to each other. Moreover, the brain occupied by State #2 would exhibit the highest degree of information integration.</p>
<p>To test the first prediction, we examined the between-state switching matrix inferred by the HMM, which showed the probabilities of a state at each timepoint transitioning to another or staying in the same state at the next timepoint. Consistent with our prediction, both State #1 and #3 were more likely to switch to State #2 than switching directly to each other, i.e., State #2 acted as a transitional hub. To confirm that this state-switching tendency was driven by meaningful processes rather than occurring by chance, we made surrogate data by having the nine-network time series circular shifted independently for 1000 times. In each iteration, we carried out an HMM analysis with K=3, and extracted the difference in transition probability if the inferred states exhibited a similar switching pattern as those from the experiment data. The results showed the differences in transition probabilities observed in our experiment, computed as <italic>P</italic><sub>(State#1→State#2)</sub>→<italic>P</italic><sub>(State#1→State#3)</sub> and <italic>P</italic><sub>(State#3→State#2)</sub>→ <italic>P</italic><sub>(State#3→State#1)</sub>, were respectively larger than 99.9 % and 94.4% of instances from the surrogate data (<xref rid="fig2" ref-type="fig">Fig.2</xref>). In agreement with the between-state switching pattern, the brain spent most of the time on State #2 (mean FO = 46.7%), next on State #1 (mean FO =29%) and the least on State #3 (mean FO = 24.3 %). The same pattern was found in the dwelling time, with a group mean of 15.29s for State #2, 9.99s for State #1, and 9.68s for State #3.</p>
<p>To test the second prediction, we applied the graph theoretical analyses to assess the global efficiency and modularity of the whole-brain networks when occupied by each of the three states. Consistent with our prediction, when occupied by State#2, the brain exhibited significantly higher global efficiency than when occupied by the other two states (<italic>t</italic> values &gt; 4.67, <italic>ps</italic> &lt; 10<sup>-4</sup>). An opposite pattern was found in network modularity (<italic>t</italic> values &lt; -5.82, <italic>ps</italic> &lt; 10<sup>-6</sup>). These results indicate that, when occupied by State #2, the whole-brain networks were well connected to enable efficient information integration across distinct functional systems. In contrast, when occupied by State #1 and State #3, the whole-brain networks were well separated which enabled functional specialization. The findings were consistent either using state-specific time series from individual participants to construct the FC matrix or taking the FC matrix derived from the HMM (<xref rid="fig2" ref-type="fig">Fig. 2</xref>).</p>
<p>The between-state switching and topological properties are replicable using the different brain network parcellation scheme (Fig.S2) and generalizable to the independent dataset consisting of the older adults (Fig.S3).</p>
</sec>
<sec id="s2d">
<title>Expression of brain states is selectively modulated by narrative properties</title>
<p>To more directly establish the association of the three brain states to the theoretical language modules, we investigated how the expression of brain states would be modulated by changes in the stimuli properties as the narrative progressed. Three distinct stimuli properties presumably reflecting an increasingly deeper level of information conveyed by the narrative were extracted, including speech envelope, word-level semantic coherence and clause-level semantic coherence.</p>
<p>Speech envelope captures the slow amplitude fluctuations of the speech signal over time, which is the perceptual property of the stimuli. We observed a consistent positive correlation across individuals between speech envelope and the expression probability of State #1 (<italic>t</italic><sub>(63)</sub> = 2.67, <italic>p</italic> = 0.009, FDR corrected) (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). A slightly weaker but significant effect was also observed on State #2 (<italic>t</italic><sub>(63)</sub> = 2.61, <italic>p</italic> = 0.011, FDR corrected). The word-level semantic coherence was assessed by cosine similarity between embedding vectors for each word and the word immediately before it. Among the three states, only the expression probability of State #2 was consistently correlated with word-level semantic coherence across participants (<italic>t</italic><sub>(63)</sub>=2.48, <italic>p</italic> = 0.015, FDR corrected). Clause-level semantic coherence was assessed by cosine similarity between embedding vectors for each clause and the clause immediately before it. Only the expression probability of State #3 was consistently correlated with the semantic coherence of clauses (<italic>t</italic><sub>(63)</sub>=2.89, <italic>p</italic> = 0.005, FDR corrected). All of these effects were significantly greater than results from the permutated data (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). The selective modulation by the different aspects of narrative properties provides further evidence supporting the functional relevance of three latent brain states to different language components.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Selective modulation of state expression by different narrative features.</title>
<p>The expression probability of State #1, as well as of State #2, was positively modulated by the temporal envelope of speech. The expression probability of State #2 was also modulated by word-level semantic coherence, while that of State #3 was modulated by clause-level semantic coherence. Semantic coherence was measured by cosine similarity between the embeddings (obtained by BERT) of each word (or clause) and the word (clause) immediately before it. Those effects were greater than most of the instances from permutation where the time courses of state expression were randomly shuffled 5000 times. *<italic>p</italic> &lt; 0.05, **<italic>p</italic>&lt; 0.01, ***<italic>p</italic> &lt; 0.005 for <italic>t</italic>-tests.</p></caption>
<graphic xlink:href="598625v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>These results are replicated with the different brain network atlas. On the independent dataset, we also observed selective modulation effects of speech envelope on State#1 and word-level semantic coherence on State#2; however, no modulation effect of clause-level semantic coherence was found (<xref rid="figs3" ref-type="fig">Fig. S3</xref>).</p>
</sec>
<sec id="s2e">
<title>Inter-subject correlation in brain state dynamics predict task performance</title>
<p>The above results have demonstrated the functional relevance of the tripartite state space to narrative comprehension. Next, we tested the hypothesis that effective narrative comprehension would rely on engaging these states in a timely manner. To tackle this question, we measured the alignment of brain state fluctuation between each participant (except for the best performers) with that of the best performer(s), then we used the inter-brain alignment index to predict participants’ comprehension scores. The best performer was the one (or those) who achieved the highest comprehension score within the subgroup of participants exposed to the same narrative. The rationale is that, if effective comprehension relies on the brain to turn into specific patterns at the right times, the best performer would demonstrate the most “accurate” pattern. Consequently, participants whose brain state fluctuations deviated more (or less alignment) from the “accurate” pattern were anticipated to perform less effectively in the task.</p>
<p>As anticipated, alignments with the best performer(s) in both the State#1 and State#2 were significantly correlated with participants comprehension scores (Pearson’s r<sub>(54)</sub> = 0.31 and 0.36, respectively). A marginally significant correlation was also found in the alignment of State#3 (r<sub>(54)</sub>=0.22, p = 0.10). As an alternative, we also took the group-mean time courses of brain states expression as the most “accurate” pattern and recalculated the inter-brain alignment value. Even stronger correlations were found between individual-to-group alignments and comprehension scores in all three states (<italic>r</italic><sub>(62)</sub>= 0.425, 0.507, 0.269 for State#1, #2, and #3 respectively) (<xref rid="fig4" ref-type="fig">Fig. 4</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Correlation of state expression with behavior.</title>
<p>Participants’ alignments with both the best performer(s) and the group mean in terms of brain state expression predicted their narrative comprehension scores. The alignment with the best performer in head movement trajectory, which probably reflected inter-subject similarity in the fluctuation of task engagement or attention, also correlated with narrative comprehension. After adjusting this effect using partial correlation, the significant correlations between inter-subject alignment in states expression and narrative comprehension still existed.</p></caption>
<graphic xlink:href="598625v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In previous studies, the similarity of brain activities across subjects has usually been interpreted as reflecting the inter-subject similarity in the fluctuation of task engagement or attention (<xref ref-type="bibr" rid="c19">Nanni-Zepeda et al., 2024</xref>; <xref ref-type="bibr" rid="c20">Ohad &amp; Yeshurun, 2023</xref>), which in turn may be associated with the individual similarity in task performance. We examined whether the above association of inter-subject alignment in brain states with behavior was merely an epiphenomenon of overall task engagement. It is well known that continuous self-reports on task engagement may severely disrupt the ongoing processing of prolonged naturalistic stimuli. As an alternative, studies have demonstrated that head movement serves as a reliable time-resolved indicator for task engagement, with greater task engagement accompanied by decreased movement (<xref ref-type="bibr" rid="c2">Ballenghein, Megalakaki, &amp; Baccino, 2019</xref>; <xref ref-type="bibr" rid="c11">Greipl, Bernecker, &amp; Ninaus, 2021</xref>; <xref ref-type="bibr" rid="c14">Kaakinen, Ballenghein, Tissier, &amp; Baccino, 2018</xref>). Leveraging this, we computed inter-subject correlations (ISC) in the trajectory of head movement (quantified by framewise displacement) during the fMRI scanning as a proxy for inter-subject similarity in task engagement. Congruent with our assumption, similarities with the best performer in terms of head movement trajectory were indeed positively correlated with participants’ comprehension scores (r<sub>(54)</sub> = 0.33, p = 0.01) (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). After adjusting the effect of head movement by applying partial correlation, the positive correlation between the inter-subject alignment in brain states and comprehension scores remained robust (partial r values &gt; 0.29, ps &lt; 0.04). These findings suggest that the inter-subject alignments in brain states were unlikely merely the byproduct of shared levels of task engagement, but instead reflected the commonality in neural processes that directly influence narrative comprehension.</p>
<p>As a comparison, we also whether individual differences in the FO and dwell time of latent states were associated with individual difference in narrative comprehension. No significant result was found on any of the three states (r values &lt; 0.15, <italic>ps</italic> &gt; 0.23). Taken together, these findings suggest that timely engagement with specific brain states, rather than the overall magnitude of engagement in those states, is crucial for narrative comprehension.</p>
<p>These findings were replicable with the different brain network atlas (Fig.S3). However, on the independent dataset, we did not find significant positive correlations between inter-subject alignment in brain states and narrative comprehension. This may be because there is too much heterogeneity among the older adults and therefore the ISCs in brain activities lack sensitivity to individual difference in task processing.</p>
</sec>
<sec id="s2f">
<title>Comparison between conditions</title>
<p>The above results have revealed a tripartite latent space of whole-brain dynamics, with each state probably subserving a different cognitive component underlying narrative comprehension. Is this temporospatial organization a task-free, intrinsic organization of the dynamic brain, or mainly driven by language processing? To address this question, we compared the brain states involved in narrative comprehension with those of the same participants when they listened to an unintelligible narrative (told in Mongolian) and during rest. Note, the involvement in linguistic computations decreased monotonically across the three conditions.</p>
<p>The HMMs with K=3 conducted separately for the resting condition revealed three states with moderate similarity in activity patterns to that of the narrative comprehension condition (overall r<sub>(25)</sub> = 0.43, <italic>p</italic> = 0.024). Yet, differing from the narrative comprehension condition, it was the State#3 that acted as the transitional hub (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). For the unintelligible condition, the activity patterns of latent states varied substantially from that of the narrative condition (overall r<sub>(25)</sub> = 0.21, <italic>p</italic> = 0.29), while State#2 still acted as a transitional hub (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). Notably, the FOs of State#2 monotonically increased across the three conditions: resting &lt; unintelligible condition &lt; narrative comprehension. In contrast, the FOs of the State#3 monotonically decreased: resting &gt; unintelligible condition &gt; narrative comprehension. A similar pattern was found on the dwelling time. These findings provide additional evidence supporting that State#2 was associated with linguistic computations, while State#3 was associated with internalized mental activities. Together, these results suggest that the tripartite latent space of whole-brain dynamics is mainly driven by language processing.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Comparisons of brain states across conditions.</title>
<p><bold>(a)</bold> During rest, the activity patterns of latent states were similar to those during narrative comprehension, but State #3 became the transitional hub. <bold>(b)</bold> When listening to the unintelligible narrative (in Mongolian, MG), the activity patterns of latent states varied substantially from that during narrative comprehension, but State#2 was still the transitional hub. <bold>(c)</bold> The fractional occupation of State#2 increased with greater involvement in linguistic computations, while that of State#3 decreased. A similar pattern was found on the dwelling time of states.</p></caption>
<graphic xlink:href="598625v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Speech comprehension is a sophisticated cognitive task that requires the dynamic interplay of various processes, from basic sound perception to complex semantic-pragmatic interpretations, all of which are fluidly coordinated in real time as the speech unfolds. Here, we explored how the brain transiently activates and coordinates distributed neural networks to support the diverse cognitive streams underlying spoken narrative comprehension. Applying HMM, we found that the brain reliably and robustly switches through three latent states, which were characterized respectively by high activities in the sensory-motor (State #1), bilateral temporal-frontal (State #2), and DMN (State #3) regions. Among them, State #2 occurred most frequently, acted as a “transitional hub”, and was characterized by the highest level of functional integration. Furthermore, the three states were selectively modulated by the perceptual, word-level semantic and clause-level semantic properties of the speech. Importantly, participants’ alignments with the best performers on the time courses of brain states expression predicted their narrative comprehension scores, indicating effective speech comprehension relies on engaging the specific brain states in a timely manner. Finally, by comparing the comprehension task with the resting and the unintelligible speech conditions, we demonstrated that the tripartite latent state space was mainly driven by language processing.</p>
<p>A set of results convergently suggest that the tripartite state space is not incidental, but likely reflects a fundamental principle governing the brain dynamics underlying narrative comprehension. First, among a range of candidate models with the number of states ranging from 2 to 10, the model with K=3 performed the best in terms of separating patterns in the data and decoding narrative contents, being both statistically robust and cognitively sensible. Second, the tripartite latent state space was replicable with different network atlas and generalizable to independent datasets. Especially, despite that the two datasets vary substantially in terms of participants (young versus older adults), the contents of narratives and data length, the two groups still exhibited highly similar brain temporal organization that was best captured by the three latent states. Moreover, the spatial and temporal patterns of the tripartite state space can be hierarchically reconstructed from more nuanced state patterns, being “metastates” of the brain.</p>
<p>Intriguingly, the characteristics of the three latent states align well with the theoretical framework concerning the basic design of language faculty (<xref ref-type="bibr" rid="c3">Berwick et al., 2013</xref>). The State#1, which was featured by relatively high activities in the auditory and somatomotor networks and more likely to occur when speech sounds were louder, probably corresponds to the external sensory-motor component of language faulty. State#2, which was featured by relatively high activities in the bilateral temporal and the frontal-parietal networks and more likely to occur when the inputting word was semantically related to the word immediately before it, probably corresponds to the basic linguistic component. State#3, which was featured by relatively high activities in the DMN and frontal-parietal networks and more likely to occur when the inputting clause was semantically related to the clause immediately before it, probably corresponds to the higher-level semantic-conceptual component. Moreover, State #2 acted as a transitional hub that both State #1 and State #3 were more likely to switch to it than switching directly within them. This directed switching pattern was not incidental, as the observed discrepancy in switching probability was greater than most instances from the surrogate data. Additionally, when occupied by State #2, the whole brain networks exhibited a higher level of information integration (quantified by global efficiency) than when occupied by the other two states. These patterns are also consistent with the theoretical prediction that the basic linguistic module is located in the middle of the external and internal modules, having direct interactions with the other two. Collectively, these findings demonstrate specific relationship between the tripartite brain latent states and three critical components of language cognition, going beyond the account of arousal or attentional fluctuation for brain state dynamics (<xref ref-type="bibr" rid="c18">Meer et al., 2020</xref>; <xref ref-type="bibr" rid="c24">Song et al., 2023</xref>; <xref ref-type="bibr" rid="c25">Taghia et al., 2018</xref>).</p>
<p>The activity patterns of the brain latent states associated with each of the theoretical components of language faculty are consistent with the findings from earlier studies that have mainly focused on the averaged brain activities over time (<xref ref-type="bibr" rid="c7">Ferstl, Neumann, Bogler, &amp; von Cramon, 2008</xref>; <xref ref-type="bibr" rid="c22">Price, 2012</xref>). Extending prior work, our study may provide novel insights about how the different streams of cognitive processing are temporally organized with the unfolding of speech. Specifically, the time-varying probabilities of latent states indicate that the associated cognitive processes underlying speech comprehension may not operate in parallel with equal priority or occur one after another. Instead, while all processes are simultaneously engaged, one process dominates over others and this dominance changes over time, taking the form of mode-switching. This is consistent with the emerging view that internal/external switching processes of neural circuits drive learning (<xref ref-type="bibr" rid="c12">Honey et al., 2018</xref>). Furthermore, we found it was the alignment with the best performer in the time courses of state expression, rather than the overall occupancy of latent states, that positively correlated with participants’ task performance, suggesting recruiting these states in a timely manner is the key to effective speech comprehension. These findings may provide a useful guide to understand the development of language ability as well as language disorders.</p>
<p>Our study provides a unifying perspective for two prevailing approaches aiming to understand how the brain produces cognition. The modular approach postulates the brain areas to act as independent processors for a specific aspect of complex cognitive functions, contributing to much of our current knowledge of the relationship between brain and behavior. However, this approach has been criticized for ignoring the multifunctionality of brain structures (<xref ref-type="bibr" rid="c8">Fuster, 2000</xref>). Alternatively, the network approach, which has been growing rapidly in recent years, posits that cognitive functions arise from dynamic interactions within and between distributed brain systems (<xref ref-type="bibr" rid="c4">Bressler &amp; Menon, 2010</xref>). While revealing valuable insights into the operation rules of the brain, the network approach seems to only provide a general descriptive model. It lacks mechanism accounts for how the interactions of large-scale brain networks give rise to the different streams of information processing involved in a cognitive task. Here, by demonstrating the multistability of large-scale brain networks and establishing the close relationship between specific latent states to specific language components, our study raises a hypothesis that could reconcile the modular and the dynamic network approaches to understand the brain function. Specifically, for a given task, the brain follows modular organization where different regions specialize in specific functions. However, the importance of these regions dynamically changes in response to external environment and internal demands. Accordingly, goal-directed behaviors arise from the precise temporal coordination of different functional modules (<xref ref-type="bibr" rid="c29">Vyas, Golub, Sussillo, &amp; Shenoy, 2020</xref>). To test this possibility, future studies could combine fMRI and neuroregulation techniques and assess the change in state dynamics and behavioral performance as a result of intervention.</p>
</sec>
<sec id="s4">
<title>Conclusion</title>
<p>In sum, our study reveals that the brain involved in narrative comprehension predominantly oscillates within a tripartite latent state space. The spatial and topological characteristics of these states correspond well to the three core components of language faculty as specified in the theory (<xref ref-type="bibr" rid="c3">Berwick et al., 2013</xref>). Moreover, we demonstrate that effective speech comprehension relies on engaging these brain states in a timely manner. These results are largely reproducible with different brain network parcellation schemes, and generalizable to two independent datasets consisting of young and older adults. The findings establish the link of brain dynamics with both ongoing cognitive processing and behavioral outcomes, providing a mechanistic account of how language comprehension arises from the dynamic interplay of large-scale brain networks.</p>
</sec>
<sec id="s5">
<title>Materials and methods</title>
<sec id="s5a">
<title>Participants and experiment procedure</title>
<p>The main dataset came from 64 Chinese college students (33 males, aged 19-27 years) scanned with fMRI while listening to a 10-min narrative in Chinese. The speech played to each participant was randomly chosen from three real-life stories told by a female college student. After the scanning, participants were asked to recall the narrative as detailed as possible, and then answered several questions regarding narrative contents that were not recalled. Two experimenters then independently rated the degree of narrative comprehension for each participant based on the interview.</p>
<p>The independent dataset came from 30 healthy older adults (12 males, aged 53-75 years) recruited from the residential community near the college. During fMRI scanning, each participant listened to two real-life stories told by a 62-year-old female, presented with and without background noise. After omitting those with large head movements, a total of 50 runs of fMRI scans were included for subsequence analyses.</p>
<p>This research was approved by the Reviewer Board of Southwest University in China. The same dataset has been used in our previous work addressing a different question (<xref ref-type="bibr" rid="c17">Liu et al., 2020</xref>).</p>
</sec>
<sec id="s5b">
<title>MRI acquisition and preprocessing</title>
<p>We used a 3T Siemens Trio scanner in the MRI Center of the Southwest University of China to collect imaging data. Functional images were acquired employing a gradient echo-planar imaging sequence with the specified parameters: repetition time = 2000 ms, echo time = 30 ms, flip angle = 90°, field of view = 220 mm<sup>2</sup>, matrix size = 64 × 64, 32 interleaved slice, voxel size = 3.44 × 3.44 × 3.99 mm<sup>3</sup>. Structural images were acquired using a MPRAGE sequence with the following parameters: repetition time = 2530 ms, echo time = 3.39 ms, flip angle = 7°, FOV = 256 mm<sup>2</sup>, scan order = interleaved, matrix size = 256 × 256, and voxel size = 1.0 × 1.0 × 1.33 mm<sup>3</sup>. The preprocessing pipeline includes slice-timing correction, spatial realignment, co-registration to the individual participants’ anatomical maps, normalization to the Montreal Neurological Institute (MNI) space, resampling into a 3 × 3 × 3 mm<sup>3</sup> voxel size, and smoothing (FWHM = 7mm). The resulting images underwent additional processing, including detrending, nuisance variable regression and high-pass filtering (1/128 Hz). Data with head movement greater than 3 degrees or 3 mm were omitted from further analyses.</p>
</sec>
</sec>
<sec id="s6">
<title>Data analyses</title>
<sec id="s6a">
<title>Whole-brain parcellation</title>
<p>The inference for brain dynamic states was conducted at the whole-brain network level. Currently, most brain functional networks reported in the literature are made based on resting-state fMRI data. To better capture the brain network organization during the task, we conducted brain network parcellation applying a state-of-the-art method proposed by (<xref ref-type="bibr" rid="c13">Ji et al., 2019</xref>), using data from the 64 participants engaged in narrative comprehension. This method employs multiple quality control metrics to ensure the stability and reliability of the network partition, and most importantly, uses parameter optimization guided by well-established neurobiological principles (e.g., the separation of sensory and motor systems). A detailed description of network partition is presented in the supplementary material. The network detection approach identified a total of 11 networks (<xref rid="figs1" ref-type="fig">Fig. S1</xref>). Two networks were discarded due to comprising too few nodes (less than three) and nine networks were included for further analyses. By reference to the functional decoding results using NeuroSynth (<ext-link ext-link-type="uri" xlink:href="https://www.neurosynth.org">https://www.neurosynth.org</ext-link>), we tentatively labelled the nine networks as the auditory, visual, somatomotor, bilateral language, medial temporal, frontal-parietal, ventral attention, subcortical and default mode networks. To test the robustness of findings, we also adopted the seven-network atlas (<xref ref-type="bibr" rid="c31">Yeo et al., 2011</xref>) for whole-brain parcellation and reconducted the main analyses.</p>
</sec>
<sec id="s6b">
<title>Brain state inference using Hidden Markov Model</title>
<p>We applied Hidden Markov model (HMM) to infer latent brain states during narrative comprehension using the HMM-MAR toolbox (<ext-link ext-link-type="uri" xlink:href="https://github.com/OHBA-analysis/HMM-MAR">https://github.com/OHBA-analysis/HMM-MAR</ext-link>). The HMM model assumes that the observed data are generated through a finite number of latent states, and each state can be characterized respectively by a multivariate Gaussian distribution with mean and covariance. The BOLD time series were first standardized within each participant and each network. Then HMM was fitted using concatenated data from all participants, such that unified brain states could be obtained.</p>
<p>The number of latent states (represented by “K”) is a crucial aspect of the HMM, and it needs to be predetermined before fitting the model. Two criteria were considered to determine the optimal K. The first was a model’s clustering performance, which reflects how well the model can capture and separate different patterns in the data. The second criterion was how well the model aligned with existing knowledge about the data. This criterion was evaluated by the ability of a trained HMM model to decode the narrative content heard by unseen participants. This dual criterion ensures that the selected number of brain states (K) for the HMM is both statistically robust and cognitively meaningful (<xref ref-type="bibr" rid="c21">Pohle et al., 2017</xref>). The clustering performance and prediction accuracy were assessed through a leave-one-out cross-validation strategy. In this approach, we trained the HMM using data from all participants except one. For each candidate K, we repeated the training process 10 times, and the instance with the smallest free energy was selected for decoding the latent state sequence of the left-out participant. Utilizing the decoded latent state sequence, along with the participant’s network time series, we calculated the Calinski-Harabasz score as an indicator of the model’s clustering performance, with a higher score indicating better clustering performance. Further, to assess the model’s decoding capability, we applied a K-nearest neighbor algorithm utilizing the decoded latent state sequences to classify which of the three narratives the left-out participant was listening to. A higher accuracy indicates the model has well captured the task information in the data. Both the Calinski-Harabasz score and narrative classification accuracy were acquired from each participant and then averaged across the group. To combine the two criteria, we first converted the Calinski-Harabasz score and narrative decoding accuracy independently to Z scores and then summed them up to create a single composite score.</p>
<p>We repeated the above cross-validation procedure across a range of K from 2 to 10. The K with the largest composite score was set to be the optimal number of HMM states representing the brain dynamics during the narrative comprehension task. Upon determining the optimal number of states, we reconducted the HMM on the data from all participants and chose the instance with the largest model evidence (lowest free energy) from 10 iterations as the final result.</p>
<p>To demonstrate that those hidden states identified by the above analyses was not trivial but potentially reflected several fundamental processes of the dynamic brain, we explored whether they can be reconstructed from smaller, more nuanced patterns using hierarchically clustering (see supplementary material for details).</p>
</sec>
<sec id="s6c">
<title>Analyses of brain state properties</title>
<p>The HMM model generated, for each state, a group-level activation map and a functional connectivity matrix, as well as a between-state transition probabilities matrix. With these parameters, the probability of each state being active (or expressed) at each time point and the most likely sequence of states (referred to as the Viterbi path) were estimated for each participant. Based on the Viterbi path, the total time spent on each state over the entire duration (referred to as fractional occupancy, FO) and the duration for which a state continuously persisted before switching to another one (referred to as dwell time) were computed for each participant.</p>
<p>Next, we conducted a graph theoretical analysis to assess the degree of functional integration and segregation of the whole brain when occupied by a specific state. For each participant and each state, a weighted and undirected graph was constructed in which the nine networks were represented as nodes, and FCs estimated using network time series corresponding to the specific state were represented as edges. Employing Brain Connectivity toolbox (<xref ref-type="bibr" rid="c30">Whitfield-Gabrieli &amp; Nieto-Castanon, 2012</xref>), we computed network global efficiency as the measurement for functional integration. Functional segregation was measured by a network modularity score using Louvain algorithm with a resolution parameter gamma=1. Then t-tests were employed to examine the differences in these indices across the three states. For validation purpose, we additionally computed the two graph theoretical indices using the state-specific FC matrices estimated by the HMM.</p>
</sec>
<sec id="s6d">
<title>Surrogate data generation and permutation test</title>
<p>To ascertain that the trend in between-state transition was not by chance, we generated surrogate data by having the 9-network time series circular shifted independently. In this approach, the meaningful covariance between networks was disrupted while the temporal characteristics of the time series were retained (<xref ref-type="bibr" rid="c24">Song et al., 2023</xref>). On each permutated data, we conducted an HMM analysis with the optimal K (i.e., K=3). If there were two states where both showed a higher probability of transitioning to a third state compared to directly transitioning between them, this instance would be taken as exhibiting a similar switching pattern as to the experiment result. Then the associated differences in the transition probabilities were extracted and averaged between two pairs. Otherwise, the difference for this instance was set to zero. This step ensured that only meaningful differences in transition probabilities were considered. By repeating this procedure 1000 times, we obtained a null distribution for the discrepancy in state transition probabilities.</p>
</sec>
<sec id="s6e">
<title>Modulation of brain state activation by time-varying stimuli features</title>
<p>To gain more insights into the functional nature of brain dynamic states, we investigated how narrative properties would modulate the probability of a neural state being expressed in individuals. Specifically, we focused on three different stimuli properties which were assumed to reflect an increasingly “deeper” level of information conveyed by the narrative, including the temporal changes in acoustic property, and semantic coherence at the word level and at the clause level.</p>
<p>To characterize the temporal variation of acoustic property, we derived the temporal envelope of each story using Hilbert transform, which reflects the overall fluctuation of voice amplitude. The speech envelope was then convolved with the canonical hemodynamic response function (HRF) and down-sampled to 0.5 Hz (the same resolution as the fMRI acquisition). To characterize the temporal variation of semantic coherence, we first transcribed the speech to texts and retrieved the semantic representations for each word applying a large language model BERT that was pretrained on a large-scale Chinese corpus (<xref ref-type="bibr" rid="c5">Cui, Che, Liu, Qin, &amp; Yang, 2021</xref>; <xref ref-type="bibr" rid="c6">Devlin, Chang, Lee, &amp; Toutanova, 2018</xref>). The output from the last layer of the model was used as word embedding. To avoid overfitting, we further decomposed the high-dimensional embedding vectors (N=768) with principal component analysis (PCA) and retained the first 50 PCs (<xref ref-type="bibr" rid="c9">Goldstein et al., 2024</xref>; <xref ref-type="bibr" rid="c10">Goldstein et al., 2022</xref>). Next, a vector of word-level semantic coherence was generated for each narrative by computing the cosine similarity between the embeddings of every word and the word immediately before it. After aligning the onset time of words using Praat (<ext-link ext-link-type="uri" xlink:href="https://www.fon.hum.uva.nl/praat/">https://www.fon.hum.uva.nl/praat/</ext-link>), the semantic coherence vector was convolved with HRF and down-sampled to 0.5Hz. Clauses were encoded by two researchers, each including 8-9 characters on average. The semantic representations for clauses were obtained by averaging the embedding vectors of words within a clause. Using the same method, a vector for clause-level semantic coherence was generated for each narrative.</p>
<p>We first computed Pearson’s correlation between the vector of narrative properties and the vector of state expression probability at the individual level. To infer significance, the group mean of correlation values across participants was compared to a null distribution generated by 5000 permutations. For each iteration, the time courses of brain state expression were randomly shuffled, and the correlation between narrative property vector and the shuffled time course of state expression was re-calculated and averaged over participants to create a random value. An empirical <italic>p</italic>-value was determined by the proportion of values from the 5000 iterations that were larger than the original group-mean value. FDR correction was used to account for multiple comparisons.</p>
</sec>
<sec id="s6f">
<title>Correlation of latent state dynamics with behavior</title>
<p>To assess the importance of the timing of brain latent states to behavior, we examined whether the alignment of participant’s brain state fluctuations with that of the best performer could predict their narrative comprehension scores. The best performer was the one (or those) who scored the highest in the narrative recall task within the subgroup of participants exposed to the same narrative. For each narrative, if there were more than one best performer, we first assessed the alignment between a participant with each of them, and then got the average. For the non-best-performers (N=56), their brain alignment with the best performer(s) was measured by Pearson’s correlation using the time course of state expression probability. After that, we computed a Pearson’s correlation between inter-brain alignments and participants’ comprehension scores. Considering that the best performer may lack of representativeness, we also measured the alignment of each participant’s brain state fluctuations with that of the group mean. In this approach, the inter-brain alignment value was obtained by iteratively leaving a participant, and calculating a Pearson’s correlation between the time course of state expression probability of the left-out participant and the average time course of the rest of participants engaged in the same narrative.</p>
<p>As a comparison, we also investigated whether the overall engagement of a brain state was associated with task performance. For this purpose, we examined the correlation between participants’ FO and dwell time in each state and their comprehension scores.</p>
</sec>
<sec id="s6g">
<title>Compare brain states across conditions</title>
<p>Finally, we investigated whether the temporal organization of brain dynamics observed during narrative comprehension was mainly driven by language processing, or instead an intrinsic organization of the dynamic brain. For this purpose, we analyzed the fMRI data from the same group of participants at rest and when listening to an unintelligible narrative told in a foreign language (Mongolian). The scanning parameters as well as the scanning length were identical to the main experiment. The HMM with K=3 was conducted separately for the two conditions, then the resulting three brain states were mapped to the corresponding states from the narrative comprehension condition by maximizing the similarity in state activity patterns.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by grants from the National Natural Science Foundation of China (NSFC:31900802, 31971036), and Guangdong Basic and Applied Basic Research Foundation. No conflict of interest is declared.</p>
</ack>
<ref-list>
<title>Reference</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baldassano</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zadbood</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name>, &amp; <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Discovering event structure in continuous narrative perception and memory</article-title>. <source>Neuron</source>, <volume>95</volume>(<issue>3</issue>), <fpage>709</fpage>–<lpage>721. e705</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ballenghein</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Megalakaki</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Baccino</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Cognitive engagement in emotional text reading: concurrent recordings of eye movements and head motion</article-title>. <source>Cognition and Emotion</source>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berwick</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Friederici</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Chomsky</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Bolhuis</surname>, <given-names>J. J.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Evolution, brain, and the nature of language</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>17</volume>(<issue>2</issue>), <fpage>89</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2012.12.002</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bressler</surname>, <given-names>S. L.</given-names></string-name>, &amp; <string-name><surname>Menon</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Large-scale brain networks in cognition: emerging methods and principles</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>14</volume>(<issue>6</issue>), <fpage>277</fpage>–<lpage>290</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cui</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Che</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Qin</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Yang</surname>, <given-names>Z.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Pre-training with whole word masking for chinese bert. <italic>IEEE/ACM Transactions on Audio</italic></article-title>, <source>Speech, and Language Processing</source>, <volume>29</volume>, <fpage>3504</fpage>–<lpage>3514</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Devlin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>M.-W.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Toutanova</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Bert: Pre-training of deep bidirectional transformers for language understanding</article-title>. <source>arXiv</source> preprint arXiv:<pub-id pub-id-type="arxiv">1810.04805</pub-id>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ferstl</surname>, <given-names>E. C.</given-names></string-name>, <string-name><surname>Neumann</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bogler</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>von Cramon</surname>, <given-names>D. Y.</given-names></string-name></person-group> (<year>2008</year>). <article-title>The extended language network: A meta-analysis of neuroimaging studies on text comprehension</article-title>. <source>Human Brain Mapping</source>, <volume>29</volume>(<issue>5</issue>), <fpage>581</fpage>–<lpage>593</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.20422</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fuster</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2000</year>). <article-title>The module: crisis of a paradigm</article-title>. <source>Neuron</source>, <volume>26</volume>(<issue>1</issue>), <fpage>51</fpage>–<lpage>53</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldstein</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Grinstein-Dabush</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schain</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hong</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Aubrey</surname>, <given-names>B.</given-names></string-name>, … <string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Alignment of brain embeddings and artificial contextual embeddings in natural language points to common geometric patterns</article-title>. <source>Nature Communications</source>, <volume>15</volume>(<issue>1</issue>), <fpage>2768</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-024-46631-y</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldstein</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zada</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Buchnik</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Schain</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Price</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Aubrey</surname>, <given-names>B.</given-names></string-name>, … <string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Shared computational principles for language processing in humans and deep language models</article-title>. <source>Nature Neuroscience</source>, <volume>25</volume>(<issue>3</issue>), <fpage>369</fpage>–<lpage>380</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-022-01026-4</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greipl</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bernecker</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Ninaus</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Facial and bodily expressions of emotional engagement: How dynamic measures reflect the use of game elements and subjective experience of emotions and effort</article-title>. <source>Proceedings of the ACM on Human-Computer Interaction</source>, <volume>5</volume>(CHI PLAY), <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Honey</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Newman</surname>, <given-names>E. L.</given-names></string-name>, &amp; <string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Switching between internal and external modes: A multiscale learning principle</article-title>. <source>Netw Neurosci</source>, <volume>1</volume>(<issue>4</issue>), <fpage>339</fpage>–<lpage>356</lpage>. doi:<pub-id pub-id-type="doi">10.1162/NETN_a_00024</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ji</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Spronk</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kulkarni</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Repovš</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Anticevic</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Cole</surname>, <given-names>M. W.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Mapping the human brain’s cortical-subcortical functional network organization</article-title>. <source>Neuroimage</source>, <volume>185</volume>, <fpage>35</fpage>–<lpage>57</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaakinen</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Ballenghein</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Tissier</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Baccino</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Fluctuation in cognitive engagement during reading: Evidence from concurrent recordings of postural and eye movements. <italic>Journal of Experimental Psychology: Learning</italic></article-title>, <source>Memory, and Cognition</source>, <volume>44</volume>(<issue>10</issue>), <fpage>1671</fpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kelso</surname>, <given-names>J. A. S.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Multistability and metastability: understanding dynamic coordination in the brain</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>367</volume>(<issue>1591</issue>), <fpage>906</fpage>–<lpage>918</lpage>. doi:doi:<pub-id pub-id-type="doi">10.1098/rstb.2011.0351</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Langdon</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Genkin</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Engel</surname>, <given-names>T. A.</given-names></string-name></person-group> (<year>2023</year>). <article-title>A unifying perspective on neural manifolds and circuits for cognition</article-title>. <source>Nat Rev Neurosci</source>, <volume>24</volume>(<issue>6</issue>), <fpage>363</fpage>–<lpage>377</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41583-023-00693-x</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Garrett</surname>, <given-names>D. D.</given-names></string-name>, <string-name><surname>Lu</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>A.</given-names></string-name>, … <string-name><surname>Ding</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Auditory–Articulatory Neural Alignment between Listener and Speaker during Verbal Communication</article-title>. <source>Cerebral Cortex</source>, <volume>30</volume>(<issue>3</issue>), <fpage>942</fpage>–<lpage>951</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhz138</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meer</surname>, <given-names>J. N. V.</given-names></string-name>, <string-name><surname>Breakspear</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Sonkusare</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Cocchi</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Movie viewing elicits rich and reliable brain state dynamics</article-title>. <source>Nat Commun</source>, <volume>11</volume>(<issue>1</issue>), <fpage>5004</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-020-18717-w</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nanni-Zepeda</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>DeGutis</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rothlein</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Fan</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Grimm</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zuberer</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Neural signatures of shared subjective affective engagement and disengagement during movie viewing</article-title>. <source>Human Brain Mapping</source>, <volume>45</volume>(<issue>4</issue>), <fpage>e26622</fpage>. <pub-id pub-id-type="doi">10.1002/hbm.26622</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ohad</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Yeshurun</surname>, <given-names>Y.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Neural synchronization as a function of engagement with the narrative</article-title>. <source>Neuroimage</source>, <volume>276</volume>, <fpage>120215</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120215</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pohle</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Langrock</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Van Beest</surname>, <given-names>F. M.</given-names></string-name>, &amp; <string-name><surname>Schmidt</surname>, <given-names>N. M.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Selecting the number of states in hidden Markov models: pragmatic solutions illustrated using animal movement. <italic>Journal of Agricultural</italic></article-title>, <source>Biological and Environmental Statistics</source>, <volume>22</volume>, <fpage>270</fpage>–<lpage>293</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Price</surname>, <given-names>C. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>A review and synthesis of the first 20 years of PET and fMRI studies of heard speech, spoken language and reading</article-title>. <source>Neuroimage</source>, <volume>62</volume>(<issue>2</issue>), <fpage>816</fpage>–<lpage>847</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>B. Y.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Shim</surname>, <given-names>W. M.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Cognitive and Neural State Dynamics of Narrative Comprehension</article-title>. <source>J Neurosci</source>, <volume>41</volume>(<issue>43</issue>), <fpage>8972</fpage>–<lpage>8990</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0037-21.2021</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Shim</surname>, <given-names>W. M.</given-names></string-name>, &amp; <string-name><surname>Rosenberg</surname>, <given-names>M. D.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Large-scale neural dynamics in a shared low-dimensional state space reflect cognitive and attentional dynamics</article-title>. <source>Elife</source>, <volume>12</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.85487</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Taghia</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Ryali</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kochalka</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Nicholas</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Menon</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Uncovering hidden brain state dynamics that regulate performance and decision-making during cognition</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>), <fpage>2505</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-018-04723-6</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tan</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Inferring Brain State Dynamics Underlying Naturalistic Stimuli Evoked Emotion Changes With dHA-HMM</article-title>. <source>Neuroinformatics</source>, <volume>20</volume>(<issue>3</issue>), <fpage>737</fpage>–<lpage>753</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s12021-022-09568-5</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Ding</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Distinct brain state dynamics of native and second language processing during narrative listening in late bilinguals</article-title>. <source>Neuroimage</source>, <volume>280</volume>, <fpage>120359</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120359</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vidaurre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, &amp; <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Brain network dynamics are hierarchically organized in time</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>114</volume>(<issue>48</issue>), <fpage>12827</fpage>–<lpage>12832</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1705120114</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vyas</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Golub</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Sussillo</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Computation Through Neural Population Dynamics</article-title>. <source>Annu Rev Neurosci</source>, <volume>43</volume>, <fpage>249</fpage>–<lpage>275</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-092619-094115</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whitfield-Gabrieli</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Nieto-Castanon</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Conn: a functional connectivity toolbox for correlated and anticorrelated brain networks</article-title>. <source>Brain Connectivity</source>, <volume>2</volume>(<issue>3</issue>), <fpage>125</fpage>–<lpage>141</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yeo</surname>, <given-names>B. T.</given-names></string-name>, <string-name><surname>Krienen</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Sepulcre</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sabuncu</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Lashkari</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hollinshead</surname>, <given-names>M.</given-names></string-name>, … <string-name><surname>Polimeni</surname>, <given-names>J. R.</given-names></string-name></person-group> (<year>2011</year>). <article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>. <source>Journal of neurophysiology</source>.</mixed-citation></ref>
</ref-list>
<sec id="s7">
<title>Supplementary Material</title>
<sec id="s7a">
<title>Functional network detection</title>
<p>Network detection was performed following the method proposed by (<xref ref-type="bibr" rid="c13">Ji et al., 2019</xref>), using fMRI data from the 64 participants engaged in narrative comprehension. First, the mean time series of 246 regions defined by the Brainnetome atlas (Fan et al., 2016) was extracted, and a functional connectivity (FC) matrix was computed for each participant and then averaged across them. This atlas covers both cortical and subcortical regions and is made based on both anatomical and functional connectivity (FC) patterns. Next, community detection was performed on the group-averaged FC matrix applying the Louvain clustering algorithm in the Brain connectivity toolbox (<ext-link ext-link-type="uri" xlink:href="https://sites.google.com/site/bctnet/">https://sites.google.com/site/bctnet/</ext-link>). Three criteria were taken into account when determining the Gamma parameter in the algorithm, including (1) separation of primary sensory-motor network (visual, auditory and somatomotor) from all other networks (i.e., neurobiologically sensible); (2) high similarity of network partitions across nearby parameters (i.e., statistically stable); and (3) high with-network connectivity relative to between-network connectivity (i.e., high modularity).</p>
<p>A set of gamma values ranging from 1.2 to 2.5 were tested. For every tested gamma, we ran the algorithm 1,000 times and measured how consistent a given partition was to every other partition using a z-rand score. Each z-rand score averaged across the iterations was then multiplied by its corresponding modularity score to find a modularity-weighted z-rand score. Finally, the gamma value (gamma =2.5) was selected, which corresponded to the peak of the modularity-weighted z-rand score meanwhile satisfying the three criteria of finding a plausible number of networks including the primary sensory/motor networks. We implemented network detection using codes published by a prior study (<xref ref-type="bibr" rid="sc1">Barnett et al., 2021</xref>).</p>
<p>A total of 11 networks were obtained by the above method. We discarded two networks which comprised too few nodes (less than three), and subsequent analyses included nine networks.</p>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><p>The spatial maps of 11 networks derived from whole-brain parcellation using data from 64 participants engaged in narrative comprehension. The last unlabeled two networks consisted of only one or two nodes (parcels), and therefore were not included in further analyses.</p></caption>
<graphic xlink:href="598625v1_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Fig. S2.</label>
<caption><p>Replicating the findings with the 7-network atlas to parcellate brain networks. <bold>(a)</bold> Model selection. The model with K=3 achieved the overall best performance in terms of clustering and accuracy in classifying three narratives. <bold>(b)</bold> Activity patterns of latent states. <bold>(c)</bold> Between-state switching probabilities. State#2 was the transitional hub. Topological properties of whole brain networks when occupied by each state. At State#2, the brain exhibited the highest global efficiency and lowest modularity. <bold>(e)</bold> The modulation of state expression probability by narrative properties. <bold>(f)</bold> Alignment with the best performer predicted participants’ narrative comprehension performance.</p></caption>
<graphic xlink:href="598625v1_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Fig. S3.</label>
<caption><p>Replicating the major result on an independent dataset consisting of older adults. <bold>(a)</bold> Model selection. The model with K=3 achieved the overall best performance in terms of clustering and accuracy in classifying two narratives. <bold>(b)</bold> Activity patterns of latent states. Note, each of the three state was exclusively correlated to one of the target states (from the young group) in activity patterns, as demonstrated in the matrix. <bold>(c)</bold> Between-state switching probabilities. State#2 was the transitional hub. <bold>(d)</bold> Topological properties of whole brain networks when occupied by each state. At State#2, the brain exhibited the highest global efficiency and lowest modularity. <bold>(d)</bold> The modulation of state expression probability by narrative properties.</p></caption>
<graphic xlink:href="598625v1_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s7b">
<title>Reconstruction of latent states using Hierarchical clustering</title>
<p>We explored whether the latent states derived from HHM with K=3 can be reconstructed from smaller, more nuanced patterns. To this end, we applied an agglomerative hierarchical clustering algorithm to the transition probability matrix derived from HMM with K = 4, 10 and 12, respectively, and obtained three clusters from each. Next, we compared the clusters with the target states (i.e., those resulting from the HMM with K=3) in terms of similarities in activity patterns (spatial overlap) and the time course of state expression (temporal overlap).</p>
<p>To evaluate the spatial overlap, we first averaged the activation values across those states belonging to the same cluster, merging them into a single new state. Then we assessed the similarity in the activity patterns between the merged states and the target states using Pearson’s correlation. To evaluate temporal overlap, we first substituted states belonging to the same cluster with the newly formed one, then computed Jaccard Similarity between the sequences of the new states and the sequences of the targeted states.</p>
<p>There was a clear and exclusive correspondence between clusters reconstructed from both the 4-state and 10-state models and the predefined target states in terms of activity patterns (r<sub>(6)</sub> ranges from 0.72 to 0.98). The timing of state expression was also well aligned between the reconstructed model and the target model (more than 77 % overlap across a total of 19, 200 time points for 64 participants). For the 12-states model, we also found two reconstructed clusters resembling State#1 and State#3 (Fig.S2). Probe on the cluster that deviated most from the target states showed that it consisted of nine states, possibly capturing too many nuanced patterns of neural dynamics. Indeed, when splitting this “big” cluster into two smaller ones, one of them demonstrated significant similarity to State#2 (r<sub>(7)</sub>=0.75).</p>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><title>Reconstructing the tripartite-state space from smaller states.</title>
<p>Left and middle panels: States inferred by HMM with K= 4,10, and 12 were hierarchically grouped into three clusters based on between-states transition probability matrix. Right panels: The reconstructed states (clusters) from the 4- and 10-state models show high and exclusive similarity to the three states (targets) inferred by HMM=3.</p></caption>
<graphic xlink:href="598625v1_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<ref-list>
<title>Reference</title>
<ref id="sc1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barnett</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Reilly</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Dimsdale-Zucker</surname>, <given-names>H. R.</given-names></string-name>, <string-name><surname>Mizrak</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Reagh</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Ranganath</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Intrinsic connectivity reveals functionally distinct cortico-hippocampal networks in the human brain</article-title>. <source>PLoS Biology</source>, <volume>19</volume>(<issue>6</issue>), <fpage>e3001275</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.3001275</pub-id></mixed-citation></ref>
<ref id="sc2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ji</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Spronk</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kulkarni</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Repovš</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Anticevic</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Cole</surname>, <given-names>M. W.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Mapping the human brain’s cortical-subcortical functional network organization</article-title>. <source>NeuroImage</source>, <volume>185</volume>, <fpage>35</fpage>–<lpage>57</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.006</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99997.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Martin</surname>
<given-names>Andrea E</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Psycholinguistics</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>Liu and colleagues' study provides <bold>important</bold> insights into the neural mechanisms of narrative comprehension by identifying three distinct brain states using a hidden Markov model on fMRI data. The work is <bold>compelling</bold>, as it demonstrates that the dynamics of these brain states, particularly their timely expression, are linked to better comprehension and are specific to spoken language processing. The study's robust findings, validated in a separate dataset, will be of broad interest to researchers exploring the neural basis of speech and language comprehension, as well as those studying the relationship between dynamic brain states and cognition.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99997.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Liu and colleagues applied the hidden Markov model on fMRI to show three brain states underlying speech comprehension. Many interesting findings were presented: brain state dynamics were related to various speech and semantic properties, timely expression of brain states (rather than their occurrence probabilities) was correlated with better comprehension, and the estimated brain states were specific to speech comprehension but not at rest or when listening to non-comprehensible speech.</p>
<p>Strengths:</p>
<p>Recently, the HMM has been applied to many fMRI studies, including movie watching and rest. The authors cleverly used the HMM to test the external/linguistic/internal processing theory that was suggested in comprehension literature. I appreciated the way the authors theoretically grounded their hypotheses and reviewed relevant papers that used the HMM on other naturalistic datasets. The manuscript was well written, the analyses were sound, and the results had clear implications.</p>
<p>Weaknesses:</p>
<p>Further details are needed for the experimental procedure, adjustments needed for statistics/analyses, and the interpretation/rationale is needed for the results.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99997.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Liu et al. applied hidden Markov models (HMM) to fMRI data from 64 participants listening to audio stories. The authors identified three brain states, characterized by specific patterns of activity and connectivity, that the brain transitions between during story listening. Drawing on a theoretical framework proposed by Berwick et al. (TICS 2023), the authors interpret these states as corresponding to external sensory-motor processing (State 1), lexical processing (State 2), and internal mental representations (State 3). States 1 and 3 were more likely to transition to State 2 than between one another, suggesting that State 2 acts as a transition hub between states. Participants whose brain state trajectories closely matched those of an individual with high comprehension scores tended to have higher comprehension scores themselves, suggesting that optimal transitions between brain states facilitated narrative comprehension.</p>
<p>Overall, the conclusions of the paper are well-supported by the data. Several recent studies (e.g., Song, Shim, and Rosenberg, eLife, 2023) have found that the brain transitions between a small number of states; however, the functional role of these states remains under-explored. An important contribution of this paper is that it relates the expression of brain states to specific features of the stimulus in a manner that is consistent with theoretical predictions.</p>
<p>(1) It is worth noting, however, that the correlation between narrative features and brain state expression (as shown in Figure 3) is relatively low (~0.03). Additionally, it was unclear if the temporal correlation of the brain state expression was considered when generating the null distribution. It would be helpful to clarify whether the brain state expression time courses were circularly shifted when generating the null.</p>
<p>(2) A strength of the paper is that the authors repeated the HMM analyses across different tasks (Figure 5) and an independent dataset (Figure S3) and found that the data was consistently best fit by 3 brain states. However, it was not entirely clear to me how well the 3 states identified in these other analyses matched the brain states reported in the main analyses. In particular, the confusion matrices shown in Figure 5 and Figure S3 suggests that that states were confusable across studies (State 2 vs. State 3 in Fig. 5A and S3A, State 1 vs. State 2 in Figure 5B). I don't think this takes away from the main results, but it does call into question the generalizability of the brain states across tasks and populations.</p>
<p>(3) The three states identified in the manuscript correspond rather well to areas with short, medium, and long temporal timescales (see Hasson, Chen &amp; Honey, TiCs, 2015). Given the relationship with behavior, where State 1 responds to acoustic properties, State 2 responds to word-level properties, and State 3 responds to clause-level properties, the authors may want to consider a &quot;single-process&quot; account where the states differ in terms of the temporal window for which one needs to integrate information over, rather than a multi-process account where the states correspond to distinct processes.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99997.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Lanfang</surname>
<given-names>Liu</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1448-9009</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Jiahao</surname>
<given-names>Jiang</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6335-391X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Hehui</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Guosheng</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>Liu and colleagues applied the hidden Markov model on fMRI to show three brain states underlying speech comprehension. Many interesting findings were presented: brain state dynamics were related to various speech and semantic properties, timely expression of brain states (rather than their occurrence probabilities) was correlated with better comprehension, and the estimated brain states were specific to speech comprehension but not at rest or when listening to non-comprehensible speech.</p>
<p>Strengths:</p>
<p>Recently, the HMM has been applied to many fMRI studies, including movie watching and rest. The authors cleverly used the HMM to test the external/linguistic/internal processing theory that was suggested in comprehension literature. I appreciated the way the authors theoretically grounded their hypotheses and reviewed relevant papers that used the HMM on other naturalistic datasets. The manuscript was well written, the analyses were sound, and the results had clear implications.</p>
<p>Weaknesses:</p>
<p>Further details are needed for the experimental procedure, adjustments needed for statistics/analyses, and the interpretation/rationale is needed for the results.</p>
</disp-quote>
<p>We greatly appreciate the reviewers for the insightful comments and constructive suggestions. Below are the revisions we plan to make:</p>
<p>(1) Experimental Procedure: We will provide a more detailed description of the stimuli and comprehension tests in the revised manuscript. Additionally, we will upload the corresponding audio files and transcriptions as supplementary data to ensure full transparency.</p>
<p>(2) Statistics/Analyses: In response to the reviewer's suggestions, we have reproduced the states' spatial maps using unnormalized activity patterns. For the resting state, we observed a state similar to the baseline state described by Song, Shim, &amp; Rosenberg (2023). However, for the speech comprehension task, all three states showed network activity levels that deviated significantly from zero. Furthermore, we regenerated the null distribution for behavior-brain state correlations using a circular shift approach, and the results remain largely consistent with our previous findings. We have also made other adjustments to the analyses and introduced some additional analyses, as per the reviewer's recommendations. These changes will be incorporated into the revised manuscript.</p>
<p>(3) Interpretation/Rationale: We will expand on the interpretation of the relationship between state occurrence and semantic coherence. Specifically, we will highlight that higher semantic coherence may enable the brain to more effectively accumulate information over time. State #2 appears to be involved in the integration of information over shorter timescales (hundreds of milliseconds), while State #3 is engaged in longer timescales (several seconds).</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Liu et al. applied hidden Markov models (HMM) to fMRI data from 64 participants listening to audio stories. The authors identified three brain states, characterized by specific patterns of activity and connectivity, that the brain transitions between during story listening. Drawing on a theoretical framework proposed by Berwick et al. (TICS 2023), the authors interpret these states as corresponding to external sensory-motor processing (State 1), lexical processing (State 2), and internal mental representations (State 3). States 1 and 3 were more likely to transition to State 2 than between one another, suggesting that State 2 acts as a transition hub between states. Participants whose brain state trajectories closely matched those of an individual with high comprehension scores tended to have higher comprehension scores themselves, suggesting that optimal transitions between brain states facilitated narrative comprehension.</p>
<p>Overall, the conclusions of the paper are well-supported by the data. Several recent studies (e.g., Song, Shim, and Rosenberg, eLife, 2023) have found that the brain transitions between a small number of states; however, the functional role of these states remains under-explored. An important contribution of this paper is that it relates the expression of brain states to specific features of the stimulus in a manner that is consistent with theoretical predictions.</p>
<p>(1) It is worth noting, however, that the correlation between narrative features and brain state expression (as shown in Figure 3) is relatively low (~0.03). Additionally, it was unclear if the temporal correlation of the brain state expression was considered when generating the null distribution. It would be helpful to clarify whether the brain state expression time courses were circularly shifted when generating the null.</p>
</disp-quote>
<p>We have regenerated the null distribution by circularly shifting the state time courses. The results remain consistent with our previous findings: p = 0.002 for the speech envelope, p = 0.007 for word-level coherence, and p = 0.001 for clause-level coherence.</p>
<p>We notice that in other studies which examined the relationship between brain activity and word embedding features, the group-mean correlation values are similarly low but statistically significant and theoretically meaningful (e.g., Fernandino et al., 2022; Oota et al., 2022). We think these relatively low correlations is primarily due to the high level of noise inherent in neural data. Brain activity fluctuations are shaped by a variety of factors, including task-related cognitive processing, internal thoughts, physiological states, as well as arousal and vigilance. Additionally, the narrative features we measured may account for only a small portion of the cognitive processes occurring during the task. As a result, the variance in narrative features can only explain a limited portion of the overall variance in brain activity fluctuations.</p>
<p>We will update Figure 3 and relevant supplementary figures to reflect the new null distribution generated via circular shift. Furthermore, we will expand the discussion to address why the observed brain-stimuli correlations are relatively small, despite their statistical significance.</p>
<disp-quote content-type="editor-comment">
<p>(2) A strength of the paper is that the authors repeated the HMM analyses across different tasks (Figure 5) and an independent dataset (Figure S3) and found that the data was consistently best fit by 3 brain states. However, it was not entirely clear to me how well the 3 states identified in these other analyses matched the brain states reported in the main analyses. In particular, the confusion matrices shown in Figure 5 and Figure S3 suggests that that states were confusable across studies (State 2 vs. State 3 in Fig. 5A and S3A, State 1 vs. State 2 in Figure 5B). I don't think this takes away from the main results, but it does call into question the generalizability of the brain states across tasks and populations.</p>
</disp-quote>
<p>We identified matching states across analyses based on similarity in the activity patterns of the nine networks. For each candidate state identified in other analyses, we calculate the correlation between its network activity pattern and the three predefined states from the main analysis, and set the one it most closely resembled to be its matching state. For instance, if a candidate state showed the highest correlation with State #1, it was labelled State #1 accordingly.</p>
<p>Each column in the confusion matrix depicts the similarity of each candidate state with the three predefined states. In Figure S3 (analysis for the replication dataset), the highest similarity occurred along the diagonal of the confusion matrix. This means that each of the three candidate states was best matched to State #1, State #2, and State #3, respectively, maintaining a one-to-one correspondence between the states from two analyses.</p>
<p>For the comparison of speech comprehension task with the resting and the incomprehensible speech condition, there was some degree of overlap or &quot;confusion.&quot; In Figure 5A, there were two candidate states showing the highest similarity to State #2. In this case, we labelled the candidate state with the the strongest similarity as State #2, while the other candidate state is assigned as State #3 based on this ranking of similarity. This strategy was also applied to naming of states for the incomprehensible condition. The observed confusion supports the idea that the tripartite-state space is not an intrinsic, task-free property. To make the labeling clearer in the presentation of results, we will use a prime symbol (e.g., State #3') to indicate cases where such confusion occurred, helping to distinguish these ambiguous matches.</p>
<p>In the revised manuscript, we will give a detailed illustration for how the correspondence of states across analyses were made.</p>
<disp-quote content-type="editor-comment">
<p>(3) The three states identified in the manuscript correspond rather well to areas with short, medium, and long temporal timescales (see Hasson, Chen &amp; Honey, TiCs, 2015). Given the relationship with behavior, where State 1 responds to acoustic properties, State 2 responds to word-level properties, and State 3 responds to clause-level properties, the authors may want to consider a &quot;single-process&quot; account where the states differ in terms of the temporal window for which one needs to integrate information over, rather than a multi-process account where the states correspond to distinct processes.</p>
</disp-quote>
<p>The temporal window hypothesis indeed provides a better explanation for our results. Based on the spatial maps and their modulation by speech features, States #1, #2, and #3 seem to correspond to the short, medium, and long processing timescales, respectively. We will update the discussion to reflect this interpretation.</p>
<p>We sincerely appreciate the constructive suggestions from the two anonymous reviewers, which have been highly valuable in improving the quality of the manuscript.</p>
</body>
</sub-article>
</article>