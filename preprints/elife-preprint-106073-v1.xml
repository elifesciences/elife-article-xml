<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106073</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106073</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106073.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Disinformation elicits learning biases</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Vidal-Perez</surname>
<given-names>Juan</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
<email>juanvidalpe@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dolan</surname>
<given-names>Raymond J</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Moran</surname>
<given-names>Rani</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A3">3</xref>
<email>rani.moran@gmail.com</email>
</contrib>
<aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Max Planck Centre for Computational Psychiatry and Ageing, University College London</institution></institution-wrap>, <city>London</city> <country country="GB">United Kingdom</country></aff>
<aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Wellcome Centre for Human Neuroimaging, University College London</institution></institution-wrap>, <city>London</city> <country country="GB">United Kingdom</country></aff>
<aff id="A3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026zzn846</institution-id><institution>Department of Psychology, School of Biological and Behavioural Sciences, Queen Mary University of London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement" id="FN1"><p>Competing Interests: Authors declare that they have no competing interests.</p></fn>
</author-notes>
<pub-date pub-type="epub">
<day>17</day>
<month>01</month>
<year>2025</year>
</pub-date>
<pub-date date-type="original-publication" iso-8601-date="2025-05-12">
<day>12</day>
<month>05</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106073</elocation-id>
<history><date date-type="sent-for-review" iso-8601-date="2025-01-28">
<day>28</day>
<month>01</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-17">
<day>17</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.31219/osf.io/st4kg"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Vidal-Perez et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Vidal-Perez et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106073-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>In open societies disinformation is often considered a threat to the very fabric of democracy. However, we know little about how disinformation exerts its impact, especially its influences on individual learning processes. Guided by the notion that disinformation exerts its pernicious effects by capitalizing on learning biases, we ask which aspects of learning from potential disinformation align with normative “Bayesian” principles, and which exhibit biases deviating from these standards. To this end, we harnessed a reinforcement learning framework, offering computationally tractable models capable of estimating latent aspects of a learning process as well as identifying biases in learning. Across two experiments, computational modelling indicated that learning increased in tandem with source credibility, consistent with normative Bayesian principles. However, we also observed striking biases reflecting divergence from normative learning patterns. Notably, individuals learned from sources that should have been ignored, as these were known to be fully unreliable. Additionally, the presence of disinformation elicited exaggerated learning from trustworthy information (akin to jumping to conclusions) and exacerbated a “positivity bias” whereby individuals self-servingly boost their learning from positive, compared to negative, choice-feedback. Thus, in the face of disinformation we identify specific cognitive mechanisms underlying learning biases, with potential implications for societal strategies aimed at mitigating its harmful impacts.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1" sec-type="intro">
<title>Introduction</title>
<p>Disinformation is a pervasive and pernicious feature of the modern world (<xref ref-type="bibr" rid="c1">1</xref>). It is linked to negative social impacts that include public-health risks (<xref ref-type="bibr" rid="c2">2</xref>–<xref ref-type="bibr" rid="c4">4</xref>), political radicalization (<xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c6">6</xref>), violence (<xref ref-type="bibr" rid="c6">6</xref>–<xref ref-type="bibr" rid="c8">8</xref>) and adherence to conspiracy theories (<xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref>). Consequently, there is a growing interest in comprehending how false information propagates across social networks (<xref ref-type="bibr" rid="c10">10</xref>–<xref ref-type="bibr" rid="c12">12</xref>), including an interest in designing strategies to curb its impact (<xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c16">16</xref>) albeit with limited success to date (<xref ref-type="bibr" rid="c17">17</xref>). However, there is also a considerable knowledge lacuna regarding how individuals learn and update their beliefs when exposed to potential disinformation. Addressing this gap is crucial, as it has been suggested that disinformation propagates by exploiting cognitive biases (<xref ref-type="bibr" rid="c18">18</xref>–<xref ref-type="bibr" rid="c22">22</xref>). Thus, discerning which aspects of learning from potential disinformation are <italic>normative</italic> versus <italic>biased</italic> has the potential to better enable targeted interventions aimed at countering its harmful effects.</p>
<p>We start with an assessment of a normative, Bayesian, prediction that individuals should modulate their learning as a function of the credibility of an information source, and learn more from credible, truthful, sources. This prediction is supported by previous findings showing that individuals flexibly and adaptively adjust their learning rates in response to key statistical features of the environment. For example, learning is more rapid when observation-uncertainty (“noise”) decreases and in volatile, changing, compared to stable environments, particularly following detection of change-points that render re-change knowledge obsolete (<xref ref-type="bibr" rid="c23">23</xref>–<xref ref-type="bibr" rid="c25">25</xref>). Moreover, human choice is strongly influenced by social information of high (as opposed to low) credibility, such as majority opinions more confident judgments (<xref ref-type="bibr" rid="c26">26</xref>) and large group consensus (<xref ref-type="bibr" rid="c27">27</xref>). Additionally, people are disposed to follow trustworthy advisors (<xref ref-type="bibr" rid="c28">28</xref>), including those who have recommended optimal actions in the past (<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref>).</p>
<p>We hypothesised that in a disinformation context individuals would show significant deviations from normative learning, reflecting a diversity of biases. First, filtering non-credible information is likely to be cognitively demanding (<xref ref-type="bibr" rid="c31">31</xref>), and this predicts such information would impact belief updating, even if individuals are aware it is untrustworthy. An additional consideration is that humans tend to learn more from positive self-confirming information (<xref ref-type="bibr" rid="c32">32</xref>–<xref ref-type="bibr" rid="c34">34</xref>), which presents one in a positive light. We conjectured, influenced by ideas from motivated-cognition (<xref ref-type="bibr" rid="c35">35</xref>), that low-credibility information provides a pathway for amplification of such a bias, as uncertainty regarding information-veracity might dispose individuals to self-servingly interpret positive information as true and explain-away negative information as false. A final additional consideration is the question of how exposure to potential disinformation impacts on learning from trusted sources. One possibility is that disinformation serves as a background context against which credible information would appear more salient. Alternatively, it might lead individuals to strategically reduce their overall learning in disinformation-rich environments, resulting in diminished learning from credible sources.</p>
<p>To address these questions, we adopt a novel approach within the disinformation literature by exploiting a Reinforcement Learning (RL) experimental framework (<xref ref-type="bibr" rid="c36">36</xref>). This has the advantage that it provides a suite of behavioural tasks, and computationally tractable models, that enable estimation of latent aspects of learning processes, such as belief updating. Moreover, RL also enables an examination of the dynamics of belief updates over short timescales reflecting real-life engagements with disinformation, such as deciding whether to share a post on social media. Moreover, RL has proven success in characterizing key decision-making biases (e.g., positivity bias (<xref ref-type="bibr" rid="c37">37</xref>–<xref ref-type="bibr" rid="c39">39</xref>)), albeit in scenarios where learners receive accurate information. Within RL, we can also establish benchmarks of Bayesian learning that allow a characterization of biases and deviations from normative standards. Finally, a previous literature has suggested a role for reinforcement in the dissemination of disinformation, where individuals may receive positive reinforcement (likes, shares) for spreading sensationalized or misleading information on social media platforms, inadvertently reinforcing such behaviours and contributing to a disinformation proliferation (<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c40">40</xref>,<xref ref-type="bibr" rid="c41">41</xref>).</p>
<p>We developed a novel “disinformation” version of the classical two-armed bandit task to test the effects of potential disinformation on learning. In the <italic>hallmark</italic> two-armed bandit task (<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c42">42</xref>), participants choose repeatedly between two unfamiliar bandits (i.e., slot machines), that provided rewards with different probabilities, to learn which bandit is more rewarding. Critically, in our <italic>disinformation</italic>-variant, true choice outcomes (reward or non-reward) were <italic>latent</italic>, i.e., unobservable. Instead, participants were informed about choice-outcomes by computer-programmed “feedback agents”, who were disposed to occasionally disseminate disinformation by lying (reporting a reward when the true outcome was non-reward or vice versa). As these feedback-agents varied in truthfulness, this allowed us to test the effects of source-credibility on learning. We show across two studies that the extent of belief-updates increases as a function of source-credibility. However, there were striking deviations from normative Bayesian learning, where we identify several sources of bias related to processing potential disinformation. These included learning from non-credible information, an amplified positivity bias for non-credible sources, and increased learning from trustworthy information when it was preceded by non-credible information.</p>
</sec>
<sec id="s2" sec-type="results">
<title>Results</title>
<sec id="s2-1">
<title>Disinformation two-armed bandit task</title>
<p>We conducted a discovery (n=104) and follow-up study (n=204). In both studies the learning tasks had the same basic structure but with a few subtle differences between them (see Discovery study and SI Discovery study methods). To anticipate, the results of both studies support similar conclusions, and, in the results section, we focus on the main study, with the final results section detailing similarities and differences in findings across the two studies.</p>
<p>In the main study, participants (n=204) completed the <italic>disinformation</italic> two-armed bandit task. In the <italic>traditional</italic> two-armed bandit task (<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c42">42</xref>), participants choose between two slot-machines (i.e., bandits) differing in their reward probability. Participants are not instructed about bandit rewardprobabilities but instead they are provided with veridical choice feedback (e.g., reward or nonreward), allowing participants to learn which bandit is more rewarding. By contrast, in our disinformation version <italic>true</italic> choice-outcomes were latent (i.e., unobserved) and participants were informed about these outcomes via three computerized feedback-agents, who had privileged access to the true outcomes.</p>
<p>Before commencing the task, participants were instructed that feedback agents could disseminate disinformation, meaning that they were disposed to lie on a random minority of trials, reporting a reward when the true outcome was a non-reward, or vice versa (<xref ref-type="fig" rid="fig1">Fig. 1a</xref>). Participants were explicitly instructed about the credibility of each agent (i.e., based on the proportion of truth-telling trials), indicated by a “star system”: the 3-star agent was always truthful, the 2-star agents told the truth on 75% of the trials while the 1-star agent did so on 50% of the trials (<xref ref-type="fig" rid="fig1">Fig. 1b</xref>). Note that while the 1-star agent’s feedback was statistically equivalent to random feedback, participants were not explicitly instructed about this equivalence. Each experimental block encompassed 3 bandit pairs, each presented over 15 trials in a randomly interleaved manner. Each agent provided feedback for 5 trials for each bandit pair (with the agent order interleaved within the bandit pair). Thus, in every trial, participants were presented with one of the bandit pairs and the feedback agent associated with that trial. Upon selecting a bandit, they then received feedback from the agent (<xref ref-type="fig" rid="fig1">Fig. 1c</xref>). Importantly, at the end of the experiment participants received a performance-based bonus based on <italic>true</italic> bandit outcomes, which could differ from agent-provided feedback. Within each bandit-pair one bandit provided a (true) reward on 75% of the trials and the other on 25% of trials. Choice accuracy, i.e., the probability of selecting the more rewarding bandit (within each pair), was significantly above chance (mean accuracy = 0.62, t(203) = 19.94, p &lt;.001) and improved as a function of increasing experience with each bandit-pair (average overall improvement over 15 trials = 0.22, t(203)=19.95, p&lt;0.001) (<xref ref-type="fig" rid="fig1">Fig. 1d</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Task design and performance.</title>
<p><bold>a</bold>, Illustration of agent-feedback. Each selected bandit generated a <italic>true</italic> outcome, either a reward or a non-reward. Participants <italic>did not</italic> see this true outcome but instead were informed about it via a computerised feedback agent (reward: dollar sign; non-reward: sad emoji). Agents told the truth on most trials (left panel). However, on a random minority of trials they lied, reporting a reward when the true outcome was a non-reward or vice versa (right panel). <bold>b,</bold> Participants received feedback from 3 distinct feedback agents of variable credibility (i.e., truth-telling probability). Credibility was represented using a starbased system: a 3-star agent always reported the truth (and never lied), a 2-star agent reported the truth on 75% of trials (lying on the remaining 25%), and a 1-star agent reported the truth half of the time (lying on the other half). Participants were explicitly instructed and quizzed about the credibility of each agent prior to the task. <bold>c,</bold> Trial-structure: On each trial participants were first presented with the feedback agent for that trial (here, the 2-star agent) and next offered a choice between a pair of bandits (represented by identicons) (for 2sec). Next, choice-feedback was provided by the agent. <bold>d,</bold> Learning curves. Average choice accuracy as a function of trial number (within a bandit-pair). Thin lines: individual participants; thick line: group mean with thickness representing the group standard error of the mean for each trial.</p></caption>
<graphic xlink:href="st4kgv3_fig1.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-2">
<title>Credible feedback promotes greater learning</title>
<p>A hallmark of RL value-learning is that participants are more likely to repeat a choice following positive compared to negative reward-feedback (henceforth, “feedback effect on choice repetition”). We tested a hypothesis, based on Bayesian-normative reasoning, that this tendency would increase as a function of agent-credibility (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>). Thus, in a binomial mixed-effects model we regressed choicerepetition (i.e., whether participants repeated their choice from the most recent trial featuring the same bandit pair; 0-switch; 1-repeat) on feedback-valence (negative or positive) and agent-credibility (1,2, or 3-star), where these are taken from the last trial featuring the same bandit pair (Methods for model-specification). Feedback valence exerted a positive effect on choice-repetition (b=0.72, F(1,2436)=1369.6, p&lt;0.001) and interacted with agent-credibility (F(2,2436)=307.11, p&lt;0.001), with a feedback effect being greater for more credible agents (3-star vs. 2-star: b= 0.91, F(1,2436)=351.17; 3-star vs. 1-star: b=1.15, t(2436)=24.02; and 2-star vs. 1-star: b=0.24, t(2436)=5.34, all p’s&lt;0.001). Additionally, we found a positive feedback-effect for the 3-star agent (b=1.41, F(1,2436)=1470.2, p&lt;0.001), and a smaller feedback-effect for the 2-star agent (b=0.49 ,F(1,2436)=230.0, p&lt;0.001). These results support our hypothesis that learning increases as a function of information credibility (note that the feedback effect for the 1-star agent is examined below; see “Non-credible feedback elicits learning”).</p>
<p>To confirm that increased learning based on information credibility is expected under an assumption that subjects adhere to normative Bayesian reasoning, we formulated two Bayesian models whereby the latent value of each bandit is represented as a distribution over the probability that a bandit is truly rewarding. During the feedback stage of each trial, the value of the chosen bandit is updated (based on feedback valence and credibility) according to Bayes rule (<xref ref-type="fig" rid="fig2">Fig. 2a</xref>, top panel; Fig. S5c for an illustration of the model; for full model descriptions, see Methods). In the <italic>instructed-credibility Bayesian</italic> model, belief-updates are based on the <italic>instructed</italic> credibility of feedback-sources. In contrast, a <italic>free-credibility Bayesian</italic> model, allows for the possibility that value inference is Bayesian but based on “distorted probabilities”(<xref ref-type="bibr" rid="c43">43</xref>), attributing <italic>non-instructed</italic> degrees of credibility to sources of false information (despite our explicit instructions on the credibility of different agents). In this variant, we fixed the credibility of the 3-star agent to 1 and estimated the credibility of 2 and 1-star agents as free parameters (which were highly recoverable; see Methods and SI 3.3). Simulations based on both Bayesian models (see Methods) predicted increased learning as a function of feedback credibility (<xref ref-type="fig" rid="fig3">Fig. 3b</xref>; top panels; SI 3.1.1.1 Tables S3 and S4 for statistical analysis).</p>
<p>Next, we formulated a family of <italic>non-Bayesian</italic> computational RL models. Importantly, these models can flexibly express non-Bayesian learning patterns and, as we show in following sections, can serve to identify non-normative learning biases. Here, an assumption is that during feedback, the value of a chosen bandit (which here is represented by a point estimate, “Q value”, rather than a distribution) either increases or decreases (for positive or negative feedback, respectively) according to a magnitude quantified by the free “Credit-Assignment (CA)” model parameters(<xref ref-type="bibr" rid="c44">44</xref>) (<xref ref-type="fig" rid="fig2">Fig. 2a</xref>, bottom panel; Fig. S5b; Methods). Different model variants varied as to how task-variables influenced CA parameters with the “null” model attributing the same CA to all feedback-agents (regardless of their credibility, i.e., a single free CA-parameter), whereas the “credibility-CA” model availed of three separate CA parameters, one for each feedback agent, thereby allowing us to test how learning was modulated by feedback-credibility. Using a bootstrap generalized-likelihood ratio test for modelcomparison (Methods) we rejected the null model (group level: p&lt;0.001), in favour of the credibility-CA model. Furthermore, model-simulations based on participants best-fitting parameters (Methods) falsified the null model as it failed to predict credibility-modulated learning, showing instead, equal learning from all feedback sources (<xref ref-type="fig" rid="fig3">Fig, 3b</xref>; bottom-left panel). In contrast, the credibility-CA model successfully predicted increased learning as a function of credibility (<xref ref-type="fig" rid="fig3">Fig. 3b</xref>, bottom-right panel) (see SI 3.1.1.1 Tables S5 and S6).</p>
<p>After confirming CA parameters are highly recoverable (see Methods and SI 3.3), we examined how the Maximum Likelihood (ML) CA parameters from the credibility-CA model differed as a function of feedback credibility (<xref ref-type="fig" rid="fig3">Fig. 3c</xref>). Using a mixed effects model (Methods), we regressed the CA parameters on their associated agents, finding that CA differed across the agents (F(2,609)=212.65, p&lt;0.001), increasing as a function of agent-credibility (3-star vs. 2-star: b= 1.02, F(1,609)=253.73 ; 3-star vs. 1- star: b=1.24, t(609)=19.31; and 2-star vs. 1-star: b=0.22, t(609)=3.38, all p’s&lt;0.001). We found similar results in the discovery study (see SI 1.2.1). Thus, these results provide convergent support for our conjecture that feedback from more credible sources leads to more pronounced learning.</p>
</sec>
<sec id="s2-3">
<title>Substantial deviations from Bayesian learning</title>
<p>We next implemented a model comparison between each of the Bayesian models and the credibility-CA model, using a parametric bootstrap cross-fitting method (Methods). We found that the credibility-CA model provided a superior fit for 71% of participants (sign test; p&lt;0.001) when compared to the instructed-credibility Bayesian model, <xref ref-type="fig" rid="fig2">Fig. 2b</xref>; and for 53.9% (p=0.29) when compared to the free-credibility Bayesian model, <xref ref-type="fig" rid="fig2">Fig 2c</xref>). The discovery study revealed even stronger results supporting a conclusion that the credibility-CA model was superior to both Bayesian models for most subjects (see SI 1.2.2), suggesting pervasive deviations from normative learning.</p>
<p>To further characterise these deviations, we used a “cross-fitting” method. We simulated synthetic data based on <italic>Bayesian</italic> agents (using participants’ best fitting parameters), but fitted these data using the CA-models, obtaining what we term “Bayesian-CA parameters” (<xref ref-type="fig" rid="fig2">Fig. 2d</xref>; Methods). A comparison of these Bayesian-CA parameters, with empirical-CA parameters obtained by fitting CA models to empirical data, allowed us to uncover patterns consistent with, or deviating from, normative-Bayesian value-based inference. Using this approach, we found that both the instructed-credibility and free-credibility Bayesian models predicted increased Bayesian-CA parameters as a function of agent credibility (<xref ref-type="fig" rid="fig3">Fig. 3c</xref>; see SI 3.1.1.2 Tables S8 and S9). However, an in-depth comparison between Bayesian and empirical CA parameters revealed discrepancies from normative Bayesian learning.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Computational models and cross-fitting method.</title>
<p><bold>a</bold>, Summary of the two model families. Bayesian models (top panel) represent a benchmark for normative learning. In these models, the observer maintains a belief-distribution over the probability a bandit is <italic>truly</italic> rewarding (denoted <italic>r</italic>). On each trial, this distribution is updated for the selected bandit according to Bayes rule, based on the valence (i.e., rewarding/non-rewarding; denoted <italic>f</italic>) and credibility of the trial’s reward feedback (denoted <italic>c</italic>). Credit-assignment models (bottom panel) are used to test deviations from Bayesian learning. Here, the observer maintains a subjective point-value (denoted <italic>Q</italic>) for each bandit. On each trial the value of the chosen bandit is updated based on a free CA parameter, quantifying the extent of value increase/decrease following positive/negative feedback. CA parameters can be modulated by the valence and credibility of feedback. <bold>b,c,</bold> Model selection between the credibility-CA model and the two variants of Bayesian models. Most participants were best fitted by a credibility-CA model, compared to the instructed-credibility Bayesian model (b) or free-credibility Bayesian (c) models. <bold>d,</bold> Cross-fitting method: Firstly, we fit a Bayesian model to empirical data, to estimate its (ML) parameters. This yields the Bayesian learning token that comes closest to accounting for a participant’s choices. Secondly, we simulate synthetic data based on the Bayesian model, using its ML parameters to obtain instances of how a Bayesian learner would behave in our task. Thirdly, we fit these synthetic data with a CA model, thus estimating “Bayesian CA parameters”, i.e., CA parameters capturing the performance of a Bayesian model. Finally, we fit the CA model directly to empirical data to obtain “empirical CA parameters”. A comparison of Bayesian and empirical CA parameters, allows us to identify, which aspects of behaviour are consistent with Bayesian belief updating, as well as characterize biases in behaviour that deviate from normative Bayesian learning.</p></caption>
<graphic xlink:href="st4kgv3_fig2.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Learning adaptations to credibility.</title>
<p><bold>a</bold>, Probability of repeating a choice as a function of feedbackvalence and agent-credibility on the previous trial for the same bandit pair. The effect of feedback-valence on repetition increases as the feedback credibility increases, indicating that more credible feedback has a greater effect on behaviour. <bold>b,</bold> Similar analysis as in panel a, but for synthetic data obtained by simulating the main models. Simulations were computed using the ML parameters of participants for each model. The null model (<bold>bottom left</bold>) attributes a single CA to all credibility-levels, hence feedback exerts a constant effect on repetition (independently of its credibility). The credibility-CA model (<bold>bottom-right</bold>) allowed credit assignment to change as a function of source credibility, predicting varying effects of feedback with different credibility levels. The instructed-credibility Bayesian model (<bold>top left</bold>) updated beliefs normatively based on the true credibility of the feedback, and therefore predicted an increase effect of feedback on repetition as credibility increased. Finally, the free-credibility Bayesian model (<bold>top right</bold>) allowed for a possibility that participants use distorted credibilities for 1-star and 2-star agents when following a Bayesian strategy, also predicting an increase in the effect of feedback as credibility increased. <bold>c,</bold> ML credit assignment parameters for the credibility-CA model. Participants show a CA increase as a function of agent-credibility, as predicted by Bayesian-CA parameters for both the instructed-credibility and free-credibility Bayesian models. Moreover, participants showed a positive CA for the 1-star agent (which essentially provides feedback), which is only predicted by cross-fitting parameters for the free-credibility Bayesian model. <bold>d,</bold> ML credibility parameters for a free-credibility Bayesian model attributing credibility 1 to the 3-star agent but estimating credibility for the two lying agents as free parameters. Small dots represent results for individual participants/simulations, big circles represent the group mean (a,b,d) or median (c) of participants’ behaviour. Results of the synthetic model simulations are represented by diamonds (instructed-credibility Bayesian model), squares (free-credibility Bayesian model), upward-pointing triangles (null-CA model) and downward-pointing triangles (credibility-CA model). Error bars show the standard error of the mean. (*) p&lt;.05, (**) p&lt;0.01, (***) p&lt;.001.</p></caption>
<graphic xlink:href="st4kgv3_fig3.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-4">
<title>Non-credible feedback elicits learning</title>
<p>While our task instructions framed the 1-star agent as highly deceptive, lying 50% of the time, its feedback is statistically equivalent to entirely non-informative i.e., <italic>random</italic> feedback. Thus, normatively, participants should ignore and filter-out such feedback from their belief updates. Indeed, for the 1-star agent, simulations based on the instructed-credibility Bayesian model provided no evidence for either a positive feedback-effect on choice-repetition (mixed effects model described above; b=-0.01, t(2436)=-0.41, p=0.68; <xref ref-type="fig" rid="fig3">Fig 3b</xref> top-left) or a positive Bayesian-CA (b=-0.01, t(609)=- 0.31, p=0.76; <xref ref-type="fig" rid="fig3">Fig. 3c</xref>). However, contrary to this, we hypothesized that participants would struggle to entirely disregard non-credible feedback. Indeed, we found a positive feedback-effect on choicerepetition for the 1-star agent (mixed effects model, delta(M)=0.049, b=0.25, t(2436)=8.05, p&lt;0.001), indicating participants are more likely to repeat a bandit selection after receiving positive feedback from this agent (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>). Similarly, the CA parameter for the 1-star agent in the credibility-CA model was positive (b=0.23, t(609)=4.54, p&lt;0.001) (<xref ref-type="fig" rid="fig3">Fig. 3c</xref>). The upshot of this empirical finding is that participants updated their beliefs based on essentially random feedback (see Fig. S7 for analysis showing that this resulted in decreased accuracy rates).</p>
<p>A potential explanation for this finding is that participants <italic>do</italic> rely on a Bayesian strategy but “distort probabilities”, attributing non-instructed degrees of credibility to lying sources (despite our explicit instructions on the credibility of different agents). Consistent with this, the ML-estimated credibility of the 1-star agent (<xref ref-type="fig" rid="fig3">Fig. 3d</xref>) was significantly greater than 0.5 (Wilcoxon signed-rank test, median=0.08, z=5.50, p&lt;0.001), allowing the free-credibility Bayesian model to predict a positive feedback effect on choice-repetition (mixed-effects model: b=0.12, t(2436)=9.48, p&lt;0.001; <xref ref-type="fig" rid="fig3">Fig 3b</xref> top-right) and a positive Bayesian-CA (b=0.08, t(609)=3.32, p&lt;0.001; <xref ref-type="fig" rid="fig3">Fig. 3c</xref>) for the 1-star agent. For corresponding results in the discovery study see SI 1.2.3. In our Discussion we elaborate on why it might be difficult to filter out this feedback even if one can explicitly infer its randomness.</p>
</sec>
<sec id="s2-5">
<title>Increased learning from fully credible feedback when it follows noninformative feedback</title>
<p>A comparison of empirical and Bayesian credit-assignment parameters revealed a further deviation from normative learning: both Bayesian models predicted an attenuated credit-assignment for the 3- star agent [Wilcoxon signed-rank test, instructed-credibility Bayesian model (median difference=0.74, z=11.14); free-credibility Bayesian model (median difference=0.62, z=10.71), all p’s&lt;0.001] (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>). One explanation for enhanced learning for the 3-star agents is a contrast effect, whereby credible information looms larger against a backdrop of non-credible information. To test this hypothesis, we examined whether the impact of feedback from the 3-star agent is modulated by the credibility of the agent in the trial immediately preceding it. More specifically, we reasoned that the impact of a 3-star agent would be amplified by a “low credibility context” (i.e., when it is preceded by a low credibility trial), even when this context is entirely irrelevant for current learning. In a binomial mixed effects model, we regressed choice-repetition on feedback valence from the last trial featuring the same bandit pair, and on the feedback agent on the trial immediately preceding that last trial (i.e., the contextual credibility; Methods for model-specification). This analysis included only trials for which the last same-pair trial featured the 3-star agent and in which the context trial featured a different bandit pair (<xref ref-type="fig" rid="fig4">Fig. 4a</xref>). We found that feedback valence interacted with contextual credibility (F(2,2419)=5.06, p=0.006) such that a feedback-effect (from the 3-star agent) was greater when preceded by the temporal-context of the 1-star agent, compared to a context involving a 2-star (b=0.20, t(2419)=-2.42, p=0.016) or a 3-star agent (b=0.24, t(2419)=-3.01, p=0.003) (<xref ref-type="fig" rid="fig4">Fig. 4b</xref>). There was no difference between 2-star and 3-star agent contexts (b=0.051, F(1,2419)=0.39, p=0.53). Thus, these results support an interpretation that credible feedback exerts a greater impact on participants’ learning when it follows non-credible feedback.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Contextual effects and learning.</title>
<p><bold>a</bold>, Trials contributing to the analysis of effects of credibility-context on learning from the fully credible agent. We included only “current trials (n)” for which: 1) the last trial (trial n-k) offering the same bandit pair was associated with the 3-star agent, and 2) the immediately preceding context trial (n-k-1) featured a different bandit pair (providing a learning context irrelevant to current choice). We examined how choice-repetition (from n-k to n) was modulated by feedback valence on the last same-pair trial, and on the feedback agent on the context trial (i.e., the credibility context). Note the greyed-out star-rating on the current trial indicates the identity of the current agent and was not included in the analysis. <bold>b,</bold> Difference in probability of repeating a choice after receiving positive vs negative feedback (i.e., feedback effect) from the 3- star agent, as a function of the credibility context. The 3-star agent feedback-effect is greater when preceded by a low-credibility context (i.e., 1-star agent in preceding trial), than when preceded by a higher credibility context (i.e., 2-star or 3-star agent in preceding trial). Big circles represent the group mean, and error bars show the standard error of the mean. (*) p&lt;.05, (**) p&lt;0.01.</p></caption>
<graphic xlink:href="st4kgv3_fig4.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-6">
<title>Positivity bias in learning and credibility</title>
<p>Previous research has shown that reinforcement learning is characterized by a positivity bias, wherein subjects systematically learn more from positive than from negative feedback (<xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c39">39</xref>). One account is that this bias might result from motivated cognition influences on learning, whereby participants favour positive feedback that reflects well on their choices. We conjectured that feedback of ambiguous veracity (i.e., from the 1-star and 2-star agents) would promote this bias by allowing participants to explain-away negative feedback as a case of an agent-lying, while choosing to believe positive feedback. Previous research has quantified positivity bias in 2 ways: 1) as the <italic>absolute</italic> difference between credit-assignment based on positive or negative feedback, and 2) as the same difference but <italic>relative</italic> to the overall extent of learning.</p>
<p>To investigate this bias across different levels of feedback credibility we formulated a more detailed variant of the CA model. To quantify the extent of a chosen-bandit’s value increase or decrease - following positive or negative feedback respectively – the “credibility-valence-CA” variant included separate CA parameters for positive (CA+) and negative (CA-) feedback for each feedback agent. In effect, this model variant enabled us to test whether different levels of feedback credibility elicited a positivity bias (i.e., CA+ &gt; CA-). Using a bootstrap generalized-likelihood ratio test for model comparison (Methods), we rejected, in favour of the valence-credibility-CA model, the null-CA model, the credibility-CA model and a “constant feedback-valence bias” CA model, which attributed a common valence bias (CA+ minus CA-) to all agents (all group level: all p’s&lt;0.001). This test supported our choice of flexible CA parametrization as a factorial function of agent and feedback-valence.</p>
<p>After confirming the parameters of this model were highly recoverable (see Methods and SI 3.3), we used a mixed effects model to regress the ML parameters (<xref ref-type="fig" rid="fig5">Fig. 5a</xref>) on their associated agent-credibility and valence (see Methods). This revealed participants attributed a greater CA to positive feedback than to negative feedback (b=0.64, F(1,1218)=37.39, p&lt;0.001). Strikingly, for lying agents, participants selectively assigned credit based on positive feedback (1-star: b=0.61, F(1,1218)=22.81, p&lt;0.001; 2- star: b=0.85, F(1,1218)=43.5, p&lt;0.001), with no evidence for significant credit-assignment based on negative feedback (1-star: b=-0.03, F(1,1218)=0.07, p=0.79; 2-star: b=0.14, F(1,1218)=1.28, p=0.25). Only for the 3-star agent, credit-assignment was positive for both positive (b=1.83, F(1,1218)=203.1, p&lt;0.001) and negative (b=1.25, F(1,1218)=95.7, p=&lt;0.001) feedback. We found no significant interaction effect between feedback valence and credibility on CA (F(2,1218)=0.12, p=0.88; <xref ref-type="fig" rid="fig5">Fig. 5a-b</xref>).</p>
<p>However, we found evidence for agent-based modulation of positivity bias when this bias was measured in relative terms. Here we calculated, for each participant and agent, a relative Valence Bias Index (rVBI) as the difference between the Credit Assignment for positive feedback (CA<sup>+</sup>) and negative feedback (CA<sup>–</sup>), relative to the overall magnitude of CA (i.e., |CA<sup>+</sup>| + |CA<sup>–</sup>|) (<xref ref-type="fig" rid="fig5">Fig. 5c</xref>). rVBI was significantly positive for all credibility levels [Wilcoxon signed-rank test, 50% credibility (median=0.92, z=6.04), 75% credibility (median=0.73, z=6.69) and 100% credibility (median=0.21, z=4.96), all p’s&lt;0.001]. Critically, the rVBI varied depending on the credibility of feedback (Friedman test, χ2(<xref ref-type="bibr" rid="c2">2</xref>) = 62.39, p&lt;0.001), such that the rVBI for the 3-star agent was lower than that for both the 1-star (Wilcoxon signed rank tests, median difference = -0.42, z = -5.40, p&lt;0.001) and 2-start agent (median difference = -0.22, z = -5.63, p&lt;0.001). Feedback with 50% and 75% credibility yielded similar rVBI values (median difference (75%-50%) = -0.08, z = -1.91, p = 0.055). Results from the discovery study indicate similar conclusions (Fig. S3; see SI 1.2.5). Finally, a positivity bias could not stem from a Bayesian strategy as both Bayesian models predicted a negativity bias (<xref ref-type="fig" rid="fig5">Fig. 5b-c</xref>; Fig. S8; and SI 3.1.1.3 Table S11-S12, 3.2.1.1, and 3.2.1.2). The upshot is that positivity bias, relative to the overall extent of CA, was greater for lying than for fully-credible agents—a pattern deviating from Bayesian normativity.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Positivity bias as a function of agent-credibility.</title>
<p><bold>a</bold>, ML parameters from the credibility-valence-CA model. CA+ and CA-are free parameters representing credit assignments for positive and negative feedback respectively (for each credibility level). Our data revealed a positivity bias (CA+ &gt; CA-) for all credibility levels. <bold>b,</bold> Absolute valence bias index (defined as CA<sup>+</sup>-CA<sup>–</sup>) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>c,</bold> Relative valence bias index (defined as (CA<sup>+</sup>-CA<sup>–</sup>)/(|CA<sup>+</sup>|+|CA<sup>–</sup>|)) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. Small dots represent fitted parameters for individual participants and big circles represent the group median (a,b) or mean (c) (both of participants’ behavior), while squares are the median or mean of the fitted parameters of the free-credibility Bayesian model simulations. Error bars show the standard error of the mean. (***) p&lt;.001 for ML fits of participants behavior.</p></caption>
<graphic xlink:href="st4kgv3_fig5.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-7">
<title>True feedback elicits greater learning</title>
<p>Our findings are consistent with participant modulation of the extent of credit-assignment based <italic>solely</italic> on cued task-variables, such as feedback-credibility and valence. However, we also considered another possibility: that participants might infer, on a <italic>trial-by-trial</italic> basis, whether the feedback they received was true or false and adjust their credit assignment based on this inference. For example, for a given feedback-agent, participants might boost the credit assigned to a chosen bandit as a function of the degree to which they believe feedback was true. Notably, Bayesian inference can support a trial-level calculation of a posterior probability that feedback is true based on its credibility, valence and a prior belief (based on experiences in previous trials) regarding the probability that the chosen bandit is truly rewarding (<xref ref-type="fig" rid="fig6">Fig. 6a</xref>). These beliefs can partially discriminate between truthful and false feedback. As proof of this, we calculated a Bayesian posterior feedback-truthfulness belief for each participant and trial featuring the 1- or 2-star agents, (Methods; Recall for the 3-star agent, feedback is always true). On testing whether these posterior-truthfulness beliefs vary as a function of objective feedback truthfulness (true vs. lie), we found beliefs are stronger for truthful trials than for untruthful trials for both agents (1-star agent: mean difference=0.10, t(203)=39.47, p&lt;0.001; 2-star agent: mean difference=0.08 , t(203)=34.43, p&lt;0.001) (<xref ref-type="fig" rid="fig6">Fig. 6b</xref> and Fig. S9a). Note that this calculation was feasible because, as experimenters, we had privileged access to the objective truth of the choice-feedback as, when designing the experimental sessions, we generated latent true choice outcomes which could be compared to agent-reported feedback.</p>
<p>To formally address whether inference about feedback truthfulness modulates credit assignment, we fitted a new variant of the CA model (the “Truth-CA” model) to the data. This variant features two separate CA parameters for objectively true (CA<sup>true</sup>) and false (CA<sup>lie</sup>) feedback for each of the lying agents (i.e., the 1-star and 2-star agents) and a single CA parameter for the 3-star agent. We acknowledge that this model falls short of providing a mechanistically plausible description of the credit assignment process, because, unlike experimenters, participants cannot determine with certainty whether feedback from the 1- and 2-star agents is objectively true. Nonetheless, we use this ‘oracle model’ as a measurement tool to glean rough estimates for the average levels of credit assignment for true and false-feedback trials for each agent.</p>
<p>If participants rely on a (partial) insight regarding feedback truthfulness to amplify CA for feedback inferred as true, compared to false, then this predicts elevated average levels on CA on objectively true compared to lie feedback trials. In a mixed-effects model, we regressed the ML parameters for the non-credible agents on agent-credibility (1-star or 2-star) and truthfulness of their associated feedback (Methods). We found a main effect of truthfulness (b=0.084, t(812)=2.23, p=0.026; <xref ref-type="fig" rid="fig6">Fig. 6c and 6e</xref>), which was not qualified by an interaction between agent and truthfulness (b=-0.03, t(812)=- 0.43, p=0.67), consistent with participants assigning greater credit for objectively true compared to false feedback. Strikingly, model-simulations (Methods) showed this pattern is not predicted by any of our other models (<xref ref-type="fig" rid="fig6">Fig. 6d and 6e</xref>) (see SI 3.1.1.4 Tables S14-S17). In agreement with previous results, we found a main effect of agent (b=0.20, t(812)=5.30, p&lt;0.001), consistent with individuals assigning greater credit for feedback from the two-star compared to the one-star agent. Note similar conclusions were found in our discovery study (see SI 1.2.6), and the overall pattern suggests that participants infer the truthfulness of feedback but modulate their credit assignment in a nonnormative manner.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Credit assignment is higher on true-feedback trials.</title>
<p><bold>a</bold>, Posterior belief that feedback is true (y-axis) as a function of prior belief, i.e., during choice and before feedback receipt, that the selected bandit is rewarding (x-axis), feedback valence (dashed vs solid lines), and agent credibility (different colors). <bold>b</bold>, Distribution of posterior belief probability that feedback is true, calculated separately for each agent (1 or 2 star) and objective feedback-truthfulness (true or lie). These probabilities were computed based on trial-sequences and feedback participants experienced, indicating belief probabilities that feedback is true are higher in truth compared to lie trials. For illustration, plotted distributions pool trials across participants. The black line within each box represents the median, upper and lower bounds represent the third and first quartile respectively. The width of each half-violin plot corresponds to the density of each posterior belief value among all trials for a given condition. <bold>c,</bold> ML parameters for the “Truth-CA” model. Credit assignment parameters (y-axes) are shown as a function of agent-credibility and feedback-truthfulness (x-axes). These data show credit assignment was enhanced for true compared to false feedback (CA<sup>true</sup>&gt;CA<sup>lie</sup>). Small dots represent fitted parameters for individual participants, big circles represent the group median, and error bars show the standard error of the mean. <bold>d,</bold> Like <bold>c</bold>. but here CA parameters were obtained by fitting the Truth-CA model not to empirical data but rather, to synthetic data generated from simulations of our alternative models (based on participants best fitting parameters). <bold>e,</bold> Effect of feedback-truthfulness on empirical Truth-CA parameters and on Truth-CA parameters based on synthetic simulations of our alternative models (obtained as in <bold>d.</bold>). Effects were estimated by regressing CA parameters from the Truth-CA model on the agent (1-star or 2-star) and on feedback-truthfulness. None of our models predicted higher credit assignment for true compared to false feedback. Lines represent 95% confidence intervals around the estimated effect coefficient. Small dots represent fitted parameters for individual simulations, diamonds represent the median value, and error bars show the standard error of the mean. (*) p&lt;.05 and (***) p&lt;.001</p></caption>
<graphic xlink:href="st4kgv3_fig6.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-8">
<title>Discovery study</title>
<p>The discovery study (n=104) used a disinformation task structurally similar to that used in our main study, but with three notable differences: 1) it included 4 feedback agents, with credibilities of 50%, 70%, 85% and 100%, represented by 1, 2, 3, and 4 stars, respectively; 2) each experimental block consisted of a single bandit pair, presented over 16 trials (with 4 trials for each feedback agent); and 3) in certain blocks, unbeknownst to participants, the two bandits within a pair were equally rewarding (see SI section 1.1). Overall, the results from this study support the exact same conclusions (See SI section 1.2) but with one difference. In the discovery study, we found no evidence for learning based on 50%-credibility feedback when examining either the feedback effect on choice repetition or CA in the credibility-CA model (SI 1.2.3). However, this does not mean that participants fully filtered this feedback, because importantly, feedback from the 1-star agent elicited a positivity bias.</p>
</sec>
</sec>
<sec id="s3" sec-type="discussion">
<title>Discussion</title>
<p>Accurate information enables individuals to adapt effectively to their environment (<xref ref-type="bibr" rid="c45">45</xref>,<xref ref-type="bibr" rid="c46">46</xref>). Indeed, it has been suggested that the importance and utility of information elevate its status to that of a secondary reinforcer, imbuing it with intrinsic value beyond its immediate usefulness (<xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c48">48</xref>). However, a significant societal challenge arises from the fact that, as social animals, much information we receive is mediated by others, entailing it can be inaccurate, biased or purposefully misleading. Here, using a novel variant of the two-armed bandit task, we asked how we update our beliefs in the presence of potential disinformation, wherein <italic>true choice</italic> outcomes are latent and feedback is provided by potentially disinformative agents.</p>
<p>We acknowledge that several factors may limit the external validity of our task, including the fact that participants were explicitly instructed about the credibility of information sources. In contrast, in many real-life scenarios, individuals need to learn the credibility of information sources based on their own experience of the world or may even have false beliefs regarding the source-credibility of agents. Moreover, in our task, the experimenter fully controlled the credibility of the information source in every trial, whereas in many real-life situations people can exercise a degree of control over the credibility of information they receive. For example, search engines allow an exercise of choice regarding the credibility of sources. Finally, in our task, feedback agents served as rudimentary representations of social agents, who lied randomly and arbitrarily, in a motivation-free manner. Conversely, in real life, others may strategically attempt to mislead us, and we can exploit knowledge of their motivation to lie, such as when we assume that a used cars seller is more likely to portray a clapped-out car as excellent, rather than state the unfiltered truth. Nevertheless, our results attest to the utility of our task in discerning normative from biased aspects of learning in the face of disinformation, even in a simplified scenario.</p>
<p>Consistent with normative Bayesian principles, we show that individuals increased their learning as a function of feedback credibility. This aligns with previous studies demonstrating an impressive human ability to flexibly increase learning rates when environmental changes render prior knowledge obsolete (<xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c49">49</xref>,<xref ref-type="bibr" rid="c50">50</xref>), and when there is reduced inherent uncertainty, such as “observation noise” (<xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c51">51</xref>,<xref ref-type="bibr" rid="c52">52</xref>). However, as hypothesized, when facing potential disinformation, we also find that individuals deviate from a standard of optimal Bayesian learning in several important ways.</p>
<p>We show that participants revised their beliefs based on entirely non-credible feedback, whereas a Bayesian strategy dictates such feedback should be ignored. One possible explanation is that some participants failed to infer that feedback from the 1-star agent was statistically void of information content, essentially random (e.g., the group-level credibility of this agent was estimated by our free-credibility Bayesian model as higher than 50%). Participants were instructed that this feedback would be “a lie 50% of the time but were not explicitly told that this meant it was random and should therefore be disregarded. However, we argue that even if one explicitly infers the randomness of this feedback, it may still be difficult to filter it out. Indeed, truth bias (<xref ref-type="bibr" rid="c53">53</xref>)—the cognitive tendency to assume information is truthful unless strong evidence suggests otherwise— may have led participants to implicitly attribute some credibility to the 1-star feedback. Additionally, an individual’s ability to filter out random information might have been limited due to a high cognitive load induced by the task, which required participants to track the values of three bandit pairs and juggle between three interleaved feedback agents. Importantly, most trials in our task provided feedback from mostly truthful sources, requiring frequent belief updates. As a result, filtering out random feedback may require significant engagement of cognitive control processes. Future studies could explore whether this filtering process is more effective in environments where ignoring feedback is the default policy, such as when random feedback is presented on a majority of trials. Another possibility is that randomfeedback influences on choice may stem from reliance on episodic memory (<xref ref-type="bibr" rid="c54">54</xref>,<xref ref-type="bibr" rid="c55">55</xref>), e.g., a recollection of past choice outcomes (positive or negative feedback) accompanied by a failure to recall corresponding feedback sources. It is entirely plausible that rapid information flow on social media platforms, featuring a considerable number of information-sources, is both cognitively demanding (<xref ref-type="bibr" rid="c56">56</xref>,<xref ref-type="bibr" rid="c57">57</xref>) and taxing for source recollection, hindering efficient filtering out of non-credible information (<xref ref-type="bibr" rid="c58">58</xref>), such as posts from bots or unfamiliar users. Soft moderation policies in social media (<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c59">59</xref>), or indeed fact-checking (<xref ref-type="bibr" rid="c60">60</xref>), may enable better filtering of disinformation, mitigating the cognitive load associated with discerning credible information from a profusion of noise. Future studies should investigate conditions that enhance an ability to discard disinformation, such as providing explicit instructions to ignore misleading feedback, manipulations that increase the time available for evaluating information, or interventions that strengthen source memory.</p>
<p>In support of our a priori hypothesis, and in violation of Bayesian-normative learning, participants assigned greater credit based on positive than negative feedback across all feedback-credibility levels. A similar bias has been reported in previous reinforcement learning studies, albeit only in the context of veridical feedback (<xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c39">39</xref>,<xref ref-type="bibr" rid="c61">61</xref>). Here, we show that this positivity bias is amplified (relative to the overall extent of CA) for information of low and intermediate credibility. Of note, previous literature has interpreted enhanced learning for positive outcomes in reinforcement learning as indicative of a confirmation bias (<xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c39">39</xref>). For example, given that participants predominantly receive rewards (and positive feedback) in our task, positive feedback may confirm, to a greater extent than negative feedback, one’s choice-outcome expectations (e.g., “I expected a positive outcome”). Additionally, positive feedback confirms one’s choice as superior (e.g., “I chose the better of the two options”). Leveraging the framework of motivated cognition (<xref ref-type="bibr" rid="c35">35</xref>), we posited that feedback of uncertain veracity (e.g., low credibility) amplifies this bias by incentivising individuals to self-servingly accept positive feedback as true (either because it confers positive, desirable outcomes or because it confirms one’s choice or outcome expectations), and explain away undesirable, choice-disconfirming, negative feedback as false. Alternative “informational” (motivation-independent) accounts of positivity and confirmation bias predict a contrasting trend (i.e., reduced bias in low- and medium credibility conditions) because in these contexts it is more ambiguous whether feedback confirms one’s choice or outcome expectations, as compared to a full-credibility condition. Our findings of bias exacerbation hint that previous estimates of the extent of confirmation bias may represent a lower bound, and that negative effects of confirmation bias are augmented in the presence of disinformation. This could imply an amplified confirmation bias on social media, where content from sources of uncertain credibility, such as unknown or unverified users, is more easily interpreted in a self-serving manner, disproportionately reinforcing existing beliefs (<xref ref-type="bibr" rid="c62">62</xref>). In turn, this could contribute to an exacerbation of the negative social outcomes previously linked to confirmation bias such as polarization (<xref ref-type="bibr" rid="c63">63</xref>,<xref ref-type="bibr" rid="c64">64</xref>), the formation of ‘echo chambers’ (<xref ref-type="bibr" rid="c19">19</xref>), and the persistence of misbelief regarding contemporary issues of importance such as vaccination (<xref ref-type="bibr" rid="c65">65</xref>,<xref ref-type="bibr" rid="c66">66</xref>) and climate change (<xref ref-type="bibr" rid="c67">67</xref>–<xref ref-type="bibr" rid="c70">70</xref>).</p>
<p>A striking finding in our study was that for a fully credible feedback agent, credit assignment was exaggerated (i.e., higher than predicted by a Bayesian strategy). Furthermore, the effect of fully credible feedback on choice was further boosted when it was preceded by a low-credibility context, even when this context was entirely unrelated to current learning. We interpret this in terms of a “contrast effect”, whereby veridical information looms larger against a backdrop of disinformation (<xref ref-type="bibr" rid="c21">21</xref>). One upshot is that exaggerated learning might entail a risk of jumping to premature conclusions based on limited credible evidence. To illustrate, consider the example wherein a revision of one’s opinion regarding the potential risk and benefits posed by AI, based on information provided by a credible tech-source, is greater after reading a low (compared to high) credibility news item regarding climate-change. An intriguing possibility, that could be tested in future studies, is that participants strategically amplify the extent of learning from credible feedback to dilute the impact of learning from non-credible feedback. For example, a person scrolling through a social media feed, encountering copious amounts of disinformation, might amplify the weight they assign to credible feedback in order to dilute effects of ‘fake news’. Whereas such a strategy would backfire in our task, where bandits were randomly interleaved between trials, it could be beneficial in situations where the content of consumed information is temporally autocorrelated (for example, one reads several social-media items posted by members of the “AI group” and only then continues to items from a “climate-change group”). Ironically, these results also suggest that public campaigns might be more effective when embedding their messages in low-credibility contexts, which may boost their impact.</p>
<p>Our study suggests that individuals’ learning is modulated based on a trial-by-trial latent-state inference, amplifying learning for feedback deemed true as opposed to false. Strikingly, this nonnormative belief-updating strategy was not predicted by any of our Bayesian (or CA) models. One possibility is that this strategy is more efficient in ecological environments providing richer cues, beyond average source-credibility, as to whether an information source should be trusted in specific situations (e.g., when information sources have interests and motives that can be considered). Hence, our finding of increased learning for truthful feedback may stem from a failure to appreciate the inadequacy of this strategy in our relatively impoverished task. We note that the use of this strategy is consistent with our finding of exaggerated learning for fully credible, always-true, feedback. Taken together, these findings show that participants exaggerate learning from feedback they either <italic>know</italic> (3-star agent) or <italic>infer</italic> (1 and 2-star agents) to be true.</p>
<p>An important question arises as to the psychological locus of the biases we uncovered. Because we were interested in how individuals process disinformation—deliberately false or misleading information intended to deceive or manipulate—we framed the feedback agents in our study as deceptive, who would occasionally “lie” about the true choice outcome. However, statistically (though not necessarily psychologically), these agents are equivalent to agents who mix truth-telling with random “guessing” or “noise” where inaccuracies may arise from factors such as occasionally lacking access to true outcomes, simple laziness, or mistakes, rather than an intent to deceive. For example, our “50% credibility agent” is statistically identical to a “100% guessing (fully random)” agent, and our 75% credibility agent corresponds to an agent who mixes truth-telling and guessing on half the trials. While information from guessing agents would constitute misinformation due to its inaccuracy, it lacks the intentionality required to qualify as disinformation. It is possible that participants in our task represented the agents as varying in randomness or noisiness rather than as intentionally deceitful. This raises the question of whether the biases we observed are driven by the perception of potential disinformation as deceitful per se or simply as deviating from the truth. Future studies could address this question by directly comparing learning from statistically equivalent sources framed as either lying or noisy. We have begun exploring this question in a new study by comparing learning from agents who lie on a minority of trials (e.g., 25% of the time) with agents who lie on a majority of trials (e.g., 75% of the time). Although both agents provide statistically equivalent information (via flipping the feedback of the mostly lying agent), the latter is perceived as more deceitful.</p>
<p>Our study has bearing on prior research involving observational learning, which examined how individuals learn from the actions or advice of social partners (<xref ref-type="bibr" rid="c71">71</xref>,<xref ref-type="bibr" rid="c72">72</xref>). This body of work has demonstrated that individuals integrate learning from their private experiences with learning based on others’ actions or advice—whether by inferring the value others attribute to different options or by mimicking their behavior (<xref ref-type="bibr" rid="c73">73</xref>). Here, individuals modulate the extent to which they rely on social partners based on the partner’s accuracy (<xref ref-type="bibr" rid="c74">74</xref>). However, our task differs from traditional observational learning paradigms in several key ways. Firstly, in our study, feedback agents do not demonstrate or recommend actions; instead, they interpret the outcomes of actions on behalf of participants by indicating whether these actions generated a latent reward. Secondly, participants in our task lack a private set of experiences unmediated by feedback sources, unlike many reported observational learning paradigms. Finally, while observational learning tasks often involve actions or advice that are not always accurate (e.g., recommending or demonstrating a suboptimal choice), and research to date has not systematically addressed scenarios that involve deliberately misleading social partners. Future studies could incorporate deceptive social partners into observational learning paradigms, offering an opportunity to bridge the mechanisms underlying observational learning with those that are operative in our task. Developing unified models for these processes could provide valuable insights into how individuals integrate social information, particularly when the credibility of that information is critical for decision-making.</p>
<p>Although our findings and interpretations are grounded in a reinforcement learning (RL) framework, we acknowledge parallels with other approaches that have explored adaptive and biased learning. For instance, previous studies utilizing change-point inference (<xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c49">49</xref>,<xref ref-type="bibr" rid="c50">50</xref>,<xref ref-type="bibr" rid="c74">74</xref>) have addressed how individuals determine whether unexpected perceptual observations stem from “noise” as opposed to representing a genuine latent change in the underlying cause of their observations. In such tasks, incorrect assumptions about the rate of these changes (e.g., the “hazard rate”) can lead to deviations from normative statistical optimality. Similarly, in our task, learning bandit-values might involve inferring the extent to which variable choice feedback (for a bandit across trials) reflects inherent stochasticity in latent outcomes as opposed to agent deception. As in the change-point inference framework, incorrect assumptions in our task also produce biases. For example, a mistaken belief that the 1-star, random-feedback, agent is truthful on most trials would lead participants to erroneously learn from that agent’s feedback. Nevertheless, despite such similarities, there remain key differences between our task and change-point inference paradigms. Notably, choices in our task are value-based, and we consider it likely that this setup introduces biases (e.g., positivity) driven by a motivational preference for one outcome (reward) over another (non-reward). This motivational aspect may also influence whether individuals are inclined to trust or doubt feedback, depending on its valence. Additionally, explaining some of the biases we observed—such as the amplified learning from a credible source after exposure to non-credible sources in independent learning contexts—would require hierarchical inference frameworks that incorporate assumptions about the breakdown of learning-context independence. Future research could usefully investigate whether shared mechanisms underlie the biases identified here and those observed in other paradigms, potentially offering a unified account for inference problems across these approaches.</p>
<p>We conclude by noting previous research has often attributed the negative impacts of disinformation, such as polarization and the formation of echo chambers, to intricate processes facilitated by external or self-selection of information (<xref ref-type="bibr" rid="c75">75</xref>–<xref ref-type="bibr" rid="c77">77</xref>). These processes include algorithms tailoring information to align with users’ attitudes (<xref ref-type="bibr" rid="c78">78</xref>) or individuals consciously opting to engage with like-minded peers (<xref ref-type="bibr" rid="c79">79</xref>). However, our study reveals a more profound effect of disinformation, namely that even in minimal conditions, when low credibility information is explicitly identified, disinformation significantly impacts individuals’ beliefs and decision-making processes. This occurs even when the decision at hand lacks emotional engagement or pertinence to deep, identity-related, issues. A critical next step is to deepen our understanding of these biases, particularly within complex social environments, not least to enable the development of effective prospective interventions capable of mitigating the potentially pernicious impacts of disinformation.</p>
</sec>
<sec id="s4" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="s4-1">
<title>Participants</title>
<p>We recruited 246 participants (mean age 39.33± 12.65, 112 female) from the Prolific participant pool (<ext-link ext-link-type="uri" xlink:href="http://www.prolific.co">www.prolific.co</ext-link>) who went on to perform the task on the Gorilla platform(<xref ref-type="bibr" rid="c80">80</xref>). All participants were fluent English speakers with normal or corrected-to-normal vision and a Prolific approval rate of 95% or higher. UCL Research Ethics Committee approved the study (Project ID 6649/004), and all participants provided prior informed consent.</p>
</sec>
<sec id="s4-2">
<title>Experimental protocol</title>
<sec id="s4-2-1">
<title>Traditional two-armed bandit task</title>
<p>At the beginning of the experiment participants completed a traditional version of the two-armed bandit task. Participants performed 45 trials, each featuring one of three randomly interleaved bandit pairs (such that each pair was presented on 15 trials). On each trial, participants choose between the bandit-pair, with each bandit being represented by a distinct identicon. Once a bandit was selected it generated a true outcome (converted to bonus monetary compensation) corresponding to either a reward or nothing. Within each bandit-pair, one bandit provided rewards on 75% of trials (with 25% providing no-reward), while the other bandit rewarded on 25% of the trials (75% non-reward trials). Participants were uninformed about the reward probabilities of each bandit and had to learn these based on experience.</p>
<p>At onset of each trial, the two bandits were presented, one on each side of the screen, and participants were asked to indicate their choice within 3 seconds by pressing the left/right arrow-keys. If the 3 seconds elapsed with no choice, participants were shown a “too slow” message and proceeded to the next trial. Following choice, the unselected bandit disappeared, and the participants were presented with the outcome of the selected bandit for 1200ms, followed by a 250 ms ISI before the start of the next trial. Rewards were represented by a green dollar symbol and non-rewards by a red sad face (both in the center of the screen). At the end of the task, participants were informed about the number of rewards they had earned.</p>
</sec>
<sec id="s4-2-2">
<title>Disinformation task</title>
<p>This involved a modified, disinformation version, of the same two-armed bandit task. Participants performed 8 blocks, each consisting of 45 trials. Each block followed the structure of the traditional two-armed bandit task, but with a critical difference: true choice-outcomes were withheld from participants and instead they received reward-feedback from a feedback agent. Participants were instructed prior to the task that feedback agents mostly provide accurate feedback (i.e., the true outcome) but could lie on a random minority of trials by reporting a reward in case of a true nonreward, or vice versa. The task featured three feedback agents varying in their credibility (i.e., probability of truth-telling), as indicated by a “star-rating” system, about which participants were instructed prior to the task. The 3-star agent always told the truth, whereas the other 2 agents were partially credible, reporting the truth on 75% (2-star) or 50% (1-star) of the trials. Feedback agents were randomly interleaved across trials subject to the constraint that each agent appeared on 5-trials for each bandit pair.</p>
<p>At the onset of each trial, participants were presented with the feedback agent for the trial (screen center) and with the two bandits, one on each side of the screen. Participants made a 2-second time limited choice by pressing the left/right arrow-keys. Following choice, the unselected bandit disappeared, and were then presented with the agent feedback for 1200ms (represented by either a rewarding green dollar sign or a non-rewarding red sad face in the center of the screen). All stimuli then disappeared for 250 ms to be followed by the start of the next trial. At the end of each block, participants were informed about the number of true rewards they had earned. They then received a 30-second break before the next block started with new 3 bandit pairs.</p>
</sec>
<sec id="s4-2-3">
<title>General protocol</title>
<p>At the beginning of the experiment, participants were presented with instructions for the traditional two-armed bandit task. The instructions were interleaved with four multiple-choice questions. When participants answered a question incorrectly, they could re-read the instructions and re-attempt. If participants answered a question incorrectly twice, they were compensated for the time but could not continue to the next stage. Upon completing the instructions participants proceeded to the traditional two-armed bandit task.</p>
<p>After the two-armed bandit task, participants were presented with instructions regarding the disinformation task. Again, these were interleaved with six questions wherein participants had two attempts to answer each question correctly. If they answered a question incorrectly twice, they were rejected and received partial participatory compensation. Participants then proceeded to the disinformation task. After completing the disinformation task, participants completed three psychiatric questionnaires (presented in random order): 1) the Obsessional Compulsive Inventory - Revised (OCI-R)(<xref ref-type="bibr" rid="c81">81</xref>), assessing symptoms of obsessive-compulsive disorder (OCD); 2) The Revised Green et al. Paranoid Thoughts Scale (R-GPTS)(<xref ref-type="bibr" rid="c82">82</xref>), measuring paranoid ideations; and 3) the DOG scale, evaluating dogmatism(<xref ref-type="bibr" rid="c83">83</xref>).</p>
<p>The participants took on average 43 minutes to complete the experiment. They received a fixed compensation of 5.48 GBP and variable compensation between 0 and 2 GBP based on their performance on the disinformation task.</p>
</sec>
<sec id="s4-2-4">
<title>Attention checks</title>
<p>The two tasks included randomly interleaved catch trials wherein participants were cued to press a given key within a 3-second limit. None of the participants failed more than one of these attention checks.</p>
</sec>
</sec>
<sec id="s4-3">
<title>Data analysis</title>
<sec id="s4-3-1">
<title>Exclusion criteria</title>
<p>Participants were excluded if they: 1) Either repeated or alternated key presses in more than 70% of the trials, and/or 2) their reaction time was lower than 150 ms in more than 5% of the trials. Based on these criteria 42 participants were excluded, while 204 participants were kept for the analyses.</p>
</sec>
<sec id="s4-3-2">
<title>Accuracy</title>
<p>Accuracy rates were calculated as the probability of choosing within a given pair the bandit with a higher reward probability. For <xref ref-type="fig" rid="fig1">figure 1d</xref>, we calculated for each participant and for each trial (within a bandit-pair) averaged accuracy across all bandit-pairs. We then averaged accuracy at the trial level across participants. Overall improvement for each participant was calculated as the average accuracy difference between the last and first trials for each of the bandit-pairs.</p>
</sec>
<sec id="s4-3-3">
<title>Computational models</title>
<sec id="s4-3-3-1">
<title>Rl Models</title>
<p>We formulated a family of RL models to account for participant choices. In these models, a tendency to choose each bandit is captured by a Q-value. After reward-feedback the Q-value of the chosen bandit was updated conditional on the agent and on whether the feedback was positive or negative according to the following rule:
<disp-formula id="FD1">
<alternatives>
<mml:math display="block" id="M1"><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>F</mml:mi></mml:math>
<graphic xlink:href="st4kgv3_eqn1.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(1)</label>
</disp-formula>
</p>
<p>where <italic>CA</italic> is a free credit assignment parameter representing the magnitude of the value increase/decrease following feedback receipt <italic>F</italic> from the agents (coded as 1 for reward feedback and -1 for non-reward feedback), while <italic>f<sub>Q</sub></italic> (∈ [0,1]) is the free parameter representing the forgetting rate of the Q-value. Additionally, the value of each of the other bandits (i.e., the unchosen bandit in the presented pair and all the bandits from the other not-shown pairs) were forgotten as per the following:
<disp-formula id="FD2">
<alternatives>
<mml:math display="block" id="M2"><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv3_eqn2.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(2)</label>
</disp-formula>
</p>
<p>Alternative model-variants differed based on whether the CA parameter(s) were influenced by agents and/or feedback valence (see <xref ref-type="table" rid="tbl1">Table 1</xref> below), allowing us to test how these variables impacted learning.</p>
<list list-type="order">
<list-item><p>The “Null” model included a unique CA parameter conveying an assumption that feedback is modulated by neither agent-credibility nor feedback valence.</p></list-item>
<list-item><p>The “Credibility-CA” models included a dedicated CA parameter for each agent allowing for the possibility learning was selectively modulated by agent credibility (but not by feedback valence).</p></list-item>
<list-item><p>The “Credibility-Valence-CA” model included distinct CA parameters for rewarding (CA+) and nonrewarding feedback (CA-) for each agent, allowing CA to be influenced by both feedback valence and credibility.</p></list-item>
<list-item><p>The “constant feedback-valence bias” CA model included separate CA-parameters for each agent, but a single valence bias parameter (VB) common to all agents, such that the CA+ parameter for each agent corresponded to the sum of its CA-parameter and the common VB parameter.</p></list-item>
</list>
<p>Additionally, we formulated a “Truth-CA” model where CA parameters were influenced by agentcredibility and whether the feedback was objectively true. This model included distinct CA parameters for truthful (CA<sup>true</sup>) and non-truthful (CA<sup>lie</sup>) feedback for each non-credible agent (i.e., 1-star and 2- star) and a single CA parameter for the 3-star agent, since it never lied.</p>
<table-wrap id="tbl1" position="float" orientation="portrait">
<label>Table 1:</label>
<caption><p>summary of free parameters for each of the CA models.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv3_tbl1.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Model</th>
<th align="center" valign="top">Free CA parameter</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>Null</bold></td>
<td align="center" valign="top"><italic>CA</italic></td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>Credibility-CA</bold></td>
<td align="center" valign="top"><italic>CA</italic><sub>0.5</sub>+, <italic>CA</italic><sub>0.75</sub>, <italic>CA</italic><sub>1</sub></td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>Credibility-Valence-CA</bold></td>
<td align="center" valign="top"><italic>CA</italic><sub>0.5</sub>+, <italic>CA</italic><sub>0.75</sub>+, <italic>CA</italic><sub>1</sub> + <italic>CA</italic><sub>0.5</sub>-, <italic>CA</italic><sub>0.75</sub>-, <italic>CA</italic><sub>1</sub> -</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>constant feedbackvalence bias CA</bold></td>
<td align="center" valign="top"><italic>VB</italic><break/><italic>CA</italic><sub>0.5</sub>-, <italic>CA</italic><sub>0.75</sub>-, <italic>CA</italic><sub>1</sub> -</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>Truth-CA</bold></td>
<td align="center" valign="top"><inline-formula id="ID1">
<alternatives>
<mml:math display="inline" id="I1"><mml:mi>C</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="st4kgv3_ieq1.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, <inline-formula id="ID2">
<alternatives>
<mml:math display="inline" id="I2"><mml:mi>C</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mn>0.75</mml:mn></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="st4kgv3_ieq2.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, <inline-formula id="ID3">
<alternatives>
<mml:math display="inline" id="I3"><mml:mi>C</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="st4kgv3_ieq3.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, <inline-formula id="ID4">
<alternatives>
<mml:math display="inline" id="I4"><mml:mi>C</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mn>0.5</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="st4kgv3_ieq4.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, <inline-formula id="ID5">
<alternatives>
<mml:math display="inline" id="I5"><mml:mi>C</mml:mi><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mn>0.75</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="st4kgv3_ieq5.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>All models also included gradual perseveration for each bandit. In each trial the perseveration values (P) were updated according to
<disp-formula id="FD3">
<alternatives>
<mml:math display="block" id="M3"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:math>
<graphic xlink:href="st4kgv3_eqn3.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(3)</label>
</disp-formula>
</p>
<p>Where PERS is a free parameter representing the P-value change for the chosen bandit, and <italic>f<sub>p</sub></italic> (∈ [0,1]) is the free parameter denoting the forgetting rate applied to the P value. Additionally, the P-values of all the non-chosen bandits (i.e., again, the unchosen bandit of the current pair, and all the bandits from the not-shown pairs) were forgotten as follows:
<disp-formula id="FD4">
<alternatives>
<mml:math display="block" id="M4"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv3_eqn4.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(4)</label>
</disp-formula>
</p>
<p>We modelled choices using a <italic>softmax</italic> decision rule, representing the probability of the participant to choose a given bandit over the alternative:
<disp-formula id="FD5">
<alternatives>
<mml:math display="block" id="M5"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv3_eqn5.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(5)</label>
</disp-formula>
</p>
</sec>
<sec id="s4-3-3-2">
<title>Bayesian Models</title>
<p>We also formulated a Bayesian model corresponding to a normative, ideal belief, updating strategy. In this model, beliefs about each bandit were represented by a density distribution over the probability that a bandit provides a true reward <italic>g(p),</italic> where <italic>p</italic> is the probability of a true reward (see full derivation in SI 4.1). During learning, following reward-feedback, the distribution <italic>for</italic> the chosen bandit was updated based on the agent’s feedback (<italic>F</italic>) and its associated credibility (<italic>C</italic>):
<disp-formula id="FD6">
<alternatives>
<mml:math display="block" id="M6"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>C</mml:mi><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>
<graphic xlink:href="st4kgv3_eqn6.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(6)</label>
</disp-formula>
<disp-formula id="FD7">
<alternatives>
<mml:math display="block" id="M7"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext> </mml:mtext><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math>
<graphic xlink:href="st4kgv3_eqn7.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(7)</label>
</disp-formula>
<disp-formula id="FD8">
<alternatives>
<mml:math display="block" id="M8"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv3_eqn8.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(8)</label>
</disp-formula>
</p>
<p>At the beginning of each block priors for each bandit were initialized to uniform distributions (<italic>g(p)=U[0,1]</italic>). In the <italic>instructed-credibility Bayesian model</italic>, we fixed the credibilities to their true values (i.e., 0.5, 0.75 and 1).</p>
<p>We also formulated a <italic>free-credibility Bayesian model</italic>, where we only fixed the three-star agent credibility to 1 but estimated the credibility of the two lying agents as free parameters. This model allowed the possibility that participants use distorted instructed-credibilities when following a Bayesian strategy.</p>
<p>For both versions, we modelled choice using a SoftMax function with a free inverse temperature parameter (β):
<disp-formula id="FD9">
<alternatives>
<mml:math display="block" id="M9"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv3_eqn9.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(9)</label>
</disp-formula>
</p>
<p>Where here <italic>Q(bandit)</italic> is the expected probability, the bandit provides a true reward.</p>
</sec>
</sec>
<sec id="s4-3-4">
<title>Parameter optimization, model selection and synthetic model simulations</title>
<p>For each participant, we estimated the free parameter values that maximized the summed loglikelihood of the observed choices across all games. Trials where participants showed a response time below 150 ms were excluded from the log-likelihood calculations. To minimise the chances of finding local minima, we ran the fitting procedure 10 times for each participant, using random initializations for the parameters (CA~U[-10,10], PERS~U[-5,5], f<sub>Q</sub>~[0,1], f<sub>P</sub>~[0,1], β~[0,30], C~U[0,1]). Our Truth-CA model showed poorer convergence, so for this model we ran the fitting procedure 100 times per participant.</p>
<p>We performed model comparison between Bayesian and CA models using the parametric bootstrap cross-fitting method (PBCM)(<xref ref-type="bibr" rid="c84">84</xref>,<xref ref-type="bibr" rid="c85">85</xref>). In brief, this method relies on generating, for each participant, synthetic datasets (we used 201) based on maximal likelihood parameters and each model variant (i.e., the Bayesian model and the CA model), and fitting each dataset with the two models. We then calculated the log likelihood difference between the two fits for each dataset, obtaining two loglikelihood difference distributions, one for each generative model. We determined a loglikelihood difference threshold that leads to best model-classification (i.e., maximizing the proportion of true positives and true negatives). Finally, we fit the empirical data from each participant with the two model variants, calculating an empirical loglikelihood difference. A comparison of this empirical likelihood difference to the classification threshold determines which model provides a better fit for a participant’s data (see <xref ref-type="fig" rid="fig6">Fig. S6</xref> for more information). We used this procedure to compare our Bayesian models (instructed-credibility and free-credibility Bayesian) with a simplified version of the credibility-CA model that did not include perseveration (PERS, fP = 0).</p>
<p>We also performed model-comparisons for nested CA models using generalized-likelihood ratio tests where the null distribution for rejecting a nested model (in favour of a nesting model) was based on a bootstrapping method (BGLRT)(<xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c86">86</xref>).</p>
<p>To assess the mechanistic predictions of each model, we generated synthetic simulations based on the ML parameters of participants. Unless stated otherwise, we generated 5 simulations for each participant (1020 total simulations) with a new sequence of trials generated as in the actual data. We analysed these data in the same way as we analysed empirical data, after pooling together the 5 simulated data set per participant.</p>
</sec>
<sec id="s4-3-5">
<title>Parameter recovery</title>
<p>For each model of interest, we generated 201 synthetic simulations based on parameters sampled from uniform distributions (CA~U[-10,10], PERS~U[-5,5], f<sub>Q</sub>~U[0,1], f<sub>P</sub>~U[0,1], β~U[0,30], C~U[0,1]). We fitted each simulated dataset with its generative model and calculated the Spearman’s correlation between the generative and fitted parameters.</p>
</sec>
<sec id="s4-3-6">
<title>Mixed effects models</title>
<sec id="s4-3-6-1">
<title>Model-agnostic analysis of agent-credibility effects on choice-repetition</title>
<p>We used a mixed-effects binomial regression model to assess whether, and how, value-learning was modulated by agent-credibility, with participants serving as random effects. The regressed variable <italic>REPEAT</italic> indicated whether the current trial repeated the choice from the previous trial featuring the same bandit-pair (repeated choice=1, non-repeated choice=0) and was regressed on the following regressors: <italic>FEEDBACK</italic> coded whether feedback received in the previous trial with the same bandit pair was positive or negative (coded as 0.5, -0.5, respectively), <italic>BETTER</italic> coded whether the bandit chosen in that previous trial was the better-mostly rewarding- or the worse-mostly unrewarding-bandit within the pair, coded as 0.5 and -0.5 respectively, AGENT<sub>2-star</sub> indicated whether feedback received in the previous trial (featuring the same bandit pair) came from the 2-star agent (previous feedback from 2-star agent=1, otherwise=0) and, AGENT<sub>3-star</sub> indicated whether the feedback in the previous trial came from the 3-star agent. The model in Wilkinson’s notation was:
<disp-formula id="FD10">
<alternatives>
<mml:math display="block" id="M10"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mo>~</mml:mo><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>K</mml:mi><mml:mo>∗</mml:mo><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv3_eqn10.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(10)</label>
</disp-formula>
</p>
<p>In <xref ref-type="fig" rid="fig2">figure 2a and 2b</xref>, we plot the choice-repeat probability based on feedback-valence and agentcredibility from the preceding trial with the same bandit pair. We independently calculated the repeat probability for the better (mostly rewarding) and worse (mostly non-rewarding) bandits and averaged across them. This calculation was done at the participants level, and finally averaged across participants.</p>
</sec>
<sec id="s4-3-6-2">
<title>Model-agnostic analysis of contextual credibility effects on choice-repetition</title>
<p>We used a different mixed-effects binomial regression model to test whether value learning from the 3-star agent was modulated by contextual credibility. We focused this analysis on instances where the previous trial with the same bandit pair featured the 3-star agent. We regressed the variable <italic>REPEAT</italic>, which indicated whether the current trial repeated the choice from the previous trial featuring the same bandit-pair (repeated choice=1, non-repeated choice=0). We included the following regressors: <italic>FEEDBACK</italic> coding the valence of feedback in the previous trial with the same bandit pair (positive=0.5, negative=-0.5), CONTEXT<sub>2-star</sub> indicating whether the trial immediately preceding the previous trial with the same bandit pair (context trial) featured the 2-star agent (feedback from 2-star agent=1, otherwise=0), and CONTEXT<sub>3-star</sub> indicating whether the trial immediately preceding the previous trial with the same bandit pair featured the 3-star agent. We included in this analysis only current trials where the context trial featured a different bandit pair. The model in Wilkinson’s notation was:
<disp-formula id="FD11">
<alternatives>
<mml:math display="block" id="M11"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mo>~</mml:mo><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>K</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>X</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>X</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv3_eqn11.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(11)</label>
</disp-formula>
</p>
<p>We originally included another regressor (<italic>BETTER</italic>) coding whether the bandit chosen in that previous trial was the better-mostly rewarding- or the worse-mostly unrewarding-bandit within the pair. Since we did not find any significant interactions between BETTER and the other regressors, we decided to omit it from the model formulation.</p>
<p>In <xref ref-type="fig" rid="fig4">figure 4c</xref>, we independently calculate the repeat probability difference for the better (mostly rewarding) and worse (mostly non-rewarding) bandits and averaged across them. This calculation was done at the participants level, and finally averaged across participants.</p>
</sec>
<sec id="s4-3-6-3">
<title>Effects of agent-credibility on CA parameters from credibility-CA model</title>
<p>We used a mixed-effects linear regression model to assess whether, and how, credit assignment was modulated by feedback-agent, with participants serving as random effects (data from <xref ref-type="fig" rid="fig2">Fig. 2c</xref>). We regressed the maximal likelihood CA parameters from the credibility-CA model. The regressors AGENT<sub>2-star</sub> and AGENT<sub>3-star</sub> indicated, respectively, whether the CA parameter was attributed to the 2- star or the 3-star agent. The model’s Wilkinson’s notation was:
<disp-formula id="FD12">
<alternatives>
<mml:math display="block" id="M12"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>~</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv3_eqn12.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(12)</label>
</disp-formula>
</p>
</sec>
<sec id="s4-3-6-4">
<title>Effects of agent-credibility and feedback valence on CA parameters from credibility-valence-CA model</title>
<p>We used a second mixed-effects linear regression model to test for a valence bias in learning, and how such bias was modulated by feedback credibility, with participants serving again as random effects (data from <xref ref-type="fig" rid="fig3">Fig. 3a</xref>). The maximal likelihood CA parameters from the credibility-valence-CA model served as the regressed variable, which was regressed on: AGENT<sub>2-star</sub> and AGENT<sub>3-star</sub> (defined in the same way as the previous model), and <italic>VALENCE</italic> coding whether the CA parameter was attributed to positive (coded as 0.5) or negative (coded as -0.5) feedback. The Wilkinson’s notation of the model was:
<disp-formula id="FD13">
<alternatives>
<mml:math display="block" id="M13"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>~</mml:mo><mml:mi>V</mml:mi><mml:mi>A</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv3_eqn13.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(13)</label>
</disp-formula>
</p>
</sec>
<sec id="s4-3-6-5">
<title>Effects of agent-credibility and feedback truthfulness on CA parameters from truth-CA model</title>
<p>Finally, we used another mixed-effects linear regression model to test whether average levels of credit participants assigned to chosen bandits varied between objectively true and false feedback (data from <xref ref-type="fig" rid="fig4">figures 4b and 4c</xref>). We regressed the maximal likelihood CA parameters for the 1-star and 2-star agents from the truth-CA model on the regressors: CREDIBILITY, coding whether the CA came from the 1-star or the 2-star agent (coded as -0.5 and 0.5 respectively); and TRUTH, coding whether the CA parameter was attributed to trials were the agents told the truth (coded as 0.5) or lied (coded as -0.5). The Wilkinson’s notation of the model was:
<disp-formula id="FD14">
<alternatives>
<mml:math display="block" id="M14"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>~</mml:mo><mml:mi>C</mml:mi><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>I</mml:mi><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>L</mml:mi><mml:mi>I</mml:mi><mml:mi>T</mml:mi><mml:mi>Y</mml:mi><mml:mo>∗</mml:mo><mml:mi>T</mml:mi><mml:mi>R</mml:mi><mml:mi>U</mml:mi><mml:mi>T</mml:mi><mml:mi>H</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv3_eqn14.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(14)</label>
</disp-formula>
</p>
<p>We fitted these mixed effects models using the <italic>fitglme</italic> function in Matlab. Follow up analysis were based on testing contrasts from these models.</p>
</sec>
</sec>
<sec id="s4-3-7">
<title>Bayesian estimation of posterior belief that feedback is true</title>
<p>We calculated the Bayesian posterior conditional probability of feedback truthfulness (<xref ref-type="fig" rid="fig4">Fig. 4a and 4b</xref>) follows. First, we calculated the probability of each true outcome, r (0-non-reward; 1-reward) conditional on the feedback, <italic>f</italic> (0: non-reward, 1: reward), the credibility of the agent reporting the feedback (C) and the history of experiences from past trials (H):
<disp-formula id="FD15">
<alternatives>
<mml:math display="block" id="M15"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>    </mml:mtext><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>C</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>≠</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="st4kgv3_eqn15.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(15)</label>
</disp-formula>
</p>
<p>Where proportionality omits terms independent of <italic>r</italic>, <inline-formula id="ID6">
<alternatives>
<mml:math display="inline" id="I6"><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:mi>p</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<inline-graphic xlink:href="st4kgv3_ieq6.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> is the expected probability of the chosen bandit is rewarding (conditional on past-trial history), and <italic>g</italic>(<italic>p</italic>|<italic>H</italic>) is the density over the probability (the chosen bandit) is rewarded (conditional on the history of previous trials).</p>
<p>Next, we normalized the two terms (for <italic>r</italic>=0,1) to sum to 1 (to correct for the proportionality in (<xref ref-type="bibr" rid="c14">14</xref>)). Finally, the posterior belief in truthfulness was taken as <italic>P(r=f</italic> | <italic>f,C,H)</italic>.</p>
<p>In <xref ref-type="fig" rid="fig4">Fig. 4b</xref>, we calculated for each participant the mean posterior belief of truthfulness separately for trials where each agents told the truth or lied, and we compared these mean beliefs between the two kinds of trials using a paired t-tests (one test per agent).</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s5" sec-type="data-availability">
<title>Code and data availability</title>
<p>All code and data used to generate the results and figures in this paper will be made available on GitHub upon publication.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Bastien Blain, Lucie Charles and Stephano Palminteri for helpful discussions. We thank Nira Liberman, Keiji Ota, Nitzan Shahar, Konstantinos Tsetsos and Tali Sharot for providing feedback on earlier versions of the manuscript. We additionally thank the members of the Max Planck UCL Centre for Computational Psychiatry and Ageing Research for insightful discussions. The Max Planck UCL Centre is a joint initiative supported by UCL and the Max Planck Society.</p>
<p>J.V.P. is a pre-doctoral fellow of the International Max Planck Research School on Computational Methods in Psychiatry and Ageing Research (IMPRS COMP2PSYCH). We acknowledge funding from the Max Planck research school to J.V.P. (577749-D-CON 186534), and funding from the Max Planck Society to R.J.D. (549771-D.CON 177814). The project that gave rise to these results received the support of a fellowship from “la Caixa” Foundation (ID 100010434), with the fellowship code LCF/BQ/EU21/11890109.</p>
<p>J.V.P. contributed to the study design, data collection, data coding, data analyses, and writing of the manuscript. R.M. contributed to the study design, data analyses, and writing of the manuscript. R.J.D. contributed to the writing of the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><collab>World Economic Forum [Internet]</collab></person-group>. [<date-in-citation>cited <year>2024</year> <month>Feb</month> <day>6</day></date-in-citation>]. <source>Global Risks Report</source> <year>2024</year>. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.weforum.org/publications/global-risks-report-2024/">https://www.weforum.org/publications/global-risks-report-2024/</ext-link></mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carrieri</surname> <given-names>V</given-names></string-name>, <string-name><surname>Madio</surname> <given-names>L</given-names></string-name>, <string-name><surname>Principe</surname> <given-names>F</given-names></string-name></person-group>. <article-title>Vaccine hesitancy and (fake) news: Quasi-experimental evidence from Italy</article-title>. <source>Health Econ</source>. <year>2019</year>;<volume>28</volume>(<issue>11</issue>):<fpage>1377</fpage>–<lpage>82</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rocha</surname> <given-names>YM</given-names></string-name>, <string-name><surname>de Moura</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Desidério</surname> <given-names>GA</given-names></string-name>, <string-name><surname>de Oliveira</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Lourenço</surname> <given-names>FD</given-names></string-name>, <string-name><surname>de Figueiredo Nicolete</surname> <given-names>LD</given-names></string-name></person-group>. <article-title>The impact of fake news on social media and its influence on health during the COVID-19 pandemic: a systematic review</article-title>. <source>J Public Health</source>. <year>2023</year> <month>Jul</month> <day>1</day>; <volume>31</volume>(<issue>7</issue>):<fpage>1007</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Belluz</surname> <given-names>J. Vox.</given-names></string-name></person-group> <year>2017</year> [<date-in-citation>cited <year>2024</year> <month>Jan</month> <day>17</day></date-in-citation>]. <source>Why Japan’s HPV vaccine rates dropped from 70% to near zero</source>. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.vox.com/science-and-health/2017/12/1/16723912/japan-hpv-vaccine">https://www.vox.com/science-and-health/2017/12/1/16723912/japan-hpv-vaccine</ext-link></mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Horta Ribeiro</surname> <given-names>M</given-names></string-name>, <string-name><surname>Calais</surname> <given-names>PH</given-names></string-name>, <string-name><surname>Almeida</surname> <given-names>VAF</given-names></string-name>, <string-name><surname>Meira</surname> <given-names>W</given-names> <suffix>Jr.</suffix></string-name></person-group> <article-title>“Everything I Disagree With is #FakeNews”: Correlating Political Polarization and Spread of Misinformation</article-title>. <source>arXiv</source>. <year>2017</year>. <pub-id pub-id-type="doi">10.48550/arXiv.1706.05924</pub-id></mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piazza</surname> <given-names>JA</given-names></string-name></person-group>. <article-title>Fake news: the effects of social media disinformation on domestic terrorism</article-title>. <source>Dyn Asymmetric Confl</source>. <year>2022</year> <month>Jan</month> <day>2</day>; <volume>15</volume>(<issue>1</issue>):<fpage>55</fpage>–<lpage>77</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roy</surname> <given-names>S</given-names></string-name>, <string-name><surname>Singh</surname> <given-names>AK</given-names></string-name>, <collab>Kamruzzaman</collab></person-group>. <article-title>Sociological perspectives of social media, rumors, and attacks on minorities: Evidence from Bangladesh</article-title>. <source>Front Sociol</source>. <year>2023</year> <month>Feb</month> <day>24</day>;<volume>8</volume>:<fpage>1067726</fpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>The saga of “Pizzagate”: The fake story that shows how conspiracy theories spread</collab></person-group>. <source>BBC News [Internet]</source>. <year>2016</year> <month>Dec</month> <day>2</day> [<date-in-citation>cited <year>2024</year> <month>Jan</month> <day>17</day></date-in-citation>]; Available from: <ext-link ext-link-type="uri" xlink:href="https://www.bbc.com/news/blogs-trending-38156985">https://www.bbc.com/news/blogs-trending-38156985</ext-link></mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Enders</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Uscinski</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Seelig</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Klofstad</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Wuchty</surname> <given-names>S</given-names></string-name>, <string-name><surname>Funchion</surname> <given-names>JR</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The Relationship Between Social Media Use and Beliefs in Conspiracy Theories and Misinformation</article-title>. <source>Polit Behav</source>. <year>2023</year> <month>Jun</month> <day>1</day>;<volume>45</volume>(<issue>2</issue>):<fpage>781</fpage>–<lpage>804</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guess</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nagler</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tucker</surname> <given-names>J</given-names></string-name></person-group>. <article-title>Less than you think: Prevalence and predictors of fake news dissemination on Facebook</article-title>. <source>Sci Adv</source>. <year>2019</year> <month>Jan</month> <day>9</day>;<volume>5</volume>(<issue>1</issue>):<elocation-id>eaau4586</elocation-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Del Vicario</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bessi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Zollo</surname> <given-names>F</given-names></string-name>, <string-name><surname>Petroni</surname> <given-names>F</given-names></string-name>, <string-name><surname>Scala</surname> <given-names>A</given-names></string-name>, <string-name><surname>Caldarelli</surname> <given-names>G</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The spreading of misinformation online</article-title>. <source>Proc Natl Acad Sci</source>. <year>2016</year> <month>Jan</month> <day>19</day>;<volume>113</volume>(<issue>3</issue>):<fpage>554</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shao</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ciampaglia</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Varol</surname> <given-names>O</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>KC</given-names></string-name>, <string-name><surname>Flammini</surname> <given-names>A</given-names></string-name>, <string-name><surname>Menczer</surname> <given-names>F</given-names></string-name></person-group>. <article-title>The spread of low-credibility content by social bots</article-title>. <source>Nat Commun</source>. <year>2018</year> <month>Nov</month> <day>20</day>;<volume>9</volume>(<issue>1</issue>):<fpage>4787</fpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharevski</surname> <given-names>F</given-names></string-name>, <string-name><surname>Alsaadi</surname> <given-names>R</given-names></string-name>, <string-name><surname>Jachim</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pieroni</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Misinformation warnings: Twitter’s soft moderation effects on COVID-19 vaccine belief echoes</article-title>. <source>Comput Secur</source>. <year>2022</year> <month>Mar</month>;<volume>114</volume>:<fpage>102577</fpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walter</surname> <given-names>N</given-names></string-name>, <string-name><surname>Murphy</surname> <given-names>ST</given-names></string-name></person-group>. <article-title>How to unring the bell: A meta-analytic approach to correction of misinformation</article-title>. <source>Commun Monogr</source>. <year>2018</year> <month>Jul</month> <day>3</day>;<volume>85</volume>(<issue>3</issue>):<fpage>423</fpage>–<lpage>41</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Globig</surname> <given-names>LK</given-names></string-name>, <string-name><surname>Holtz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Sharot</surname> <given-names>T</given-names></string-name></person-group>. <article-title>Changing the Incentive Structure of Social Media Platforms to Halt the Spread of Misinformation</article-title>. <source>PsyArXiv</source> <year>2022</year> <pub-id pub-id-type="doi">10.31234/osf.io/26j8w</pub-id></mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roozenbeek</surname> <given-names>J</given-names></string-name>, <string-name><surname>van der Linden</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Fake news game confers psychological resistance against online misinformation</article-title>. <source>Palgrave Commun</source>. <year>2019</year> <month>Jun</month> <day>25</day>;<volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Mahony</surname> <given-names>C</given-names></string-name>, <string-name><surname>Brassil</surname> <given-names>M</given-names></string-name>, <string-name><surname>Murphy</surname> <given-names>G</given-names></string-name>, <string-name><surname>Linehan</surname> <given-names>C</given-names></string-name></person-group>. <article-title>The efficacy of interventions in reducing belief in conspiracy theories: A systematic review</article-title>. <source>PLOS One</source>. <year>2023</year> <month>Apr</month> <day>5</day>;<volume>18</volume>(<issue>4</issue>):<elocation-id>e0280902</elocation-id>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vosoughi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Roy</surname> <given-names>D</given-names></string-name>, <string-name><surname>Aral</surname> <given-names>S</given-names></string-name></person-group>. <article-title>The spread of true and false news online</article-title>. <source>Science</source>. <year>2018</year> <month>Mar</month> <day>9</day>;<volume>359</volume>(<issue>6380</issue>):<fpage>1146</fpage>—<lpage>51</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Modgil</surname> <given-names>S</given-names></string-name>, <string-name><surname>Singh</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Gupta</surname> <given-names>S</given-names></string-name>, <string-name><surname>Dennehy</surname> <given-names>D</given-names></string-name></person-group>. <article-title>A Confirmation Bias View on Social Media Induced Polarisation During Covid-19</article-title>. <source>Inf Syst Front</source>. <year>2021</year> <volume>26</volume>:<fpage>417</fpage>–<lpage>41</lpage> <pub-id pub-id-type="doi">10.1007/s10796-021-10222-9</pub-id></mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Menczer</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ciampaglia</surname> <given-names>GL</given-names></string-name></person-group>. <article-title>The Conversation</article-title>. <year>2018</year> [<date-in-citation>cited <year>2024</year> <month>Jun</month> <day>10</day></date-in-citation>]. <source>Misinformation and biases infect social media, both intentionally and accidentally</source>. Available from: <ext-link ext-link-type="uri" xlink:href="http://theconversation.com/misinformation-and-biases-infect-social-media-both-intentionally-and-accidentally-97148">http://theconversation.com/misinformation-and-biases-infect-social-media-both-intentionally-and-accidentally-97148</ext-link></mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pennycook</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bear</surname> <given-names>A</given-names></string-name>, <string-name><surname>Collins</surname> <given-names>ET</given-names></string-name>, <string-name><surname>Rand</surname> <given-names>DG</given-names></string-name></person-group>. <article-title>The Implied Truth Effect: Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings</article-title>. <source>Manag Sci</source>. <year>2020</year> <month>Nov</month>;<volume>66</volume>(<issue>11</issue>):<fpage>4944</fpage>–<lpage>57</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Swire</surname> <given-names>B</given-names></string-name>, <string-name><surname>Berinsky</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Lewandowsky</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ecker</surname> <given-names>UKH</given-names></string-name></person-group>. <article-title>Processing political misinformation: comprehending the Trump phenomenon</article-title>. <source>R Soc Open Sci</source>. <year>2017</year> <month>Mar</month>;<volume>4</volume>(<issue>3</issue>):<fpage>160802</fpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name><surname>Woolrich</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Walton</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Rushworth</surname> <given-names>MFS</given-names></string-name></person-group>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>. <year>2007</year> <month>Sep</month>;<volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Heasly</surname> <given-names>B</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name></person-group>. <article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title>. <source>J Neurosci Off J Soc Neurosci</source>. <year>2010</year> <month>Sep</month> <day>15</day>;<volume>30</volume>(<issue>37</issue>):<fpage>12366</fpage>–<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diederen</surname> <given-names>KMJ</given-names></string-name>, <string-name><surname>Schultz</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Scaling prediction errors to reward variability benefits error-driven learning in humans</article-title>. <source>J Neurophysiol</source>. <year>2015</year> <month>Jul</month> <day>15</day>;<volume>114</volume>(<issue>3</issue>):<fpage>1628</fpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Campbell-Meiklejohn</surname> <given-names>D</given-names></string-name>, <string-name><surname>Simonsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Frith</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Daw</surname> <given-names>ND</given-names></string-name></person-group>. <article-title>Independent Neural Computation of Value from Other People’s Confidence</article-title>. <source>J Neurosci</source>. <year>2017</year> <month>Jan</month> <day>18</day>;<volume>37</volume>(<issue>3</issue>):<fpage>673</fpage>–<lpage>84</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Martino</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bobadilla-Suarez</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nouguchi</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sharot</surname> <given-names>T</given-names></string-name>, <string-name><surname>Love</surname> <given-names>BC</given-names></string-name></person-group>. <article-title>Social Information Is Integrated into Value and Confidence Judgments According to Its Reliability</article-title>. <source>J Neurosci</source>. <year>2017</year> <month>Jun</month> <day>21</day>;<volume>37</volume>(<issue>25</issue>):<fpage>6066</fpage>–<lpage>74</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toelch</surname> <given-names>U</given-names></string-name>, <string-name><surname>Bach</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>The neural underpinnings of an optimal exploitation of social information under uncertainty</article-title>. <source>Soc Cogn Affect Neurosci</source>. <year>2014</year> <month>Nov</month>;<volume>9</volume>(<issue>11</issue>):<fpage>1746</fpage>–<lpage>53</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Biele</surname> <given-names>G</given-names></string-name>, <string-name><surname>Rieskamp</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gonzalez</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Computational models for the combination of advice and individual learning</article-title>. <source>Cogn Sci</source>. <year>2009</year> <month>Mar</month>;<volume>33</volume>(<issue>2</issue>):<fpage>206</fpage>–<lpage>42</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vélez</surname> <given-names>N</given-names></string-name>, <string-name><surname>Gweon</surname> <given-names>H</given-names></string-name></person-group>. <article-title>Integrating Incomplete Information With Imperfect Advice</article-title>. <source>Top Cogn Sci</source>. <year>2019</year> <month>Apr</month>;<volume>11</volume>(<issue>2</issue>):<fpage>299</fpage>–<lpage>315</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Jiwa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Boonyaratvej</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ciston</surname> <given-names>A</given-names></string-name>, <string-name><surname>Haggard</surname> <given-names>P</given-names></string-name>, <string-name><surname>Charles</surname> <given-names>L</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>Exposure to misleading and unreliable information reduces active information-seeking</article-title>. <source>PsyArXiv</source>; <year>2023</year> <pub-id pub-id-type="doi">10.31234/osf.io/4zkxw</pub-id></mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharot</surname> <given-names>T</given-names></string-name></person-group>. <article-title>The optimism bias</article-title>. <source>Curr Biol</source>. <year>2011</year> <month>Dec</month>;<volume>21</volume>(<issue>23</issue>):<fpage>R941</fpage>–<lpage>5</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharot</surname> <given-names>T</given-names></string-name>, <string-name><surname>Garrett</surname> <given-names>N</given-names></string-name></person-group>. <article-title>Forming Beliefs: Why Valence Matters</article-title>. <source>Trends Cogn Sci</source>. <year>2016</year> <month>Jan</month>;<volume>20</volume>(<issue>1</issue>):<fpage>25</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharot</surname> <given-names>T</given-names></string-name>, <string-name><surname>Korn</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>How unrealistic optimism is maintained in the face of reality</article-title>. <source>Nat Neurosci</source>. <year>2011</year> <month>Nov</month>;<volume>14</volume>(<issue>11</issue>):<fpage>1475</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hughes</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Zaki</surname> <given-names>J</given-names></string-name></person-group>. <article-title>The neuroscience of motivated cognition</article-title>. <source>Trends Cogn Sci</source>. <year>2015</year> <month>Feb</month> <day>1</day>;<volume>19</volume>(<issue>2</issue>):<fpage>62</fpage>–<lpage>4</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sutton</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Barto</surname> <given-names>AG</given-names></string-name></person-group>. <source>Reinforcement Learning: An Introduction</source>. <publisher-name>The MIT Press</publisher-name> <year>2018</year></mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lefebvre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kilford</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Blakemore</surname> <given-names>SJ</given-names></string-name></person-group>. <article-title>Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing</article-title>. <source>PLOS Comput Biol</source>. <year>2017</year> <month>Aug</month> <day>1</day>;<volume>13</volume>(<issue>8</issue>):<elocation-id>e1005684</elocation-id>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lefebvre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lebreton</surname> <given-names>M</given-names></string-name>, <string-name><surname>Meyniel</surname> <given-names>F</given-names></string-name>, <string-name><surname>Bourgeois-Gironde</surname> <given-names>S</given-names></string-name>, <string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Behavioural and neural characterization of optimistic reinforcement learning</article-title>. <source>Nat Hum Behav</source>. <year>2017</year> <month>Mar</month> <day>20</day>;<volume>1</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lebreton</surname> <given-names>M</given-names></string-name></person-group>. <article-title>The computational roots of positivity and confirmation biases in reinforcement learning</article-title>. <source>Trends Cogn Sci</source>. <year>2022</year> <month>Jul</month> <day>1</day>;<volume>26</volume>(<issue>7</issue>):<fpage>607</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lindström</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bellander</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schultner</surname> <given-names>DT</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>A</given-names></string-name>, <string-name><surname>Tobler</surname> <given-names>PN</given-names></string-name>, <string-name><surname>Amodio</surname> <given-names>DM</given-names></string-name></person-group>. <article-title>A computational reward learning account of social media engagement</article-title>. <source>Nat Commun</source>. <year>2021</year> <month>Feb</month> <day>26</day>;<volume>12</volume>(<issue>1</issue>):<fpage>1311</fpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brady</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>McLoughlin</surname> <given-names>K</given-names></string-name>, <string-name><surname>Doan</surname> <given-names>TN</given-names></string-name>, <string-name><surname>Crockett</surname> <given-names>MJ</given-names></string-name></person-group>. <article-title>How social learning amplifies moral outrage expression in online social networks</article-title>. <source>Sci Adv</source>. <year>2021</year> <month>Aug</month> <day>13</day>;<volume>7</volume>(<issue>33</issue>):<elocation-id>eabe5641</elocation-id>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Collins</surname> <given-names>AG</given-names></string-name></person-group>. <article-title>Ten simple rules for the computational modeling of behavioral data</article-title>. <source>eLife</source>. <volume>8</volume>:<elocation-id>e49547</elocation-id>. <year>2019</year>. <pub-id pub-id-type="doi">10.7554/eLife.49547</pub-id></mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reyna</surname> <given-names>VF</given-names></string-name>, <string-name><surname>Brainerd</surname> <given-names>CJ</given-names></string-name></person-group>. <article-title>Numeracy, gist, literal thinking and the value of nothing in decision making</article-title>. <source>Nat Rev Psychol</source>. <year>2023</year> <month>Jul</month>;<volume>2</volume>(<issue>7</issue>):<fpage>421</fpage>–<lpage>39</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>Human subjects exploit a cognitive map for credit assignment</article-title>. <source>Proc Natl Acad Sci</source>. <year>2021</year> <month>Jan</month> <day>26</day>;<volume>118</volume>(<issue>4</issue>):<elocation-id>e2016884118</elocation-id>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Geana</surname> <given-names>A</given-names></string-name>, <string-name><surname>White</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Ludvig</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name></person-group>. <article-title>Humans Use Directed and Random Exploration to Solve the Explore–Exploit Dilemma</article-title>. <source>J Exp Psychol Gen</source>. <year>2014</year> <month>Dec</month>;<volume>143</volume>(<issue>6</issue>):<fpage>2074</fpage>–<lpage>81</lpage>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niv</surname> <given-names>Y</given-names></string-name></person-group>. <article-title>Reinforcement learning in the brain</article-title>. <source>J Math Psychol</source>. <year>2009</year> <month>Jun</month> <day>1</day>;<volume>53</volume>(<issue>3</issue>):<fpage>139</fpage>–<lpage>54</lpage>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bennett</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bode</surname> <given-names>S</given-names></string-name>, <string-name><surname>Brydevall</surname> <given-names>M</given-names></string-name>, <string-name><surname>Warren</surname> <given-names>H</given-names></string-name>, <string-name><surname>Murawski</surname> <given-names>C</given-names></string-name></person-group>. <article-title>Intrinsic Valuation of Information in Decision Making under Uncertainty</article-title>. <source>PLOS Comput Biol</source>. <year>2016</year> <month>Jul</month> <day>14</day>;<volume>12</volume>(<issue>7</issue>):<elocation-id>e1005020</elocation-id>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bromberg-Martin</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Monosov</surname> <given-names>IE</given-names></string-name></person-group>. <article-title>Neural circuitry of information seeking</article-title>. <source>Curr Opin Behav Sci</source>. <year>2020</year> <month>Oct</month>;<volume>35</volume>:<fpage>62</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Glaze</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Kable</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name></person-group>. <chapter-title>Normative evidence accumulation in unpredictable environments</chapter-title>. <person-group person-group-type="editor"><string-name><surname>Behrens</surname> <given-names>T</given-names></string-name></person-group>,. <source>eLife</source>. <year>2015</year> <month>Aug</month> <day>31</day>;<volume>4</volume>:<elocation-id>e08825</elocation-id>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glaze</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Filipowicz</surname> <given-names>ALS</given-names></string-name>, <string-name><surname>Kable</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Balasubramanian</surname> <given-names>V</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name></person-group>. <article-title>A bias–variance trade-off governs individual differences in on-line learning in an unpredictable environment</article-title>. <source>Nat Hum Behav</source>. <year>2018</year> <month>Mar</month>;<volume>2</volume>(<issue>3</issue>):<fpage>213</fpage>–<lpage>24</lpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pulcu</surname> <given-names>E</given-names></string-name>, <string-name><surname>Browning</surname> <given-names>M</given-names></string-name></person-group>. <article-title>The Misestimation of Uncertainty in Affective Disorders</article-title>. <source>Trends Cogn Sci</source>. <year>2019</year> <month>Oct</month> <day>1</day>;<volume>23</volume>(<issue>10</issue>):<fpage>865</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname> <given-names>S</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name>, <string-name><surname>Kable</surname> <given-names>JW</given-names></string-name></person-group>. <article-title>The human as delta-rule learner</article-title>. <source>Decision</source>. <year>2020</year>;<volume>7</volume>(<issue>1</issue>):<fpage>55</fpage>–<lpage>66</lpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Levine</surname> <given-names>TR</given-names></string-name></person-group>. <article-title>Truth-Default Theory (TDT): A Theory of Human Deception and Deception Detection</article-title>. <source>J Lang Soc Psychol</source>. <year>2014</year> <month>Sep</month> <day>1</day>;<volume>33</volume>(<issue>4</issue>):<fpage>378</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bornstein</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Norman</surname> <given-names>KA</given-names></string-name></person-group>. <article-title>Reinstated episodic context guides sampling-based decisions for reward</article-title>. <source>Nat Neurosci</source>. <year>2017</year> <month>Jul</month>;<volume>20</volume>(<issue>7</issue>):<fpage>997</fpage>–<lpage>1003</lpage>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bornstein</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Khaw</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Shohamy</surname> <given-names>D</given-names></string-name>, <string-name><surname>Daw</surname> <given-names>ND</given-names></string-name></person-group>. <article-title>Reminders of past choices bias decisions for reward in humans</article-title>. <source>Nat Commun</source>. <year>2017</year> <month>Jun</month> <day>27</day>;<volume>8</volume>(<issue>1</issue>):<fpage>15958</fpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pittman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Haley</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Cognitive Load and Social Media Advertising</article-title>. <source>J Interact Advert</source>. <year>2023</year> <month>Jan</month> <day>2</day>;<volume>23</volume>(<issue>1</issue>):<fpage>33</fpage>–<lpage>54</lpage>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rodriguez</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Gummadi</surname> <given-names>K</given-names></string-name>, <string-name><surname>Schoelkopf</surname> <given-names>B</given-names></string-name></person-group>. <article-title>Quantifying Information Overload in Social Media and Its Impact on Social Contagions</article-title>. <source>Proc Int AAAI Conf Web Soc Media</source>. <year>2014</year> <month>May</month> <day>16</day>;<volume>8</volume>(<issue>1</issue>):<fpage>170</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahmed</surname> <given-names>S</given-names></string-name>, <string-name><surname>Tan</surname> <given-names>HW</given-names></string-name></person-group>. <article-title>Personality and perspicacity: Role of personality traits and cognitive ability in political misinformation discernment and sharing behavior</article-title>. <source>Personal Individ Differ</source>. <year>2022</year> <month>Oct</month> <day>1</day>;<volume>196</volume>:<fpage>111747</fpage>.</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Hwang</surname> <given-names>EH</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>S</given-names></string-name></person-group>. <article-title>A Nudge to Credible Information as a Countermeasure to Misinformation: Evidence from Twitter</article-title>. <source>Inf Syst Res [Internet]</source>. <year>2024</year> <month>Feb</month> <day>28</day> [<date-in-citation>cited <year>2024</year> <month>Mar</month> <day>21</day></date-in-citation>]; Available from: <ext-link ext-link-type="uri" xlink:href="https://pubsonline.informs.org/doi/full/10.1287/isre.2021.0491">https://pubsonline.informs.org/doi/full/10.1287/isre.2021.0491</ext-link></mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walter</surname> <given-names>N</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Holbert</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Morag</surname> <given-names>Y</given-names></string-name></person-group>. <article-title>Fact-Checking: A Meta-Analysis of What Works and for Whom</article-title>. <source>Polit Commun</source>. <year>2020</year> <month>May</month> <day>3</day>;<volume>37</volume>(<issue>3</issue>):<fpage>350</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chambon</surname> <given-names>V</given-names></string-name>, <string-name><surname>Théro</surname> <given-names>H</given-names></string-name>, <string-name><surname>Vidal</surname> <given-names>M</given-names></string-name>, <string-name><surname>Vandendriessche</surname> <given-names>H</given-names></string-name>, <string-name><surname>Haggard</surname> <given-names>P</given-names></string-name>, <string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Information about action outcomes differentially affects learning from self-determined versus imposed choices</article-title>. <source>Nat Hum Behav</source>. <year>2020</year> <month>Oct</month>;<volume>4</volume>(<issue>10</issue>):<fpage>1067</fpage>–<lpage>79</lpage>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Westerwick</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sude</surname> <given-names>D</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Knobloch-Westerwick</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Peers Versus Pros: Confirmation Bias in Selective Exposure to User-Generated Versus Professional Media Messages and Its Consequences</article-title>. <source>Mass Commun Soc</source>. <year>2020</year> <month>Jul</month> <day>3</day>;<volume>23</volume>(<issue>4</issue>):<fpage>510</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Gallo</surname> <given-names>E</given-names></string-name>, <string-name><surname>Langtry</surname> <given-names>A</given-names></string-name></person-group>. <source>Social Networks, Confirmation Bias and Shock Elections</source>. <year>2020</year> <month>Nov</month> <day>2</day> [<date-in-citation>cited <year>2024</year> <month>Feb</month> <day>29</day></date-in-citation>]; Available from: <ext-link ext-link-type="uri" xlink:href="https://www.repository.cam.ac.uk/handle/1810/315203">https://www.repository.cam.ac.uk/handle/1810/315203</ext-link></mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lefebvre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Deroy</surname> <given-names>O</given-names></string-name>, <string-name><surname>Bahrami</surname> <given-names>B</given-names></string-name></person-group>. <article-title>The roots of polarization in the individual reward system</article-title>. <source>Proc R Soc B Biol Sci</source>. <year>2024</year> <month>Feb</month> <day>28</day>;<volume>291</volume>(<issue>2017</issue>):<fpage>20232011</fpage>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meppelink</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Smit</surname> <given-names>EG</given-names></string-name>, <string-name><surname>Fransen</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Diviani</surname> <given-names>N</given-names></string-name></person-group>. <article-title>“I was Right about Vaccination”: Confirmation Bias and Health Literacy in Online Health Information Seeking</article-title>. <source>J Health Commun</source>. <year>2019</year> <month>Feb</month> <day>1</day>;<volume>24</volume>(<issue>2</issue>):<fpage>129</fpage>–<lpage>40</lpage>.</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malthouse</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Confirmation bias and vaccine-related beliefs in the time of COVID-19</article-title>. <source>J Public Health</source>. <year>2023</year> <month>Jun</month> <day>1</day>;<volume>45</volume>(<issue>2</issue>):<fpage>523</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Overcoming Confirmation Bias in Misinformation Correction: Effects of Processing Motive and Jargon on Climate Change Policy Support</article-title>. <source>Sci Commun</source>. <year>2024</year> <month>Feb</month> <day>20</day>;<fpage>10755470241229452</fpage>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sunstein</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Bobadilla-Suarez</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lazzaro</surname> <given-names>SC</given-names></string-name>, <string-name><surname>Sharot</surname> <given-names>T</given-names></string-name></person-group>. <article-title>How People Update Beliefs about Climate Change: Good News and Bad News</article-title>. <source>CORNELL LAW Rev</source>. <volume>102</volume>:<elocation-id>1</elocation-id>. <year>2017</year></mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shen</surname> <given-names>L</given-names></string-name></person-group>. <article-title>Confirmation Bias and the Persistence of Misinformation on Climate Change</article-title>. <source>Commun Res</source>. <year>2022</year> <month>Jun</month> <day>1</day>;<volume>49</volume>(<issue>4</issue>):<fpage>500</fpage>–<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hart</surname> <given-names>PS</given-names></string-name>, <string-name><surname>Nisbet</surname> <given-names>EC</given-names></string-name></person-group>. <article-title>Boomerang Effects in Science Communication: How Motivated Reasoning and Identity Cues Amplify Opinion Polarization About Climate Mitigation Policies</article-title>. <source>Commun Res</source>. <year>2012</year> <month>Dec</month> <day>1</day>;<volume>39</volume>(<issue>6</issue>):<fpage>701</fpage>–<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Gläscher</surname> <given-names>J</given-names></string-name></person-group>. <article-title>A brain network supporting social influences in human decision-making</article-title>. <source>Sci Adv</source>. <year>2020</year> <month>Aug</month>;<volume>6</volume>(<issue>34</issue>):<elocation-id>eabb4159</elocation-id>.</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burke</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Tobler</surname> <given-names>PN</given-names></string-name>, <string-name><surname>Baddeley</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schultz</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Neural mechanisms of observational learning</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2010</year> <month>Aug</month> <day>10</day>;<volume>107</volume>(<issue>32</issue>):<fpage>14431</fpage>–<lpage>6</lpage>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charpentier</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Iigaya</surname> <given-names>K</given-names></string-name>, <string-name><surname>O’Doherty</surname> <given-names>JP</given-names></string-name></person-group>. <article-title>A Neuro-computational Account of Arbitration between Choice Imitation and Goal Emulation during Human Observational Learning</article-title>. <source>Neuron</source>. <year>2020</year> <month>May</month> <day>20</day>;<volume>106</volume>(<issue>4</issue>):<fpage>687</fpage>–<lpage>699</lpage>.<elocation-id>e7</elocation-id>.</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name><surname>Hunt</surname> <given-names>LT</given-names></string-name>, <string-name><surname>Woolrich</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Rushworth</surname> <given-names>MFS</given-names></string-name></person-group>. <article-title>Associative learning of social value</article-title>. <source>Nature</source>. <year>2008</year> <month>Nov</month>;<volume>456</volume>(<issue>7219</issue>):<fpage>245</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garrett</surname> <given-names>RK</given-names></string-name></person-group>. <article-title>Echo chambers online?: Politically motivated selective exposure among Internet news users1</article-title>. <source>J Comput-Mediat Commun</source>. <year>2009</year> <month>Jan</month> <day>1</day>;<volume>14</volume>(<issue>2</issue>):<fpage>265</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Ross Arguedas</surname> <given-names>A</given-names></string-name>, <string-name><surname>Robertson</surname> <given-names>C</given-names></string-name>, <string-name><surname>Fletcher</surname> <given-names>R</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Echo chambers, filter bubbles, and polarisation: a literature review [Internet]</article-title>. <source>Reuters Institute for the Study of Journalism</source>; <year>2022</year> [<date-in-citation>cited <year>2024</year> <month>Apr</month> <day>29</day></date-in-citation>]. Available from: <ext-link ext-link-type="uri" xlink:href="https://ora.ox.ac.uk/objects/uuid:6e357e97-7b16-450a-a827-a92c93729a08">https://ora.ox.ac.uk/objects/uuid:6e357e97-7b16-450a-a827-a92c93729a08</ext-link></mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cardenal</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Aguilar-Paredes</surname> <given-names>C</given-names></string-name>, <string-name><surname>Galais</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pérez-Montoro</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Digital Technologies and Selective Exposure: How Choice and Filter Bubbles Shape News Media Exposure</article-title>. <source>Int J Press</source>. <year>2019</year> <month>Oct</month> <day>1</day>;<volume>24</volume>(<issue>4</issue>):<fpage>465</fpage>–<lpage>86</lpage>.</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brady</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Jackson</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Lindström</surname> <given-names>B</given-names></string-name>, <string-name><surname>Crockett</surname> <given-names>MJ</given-names></string-name></person-group>. <article-title>Algorithm-mediated social learning in online social networks</article-title>. <source>Trends Cogn Sci</source>. <year>2023</year> <month>Oct</month> <day>1</day>;<volume>27</volume>(<issue>10</issue>):<fpage>947</fpage>–<lpage>60</lpage>.</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bakshy</surname> <given-names>E</given-names></string-name>, <string-name><surname>Messing</surname> <given-names>S</given-names></string-name>, <string-name><surname>Adamic</surname> <given-names>LA</given-names></string-name></person-group>. <article-title>Exposure to ideologically diverse news and opinion on Facebook</article-title>. <source>Science</source>. <year>2015</year> <month>Jun</month> <day>5</day>;<volume>348</volume>(<issue>6239</issue>):<fpage>1130</fpage>–<lpage>2</lpage>.</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anwyl-Irvine</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Massonnié</surname> <given-names>J</given-names></string-name>, <string-name><surname>Flitton</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kirkham</surname> <given-names>N</given-names></string-name>, <string-name><surname>Evershed</surname> <given-names>JK</given-names></string-name></person-group>. <article-title>Gorilla in our midst: An online behavioral experiment builder</article-title>. <source>Behav Res Methods</source>. <year>2020</year> <month>Feb</month> <day>1</day>;<volume>52</volume>(<issue>1</issue>):<fpage>388</fpage>–<lpage>407</lpage>.</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foa</surname> <given-names>EB</given-names></string-name>, <string-name><surname>Huppert</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Leiberg</surname> <given-names>S</given-names></string-name>, <string-name><surname>Langner</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kichic</surname> <given-names>R</given-names></string-name>, <string-name><surname>Hajcak</surname> <given-names>G</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The Obsessive-Compulsive Inventory: Development and validation of a short version</article-title>. <source>Psychol Assess</source>. <year>2002</year>;<volume>14</volume>(<issue>4</issue>):<fpage>485</fpage>–<lpage>96</lpage>.</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freeman</surname> <given-names>D</given-names></string-name>, <string-name><surname>Loe</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Kingdon</surname> <given-names>D</given-names></string-name>, <string-name><surname>Startup</surname> <given-names>H</given-names></string-name>, <string-name><surname>Molodynski</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rosebrock</surname> <given-names>L</given-names></string-name>, <etal>et al</etal></person-group>. <article-title>The revised Green et al., Paranoid Thoughts Scale (R-GPTS): psychometric properties, severity ranges, and clinical cutoffs</article-title>. <source>Psychol Med</source>. <volume>51</volume>(<issue>2</issue>):<fpage>244</fpage>–<lpage>53</lpage>. <year>2021</year></mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altemeyer</surname> <given-names>B</given-names></string-name></person-group>. <article-title>Dogmatic behavior among students: testing a new measure of dogmatism</article-title>. <source>J Soc Psychol</source>. <year>2002</year> <month>Dec</month>;<volume>142</volume>(<issue>6</issue>):<fpage>713</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wagenmakers</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Ratcliff</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gomez</surname> <given-names>P</given-names></string-name>, <string-name><surname>Iverson</surname> <given-names>GJ</given-names></string-name></person-group>. <article-title>Assessing model mimicry using the parametric bootstrap</article-title>. <source>J Math Psychol</source>. <year>2004</year> <month>Feb</month> <day>1</day>;<volume>48</volume>(<issue>1</issue>):<fpage>28</fpage>–<lpage>50</lpage>.</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Keramati</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>Retrospective model-based inference guides modelfree credit assignment</article-title>. <source>Nat Commun</source>. <year>2019</year> <month>Feb</month> <day>14</day>;<volume>10</volume>(<issue>1</issue>):<fpage>750</fpage>.</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Goshen-Gottstein</surname> <given-names>Y</given-names></string-name></person-group>. <article-title>Old processes, new perspectives: Familiarity is correlated with (not independent of) recollection and is more (not equally) variable for targets than for lures</article-title>. <source>Cognit Psychol</source>. <year>2015</year> <month>Jun</month> <day>1</day>;<volume>79</volume>:<fpage>40</fpage>–<lpage>67</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides a <bold>valuable</bold> extension of credibility-based learning research by showing how feedback reliability can distort reward-learning biases in a disinformation-like bandit task. Although the paradigm is well controlled and the computational modelling rigorous, the evidential support is <bold>incomplete</bold>: key claims about learning from 50 %-credible feedback and heightened positivity bias at low credibility hinge on a single dataset, specific parameter definitions, and modelling assumptions not fully validated across studies. Clearer reporting of the discovery-study null result, behavioural tests of positivity bias, and standard information-criterion model comparisons are needed to solidify the conclusions and enhance generalizability.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This is a well-designed and very interesting study examining the impact of imprecise feedback on outcomes in decision-making. I think this is an important addition to the literature, and the results here, which provide a computational account of several decision-making biases, are insightful and interesting.</p>
<p>I do not believe I have substantive concerns related to the actual results presented; my concerns are more related to the framing of some of the work. My main concern is regarding the assertion that the results prove that non-normative and non-Bayesian learning is taking place. I agree with the authors that their results demonstrate that people will make decisions in ways that demonstrate deviations from what would be optimal for maximizing reward in their task under a strict application of Bayes' rule. I also agree that they have built reinforcement learning models that do a good job of accounting for the observed behavior. However, the Bayesian models included are rather simple, per the author's descriptions, applications of Bayes' rule with either fixed or learned credibility for the feedback agents. In contrast, several versions of the RL models are used, each modified to account for different possible biases. However, more complex Bayes-based models exist, notably active inference, but even the hierarchical Gaussian filter. These formalisms are able to accommodate more complex behavior, such as affect and habits, which might make them more competitive with RL models. I think it is entirely fair to say that these results demonstrate deviations from an idealized and strict Bayesian context; however, the equivalence here of Bayesian and normative is, I think, misleading or at least requires better justification/explanation. This is because a great deal of work has been done to show that Bayes optimal models can generate behavior or other outcomes that are clearly not optimal to an observer within a given context (consider hallucinations for example) but which make sense in the context of how the model is constructed as well as the priors and desired states the model is given.</p>
<p>As such, I would recommend that the language be adjusted to carefully define what is meant by normative and Bayesian and to recognize that work that is clearly Bayesian could potentially still be competitive with RL models if implemented to model this task. An even better approach would be to directly use one of these more complex modelling approaches, such as active inference, as the comparator to the RL models, though I would understand if the authors would want this to be a subject for future work.</p>
<p>Abstract:</p>
<p>The abstract is lacking in some detail about the experiments done, but this may be a limitation of the required word count. If word count is not an issue, I would recommend adding details of the experiments done and the results.</p>
<p>
One comment is that there is an appeal to normative learning patterns, but this suggests that learning patterns have a fixed optimal nature, which may not be true in cases where the purpose of the learning (e.g. to confirm the feeling of safety of being in an in-group) may not be about learning accurately to maximize reward. This can be accommodated in a Bayesian framework by modelling priors and desired outcomes. As such, the central premise that biased learning is inherently non-normative or non-Bayesian, I think, would require more justification. This is true in the introduction as well.</p>
<p>Introduction:</p>
<p>As noted above, the conceptualization of Bayesian learning being equivalent to normative learning, I think requires further justification. Bayesian belief updating can be biased and non-optimal from an observer perspective, while being optimal within the agent doing the updating if the priors/desired outcomes are set up to advantage these &quot;non-optimal&quot; modes of decision making.</p>
<p>Results:</p>
<p>I wonder why the agent was presented before the choice, since the agent is only relevant to the feedback after the choice is made. I wonder if that might have induced any false association between the agent identity and the choice itself. This is by no means a critical point, but it would be interesting to get the authors' thoughts.</p>
<p>The finding that positive feedback increases learning is one that has been shown before and depends on valence, as the authors note. They expanded their reinforcement learning model to include valence, but they did not modify the Bayesian model in a similar manner. This lack of a valence or recency effect might also explain the failure of the Bayesian models in the preceding section, where the contrast effect is discussed. It is not unreasonable to imagine that if humans do employ Bayesian reasoning that this reasoning system has had parameters tuned based on the real world, where recency of information does matter; affect has also been shown to be incorporable into Bayesian information processing (see the work by Hesp on affective charge and the large body of work by Ryan Smith). It may be that the Bayesian models chosen here require further complexity to capture the situation, just like some of the biases required updates to the RL models. This complexity, rather than being arbitrary, may be well justified by decision-making in the real world.</p>
<p>The methods mention several symptom scales- it would be interesting to have the results of these and any interesting correlations noted. It is possible that some of the individual variability here could be related to these symptoms, which could introduce precision parameter changes in a Bayesian context and things like reward sensitivity changes in an RL context.</p>
<p>Discussion:</p>
<p>(For discussion, not a specific comment on this paper): One wonders also about participants' beliefs about the experiment or the intent of the experimenters. I have often had participants tell me they were trying to &quot;figure out&quot; a task or find patterns even when this was not part of the experiment. This is not specific to this paper, but it may be relevant in the future to try and model participant beliefs about the experiment especially in the context of disinformation, when they might be primed to try and &quot;figure things out&quot;.</p>
<p>As a general comment, in the active inference literature, there has been discussion of state-dependent actions, or &quot;habits&quot;, which are learned in order to help agents more rapidly make decisions, based on previous learning. It is also possible that what is being observed is that these habits are at play, and that they represent the cognitive biases. This is likely especially true given, as the authors note, the high cognitive load of the task. It is true that this would mean that full-force Bayesian inference is not being used in each trial, or in each experience an agent might have in the world, but this is likely adaptive on the longer timescale of things, considering resource requirements. I think in this case you could argue that we have a departure from &quot;normative&quot; learning, but that is not necessarily a departure from any possible Bayesian framework, since these biases could potentially be modified by the agent or eschewed in favor of more expensive full-on Bayesian learning when warranted.</p>
<p>Indeed, in their discussion on the strategy of amplifying credible news sources to drown out low-credibility sources, the authors hint at the possibility of longer-term strategies that may produce optimal outcomes in some contexts, but which were not necessarily appropriate to this task. As such, the performance on this task- and the consideration of true departure from Bayesian processing- should be considered in this wider context.</p>
<p>Another thing to consider is that Bayesian inference is occurring, but that priors present going in produce the biases, or these biases arise from another source, for example, factoring in epistemic value over rewards when the actual reward is not large. This again would be covered under an active inference approach, depending on how the priors are tuned. Indeed, given the benefit of social cohesion in an evolutionary perspective, some of these &quot;biases&quot; may be the result of adaptation. For example, it might be better to amplify people's good qualities and minimize their bad qualities in order to make it easier to interact with them; this entails a cost (in this case, not adequately learning from feedback and potentially losing out sometimes), but may fulfill a greater imperative (improved cooperation on things that matter). Given the right priors/desired states, this could still be a Bayes-optimal inference at a social level and, as such, may be ingrained as a habit that requires effort to break at the individual level during a task such as this.</p>
<p>The authors note that this task does not relate to &quot;emotional engagement&quot; or &quot;deep, identity-related issues&quot;. While I agree that this is likely mostly true, it is also possible that just being told one is being lied to might elicit an emotional response that could bias responses, even if this is a weak response.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This valuable paper studies the problem of learning from feedback given by sources of varying credibility. The solid combination of experiment and computational modeling helps to pin down properties of learning, although some ambiguity remains in the interpretation of results.</p>
<p>Summary:</p>
<p>This paper studies the problem of learning from feedback given by sources of varying credibility. Two bandit-style experiments are conducted in which feedback is provided with uncertainty, but from known sources. Bayesian benchmarks are provided to assess normative facets of learning, and alternative credit assignment models are fit for comparison. Some aspects of normativity appear, in addition to deviations such as asymmetric updating from positive and negative outcomes.</p>
<p>Strengths:</p>
<p>The paper tackles an important topic, with a relatively clean cognitive perspective. The construction of the experiment enables the use of computational modeling. This helps to pinpoint quantitatively the properties of learning and formally evaluate their impact and importance. The analyses are generally sensible, and parameter recovery analyses help to provide some confidence in the model estimation and comparison.</p>
<p>Weaknesses:</p>
<p>(1) The approach in the paper overlaps somewhat with various papers, such as Diaconescu et al. (2014) and Schulz et al. (forthcoming), which also consider the Bayesian problem of learning and applying source credibility, in terms of theory and experiment. The authors should discuss how these papers are complementary, to better provide an integrative picture for readers.</p>
<p>Diaconescu, A. O., Mathys, C., Weber, L. A., Daunizeau, J., Kasper, L., Lomakina, E. I., ... &amp; Stephan, K. E. (2014). Inferring the intentions of others by hierarchical Bayesian learning. PLoS computational biology, 10(9), e1003810.</p>
<p>
Schulz, L., Schulz, E., Bhui, R., &amp; Dayan, P. Mechanisms of Mistrust: A Bayesian Account of Misinformation Learning. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.31234/osf.io/8egxh">https://doi.org/10.31234/osf.io/8egxh</ext-link></p>
<p>(2) It isn't completely clear what the &quot;cross-fitting&quot; procedure accomplishes. Can this be discussed further?</p>
<p>(3) The Credibility-CA model seems to fit the same as the free-credibility Bayesian model in the first experiment and barely better in the second experiment. Why not use a more standard model comparison metric like the Bayesian Information Criterion (BIC)? Even if there are advantages to the bootstrap method (which should be described if so), the BIC would help for comparability between papers.</p>
<p>(4) As suggested in the discussion, the updating based on random feedback could be due to the interleaving of trials. If one is used to learning from the source on most trials, the occasional random trial may be hard to resist updating from. The exact interleaving structure should also be clarified (I assume different sources were shown for each bandit pair). This would also relate to work on RL and working memory: Collins, A. G., &amp; Frank, M. J. (2012). How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis. European Journal of Neuroscience, 35(7), 1024-1035.</p>
<p>(5) Why does the choice-repetition regression include &quot;only trials for which the last same-pair trial featured the 3-star agent and in which the context trial featured a different bandit pair&quot;? This could be stated more plainly.</p>
<p>(6) Why apply the &quot;Truth-CA&quot; model and not the Bayesian variant that it was motivated by?</p>
<p>(7) &quot;Overall, the results from this study support the exact same conclusions (See SI section 1.2) but with one difference. In the discovery study, we found no evidence for learning based on 50%-credibility feedback when examining either the feedback effect on choice repetition or CA in the credibility-CA model (SI 1.2.3)&quot; - this seems like a very salient difference, when the paper reports the feedback effect as a primary finding of interest, though I understand there remains a valence-based difference.</p>
<p>(8) &quot;Participants were instructed that this feedback would be &quot;a lie 50% of the time but were not explicitly told that this meant it was random and should therefore be disregarded.&quot; - I agree that this is a possible explanation for updating from the random source. It is a meaningful caveat.</p>
<p>(9) &quot;Future studies should investigate conditions that enhance an ability to discard disinformation, such as providing explicit instructions to ignore misleading feedback, manipulations that increase the time available for evaluating information, or interventions that strengthen source memory.&quot; - there is work on some of this in the misinformation literature that should be cited, such as the &quot;continued influence effect&quot;. For example: Johnson, H. M., &amp; Seifert, C. M. (1994). Sources of the continued influence effect: When misinformation in memory affects later inferences. Journal of experimental psychology: Learning, memory, and cognition, 20(6), 1420.</p>
<p>(10) Are the authors arguing that choice-confirmation bias may be at play? Work on choice-confirmation bias generally includes counterfactual feedback, which is not present here.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>This paper investigates how disinformation affects reward learning processes in the context of a two-armed bandit task, where feedback is provided by agents with varying reliability (with lying probability explicitly instructed). They find that people learn more from credible sources, but also deviate systematically from optimal Bayesian learning: They learned from uninformative random feedback, learned more from positive feedback, and updated too quickly from fully credible feedback (especially following low-credibility feedback). Overall, this study highlights how misinformation could distort basic reward learning processes, without appeal to higher-order social constructs like identity.</p>
<p>Strengths</p>
<p>(1) The experimental design is simple and well-controlled; in particular, it isolates basic learning processes by abstracting away from social context.</p>
<p>(2) Modeling and statistics meet or exceed the standards of rigor.</p>
<p>(3) Limitations are acknowledged where appropriate, especially those regarding external validity.</p>
<p>(4) The comparison model, Bayes with biased credibility estimates, is strong; deviations are much more compelling than e.g., a purely optimal model.</p>
<p>(5) The conclusions are interesting, in particular the finding that positivity bias is stronger when learning from less reliable feedback (although I am somewhat uncertain about the validity of this conclusion)</p>
<p>Weaknesses</p>
<p>(1) Absolute or relative positivity bias?</p>
<p>In my view, the biggest weakness in the paper is that the conclusion of greater positivity bias for lower credible feedback (Figure 5) hinges on the specific way in which positivity bias is defined. Specifically, we only see the effect when normalizing the difference in sensitivity to positive vs. negative feedback by the sum. I appreciate that the authors present both and add the caveat whenever they mention the conclusion (with the crucial exception of the abstract). However, what we really need here is an argument that the relative definition is the *right* way to define asymmetry....</p>
<p>Unfortunately, my intuition is that the absolute difference is a better measure. I understand that the relative version is common in the RL literature; however previous studies have used standard TD models, whereas the current model updates based on the raw reward. The role of the CA parameter is thus importantly different from a traditional learning rate - in particular, it's more like a logistic regression coefficient (as described below) because it scales the feedback but *not* the decay. Under this interpretation, a difference in positivity bias across credibility conditions corresponds to a three-way interaction between the exponentially weighted sum of previous feedback of a given type (e.g., positive from the 75% credible agent), feedback positivity, and condition (dummy coded). This interaction corresponds to the non-normalized, absolute difference.</p>
<p>Importantly, I'm not terribly confident in this argument, but it does suggest that we need a compelling argument for the relative definition.</p>
<p>(2) Positivity bias or perseveration?</p>
<p>A key challenge in interpreting many of the results is dissociating perseveration from other learning biases. In particular, a positivity bias (Figure 5) and perseveration will both predict a stronger correlation between positive feedback and future choice. Crucially, the authors do include a perseveration term, so one would hope that perseveration effects have been controlled for and that the CA parameters reflect true positivity biases. However, with finite data, we cannot be sure that the variance will be correctly allocated to each parameter (c.f. collinearity in regressions). The fact that CA- is fit to be negative for many participants (a pattern shown more strongly in the discovery study) is suggestive that this might be happening. A priori, the idea that you would ever increase your value estimate after negative feedback is highly implausible, which suggests that the parameter might be capturing variance besides that it is intended to capture.</p>
<p>The best way to resolve this uncertainty would involve running a new study in which feedback was sometimes provided in the absence of a choice - this would isolate positivity bias. Short of that, perhaps one could fit a version of the Bayesian model that also includes perseveration. If the authors can show that this model cannot capture the pattern in Figure 5, that would be fairly convincing.</p>
<p>(3) Veracity detection or positivity bias?</p>
<p>The &quot;True feedback elicits greater learning&quot; effect (Figure 6) may be simply a re-description of the positivity bias shown in Figure 5. This figure shows that people have higher CA for trials where the feedback was in fact accurate. But, assuming that people tend to choose more rewarding options, true-feedback cases will tend to also be positive-feedback cases. Accordingly, a positivity bias would yield this effect, even if people are not at all sensitive to trial-level feedback veracity. Of course, the reverse logic also applies, such that the &quot;positivity bias&quot; could actually reflect discounting of feedback that is less likely to be true. This idea has been proposed before as an explanation for confirmation bias (see Pilgrim et al, 2024 <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2023.105693">https://doi.org/10.1016/j.cognition.2023.105693</ext-link> and much previous work cited therein). The authors should discuss the ambiguity between the &quot;positivity bias&quot; and &quot;true feedback&quot; effects within the context of this literature....</p>
<p>The authors get close to this in the discussion, but they characterize their results as differing from the predictions of rational models, the opposite of my intuition. They write:</p>
<p>Alternative &quot;informational&quot; (motivation-independent) accounts of positivity and confirmation bias predict a contrasting trend (i.e., reduced bias in low- and medium credibility conditions) because in these contexts it is more ambiguous whether feedback confirms one's choice or outcome expectations, as compared to a full-credibility condition.</p>
<p>I don't follow the reasoning here at all. It seems to me that the possibility for bias will increase with ambiguity (or perhaps will be maximal at intermediate levels). In the extreme case, when feedback is fully reliable, it is impossible to rationally discount it (illustrated in Figure 6A). The authors should clarify their argument or revise their conclusion here.</p>
<p>(4) Disinformation or less information?</p>
<p>Zooming out, from a computational/functional perspective, the reliability of feedback is very similar to reward stochasticity (the difference is that reward stochasticity decreases the importance/value of learning in addition to its difficulty). I imagine that many of the effects reported here would be reproduced in that setting. To my surprise, I couldn't quickly find a study asking that precise question, but if the authors know of such work, it would be very useful to draw comparisons. To put a finer point on it, this study does not isolate which (if any) of these effects are specific to *disinformation*, rather than simply _less information._ I don't think the authors need to rigorously address this in the current study, but it would be a helpful discussion point.</p>
<p>(5) Over-reliance on analyzing model parameters</p>
<p>Most of the results rely on interpreting model parameters, specifically, the &quot;credit assignment&quot; (CA) parameter. Exacerbating this, many key conclusions rest on a comparison of the CA parameters fit to human data vs. those fit to simulations from a Bayesian model. I've never seen anything like this, and the authors don't justify or even motivate this analysis choice. As a general rule, analyses of model parameters are less convincing than behavioral results because they inevitably depend on arbitrary modeling assumptions that cannot be fully supported. I imagine that most or even all of the results presented here would have behavioral analogues. The paper would benefit greatly from the inclusion of such results. It would also be helpful to provide a description of the model in the main text that makes it very clear what exactly the CA parameter is capturing (see next point).</p>
<p>(6) RL or regression?</p>
<p>I was initially very confused by the &quot;RL&quot; model because it doesn't update based on the TD error. Consequently, the &quot;Q values&quot; can go beyond the range of possible reward (SI Figure 5). These values are therefore *not* Q values, which are defined as expectations of future reward (&quot;action values&quot;). Instead, they reflect choice propensities, which are sometimes notated $h$ in the RL literature. This misuse of notation is unfortunately quite common in psychology, so I won't ask the authors to change the variable. However, they should clarify when introducing the model that the Q values are not action values in the technical sense. If there is precedent for this update rule, it should be cited.</p>
<p>Although the change is subtle, it suggests a very different interpretation of the model.</p>
<p>Specifically, I think the &quot;RL model&quot; is better understood as a sophisticated logistic regression, rather than a model of value learning. Ignoring the decay term, the CA term is simply the change in log odds of repeating the just-taken action in future trials (the change is negated for negative feedback). The PERS term is the same, but ignoring feedback. The decay captures that the effect of each trial on future choices diminishes with time. Importantly, however, we can re-parameterize the model such that the choice at each trial is a logistic regression where the independent variables are an exponentially decaying sum of feedback of each type (e.g., positive-cred50, positive-cred75, ... negative-cred100). The CA parameters are simply coefficients in this logistic regression.</p>
<p>Critically, this is not meant to &quot;deflate&quot; the model. Instead, it clarifies that the CA parameter is actually not such an assumption-laden model estimate. It is really quite similar to a regression coefficient, something that is usually considered &quot;model agnostic&quot;. It also recasts the non-standard &quot;cross-fitting&quot; approach as a very standard comparison of regression coefficients for model simulations vs. human data. Finally, using different CA parameters for true vs false feedback is no longer a strange and implausible model assumption; it's just another (perfectly valid) regression. This may be a personal thing, but after adopting this view, I found all the results much easier to understand.</p>
</body>
</sub-article>
</article>