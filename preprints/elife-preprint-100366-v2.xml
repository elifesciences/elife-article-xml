<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">100366</article-id>
<article-id pub-id-type="doi">10.7554/eLife.100366</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100366.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.5</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Risking your Tail: Modeling Individual Differences in Risk-sensitive Exploration using Bayes Adaptive Markov Decision Processes</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-0286-5663</contrib-id>
<name>
<surname>Shen</surname>
<given-names>Tingke</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
<email>tingke.shen@tuebingen.mpg.de</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dayan</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026nmvv73</institution-id><institution>Max Planck Institute for Biological Cybernetics</institution></institution-wrap>, <city>Tübingen</city>, <country country="DE">Germany</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>University of Tübingen</institution></institution-wrap>, <city>Tübingen</city>, <country country="DE">Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Langdon</surname>
<given-names>Angela</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
<city>Bethesda</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="present-address"><label>*</label><p>Present address: Max-Planck-Ring 8, Tübingen, Germany</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-11-11">
<day>11</day>
<month>11</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-09-26">
<day>26</day>
<month>09</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP100366</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-07-22">
<day>22</day>
<month>07</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-08-14">
<day>14</day>
<month>08</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.01.07.574574"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-11-11">
<day>11</day>
<month>11</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100366.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.100366.1.sa3">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.100366.1.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.100366.1.sa1">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.100366.1.sa0">Reviewer #3 (Public review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Shen &amp; Dayan</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Shen &amp; Dayan</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-100366-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>Novelty is a double-edged sword for agents and animals alike: they might benefit from untapped resources or face unexpected costs or dangers such as predation. The conventional exploration/exploitation tradeoff is thus coloured by risk-sensitivity. A wealth of experiments has shown how animals solve this dilemma, for example using intermittent approach. However, there are large individual differences in the nature of approach, and modeling has yet to elucidate how this might be based on animals’ differing prior expectations about reward and threat, and differing degrees of risk aversion. To capture these factors, we built a Bayes adaptive Markov decision process model with three key components: an adaptive hazard function capturing potential predation, an intrinsic reward function providing the urge to explore, and a conditional value at risk (CVaR) objective, which is a contemporary measure of trait risk-sensitivity. We fit this model to a coarse-grain abstraction of the behaviour of 26 animals who freely explored a novel object in an open-field arena (Akiti et al. <italic>Neuron</italic> 110, 2022). We show that the model captures both quantitative (frequency, duration of exploratory bouts) and qualitative (with distinguished, cautious, tail-behind approach) features of behavior, including the substantial idiosyncrasies that were observed. Some animals begin with cautious exploration, and quickly transition to confident approach to maximize exploration for reward; we classify them as potentially more risk neutral, and enjoying a flexible hazard prior. By contrast, other animals only ever approach in a cautious manner and display a form of self-censoring; they are characterized by potential risk aversion and high and inflexible hazard priors. Explaining risk-sensitive exploration using factorized parameters of reinforcement learning models could aid in the understanding, diagnosis, and treatment of psychiatric abnormalities such as anxiety disorders.</p>
</abstract>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01hhn8329</institution-id>
<institution>Max Planck Society</institution>
</institution-wrap>
</funding-source>
</award-group>
<award-group id="funding-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/012kf4317</institution-id>
<institution>Alexander von Humboldt Foundation</institution>
</institution-wrap>
</funding-source>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Significant revisions: changed subsection numbering of Results section, added clarifications to discussion and abstract.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>In naturalistic environments, novelty can be a source of both reward and dangers. Despite these duelling aspects, investigations of novelty in reinforcement learning (RL) have mostly focused on neophilia driven by optimism in the face of uncertainty, and so information-seeking (<xref ref-type="bibr" rid="c24">Duff, 2002a</xref>; <xref ref-type="bibr" rid="c22">Dayan and Sejnowski, 1996</xref>; <xref ref-type="bibr" rid="c36">Gottlieb et al., 2013</xref>; <xref ref-type="bibr" rid="c72">Wilson et al., 2014</xref>). Neophobia has attracted fewer computational studies, apart from some interesting evolutionary analyses (<xref ref-type="bibr" rid="c37">Greggor et al., 2015</xref>).</p>
<p>Excessive novelty seeking and excessive novelty avoidance can both be maladaptive – they are flip sides of a disturbed balance. Here, we seek to examine potential sources of such disturbances, for instance, in distorted priors about the magnitude or probabilities of rewards (which have been linked to mania; <xref ref-type="bibr" rid="c60">Radulescu and Niv, 2019</xref>; <xref ref-type="bibr" rid="c10">Bennett and Niv, 2020</xref>; <xref ref-type="bibr" rid="c28">Eldar et al., 2016</xref>) or threats (linked to anxiety and depression; <xref ref-type="bibr" rid="c11">Bishop and Gagne, 2018</xref>; <xref ref-type="bibr" rid="c59">Paulus and Yu, 2012</xref>), or in extreme risk attitudes (<xref ref-type="bibr" rid="c31">Gagne and Dayan, 2022</xref>).</p>
<p>To do this, we take advantage of a recent study by <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) on the behaviour of mice exploring a familiar open-field arena after the introduction of a novel object near to one corner. The mice could move freely and interact with the object at will. <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) performed detailed analyses of how individual animals’ trajectories reflected the novel object, including using DeepLabCut (<xref ref-type="bibr" rid="c51">Mathis et al., 2018</xref>) to track the orientation of the mice relative to the object and MOSEQ (<xref ref-type="bibr" rid="c73">Wiltschko et al., 2020</xref>) to extract behavioural ‘syllables’ whose prevalence was affected by it. The animals differed markedly in how they approached the object, and in what pattern. For the former, <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) observed two characteristic positionings of the animals when near to the object: ‘tail-behind’ (bouts where the animal’s nose was closer to the object than the tail for the entire bout) and ‘tail-exposed’ (bouts where the animal’s tail is closer to the object than the nose at some point during the bout), associated respectively with cautious risk-assessment and engagement. For the latter, there was substantial heterogeneity, with all animals initially performing tail-behind approach, but some taking much longer (or failing altogether) to transition to tail-exposed approach.</p>
<p><xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) provides a model-free reinforcement learning account of their data, focusing on the prediction of threat and its realization in the tail of the striatum. Here, we provide a model-based reinforcement learning account, focusing on the rich details of the dynamics of approach carefully characterized by <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>). These include intermittency (i.e., why animals retreat from the object), approach drive (or why animals approach in the first place), the significant long-run approach of cautious animals despite having reached periods of “avoidance” behavior, and how the intensity of approach increases when the other animals transition from risk-assessment to engagement and then decreases in the long-run of the “engagement” phase. Our model provides an alternative explanation for why animals learn to avoid the novel object in a completely benign environment. Through modeling these additional statistics and behaviors, we reveal multi-dimensional aspect of caution in exploration which cannot be captured just in terms of time spent at the object.</p>
<p>We model an abstract depiction of the behaviour of individual mice by combining the Bayes-adaptive Markov Decision Process (BAMDPs) treatment of rational exploration (<xref ref-type="bibr" rid="c23">Dearden et al., 2013</xref>; <xref ref-type="bibr" rid="c24">Duff, 2002a</xref>; <xref ref-type="bibr" rid="c38">Guez et al., 2013</xref>) with two sources of risk-sensitivity: the prior over the potential hazard associated with the object, and the conditional value at risk (CVaR) probability distortion mechanism (<xref ref-type="bibr" rid="c7">Artzner et al., 1999</xref>; <xref ref-type="bibr" rid="c17">Chow et al., 2015</xref>; <xref ref-type="bibr" rid="c31">Gagne and Dayan, 2022</xref>; <xref ref-type="bibr" rid="c8">Bellemare et al., 2023a</xref>).</p>
<p>In a BAMDP, the agent maintains a belief about the possible rewards, costs and transitions in the environment, and decides upon optimal actions based on these beliefs. Since the agent can optionally reuse or abandon incompletely known actions based on what it discovers about them, these actions traditionally enjoy an exploration bonus or “value of information”, which generalizes the famous Gittins indices (<xref ref-type="bibr" rid="c34">Gittins, 1979</xref>; <xref ref-type="bibr" rid="c71">Weber, 1992</xref>). In addition to beliefs about reward, the agent also maintains a belief about potential hazard which is the first source of risk-sensitivity. These beliefs are initialized as prior expectations about the environment; and so are readily subject to individual differences.</p>
<p>In addition to beliefs about hazards which may be specific to a particular environment, we include a second, potential more general, source of risk-sensitivity. That is, we consider optimizing the CVaR, in which agents concentrate on the average value within lower (risk-averse) or upper (risk-seeking) quantiles of the distribution of potential outcomes (<xref ref-type="bibr" rid="c63">Rigter et al., 2021</xref>). In the context of a BAMDP, this can force agents to pay particular attention to hazards. More extreme quantiles are associated with more extreme risk-sensitivity; and again are a potential locus of individual differences (as examined in regular Markov decision processes in the context of anxiety disorders in <xref ref-type="bibr" rid="c31">Gagne and Dayan, 2022</xref>).</p>
<p>In sum, we present a behavioral model of risk sensitive exploration, with an agent computing optimal actions using the BAMDP framework under a CVaR objective. This model provides a normative explanation of individual variability – the agent makes decisions by trading off potential reward and threat in a principled way. Different priors and risk sensitivities lead to exploratory schedules that differ in duration, frequency, and type of approach (risk-assessment versus engagement) through time. We report features of the different behavioural trajectories the model is able to capture, providing mechanistic insight into how the trade-off between potential reward and threat leads to rational exploratory schedules. Behavioral phenotypes emerge from the interaction of the separate computational mechanisms elucidated by our model-based treatment. This paves the way for future experimental investigations of these mechanisms, including the unexpected non-identifiability of our two sources of risk-sensitivty: hazard priors and CVaR.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<sec id="s2a">
<label>2.1</label>
<title>Behavior Phases and Animal Groups</title>
<p>Our goal is to provide a computational account of the exploratory behavior of individual mice under the assumption that they have different prior expectations and risk sensitivities. We start from <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>)’s observation that the animal approaches and remains within a threshold distance (determined by them to be 7cm) of the object in “bouts” which can be characterized as “cautious” or tail-behind (if the animal’s nose lies between the object and tail) or otherwise “confident” or tail-exposed. We sought to capture these qualitative differences (cautious versus confident) as well as aspects of the quantitative changes in bout durations and frequencies as the animal learns about their environment. To make this readily possible, we abstracted the data in two ways: averaging bout statistics over time, and clustering the animals into three groups with operationally distinct behaviors.</p>
<p><xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>)’s classification into bouts can be seen a very useful abstraction over some of the detailed complexities of the behavior. In order to focus narrowly on interaction with the object, we abstracted further. In particular, instead of the modeling the details of the animals’ spatial interaction with the object, we fitted boxcar functions to the percentages of its time <italic>g</italic><sup>cau</sup>(<italic>t</italic>), <italic>g</italic><sup>con</sup>(<italic>t</italic>) that the animal spends in cautious and confident bouts around time <italic>t</italic> in the apparatus. We can then well encompass the behaviour of most animals via four coarse phases of behaviour that arise from two binary factors: whether the animal is mainly performing cautious or confident approaches, and whether bouts happen frequently, at a peak rate, or at a lower, steady-state rate. The time an animal spends near the object in one of these phases reflects the product of how frequently it visits the object, and how long it stays per visit. We average these two factors within each phase.</p>
<p>Consider the behaviour of the animal in <xref rid="fig1" ref-type="fig">Fig 1a</xref>. Here, <italic>g</italic><sup>cau</sup>(<italic>t</italic>) (top graph) makes a transition from an initial level <inline-formula><inline-graphic xlink:href="574574v5_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (during the “cautious” phase) to a final steady-state level <inline-formula><inline-graphic xlink:href="574574v5_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (which we simplify as being <italic>g</italic><sup>cau</sup> = 0) at a transition point <italic>t</italic> = <italic>t</italic><sub>1</sub>. At the same timepoint, <italic>g</italic><sup>con</sup>(<italic>t</italic>) (second row) makes a transition from 0 to a peak level <inline-formula><inline-graphic xlink:href="574574v5_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> of confident approach (defining the “peak confident” phase). Finally, there is another transition at time <italic>t</italic><sub>2</sub> from peak to a steady-state confident approach time <inline-formula><inline-graphic xlink:href="574574v5_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (in the “steady-state confident” phase). The lower two rows of <xref rid="fig1" ref-type="fig">figure 1a</xref> show the duration of the bouts in the relevant phases, and the frequency per unit time of such bouts. The upper panel of <xref rid="fig1" ref-type="fig">fig 1b</xref> shows the same data in a more convenient manner. The colours in the top row indicate the type of approach (green is cautious; blue is confident). The second and third rows indicate the duration and frequency of approach. Darker colours represent higher values.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>a.) Detailed visualization of minute-to-minute statistics of animal 25 (in the sessions after the introduction of the novel object). From top to bottom, the plots show % time within (<xref ref-type="bibr" rid="c2">Akiti et al., 2022</xref>)’s 7cm threshold of the object with (cautious) and without (confident) tail behind, the length of a bout at the object and the number of bouts per minute. Orange lines are the box-car functions fitted to segment phases and illustrate the change in time, duration, and frequency statistics across phases. The transition points <italic>t</italic><sub>1</sub> and <italic>t</italic><sub>2</sub> as well as the initial cautious <inline-formula><inline-graphic xlink:href="574574v5_inline28.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,final cautious <inline-formula><inline-graphic xlink:href="574574v5_inline29.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,peak confident <inline-formula><inline-graphic xlink:href="574574v5_inline30.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and steady-state confident <inline-formula><inline-graphic xlink:href="574574v5_inline31.gif" mimetype="image" mime-subtype="gif"/></inline-formula> approach percentage times are shown. The right plots show examples of minute-to-minute and phase-averaged approach time, duration, and frequency for (b.) brave, (c.) intermediate, and (d.) timid animals. Note that animals are ordered by the group-timidity animal index (see main text Section 2.3.1). Green indicates cautious and blue indicates confident approach. Darker colors indicate higher values. For the purpose of modeling, we average the idiosyncracies of behavior over phases and thereby characterize a high-level summary of learning dynamics.</p></caption>
<graphic xlink:href="574574v5_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The orange coloured lines in <xref rid="fig1" ref-type="fig">Fig 1a</xref> and the lower panel in <xref rid="fig1" ref-type="fig">Fig 1b</xref> render the abstracted behaviour of this animal in an integrated form, showing how we generate “phase-level” statistics from minute-to-minute statistics. Averaging statistics over phases ignores idiosyncrasies of behavior and allows us to fit the high-level statistics of behavior: phase-transiton times, phase-averaged durations and frequencies. We consider animal 25 to be a “brave” animal because of its transition to peak and then steady-state confident approach. There were 12 brave mice out of the 26 in total.</p>
<p><xref rid="fig1" ref-type="fig">Fig 1c</xref> shows an example of another characteristic “intermediate” animal. This animal makes a transition from cautious to confident approach (where both duration and frequency of visits can change), but the approach time during the confident phase <inline-formula><inline-graphic xlink:href="574574v5_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> does not decrease. Hence, intermediate animals do not have a transition from peak to steady-state confident phase. There were 5 such intermediate mice.</p>
<p><xref rid="fig1" ref-type="fig">Fig 1d</xref> shows the behaviour of an example of the last class of “timid” animals. This animal never makes a transition to confident approach. Hence, for it, <italic>g</italic><sup>con</sup>(<italic>t</italic>) = 0. However, the cautious approach time makes a transition to a non-zero steady state <inline-formula><inline-graphic xlink:href="574574v5_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,often via a change in frequency, defining the fourth phase (“steady-state cautious”). There were 9 such timid mice.</p>
<p><xref rid="fig2" ref-type="fig">Fig 2</xref> summarizes our categorization of the animals into the three groups: brave, intermediate, and timid based on the phases identified in the animal’s exploratory trajectories. Timid animals spend no time in confident approach and are plotted in orange at the origin of <xref rid="fig2" ref-type="fig">Fig 2</xref>. Brave animals differ from intermediate animals in that their approach time during the first ten minutes of the confident phase is greater than the last ten minutes (steady-state phase). Brave animals are plotted in green above and intermediate animals are plotted in black below the <italic>y</italic> = 1 line in <xref rid="fig2" ref-type="fig">Fig 2</xref>.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Separating the three animal groups.</title>
<p>The <italic>x</italic>-axis shows the ratio of total time spent in confident versus cautious bouts. The <italic>y</italic>-axis shows the ratio of bout time in the first 10 minutes of confident approach and the last 10 minutes of confident approach (set to 0 for timid animals that do not have a confident phase). The horizontal line indicates <italic>y</italic> = 1.0. All 9 timid animals are close to the origin. We separate brave and intermediate animals according to the <italic>y</italic> = 1 line. Solid green dots are brave animals that pass the Benjamini–Hochberg procedure for <italic>y</italic> &gt; 1 at level <italic>q</italic> = 0.05 according to a random permutation test. Hollow dots represent brave animals that did not pass. We decided to model these animals as brave since they had <italic>y</italic> &gt; 1.5 and hence a relatively clear confident-peak to confident-steady-state transition point. Modelling them as intermediate animals instead would not have significantly affected our results. Black dots are intermediate animals. They did not pass the Benjamini-Hochberg procedure for either <italic>y</italic> &gt; 1 or <italic>y</italic> &lt; 1.</p></caption>
<graphic xlink:href="574574v5_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>A Bayes-adaptive Model-based Model for Exploration and Timidity</title>
<sec id="s2b1">
<label>2.2.1</label>
<title>State description</title>
<p>We use a model-based Bayes-adaptive reinforcement learning model (BAMDP) to provide a mechanistic account of the behavior of the mice under threat of predation. This extends the model-free description of threat in <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) by constructing various mechanisms to explain additional facets of the dynamics of the behavior.</p>
<p>Underlying the BAMDP is a standard multi-step decision-making problem of the sort that is the focus of a huge wealth of studies (<xref ref-type="bibr" rid="c64">Russell and Norvig, 2016</xref>). We cartoon the problem with the four real and four counterfactual states shown in <xref rid="fig3" ref-type="fig">Fig 3</xref>. The <italic>nest</italic> is a place of safety, (modelling all places in the environment away from the object, ignoring, for instance, the change to thigmotactic behaviour that the mice exhibit when the object is introduced. The animal can choose to stay at the nest (possibly for multiple steps) or choose to approach the object. For convenience, we adopt <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>)’s binary classification of approach, while acknowledging the substantial simplification this classification entails (a fuller but more complex characterization of approach would be continuous and multidimensional). We represent tail-behind (respectively tail-exposed) approach as transitioning to the cautious (respectively confident) object state.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Markov decision process underlying the BAMDP model.</title>
<p>Four real (nest, cautious object, confident object, retreat) and three imagined (cautious detect, confident detect, dead) states. Agent actions are italicized. Blue arrows indicate (possibly stochastic) transitions caused by agent actions. Green arrows indicate (possibly stochastic) forced transitions. Cautious approach provides less informational reward <italic>r</italic><sub>2</sub> &lt; <italic>r</italic><sub>1</sub> but has a smaller chance of death <italic>p</italic><sub>2</sub> &lt; <italic>p</italic><sub>1</sub> compared to confident approach. Travel and dying costs are not shown.</p></caption>
<graphic xlink:href="574574v5_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At an approach state, the modelled agent can either stay, or return to the nest via the retreat state; the latter happens anyhow after four steps. The animal also imagines the (in reality, counterfactual) possibility of being detected by a potential predator. It can then either manage to escape back to the nest, or alternatively expire. We parameterize costs associated with the various movements; and also the probability of unsuccessful escape starting from confident (<italic>p</italic><sub>1</sub>) or cautious (<italic>p</italic><sub>2</sub> &lt; <italic>p</italic><sub>1</sub>) approach.</p>
<p>We describe the dilemma between cautious and confident approach as a calculation of the risk and reward trade-off between the two types of approaches. Cautious approach (the “cautious object” state) has a lower (informational) reward (e.g. because in the cautious state the animal spends more cognitive effort monitoring for lurking predators rather than exploring the object). However, cautious approach leads to a lower probability of expiring if detected than does confident approach (the “cautious object” state) (e.g. because in the cautious state the animal is better poised to escape). Risk aversion modulates the agent’s choice of approach type.</p>
<p>The next sections describe the components of the BAMDP model: a characterization of the timedependent risk of predation, an informational reward for exploration, and a method for handling risk sensitivity. Finally, we will discuss the way we fitted individual mice, and present a full analysis of their behaviour. We report on recovery simulations in the supplement.</p>
</sec>
<sec id="s2b2">
<label>2.2.2</label>
<title>Modeling Threat with a Bayesian, Generalizing Hazard Function</title>
<p>Whilst exploring the novel object in the “object” state, the decision problem allows for the possibility of detection, and then attack, by a predator whose appearance is governed by a temporal hazard function (see <xref rid="fig4" ref-type="fig">Fig 4</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Hazard function learning for (a.) brave and (b.) timid animals.</title>
<p>Brave animals start with a flexible hazard prior with a low mean for <italic>h</italic><sub>2</sub>. This leads to longer bouts (first length 2, then 3 and 4), which imply that the hazard posterior quickly approaches zero (here, after 10 bouts). Timid animals start with an inflexible hazard prior with a higher mean <italic>h</italic><sub>2</sub>, and are limited to length 2 bouts. The hazard posterior only changes slightly after 10 bouts.</p></caption>
<graphic xlink:href="574574v5_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Formally, the probability of detection given either cautious or confident approach is modelled using the <italic>hazard</italic> function <italic>h</italic><sub><italic>τ</italic></sub>, where <italic>τ</italic> is the number of steps the animal has so far spent at the object in the current bout. In a key simplification, this probability resets back to baseline upon a return to the nest. We treat the hazard function as being learned in a Bayesian manner, from the experience (in this case, of not being detected). We assume that the animal has the inductive bias that the hazard function is increasing over time, reflecting a potential predator’s evidence accumulation process about the prey. Therefore, we derive it from a succession of independent Beta-distributed random variables <italic>θ</italic><sub>1</sub> = 0; <italic>θ</italic><sub><italic>τ</italic></sub> <italic>∼</italic> Beta(<italic>μ</italic><sub><italic>τ</italic></sub>, <italic>σ</italic><sub><italic>τ</italic></sub>), <italic>τ</italic> &gt; 1 as:
<disp-formula id="eqn1">
<graphic xlink:href="574574v5_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="574574v5_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
rather as in what is known as a stick-breaking process. Note that, for convenience, we parameterize the Beta distribution in terms of its mean <italic>μ</italic> and standard deviation <italic>σ</italic> rather than its pseudocounts, as is perhaps more common.</p>
<p><xref ref-type="disp-formula" rid="eqn2">Eq 2</xref> shows that the hazard function is always increasing. As we will see, the duration of bouts at the object depend on the (discrete) <italic>slope</italic> of the hazard function, with steep hazard functions leading to short bouts. In our model, the agent can stay at the object 2, 3 or 4 turns (we take <italic>θ</italic><sub>1</sub> = 0 as a way of coding actual approach; We therefore sometimes refer to cautious−<italic>k</italic> or confident−<italic>k</italic> bouts in which the model animal spends <italic>k</italic> = {2, 3, 4} steps at the object.). Hence the collection of random variables, <italic>h</italic><sub><italic>τ</italic></sub>, is derived from six parameters (the mean <italic>μ</italic><sub><italic>τ</italic></sub> and the standard deviation <italic>σ</italic><sub><italic>τ</italic></sub> of the Beta distribution for the turn). These start at initial prior values, and are subject to an update from experience. Here, that experience is exclusively negative, since there is no actual predator; this implies that the update has a simple, closed form (see Methods). The animals’ initial ignorance, which is mitigated by learning, makes the problem a BAMDP, whose solution is a risk-averse itinerant policy.</p>
<p>A particular characteristic of the noisy-or hazard function of <xref ref-type="disp-formula" rid="eqn1">Eq 1</xref> is that the derived bout duration increases progressively. This is because not being detected at <italic>τ</italic> = 2, say, provides information that <italic>θ</italic><sub>2</sub> is small, and so reduces the hazard function for longer bouts <italic>τ</italic> &gt; 2.</p>
<p><xref rid="fig4" ref-type="fig">Fig 4</xref> shows the fitted priors of a brave (top) and timid (bottom) animal, as well as the posteriors after ten exploratory bouts. The brave animal starts with a high variance prior. This flexibility allows it to transition from short, cautious bouts (duration <italic>τ</italic> = 2) to longer confident bouts (duration <italic>τ</italic> = 3, 4), reducing the hazard function to near zero. The timid animal has a low variance prior, and does not stay long enough at the object to build sufficient confidence (only performing duration <italic>τ</italic> = 2 bouts). As a result, its posterior hazard function remains similar to its prior.</p>
</sec>
<sec id="s2b3">
<label>2.2.3</label>
<title>Modeling the Motivation to Approach</title>
<p>We model the mouse’s drive to approach the object as stemming from its belief that the object might be rewarding. In a fully Bayesian treatment, the agent would maintain a posterior over the possibility of rewards and would enjoy a conventional, informational, Bayes-adaptive exploration bonus encouraging it to approach the object. However, this would add substantial computational complexity. Thus, instead, we use a simple, heuristic, exploration bonus <italic>G</italic>(<italic>t</italic>) (<xref ref-type="bibr" rid="c43">Kakade and Dayan, 2002</xref>). The model mouse moves from the “nest” state to the “object” state when this exploration bonus exceeds the costs implied by the risk of being attacked.</p>
<p>We characterize the exploration bonus as coming from an initial ‘pool’ <italic>G</italic><sub>0</sub> that becomes depleted when the animal is at the object, as it experiences a lack of reward, but is replenished at a steady rate <italic>f</italic> when the animal is at the nest, through forgetting or potential change. We model the animal as harvesting this exploration bonus pool more quickly under confident than cautious approaches, for instance since it can pay more attention to the object (an issue captured in more explicit detail in the context of foraging by <xref ref-type="bibr" rid="c46">Lloyd and Dayan (2018)</xref>). This underpins the transition between the two types of approach for non-timid animals. In simulations, when <italic>G</italic>(<italic>t</italic>) is high, the agent has a high motivation to explore the object, spending only a single turn in the nest state between bouts. In other words, the depletion from <italic>G</italic><sub>0</sub> substantially influences the time point at which approach makes a transition from peak to steady-state; the steady-state time then depends on the dynamics of depletion (when at the object) and replenishment (when at the nest). In particular, in the steady-state phases, the agent must wait multiple turns at the nest for <italic>G</italic>(<italic>t</italic>) to regenerate so that informational reward once again exceeds the potential cost of hazard.</p>
<p>Finally, the animal is also motivated to approach by instrumental informational reward arising from the hazard function (which can be exploited to collect more future reward) – according to a standard Bayes-adaptive bonus mechanism (<xref ref-type="bibr" rid="c24">Duff, 2002a</xref>).</p>
</sec>
<sec id="s2b4">
<label>2.2.4</label>
<title>Conditional Value at Risk Sensitivity</title>
<p>Along with varying degrees of pessimism in their prior over the hazard function, the mice could have different degrees of risk sensitivity in the aspect of the return that they seek to optimize. There are various ways in which the mice might be risk sensitive. Following <xref ref-type="bibr" rid="c31">Gagne and Dayan (2022)</xref>, we consider a form called nested conditional value at risk (nCVaR). In general, CVaR<sub><italic>α</italic></sub>, for risk sensitivity 0 ≤ <italic>α</italic> ≤ 1, measures the expected value in the lower <italic>α</italic> quantile of returns – thus over-weighting the worse outcomes. The lower <italic>α</italic>, the more extreme the risk-aversion; with <italic>α</italic> = 1 being associated with the conventional, risk-neutral, expected value of the return. Section 4.3 details the approximate optimization procedure concerned (<xref ref-type="bibr" rid="c17">Chow et al., 2015</xref>; <xref ref-type="bibr" rid="c39">Hau et al., 2023</xref>) – it operates by upweighting the probabilities of outcomes with low returns – which come here from detection and expiration. Thus, when <italic>α</italic> is low, confident and longer bouts are costly, inducing shorter, cautious ones. nCVaR<sub><italic>α</italic></sub> affects behavior in a similar manner to pessimistic hazard priors, except that nCVaR<sub><italic>α</italic></sub> acts on both the aleatoric uncertainty of expiring and epistemic uncertainty of detection, while priors only affect the latter. As we will see, despite this difference, we were not able to differentiate pessimistic priors from risk sensitivity using the data in (<xref ref-type="bibr" rid="c2">Akiti et al., 2022</xref>).</p>
</sec>
<sec id="s2b5">
<label>2.2.5</label>
<title>Model Fitting</title>
<p>The output of each simulation is a sequence of states which we use to derive summary statistics that can be compared directly with our abstraction of the behavior of a mouse (as in <xref rid="fig1" ref-type="fig">figure 1</xref>). This requires us to model transition points in this behavior, and the times involved in each state.</p>
<p>In the model, the transition point from cautious to confident approach happens when the agent first ventures a confident approach; this switch is rarely reversed. Peak to steady-state transition points occur when the model mouse decreases its frequency of bouts, which tends to happen abruptly in the model. We fit the transition points in mouse data by mapping the length of a step in the model to wall-clock time. As in the abstraction of the experimental data, we average the duration (number of turns at the object) and frequency statistics in each phase. We characterize the relative frequencies of the bouts across phase transitions. Frequency mainly governs the total time at or away from the object and is formally defined as the inverse of the number of steps the model spends at the object and the nest.</p>
<p>We use a form of Approximate Bayesian computation Sequential Monte Carlo (ABCSMC; <xref ref-type="bibr" rid="c69">Toni et al. (2009</xref>)) to fit the elements of our abstraction of the approach behaviour of the mice (section 2.1), namely change points, peak and steady-state durations as well as relative frequencies of bouts. See the Methods section 4.6 for details on the fitted statistics. At the core of ABCSMC is the ability to simulate the behaviour of model mice for given parameters. We do this by solving the underlying BAMDP problem approximately using receding horizon tree search with a maximum depth of 5 steps (which covers the longest allowable bout, defined as a subsequence of states where the model mouse goes from the nest to the object and back to the nest).</p>
<p>The full set of parameters includes 6 for the prior over the hazard function (given that we limit to four the number of time steps the model mouse can stay at the object), the risk sensitivity parameter <italic>α</italic> for CVaR<sub><italic>α</italic></sub>, the initial reward pool <italic>G</italic><sub>0</sub> and the forgetting rate <italic>f</italic>.</p>
</sec>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Explaining Exploration Schedules with Fitted Model Parameters</title>
<sec id="s2c1">
<label>2.3.1</label>
<title>A Spectrum of Risk-Sensitive Exploration Trajectories</title>
<p><xref rid="fig5" ref-type="fig">Fig 5</xref> shows model fits on the 26 mice from <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>). The animal ranking is sorted first by animal group, and second by total time spent near the object. We call this ranking the group-timidity animal index – it slightly differs from the timidity index used in <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) which is only based on total time spent near the object. The model captures many details of the data across the entire spectrum of courage to timidity, explaining the behavior mechanistically. Differing schedules of exploration emerge because of the battle between learning about threat and reward.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Summary of model fit.</title>
<p>Left panels: minute-to-minute time the animals spend within 7cm of the novel object (top), duration (middle), and frequency (bottom). There are 26 animals (one per row) sorted by the group-timidity animal index (see main text Section 2.3.1). Central panels: the same values averaged over behavioral phases. Right panels: time, duration and frequency of bouts generated as sample trajectories from the individual fits of the BAMDP model. Legend: green/blue distinguishes cautious and confident bouts. The intensity of colors indicates higher values, and gray indicates zeros.</p></caption>
<graphic xlink:href="574574v5_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>All animals initially assess risk with cautious approach, since the costs of potential predation significantly outweigh potential rewards. Brave animals assess risk either with short (length 2 bouts) or medium (length 3 bouts) depending on the hazard priors (<xref rid="fig6" ref-type="fig">Fig 6 a</xref>. and <xref rid="fig6" ref-type="fig">b</xref>. versus c. and d.). If <italic>E</italic>[<italic>h</italic><sub>3</sub>] is high, then the animal performs cautious length 2 bouts, otherwise, it performs cautious length 3 bouts. With more bout experience, the posterior hazard function becomes more optimistic (since there is no actual predator to observe; <xref rid="fig4" ref-type="fig">Fig 4</xref>), empowering it to take on more risk by staying even longer at the object and performing confident approach. Animals with low <italic>E</italic>[<italic>h</italic><sub>4</sub>] perform the longest, confident, length 4 bouts instead of length 3 bouts (<xref rid="fig6" ref-type="fig">Fig 6 a</xref>. and <xref rid="fig6" ref-type="fig">c</xref>. versus b. and d). How long brave animals spend assessing risk depends on hazard priors and the risk sensitivity: nCVaR’s <italic>α</italic>.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>The bout durations of brave animals depend on the hazard prior.</title>
<p>a.) Brave animals that initially perform cautious-2 bouts, then confident-3 bouts. The prior mean <italic>μ</italic><sub>3</sub> for <italic>τ</italic> = 3 is higher than in (c.) because there is some hazard to overcome before the animal does a duration-3 bout. Blue indicates individual animals and black indicates the mean. The y-axis <italic>E</italic>[<italic>μ</italic><sub><italic>τ</italic></sub>], shows <italic>μ</italic><sub><italic>τ</italic></sub> averaged over the ABCSMC posterior particles for each animal. b.) Cautious-2 then confident-4 animals. Since the mean <italic>μ</italic><sub>4</sub> prior is low, once the animal overcomes the <italic>τ</italic> = 2 hazard, it quickly transitions from duration 2 to 4. c.) Cautious-3, then confident-3 animals. These animals are fitted with a low <italic>μ</italic><sub>3</sub> prior and high <italic>μ</italic><sub>4</sub> prior because they never perform duration-4 bouts. d.) Cautious-3 then confident-4 animals. Since the <italic>μ</italic><sub>3</sub> prior is lower than in (b.), these animals begins with duration-3 bouts.</p></caption>
<graphic xlink:href="574574v5_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig7" ref-type="fig">Fig 7</xref> shows that the fitted hazard priors and risk sensitivity relate to the group-timidity animal index. Brave animals are fitted with higher <italic>α</italic> and a low slope and high variance (flexibility) hazard prior. In other words, the model brave mouse believes that the hazard probability for long bouts is low in its environment. Timid animals are fitted by lower <italic>α</italic> and a higher slope, inflexible hazard prior. The parameters for intermediate animals lie between those for brave and timid animals.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><p>a.) nCVaR’s <italic>α</italic> versus the group-timidity animal index ranking defined in Section 2.3.1. Color indicates the animal group. More timid animals are generally fitted by a lower <italic>α</italic>. Prior hazard parameter for t=2 (b.), t=3 (c.), and t=4 (d.) versus timidity ranking. Dots indicate the mean; the probability density is represented by color where darker means higher density regions. The t=2 prior <italic>mean</italic> is similar across all animals (timid = 0.28 ± 0.02, intermediate = 0.26 ± 0.04, brave = 0.22 ± 0.08) explaining the short, cautious bouts all animals initially use to assess risk. However, timid animals are best fit with lower variance (inflexible) and higher t=3 and t=4 prior means. This leads to shorter, cautious bouts in the long run. Brave animals are fitted by a low slope (indicated by lower mean for t=3 and t=4) and high variance (flexible) hazard prior. This allows them to perform longer bouts over time. t=4 mean is low (panel d) for brave animals that perform length 4 bouts. Like brave animals, most intermediate animals have flexible, gradual hazards up to t=3.</p></caption>
<graphic xlink:href="574574v5_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><italic>G</italic><sub>0</sub> determines how much time brave animals spend in the peak-confident exploration phase, or the peak to steady-state change point. Animals with larger <italic>G</italic><sub>0</sub> tend to have high bout frequencies for a longer period (see <xref rid="fig8" ref-type="fig">Fig 8</xref>). Finally, how often brave animals revisit the object, which is related to the relative steady-state frequency, is determined by the forgetting rate.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><p>a.) The relationship between <italic>G</italic><sub>0</sub> and the peak to steady-state change point for brave animals. The best fit line is shown in black. Higher <italic>G</italic><sub>0</sub> means the agent explores longer, hence postponing the change point. b.) <italic>G</italic><sub>0</sub> versus peak to steady-state change point for timid animals. c.) Forgetting rate versus steady-state turns at the nest state for brave animals. A higher forgetting rate leads to quicker replenishment of the exploration pool and hence fewer turns at the nest before approaching the object. d.) Forgetting rate versus turns at nest timid animal. All correlations are significant with <italic>p</italic> &lt; 0.002.</p></caption>
<graphic xlink:href="574574v5_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Timid animals have short bouts and continue to assess risk with cautious approach in the steady-state. <xref rid="fig7" ref-type="fig">Fig 7</xref> shows that their hazard priors are inflexible (low variance), with a high slope, and that they have low <italic>α</italic>. The priors are slow to update and risk sensitivity causes timid agents to overestimate the probability of bad outcomes, leading to their prolonged cautious behavior. Hence, the reward exploration pool is depleted (i.e. the agent transitions to the steady-state phase) before the agent overcomes its priors. This particular dynamic of approach-drive and hazard function updating leads to self-censoring and neophobia. In the steady-state phase, the agent stays long periods at the nest (how long depends again on the forgetting rate). As a result, the animal (at least during the course of the experiment) never accumulates sufficient evidence to learn the safety of the object or if the object yields rewards. Akiti et al’s experiment did not last long enough to answer the question of whether all animals, even the most timid ones, eventually perform confident approach. Our model predicts that they will since the agent only accumulates negative evidence for the hazard function. However, with sufficient low <italic>α</italic> or pessimistic priors, this may take a very long time.</p>
<p>Intermediate animals, like brave animals, eventually switch to confident approach to maximize information gained about potential rewards. Similar to brave animals, the cautious to confident transition tends to be later with lower <italic>α</italic> and steeper, less flexible priors. Intermediate animals perform both cautious and confident bouts with medium duration. This is captured by a hazard prior with smaller <italic>E</italic>[<italic>h</italic><sub>3</sub>] and larger <italic>E</italic>[<italic>h</italic><sub>4</sub>]. The percentage of time spent at the object is relatively constant throughout the experiment for intermediate animals. This can be explained by either large <italic>G</italic><sub>0</sub> or a high forgetting rate. In other words, the animal is either slow to update its belief about the potential reward at the object, or it expects the reward probability to change quickly.</p>
<p><xref rid="fig5" ref-type="fig">Fig 5</xref> also illustrates several limitations of the model. In particular, the duration of bouts can only increase, whereas a few animals exhibit decreasing bout duration between confident-peak and confident-steady-state phases. Furthermore, the model has trouble capturing abrupt changes in duration (from 2 turns to 4) coinciding with an animal’s transition from cautious to confident approach.</p>
</sec>
<sec id="s2c2">
<label>2.3.2</label>
<title>Risk Sensitivity versus Prior Belief Pessimism</title>
<p>We found that risk sensitivity and prior pessimism could not be teased apart in our model fits. This is illustrated in <xref rid="fig9" ref-type="fig">Fig 9</xref>. In the ABCSMC posterior distributions, nCVaR’s <italic>α</italic> is correlated with the mean</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><title>Non-identifiability of nCVaR’s <italic>α</italic> against the hazard prior.</title>
<p>Animals are labeled using the group-timidity animal index. a.) The scatter plot shows the t=2 prior mean (<italic>μ</italic><sub>2</sub>) versus <italic>α</italic> for ABCSMC particles of timid animal 1. The ellipse indicates one standard deviation in a Gaussian density model. Animal 1 (and timid animals generally) can be either fit with a higher <italic>α</italic> and a higher <italic>μ</italic><sub>2</sub>, or a lower <italic>α</italic> and a lower <italic>μ</italic><sub>2</sub>. The box-and-whisker plot illustrates the correlation between <italic>μ</italic><sub>2</sub> and <italic>α</italic> across all timid animals. b.) The scatter plot shows an example intermediate animal 10; the box-and-whisker plot shows <italic>μ</italic><sub>2</sub> versus <italic>α</italic> for the intermediate population. c.) The scatter plot shows an example animal 11 from the group containing cautious-2/confident-4 and cautious-2/confident-3 animals. This group of animals starts with duration= 2 bouts and hence must overcome the prior <italic>μ</italic><sub>3</sub>. The box-and-whisker plot shows <italic>μ</italic><sub>3</sub> versus <italic>α</italic> for the population. d.) The scatter plot shows an example animal 25 from the group containing cautious-2/confident-4 and cautious-3/confident-4 animals. This group of animals eventually performs duration= 4 bouts and hence must overcome the prior <italic>μ</italic><sub>4</sub>. The box-and-whisker plot shows <italic>μ</italic><sub>4</sub> versus <italic>α</italic> for the population. <italic>α</italic> and <italic>μ</italic> are correlated in the ABCSMC posterior for all animals and hence non-identifiable. <italic>p</italic> &lt; 0.05 for all correlations.</p></caption>
<graphic xlink:href="574574v5_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><italic>μ</italic><sub>2</sub> for timid and intermediate animals, <italic>μ</italic><sub>3</sub> for cautious-2/confident-4 and cautious-2/confident-3 animals, and <italic>μ</italic><sub>4</sub> for cautious-2/confident-4 and cautious-3/confident-4 animals. In other words, lower <italic>α</italic> (higher risk-sensitivity) can be traded off against lower (more optimistic) priors to explain the observed risk-aversion in animals.</p>
<p>In ablation studies (not shown), we found that it is possible to fit the full range of the behavior equally well with a risk-neutral nCVaR<sub>1.0</sub> objective, only varying the hazard priors (with their many extra parameters). There is a technical advantage of fitting both nCVaR<sub><italic>α</italic></sub> and hazard priors to each animal, namely greater diversity in the particles discovered by ABCSMC.</p>
<p>By contrast, we found that nCVaR<sub><italic>α</italic></sub> alone, with the same hazard prior for all animals, is incapable of fitting the full range of animal behavior (results not shown). This can be explained by the fact that nCVaR<sub><italic>α</italic></sub> cannot model the different slopes in the hazard function. For example, a cautious-2/confident-3 animal must be modeled using a high value of <italic>μ</italic><sub>4</sub>. Starting with the parameters for a cautious-2/confident-4 animal and decreasing <italic>α</italic> will not create a cautious-2/confident-3 animal. Instead, decreasing <italic>α</italic> will delay the cautious-to-confident transition of the cautious-2/confident-4 animal and eventually create a cautious-2 timid animal. Therefore, in our task, structured prior beliefs are required to model the detailed behavior of animals. It is not clear in general, in which environments one can expect <italic>α</italic> and priors to be identifiable given the complex interaction of these two sources of risk-sensitivity.</p>
</sec>
<sec id="s2c3">
<label>2.3.3</label>
<title>Familiar Object Novel Context</title>
<p>As a contrast to their main experiment, in which mice were exposed to an unfamiliar object in a novel context (UONC), <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) also looked at the consequences of exposing animals to a familiar object in a novel context (FONC), where the animals still habituate in the arena over two days but the combination of the object and arena is novel. We fit the behavior of the 9 FONC amimals, and, as the closest match compared this with that of the 11 brave amimals in the UONC condition. <xref rid="fig10" ref-type="fig">Figure 10</xref> shows that there are 1 intermediate and 8 brave FONC animals, with the latter having exploration schedules similar to the bravest UONC animals. The 8 FONC animals have confident-peak and confident-steady-state phases, meaning their approach decreases in the steady-state, suggesting that they are reinvestigating the <italic>familiar</italic> object for reward.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10.</label>
<caption><title>Comparing the behavior of FONC and UONC conditions.</title>
<p>There are 9 FONC and 11 UONC brave animals (one per row). Left panels: minute-to-minute time the animals spend within 7cm of the novel object (top), duration (middle), and frequency (bottom). Animals are again sorted by group-timidity animal index but split by experiment condition (UONC then FONC). Central panels: the same values averaged over behavioral phases. Right panels: time, duration and frequency of bouts generated as sample trajectories from the individual fits of the BAMDP model.</p></caption>
<graphic xlink:href="574574v5_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig11" ref-type="fig">Figure 11</xref> compares the posteriors of the ABCSMC fit of brave UONC and FONC animals. The x-axis shows the group-timidity animal index, but split by experiment condition (UONC then FONC). Compared to brave UONC animals, FONC animals are fitted with higher nCVaR’s <italic>α</italic> and lower hazard priors (average posterior parameters across animals are significantly different according to the Kolmogorov-Smirnov test, <italic>p</italic> &lt; 0.05). Both the hazard prior means and variances are lower for the FONC animals indicating these animals are more certain of the safety of the object compared to UONC animals. For 3 animals the hazard prior means are nearly zero, indicating belief of almost certain safety. This is similar to the hazard function of a brave UONC animal at the end of the experiment. For the other 6 FONC animals, the hazard prior is high enough to warrant initial cautious bouts suggesting that the novelty of the context has increased their beliefs of the threat level of the familiar object. However, even these animals transition faster to confident approach than the brave UONC animals. This can be seen in <xref rid="fig10" ref-type="fig">Figure 10</xref>. <xref rid="fig11" ref-type="fig">Figure 11b</xref> shows that FONC animals also have on average lower (<italic>p</italic> &lt; 0.05)) exploration pool than brave UONC animals. Taken together, these results show that pre-exposure to the object decreases both the animals’ beliefs about potential hazards but also their motivation to explore the object for reward.</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11.</label>
<caption><title>ABCSMC parameter fits of the 9 FONC and 11 UONC animals (with the latter replotted from figure 7 for convenience).</title>
<p>The x-axis shows group-timidity animal index but UONC and FONC animals are separated. a.) Average nCVaR’s <italic>α</italic> over posterior particles of each animal. Color indicates the animal group. Dashed lines indicate the average (across animals) values of each condition (UONC brave or FONC brave). <italic>p</italic>-values for the Kolmogorov-Smirnov test of condition differences are shown. <italic>p</italic> &lt; 0.05 and therefore the <italic>α</italic> values of brave FONC animals are significantly higher than those of brave UONC animals. b.) Exploration bonus pool, which is also significantly different between FONC and UONC animals. c.) Forgetting rate, which is not significantly different between the two conditions. Prior hazard parameter for t=2 (d.), t=3 (e.), and t=4 (f.). The probability density is represented by color where darker means higher density regions. Dots indicate the mean. Dashed lines indicate the average of <italic>mean</italic> values across animals while dotted lines indicate the average of <italic>standard deviation</italic> values across animals. <italic>p</italic>-values testing the difference between the two conditions’ means and standard deviations are shown on the right-hand-side and left-hand-side of the plots respectively. Brave FONC animals have both significantly lower hazard prior mean and standard deviation than brave UONC animals.</p></caption>
<graphic xlink:href="574574v5_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
</sec>
<sec id="s3">
<label>3.</label>
<title>Discussion</title>
<p>We combined a Bayes adaptive Markov decision process framework with beliefs about hazards, and a conditional value at risk objective to capture many facets of an abstraction of the substantially different risk-sensitive exploration of individual animals reported by <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>). In the model, behaviour reflects a battle between learning about potential threat and potential reward (neither of which actually exists). The substantial individual variability in the schedules of exploratory approach was explained by different risk sensitivities, forgetting rates, exploration bonuses and prior beliefs about an assumed hazard associated with a novel object. Neophilia arises from a form of optimism in the face of uncertainty, and neophobia from the hazard. Critically, the hazard function is generalizing (reducing the <italic>t</italic> = 2 hazard reduces the <italic>t</italic> = 4 hazard) and monotonic. The former property induces an increasing approach duration over time (<xref ref-type="bibr" rid="c6">Arsenian, 1943</xref>). Furthermore, the exploration bonus associated with the object regenerates, as if the subjects consider its affordance to be non-stationary (<xref ref-type="bibr" rid="c20">Dayan et al., 2000</xref>). This encourages even the most timid animals to continue revisiting it. Nevertheless, a main source of persistent timidity is a sort of path-dependent self-censoring (<xref ref-type="bibr" rid="c21">Dayan et al., 2020</xref>). That is, the agents could be so pessimistic about the object that they never visit it for long enough to overturn their negative beliefs. In our model, timid behavior can, in principle, arise from either excessive risk-sensitivity or overly pessimistic priors about the hazard function. Indeed, CVaR is a probability distortion-based risk measure which is calculated by boosting the probabilities associated with the worst possibilities. Such boosting has obvious parallels with the effect of increasing prior expectations about those worst possibilities – particularly if the consequence of the boosting is a path-dependent reluctance to gather the experience necessary to overwhelm the prior. Given their similar behavioral phenotypes in this task, we duly found that it was not possible to use the model to disentangle the extent to which priors versus values of <italic>α</italic> were responsible for the observed timidity/bravery. One key difference is that risk aversion continues to affect behaviour at the asymptote of learning; something that might be revealed by due choice of a series of environments. Certainly, according to the model, forced exposure (<xref ref-type="bibr" rid="c40">Huys et al., 2022</xref>) would hasten convergence to the true hazard function and the transition to confident approach.</p>
<p>Due to the complexity of the dataset, we made several rather substantial simplifying assump tions. First, the model employs a particular set of state abstractions, for instance representing thigmotaxis as a notional “nest” (<xref ref-type="bibr" rid="c66">Simon et al., 1994</xref>). Motivated by tail-behind versus tail-exposed in <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>), we model approach using a dichotomy between cautious and confident approach states. This is likely a crude approximation to the continuous and multifaceted nature of animal approach behavior. For example, during approach animals likely adjust their levels of vigilance continuously (or discretely; <xref ref-type="bibr" rid="c46">Lloyd and Dayan (2018)</xref>) to monitor threat, and choose different velocities for movement, and different attentional strategies for inspecting the novel object. We hope future works will model these additional behavioral complexities, perhaps with additional internal states, and corroborate these states with neurobiological data.</p>
<p>Second, the model only allows the frequency of approach, and not its duration, to decrease during the steady-state phase - some animals are better fit by decreasing duration. This limitation could be lifted in future models with, for example, a mechanism for boredom causing the animal to retreat when little potential reward remains at the object.</p>
<p>Third, the probability of being detected was the same between cautious and confident approaches, which may not be true in general. Note that the agent decides the type of approach before the bout, and is incapable of switching from cautious to confident mid-bout or vice versa.</p>
<p>Fourth, we modeled the relative amount of time the animal spends at the object versus elsewhere in the environment which depends on the differential risk in the two states. However, it is likely the animals avoid the novel object largely because of the object itself, rather than the potential danger associated with the arena since they spend much less time at the center of the arena during novelty than habituation days.</p>
<p>Finally, we restricted ourselves to a monotonic hazard function for the predator. It would be interesting to experiment with a non-monotonic hazard function instead, as would arise, for instance, if the agent believed that if the predator has not shown up after a long time, then there actually is no predator. Of course, a sophisticated predator would exploit the agent’s inductive bias about the hazard function – by waiting until the agent’s posterior distribution has settled. In more general terms, the hazard function is a first-order approximation to a complex game-theoretic battle between prey and predator, which could be modeled, for instance using an interactive IPOMDP (<xref ref-type="bibr" rid="c35">Gmytrasiewicz and Doshi, 2005</xref>). How the predator’s belief about the whereabouts of the prey diminishes could also be modeled game-theoretically, leading to partial hazard resetting rather than the simplified complete resetting in our model.</p>
<p>Our account is model-based, with the mice assumed to be learning the statistics of the environment and engaging in prospective planning (<xref ref-type="bibr" rid="c56">Mobbs et al., 2020</xref>). By contrast, <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) provide a model-free account of the same data. They suggest that the mice learn the values of threat using an analogue of temporal difference learning (<xref ref-type="bibr" rid="c68">Sutton, 1988</xref>), and explain individual variability as differences in value initialization (<xref ref-type="bibr" rid="c2">Akiti et al., 2022</xref>). The initial values are generalizations from previous experiences with similar objects, and are implemented by activity of dopamine in the tail of the striatum (TS) responding to stimuli salience (<xref ref-type="bibr" rid="c2">Akiti et al., 2022</xref>). By contrast, our model encompasses extra features of behavior such as bout duration, frequency, and type of approach – ultimately arriving at a different mechanistic explanation of neophobia. In the context of our model, TS dopamine could still respond to the physical salience of the novel object but might then affect choices by determining the potential cost of the encountered threat (a parameter we did not explore here) or perhaps the prior on the hazard function. An analogous mechanism may set the exploration pool or the prior belief about reward perhaps involving projections from other dopamine neurons, which have been implicated in novelty in the context of exploration bonuses (<xref ref-type="bibr" rid="c43">Kakade and Dayan, 2002</xref>) and information-seeking for reward (<xref ref-type="bibr" rid="c57">Ogasawara et al., 2022</xref>; <xref ref-type="bibr" rid="c13">Bromberg-Martin and Hikosaka, 2009</xref>).</p>
<p>CVaR is known to come in different flavors in the case of temporally-extended behavior. <xref ref-type="bibr" rid="c32">Gagne and Dayan (2021)</xref> introduces two alternative time-consistent formulations of CVaR: nested CVaR (nCVaR) and precommitted CVaR (pCVaR). nCVaR and pCVaR both enjoy Bellman equations which make it possible to compute approximately optimal policies without directly computing whole distributions of the outcomes. We use nCVaR in this study for its computational efficiency. There is, of course, great current interest in distributional reinforcement learning (<xref ref-type="bibr" rid="c9">Bellemare et al., 2023b</xref>) which does acquire such whole distributions, not the least because of prominent observations linking non-linearities in the response functions of dopamine neurons to methods for learning distributions of outcomes (<xref ref-type="bibr" rid="c19">Dabney et al., 2020</xref>; <xref ref-type="bibr" rid="c50">Masset et al., 2023</xref>; <xref ref-type="bibr" rid="c67">Sousa et al., 2023</xref>). One functional motivation for considering entire outcome distributions is the possibility of using them to determine risk-sensitive policies (<xref ref-type="bibr" rid="c32">Gagne and Dayan, 2021</xref>). While it is possible to compute CVaR directly from return distributions, <xref ref-type="bibr" rid="c32">Gagne and Dayan (2021)</xref> showed that this can lead to temporally inconsistent policies where the agent deviates from its original plans (the authors called this the fixed CVaR or fCVaR measure).</p>
<p>Rather further removed from our model-based methods is work from <xref ref-type="bibr" rid="c5">Antonov and Dayan (2023)</xref>, who consider a model-free exploration strategy which exploits full return distributions to compute the value of perfect information which is used as a heuristic for trying actions with uncertain consequences. Future works can examine risk-sensitive versions of <xref ref-type="bibr" rid="c5">Antonov and Dayan (2023)</xref>’s computationally efficient model-free algorithm as one solution to the burdensome computations in our model-based method.</p>
<p>As reported in <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>), animals in the FONC condition in which the object is familiar (though the context is less so) transition quickly to tail-exposed approach and therefore spend more time near the object compared to animals in the UONC condition. <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) models the FONC animals using low initial mean threat and high initial threat uncertainty. We directly compare the behavior of FONC animals against that of the 11 brave UONC animals, showing that FONC animals make choices that are comparable to the bravest UONC animals. FONC behavior is fit by significantly higher nCVaR’s <italic>α</italic> than brave UONC behavior animals. This is surprising if we interpret <italic>α</italic> as a trait that is stable through time. Unfortunately, due to the non-identifiability between <italic>α</italic> and hazard priors, we cannot verify whether <italic>α</italic> is actually higher for FONC animals than UONC animals. FONC animals are also characterized by both lower hazard prior means and standard deviations compared to UONC animals, implying greater certainty about the object’s safety. Furthermore, FONC behavior is fitted with lower exploration pools than brave UONC behavior. Taken together, we can understand the FONC animals as having both lower uncertainty about hazard and reward compared to the brave UONC animals at the start of the experiment. However, the hazard and reward uncertainties are higher than what we might expect of UONC animals at the end of the experiment, suggesting the novel context modulates both of these uncertainties. However, heterogeneity exists between FONC individuals in terms of nCVaR’s <italic>α</italic>, hazard priors, and exploration pool which allows another possibility: that both hazard and reward uncertainty are restored by forgetting during the time that passed between pre-exposure and the experiment.</p>
<p>Our model-based account recovers several behavioral phenotypes in addition to those considered in <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>). First, intermittency in our model emerges from the fact that the (possibly CVaR perturbed) hazard function increases with time spent at the object. Therefore, it is rational for the model mice to retreat to the nest when the probability of detection becomes too high and wait until (they believe) the “predator has forgotten about them”, before venturing to the object again.</p>
<p>Second, we offer an alternative explanation for why animals avoid after risk-assessment in a benign environment. In Akiti’s model, timid animals perform risk-assessment because of the delay in model-free value updating from the initial threat at the object (at timestep <italic>t</italic> = 10 in their account) to the time of decision (<italic>t</italic> = 8). In our model, avoidance arises from a rational trade-off between potential risk and reward: timid animals perform risk-assessment because of the potential reward at the object and having found none, cease to approach because, although potential threat is lower than at the outset, it still outweighs the even further-reduced potential reward. The same exhaustion of the exploration bonus explains why the brave animals decrease their approach during the steady-state of engagement. If the potential reward is low, there is no reason to return to the object at the initial, high rate of engagement.</p>
<p>Third, the temporally evolving battle between reward and threat also explains why brave animals increase their duration of approach when transitioning from risk-assessment to engagement.</p>
<p>During confident approach, the animals harvest the exploration pool faster, at the cost of an increased probability of expiring. For brave animals, the hazard posterior decreases faster than the depletion of the exploration pool, and hence brave animals decide to save on travel costs by exploring the object longer in each bout.</p>
<p>Fourth, timid animals return to the object in the steady-state of “avoidance”, albeit at a lower rate than during risk-assessment. This was not considered in <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>)’s account. In our model, timid animals’ steady-state approach is explained by the regenerating exploration pool. Such regeneration is natural if the animals assume that the environment is non-stationary, allowing reward structures to change and thus potentially repaying occasional returns to the object if the potential threat has become sufficiently low. Similarly, the animal may believe that threat is non-stationary. Threat forgetting may act on longer time-scales than reward forgetting in our studied environment, and is one possible explanation for the initial non-zero hazard functions of some brave animals in the FONC condition.</p>
<p>Finally, our model shows the multi-faceted nature of timidity during exploration. Not only do animals differ in <italic>time spent near the object</italic> but also in how quickly they transition from cautious to confident approach, and their duration and frequency of approach along their exploration schedules. These proxies for timidity are imperfectly correlated. Indeed, an animal could believe that short bouts (<italic>τ</italic> = 2) are very safe while long bouts (<italic>τ</italic> = 4) certainly lead to expiration.</p>
<p>Of course, agents do not need to be fully model-free or model-based. They can truncate model-based planning using model-free values at leaf nodes (<xref ref-type="bibr" rid="c45">Keramati et al., 2016</xref>). Furthermore, replay-like prioritized model-based updates can update a model-free policy when environmental contingencies change (<xref ref-type="bibr" rid="c5">Antonov and Dayan, 2023</xref>). Finally, while online BAMDP planning can be computationally expensive, a model-based agent may simply amortize planning into a model-free policy which it can reuse in similar environments or even precompile model-based strategies into an efficient model-free policy using meta-learning (<xref ref-type="bibr" rid="c70">Wang et al., 2017</xref>). Agents may have faced many different exploration environments with differing reward and threat trade-offs through their lifetimes and even over evolution that they have used to create fast, instinctive model-free policies that resemble prospective, model-based behavior (<xref ref-type="bibr" rid="c65">Rusu et al., 2016</xref>; <xref ref-type="bibr" rid="c52">Mattar and Daw, 2018</xref>). In turn, TS dopamine might reflect aspects of MF values or prediction errors that had been trained by a MB system following the precepts we outlined.</p>
<p>In <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>), ablating TS-projecting dopamine neurons made mice “braver”. They spent more time near the object, performed more tail-exposed approach and transitioned faster to tail-exposed approach compared to control. In <xref ref-type="bibr" rid="c54">Menegas et al. (2018</xref>) TS ablation affected the learning dynamics for actual, rather than predicted threat. Both ablated and control animals initially demonstrated retreat responses towards airpuffs but only control mice maintained this response (<xref ref-type="bibr" rid="c54">Menegas et al., 2018</xref>). After airpuff punishment, ablated individuals surprisingly did not decrease their choices of water ports associated with airpuffs (while controls did). One possibility is that this additional exposure could have caused acclimatization to the airpuffs in the same way that brave animals in our study acclimatize to the novel object by approaching more, and timid animals fail to acclimatize because of self-censoring. Indeed, future experiments might investigate why punishment-avoidance does not occur in ablated animals and whether the same holds in risk-sensitive exploration settings (<xref ref-type="bibr" rid="c54">Menegas et al., 2018</xref>). In other words, would mice decrease approach after reaching the “detected” state, as expected by our model, or would they maladaptively continue the same rate of approach? Finally, while our study has focused on threat, <xref ref-type="bibr" rid="c55">Menegas et al. (2017</xref>) showed that TS also responds to novelty and salience in the context of rewards and neutral stimuli. That TS ablated animals spend more, rather than less time near the novel object suggests that the link from novelty to neophilia and exploration bonuses might not be mediated by this structure.</p>
<p>The behaviour of the mice in <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) somewhat resembles attachment behaviour in toddlers (<xref ref-type="bibr" rid="c1">Ainsworth, 1964</xref>; <xref ref-type="bibr" rid="c12">Bowlby, 1955</xref>), albeit with the care-giver’s trusty leg (a secure base from which to explore) replaced by thigmotaxis (or, in our case, the notional ‘nest’). Characteristic to this behaviour is an intermittent exploration strategy, with babies venturing away from the leg for a period before retreating back to its safety. Through the time course of exposure to a novel environment, toddlers progressively venture out longer and farther away, spending more time actively playing with the toys rather than passively observing them in hesitation (<xref ref-type="bibr" rid="c6">Arsenian, 1943</xref>). This is another example of a dynamic exploratory strategy, putatively arising again from differential updates to beliefs about threats and the rewards in the environment (<xref ref-type="bibr" rid="c6">Arsenian, 1943</xref>; <xref ref-type="bibr" rid="c1">Ainsworth, 1964</xref>).</p>
<p>Our data show that there is substantial variation in the degrees of risk sensitivity across the mice. Previous works have reported substantial interpopulation and intrapopulation differences in risk-sensitivity in humans which depend on gender, age, socioeconomic status, personality characteristics, wealth and culture (<xref ref-type="bibr" rid="c62">Rieger et al., 2015</xref>; <xref ref-type="bibr" rid="c30">Frey et al., 2017</xref>). Despite the normative appeal of <italic>α</italic> = 1, it is possible that a population may benefit from including individuals with <italic>α</italic> different from 1.0 or highly negative priors. For example, more cautious individuals could learn from merely observing the risky behavior of less cautious individuals. Furthermore, we have only considered risk-sensitivity under epistemic uncertainty in our work. Risk averse individuals, for instance with <italic>α</italic> &lt; 1 may be more successful than risk-neutral agents in environments where there are unexpected dangers (unknown unknowns). Risk-aversion is thus a temperament of ecological and evolutionary significance (<xref ref-type="bibr" rid="c61">Réale et al., 2007</xref>).</p>
<p>Consistent with this, variability in timidity during exploration has been reported in other animal species and can be caused by differences in both prior experience and genotype. Fish from predator-dense environments tend to make more inspection approaches but stay further away, avoid dangerous areas (attack-cone avoidance) and approach in larger shoals compared to fish from predator-sparse environments (<xref ref-type="bibr" rid="c48">Magurran and Seghers, 1990</xref>; <xref ref-type="bibr" rid="c26">Dugatkin, 1988</xref>; <xref ref-type="bibr" rid="c47">Magurran, 1986</xref>). <xref ref-type="bibr" rid="c26">Dugatkin, 1988</xref> and <xref ref-type="bibr" rid="c47">Magurran, 1986</xref> report significant within-population differences in the inspection behavior of guppies and minnows respectively. <xref ref-type="bibr" rid="c14">Brown and Dreier (2002)</xref> directly manipulates the predator experience of glowlight tetras, leading to changes to inspection behavior. Similar inter- and intra-population differences in timidity have been reported in mammals. In <xref ref-type="bibr" rid="c18">Coss and Biardi (1997)</xref>, the squirrel population sympatric with the tested predators stayed further away and spent less time facing the predator compared to the allopatric population. Furthermore, the number of inspection bouts differed between litters, between individuals within the same litter, and even between the same individuals at different times during development (<xref ref-type="bibr" rid="c18">Coss and Biardi, 1997</xref>). In <xref ref-type="bibr" rid="c44">Kemp and Kaplan (2011)</xref>, marmosets differed in risk-aversion when inspecting a potential (taxidermic) predator but risk-aversion was not stable across contexts for some individuals. <xref ref-type="bibr" rid="c29">FitzGibbon (1994)</xref> reports age differences in inspection behavior - adolescent gazelles inspected cheetahs more than adults or half-growns. Finally, <xref ref-type="bibr" rid="c53">Mazza et al. (2019</xref>); <xref ref-type="bibr" rid="c27">Eccard et al. (2020</xref>) report substantial individual differences in the foraging behavior of voles in risky environments and <xref ref-type="bibr" rid="c46">Lloyd and Dayan (2018)</xref> provide a somewhat general model of foraging under risk.</p>
<p>Inter-individual differences in risk sensitivity are also of critical importance in psychiatry, reflected in a panoply of anxiety disorders (<xref ref-type="bibr" rid="c15">Butler and Mathews, 1983</xref>; <xref ref-type="bibr" rid="c33">Giorgetta et al., 2012</xref>; <xref ref-type="bibr" rid="c49">Maner et al., 2007</xref>; <xref ref-type="bibr" rid="c16">Charpentier et al., 2017</xref>), along with worry and rumination (<xref ref-type="bibr" rid="c31">Gagne and Dayan, 2022</xref>). Understanding the spectrum of extreme priors and extreme values of <italic>α</italic> could have therapeutic implications, adding significance to the search for tasks that can more cleanly separate them.</p>
<p>In conclusion, our model shows that risk-sensitive, normative, reinforcement learning can account for individual variability in exploratory schedules of animals, providing a crisp account of the competition between neophilia and neophobia that characterizes many interactions with an incompletely known world.</p>
</sec>
<sec id="s4">
<label>4</label>
<title>Materials and methods</title>
<sec id="s4a">
<label>4.1</label>
<title>Code availability</title>
<p>The analysis code used in this study is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/shenkev/Risking-your-Tail-Modeling-Individual-Differences-in-Risk-sensitive-Exploration">https://github.com/shenkev/Risking-your-Tail-Modeling-Individual-Differences-in-Risk-sensitive-Exploration</ext-link>.</p>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>BAMDP Hyperstate</title>
<p>A Bayes-Adaptive Markov Decision Process (BAMDP; <xref ref-type="bibr" rid="c25">Duff, 2002b</xref>; <xref ref-type="bibr" rid="c38">Guez et al., 2013</xref>) is an extension of model-based MDP and a special case of a Partially Observable Markov Decision Process (POMDP; <xref ref-type="bibr" rid="c42">Kaelbling et al., 1998</xref>) in which the agent models its uncertainty about the (unchanging) transition dynamics. In a BAMDP, the agent extends its state representation into a hyperstate consisting of the original MDP state <italic>s</italic>, and the belief over the transition dynamics <italic>b</italic>(<italic>T</italic>).</p>
<p>In our model <italic>s</italic> is the conjunction of the “physical state” (the location of the agent, as shown in <xref rid="fig3" ref-type="fig">Fig 3</xref>) and the number of turns the agent has spent at the object so far <italic>τ</italic>. In the general case, <italic>T</italic> is a |<italic>S</italic>| × |<italic>A</italic>| × |<italic>S</italic>| tensor where each element is <italic>p</italic>(<italic>s, a, s</italic><sup>′</sup>) and |<italic>S</italic>| and |<italic>A</italic>| are the number of states and actions respectively. Therefore, <italic>b</italic>(<italic>T</italic>) is a probability distribution over (possibly infinite) transition tensors. In our model, all transition probabilities are assumed fixed except for the hazard function probabilities. Therefore, a belief over transition tensors <italic>b</italic>(<italic>T</italic>) is a belief over hazard functions <italic>b</italic>(<italic>h</italic>). We use a noisy-or hazard function parameterized by a vector of Beta distribution <inline-formula><inline-graphic xlink:href="574574v5_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.In totality, the belief over transition tensors <italic>b</italic>(<italic>T</italic>) is a belief over parameter vectors <inline-formula><inline-graphic xlink:href="574574v5_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.
<disp-formula id="eqn3">
<graphic xlink:href="574574v5_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
However, to maintain generality in the next section, we derive the Bellman updates using the notation <italic>b</italic>(<italic>T</italic>).</p>
<p>Our hyperstate additionally contains the nCVaR static risk preference <inline-formula><inline-graphic xlink:href="574574v5_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and the parameters of the heuristic exploration bonus <inline-formula><inline-graphic xlink:href="574574v5_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (see Section 4.5).</p>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Bellman Updates for BAMDP nCVaR</title>
<p>As for a conventional MDP, the nCVaR objective for a BAMDP can be solved using Bellman updates. We use <xref ref-type="disp-formula" rid="eqn4">Eq 4</xref> which assumes a deterministic, state-dependent, reward.
<disp-formula id="eqn4">
<graphic xlink:href="574574v5_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<italic>s</italic><sup>′</sup> is the next state and <italic>b</italic><sup>′</sup>(<italic>T</italic>) is the posterior belief over transition dynamics after observing the <inline-formula><inline-graphic xlink:href="574574v5_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the expected transition probability.
<disp-formula id="eqn5">
<graphic xlink:href="574574v5_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Proof of <xref ref-type="disp-formula" rid="eqn4">Eq 4</xref>.
<disp-formula id="ueqn1">
<graphic xlink:href="574574v5_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="574574v5_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the risk envelope for CVaR (<xref ref-type="bibr" rid="c17">Chow et al., 2015</xref>). But <inline-formula><inline-graphic xlink:href="574574v5_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is only non-zero when <inline-formula><inline-graphic xlink:href="574574v5_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.
<disp-formula id="ueqn2">
<graphic xlink:href="574574v5_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Hence we can drop the independent integration over <inline-formula><inline-graphic xlink:href="574574v5_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,and only integrate over <italic>s</italic><sup>′</sup>.
<disp-formula id="ueqn3">
<graphic xlink:href="574574v5_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Epistemic uncertainty about the transitions only generates risk in as much as it affects the probabilities of realizable transitions in the environment.</p>
</sec>
<sec id="s4d">
<label>4.4</label>
<title>Noisy-Or Hazard Function</title>
<p>
<disp-formula id="eqn6">
<graphic xlink:href="574574v5_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In our model, the hazard function defines a binary detection event <italic>X</italic><sub><italic>τ</italic></sub> for each number of turns the agent spends at the object <italic>τ</italic> = 2, 3, 4. The predator detects the agent when <italic>X</italic><sub><italic>τ</italic></sub> = 1. We use a noisy-or hazard function which defines <italic>X</italic><sub><italic>τ</italic></sub> as the union of Bernoulli random variables <italic>Z</italic><sub><italic>j</italic></sub> <italic>∼</italic> Bernoulli(<italic>θ</italic><sub><italic>j</italic></sub>) (<xref ref-type="disp-formula" rid="eqn6">Eq 6</xref>) with priors <italic>θ</italic><sub><italic>j</italic></sub> <italic>∼</italic> Beta(<italic>μ</italic><sub><italic>j</italic></sub>, <italic>σ</italic><sub><italic>j</italic></sub>) for <italic>j</italic> = 2, 3, 4. <xref rid="fig12" ref-type="fig">Fig 12</xref> shows the relationships between the random variables in plate notation.</p>
<fig id="fig12" position="float" fig-type="figure">
<label>Figure 12.</label>
<caption><title>Bayes-net showing the relationship between the random variables in the noisy-or model.</title>
<p>Only <italic>x</italic><sub><italic>τ</italic></sub> is shown. <italic>x</italic><sub><italic>τ</italic>+1</sub> depends on <italic>z</italic><sub><italic>t</italic>=1:<italic>τ</italic>+1</sub>, and so on.</p></caption>
<graphic xlink:href="574574v5_fig12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Posterior inference for the noisy-or model is intractable in the general case (<xref ref-type="bibr" rid="c41">Jaakkola and Jordan, 1999</xref>). However, there is a closed-form solution for the posterior when the agent only makes <italic>negative</italic> observations, meaning <inline-formula><inline-graphic xlink:href="574574v5_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (in our case, since there is no actual predator). For example, given a single observation <italic>x</italic><sub><italic>τ</italic></sub> = 0,
<disp-formula id="ueqn4">
<graphic xlink:href="574574v5_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here we switch back to the pseudocount parameterization of the Beta distribution Beta(<italic>θ</italic>; <italic>a, b</italic>) to exploit its conjugacy.
<disp-formula id="eqn7">
<graphic xlink:href="574574v5_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Hence the posterior update simply increments the Beta pseudocounts for the ‘0’ outcomes. The hazard probability is the posterior predictive distribution <italic>h</italic>(<italic>τ</italic>) = <italic>p</italic>(<italic>x</italic><sub><italic>τ</italic></sub> = 1| <italic>D</italic>) where <italic>D</italic> are a set of observations of <italic>X</italic><sub>1</sub>, <italic>X</italic><sub>2</sub>, … <italic>X</italic><sub><italic>τ</italic></sub>.
<disp-formula id="eqn8">
<graphic xlink:href="574574v5_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Where <italic>μ</italic><sub><italic>j</italic></sub> = 𝔼[<italic>θ</italic><sub><italic>j</italic></sub>] is the expected value of the posterior on <italic>θ</italic><sub><italic>j</italic></sub>.</p>
<p>Proof of <xref ref-type="disp-formula" rid="eqn8">Eq 8</xref>.
<disp-formula id="ueqn5">
<graphic xlink:href="574574v5_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="574574v5_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula> are the pseudocounts of negative observations after updating the Beta prior with <italic>D</italic> using <xref ref-type="disp-formula" rid="eqn7">Eq 7</xref>. It can be shown that <italic>h</italic>(<italic>τ</italic>) is recursive.
<disp-formula id="eqn9">
<graphic xlink:href="574574v5_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This recursion has two implications. First, the hazard function is monotonic since (1−<italic>h</italic>(<italic>τ</italic>−1)) &gt; 0 and <italic>μ</italic><sub><italic>τ</italic></sub> &gt; 0. Second, the hazard function generalizes. From <xref ref-type="disp-formula" rid="eqn9">Eq 9</xref> it is clear if <italic>h</italic>(<italic>τ</italic> − 1) increases, then <italic>h</italic>(<italic>τ</italic>) increases. It is this generalization that allows the agent to progressively spend more turns at the object.</p>
<sec id="s4d1">
<label>4.4.1</label>
<title>Transforming <italic>μ, σ</italic> to Pseudocount Parameterization of Beta Distribution</title>
<p>We use the mean <italic>μ</italic> and variance <italic>v</italic> = <italic>σ</italic><sup>2</sup> parameterization of the Beta distribution to get a more uniform sampling of the prior parameter space for ABCSMC fitting. We sample <italic>μ</italic> and <italic>σ</italic> from uniform distributions. However, it is more convenient to work with pseudocounts for computing the hazard posterior. Therefore, we transform <italic>μ</italic> and <italic>σ</italic> to pseudocounts <italic>a, b</italic> using the identities below. Note that <italic>v</italic> must be less than <italic>μ</italic> − <italic>μ</italic><sup>2</sup> to avoid negative values of <italic>a, b</italic>.
<disp-formula id="eqn10">
<graphic xlink:href="574574v5_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn11">
<graphic xlink:href="574574v5_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn12">
<graphic xlink:href="574574v5_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn13">
<graphic xlink:href="574574v5_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s4e">
<label>4.5</label>
<title>Heuristic Exploration Bonus Pool</title>
<p>The heuristic reward function approximates the sort of exploration bonus (<xref ref-type="bibr" rid="c34">Gittins, 1979</xref>) that would arise from uncertainty about potential exploitable benefits of the object. It incentivizes approach and engagement. In the experiment, there is no actual reward so the motivation is purely intrinsic (<xref ref-type="bibr" rid="c58">Oudeyer and Kaplan, 2007</xref>). The exploration bonus depletes as the agent learns about the object; but regenerates if the agent believes that the object can change over time (or, equivalently, if the agent forgets what it has learnt). This regenerating uncertainty can be modeled normatively using POMDPs but is only approximated here. Since we imagine the agent as finding more out about the object through confident than cautious approach, the former generates a greater bonus per step, but also depletes it more quickly.</p>
<p>We model the exploration-based reward as an exponentially decreasing resource. <italic>G</italic>(<italic>t</italic>) is the “exploration bonus pool” and can be interpreted as the agent’s remaining motivation to explore in the future. We fit the size of the initial exploration pool <italic>G</italic>(0) = <italic>G</italic><sub>0</sub> to the behavior of each animal. During planning, the agent imagines receiving rewards at the cautious and confident object states proportional to <italic>G</italic>(<italic>t</italic>).
<disp-formula id="eqn14">
<graphic xlink:href="574574v5_eqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn15">
<graphic xlink:href="574574v5_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn16">
<graphic xlink:href="574574v5_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
On every turn at the cautious or confident object states, the agent <italic>extracts</italic> reward <inline-formula><inline-graphic xlink:href="574574v5_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> or <inline-formula><inline-graphic xlink:href="574574v5_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula> from its budget <italic>G</italic>, depleting <italic>G</italic> at rates <italic>ω</italic><sub>cautious</sub> or <italic>ω</italic><sub>confident</sub>. This leads to an exponential decrease in <italic>G</italic>(<italic>t</italic>) with turns spent at the object which is clear from <xref ref-type="disp-formula" rid="eqn17">Eq 17</xref>. For example, at the cautious object state the update to <italic>G</italic>(<italic>t</italic>) is,
<disp-formula id="eqn17">
<graphic xlink:href="574574v5_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
However, a secondary factor affects the update to <italic>G</italic>(<italic>t</italic>). <italic>G</italic> linearly regenerates back to <italic>G</italic><sub>0</sub> at the forgetting rate <italic>f</italic> which we also fit for each animal. The full update to the reward pool for spending one turn at the cautious object state is,
<disp-formula id="eqn18">
<graphic xlink:href="574574v5_eqn18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Note that <italic>G</italic>(<italic>t</italic>) regenerates by <italic>f</italic> in all states, not only at the object states. We use linear forgetting for its simplicity although other mechanisms such as exponential forgetting are possible.</p>
<p>Finally, for completeness in other environments, the reward the agent imagines receiving also depends on the actual reward it has received in the past. Let <italic>n</italic><sup>1</sup> and <italic>n</italic><sup>0</sup> be the number of times the agent has received one or zero reward at the object state, analogous to the pseudocounts of a Beta posterior in a fully Bayesian treatment of reward. Furthermore, let <inline-formula><inline-graphic xlink:href="574574v5_inline19a.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="574574v5_inline19b.gif" mimetype="image" mime-subtype="gif"/></inline-formula> be the (fitted) values at <italic>t</italic> = 0. We use <inline-formula><inline-graphic xlink:href="574574v5_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="574574v5_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.The agent imagines receiving reward
<disp-formula id="eqn19">
<graphic xlink:href="574574v5_eqn19.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
after spending one turn in the cautious object state. A similar equation applies to the confident object state.</p>
<p>We define the depletion rates as <inline-formula><inline-graphic xlink:href="574574v5_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <italic>ω</italic><sub>cautious</sub> = <italic>K · ω</italic><sub>confident</sub> with constants <italic>R</italic> = 1.1 and <italic>K</italic> = 0.89 &lt; 1.0. These values were fitted to capture the full range of behavior of the 26 animals.</p>
</sec>
<sec id="s4f">
<label>4.6</label>
<title>Data Fitting</title>
<p>Data fitting aims to elucidate individual differences and population patterns in behavior by searching for the model parameters that best describe the behavior of each animal. We map the behavior of model and animals to a shared abstract space using a common set of statistics and then fit the model to data using ABCSMC.</p>
<sec id="s4f1">
<label>4.6.1</label>
<title>Animal Statistics</title>
<p>To extract animal statistics, we first coarse-grain behavior into phases and subsequently classify the animals into three groups: brave, intermediate, and timid (as described in the main text). This allows us to maintain the temporal dynamics of the behavior while reducing the dimension of the data. We average the approach type, duration, and frequency over each phase and fit a subset of statistics that capture the high-level temporal dynamics of behavior of animals in each group.</p>
<p>The behavior of brave animals comes in three phases: cautious, confident-peak and confident-steady-state. We fit five statistics: the transition time from cautious to confident-peak phase <italic>t</italic><sup>cautious-to-confident</sup>, the transition time from confident-peak to confident-steady-state phase <italic>t</italic><sup>peak-to-steady</sup>, the average durations during the cautious and confident-peak phases <italic>d</italic><sup>cautious</sup>, <italic>d</italic><sup>peak-confident</sup>, and the ratio of confident-peak and confident-steady-state phases’ frequencies <inline-formula><inline-graphic xlink:href="574574v5_inline23.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>Intermediate animals only exhibit two phases: cautious and confident. We fit four statistics: the transition time from cautious to confident phase <italic>t</italic><sup>cautious-to-confident</sup>, the durations of the two phases <italic>d</italic><sup>cautious</sup>, <italic>d</italic><sup>confident</sup>, and the ratio of the cautious and confident phases frequencies <inline-formula><inline-graphic xlink:href="574574v5_inline24.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.However, one limitation of the model is that frequency can only decrease, not increase, because of the dynamics of depletion and replenishment of the exploration bonus pool. Hence we instead fit <inline-formula><inline-graphic xlink:href="574574v5_inline25.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>Timid animals also only exhibit two phases, albeit different ones from the intermediate animals: cautious-peak and cautious-steady-state. We fit four statistics: the transition time from cautious-peak to cautious-steady-state phase <italic>t</italic><sup>peak-to-steady</sup>, the durations of the two phases <italic>d</italic><sup>cautious-peak</sup> and <italic>d</italic><sup>cautious-steady</sup>, and the ratio of the frequencies of the two phases <inline-formula><inline-graphic xlink:href="574574v5_inline26.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
</sec>
<sec id="s4f2">
<label>4.6.2</label>
<title>Model Statistics</title>
<p>By design, our BAMDP agent also enjoys a notion of bouts and behavioral phases. We map the behavior of the agent to the same abstract space of duration, frequency, and transition time statistics as the animals to allow the fitting.</p>
<p>We consider the agent as performing a bout when it leaves the nest, stays at the object state for some turns, and finally returns to the nest. We parse bouts and behavioral phases from the overall state trajectory of the agent which, like the animals, has what we can describe as contiguous periods of cautious or confident approach and low or high approach frequency.</p>
<p>The transition from cautious to confident phase (measured in the number of turns) is when the model begins visiting the confident-object state rather than the cautious-object state (this transition never happens for low <inline-formula><inline-graphic xlink:href="574574v5_inline27.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). The transition from peak to steady-state phase is when the model starts spending &gt; 1 consecutive turns at the nest (to regenerate <italic>G</italic>), which happens when <italic>G</italic> reaches its steady-state value determined by the forgetting rate. We linearly map the agent’s transition times (in units of turns) to the space of animals’ transition times (units of minutes) using the relationship: 2 turns to 1 minute. Therefore, agent is simulated for 200 turns corresponding to 100 minutes in the experiment.</p>
<p>Bout duration is naturally defined as the number of consecutive turns the agent spends at the object. Because the agent lives in discrete time, we map its duration (units of turns) to the space of animal duration (units of seconds) using the formula,
<disp-formula id="eqn20">
<graphic xlink:href="574574v5_eqn20.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Hence the agent is capable of having durations from 0.75 to 3.75 seconds. This captures a large range of the animals’ phase-averaged durations.</p>
<p>We define the momentary frequency with which the agent visits the object as the inverse of the period, which is the number of turns between two consecutive bouts (sum of turns at nest and object states). Frequency ratios are computed by dividing the average periods of two phases (in units of turns) and are unitless. Hence, no mapping between agent and animal frequency ratios is necessary.</p>
</sec>
<sec id="s4f3">
<label>4.6.3</label>
<title>Approximate Bayesian Computation</title>
<p>We fit each of the 26 animals from <xref ref-type="bibr" rid="c2">Akiti et al. (2022</xref>) separately using an Approximate Bayesian Computation Sequential Monte Carlo (ABCSMC) algorithm (<xref ref-type="bibr" rid="c69">Toni et al., 2009</xref>). We use an adaptive acceptance threshold schedule that sets <italic>ε</italic><sub><italic>t</italic></sub> to the lowest 30-percentile of distances <italic>d</italic>(<italic>x, x</italic><sub>0</sub>) in the previous population. We use a Gaussian transition kernel <italic>K</italic><sub><italic>t</italic></sub>(<italic>θ</italic>| <italic>θ</italic><sup><italic>*</italic></sup>) = 𝒩 (0, Σ), where the bandwidth of Σis set using the Silverman heuristic. We ran ABC-SMC for <italic>T</italic> = 30 populations for each animal but most animals converged earlier. We used uniform priors. <xref rid="tbl1" ref-type="table">Table 1</xref> contains a list of ABCSMC parameters.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Table of ABCSMC Parameters</title></caption>
<graphic xlink:href="574574v5_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Given agent statistics x and animal statistics x<sub>0</sub> in a joint space, we compute the ABC distance <italic>d</italic>(x, x<sub>0</sub>) using the a normalized <italic>L</italic><sub>1</sub> distance function.
<disp-formula id="eqn21">
<graphic xlink:href="574574v5_eqn21.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>i</italic> indexes the statistics. <italic>C</italic><sup><italic>i</italic></sup>(<italic>x</italic><sup><italic>i</italic></sup>) is a normalization constant that depends on the statistic and possibly the value <italic>x</italic><sup><italic>i</italic></sup>. Normalization is necessary because the statistics have different units and value ranges.</p>
<p>We normalize durations using a constant <italic>C</italic><sup><italic>i</italic></sup>(<italic>x</italic><sup><italic>i</italic></sup>) = 4.0 seconds. We normalize the transition times using a piece-wise linear function to prevent extremely small or large values from dominating the distance.
<disp-formula id="eqn22">
<graphic xlink:href="574574v5_eqn22.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We also normalize the frequency ratio using a piece-wise linear function.
<disp-formula id="eqn23">
<graphic xlink:href="574574v5_eqn23.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We are grateful to Chris Gagne, Vikki Neville, Mike Mendl, Elizabeth S. Paul, Richard Gao and particularly Mitsuko Watabe-Uchida for their helpful discussion and feedback.</p>
<p>Funding was from the Max Planck Society and the Humboldt Foundation. <italic>Open access funding provided by Max Planck Society</italic>. PD is a member of the Machine Learning Cluster of Excellence, EXC number 2064/1 – Project number 39072764 and of the Else Kröner Medical Scientist Kolleg “ClinbrAIn: Artificial Intelligence for Clinical Brain Research. We thank the IT team from the Max Planck Institute for Biological Cybernetics for technical support.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ainsworth</surname> <given-names>MD</given-names></string-name></person-group>. <article-title>Patterns of attachment behavior shown by the infant in interaction with his mother</article-title>. <source>Merrill-Palmer Quarterly of Behavior and Development</source>. <year>1964</year>; <volume>10</volume>(<issue>1</issue>):<fpage>51</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akiti</surname> <given-names>K</given-names></string-name>, <string-name><surname>Tsutsui-Kimura</surname> <given-names>I</given-names></string-name>, <string-name><surname>Xie</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Mathis</surname> <given-names>A</given-names></string-name>, <string-name><surname>Markowitz</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Anyoha</surname> <given-names>R</given-names></string-name>, <string-name><surname>Datta</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Mathis</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N</given-names></string-name>, <string-name><surname>Watabe-Uchida</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Striatal dopamine explains novelty-induced behavioral dynamics and individual variability in threat prediction</article-title>. <source>Neuron</source>. <year>2022</year> 11; <volume>110</volume>:<fpage>3789</fpage>–<lpage>3804.e9</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2022.08.022</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Antonov</surname> <given-names>G</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Exploring Replay</article-title>. <source>bioRxiv</source>. <year>2023</year>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arsenian</surname> <given-names>JM</given-names></string-name></person-group>. <article-title>Young children in an insecure situation</article-title>. <source>The Journal of Abnormal and Social Psychology</source>. <year>1943</year>; <volume>38</volume>(<issue>2</issue>):<fpage>225</fpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Artzner</surname> <given-names>P</given-names></string-name>, <string-name><surname>Delbaen</surname> <given-names>F</given-names></string-name>, <string-name><surname>Eber</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Heath</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Coherent measures of risk</article-title>. <source>Mathematical finance</source>. <year>1999</year>; <volume>9</volume>(<issue>3</issue>):<fpage>203</fpage>–<lpage>228</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bellemare</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Dabney</surname> <given-names>W</given-names></string-name>, <string-name><surname>Rowland</surname> <given-names>M.</given-names></string-name></person-group> <source>Distributional Reinforcement Learning</source>. <publisher-name>MIT Press</publisher-name>; <year>2023a</year>. <ext-link ext-link-type="uri" xlink:href="http://www.distributional-rl.org">http://www.distributional-rl.org</ext-link>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bellemare</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Dabney</surname> <given-names>W</given-names></string-name>, <string-name><surname>Rowland</surname> <given-names>M.</given-names></string-name></person-group> <source>Distributional reinforcement learning</source>. <publisher-name>MIT Press</publisher-name>; <year>2023b</year>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bennett</surname> <given-names>D</given-names></string-name>, <string-name><surname>Niv</surname> <given-names>Y.</given-names></string-name></person-group> <article-title>Opening Burton’s clock: Psychiatric insights from computational cognitive models</article-title>. <source>The Cognitive Neurosciences</source>. <year>2020</year>; p. <fpage>439</fpage>–<lpage>450</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bishop</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Gagne</surname> <given-names>C.</given-names></string-name></person-group> <article-title>Anxiety, Depression, and Decision Making: A Computational Perspective</article-title>. <source>Annual Review of Neuroscience</source>. <year>2018</year>; <volume>41</volume>(<issue>1</issue>):<fpage>371</fpage>–<lpage>388</lpage>. doi: <pub-id pub-id-type="doi">10.1146/annurev-neuro-080317-062007</pub-id>, PMID: <pub-id pub-id-type="pmid">29709209</pub-id>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bowlby</surname> <given-names>J.</given-names></string-name></person-group> <article-title>(b) The Growth of Independence in the Young Child</article-title>. <source>Journal (Royal Society of Health)</source>. <year>1955</year>; <volume>76</volume>(<issue>9</issue>):<fpage>587</fpage>– <lpage>591</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bromberg-Martin</surname> <given-names>E</given-names></string-name>, <string-name><surname>Hikosaka</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Midbrain Dopamine Neurons Signal Preference for Advance Information about Upcoming Rewards</article-title>. <source>Neuron</source>. <year>2009</year> 08; <volume>63</volume>:<fpage>119</fpage>–<lpage>26</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2009.06.009</pub-id>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brown</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Dreier</surname> <given-names>VM</given-names></string-name></person-group>. <article-title>Predator inspection behaviour and attack cone avoidance in a characin fish: the effects of predator diet and prey experience</article-title>. <source>Animal Behaviour</source>. <year>2002</year>; <volume>63</volume>(<issue>6</issue>):<fpage>1175</fpage>–<lpage>1181</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Butler</surname> <given-names>G</given-names></string-name>, <string-name><surname>Mathews</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Cognitive processes in anxiety</article-title>. <source>Advances in behaviour research and therapy</source>. <year>1983</year>; <volume>5</volume>(<issue>1</issue>):<fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charpentier</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Aylward</surname> <given-names>J</given-names></string-name>, <string-name><surname>Roiser</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>OJ</given-names></string-name></person-group>. <article-title>Enhanced risk aversion, but not loss aversion, in unmedicated pathological anxiety</article-title>. <source>Biological psychiatry</source>. <year>2017</year>; <volume>81</volume>(<issue>12</issue>):<fpage>1014</fpage>–<lpage>1022</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chow</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Tamar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mannor</surname> <given-names>S</given-names></string-name>, <string-name><surname>Pavone</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Risk-sensitive and robust decision-making: a cvar optimization approach</article-title>. <source>Advances in neural information processing systems</source>. <year>2015</year>; <volume>28</volume>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Coss</surname> <given-names>RG</given-names></string-name>, <string-name><surname>Biardi</surname> <given-names>JE</given-names></string-name></person-group>. <article-title>Individual variation in the antisnake behavior of California ground squirrels (Spermophilus beecheyi)</article-title>. <source>Journal of Mammalogy</source>. <year>1997</year>; <volume>78</volume>(<issue>2</issue>):<fpage>294</fpage>–<lpage>310</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dabney</surname> <given-names>W</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N</given-names></string-name>, <string-name><surname>Starkweather</surname> <given-names>CK</given-names></string-name>, <string-name><surname>Hassabis</surname> <given-names>D</given-names></string-name>, <string-name><surname>Munos</surname> <given-names>R</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>M.</given-names></string-name></person-group> <article-title>A distributional code for value in dopamine-based reinforcement learning</article-title>. <source>Nature</source>. <year>2020</year>; <volume>577</volume>(<issue>7792</issue>):<fpage>671</fpage>–<lpage>675</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kakade</surname> <given-names>S</given-names></string-name>, <string-name><surname>Montague</surname> <given-names>PR</given-names></string-name></person-group>. <article-title>Learning and selective attention</article-title>. <source>Nature neuroscience</source>. <year>2000</year>; <volume>3</volume>(<issue>11</issue>):<fpage>1218</fpage>– <lpage>1223</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Roiser</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Viding</surname> <given-names>E.</given-names></string-name></person-group> <chapter-title>The first steps on long marches: The costs of active observation</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Savulescu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Roache</surname> <given-names>R</given-names></string-name>, <string-name><surname>Davies</surname> <given-names>W</given-names></string-name>, <string-name><surname>Loebel</surname> <given-names>JP</given-names></string-name></person-group>, editors. <source>Psychiatry Reborn: Biopsychosocial psychiatry in modern medicine</source> <publisher-name>Oxford University Press</publisher-name>; <year>2020</year>. doi: <pub-id pub-id-type="doi">10.1093/med/9780198789697.003.0014</pub-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Sejnowski</surname> <given-names>TJ</given-names></string-name></person-group>. <article-title>Exploration bonuses and dual control</article-title>. <source>Machine Learning</source>. <year>1996</year>; <volume>25</volume>:<fpage>5</fpage>–<lpage>22</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Dearden</surname> <given-names>R</given-names></string-name>, <string-name><surname>Friedman</surname> <given-names>N</given-names></string-name>, <string-name><surname>Andre</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Model-based Bayesian exploration</article-title>. <source>arXiv</source> <elocation-id>13016690</elocation-id>. <year>2013</year>;.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Duff</surname> <given-names>MO</given-names></string-name></person-group>. <source>Optimal Learning: Computational procedures for Bayes-adaptive Markov decision processes</source>. <publisher-name>University of Massachusetts Amherst</publisher-name>; <year>2002a</year>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="thesis"><person-group person-group-type="author"><string-name><surname>Duff</surname> <given-names>M.</given-names></string-name></person-group> <source>Optimal learning: Computational procedures for Bayes-adaptive Markov decision processes</source>. <comment>PhD thesis</comment>, <publisher-name>University of Massachusetts Amherst</publisher-name>; <year>2002b</year>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dugatkin</surname> <given-names>LA</given-names></string-name></person-group>. <article-title>Do guppies play TIT FOR TAT during predator inspection visits?</article-title> <source>Behavioral Ecology and Sociobiology</source>. <year>1988</year>; <volume>23</volume>:<fpage>395</fpage>–<lpage>399</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eccard</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Liesenjohann</surname> <given-names>T</given-names></string-name>, <string-name><surname>Dammhahn</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Among-individual differences in foraging modulate resource exploitation under perceived predation risk</article-title>. <source>Oecologia</source>. <year>2020</year>; <volume>194</volume>:<fpage>621</fpage>–<lpage>634</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eldar</surname> <given-names>E</given-names></string-name>, <string-name><surname>Rutledge</surname> <given-names>RB</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Niv</surname> <given-names>Y.</given-names></string-name></person-group> <article-title>Mood as representation of momentum</article-title>. <source>Trends in cognitive sciences</source>. <year>2016</year>; <volume>20</volume>(<issue>1</issue>):<fpage>15</fpage>–<lpage>24</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>FitzGibbon</surname> <given-names>CD</given-names></string-name></person-group>. <article-title>The costs and benefits of predator inspection behaviour in Thomson’s gazelles</article-title>. <source>Behavioral Ecology and Sociobiology</source>. <year>1994</year>; <volume>34</volume>:<fpage>139</fpage>–<lpage>148</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frey</surname> <given-names>R</given-names></string-name>, <string-name><surname>Pedroni</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mata</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rieskamp</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hertwig</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Risk preference shares the psychometric structure of major psychological traits</article-title>. <source>Science advances</source>. <year>2017</year>; <volume>3</volume>(<issue>10</issue>):<fpage>e1701381</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gagne</surname> <given-names>C</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Peril, prudence and planning as risk, avoidance and worry</article-title>. <source>Journal of Mathematical Psychology</source>. <year>2022</year>; <volume>106</volume>:<fpage>102617</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jmp.2021.102617</pub-id>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gagne</surname> <given-names>C</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Two steps to risk sensitivity</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2021</year>; <volume>34</volume>:<fpage>22209</fpage>–<lpage>22220</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giorgetta</surname> <given-names>C</given-names></string-name>, <string-name><surname>Grecucci</surname> <given-names>A</given-names></string-name>, <string-name><surname>Zuanon</surname> <given-names>S</given-names></string-name>, <string-name><surname>Perini</surname> <given-names>L</given-names></string-name>, <string-name><surname>Balestrieri</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bonini</surname> <given-names>N</given-names></string-name>, <string-name><surname>Sanfey</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Brambilla</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Reduced risk-taking behavior as a trait feature of anxiety</article-title>. <source>Emotion</source>. <year>2012</year>; <volume>12</volume>(<issue>6</issue>):<fpage>1373</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gittins</surname> <given-names>JC</given-names></string-name></person-group>. <article-title>Bandit processes and dynamic allocation indices</article-title>. <source>Journal of the Royal Statistical Society Series B: Statistical Methodology</source>. <year>1979</year>; <volume>41</volume>(<issue>2</issue>):<fpage>148</fpage>–<lpage>164</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gmytrasiewicz</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Doshi</surname> <given-names>P.</given-names></string-name></person-group> <article-title>A Framework for Sequential Planning in Multi-Agent Settings</article-title>. <source>Journal of Artificial Intelligence Research</source>. <year>2005</year> <month>jul</month>; <volume>24</volume>:<fpage>49</fpage>–<lpage>79</lpage>. doi: <pub-id pub-id-type="doi">10.1613/jair.1579</pub-id>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gottlieb</surname> <given-names>J</given-names></string-name>, <string-name><surname>Oudeyer</surname> <given-names>PY</given-names></string-name>, <string-name><surname>Lopes</surname> <given-names>M</given-names></string-name>, <string-name><surname>Baranes</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Information-seeking, curiosity, and attention: computational and neural mechanisms</article-title>. <source>Trends in cognitive sciences</source>. <year>2013</year>; <volume>17</volume>(<issue>11</issue>):<fpage>585</fpage>–<lpage>593</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greggor</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Thornton</surname> <given-names>A</given-names></string-name>, <string-name><surname>Clayton</surname> <given-names>NS</given-names></string-name></person-group>. <article-title>Neophobia is not only avoidance: improving neophobia tests by combining cognition and ecology</article-title>. <source>Current Opinion in Behavioral Sciences</source>. <year>2015</year>; <volume>6</volume>:<fpage>82</fpage>–<lpage>89</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cobeha.2015.10.007</pub-id>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guez</surname> <given-names>A</given-names></string-name>, <string-name><surname>Silver</surname> <given-names>D</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Scalable and efficient Bayes-adaptive reinforcement learning based on Monte-Carlo tree search</article-title>. <source>Journal of Artificial Intelligence Research</source>. <year>2013</year>; <volume>48</volume>:<fpage>841</fpage>–<lpage>883</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Hau</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Delage</surname> <given-names>E</given-names></string-name>, <string-name><surname>Ghavamzadeh</surname> <given-names>M</given-names></string-name>, <string-name><surname>Petrik</surname> <given-names>M.</given-names></string-name></person-group> <article-title>On Dynamic Program Decompositions of Static Risk Measures</article-title>. <source>arXiv</source> <elocation-id>230412477</elocation-id>. <year>2023</year>;.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huys</surname> <given-names>QJM</given-names></string-name>, <string-name><surname>Russek</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Abitante</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kahnt</surname> <given-names>T</given-names></string-name>, <string-name><surname>Gollan</surname> <given-names>JK</given-names></string-name></person-group>. <article-title>Components of Behavioral Activation Therapy for Depression Engage Specific Reinforcement Learning Mechanisms in a Pilot Study</article-title>. <source>Computational Psychiatry</source>. <year>2022</year> <month>Oct</month>; doi: <pub-id pub-id-type="doi">10.5334/cpsy.81</pub-id>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jaakkola</surname> <given-names>TS</given-names></string-name>, <string-name><surname>Jordan</surname> <given-names>MI</given-names></string-name></person-group>. <article-title>Variational probabilistic inference and the QMR-DT network</article-title>. <source>Journal of artificial intelligence research</source>. <year>1999</year>; <volume>10</volume>:<fpage>291</fpage>–<lpage>322</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaelbling</surname> <given-names>LP</given-names></string-name>, <string-name><surname>Littman</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Cassandra</surname> <given-names>AR</given-names></string-name></person-group>. <article-title>Planning and acting in partially observable stochastic domains</article-title>. <source>Artificial intelligence</source>. <year>1998</year>; <volume>101</volume>(<issue>1-2</issue>):<fpage>99</fpage>–<lpage>134</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kakade</surname> <given-names>S</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Dopamine: generalization and bonuses</article-title>. <source>Neural Networks</source>. <year>2002</year>; <volume>15</volume>(<issue>4-6</issue>):<fpage>549</fpage>–<lpage>559</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kemp</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kaplan</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Individual modulation of anti-predator responses in common marmosets</article-title>. <source>International Journal of Comparative Psychology</source>. <year>2011</year>; <volume>24</volume>(<issue>1</issue>).</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keramati</surname> <given-names>M</given-names></string-name>, <string-name><surname>Smittenaar</surname> <given-names>P</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Adaptive integration of habits into depth-limited planning defines a habitual-goal–directed spectrum</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2016</year>; <volume>113</volume>(<issue>45</issue>):<fpage>12868</fpage>– <lpage>12873</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lloyd</surname> <given-names>K</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Interrupting behaviour: Minimizing decision costs via temporal commitment and low-level interrupts</article-title>. <source>PLoS computational biology</source>. <year>2018</year>; <volume>14</volume>(<issue>1</issue>):<fpage>e1005916</fpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Magurran</surname> <given-names>AE</given-names></string-name></person-group>. <article-title>Predator inspection behaviour in minnow shoals: differences between populations and individuals</article-title>. <source>Behavioral ecology and sociobiology</source>. <year>1986</year>; <volume>19</volume>:<fpage>267</fpage>–<lpage>273</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Magurran</surname> <given-names>AE</given-names></string-name>, <string-name><surname>Seghers</surname> <given-names>BH</given-names></string-name></person-group>. <article-title>Population differences in predator recognition and attack cone avoidance in the guppy Poecilia reticulata</article-title>. <source>Animal Behaviour</source>. <year>1990</year>; <volume>40</volume>(<issue>3</issue>):<fpage>443</fpage>–<lpage>452</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maner</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Richey</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Cromer</surname> <given-names>K</given-names></string-name>, <string-name><surname>Mallott</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lejuez</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Joiner</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Schmidt</surname> <given-names>NB</given-names></string-name></person-group>. <article-title>Dispositional anxiety and riskavoidant decision-making</article-title>. <source>Personality and Individual Differences</source>. <year>2007</year>; <volume>42</volume>(<issue>4</issue>):<fpage>665</fpage>–<lpage>675</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Masset</surname> <given-names>P</given-names></string-name>, <string-name><surname>Tano</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>HR</given-names></string-name>, <string-name><surname>Malik</surname> <given-names>AN</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Multi-timescale reinforcement learning in the brain</article-title>. <source>bioRxiv</source>. <year>2023</year>;.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathis</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mamidanna</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cury</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Abe</surname> <given-names>T</given-names></string-name>, <string-name><surname>Murthy</surname> <given-names>VN</given-names></string-name>, <string-name><surname>Mathis</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M.</given-names></string-name></person-group> <article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title>. <source>Nature neuroscience</source>. <year>2018</year>; <volume>21</volume>(<issue>9</issue>):<fpage>1281</fpage>–<lpage>1289</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mattar</surname> <given-names>M</given-names></string-name>, <string-name><surname>Daw</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Prioritized memory access explains planning and hippocampal replay</article-title>. <source>Nature Neuroscience</source>. <year>2018</year> 11; <volume>21</volume>. doi: <pub-id pub-id-type="doi">10.1038/s41593-018-0232-z</pub-id>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mazza</surname> <given-names>V</given-names></string-name>, <string-name><surname>Jacob</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dammhahn</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zaccaroni</surname> <given-names>M</given-names></string-name>, <string-name><surname>Eccard</surname> <given-names>JA</given-names></string-name></person-group>. <article-title>Individual variation in cognitive style reflects foraging and anti-predator strategies in a small mammal</article-title>. <source>Scientific Reports</source>. <year>2019</year>; <volume>9</volume>(<issue>1</issue>):<fpage>10157</fpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Menegas</surname> <given-names>W</given-names></string-name>, <string-name><surname>Akiti</surname> <given-names>K</given-names></string-name>, <string-name><surname>Amo</surname> <given-names>R</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N</given-names></string-name>, <string-name><surname>Watabe-Uchida</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Dopamine neurons projecting to the posterior striatum reinforce avoidance of threatening stimuli</article-title>. <source>Nature neuroscience</source>. <year>2018</year>; <volume>21</volume>(<issue>10</issue>):<fpage>1421</fpage>–<lpage>1430</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Menegas</surname> <given-names>W</given-names></string-name>, <string-name><surname>Babayan</surname> <given-names>BM</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N</given-names></string-name>, <string-name><surname>Watabe-Uchida</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Opposite initialization to novel cues in dopamine signaling in ventral and posterior striatum in mice</article-title>. <source>eLife</source>. <year>2017</year>; <volume>6</volume>:<elocation-id>e21886</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.21886</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mobbs</surname> <given-names>D</given-names></string-name>, <string-name><surname>Headley</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Ding</surname> <given-names>W</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Space, time, and fear: survival computations along defensive circuits</article-title>. <source>Trends in cognitive sciences</source>. <year>2020</year>; <volume>24</volume>(<issue>3</issue>):<fpage>228</fpage>–<lpage>241</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ogasawara</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sogukpinar</surname> <given-names>F</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>K</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>YY</given-names></string-name>, <string-name><surname>Pai</surname> <given-names>J</given-names></string-name>, <string-name><surname>Jezzini</surname> <given-names>A</given-names></string-name>, <string-name><surname>Monosov</surname> <given-names>IE</given-names></string-name></person-group>. <article-title>A primate temporal cortex–zona incerta pathway for novelty seeking</article-title>. <source>Nature Neuroscience</source>. <year>2022</year> <month>Jan</month>; <volume>25</volume>(<issue>1</issue>):<fpage>50</fpage>–<lpage>60</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41593-021-00950-1</pub-id>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oudeyer</surname> <given-names>PY</given-names></string-name>, <string-name><surname>Kaplan</surname> <given-names>F.</given-names></string-name></person-group> <article-title>What is intrinsic motivation? A typology of computational approaches</article-title>. <source>Frontiers in neurorobotics</source>. <year>2007</year>; <volume>1</volume>:<fpage>6</fpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Paulus</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>AJ</given-names></string-name></person-group>. <article-title>Emotion and decision-making: affect-driven belief systems in anxiety and depression</article-title>. <source>Trends in cognitive sciences</source>. <year>2012</year>; <volume>16</volume>(<issue>9</issue>):<fpage>476</fpage>–<lpage>483</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radulescu</surname> <given-names>A</given-names></string-name>, <string-name><surname>Niv</surname> <given-names>Y.</given-names></string-name></person-group> <article-title>State representation in mental illness</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2019</year>; <volume>55</volume>:<fpage>160</fpage>–<lpage>166</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2019.03.011</pub-id>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Réale</surname> <given-names>D</given-names></string-name>, <string-name><surname>Reader</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Sol</surname> <given-names>D</given-names></string-name>, <string-name><surname>McDougall</surname> <given-names>PT</given-names></string-name>, <string-name><surname>Dingemanse</surname> <given-names>NJ</given-names></string-name></person-group>. <article-title>Integrating animal temperament within ecology and evolution</article-title>. <source>Biological reviews</source>. <year>2007</year>; <volume>82</volume>(<issue>2</issue>):<fpage>291</fpage>–<lpage>318</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rieger</surname> <given-names>MO</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hens</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Risk preferences around the world</article-title>. <source>Management Science</source>. <year>2015</year>; <volume>61</volume>(<issue>3</issue>):<fpage>637</fpage>–<lpage>648</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rigter</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lacerda</surname> <given-names>B</given-names></string-name>, <string-name><surname>Hawes</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Risk-averse bayes-adaptive reinforcement learning</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2021</year>; <volume>34</volume>:<fpage>1142</fpage>–<lpage>1154</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Russell</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Norvig</surname> <given-names>P.</given-names></string-name></person-group> <source>Artificial intelligence: a modern approach</source>. <publisher-loc>Malaysia</publisher-loc>; <publisher-name>Pearson Education Limited</publisher-name>; <year>2016</year>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Rusu</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Colmenarejo</surname> <given-names>SG</given-names></string-name>, <string-name><surname>Gulcehre</surname> <given-names>C</given-names></string-name>, <string-name><surname>Desjardins</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kirkpatrick</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pascanu</surname> <given-names>R</given-names></string-name>, <string-name><surname>Mnih</surname> <given-names>V</given-names></string-name>, <string-name><surname>Kavukcuoglu</surname> <given-names>K</given-names></string-name>, <string-name><surname>Hadsell</surname> <given-names>R</given-names></string-name></person-group>, <article-title>Policy Distillation</article-title> <source>arXiv</source>; <year>2016</year>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simon</surname> <given-names>P</given-names></string-name>, <string-name><surname>Dupuis</surname> <given-names>R</given-names></string-name>, <string-name><surname>Costentin</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Thigmotaxis as an index of anxiety in mice. Influence of dopaminergic transmissions</article-title>. <source>Behavioural Brain Research</source>. <year>1994</year>; <volume>61</volume>(<issue>1</issue>):<fpage>59</fpage>–<lpage>64</lpage>. doi: <pub-id pub-id-type="doi">10.1016/0166-4328(94)90008-6</pub-id>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Sousa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bujalski</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cruz</surname> <given-names>BF</given-names></string-name>, <string-name><surname>Louie</surname> <given-names>K</given-names></string-name>, <string-name><surname>McNamee</surname> <given-names>D</given-names></string-name>, <string-name><surname>Paton</surname> <given-names>JJ</given-names></string-name></person-group>. <article-title>Dopamine neurons encode a multidimensional probabilistic map of future reward</article-title>. <source>bioRxiv</source>. <year>2023</year>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sutton</surname> <given-names>RS</given-names></string-name></person-group>. <article-title>Learning to predict by the methods of temporal differences</article-title>. <source>Machine learning</source>. <year>1988</year>; <volume>3</volume>:<fpage>9</fpage>–<lpage>44</lpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toni</surname> <given-names>T</given-names></string-name>, <string-name><surname>Welch</surname> <given-names>D</given-names></string-name>, <string-name><surname>Strelkowa</surname> <given-names>N</given-names></string-name>, <string-name><surname>Ipsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Stumpf</surname> <given-names>MP</given-names></string-name></person-group>. <article-title>Approximate Bayesian computation scheme for parameter inference and model selection in dynamical systems</article-title>. <source>Journal of the Royal Society Interface</source>. <year>2009</year>; <volume>6</volume>(<issue>31</issue>):<fpage>187</fpage>– <lpage>202</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Wang</surname> <given-names>JX</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Tirumala</surname> <given-names>D</given-names></string-name>, <string-name><surname>Soyer</surname> <given-names>H</given-names></string-name>, <string-name><surname>Leibo</surname> <given-names>JZ</given-names></string-name>, <string-name><surname>Munos</surname> <given-names>R</given-names></string-name>, <string-name><surname>Blundell</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kumaran</surname> <given-names>D</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>M</given-names></string-name></person-group>, <article-title>Learning to reinforcement learn</article-title> <source>arXiv</source>; <year>2017</year>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weber</surname> <given-names>R.</given-names></string-name></person-group> <article-title>On the Gittins Index for Multiarmed Bandits</article-title>. <source>The Annals of Applied Probability</source>. <year>1992</year>; <volume>2</volume>(<issue>4</issue>):<fpage>1024</fpage> – <lpage>1033</lpage>. doi: <pub-id pub-id-type="doi">10.1214/aoap/1177005588</pub-id>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Geana</surname> <given-names>A</given-names></string-name>, <string-name><surname>White</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Ludvig</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name></person-group>. <article-title>Humans use directed and random exploration to solve the explore–exploit dilemma</article-title>. <source>Journal of Experimental Psychology: General</source>. <year>2014</year>; <volume>143</volume>(<issue>6</issue>):<fpage>2074</fpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wiltschko</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Tsukahara</surname> <given-names>T</given-names></string-name>, <string-name><surname>Zeine</surname> <given-names>A</given-names></string-name>, <string-name><surname>Anyoha</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gillis</surname> <given-names>WF</given-names></string-name>, <string-name><surname>Markowitz</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Peterson</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Katon</surname> <given-names>J</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Datta</surname> <given-names>SR</given-names></string-name></person-group>. <article-title>Revealing the structure of pharmacobehavioral space through motion sequencing</article-title>. <source>Nature Neuroscience</source>. <year>2020</year> <month>Nov</month>; <volume>23</volume>(<issue>11</issue>):<fpage>1433</fpage>–<lpage>1443</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41593-020-00706-3</pub-id>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<title>Appendix 1</title>
<sec id="s5">
<title>A Recovery Analysis</title>
<p>We performed recovery analysis on our ABCSMC fits. The <italic>recovery targets</italic> were the best-fitting particles for each of the 26 mice. We ran ABCSMC a second time, using the same hyperparameters, to check that we could recover the recovery targets.</p>
<p><xref rid="figA1_1" ref-type="fig">Fig. 1</xref> compares the recovery targets against the closest particles in the posterior of the (recovery) ABCSMC fit. Each subplot shows one of the nine fitted parameters: nCVaR<sub><italic>α</italic></sub>, <italic>G</italic><sub>0</sub>, the forgetting rate <italic>f</italic>, the three hazard prior means and the three hazard prior deviations. In general, the ABCSMC fitting algorithm recovers the recovery-target reasonably well for all animals, with a minimum <italic>R</italic><sup>2</sup> value of 0.72.</p>
<fig id="figA1_1" position="float" fig-type="figure">
<label>Appendix 1—figure 1.</label>
<caption><title>recovery targets versus the closest particles in the ABCSMC posterior.</title>
<p>Each subplot plots one of the nine fitted parameters for all 26 animals. The colors of the points indicate the animal group. The gray <italic>y</italic> = <italic>x</italic> line represents a perfect recovery of the recovery targets. Most points lie close to the <italic>y</italic> = <italic>x</italic> line, suggesting our ABCSMC fitting algorithm has good recoverability.</p></caption>
<graphic xlink:href="574574v5_figA1_1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="figA1_2" ref-type="fig">Fig. 2</xref> compares the recovery targets against the (marginal) means of the ABCSMC posterior. The exploration pool <italic>G</italic><sub>0</sub> and forgetting rate <italic>f</italic> are well recovered. However, there is poor recoverability for nCVaR<sub><italic>α</italic></sub> and the prior parameters due to non-identifiability. This is further illustrated in <xref rid="figA1_3" ref-type="fig">Fig. 3</xref> for a single brave animal. <xref rid="figA1_3" ref-type="fig">Fig. 3</xref> plots the univariate and bivariate marginals of the ABCSMC posterior. As expected, the recovery targets lie within a narrow range of the posterior distributions for <italic>G</italic><sub>0</sub> and <italic>f</italic>. For nCVaR<sub><italic>α</italic></sub> and the prior parameters, the recovery targets are farther from the means of the posterior but still lie within a region of the posterior with support.</p>
<fig id="figA1_2" position="float" fig-type="figure">
<label>&gt;Appendix 1—figure 2.</label>
<caption><title>Identical to Fig. 1 but the recovery targets are plotted against the <italic>(marginal) means of the ABCSMC posterior</italic>.</title>
<p> We chose the final ABCSMC population for the posterior (population 15). <italic>R</italic><sup>2</sup> is high for <italic>G</italic><sub>0</sub> and <italic>f</italic>, suggesting that these parameters are identifiable. <italic>R</italic><sup>2</sup> is low for nCVaR<sub><italic>α</italic></sub> and the hazard priors due to the non-identifiability discussed in the main text. In particular, <italic>R</italic><sup>2</sup> is less than 0.0 for nCVaR<sub><italic>α</italic></sub> and <italic>θ</italic><sub>2</sub>-mean suggesting these parameters are the most confounded. However, <italic>R</italic><sup>2</sup> is high for <italic>θ</italic><sub>2</sub>-deviation, suggesting nCVaR<sub><italic>α</italic></sub> does not confound the flexibility of the hazard function. Finally, the <italic>R</italic><sup>2</sup> for <italic>θ</italic><sub>3</sub> is nearly zero. This is expected because timid and some intermediate animals do not have duration-3 approach and for these animals, <italic>θ</italic><sub>3</sub> can take on arbitrary large values.</p></caption>
<graphic xlink:href="574574v5_figA1_2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figA1_3" position="float" fig-type="figure">
<label>Appendix 1—figure 3.</label>
<caption><title>The ABCSMC posterior for animal 24.</title>
<p>Univariate and bivariate marginals are shown on the diagonal and off-diagonal respectively. recovery targets are shown as green vertical lines in univariate plots and green points on bivariate plots. Marginal means are shown in orange. recovery targets and means are close for <italic>G</italic><sub>0</sub> and <italic>f</italic> due to their identifiability. nCVaR<sub><italic>α</italic></sub> and the hazard prior parameters are non-identifiable. Hence, the recovery targets are farther from the mean but still lie in a region of the posterior with support.</p></caption>
<graphic xlink:href="574574v5_figA1_3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100366.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Langdon</surname>
<given-names>Angela</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute of Mental Health</institution>
</institution-wrap>
<city>Bethesda</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>Shen et al. present a computational account of individual differences in mouse exploration when faced with a novel object in an open field from a previously published study (Akiti et al.) that relates subject-specific intrinsic exploration and caution about potential hazards to the spectrum of behaviors observed in this setting. Overall, this computational study is an <bold>important</bold> contribution that leverages a very general modeling framework (a Bayes Adaptive Markov Decision Process) to quantify and interrogate distinct drivers of exploratory behavior under potential threat. Given their assumptions, the modeling results are <bold>convincing</bold>: the authors are able to describe a substantial amount of the behavioral features and idiosyncracies in this dataset, and their model affords a normative interpretation related to inherent risk aversion and predation hazard &quot;flexibility&quot; of individual animals and should be of broad interest to researchers working to understand open-ended exploratory behaviors.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100366.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work computationally characterized the threat-reward learning behavior of mice in a recent study (Akiti et al.), which had prominent individual differences. The authors constructed a Bayes-adaptive Markov decision process model, and fitted the behavioral data by the model. The model assumed (i) hazard function staring from a prior (with free mean and SD parameters) and updated in a Bayesian manner through experience (actually no real threat or reward was given in the experiment), (ii) risk-sensitive evaluation of future outcomes (calculating lower 𝛼 quantile of outcomes with free 𝛼 parameter), and (iii) heuristic exploration bonus. The authors found that (i) brave animals had more widespread hazard priors than timid animals and thereby quickly learned that there was in fact little real threat, (ii) brave animals may also be less risk-aversive than timid animals in future outcome evaluation, and (iii) the exploration bonus could explain the observed behavioral features, including the transition of behavior from the peak to steady-state frequency of bout. Overall, this work is a novel interesting analysis of threat-reward learning, and provides useful insights for future experimental and theoretical work. However, there are several issues that I think need to be addressed.</p>
<p>Strengths:</p>
<p>- This work provides a normative Bayesian account for individual differences in braveness/timidity in reward-threat learning behavior, which complements the analysis by Akiti et al. based on model-free threat reinforcement learning.</p>
<p>- Specifically, the individual differences were characterized by (i) the difference in the variance of hazard prior and potentially also (ii) the difference in the risk-sensitivity in evaluation of future returns.</p>
<p>Weakness:</p>
<p>- Theoretically the effect of prior is diluted over experience whereas the effect of biased (risk-aversive) evaluation persists, but these two effects could not be teased apart in the fitting analysis of the current data.</p>
<p>- It is currently unclear how (whether) the proposed model corresponds to neurobiological (rather than behavioral) findings, different from the analysis by Akiti et al.</p>
<p>Comments on revisions:</p>
<p>The authors have adequately replied to all the concerns that I raised in my review of the original manuscript. I do not have any remaining concern, and I am now more convinced that this work provides novel important insights and stimulates future experimental and theoretical examinations.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100366.2.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript presents computational modelling of the behaviour of mice during encounters with novel and familiar objects, originally reported in Akiti et al. (Neuron 110, 2022). Mice typically perform short bouts of approach followed by retreat to a safe distance, presumably to balance exploration to discover possible reward with the potential risk of predation. However, there is considerable heterogeneity in this exploratory behaviour, both across time as an individual subject becomes more confident in approaching the object, and across subjects; with some mice rapidly becoming confident to closely explore the object, while other timid mice never become fully confident that the object is safe. The current work aims to explain both the dynamics of adaptation of individual animals over time, and the quantitative and qualitative differences in behaviour between subjects, by modelling their behaviour as arising from model-based planning in a Bayes adaptive Markov Decision Process (BAMDP) framework, in which the subjects maintain and update probabilistic estimates of the uncertain hazard presented by the object, and rationally balance the potential reward from exploring the object with the potential risk of predation it presents.</p>
<p>In order to fit these complex models to the behaviour the authors necessarily make substantial simplifying assumptions, including coarse-graining the exploratory behaviour into phases quantified by a set of summary statistics related to the approach bouts of the animal. Inter-individual variation between subjects is modelled both by differences in their prior beliefs about the possible hazard presented by the object, and by differences in their risk preference, modelled using a conditional value at risk (CVaR) objective, which focuses the subject's evaluation on different quantiles of the expected distribution of outcomes. Interestingly, these two conceptually different possible sources of inter-subject variation in brave vs timid exploratory behaviour turn out not to be dissociable in the current dataset as they can largely compensate for each other in their effects on the measured behaviour. Nonetheless, the modelling captures a wide range of quantitative and qualitative differences between subjects in the dynamics of how they explore the object, essentially through differences in how subject's beliefs about the potential risk and reward presented by the object evolve over the course of exploration, and are combined to drive behaviour.</p>
<p>Exploration in the face of risk is a ubiquitous feature of the decision-making problem faced by organisms, with strong clinical relevance, yet remains poorly understood and under-studied, making this work a timely and welcome addition to the literature.</p>
<p>Strengths:</p>
<p>- Individual differences in exploratory behaviour are an interesting, important, and under-studied topic.</p>
<p>- Application of cutting-edge modelling methods to a rich behavioural dataset, successfully accounting for diverse qualitative and qualitative features of the data in a normative framework.</p>
<p>- Thoughtful discussion of the results in the context of prior literature.</p>
<p>Limitations:</p>
<p>- The model-fitting approach used of coarse-graining the behaviour into phases and fitting to their summary statistics may not be applicable to exploratory behaviours in more complex environments where coarse-graining is less straightforward.</p>
<p>Comments on revisions:</p>
<p>All recommendations to authors from the first review were addressed in the revised manuscript.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100366.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Shen</surname>
<given-names>Tingke</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-0286-5663</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Dayan</surname>
<given-names>Peter</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>This work computationally characterized the threat-reward learning behavior of mice in a  recent study (Akiti et al.), which had prominent individual differences. The authors  constructed a Bayes-adaptive Markov decision process model and fitted the behavioral data  by the model. The model assumed (i) hazard function starting from a prior (with free mean  and SD parameters) and updated in a Bayesian manner through experience (actually no real  threat or reward was given in the experiment), (ii) risk-sensitive evaluation of future  outcomes (calculating lower 𝛼 quantile of outcomes with free 𝛼 parameter), and (iii) heuristic  exploration bonus. The authors found that (i) brave animals had more widespread hazard  priors than timid animals and thereby quickly learned that there was in fact little real threat,  (ii) brave animals may also be less risk-aversive than timid animals in future outcome  evaluation, and (iii) the exploration bonus could explain the observed behavioral features,  including the transition of behavior from the peak to steady-state frequency of bout. Overall,  this work is a novel interesting analysis of threat-reward learning, and provides useful  insights for future experimental and theoretical work. However, there are several issues that I  think need to be addressed.</p>
<p>Strengths:</p>
<p>(1) This work provides a normative Bayesian account for individual differences in  braveness/timidity in reward-threat learning behavior, which complements the analysis by  Akiti et al. based on model-free threat reinforcement learning.</p>
<p>(2) Specifically, the individual differences were characterized by (i) the difference in the  variance of hazard prior and potentially also (ii) the difference in the risk-sensitivity in the  evaluation of future returns.</p>
<p>Weakness:</p>
<p>(1) Theoretically the effect of prior is diluted over experience whereas the effect of biased  (risk-aversive) evaluation persists, but these two effects could not be teased apart in the  fitting analysis of the current data.</p>
<p>(2) It is currently unclear how (whether) the proposed model corresponds to neurobiological ( rather than behavioral) findings, different from the analysis by Akiti et al.</p>
</disp-quote>
<p>We thank reviewer #1 for their useful feedback which we’ve used to improve the discussion,  formatting and clarity of the paper, and for highlighting important questions for future  extensions of our work.</p>
<disp-quote content-type="editor-comment">
<p>Major points:</p>
<p>(1) Line 219</p>
<p>It was assumed that the exploration bonus was replenished at a steady rate when the animal  was at the nest. An alternative way would be assuming that the exploration bonus slowly  degraded over time or experience, and if doing so, there appears to be a possibility that the  transition of the bout rate from peak to steady-state could be at least partially explained by  such a decrease in the exploration bonus.</p>
</disp-quote>
<p>Section 2.2.3 explains the mechanism of the exploration bonus which motivates approach.  We think that the mechanism suggested by the reviewer is, in essence, what is happening in  the model. The exploration pool is indeed depleted over time or bouts of experience at the  object. In the peak confident phase for brave animals and the peak cautious phase for timid  animals, the rate of depletion exceeds the rate of regeneration, since the agent spends only  a single turn at the nest between bouts. In the steady-state phase, the exploration pool has  depleted so much previously that the agent must wait multiple turns at the nest for the pool  to regenerate to a sufficiently high value to justify approaching the object again.</p>
<p>We have updated section 2.2.3 to explain that agents spend one turn at the nest during peak  phase but multiple turns during steady-state phase. Hopefully, this makes our mechanism  clear:</p>
<p>“In simulations, when 𝐺(𝑡) is high, the agent has a high motivation to explore the object,  spending only a single turn in the nest state between bouts. In other words, the depletion  from 𝐺0 substantially influences the time point at which approach makes a transition from  peak to steady-state; the steady-state time then depends on the dynamics of depletion  (when at the object) and replenishment (when at the nest). In particular, in the steady-state  phases, the agent must wait multiple turns at the nest for 𝐺(𝑡)  to regenerate so that  informational reward once again exceeds the potential cost of hazard.“</p>
<disp-quote content-type="editor-comment">
<p>(2) Line 237- (Section 2.2.6, 2.2.7, Figures 7, 9)</p>
<p>I was confused by the descriptions about nCVaR. I looked at the cited original literature  Gagne &amp; Dayan 2022, and understood that nCVaR is a risk-sensitive version of expected  future returns (equation 4) with parameter α (α-bar) (ranging from 0 to 1) representing risk  preference. Line 269-271 and Section 4.2 of the present manuscript described (in my  understanding) that α was a parameter of the model. Then, isn't it more natural to report  estimated values of α, rather than nCVaR, for individual animals in Section 2.2.6, 2.2.7,  Figures 7, 9 (even though nCVaR monotonically depends on α)? In Figures 7 and 9, nCVaR  appears to be upper-bounded to 1. The upper limit of α is 1 by definition, but I have no idea why nCVaR was also bounded by 1. So I would like to ask the authors to add more detailed  explanations on nCVaR. Currently, CVaR is explained in Lines 237-243, but actually, there is  no explanation about nCVaR rather than its formal name 'nested conditional value at risk' in  Line 237.</p>
</disp-quote>
<p>Thank you for pointing out this error. We have corrected the paper to use nCVaR to refer to  the objective and nCVaR's α, or sometimes just α, to refer to the risk sensitivity parameter  and thus the degree of risk sensitivity.</p>
<disp-quote content-type="editor-comment">
<p>(3) Line 333 (and Abstract)</p>
<p>Given that animals' behaviors could be equally well fitted by the model having both nCVaR ( free α) and hazard prior and the alternative model having only hazard prior (with α = 1), may  it be difficult to confidently claim that brave (/timid) animals had risk-neutral (/risk-aversive)  preference in addition to widespread (/low-variance) hazard prior? Then, it might be good to  somewhat weaken the corresponding expression in the Abstract (e.g., add 'potentially also'  to the result for risk sensitivity) or mention the inseparability of risk sensitivity and prior belief  pessimism (e.g., &quot;... although risk sensitivity and prior belief pessimism could not be teased  apart&quot;).</p>
</disp-quote>
<p>Thank you for this suggestion, we have duly weakened the wording in the Abstract to say  “potentially more risk neutral”:</p>
<p>“Some animals begin with cautious exploration, and quickly transition to confident approach  to maximize exploration for reward; we classify them as potentially more risk neutral, and  enjoying a flexible hazard prior. By contrast, other animals only ever approach in a cautious  manner and display a form of  self-censoring; they are characterized by potential risk  aversion and high and inflexible hazard priors.”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Shen and Dayan build a Bayes adaptive Markov decision process model with three key  components: an adaptive hazard function capturing potential predation, an intrinsic reward  function providing the urge to explore, and a conditional value at risk (CvaR, closely related  to probability distortion explanations of risk traits). The model itself is very interesting and  has many strengths including considering different sources of risk preference in generating  behavior under uncertainty. I think this model will be useful to consider for those studying  approach/avoid behaviors in dynamic contexts.</p>
<p>The authors argue that the model explains behavior in a very simple and unconstrained  behavioral task in which animals are shown novel objects and retreat from them in various  manners (different body postures and patterns of motor chunks/syllables). The model itself  does capture lots of the key mouse behavioral variability (at least on average on a  mouse-by-mouse basis) which is interesting and potentially useful. However, the variables in  the model - and the internal states it implies the mice have during the behavior - are  relatively unconstrained given the wide range of explanations one can offer for the mouse  behavior in the original study (Akiti et al). This reviewer commends the authors on an original  and innovative expansion of existing models of animal behaviour, but recommends that the  authors  revise their study to reflect the obvious  challenges . I would also recommend a  reduction in claiming that this exercise gives a normative-like or at least quantitative account  of mental disorders.</p>
</disp-quote>
<p>We thank reviewer #2 for highlighting some of the strengths of our paper as well as pointing  out important limitations of Akiti et al’s original study which we’ve inherited as well as some  limitations of our own method. We address their concerns below.</p>
<p>We have added a paragraph to the discussion discussing the limitations of the state  representation we adopted from Akiti’s study.</p>
<p>(Reviewer #1 had the same concern, see above) “Motivated by tail-behind versus  tail-exposed in Akiti et al. (2022), we model approach using a dichotomy between cautious  and confident approach states [...]”</p>
<p>We have reduced the suggestion that our model provides an account of mental disorders in  the abstract.</p>
<p>Before:</p>
<p>“On the other hand, “timid” animals, characterized by risk aversion and high and inflexible  hazard priors, display self-censoring that leads to the sort of asymptotic maladaptive  behavior that is often associated with psychiatric illnesses such as anxiety and depression.”</p>
<p>After:</p>
<p>“By contrast, other animals only ever approach in a cautious manner and display a form of  self-censoring; they are characterized by potential risk aversion and high and inflexible  hazard priors. “</p>
<disp-quote content-type="editor-comment">
<p>My main comment is that this paper is a very nice model creation that can characterize the  heterogeneity rodent behavior in a very simple approach/avoid context (Akiti et al; when a  novel object is placed in an arena) that itself can be interpreted in a multitude of ways. The  use of terms like &quot;exploration&quot;, &quot;brave&quot;, etc in this context is tricky because the task does not  allow the original authors (Akiti et al) to quantify these &quot;internal states&quot; or &quot;traits&quot; with the  appropriate level of quantitative detail to say whether this model is correct or not in capturing  the internal states that result in the rodent behavior. That said, the original behavioral setup  is so simple that one could imagine capturing the behavioral variability in multiple ways ( potentially without evoking complex computations that the original authors never showed  the mouse brain performs). I would recommend reframing the paper as a new model that  proposes a set of internal states that could give rise to the behavioral heterogeneity  observed in Akiti et al, but nonetheless is at this time only a hypothesis. Furthermore, an  explanation of what would be really required to test this would be appreciated to make the  point clearer.</p>
</disp-quote>
<p>We thought very hard about using terms that might be considered to be anthropomorphic  such as ‘timid’ and ‘brave’. We are, of course, aware, of the concerns articulated by  investigators such as LeDoux about this. However, we think that, provided that we are clear  on the first appearance (using ‘scare’ quotes) that we are using them as indeed labels for  latent characteristics that capture correlations in various aspects of behaviour, they are more  helpful than harmful in making our descriptions understandable.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>Summary:</p>
<p>The manuscript presents computational modelling of the behaviour of mice during  encounters with novel and familiar objects, originally reported by Akiti et al. (Neuron 110, 2022)          . Mice typically perform short bouts of approach followed by a retreat to a safe  distance, presumably to balance exploration to discover possible rewards with the potential  risk of predation. However, there is considerable heterogeneity in this exploratory behaviour,  both across time as an individual subject becomes more confident in approaching the object,  and across subjects; with some mice rapidly becoming confident to closely explore the  object, while other timid mice never become fully confident that the object is safe. The  current work aims to explain both the dynamics of adaptation of individual animals over time,  and the quantitative and qualitative differences in behaviour between subjects, by modelling  their behaviour as arising from model-based planning in a Bayes adaptive Markov Decision  Process (BAMDP) framework, in which the subjects maintain and update probabilistic  estimates of the uncertain hazard presented by the object, and rationally balance the  potential reward from exploring the object with the potential risk of predation it presents.</p>
<p>In order to fit these complex models to the behaviour the authors necessarily make  substantial simplifying assumptions, including coarse-graining the exploratory behaviour into  phases quantified by a set of summary statistics related to the approach bouts of the animal.  Inter-individual variation between subjects is modelled both by differences in their prior  beliefs about the possible hazard presented by the object and by differences in their risk  preference, modelled using a conditional value at risk (CVaR) objective, which focuses the  subject's evaluation on different quantiles of the expected distribution of outcomes.  Interestingly these two conceptually different possible sources of inter-subject variation in  brave vs timid exploratory behaviour turn out not to be dissociable in the current dataset as  they can largely compensate for each other in their effects on the measured behaviour.  Nonetheless, the modelling captures a wide range of quantitative and qualitative differences  between subjects in the dynamics of how they explore the object, essentially through  differences in how subject's beliefs about the potential risk and reward presented by the  object evolve over the course of exploration, and are combined to drive behaviour.</p>
<p>Exploration in the face of risk is a ubiquitous feature of the decision-making problem faced  by organisms, with strong clinical relevance, yet remains poorly understood and  under-studied, making this work a timely and welcome addition to the literature.</p>
<p>Strengths:</p>
<p>(1) Individual differences in exploratory behaviour are an interesting, important, and  under-studied topic.</p>
<p>(2) Application of cutting-edge modelling methods to a rich behavioural dataset, successfully  accounting for diverse qualitative and qualitative features of the data in a normative  framework.</p>
<p>(3) Thoughtful discussion of the results in the context of prior literature.</p>
<p>Limitations:</p>
<p>(1) The model-fitting approach used of coarse-graining the behaviour into phases and fitting  to their summary statistics may not be applicable to exploratory behaviours in more complex  environments where coarse-graining is less straightforward.</p>
<p>(2) Some aspects of the work could be more usefully clarified within the manuscript.</p>
</disp-quote>
<p>We thank reviewer #3 for their positive feedback and helping us to improve the clarity of our  paper. We have added discussion they thought was missing.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations for the authors):</bold></p>
<p>(1) Line 25-28</p>
<p>This part of the Abstract might give an impression that timidity (but not braveness) is  potentially associated with psychiatric illness and even that timidity is thus inferior to  braveness. However, even though extreme timidity might indeed be associated with anxiety  or depression, extreme braveness could also be associated with other psychiatric or  behavioral problems. Moreover, as a population, the existence of both timid and brave  individuals could be advantageous, and it could be a reason why both types of individuals  evolutionarily survived in the case of wild animals (although Akiti et al. used mice, which may  have no or very limited genetic varieties, and so things may be different). So I would like to  encourage the authors to elaborate on the expression of this part of the Abstract and/or  enrich the related discussion in the Discussion.</p>
</disp-quote>
<p>This is an important point. We note on line 38 that excessive novelty seeking (potentially  caused by excessive braveness) could also be maladaptive.</p>
<p>Additionally, we have added a paragraph to the discussion discussing heterogeneity in risk  sensitivity within a population.</p>
<p>“Our data show that there is substantial variation in the degrees of risk sensitivity across the  mice.  Previous works have reported substantial interpopulation and intrapopulation  differences in risk-sensitivity in humans which depend on gender, age, socioeconomic  status, personality characteristics, wealth and culture (Rieger et al., 2015; Frey et al., 2017).  Despite the normative appeal of 𝛼 = 1, it is possible that a population may benefit from  including individuals with $\alpha$ different from 1.0 or highly negative priors. For example,  more cautious individuals could learn from merely observing the risky behavior of less  cautious individuals. Furthermore, we have only considered risk-sensitivity under epistemic  uncertainty in our work. Risk averse individuals, for instance with 𝛼 &lt; 1 may be more  successful than risk-neutral agents in environments where there are unexpected dangers ( unknown unknowns). Risk-aversion is thus a temperament of ecological and evolutionary  significance (Réale et al., 2007).”</p>
<disp-quote content-type="editor-comment">
<p>(2) Line 149</p>
<p>Section 2.2 consists of eight subsections. I think this organization may not be very  appealing, because there are a bit too many subsections, and their relations are not  immediately clear to readers. So I would like to encourage the authors to make an  elaboration. For example, since 2.2.1 - 2.2.5 describes a summary of model construction  and model fitting whereas 2.2.6-2.2.8 shows the results, it could be good to divide these into  separate sections (2.2.1 - 2.2.5 and 2.3.1 - 2.3.3).</p>
</disp-quote>
<p>Thank you for pointing this out. We’ve renumbered the sections as you’ve suggested.</p>
<disp-quote content-type="editor-comment">
<p>(3) Line 347-8</p>
<p>Theoretically, the effect of prior is diluted over experience whereas the effect of biased  (risk-aversive) evaluation persists, as the authors mentioned in Lines 393-394. Then isn't it  possible to consider environments/conditions in which the two effects can be separated?</p>
</disp-quote>
<p>We appreciate this suggestion. Indeed, our original thought in modeling this experiment was  that this would be exactly the case here - with epistemic uncertainty reducing as the object  became more familiar. However, proving to an animal that a single environment is  completely stationary/fixed is hard - reflected in our conclusion here that the exploration  bonus pool replenishes. Thus, we argued in the discussion that a series of environments  would be necessary to separate risk sensitivity from priors.</p>
<disp-quote content-type="editor-comment">
<p>(4) Line 407</p>
<p>It would be nice to add a brief phrase explaining how (in what sense) this model's  assumption was consistent with the reported behavior. Also, should the assumption of  having two discrete approach states (cautious and confident) itself be regarded as a  limitation of the model? If the tail-behind and tail-exposure approaches were not merely  operationally categorized but were indicated to be two qualitatively distinct behaviors in the  experiment by Akiti et al., it is reasonable to model them as two discrete states, but  otherwise, the assumption of two discrete states would need to be mentioned as a  simplification/limitation.</p>
</disp-quote>
<p>We have now removed line 407, and now have an additional  paragraph in the discussion  discussing the limitations of the tail-behind and tail-exposure state representation: “Motivated by tail-behind versus tail-exposed in Akiti et al. (2022), we model approach using  a dichotomy between cautious and confident approach states. This is likely a crude  approximation to the continuous and multifaceted nature of animal approach behavior. For  example, during approach animals likely adjust their levels of vigilance continuously (or  discretely; Lloyd and Dayan (2018)) to  monitor threat, and choose different velocities for  movement, and different attentional strategies for inspecting the novel object. We hope  future works will model these additional behavioral complexities, perhaps with additional  internal states, and corroborate these states with neurobiological data.”</p>
<disp-quote content-type="editor-comment">
<p>(5) Line 418</p>
<p>The authors contrasted their model-based analyses with the model-free analyses of Akiti et  al. Another aspect of differences between the authors' model and the model of Akiti et al. is  whether it is normative or mechanistic: while how the model of Akiti et al. can be biologically  implemented appears to be clear (TS dopamine represents threat TD error, and TS  dopamine-dependent cortico-striatal plasticity implements TD error-based update of  model-free threat prediction), biological implementation of the authors' model seems more  elusive. Given this, it might be a fruitful direction to explore how these two models can be  integrated in the future.</p>
</disp-quote>
<p>We enthusiastically agree that it would be most interesting in the future to explore the  integration of the two models - and, in the discussion ( Lines 537-548, 454-461) , point to  some first steps that might be fruitful along these lines. There are two separate  considerations here: one is that our account is mostly computational and algorithmic,  whereas Akiti’s model is mostly algorithmic and implementational; the second is, as noted by  the reviewer, that our account is model-based, whereas Akiti’s model is model-free (in the  sense of reinforcement learning; RL). These are related - thanks in no small part to the work  from the group including Akiti, we know a lot more about the implementation of model-free  than model-based RL. However, our model-based account does reach additional features of  behavior not captured in Akiti et al.’s model such as bout duration, frequency, and approach  type. Thus, the temptation of unification.</p>
<disp-quote content-type="editor-comment">
<p>(6) Line 426</p>
<p>Related to the previous point, it would be nice to more specifically describe what variable TS  dopamine can represent in the authors' model if possible.</p>
</disp-quote>
<p>In the discussion  (Lines 454-461) , we speculate that  TS dopamine could still respond to the  physical salience of the novel object and affect choices by determining the potential cost of  the encountered threat or the prior on the hazard function. For example, perhaps ablating TS  dopamine reduces the hazard priors which leads to faster transition from cautious to  confident approach and longer bout durations, consistent with the optogenetics behavioral  data reported in Akiti et al.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations for the authors):</bold></p>
<p>My guess is simpler versions of the model would not fit the data well. But this does not mean  for example that the mice have probability distortions (CvaR) or that even probabilistic  reasoning and the internal models necessary to support them are acting in the behavioral  context studied by Akiti. So related to the above, I would ask what other models would fit and  would not fit the data? And what does this mean?</p>
</disp-quote>
<p>These are good points. Our model provides an approximately normative account of the  animals’ behavior  in terms of what it achieves relative to a utility function. In practice, the  animals could deploy a precompiled model-free policy (which does not rely on probabilistic  computations) that is exactly equivalent to our model-based policy. With the current  experiment, we cannot conclude whether or not the animals are performing the prospective  calculations in an online manner. Of course, the extent to which animals or humans are  performing probabilistic computations online and have internal models are on-going  questions of study.</p>
<p>Model comparison is difficult because currently we do not know of any other risk-sensitive  exploration models. We cannot directly compare to the model in Akiti et al. since our model  explains additional features of behavior: bout duration, frequency, and approach type.  Indeed, our model is as simple as it can be in the sense with the exception of nCVaR,  removing any of the other parameters makes it difficult to fit some animals in our dataset. In the future, our model could be used to fit other datasets of risk-sensitive exploration and,  ideally,  be compared to other models.</p>
<disp-quote content-type="editor-comment">
<p>Explaining why animals avoid the novel object in what the offers call benign environment is a  very tricky issue. In Akiti et al, the readers are not yet convinced that the mice know that this  environment is benign. Being placed in an arena with a novel object presents mice with a  great uncertainty and we do not know whether they treat this as benign. Therefore, the  alternative explanations in this study need to be carefully discussed in lieu of the limitations  of the initial study.</p>
</disp-quote>
<p>It is certainly true that it is unclear if the arena is  completely  benign to the animals. However,  the amount of time the animal spends in the center of the arena decreases significantly from  habituation to novelty days. This suggests that the animals avoid the novel object largely  because of the object itself, rather than the potential danger associated with the arena.  Furthermore, the animals are not reported as exhibiting more extreme behaviours such as  freezing. In any case, our account is relative in the sense that we are comparing the time the  animal spends at the object versus elsewhere in the environment, driven by the relative  novelty and relative risk of the environment versus the object. Trying to get more absolute  measures of these quantities would require a richer experimental set-up, for instance with  different degree of habituation or experience of the occurrence of (other) novel objects, in  general.</p>
<p>We added a short note to the discussion to explain this:</p>
<p>“Fourth, we modeled the relative amount of time the animal spends at the object versus  elsewhere in the environment which depends on the differential risk in the two states.  However, it is likely the animals avoid the novel object largely because of the object itself,  rather than the potential danger associated with the arena since they spend much less time  at the center of the arena during novelty than habituation days.”</p>
<disp-quote content-type="editor-comment">
<p>Figure 2 - how confident are the authors that each mouse differs from y=1? Related to this,  the behavior in Akiti is very noisy and changes across time. I am not sure if the authors fully  describe at what levels their model captures the behavior vs not in a detailed enough  fashion.</p>
</disp-quote>
<p>We have performed a random permutation test on the minute-to-minute data. We have  updated Figure 2 so that brave animals that pass the Benjamini–Hochberg procedure y&gt;1 at  level q=0.05 are represented with solid green dots and animals that don’t pass are  represented with hollow dots. 8 out of 11 brave animals passed Benjamini–Hochberg.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations for the authors):</bold></p>
<p>(1) I could not find information in the preprint about code availability. Please consider making  the code public to help others apply these modelling methods.</p>
</disp-quote>
<p>We have released code and included the url in the paper in the Methods section.</p>
<disp-quote content-type="editor-comment">
<p>(2) Though the manuscript was generally clearly written, there were a number of places  where some additional information or clarification would be useful:</p>
<p>a) Please define and explain the terms 'tail-behind' and 'tail-exposed' (used to describe  approach bout types) when first used.</p>
</disp-quote>
<p>We have added definitions when we first mention these terms:</p>
<p>“[...] 'tail-behind' (bouts where the animal's nose was closer to the object than the tail for the  entire bout) and 'tail-exposed' (bouts where the animal's tail is closer to the object than the  nose at some point during the bout), associated respectively with cautious risk-assessment  and engagement”</p>
<disp-quote content-type="editor-comment">
<p>b) At lines 57-58 when contrasting the 'model-free' account of Akiti et al with the 'model-based' account of the current work, it would be worth clarifying that these terms are  being used in the RL sense rather than e.g. a model-based analysis of the data.</p>
</disp-quote>
<p>We have updated the relevant lines to say “model-free/based reinforcement learning”.</p>
<disp-quote content-type="editor-comment">
<p>c) Line 61, the phrase 'the significant long-run approach of timid animals despite having  reached the &quot;avoid&quot; state' is unclear as the 'avoid' state has not been defined.</p>
</disp-quote>
<p>We updated the terminology to “avoidance behavior” to be consistent with Akiti et al.  Avoidance refers to the animal routinely avoiding the object and therefore being unable to  learn whether it is safe.</p>
<disp-quote content-type="editor-comment">
<p>d) It was not completely clear to me how the coarse-graining of the behaviour was  implemented. Specifically, how were animals assigned to the brave, intermediate, or timid  group, and how were the parameters of the resulting behavioural phases fit?</p>
</disp-quote>
<p>Sorry that this was not clear. Section 2.1 explains how the minute-to-minute behavioral data  was coarse-grained and how animal groups were assigned. We have added further  explanation of Figure 2 to the main text:</p>
<p>“Fig 2 summarizes our categorization of the animals into the three groups: brave,  intermediate, and timid based on the phases identified in the animal's exploratory  trajectories. Timid animals spend no time in confident approach and are plotted in orange at  the origin of Fig 2. Brave animals differ from intermediate animals in that their approach time  during the first ten minutes of the confident phase is greater than the last ten minutes ( steady-state phase). Brave animals are plotted in green above and intermediate animals  are plotted in black below the y=1 line in Fig 2.”</p>
<p>We also added extra information to outline the goal, and methodology of coarse-graining and  animal grouping:</p>
<p>“We sought to capture  these qualitative differences (cautious versus confident) as well as  aspects of the quantitative changes in bout durations and frequencies as the animal learns  about their environment. To make this readily possible, we abstracted the data in two ways:</p>
<p>averaging  bout statistics over time, and clustering the animals into three groups with  operationally distinct behaviors.”</p>
<disp-quote content-type="editor-comment">
<p>e) What purpose does the 'retreat' state serve in the BAMDP model (as opposed to  transitioning directly from 'object' to 'nest' states), and why do subjects not pass through it  following 'detect' states?</p>
</disp-quote>
<p>Thank you for pointing this out. We have updated Figure 3 to note that the two “detected  states” also point to the “retreat” state. The reviewer is correct that there could be alternative  versions of the state diagram, and the ‘retreat’ state could indeed have been eliminated.  However, we thought that it was helpful to structure the animal’s progress through state  space.</p>
<disp-quote content-type="editor-comment">
<p>f) Why was the hazard function parameterised via the mean and SD at each time step rather  than with a parametric form of the mean and SD as a function of time?</p>
</disp-quote>
<p>Since the agent can only spend 2, 3, or 4 turns at the object states, we didn’t see a need to  parameterize the mean and SD as a function of time. Doing so is a good solution to scaling  up the hazard function to more time-steps.</p>
<disp-quote content-type="editor-comment">
<p>(3) There were also a couple of points that could potentially be usefully touched on in the  discussion:</p>
<p>a) What, if any, is the relationship between the CVaR objective and distributional RL? They  seem potentially related due to both focussing on quantiles of the outcome distribution.</p>
</disp-quote>
<p>We have added a paragraph to the discussion discussing the connection between  distributional RL and CVaR:</p>
<p>“CVaR is known to come in different flavors in the case of temporally-extended behavior.  Gagne and Dayan (2021) introduces two alternative time-consistent formulations of CVaR:  nested CVaR (nCVaR) and precommitted CVaR (pCVaR). nCVaR and pCVaR both enjoy  Bellman equations which make it possible to compute approximately optimal policies without  directly computing whole distributions of the outcomes. We use nCVaR in this study for its  computational efficiency. There is, of course, great current interest in distributional  reinforcement learning (Bellemare et al., 2023b) which does acquire such whole  distributions, not the least because of prominent observations linking non-linearities in the  response functions of dopamine neurons to methods for learning distributions of outcomes ( Dabney et al., 2020; Masset et al., 2023; Sousa et al., 2023). One functional motivation for  considering entire outcome distributions is the possibility of using them to determine  risk-sensitive policies (Gagne and Dayan, 2021).</p>
<p>While it is possible to compute CVaR directly from return distributions, Gagne and Dayan  (2021) showed that this can lead to temporally inconsistent policies where the agent  deviates from its original plans (the authors called this the fixed CVaR or fCVaR measure).</p>
<p>Rather further removed from our model-based methods is work from Antonov and Dayan  (2023), who consider a model-free exploration strategy which exploits full return distributions  to compute the value of perfect information which is used as a heuristic for trying actions  with uncertain consequences. Future works can examine risk-sensitive versions of Antonov  and Dayan (2023)'s computationally efficient model-free algorithm as one solution to the  burdensome computations in our model-based method.”</p>
<disp-quote content-type="editor-comment">
<p>b) Why normatively might subjects have non-neutral risk preference as captured by the  CvaR?</p>
</disp-quote>
<p>We also added a paragraph to the discussion discussing the advantage of heterogeneity in  risk sensitivity within a population:</p>
<p>(Reviewer #1 had the same question, see above) “Our data show that there is substantial  variation in the degrees of risk sensitivity across the mice.  Previous works have reported  substantial interpopulation and intrapopulation differences in risk-sensitivity in humans which  depend on gender, age, socioeconomic status, personality characteristics, wealth and culture [...]”</p>
<disp-quote content-type="editor-comment">
<p>c) Relevance of the current modelling work to clinical conditions characterised by  dysregulation of risk assesment (e.g. anxiety or PTSD).</p>
</disp-quote>
<p>We’ve added a paragraph to the discussion:</p>
<p>“Inter-individual differences in risk sensitivity are also of critical importance in psychiatry,  reflected in a panoply of anxiety disorders (Butler and Mathews, 1983; Giorgetta et al., 2012;  Maner et al., 2007; Charpentier et al., 2017), along with worry and rumination (Gagne and  Dayan, 2022). Understanding the spectrum of   extreme priors and extreme values of 𝛼  could have therapeutic implications, adding significance to the search for tasks that can  more cleanly separate them.”</p>
<disp-quote content-type="editor-comment">
<p>d) Is it surprising to see differences in risk preference (nCVaR) between the familiar object  and novel object condition, given that risk preference might be conceptualised as a trait  rather than a state variable?</p>
</disp-quote>
<p>Thank you for raising this point. You are right that we expected risk sensitivity (nCVaR alpha)  to be the same between FONC and UONC animals on average. It is difficult to know if alpha  is higher for FONC than UONC animals due to the non-identifiability between alpha and  hazard priors. We have added this discussion to the paper:</p>
<p>“This is surprising if we interpret 𝛼 as a trait that is stable through time. Unfortunately, due to  the non-identifiability between 𝛼 and hazard priors, we cannot verify whether 𝛼 is actually  higher for FONC animals than UONC animals.”</p>
</body>
</sub-article>
</article>