<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">89369</article-id>
<article-id pub-id-type="doi">10.7554/eLife.89369</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89369.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A cortical information bottleneck during decision-making</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4643-538X</contrib-id>
<name>
<surname>Kleinman</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Tian</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xiao</surname>
<given-names>Derek</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Feghhi</surname>
<given-names>Ebrahim</given-names>
</name>
<xref ref-type="aff" rid="a6">f</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lee</surname>
<given-names>Kenji</given-names>
</name>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Carr</surname>
<given-names>Nicole</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Yuke</given-names>
</name>
<xref ref-type="aff" rid="a5">e</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hadidi</surname>
<given-names>Nima</given-names>
</name>
<xref ref-type="aff" rid="a6">f</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chandrasekaran</surname>
<given-names>Chandramouli</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="aff" rid="a3">c</xref>
<xref ref-type="aff" rid="a4">d</xref>
<xref ref-type="aff" rid="a5">e</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kao</surname>
<given-names>Jonathan C.</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a6">f</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<aff id="a1"><label>a</label><institution>Department of Electrical and Computer Engineering, University of California</institution>, Los Angeles, CA, <country>USA</country></aff>
<aff id="a2"><label>b</label><institution>Department of Anatomy &amp; Neurobiology, Boston University School of Medicine</institution>, Boston, MA, <country>USA</country></aff>
<aff id="a3"><label>c</label><institution>Department of Psychological and Brain Sciences, Boston University</institution>, Boston, MA, <country>USA</country></aff>
<aff id="a4"><label>d</label><institution>Center for Systems Neuroscience, Boston University</institution>, Boston, MA, <country>USA</country></aff>
<aff id="a5"><label>e</label><institution>Department of Biomedical Engineering, Boston University</institution>, Boston, MA, <country>USA</country></aff>
<aff id="a6"><label>f</label><institution>Neurosciences Program, University of California</institution>, Los Angeles, CA, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ostojic</surname>
<given-names>Srdjan</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>École Normale Supérieure - PSL</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding author; email: <email>michael.kleinman@ucla.edu</email></corresp>
<fn id="n1" fn-type="others"><label>*</label><p>Joint senior authors</p></fn>
<fn id="n2" fn-type="others"><p><italic>Email addresses:</italic> <email>michael.kleinman@ucla.edu</email> (Michael Kleinman), <email>cchandr1@bu.edu</email> (Chandramouli Chandrasekaran), <email>kao@seas.ucla.edu</email> (Jonathan C. Kao)</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-09-19">
<day>19</day>
<month>09</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP89369</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-06-16">
<day>16</day>
<month>06</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-07-14">
<day>14</day>
<month>07</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.12.548742"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Kleinman et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Kleinman et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-89369-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Decision-making emerges from distributed computations across multiple brain areas, but it is unclear <italic>why</italic> the brain distributes the computation. In deep learning, artificial neural networks use multiple areas (or layers) to form optimal representations of task inputs. These optimal representations are <italic>sufficient</italic> to perform the task well, but <italic>minimal</italic> so they are invariant to other irrelevant variables. We recorded single neurons and multiunits in dorsolateral prefrontal cortex (DLPFC) and dorsal premotor cortex (PMd) in monkeys during a perceptual decision-making task. We found that while DLPFC represents task-related inputs required to compute the choice, the downstream PMd contains a minimal sufficient, or optimal, representation of the choice. To identify a mechanism for how cortex may form these optimal representations, we trained a multi-area recurrent neural network (RNN) to perform the task. Remarkably, DLPFC and PMd resembling representations emerged in the early and late areas of the multi-area RNN, respectively. The DLPFC-resembling area partially orthogonalized choice information and task inputs and this choice information was preferentially propagated to downstream areas through selective alignment with inter-area connections, while remaining task information was not. Our results suggest that cortex uses multi-area computation to form minimal sufficient representations by preferential propagation of relevant information between areas.</p></abstract>
<abstract>
<title>Significance</title>
<p>The brain uses multiple areas for cognition, decision-making, and action, but it is unclear why the brain distributes the computation and why cortical activity differs by brain area. Machine learning and information theory suggests that one benefit of multiple areas is that it provides an “information bottleneck” that compresses inputs into an optimal representation that is minimal and sufficient to solve the task. Combining experimental recordings from behaving animals and computational simulations, we show that later brain areas have a tendency to form such minimal sufficient representations of task inputs through preferential propagation of task-relevant information present in earlier areas. Our results thus provide insight into why the brain uses multiple brain areas for supporting decision-making and action.</p></abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Information Bottleneck</kwd>
<kwd>Decision-making</kwd>
<kwd>Recurrent Neural Networks (RNNs)</kwd>
<kwd>Multiple Brain Areas</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The brain uses multiple areas to perform cognitive functions and tasks, including decision-making, multisensory integration, attention, motor control, and timing<sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c10">10</xref></sup>. But why distribute computation across multiple areas? One reason is that distributed computation supports important fault tolerance in the brain which allows it to compensate when dynamics in relevant areas are altered<sup><xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c14">14</xref></sup>. But is there also a computational benefit for distributing computations across multiple areas? In deep learning for computer vision, deeper artificial neural networks (ANNs) generally perform better and exhibit hierarchical computation, a phenomenon also observed in the visual cortex, where early layers of the neural network form representations that contain low-level details (e.g., edges) and deeper layers represent higher-level concepts (e.g., object identity) <sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c16">16</xref></sup>. This hierarchical computation is related to the idea of an information bottleneck: downstream areas should form representations that remove irrelevant information not necessary to do the task. For example, to know an image of a dog is a dog, we do not need to store every pixel of the image.</p>
<p>We unpack this more formally by first asking: what makes a representation optimal? Consider the binary classification task in <xref rid="fig1" ref-type="fig">Fig. 1a</xref>, where the task <italic>Y</italic> is to answer if an image, <bold>x</bold>, is a dog. The data processing inequality (DPI) states that any <italic>representation</italic> of the original image, <bold>z</bold> = <italic>f</italic> (<bold>x</bold>), where <italic>f</italic> is a function or transformation, cannot contain more information than the image itself<sup><xref ref-type="bibr" rid="c17">17</xref></sup>. Rather, a representation <bold>z</bold> will often contain less information, so that the information between random variables <bold>Z</bold> and <bold>X</bold>, denoted <italic>I</italic>(<bold>Z</bold>; <bold>X</bold>), decreases through successive transformations. This is illustrated in <xref rid="fig1" ref-type="fig">Fig. 1a</xref>, where different transformations of the original image decrease the mutual information <italic>I</italic>(<bold>Z</bold>; <bold>X</bold>) in the representation. But the task information contained in the representation, <italic>I</italic>(<bold>Z</bold>; <italic>Y</italic>), is similar, since all images can be used to correctly answer “is this a dog?” (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Optimal representations are formed through an information bottleneck.</title>
<p><bold>(a)</bold> Consider the task <italic>Y</italic> of discerning whether the image is of a dog. Images to the right have less information than the original image (<italic>I</italic>(<bold>Z</bold>; <bold>X</bold>) is smaller) but still contain approximately the same amount of information, <italic>I</italic>(<bold>Z</bold>; <italic>Y</italic>) to perform the task: “is this a dog?” <bold>(b)</bold> The information bottleneck trades off minimality, <italic>I</italic>(<bold>Z</bold>; <bold>X</bold>) as small as possible, with sufficiency, <italic>I</italic>(<bold>Z</bold>; <italic>Y</italic>) ≈ <italic>I</italic>(<bold>X</bold>; <italic>Y</italic>). <bold>(c)</bold> Checkerboard task. The monkey reaches to the target whose color matches the checkerboard dominant color. Because there are two equally likely target configurations where the color of the left and right targets are swapped, this task unmixes the color and direction choice. <bold>(d)</bold> A minimal sufficient representation of this task is to only retain the direction decision, in this case, reach left. A cortical information bottleneck should therefore only find direction choice information in premotor and motor output areas.</p></caption>
<graphic xlink:href="548742v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The information bottleneck principle defines an optimal representation to be one that retains only the relevant or useful information for solving a task<sup><xref ref-type="bibr" rid="c18">18</xref></sup>. When a representation that is <italic>sufficient</italic> for solving the task (mathematically, <italic>I</italic>(<bold>Z</bold>; <italic>Y</italic>) ≈ <italic>I</italic>(<bold>X</bold>; <italic>Y</italic>)) is also <italic>minimal</italic> (mathematically, <italic>I</italic>(<bold>Z</bold>; <bold>X</bold>) as small as possible), machine learning theory proves these representations are the most robust to nuisances (such as the color of the dog or the background)<sup><xref ref-type="bibr" rid="c19">19</xref></sup>. In general, multi-area computation increases the minimality of a representation due to the data processing inequality: so long as these representations maintain the information to solve the task and are trainable, the <italic>deep</italic> multi-area computation produces more optimal representations for solving tasks. Although these representations contain less information than the input, they are often more useful and robust representations for solving the task<sup><xref ref-type="bibr" rid="c19">19</xref>–<xref ref-type="bibr" rid="c21">21</xref></sup>. Typically, these neural networks are not explicitly trained to optimize an information bottleneck objective<sup><xref ref-type="bibr" rid="c22">22</xref></sup>. However, recent studies<sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref></sup> showed that training ANNs with stochastic gradient descent implicitly minimizes an information bottleneck objective that results in minimal sufficient representations.</p>
<p>We hypothesized multiple areas in the brain provides a similar <italic>computational benefit</italic> by forming minimal sufficient representations of the task inputs, thus implementing a cortical information bottleneck. We tested this hypothesis by combining electrophysiological recordings in behaving monkeys, and modeling using recurrent neural networks. We recorded from the DLPFC and PMd as monkeys performed a decision-making task called the Checkerboard Task (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>). In this task, the monkey discriminated the dominant color of a checkerboard composed of red and green squares and reached to a target matching the dominant color. Because the red and green target locations were randomly assigned to be left or right on each trial (“target configuration”), the direction decision is independent of the color decision. That is, a green color decision is equally likely to correspond to a left or right decision.</p>
<p>The animal’s behavioral report was either a right or left reach, determined after combining the sensory evidence with the target configuration (<xref rid="fig1" ref-type="fig">Fig. 1d</xref>). While color is initially needed to solve the task, the minimal sufficient representation of the task to generate the correct output is a representation of only the direction decision without the color decision or the target configuration. A cortical information bottleneck would therefore predict that upstream areas should contain information about the task inputs and decision-making process, including the target configuration, perceived dominant color of the checkerboard, and direction choice, while downstream areas should only contain the direction choice (in <xref rid="fig1" ref-type="fig">Fig. 1d</xref>, “reach left”).</p>
<p>Consistent with the predictions of the information bottleneck principle, we found that DLPFC has information about the color, target configuration, and direction. In contrast, PMd had little to no information about target configuration and color, but strongly represented the direction choice. PMd therefore had a <italic>minimal and sufficient representation</italic> of direction. We then trained a multi-area RNN to perform this task. We found that the RNN faithfully reproduced DLPFC and PMd activity, enabling us to propose a mechanism for how cortex uses multiple areas to compute a minimal sufficient representation.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The checkerboard task involves multiple brain areas</title>
<p>We trained monkeys to discriminate the dominant color of a central static checkerboard (15 × 15 grid) composed of red and green squares (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>). The number of red and green squares was random on each trial, leading to different levels of discrimination difficulty. The signed color coherence linearly indicates the degree to which color is dominant in the checkerboard, with − 1 corresponding to completely green, 0 to equal numbers of red and green squares, and +1 to completely red. If the monkey reached to the target matching the dominant checkerboard color, the trial was counted as a success and the monkey received a juice reward. Critically, the color decision (red or green) was decoupled from the direction decision (left or right) because the left and right target identities were random on every trial. <xref rid="fig2" ref-type="fig">Fig. 2a,b</xref> shows the monkey’s psychometric and reaction time (RT) behavior on this task. Monkeys made more errors and reacted more slowly for more ambiguous checkerboards compared to the almost completely red or completely green checkerboards<sup><xref ref-type="bibr" rid="c23">23</xref></sup>.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>DLPFC and PMd recordings during the checkerboard task.</title>
<p><bold>(a)</bold> Psychometric and <bold>(b)</bold> reaction time curves of the monkey. X-axes in both (a) and (b) depict signed coherence which indicates the relative amount of red vs. green in the checkerboard. <bold>(c)</bold> Example DLPFC and <bold>(d)</bold> PMd PSTHs aligned to checkerboard onset. Red and green traces correspond to red and green color choices, respectively. Dotted and solid traces correspond to right and left direction choices, respectively. Data are smoothed with a 25 ms Gaussian and averaged across trials. <bold>(e)</bold> PCs 1, 3, and 4 for DLPFC and <bold>(f)</bold> PCs 1,2,3 for PMd. <bold>(g)</bold> Results of dPCA analysis for DLPFC and <bold>(h)</bold> PMd showing the dPCs for direction, target configuration, and color. <bold>(i)</bold> Histogram (across sessions) of direction, color, and target configuration decode accuracy and <bold>(j)</bold> usable information for DLPFC and PMd. The large variance in recordings is due to across-session variance.</p></caption>
<graphic xlink:href="548742v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We used linear multi-contact electrodes (U and V-probes) to record from the DLPFC (2819 single neurons and multiunits) and PMd (996 single neurons and multi units) as the monkeys performed these tasks. Sample peri-stimulus time histograms (PSTHs) for neurons in DLPFC and PMd are shown in <xref rid="fig2" ref-type="fig">Fig. 2c, d</xref>, respectively, where solid (dotted) lines correspond to left (right) reaches and color (red or green) denotes the color decision. DLPFC PSTHs in <xref rid="fig2" ref-type="fig">Fig. 2c</xref> separate based on direction choice, target configuration, and color choice, whereas PMd PSTHs primarily separate based on the direction choice, and only very modestly with target configuration or color.</p>
<p>Together, these examples demonstrate that DLPFC and PMd single units exhibit activity reflecting the decision-making process, implicating multiple brain areas in decision-making. Further, DLPFC likely contains multiple task-relevant signals signals, whereas PMd contains only direction choice related signals necessary for the behavioral report in the task. In the next sections, we use dimensionality reduction, decoding, and information theory to quantify the extent of color, target configuration, and direction representations in DLPFC and PMd at the population level <italic>and show that these physiological observations are consistent with the information bottleneck principle</italic>. We then use recurrent neural network models to build a mechanistic hypothesis for how an information bottleneck could be implemented.</p>
</sec>
<sec id="s2b">
<title>Evidence for a cortical information bottleneck between DLPFC and PMd</title>
<p>Our single neuron examples suggest that neuronal responses in DLPFC are modulated by color choice and target configuration, but PMd neurons generally are not. Our hypothesis is that these cortical representations in DLPFC and PMd are consistent with the information bottleneck principle. The direct prediction of this hypothesis is that the PMd population activity should contain a minimal and sufficient representation of the behaviorally relevant output – the direction choice – while upstream DLPFC population activity should represent multiple task-relevant variables.</p>
<p>To study this at the population level, we performed principal components analysis (PCA) on DLPFC and PMd neural population activity. In these PCA trajectories, we subtracted the condition-independent component of the signal to better highlight representations of direction, target configuration, and color. DLPFC and PMd exhibited qualitatively different neural population trajectories (<xref rid="fig2" ref-type="fig">Fig. 2e,f</xref>). First, after target onset, DLPFC trajectories separated as a function of the two target configurations, and at the time of checkerboard onset (purple dots), DLPFC activity further separated into four distinct trajectories based on the four possible color × direction outcomes (green left, green right, red left, red right, <xref rid="fig2" ref-type="fig">Fig. 2e</xref>). Thus, DLPFC contains information about target configuration, color choice, and direction choice. Note, we chose PC 1, 2 and 4 of DLPFC as they provided a better visualization of target configuration signal between target and checkerboard. In contrast, PMd trajectories in <xref rid="fig2" ref-type="fig">Fig. 2f</xref> did not exhibit target-configuration-specific steady state responses. Thus, at the point of checkerboard onset (purple dots), trajectories overlapped in the top 3 principal components, and only separated based on the direction, but not color, choice.</p>
<p>To quantify these these differences, we performed demixed principal component analysis (dPCA) on the DLPFC and PMd population activity (<xref rid="fig2" ref-type="fig">Fig. 2g,h</xref>). DLPFC and PMd activity both exhibited strong condition independent activity (82% and 86% variance, respectively). DLPFC activity represented the target configuration, but PMd did not (<xref rid="fig2" ref-type="fig">Fig. 2g,h</xref>, target configuration dPC). dPCA also identified principal axes that maximized variance related to the direction choice, color choice, and target configuration. In DLPFC, the top direction choice, color choice, and target configuration axes captured 7.1%, 1.5%, and 0.9% of the population activity. In PMd, these values were 10.6%, 0.2%, and 0.2%. Across all direction, color, and target configuration axes, the dPCA variance captured for DLPFC was 11%, 3%, 5%, while for PMd it was 12%, 1%, 1%. This dPCA analysis provides further evidence that DLPFC represents direction, target configuration, and color while PMd has nearly minimal representations of color and target configuration, consistent with the information bottleneck principle.</p>
<p>Our dPCA results with trial-averaged firing rates suggest that axes associated with color and target configuration in PMd have very little variance associated with them. However, these results do not rule out the possibility that there is decodable information about these task-related variables on single trials. We performed two other analyses to assess if there is an information bottleneck and that PMd contains a minimal sufficient representation. We calculated the decode accuracy and an estimate of mutual information for direction, color, and target configuration in DLPFC and PMd population activity. We decoded direction, color, and target configuration from DLPFC and PMd sessions where we recorded a small population of neurons using a support vector machine (see Methods). To estimate mutual information, we quantified the Usable Information, a variational lower bound to mutual information that can be computed on high-dimensional data through estimating cross-entropy loss<sup><xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c21">21</xref></sup> (see Methods).</p>
<p>We found that for many DLPFC sessions we could reliably decode direction, color, and target configuration well above chance (histogram in <xref rid="fig2" ref-type="fig">Fig. 2i</xref>, mean decoding accuracy across sessions: direction 85%, target configuration 59%, color 57%, for details on decoding, see Methods). To conservatively assess significance, we shuffled the trials for each session 100 times and obtained a surrogate decoding accuracy for each session, and then tested if the true accuracy was greater than the 99<sup>th</sup> percentile of the shuffled accuracy distribution (Wilcoxon Sign Rank test: p &lt; 0.005 for target configuration, color, and direction choice). In DLPFC, we could therefore significantly decode direction choice, target configuration, and color choice. In contrast in PMd, we rarely found sessions where target configuration and color could be reliably decoded well above chance (mean accuracy across sessions: direction 87%, target configuration 52%, color 51%), as shown in <xref rid="fig2" ref-type="fig">Fig. 2i</xref>. Again, we compared the true decode accuracy to a surrogate decoding accuracy obtained by shuffling the trials. We found that only direction could be decoded well above chance (Wilcoxon sign-rank test: direction choice p &lt; 0.005, p = 0.99 for both target configuration and color choice). The differences in mean decoding accuracy in DLPFC and PMd were significant for only color and target configuration (<italic>p &lt;</italic> 0.001, ranksum test), but not direction (<italic>p</italic> = 0.208, ranksum test). Thus, both DLPFC and PMd contain signifcantly more direction information but DLPFC contains more color choice and target configuration information consistent with the information bottleneck principle.</p>
<p>We also quantified usable information for DLPFC and PMd (<xref rid="fig2" ref-type="fig">Fig. 2j</xref>). For this analysis, we restricted it to sessions with significant decode accuracy with a session considered to have a significant decodability for a variable if the true accuracy was above the 99<sup>th</sup> percentile of the shuffled accuracy for a session. DLPFC had sessions with non-zero usable information for direction, color, and target configuration (average direction information: 0.56 bits, target configuration: 0.07 bits, color: 0.06 bits; 100%, 78%, 53% sessions above 99 percentile of shuffled accuracy, respectively) while PMd only had non-zero usable information for direction (average direction information: 0.64 bits, target configuration: 0.013 bits, color: 0.005-bits; 98%, 26%, 20% sessions above 99 percentile of shuffled accuracy, respectively). The differences in usable information in DLPFC and PMd were also significant for only color and target configuration (<italic>p &lt;</italic> 0.001, ranksum test), but not direction (<italic>p</italic> = 0.107, ranksum test). Together, these results indicate that PMd had a more minimal representation of task inputs, particularly color and target configuration, than DLPFC.</p>
<p>Our dPCA and decoding results are consistent with the existence of a cortical information bottleneck between DLPFC and PMd that reduces the amount of target configuration and color information in PMd while preserving the direction choice information necessary to solve the task. We next modeled this multi-area information bottleneck to develop a mechanistic hypothesis for how this cortical information bottleneck could be computationally implemented.</p>
</sec>
<sec id="s2c">
<title>A multi-area recurrent neural network model of DLPFC and PMd</title>
<p>To develop a mechanistic hypothesis for this cortical information bottleneck, we studied our previously reported multi-area RNN to perform the Checkerboard task (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>)<sup><xref ref-type="bibr" rid="c24">24</xref></sup>. We chose to use this multi-area RNN because prior work demonstrated this RNN, like our PMd data, has a minimal color representation in Area 3. The RNN had 3 areas, obeyed Dale’s law<sup><xref ref-type="bibr" rid="c25">25</xref></sup>, and had approximately 10% feedforward and 5% feedback connections between areas based on projections between prefrontal and premotor cortex in a macaque atlas<sup><xref ref-type="bibr" rid="c26">26</xref></sup>. RNN psychometric and RT curves for the multi-area RNN exhibited similar behavior to monkeys performing this task (<xref rid="fig3" ref-type="fig">Fig. 3b,c</xref>; across several RNNs, see <xref rid="figS1" ref-type="fig">Fig. S1</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>RNN modeling of the CB task.</title>
<p><bold>(a)</bold> Multi-area RNN configuration. The RNN received 4 inputs. The first two inputs indicated the identity of the left and right targets, which was red or green. These inputs were noiseless. The last two inputs indicated the value of the signed color coherence (proportional to amount of red in checkerboard) and negative signed color coherence (proportional to amount of green in checkerboard). We added independent Gaussian noise to these signals (see Methods). The network outputted two analog decision variables indicating evidence towards the right target (solid line) or left target (dashed line). A decision was made in the direction of whichever decision variable passed a preset threshold (0.6) first. The time at which the decision variable passed the threshold was defined to be the reaction time. <bold>(b</bold>,<bold>c)</bold> Psychometric and reaction time curves for exemplar multi-area RNN. <bold>(d)</bold> Area 1 and Area 3 principal components for exemplar RNN. <bold>(e)</bold> CCA correlation between each area and DLPFC principal components (left) and PMd principal components (right). DLPFC activity most strongly resembles Area 1, while PMd activity most strongly resembles Area 3. See also Fig. S3 where we computed CCA as a function of the number of dimensions. <bold>(f)</bold> Relative dPCA variance captured by the direction, color, and target configuration axes. Normalization makes direction variance equal to 1. Area 1 (3) variances more closely resemble DLPFC (PMd). <bold>(g)</bold> Area 1 has significantly higher decoding accuracies and <bold>(h)</bold> usable information compared to Area 3, consistent with DLPFC and PMd.</p></caption>
<graphic xlink:href="548742v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Remarkably, even though the multi-area RNN was in no way regularized to reproduce DLPFC and PMd activity, activity in Area 1 resembled neural responses in DLPFC and Area 3 resembled PMd (<xref rid="fig3" ref-type="fig">Fig. 3d,e</xref>). Like DLPFC, Area 1 had four distinct trajectories corresponding to the four possible task outcomes and represented target configuration, direction choice, and color choice (<xref rid="fig3" ref-type="fig">Fig. 3d</xref> and see <xref rid="figS2" ref-type="fig">Fig. S2</xref>). In contrast, Area 3 population trajectories primarily separated based on direction and not by target configuration or color — remarkably similar to the trajectories observed in PMd.</p>
<p>We performed CCA to assess the similarity between the empirical neural trajectories to each RNN area’s neural trajectories (see Methods). The CCA analysis suggested that Area 1 exhibited the strongest resemblance to DLPFC, while Area 3 most strongly resembled PMd activity (<xref rid="fig3" ref-type="fig">Fig. 3e</xref>). These results show that a multi-area RNN reproduced similar behavior to the monkey, and further that it did so with architecturally and qualitatively distinct areas that strongly resembled the physically distinct DLPFC and PMd cortical areas.</p>
<p>The RNN activity differs from cortical activity in two important ways. First, RNNs generally had a significantly smaller variance condition-independent signal (46.7% and 49.4% average variance in Area 1, and 3, respectively) than in DLPFC and PMd (82% and 86% variance, respectively). One possible explanation is that condition-independent variance in PMd is associated with a trigger signal, likely from the thalamus<sup><xref ref-type="bibr" rid="c27">27</xref></sup>, and these RNNs do not output arm kinematics, forces, or electromyography (EMG).</p>
<p>Similarly, in DLPFC, we did not explicitly model the target and checkerboard inputs to have large onset signals that are often associated with visual stimulation. This significant condition independent variance in the neurophysiological data may therefore make decoding more difficult since there is relatively lower variance representing direction, color, or target configuration. While our CCA analysis was performed with the condition-independent signal removed, this difference impacts both dPCA and decoding results. In general, we found that RNN exhibited trends observed in the neurophysiological data more strongly, including more variance captured for direction, color, and target configuration, as well as higher decoding accuracies. We therefore compared the relative, rather than absolute, trends in RNN activity and DLPFC for dPCA and decoding analyses for the purposes of identifying a RNN information bottleneck similar to the cortical information bottleneck.</p>
<p>We found that the 3-area RNN exhibited similar trends to DLPFC and PMd activity in dPCA variance and decoding accuracy. When comparing only the top axis for direction, color, and target configuration, DLPFC activity had relatively large variance captured along the direction axis (7.1% variance captured), followed by relatively weaker representations for target configuration (1.5%) and color (0.9%). Area 1 activity had similar relative trends, with the direction axis explaining 30.9% variance, followed by target configuration (13.3%) and color (5.6%). In <xref rid="fig3" ref-type="fig">Fig. 3f</xref>, we show the similarity in relative trends in DLPFC and Area 1 by normalizing these quantities by the variance captured by the direction axis. Meanwhile, PMd activity exhibited more direction-related variance than DLPFC (10.6% variance captured) and did not exhibit a significant target configuration and color axis representation (0.2% for both axes).</p>
<p>Likewise, Area 3 had a stronger representation of direction (48.5% variance captured) than in Area 1, but negligible target configuration and color axes variance (0.1% for both axes), demonstrating the same relative trend (<xref rid="fig3" ref-type="fig">Fig. 3f</xref>). These results show that Area 1 more strongly resembles DLPFC and Area 3 more strongly resembles PMd in relative dPCA variance.</p>
<p>We next evaluated the decode accuracy and usable information in the multi-area RNN. We found Area 1, like DLPFC, had significant information for direction, target configuration, and color. Direction, color, and target configuration could be decoded from Area 1 population activity at accuracies of 94.4%, 93.4%, and 99.0%, respectively, corresponding to 0.81, 0.79, and 0.92 bits of usable information (<xref rid="fig3" ref-type="fig">Fig. 3g,h</xref>). In contrast, Area 3 direction decode accuracy was 99.4%, while color and target configuration accuracy were significantly lower (51.1% and 54.3%, respectively). This corresponded to 0.97, 0.0023, and 0.0078 bits of usable information for direction, target configuration, and color, respectively.</p>
<p>Together, these results show that our multi-area RNN exhibited distinct areas that resembled DLPFC and PMd activity, and also implemented an information bottleneck so that its output area only had primarily direction information and less color and target configuration information. This multi-area RNN therefore implements a candidate mechanism for how a cortical information bottleneck could be implemented between DLPFC and PMd.</p>
</sec>
<sec id="s2d">
<title>Mechanistic features of the DLPFC and PMd bottleneck: partial orthogonalization and selective propagation</title>
<p>The multi-area RNN contains representations consistent with the information bottleneck principle — its input and output areas resemble DLPFC and PMd. The RNN therefore models many aspects of our physiological data and is therefore a candidate system to understand how multiple areas could lead to the empirically observed minimal sufficient representations. The unique advantage of the RNN is that we know the firing rates in each area as well as the within and inter-areal connections, which allows us to investigate how the multi-area RNN deemphasizes color information through an IB. We reasoned that such an information bottleneck could be implemented in three ways: Color information may be (1) primarily attenuated through <italic>recurrent neural dynamics</italic>, (2) primarily attenuated through <italic>inter-areal connections</italic>, or (3) attenuated through a combination of recurrent dynamics and inter-areal connections. This is illustrated in <xref rid="fig4" ref-type="fig">Fig. 4a</xref>.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>IB hypotheses and mechanism.</title>
<p><bold>(a)</bold> Candidate mechanisms for IB. <bold>(b)</bold> Axes overlap of the direction, color, and target configuration axes for DLPFC and RNN data. The direction axis is more orthogonal to the color and target configuration axes. <bold>(c)</bold> Projections onto the potent space of the intra-areal dynamics for each area. We computed the potent projection of the direction axis, color axis, and a random vector with each area’s intra-areal dynamics matrix. We found intra-areal dynamics amplify color information in Area 1, and do not selectively attenuate color information in Areas 2 and 3. <bold>(d)</bold> Illustration depicting how the orientation of the axes affect information propagation. Information on the direction axis (orange) can be selectively propagated through inter-areal connections which information on the color axis (maroon) is not. <bold>(e)</bold> Inter-areal hypotheses. <bold>(f)</bold> Projections onto the potent space between areas for the color axis, direction axis, and random vector. Regardless of the dimension of the potent space, the direction axis is preferentially aligned with the potent space, indicating the information along this axis propagates, while the color axis is approximately randomly aligned. We emphasize the high alignment of the direction axis: the direction axis has a stronger alignment onto the first potent dimension of <bold>W</bold><sub>21</sub> than the remaining dimensions combined. Meanwhile, the color axis is aligned at nearly chance levels, and will therefore be propagated significantly less than the direction axis. Shading indicates s.e.m.</p></caption>
<graphic xlink:href="548742v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To test these hypotheses, we first quantified how color, target configuration, and direction information was represented in the animals and our network. We performed dPCA in the different areas to identify demixed principal components that represented the corresponding information. In DLPFC, we quantified the overlap of the dPCA principal axes for target configuration, color, and direction. While the target configuration and color axes were relatively aligned (dot product, DP: 0.52), the direction axis was closer to orthogonal to the color axis (DP: 0.18) and the target configuration axis (DP: 0.35), as shown in <xref rid="fig4" ref-type="fig">Fig. 4b</xref>. These results suggest that DLPFC partially orthogonalizes information about the direction choice from the color choice and target configuration. We also observed these trends in the RNN, albeit more strongly. In DLPFC-resembling Area 1, we observed the target configuration and color were also highly aligned (DP: 0.95) but that the direction axis was more orthogonal to the color axis (DP: 0.13) and the target configuration axis (DP: 0.12). In our simulations, the reported values reflect the mean across 8 networks trained with the same hyperparameters. A candidate mechanism for this orthogonalization, found by performing dynamical analyses on the RNN, is shown in <xref rid="figS5" ref-type="fig">Fig. S5</xref>.</p>
<p>The advantage of our model is that both the intra-areal dynamics and inter-areal connectivity matrices are known. We analyzed how these axes were aligned with the intra-areal recurrent dynamics and inter-areal connectivity matrices to identify which hypothesis explained how the RNN implemented the information bottleneck. To do so, we performed singular value decomposition (SVD) on these matrices. We defined a <italic>k</italic>-dimensional “potent space” to be the right singular vectors corresponding to the <italic>k</italic> largest singular values of the matrix. The “null space” is the orthogonal complement of the potent space, which comprises the remaining <italic>d</italic> − <italic>k</italic> smallest singular vectors, where <italic>d</italic> refers to number of columns of the matrix. The null projection magnitudes are equal to one minus the potent projection. We quantified how the color and direction axis were aligned with these potent and null spaces (see Methods). This enabled us to study if the emergence of minimal sufficient representations was due to: (1) relative amplification of the direction information with respect to a random vector, (2) relative suppression of the color/target configuration information with respect to a random vector, or (3) a combination of both. Finally, we focused our analyses on Area 1 recurrent dynamics and the inter-areal connections between Areas 1 and 2 (<bold>W</bold><sub>21</sub>) because color information is significantly attenuated by Area 2 (dPCA color variance in Area 2: 0.14%). The same analyses applied to downstream areas are shown in <xref rid="figS8" ref-type="fig">Fig. S8</xref>.</p>
<p>We first tested the hypothesis that the RNN IB is implemented primarily by recurrent dynamics (left side of <xref rid="fig4" ref-type="fig">Fig. 4a</xref>). We quantified how the color and direction axis were aligned with these potent and null spaces of the intra-areal recurrent dynamics matrix of Area <inline-formula><alternatives><inline-graphic xlink:href="548742v1_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. The axes found through dPCA are proxies for how task information is represented in the neural activity over the trial, while the dynamical activity during a trial depends on the complex interaction between left and right singular vectors of the recurrent matrix (and task inputs)<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. We use the alignment of the (fixed) dPCA axes with the right singular vector as a proxy for the amount of information propagated through recurrence. In Area 1, we found significant alignment of the color axis with the top right singular vectors (potent space) of the recurrent dynamics matrix (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). Additionally, we also performed an alternative analysis where we compared input and activity representations of color discriminability and direction discriminability for our exemplar network. We observe an amplification, not a reduction, in color discriminability with respect to the inputs in Area 1 (<xref rid="figS6" ref-type="fig">Fig. S6</xref>) consistent with the amplification observed in <xref rid="fig4" ref-type="fig">Fig. 4c</xref>. These findings argues <italic>against the hypothesis that recurrent dynamics preferentially attenuate color information by projecting it into a nullspace of the recurrent dynamics</italic>. Rather, these data suggest that Area 1 has significant color information in its potent space, indicating that the recurrent computation <bold>amplifies</bold> color information. In Areas 2 and 3, the color axis (which had small variance of 0.14% and 0.07% in Areas 2 and 3, respectively) was again typically more strongly aligned with <inline-formula><alternatives><inline-graphic xlink:href="548742v1_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> than a random vector, (<xref rid="figS8" ref-type="fig">Fig. S8</xref>). In summary, the dPCA and discriminability analyses suggest that the network did not use recurrent dynamics to attenuate color information, and is therefore inconsistent with the hypothesis that the IB is primarily implemented through intra-areal recurrent dynamics.</p>
<p>Our alternative hypothesis is that color information is primarily attenuated through inter-areal connections. This is schematized in <xref rid="fig4" ref-type="fig">Fig. 4d</xref>, where inter-areal connections propagate activity along the Area 1 direction axis (orange) to Area 2, but attenuate Area 1 color axis activity (maroon). To test this hypothesis, we quantified how the color and direction axis were aligned with these potent and null spaces of the inter-areal matrices. This enabled us to quantify the alignment of the direction and color axes with the inter-areal potent and null spaces and specifically determine how direction and color information were differentially propagated (<xref rid="fig4" ref-type="fig">Fig. 4e</xref>). Inter areal connections could attenuate color information by aligning the color axis with the null space of <bold>W</bold><sub>21</sub> (Hypothesis 1 in <xref rid="fig4" ref-type="fig">Fig. 4e</xref>), propagate information preferentially (Hypothesis 2 in <xref rid="fig4" ref-type="fig">Fig. 4e</xref>), or both attenuate and propagate information (Hypothesis 3 in <xref rid="fig4" ref-type="fig">Fig. 4e</xref>).</p>
<p>We calculated the projections for both the color and choice axes on to the potent space for theconnection matrix from area 1 to area 2 (<bold>W</bold><sub>21</sub>) The projections onto the potent space are shown in <xref rid="fig4" ref-type="fig">Fig. 4f</xref> for the color and direction axis. We found the direction axis was more aligned with the potent space and the color axis was more aligned with the null space. In fact, the direction axis was consistently most aligned with the top singular vector of the <bold>W</bold><sub>21</sub> matrix, on average more than the remaining <italic>d</italic> − 1 singular vectors. <italic>In contrast, the color axis was aligned to a random vector</italic>. This suggests that learning in the multi-area recurrent network involved aligning the relevant information (in the activations) with the top singular vector (governed by the learned parameters of the feedforward matrix). These results indicate that direction information is preferentially propagated to subsequent areas, while color information is aligned with a random vector thus maximally consistent with the “propagate” hypothesis shown in <xref rid="fig4" ref-type="fig">Fig. 4e</xref>.</p>
<p>Such alignment of the direction axis with the top singular vector of the connection matrix isn’t trivial: the potent space depends on the parameter <bold>W</bold><sub>21</sub> learned during training, while the direction axis is not a parameter but a dPCA axis computed from Area 1 activity. This alignment was robust to the dimension of the effective potent space, and was consistent across networks with varying feedforward connectivity percentages (10%, 20%, 30%, 50%, 100%). Further, we found that <bold>W</bold><sub>21</sub> in unconstrained 3 area networks had significantly reduced alignment of the direction axis with the top singular vectors (<xref rid="figS8" ref-type="fig">Fig. S8d</xref>).</p>
<p>In summary, the multi-area RNN information bottleneck is primarily implemented through preferential propagation of direction information through inter-areal connections. Recurrent dynamics play a role in processing color information and target configuration to arrive at direction choice information. In Area 1, RNN dynamics actually amplify color information. Our results are therefore most consistent with the hypothesis that the IB is implemented primarily through inter-areal connections, not recurrent dynamics, in <xref rid="fig4" ref-type="fig">Fig. 4a</xref>.</p>
</sec>
<sec id="s2e">
<title>Effect of network architecture and training hyperparameters on the information bottleneck</title>
<p>We next assessed the network architectures and hyperparameters that influenced the formation of minimal sufficient representations during the Checkerboard task. We swept RNN architectural parameters and machine learning hyperparameters to assess what variables were important for learning minimal sufficient representations without color information. Specifically, we varied the connectivity type (unconstrained connectivity vs Dale’s law and varying proportion of connections), the percentage of unconstrained feedforward connections, the percentage of feedforward E to I connections, the percentage of E to E connections, the number of areas (from 1 to 4), the number of artificial networks, L2 weight regularization, L2 rate regularization, and the learning rate. In our sweeps we quantified the color (and direction) variance and accuracy in the last area.</p>
<p>We generally observed minimal sufficient representations in the last area so long as there was a sufficient <italic>connection</italic> bottleneck between RNN areas. In unconstrained networks, shown in <xref rid="fig5" ref-type="fig">Fig. 5a</xref>, color variance and decode accuracy decreased as the percentage of feedforward connections between areas decreased, though the representations were not minimal. We incorporated Dale’s law with 80% E and 20% I neurons following Song et al.<sup><xref ref-type="bibr" rid="c25">25</xref></sup> into subsequent sweeps (<xref rid="fig5" ref-type="fig">Fig. 5b-e</xref>). Minimal representations with chance color decode accuracy emerged when the percentage of feedforward E to I connections was 2 − 5% or less (the overall percentage of feedforward E to E was fixed at 10% following a macaque atlas). We also found that when there was no feedforward inhibition, but when we varied the percentage of feedforward or feedback E-to-E connections RNNs generally had nearly minimal representations (<xref rid="fig5" ref-type="fig">Fig. 5c</xref>, and <xref rid="figS9" ref-type="fig">Supp. Fig. S9</xref>). We observed that as long as there were 3 or 4 areas, there was a large decrease in color information in the last area (<xref rid="fig5" ref-type="fig">Fig. 5d</xref>) quantified by decoding, though note that there was a large drop in color variance for 2 area networks. These results suggest that multi-area networks, with a feedforward connection bottleneck tend to produce more minimal representations for the Checkerboard task.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Robustness of the information bottleneck across hyperparameters and computational advantage.</title><p>Varying <bold>(a)</bold> proportion of feedforward connections in an unconstrained network, <bold>(b)</bold> E-I connections in a Dale’s law network, <bold>(c)</bold> the proportion of feedforward and feedback E-E connections in a Dale’s law network, <bold>(d)</bold> the number of areas, and <bold>(e)</bold> the machine learning hyperparameters revealed that Area 3 color variance and color accuracy decrease as long as there is a connectivity bottleneck between areas. <bold>(f)</bold> Summary of these results quantifying usable information.</p></caption>
<graphic xlink:href="548742v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We also varied machine learning hyperparameters (<xref rid="fig5" ref-type="fig">Fig. 5e</xref>) to assess the extent to which the information bottleneck was present. To prevent an exponential search space, we fixed the architecture to the exemplar network used in this study and tested one hyperparameter at a time. We varied the number of artificial units in the network, the L2 weight regularization, the L2 rate regularization, and the learning rate. At each hyperparameter setting, we trained a total of 8 multi-area RNNs. Our exemplar network consistently exhibited little to no Area 3 color information across every hyperparameter setting we chose, suggesting that the presence of the information bottleneck is not a result of a particular choice of machine learning hyperparameters.</p>
<p>We again summarized all sweeps by calculating the “Usable Information”<sup><xref ref-type="bibr" rid="c20">20</xref></sup> to quantify the direction and color information in RNNs, as shown in <xref rid="fig5" ref-type="fig">Fig. 5f</xref> and the results reaffirmed conclusions from the variance and decoding analyses. Together, these results suggest that a connection bottleneck in the form of neurophysiological architecture constraints was the key design choice leading to RNNs with minimal color representations and consistent with the information bottleneck principle.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The goal of this study was to investigate if predictions from the information bottleneck principle in machine learning and information theory are also observed in cortical circuits. The information bottleneck principle defines an optimal representation to be one that retains only the relevant or useful information for solving a task<sup><xref ref-type="bibr" rid="c18">18</xref></sup>. This principle has been applied to explain the success of deep networks<sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c29">29</xref></sup>, by forming minimal sufficient representations of task inputs, leading to better generalization bounds and invariance to noise<sup><xref ref-type="bibr" rid="c19">19</xref></sup>. We explored whether such a principle could explain cortical representations across different areas during a visual perceptual decision making task. We found that later areas of cortex along a sensorimotor transformation (in PMd) only represented the behavioral report, that is the action choice, while earlier areas had stronger input representations and performed relevant computations to define the behavioral report (in DLPFC). To better understand how such a phenomenon could be implemented in cortex, we trained many artificial multi-area RNNs to perform this task. Surprisingly, we also observed that RNNs formed minimal sufficient representations across a range of hyperparameter settings, suggesting the formation of minimal sufficient representations may be a more general feature of multi-area computation.</p>
<p>Given the “full-observability” of our multi-area models, we were able to analyze the learned weight matrices and understand how the network converged to transform task inputs into minimal sufficient representations by the output area. In particular, we found that <italic>the output-relevant direction information was preferentially propagated between areas by having the largest overlap with the top singular vector of the learned feedforward matrices</italic>. In contrast, color information was almost randomly propagated through feedforward connections. This mechanism is related to prior work on output potent and output null subspaces<sup><xref ref-type="bibr" rid="c30">30</xref></sup> and communication subspaces<sup><xref ref-type="bibr" rid="c1">1</xref></sup>, with the important difference that color information isn’t preferentially projected to a nullspace, but is aligned similarly to any random vector. Preferential alignment with a cortical nullspace is therefore not <italic>necessary</italic> to achieve an IB — color information may be attenuated through random alignment to the communication subspace. This solution (random alignment) poses less constraints on inter-areal connectivity than a solution that preferentially propagates direction information while also preferentially projecting color information to a nullspace.</p>
<p>Our results are also consistent with recent work proposing that cortical areas convey information through communication subspaces. One observation in communication subspaces is that they do not merely propagate the directions of highest variance<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. We also observed this phenomenon for the <bold>W</bold><sub>21</sub> connectivity matrix, which communicates information from Area 1 to Area 2. Color activity had significant variance in Area 1 (see <xref rid="figS5" ref-type="fig">Fig. S5</xref>). Inter-areal connections must therefore not merely propagate the highest variance dimensions of a preceding area, otherwise color information would be conveyed to Area 2. Consistent with this, we found that while the top 2 PCs capture 97.7% excitatory unit variance, the top 2 readout dimensions of <bold>W</bold><sub>21</sub> only captured 40.0% of Area 1’s excitatory unit neural variance (<xref rid="figS7" ref-type="fig">Fig. S7</xref>). Hence, inter-area connections are not aligned with the most variable dimensions, but are rather aligned to preferentially propagate certain types of information — a result consistent with a recent study analyzing links between activity in V1 and V2<sup><xref ref-type="bibr" rid="c1">1</xref></sup>.</p>
<p>We find minimal sufficient representations in PMd and in the later areas of our recurrent network models. Do such representations have any advantages? One possibility is that in cortex a minimal sufficient representation provides energetic benefits<sup><xref ref-type="bibr" rid="c31">31</xref>,<xref ref-type="bibr" rid="c32">32</xref></sup>. Another possibility is that such a representation provides a computational advantage. This is an open question that is still somewhat unresolved in the machine learning community, with representation learning approaches that <italic>maximize</italic> mutual information between representations and inputs also leading to useful task representations<sup><xref ref-type="bibr" rid="c33">33</xref></sup>, in addition to compressed representations<sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c20">20</xref></sup>. The information contained in the representation of a neural network is related to the “Information in the Weights”<sup><xref ref-type="bibr" rid="c34">34</xref></sup>, which can be quantified using the Fisher Information<sup><xref ref-type="bibr" rid="c35">35</xref>–<xref ref-type="bibr" rid="c37">37</xref></sup>, a measure of sensitivity to perturbations. This “Information in the Weights” view would predict that minimal sufficient representations have smaller Fisher information and are therefore less sensitive to (local) perturbations in the readout weights. In the context of deep networks, it has been proposed that minimal sufficient representations simplify the role of the output readout or classifier<sup><xref ref-type="bibr" rid="c19">19</xref></sup>. Further, a minimal sufficient representation with respect to a family of probabilistic decoders/classifiers will provably generalize better<sup><xref ref-type="bibr" rid="c38">38</xref></sup>.</p>
<p>Although finding a resolution to this debate in machine learning is beyond the scope of this paper, we assessed if minimal RNNs exhibited any qualities consistent with machine learning predictions. We explored whether minimal sufficient representations would simplify the readout, which we quantified by measuring the model’s performance in response to perturbations to the readout weights. We found that 3-area networks with minimal color information (particularly networks in <xref rid="fig5" ref-type="fig">Fig. 5b</xref> with no feedforward E-to-I connectivity) were less sensitive to perturbations than corresponding networks with significant color information (networks in <xref rid="fig5" ref-type="fig">Fig. 5a</xref> with 10% unconstrained feedforward connectivity, see <xref rid="figS11" ref-type="fig">Fig. S11</xref>). We also found that these networks differed significantly in readout complexity, with 3-area networks with minimal color information exhibiting simpler and sparser readouts (<xref rid="figS11" ref-type="fig">Fig. S11</xref>). However, we did not observe a clear trend between perturbation sensitivity and usable color information across random initializations (<xref rid="figS11" ref-type="fig">Fig. S11</xref>) for a fixed parameter setting (networks with 10% feedforward inhibition in <xref rid="fig5" ref-type="fig">Fig. 5b</xref>). An interesting venue for future work is to further examine the potential advantages of a minimal sufficient representation. Such findings would be valuable to the machine learning and neuroscience community. In our study, several factors including recurrent connectivity, multiple areas, and E/I populations make theoretical study of this question difficult. It is likely that studying this question requires simplifying the setting. For example, it likely makes sense to first focus on feedforward networks with a variable amount of task input information, similar to the generalized checkerboard-task used in<sup><xref ref-type="bibr" rid="c20">20</xref></sup>.</p>
<p>Our task could be solved with or without feedback connections with equivalent performance, indicating that feedback was not necessary to solve the task (<xref rid="figS9" ref-type="fig">Fig. S9</xref>). Minimal sufficient representations were found in both purely feedforward RNNs or RNNs with feedback (<xref rid="figS9" ref-type="fig">Fig. S9</xref>). When the model had feedback connections, we observed that feedback connections between Areas 2 and 1 preferentially conveyed direction information. Due to the presence of choice related signals in several cortical areas, these feedback connections may also play a role in computation of the direction choice. Another perspective on feedback signals is that they may related to error signals used for learning<sup><xref ref-type="bibr" rid="c39">39</xref></sup>. Multi-area networks may help understand and develop new hypotheses for physiological studies of feedforward and feedback computation<sup><xref ref-type="bibr" rid="c40">40</xref>,<xref ref-type="bibr" rid="c41">41</xref></sup>, and more generally distributed processing for decision-making and cognition<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c42">42</xref></sup>.Future research may use carefully designed tasks in conjunction with multi-area RNNs to better understand the role of feedback in computation.</p>
<p>The multi-area RNN also provides several testable hypotheses. First, because the information bottleneck simplifies the readout, it suggests a simple readout from “output” areas of cortex (e.g PMd or Motor Cortex). In our multi-area RNN, we found that the output area was comprised of pools of neurons that represent left or right reaches<sup><xref ref-type="bibr" rid="c43">43</xref></sup>, enabling a simple readout (<xref rid="figS10" ref-type="fig">Fig. S10b</xref>, c.). In particular, the connectivity matrix for our area 3 was composed of two pools of excitatory neurons with a common inhibitory pool. Overall, this connectivity and winner-take-all architecture is consistent with our PMd activity, which appears to implement winner-take-all dynamics between a pool of neurons representing left and right reaches (<xref rid="figS10" ref-type="fig">Fig. S10h,i</xref>.) Second, due to selective propagation of inter-areal information, direction axis activity in DLPFC should be more predictive of activity in downstream regions such as PMdr and PMd than activity in the top PCs. Simultaneous recordings of DLPFC and PMd would help test this hypothesis.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Task and training details</title>
<sec id="s4a1">
<title>Somatomotor reaction time visual discrimination task and recordings from PMd</title>
<p>The task, training and electrophysiological methods used to collect the data used here have been described previously<sup><xref ref-type="bibr" rid="c23">23</xref></sup> and are reviewed briefly below. All surgical and animal care procedures were performed in accordance with National Institutes of Health guidelines and were approved by the Stanford University Institutional Animal Care and Use Committee and the Boston University Institutional Animal Care and Use Committees.</p>
<p>Two trained monkeys (Ti and Ol) performed a visual reaction time discrimination task. The monkeys were trained to discriminate the dominant color in a central static checkerboard composed of red and green squares and report their decision with an arm movement. If the monkey correctly reached to and touched the target that matched the dominant color in the checkerboard, they were rewarded with a drop of juice. This task is a reaction time task, so that monkeys initiated their action as soon as they felt they had sufficient evidence to make a decision. On a trial-by-trial basis, we varied the signed color coherence of the checkerboard, defined as (<italic>R</italic> − <italic>G</italic>)<italic>/</italic>(<italic>R</italic> + <italic>G</italic>), where R is the number of red squares and G the number of green squares. The color coherence value for each trial was chosen uniformly at random from 14 different values arranged symmetrically from 90% red to 90% green. Reach targets were located to the left and right of the checkerboard. The target configuration (left red, right green; or left green, right red) was randomly selected on each trial. Both monkeys demonstrated qualitatively similar psychometric and reaction-time behavior. 996 units were selected from PMd of Ti (n=546) and Ol (n=450) and 2819 units were recorded from DLPFC of Ti while they performed the task<sup><xref ref-type="bibr" rid="c23">23</xref></sup>. Monkey Ol and Ti’s PMd units both had low choice color probability. Reported analyses from PMd data use units pooled across Monkey Ol and Ti.</p>
</sec>
<sec id="s4a2">
<title>RNN description and training</title>
<p>We trained a continuous-time RNN to perform the checkerboard task. The RNN is composed of <italic>N</italic> artificial neurons (or units) that receive input from <italic>N</italic><sub>in</sub> time-varying inputs <bold>u</bold>(<italic>t</italic>) and produce <italic>N</italic><sub>out</sub> time-varying outputs <bold>z</bold>(<italic>t</italic>). The RNN defines a network state, denoted by <bold>x</bold>(<italic>t</italic>) ∈ ℝ<sup><italic>N</italic></sup> ; the <italic>i</italic>th element of <bold>x</bold>(<italic>t</italic>) is a scalar describing the “currents” of the <italic>i</italic>th artificial neuron. The network state is transformed into the artificial neuron firing rates (or network rates) through the transformation:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="548742v1_eqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>f</italic> (·) is an activation function applied elementwise to <bold>x</bold>(<italic>t</italic>). The activation function is typically nonlinear, endowing the RNN with nonlinear dynamics and expressive modeling capacity<sup><xref ref-type="bibr" rid="c44">44</xref></sup>. In this work, we use <italic>f</italic> (<italic>x</italic>) = max(<italic>x</italic>, 0), also known as the rectified linear unit, i.e., <italic>f</italic> (<italic>x</italic>) = relu(<italic>x</italic>). In the absence of noise, the continuous time RNN is described by the equation
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="548742v1_eqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>τ</italic> is a time-constant of the network, <bold>W</bold><sub>rec</sub> ∈ ℝ<sup><italic>N ×N</italic></sup> defines how the artificial neurons are recurrently connected, <bold>b</bold><sub>rec</sub> ∈ ℝ<sup><italic>N</italic></sup> defines a constant bias, <inline-formula><alternatives><inline-graphic xlink:href="548742v1_inline3.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> maps the RNN’s inputs onto each artificial neuron, and <italic>ϵ</italic><sub><italic>t</italic></sub> is the recurrent noise. The output of the network is given by a linear readout of the network rates, i.e.,
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="548742v1_eqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="548742v1_inline4.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> maps the network rates onto the network outputs.</p>
<p>We trained RNNs to perform the checkerboard task as follows. For all networks, unless we explicitly varied the amount of units, we used <italic>N</italic><sub>in</sub> = 4, <italic>N</italic> = 300, and <italic>N</italic><sub>out</sub> = 2.</p>
<p>The four inputs were defined as:</p>
<list list-type="order">
<list-item><p>Whether the left target is red (−1) or green (+1).</p></list-item>
<list-item><p>Whether the right target is red (−1) or green (+1).</p></list-item>
<list-item><p>Signed coherence of red (ranging from -1 to 1), (<italic>R</italic> − <italic>G</italic>)<italic>/</italic>(<italic>R</italic> + <italic>G</italic>).</p></list-item>
<list-item><p>Signed coherence of green (ranging from -1 to 1), (<italic>G</italic> − <italic>R</italic>)<italic>/</italic>(<italic>R</italic> + <italic>G</italic>). Note that, prior to the addition of noise, the sum of the signed coherence of red and green is zero.</p></list-item></list>
<p>The inputs, <bold>u</bold>(<italic>t</italic>) ∈ ℝ<sup><xref ref-type="bibr" rid="c4">4</xref></sup>, were defined at each time step, <italic>t</italic>, in distinct epochs. In the ‘Center Hold’ epoch, which lasted for a time drawn from distribution 𝒩 (200 ms, 50<sup>2</sup> ms<sup>2</sup>), all inputs were set to zero. Subsequently, during the ‘Targets’ epoch, which lasted for a time drawn from distribution 𝒰 [600 ms, 1000 ms], the colors of the left and right target were input to the network. These inputs were noiseless, as illustrated in <xref rid="fig3" ref-type="fig">Fig. 3a</xref>, to reflect that target information is typically unambiguous in our experiment. Following the ‘Targets’ epoch, the signed red and green coherences were input into the network during the ‘Decision’ epoch. This epoch lasted for 1500 ms. We added zero mean independent Gaussian noise to these inputs, with standard deviation equal to 5% of the range of the input, i.e., the noise was drawn from 𝒩 (0, 0.1<sup>2</sup>). At every time point, we drew independent noise samples and added the noise to the signed red and green coherence inputs. We added recurrent noise <italic>E</italic><sub><italic>t</italic></sub>, adding noise to each recurrent unit at every time point, from a distribution 𝒩 (0, 0.05<sup>2</sup>). Following the ‘Decision’ epoch, there was a ‘Stimulus Off’ epoch, where the inputs were all turned to 0.</p>
<p>The two outputs, <bold>z</bold>(<italic>t</italic>) ∈ ℝ<sup><xref ref-type="bibr" rid="c2">2</xref></sup> were defined as:</p>
<list list-type="order">
<list-item><p>Decision variable for a left reach.</p></list-item>
<list-item><p>Decision variable for a right reach.</p></list-item>
</list>
<p>We defined a desired output, <bold>z</bold><sub>des</sub>(<italic>t</italic>), which was 0 in the ‘Center Hold’ and ‘Targets’ epochs. During the ‘Decision’ epoch, <bold>z</bold><sub>des</sub>(<italic>t</italic>) = 1. In the ‘Stimulus Off’ epoch, <bold>z</bold><sub>des</sub>(<italic>t</italic>) = 0. In RNN training, we penalized output reconstruction using a mean-squared error loss,
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="548742v1_eqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The set 𝒯 included all times from all epochs except for the first 200 ms of the ‘Decision’ epoch from the loss. We excluded this time to avoid penalizing the output for not immediately changing its value (i.e., stepping from 0 to 1) in the ‘Decision’ epoch. Decision variables are believed to reflect a gradual process consistent with non-instantaneous integration of evidence, e.g., as in drift-diffusion style models, rather than one that steps immediately to a given output. To train the RNN, we minimized the loss function:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="548742v1_eqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where</p>
<list list-type="bullet">
<list-item><p>‖<bold>A</bold>‖<sub><italic>F</italic></sub> denotes the Frobenius norm of matrix <bold>A</bold></p></list-item>
<list-item><p><italic>λ</italic><sub>in</sub> = <italic>λ</italic><sub>rec</sub> = <italic>λ</italic><sub>out</sub> = 1, <italic>λ</italic><sub><italic>r</italic></sub> = 0 to penalize larger weights.</p></list-item>
<list-item><p><italic>λ</italic><sub>Ω</sub> = 2</p></list-item>
<list-item><p>ℒ<sub>Ω</sub> is a regularization term that ameliorates vanishing gradients proposed and is described in prior literature<sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c45">45</xref></sup>.</p></list-item>
</list>
<p>During the training process, we also incorporated gradient clipping to prevent exploding gradients<sup><xref ref-type="bibr" rid="c45">45</xref></sup>. Training was performed using stochastic gradient descent, with gradients calculated using backpropagation through time. For gradient descent, we used the Adam optimizer, which is a first order optimizer incorporating adaptive gradients and momentum<sup><xref ref-type="bibr" rid="c46">46</xref></sup>.</p>
<p>Every 200 or 500 training epochs, we generated 2800 cross-validation trials, 100 for each of the 28 possible conditions (14 coherences × 2 target configurations). For each trial, there was a correct response (left or right) based on the target configuration and checkerboard coherence. When training, we defined a “correct decision” to be when the RNNs DV for the correct response was greater than the other DV and the larger DV was greater than a pre-set threshold of 0.6. We evaluated the network 500ms before the checkerboard was turned off (the end of the trial). We required this criteria to be satisfied for at least 65% of both leftward and rightward trials. We note that this only affected how we terminated training. It had no effect on the backpropagated gradients, which depended on the mean-squared-error loss function. Note that a trial that outputted the correct target but did not reach the 0.6 threshold would not be counted towards the 65% criteria.</p>
<p>When testing, we defined the RNNs decision to be either: (1) whichever DV output (for left or right) first crossed a pre-set threshold of 0.6, or (2) if no DV output crossed the pre-set threshold of 0.6 by the end of the ‘Decision epoch,’ then the decision was for whichever DV had a higher value at the end of this epoch — an approach that is well established in models of decision-making<sup><xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c48">48</xref></sup>. If the RNN’s decision on a single trial was the same as the correct response, we labeled this trial ‘correct.’ Otherwise, it was incorrect. The proportion of decisions determined under criterion (2) was negligible (0.5% across 100 trials for each of 28 conditions). An interpretation for criterion (2) is that if the RNN’s DV has not achieved the threshold certainty level by the end of a trial, we assign the RNN’s decision to be the direction for which its DV had the largest value. Finally, in training only, we introduced ‘catch’ trials 10% of the time. On 50% of catch trials, no inputs were shown to the RNN and <bold>z</bold><sub>des</sub>(<italic>t</italic>) = 0 for all <italic>t</italic>. On the remaining 50% of catch trials, the targets were shown to the RNN, but no coherence information was shown; likewise, <bold>z</bold><sub>des</sub>(<italic>t</italic>) = 0 for all <italic>t</italic> on these catch trials.</p>
<p>We trained the three-area RNNs by constraining the recurrent weight matrix <bold>W</bold><sub>rec</sub> to have connections between the first and second areas and the second and third areas. In a multi-area network with <italic>N</italic> neurons and <italic>m</italic> areas, each area had <italic>N/m</italic> neurons. In our 3-area networks, each area had 100 units. Of these 100 units, 80 were excitatory and 20 were inhibitory. Excitatory units were constrained to have only positive outgoing weights, while inhibitory units were constrained to have only negative outgoing weights. We used the pycog repository<sup><xref ref-type="bibr" rid="c25">25</xref></sup> to implement these architecture constraints. The parameters for the exemplar RNN used in the paper are shown in <xref rid="tbl1" ref-type="table">Table 1</xref>. In our hyperparameter sweeps, we varied the hyperparameters of the exemplar RNN. For each parameter configuration, we trained 8 different networks with different random number generator seeds.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Hyperparameters of exemplar RNN.</title></caption>
<graphic xlink:href="548742v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</sec>
<sec id="s4b">
<title>Additional description of analyses</title>
<sec id="s4b1">
<title>Decoding analysis for DLPFC and PMd data</title>
<p>For DLPFC and PMd data, we calculated decoding accuracy using 400 ms bins. We report numbers in a window [-300ms, +100 ms] aligned to movement onset. We used the Python <italic>sklearn</italic>.<italic>svm</italic>.<italic>SVC</italic> command with 80% training and 20 % test sets. Decoding analyses were performed using 2-49 simultaneously recorded units from Plexon U-probes and the averages reported are across PMd and DLPFC sessions, respectively. To assess whether decoding accuracies were significant, we shuffled the trials for 100 times. The decoding accuracy for direction, color and target configuration variables of a session was judged to be significant if it lies above the 99 percentile of shuffled accuracy. For DLPFC, direction, target configuration and color decoding accuracy of 100%, 78%, 53% sessions were judged to be significantly above chance; for PMd, 97%, 26%, 20% sessions demonstrated significant decoding accuracy to direction, target configuration and color.</p>
<p>Mutual information was calculated by computing <italic>H</italic>(<italic>Y</italic>) − <italic>L</italic><sub><italic>CE</italic></sub> where <italic>H</italic>(<italic>Y</italic>) was 1 and <italic>L</italic><sub><italic>CE</italic></sub> denotes the cross entropy loss (in bits). We computed the decoding and information only for sessions with decoding accuracy significantly above chance. Negative mutual information was set to zero.</p>
</sec>
<sec id="s4b2">
<title>Decoding and Mutual information for RNNs</title>
<p>We used a decoder and mutual information approximation to quantify the amount of information (color, target configuration, direction) present in the network. We trained a neural network to predict a relevant choice (for example, color) on a test set from the activity of a population of units. We used 700 trials for training, and 2100 independent trials for testing. To generate the trials for training and testing, we increased the recurrent noise to be drawn from the distribution (𝒩 (0, 0.1<sup>2</sup>)) to prevent overfitting. For each trial, we averaged data in a window [-300ms, +100ms] around reaction time.</p>
<p>We trained a neural network with 3 layers, 64 units per layer, leakyRelu activation (<italic>α</italic>=0.2), and dropout (p=0.5), using stochastic gradient descent, to predict the choice given the activity of the population. We removed the leakyRelu activation for the linear network, and increased dropout (p=0.8). For both the nonlinear and linear network, we trained the neural network to minimize the cross-entropy loss. We used the same neural network from the decode to compute an approximation to mutual information, described in Supplementary Note 2.</p>
</sec>
<sec id="s4b3">
<title>RNN behavior</title>
<p>To evaluate the RNN’s psychometric curve and reaction-time behavior, we generated 200 trials for each of the 28 conditions, producing 400 trials for each signed coherence. For these trials, we calculated the proportion of red decisions by the RNN. This corresponds to all trials where the DV output for the red target first crossed the preset threshold of 0.6; or, if no DV output crossed the threshold of 0.6, if the DV corresponding to the red target exceeded that corresponding to the green target. The reaction time was defined to be the time between checkerboard onset to the first time a DV output exceeded the preset threshold of 0.6. If the DV output never exceeded a threshold of 0.6, in the reported results, we did not calculate a RT for this trial.</p>
</sec>
<sec id="s4b4">
<title>dPCA</title>
<p>Demixed principal components analysis (dPCA) is a dimensionality reduction technique that provides a projection of the data onto task related dimensions while preserving overall variance<sup><xref ref-type="bibr" rid="c49">49</xref></sup>. dPCA achieves these aims by minimizing a loss function:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="548742v1_eqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Here, <bold>X</bold><sub><italic>c</italic></sub> refers to data averaged over a “dPCA condition” (such as time, coherence, target configuration, color, or direction), having the same shape as <bold>X</bold> ∈ ℝ<sup><italic>N ×cT</italic></sup>, but with the entries replaced with the condition-averaged response. The aim is to recover (per dPCA condition <italic>c</italic>) a <bold>P</bold><sub><italic>c</italic></sub> and <bold>D</bold><sub><italic>c</italic></sub> matrix. <bold>P</bold><sub><italic>c</italic></sub> is constrained to have orthonormal columns, while <bold>D</bold><sub><italic>c</italic></sub> is unconstrained. The number of columns of <bold>P</bold><sub><italic>c</italic></sub> and rows of <bold>D</bold><sub><italic>c</italic></sub> reflects the number of components one seeks to find per condition. The column of <bold>P</bold><sub><italic>c</italic></sub> reflects how much the demixed data contributes to each neuron. We use the principal axes from <bold>P</bold><sub><italic>c</italic></sub> to compute the axis overlap, as in Kobak et al<sup><xref ref-type="bibr" rid="c49">49</xref></sup>. We used axes of dimension 1 for RNNs, which were sufficient to capture most color, target configuration, or direction variance. For the neural data, we used five components for direction, color and target configuration since the PMd data was higher dimensional than the RNNs.</p>
<p>For multi-area analyses, we separated the units for each area and found the task-relevant axes for this subset of units. For the inter-area analyses, we used RNNs with only excitatory connections, and therefore found the color and direction axis using only the excitatory units. In all other analyses, all units were used to identify the axes. For RNN activity, we performed dPCA using activity over the entire trial.</p>
<p>For neural data, due to the stochasticity in task design, there is a trial-by-trial difference in interval between target and checkerboard onset (TC interval). The reaction time (from the checkerboard onset to monkey’s hand movement initiation) also varies for each trial. To align time events across trials, we restretched the firing rates in each trial. For DLPFC units, each trial was aligned to targets onset first. Median reaction time (527ms) and TC interval (735ms) were calculated by combining every trial in the database. For each trial, TC interval and reaction time was either compressed or stretched to the median values through linear interpolation. After the data restretching, we choose the data window <bold>T</bold> as 1300ms, from -100ms to 1200ms around target onset with sample size of 1ms. For every unit <bold>n</bold> in total units number <bold>N</bold>, we averaged the single-trial firing rate by stimulus <bold>S</bold> (checkerboard dominant color, green or red) and decision of choice <bold>D</bold> (left or right). As a result, a 4D firing-rate matrix <bold>X</bold><sup><bold>N</bold><italic>×</italic><bold>S</bold><italic>×</italic><bold>D</bold><italic>×</italic><bold>T</bold></sup> was created as input to demixed principal component analysis algorithm.</p>
<p>For PMd units, activities before checkerboard onset were minimal. As a result, each trial was aligned to target onset and a segment with time window of [−100<italic>ms</italic>, 367<italic>ms</italic>] was chosen first. Then the same trial was aligned to checkerboard first and a segment with a window of [− 368<italic>ms</italic>, 465<italic>ms</italic>] was chosen. The final restretched data was the concatenation of these two data segments.</p>
<p>When computing the overlap in <xref rid="fig4" ref-type="fig">Fig. 4</xref>, we averaged across 8 initializations, and computed the PSTHs over 700 trials. In our dpca variance sweeps (<xref rid="fig5" ref-type="fig">Fig. 5</xref>), we computed the PSTHs over 280 trials.</p>
</sec>
<sec id="s4b5">
<title>PCA</title>
<p>Principal components analysis (PCA) is a dimensionality reduction technique that projects high-dimension data into low-dimensional axis which maximize the variance in the data. PCA provides low-dimensional projections by minimizing the loss function:
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="548742v1_eqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<bold>X</bold><sup><bold>N</bold><italic>×</italic><bold>T</bold></sup> is high-dimension raw data and <bold>D</bold><sup><bold>N</bold><italic>×</italic><bold>N</bold></sup> is the decoding matrix. The low-dimension trajectories <bold>x</bold><sup><bold>M</bold><italic>×</italic><bold>T</bold></sup> (<italic>M &lt; N</italic>) calculated by multiplying first <italic>M</italic> rows of <bold>D</bold> by <bold>X</bold>.</p>
<p>Before applying PCA on the data, the raw data was preprocessed by data normalization and average firing rate removal:</p>
</sec>
<sec id="s4b6">
<title>Data normalization for PCA</title>
<p>Due to the hererogenity in firing rates, PCA results might be dominanted by units with high firing rates. To equalize the contribution of each unit in PCA, for each unit <bold>n</bold> ∈ 𝒩, 99 percentile of max firing rate <bold>x</bold><sub><bold>n</bold>,<bold>99</bold></sub> was calculated over all stimulus, decision conditions and time point. Then we divided each data for unit <bold>x</bold><sub><bold>n</bold>,<bold>99</bold></sub> by square root of to normalize the data.</p>
</sec>
<sec id="s4b7">
<title>Condition independent signal removal for PCA</title>
<p>The condition independent signal is another source that explains substantial amount of population variance other than task-related signal. Before conducting principal component analysis (PCA), we calculated the average firing rate of each single unit <bold>X</bold><sup><bold>1</bold><italic>×</italic><bold>1</bold><italic>×</italic><bold>1</bold><italic>×</italic><bold>T</bold></sup> over all stimulus and decision conditions and subtracted this condition independent signal from the time-restretched data <bold>X</bold><sup><bold>1</bold><italic>×</italic><bold>S</bold><italic>×</italic><bold>D</bold><italic>×</italic><bold>T</bold></sup>.</p>
</sec>
<sec id="s4b8">
<title>Canonical correlation</title>
<p>We applied CCA to assess the similarity between neural activity and the artificial unit activity<sup><xref ref-type="bibr" rid="c50">50</xref></sup>. Before applying CCA, we performed principal component analysis to reduce the dimensionality of the artificial and neural activity to remove noise, which can be arbitrarily reshaped to increase the canonical correlation<sup><xref ref-type="bibr" rid="c50">50</xref></sup>. We reduced the dimensionality of PMd data to 2 (which captures over 80% of the PMd variance). For DLPFC, 18 dimensions were required to capture over 80% of the variance, but at such a high dimensionality, noise can be reshaped to significantly increase the canonical correlations. For DLPFC, we therefore show a comparison to the top 4 PCs in <xref rid="fig3" ref-type="fig">Fig. 3e</xref>. However, the trends held irrespective of the DLPFC dimensionality we chose, as shown in <xref rid="figS3" ref-type="fig">Fig. S3</xref>. In all cases, we compared to CCA with the number of dimensions equal to 2, looking at the We report the average CCA correlation coefficients in <xref rid="fig3" ref-type="fig">Fig. 3e</xref> using times in a window of [-400ms, 400ms] aligned to checkerboard onset. The data was binned in 10ms bins.</p>
</sec>
<sec id="s4b9">
<title>Analyses of inputs and activity</title>
<p>In order to disentangle the effects of external inputs and recurrence, in <xref rid="figS6" ref-type="fig">Fig. S6</xref>, we evaluated the input contribution and overall activity. For Area 1, we defined the input contribution as <bold>W</bold><sub>in</sub><bold>u</bold><sub><italic>t</italic></sub>, and for areas 2 and 3, we defined the input contribution as <inline-formula><alternatives><inline-graphic xlink:href="548742v1_inline5.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, and <inline-formula><alternatives><inline-graphic xlink:href="548742v1_inline6.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> respectively, where <inline-formula><alternatives><inline-graphic xlink:href="548742v1_inline7.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> denotes the activity of the units in area <italic>m</italic>. The activity <bold>r</bold><sup><italic>m</italic></sup> corresponds to the firing rate that experimentalists could measure, reflecting a combination of input and recurrent interactions. For constant inputs, a stable value of the activity implies there is little recurrent processing.</p>
</sec>
<sec id="s4b10">
<title>Inter-Area Projection Analyses</title>
<p>To calculate the overlap between the color and direction axes with the potent and null spaces, we performed singular value decomposition on the inter-area connections, <bold>W</bold><sub>21</sub> and <bold>W</bold><sub>32</sub>. <bold>W</bold><sub>21</sub> and <bold>W</bold><sub>32</sub> were 80 × 80 matrices, and were full rank. Nevertheless, they had near some zero singular values, indicating that the effective rank of the matrix was less than 80. We defined the potent dimensions to be the top <italic>m</italic> right singular vectors, while the null dimensions were the remaining 80 − <italic>m</italic> right singular vectors.</p>
<p>We performed the analyses of <xref rid="fig4" ref-type="fig">Fig. 4f</xref> by varying the potent and null dimensions, sweeping <italic>m</italic> from 1 to 80. For each defined potent and null space, we calculated the axis overlap between the direction (or color) axis and the potent (or null) space by computing the L2-norm of the orthogonal projection (squared). We report the squared quantity because the expectation of the norm of a projection of a random vector onto an <italic>m</italic>-dimensional subspace of an <italic>n</italic>-dimensional space is <italic>m/n</italic>. We include an approximation of the expectation of the projection of a random vector in <xref rid="fig4" ref-type="fig">Fig. 4</xref> by averaging the projection of 100 random vectors. Our results show that the direction axis was always more aligned with potent dimensions than the color axis, irrespective of the choice of <italic>m</italic>, and that the direction axis was preferentially aligned with the top singular vector.</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Supplementary Information</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1:</label>
<caption><p><bold>(a)</bold> Psychometric and <bold>(b)</bold> reaction time curves for multi-area RNNs. The hyperparameters used for these RNNs are described in <xref rid="tbl1" ref-type="table">Table 1</xref>. Gray lines represent individual RNNs and the black solid line is the average across all RNNs.</p></caption>
<graphic xlink:href="548742v1_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2:</label>
<caption><p><bold>(a)</bold> Another rotation of the first three PCs for Area 1 RNN, with PC<sub>3</sub> amplified to show that there is a low variance color axis. <bold>(b)</bold> Area 2 PCs in the same projection as used in <xref rid="fig3" ref-type="fig">Figure 3</xref>. While these PCs qualitatively appear to represent the direction decision, they are distinct from Area 3, with Area 3 demonstrating a stronger resemblance to PMd activity.</p></caption>
<graphic xlink:href="548742v1_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3:</label>
<caption><p>Because DLPFC is higher-dimensional than PMd, we performed the CCA correlation coefficient comparison to Areas 1-3 of the RNN varying the number of dimensions used for the DLPFC PCs. Note that as dimensionality increases, CCA correlation coefficient increases because additional dimensions, which are low variance, can be weighted to better reproduce the RNN PCs. We nevertheless observe that Area 1 has the highest CCA correlation to DLPFC, while Area 3 has the least.</p></caption>
<graphic xlink:href="548742v1_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S4:</label>
<caption><p>SVM Mutual Information (approximated using the Usable Information) for each RNN area as a function of increasing decoder regularization <italic>C</italic>. A lower <italic>C</italic> implies more regularization.</p></caption>
<graphic xlink:href="548742v1_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S5:</label>
<caption><title>Candidate mechanism for axis orthogonalization.</title>
<p><bold>(a)</bold> Top 2 PCs of RNN Area 1 activity. Trajectories are now colored based on the coherence of the checkerboard, and the condition-independent signal is not removed. We did not remove the condition-independent signal so we could directly study the high-dimensional dynamics of the RNN and its equilibrium states. The trajectories separate to two regions corresponding to the two potential target configurations (Target con<xref rid="fig1" ref-type="fig">fig 1</xref> in blue, Target con<xref rid="fig2" ref-type="fig">fig 2</xref> in purple). The trajectories then separate upon checkerboard color input, leading to four trajectory motifs. <bold>(b)</bold> Projection of the dPCA principal axes onto the PCs. <bold>(c)</bold> Projection of the target configuration and color inputs onto the PCs. Target configuration inputs are shown in pink, a strongly green checkerboard in green, and a strongly red checkerboard in red. Irrespective of the target configuration, green checkerboards cause the RNN state to increase along PC<sub>2</sub> while red checkerboards cause the RNN state to decrease along PC<sub>2</sub>. The strength of the input representation is state-dependent: checkerboards corresponding to left reaches, whether they are green or red, cause smaller movements of the RNN state along the color axis. <bold>(d)</bold> Visualization of RNN dynamics and inputs during the target presentation. In the Targets On epoch, target configuration inputs cause movement along the vertical target configuration axis. The RNN dynamics implemented a leftward flow-field that pushed the RNN state into an attractor region of slow dynamics. <bold>(e)</bold> At the Target con<xref rid="fig1" ref-type="fig">fig 1</xref> attractor, we plot the local dynamics using a previously described technique<sup><xref ref-type="bibr" rid="c51">51</xref></sup>. The RNN implements approximately opposing flow fields above and below a line attractor. Above the attractor, a leftward flow-field increases direction axis activity, while below the attractor, a rightward flow-field decreases direction axis activity. A green checkerboard input therefore pushes the RNN state into the leftward flow-field (solid green trajectories) while a red checkerboard input pushes the RNN state into a rightward flow-field (dotted red trajectories). This computes the direction choice in a given target configuration, while allowing the direction axis to be orthogonal to color inputs. Arrows are not to scale; checkerboard inputs have been amplified to be visible. <bold>(f)</bold> Visualized dynamics across multiple trajectory motifs. These dynamics hold in both target configurations leading to separation of right and left decisions on the direction axis. Arrows are not to scale, for visualization purposes.</p></caption>
<graphic xlink:href="548742v1_figS5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Figure S6:</label>
<caption><p>The norm of the direction discriminability (left red -right red + left green -right green)/2 and color discriminability (left green -left red + right green -right red)/2 as a function of the processing area. The inputs are shown in lighter transparency and the overall activity is shown in solid lines. Area 1 has significant recurrence evidenced by a large separation between the input and overall activity. For our exemplar network, there is very little evidence of recurrent filtering of color information (i.e recurrent activity is never below inputs).</p></caption>
<graphic xlink:href="548742v1_figS6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS7" position="float" fig-type="figure">
<label>Figure S7:</label>
<caption><title>Relationship between PCs and inter-area potent space.</title>
<p><bold>(a)</bold> Variance explained of the excitatory units in Area 1 by the top principal components and top dimensions of potent space of <bold>W</bold><sub>21</sub>, swept across all dimensions. <bold>(b)</bold> Variance explained of the excitatory units in Area 2 by the top principal components and top dimensions of potent space of <bold>W</bold><sub>32</sub>, swept across all dimensions. These plots show that the connections between areas do not necessarily propagate the most dominant axes of variability in the source area to the downstream area. Excitatory units were used for the comparison because only excitatory units are read out by subsequent areas. These results were upheld when comparing to the variance explained by the top principal components obtained from all units.</p></caption>
<graphic xlink:href="548742v1_figS7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS8" position="float" fig-type="figure">
<label>Figure S8:</label>
<caption><p><bold>(a)</bold> Alignment of dpca color and direction axes from area 2 with inter-areal connections <bold>W</bold><sub>32</sub>. <bold>((b</bold>,<bold>c)</bold> Alignment of dpca axes with intra-areal recurrent matrices for 3 area dale networks (Area 2 and Area 3). <bold>(d)</bold>. Alignment of dpca axes in area 1 with <bold>W</bold><sub>21</sub> for networks without Dale’s law. In contrast to <xref rid="fig4" ref-type="fig">Fig. 4f</xref>, direction information is not preferentially propagated. Same conventions as <xref rid="fig4" ref-type="fig">Fig. 4c,f</xref>.</p></caption>
<graphic xlink:href="548742v1_figS8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS9" position="float" fig-type="figure">
<label>Figure S9:</label>
<caption><title>Effect of feedback connections</title>
<p><bold>bold&gt;(a)</bold> dPCA variance in area 3 of RNNs where we varied the amount of feedback connectivity. RNNs exhibited nearly zero dPCA color variance in Area 3 across networks with 0%, 5%, and 10% feedback connections. <bold>(b, c)</bold> RNNs also exhibited minimal color representations, achieving nearly chance levels of decode accuracy and nearly zero mutual information. <bold>(d, e)</bold> Feedback projections of the color and direction axis on the feedback inter-area matrix between <bold>(d)</bold> area 2 and area 1, and <bold>(e)</bold> area 3 and area 2 (for networks trained with 5% feedback connections, across variable feedforward connectivity percentages).</p></caption>
<graphic xlink:href="548742v1_figS9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS10" position="float" fig-type="figure">
<label>Figure S10:</label>
<caption><title>Area 3 mechanism.</title>
<p><bold>(a)</bold> Projection of input and overall activity onto the direction axis identified through dPCA. <bold>(b)</bold> Readout weights in <bold>W</bold><sub>out</sub> are sparse, with many zero entries, and selective weights for a left or right reach. <bold>(c)</bold> The unsorted connectivity matrix for the nonzero readout units (left panel), and the sorted connectivity matrix when the matrix was reordered based on the readout weight pools (right). <bold>(d)</bold> Average PSTHs from units for a leftward reach and (inset) rightwards reach. When one pool increases activity, the other pool decreases activity. <bold>(e)</bold> Averaged recurrent connectivity matrix. <bold>(f)</bold> Schematic of output area. <bold>(g)</bold> Psychometric curve after perturbation experiment, where 10% of inhibitory weights to the left pool (orange) and right pool (blue) were increased (doubled). Directional evidence is computed by using the signed coherence and using target configuration to identify the strength of evidence for a left reach and strength of evidence for a right reach. Increasing inhibition to the left excitatory pool leads to more right choices and vice versa. <bold>(h</bold>,<bold>i)</bold> Firing rates of PMd neurons for PREF direction reaches and NONPREF direction reaches aligned to checkerboard and movement onset. In Winner-take-all models, when one pool wins the firing rate of the other pool is suppressed due to lateral inhibition. In PMd, when the PREF direction wins the firing rate of the NONPREF direction decreases (blue shaded region in i).</p></caption>
<graphic xlink:href="548742v1_figS10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS11" position="float" fig-type="figure">
<label>Figure S11:</label>
<caption><title>Potential multi-area computational advantage.</title>
<p><bold>(Top Row)</bold> Sensitivity to isotropic readout noise added to the output weights. <bold>(a)</bold> Noise added to all units in output (even the zero weights). <bold>(b)</bold> Noise only added to nonzero units. <bold>(Middle Row)</bold> Readout weights for left (dashed orange) and right (blue) reaches. <bold>(c)</bold> Readout weight with Dale’s Law enforced, (<bold>d</bold>) Readout weights in unconstrained networks. (<bold>e</bold>) Readout weights in unconstrained but ensuring positive outputs. <bold>(Bottom Row)</bold> No correlation between robustness to noise and usable color information across random initializations for networks with 10% feedforward inhibition, where after training some networks had color information (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>). We used a noise perturbation to each unit of variance <bold>(f)</bold> <italic>σ</italic><sup><xref ref-type="bibr" rid="c2">2</xref></sup> = 0.3 and <bold>(g)</bold> <italic>σ</italic><sup><xref ref-type="bibr" rid="c2">2</xref></sup> = 0.5.</p></caption>
<graphic xlink:href="548742v1_figS11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s5a">
<title>Supplementary Note: Mutual Information Estimation</title>
<p>The entropy of a distribution is defined as
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="548742v1_eqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The mutual information, <italic>I</italic>(<italic>X</italic>; <italic>Y</italic>), can be written in terms on an entropy term and as conditional entropy term:
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="548742v1_eqn9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
We want to show that the usable information lower bounds the mutual information:
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="548742v1_eqn10.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
It suffices to show that:
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="548742v1_eqn11.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>L</italic><sub><italic>CE</italic></sub> is the cross-entropy loss on the test set. For our study, <italic>H</italic>(<italic>Y</italic>) represented the known distribution of output classes, which in our case were equiprobable.
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="548742v1_eqn12.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="548742v1_eqn13.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="548742v1_eqn14.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
To approximate <italic>H</italic>(<italic>Y</italic>|<italic>Z</italic>), we first trained a neural network with cross-entropy loss to predict the output, <italic>Y</italic>, given the hidden activations, <italic>Z</italic>, learning a distribution <italic>q</italic>(<italic>y</italic>|<italic>z</italic>). The KL denotes the Kullback-Liebler divergence. We multiplied (and divided) by an arbitrary variational distribution, <italic>q</italic>(<italic>y</italic>|<italic>z</italic>), in the logarithm of <xref ref-type="disp-formula" rid="eqn12">equation 12</xref>, leading to <xref ref-type="disp-formula" rid="eqn13">equation 13</xref>. The first term in <xref ref-type="disp-formula" rid="eqn13">equation 13</xref> is the cross-entropy loss commonly used for training neural networks. The second term is a KL divergence, and is therefore non-negative. In our approximator, the distribution, <italic>q</italic>(<italic>y</italic>|<italic>x</italic>), is parametrized by a neural network. When the distribution <italic>q</italic>(<italic>y</italic>|<italic>z</italic>) = <italic>p</italic>(<italic>y</italic>|<italic>z</italic>), our variational approximation of <italic>H</italic>(<italic>Y</italic>|<italic>Z</italic>), and hence approximation of <italic>I</italic>(<italic>Z</italic>; <italic>Y</italic>) is exact<sup><xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c52">52</xref>,<xref ref-type="bibr" rid="c53">53</xref></sup>.</p>
<p>In the paper, we additionally report the accuracy of the neural network on the test set. This differs from the cross-entropy in that the cross-entropy incorporates a weighted measure of the accuracy based on how “certain” the network is, while the accuracy does not.</p>
</sec>
</sec>
<ack>
<title>Acknowledgments</title>
<p>MK was supported by the National Sciences and Engineering Research Council (NSERC). CC was supported by a NIH/NINDS R00 award R00NS092972, NIH/NINDS R01 NS122969, NIH/NINDS R01NS121409 the Moorman-Simon Interdisciplinary Career Development Professorship from Boston University, the Whitehall foundation, and the Young Investigator Award from the Brain and Behavior Research Foundation. JCK was supported by NSF CAREER 1943467, NIH DP2NS122037, the Hellman Foundation, and a UCLA Computational Medicine AWS grant. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research. We thank Laura Driscoll for helpful comments on the manuscript as well as Krishna V. Shenoy and William T. Newsome for helpful discussions on earlier versions of these results. We also thank Krishna V. Shenoy for kindly allowing us to use the PMd data collected by Dr. Chandrasekaran when he was a postdoc in the Shenoy Lab.</p>
</ack>
<sec id="s6">
<title>Author contributions</title>
<p>MK, JCK and CC conceived of the study. MK and JCK trained RNNs and analyzed networks. MK performed the multi-area computation analyses. DX, EF, and NH assisted with various analyses. CC collected experimental data in PMd in Prof. Shenoy’s lab. TW, NC, and EKL trained animals and collected DLPFC data in the lab of CC. TW performed various analyses on the neural data. YL contributed by curating data and code for further analysis. MK, CC and JCK wrote the manuscript.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><surname>Semedo</surname>, <given-names>JD</given-names></string-name>, <string-name><surname>Zandvakili</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Machens</surname>, <given-names>CK</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>BM</given-names></string-name>, and <string-name><surname>Kohn</surname>, <given-names>A</given-names></string-name> (<year>2019</year>). <article-title>Cortical Areas Interact through a Communication Subspace</article-title>. <source>Neuron</source>, <volume>102</volume>(<issue>1</issue>):<fpage>249</fpage>–<lpage>259</lpage>.e4.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><surname>Szczepanski</surname>, <given-names>SM</given-names></string-name>, <string-name><surname>Konen</surname>, <given-names>CS</given-names></string-name>, and <string-name><surname>Kastner</surname>, <given-names>S</given-names></string-name> (<year>2010</year>). <article-title>Mechanisms of Spatial Attention Control in Frontal and Parietal Cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>(<issue>1</issue>):<fpage>148</fpage>–<lpage>160</lpage>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><surname>Kalaska</surname>, <given-names>J</given-names></string-name> and <string-name><surname>Crammond</surname>, <given-names>D</given-names></string-name> (<year>1992</year>). <article-title>Cerebral cortical mechanisms of reaching movements</article-title>. <source>Science</source>, <volume>255</volume>(<issue>5051</issue>):<fpage>1517</fpage>–<lpage>1523</lpage>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><surname>Remington</surname>, <given-names>ED</given-names></string-name>, <string-name><surname>Narain</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Hosseini</surname>, <given-names>EA</given-names></string-name>, and <string-name><surname>Jazayeri</surname>, <given-names>M</given-names></string-name> (<year>2018</year>). <article-title>Flexible Sensorimotor Computations through Rapid Reconfiguration of Cortical Dynamics</article-title>. <source>Neuron</source>, <volume>98</volume>(<issue>5</issue>):<fpage>1005</fpage>–<lpage>1019</lpage>.e5.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><surname>Yamagata</surname>, <given-names>T</given-names></string-name>, <string-name><surname>Nakayama</surname>, <given-names>Y</given-names></string-name>, <string-name><surname>Tanji</surname>, <given-names>J</given-names></string-name>, and <string-name><surname>Hoshi</surname>, <given-names>E</given-names></string-name> (<year>2012</year>). <article-title>Distinct information representation and processing for goal-directed behavior in the dorsolateral and ventrolateral prefrontal cortex and the dorsal premotor cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>37</issue>):<fpage>12934</fpage>–<lpage>12949</lpage>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><surname>Yau</surname>, <given-names>JM</given-names></string-name>, <string-name><surname>DeAngelis</surname>, <given-names>GC</given-names></string-name>, and <string-name><surname>Angelaki</surname>, <given-names>DE</given-names></string-name> (<year>2015</year>). <article-title>Dissecting neural circuits for multisensory integration and crossmodal processing</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>370</volume>(<issue>1677</issue>):<fpage>20140203</fpage>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><surname>Cisek</surname>, <given-names>P</given-names></string-name> (<year>2012</year>). <article-title>Making decisions through a distributed consensus</article-title>. <source>Current opinion in neurobiology</source>, <volume>22</volume>(<issue>6</issue>):<fpage>927</fpage>–<lpage>936</lpage>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><surname>Pinto</surname>, <given-names>L</given-names></string-name>, <string-name><surname>Rajan</surname>, <given-names>K</given-names></string-name>, <string-name><surname>DePasquale</surname>, <given-names>B</given-names></string-name>, <string-name><surname>Thiberge</surname>, <given-names>SY</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>DW</given-names></string-name>, and <string-name><surname>Brody</surname>, <given-names>CD</given-names></string-name> (<year>2019</year>). <article-title>Task-dependent changes in the large-scale dynamics and necessity of cortical regions</article-title>. <source>Neuron</source>, <volume>104</volume>(<issue>4</issue>):<fpage>810</fpage>–<lpage>824</lpage>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><surname>Siegel</surname>, <given-names>M</given-names></string-name>, <string-name><surname>Buschman</surname>, <given-names>TJ</given-names></string-name>, and <string-name><surname>Miller</surname>, <given-names>EK</given-names></string-name> (<year>2015</year>). <article-title>Cortical information flow during flexible sensorimotor decisions</article-title>. <source>Science</source>, <volume>348</volume>(<issue>6241</issue>):<fpage>1352</fpage>–<lpage>1355</lpage>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><surname>Freedman</surname>, <given-names>DJ</given-names></string-name> and <string-name><surname>Assad</surname>, <given-names>JA</given-names></string-name> (<year>2016</year>). <article-title>Neuronal mechanisms of visual categorization: an abstract view on decision making</article-title>. <source>Annual review of neuroscience</source>, <volume>39</volume>:<fpage>129</fpage>–<lpage>147</lpage>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><surname>Mizusaki</surname>, <given-names>BE</given-names></string-name> and <string-name><surname>O’Donnell</surname>, <given-names>C</given-names></string-name> (<year>2021</year>). <article-title>Neural circuit function redundancy in brain disorders</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>70</volume>:<fpage>74</fpage>–<lpage>80</lpage>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>N</given-names></string-name>, <string-name><surname>Daie</surname>, <given-names>K</given-names></string-name>, <string-name><surname>Svoboda</surname>, <given-names>K</given-names></string-name>, and <string-name><surname>Druckmann</surname>, <given-names>S</given-names></string-name> (<year>2016</year>). <article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title>. <source>Nature</source>, <volume>532</volume>(<issue>7600</issue>):<fpage>459</fpage>–<lpage>464</lpage>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><surname>Jeurissen</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Shushruth</surname>, <given-names>S</given-names></string-name>, <string-name><surname>El-Shamayleh</surname>, <given-names>Y</given-names></string-name>, <string-name><surname>Horwitz</surname>, <given-names>GD</given-names></string-name>, and <string-name><surname>Shadlen</surname>, <given-names>MN</given-names></string-name> (<year>2022</year>). <article-title>Deficits in decision-making induced by parietal cortex inactivation are compensated at two timescales</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>12</issue>):<fpage>1924</fpage>–<lpage>1931</lpage>.e5.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><surname>Fetsch</surname>, <given-names>CR</given-names></string-name>, <string-name><surname>Odean</surname>, <given-names>NN</given-names></string-name>, <string-name><surname>Jeurissen</surname>, <given-names>D</given-names></string-name>, <string-name><surname>El-Shamayleh</surname>, <given-names>Y</given-names></string-name>, <string-name><surname>Horwitz</surname>, <given-names>GD</given-names></string-name>, and <string-name><surname>Shadlen</surname>, <given-names>MN</given-names></string-name> (<year>2018</year>). <article-title>Focal optogenetic suppression in macaque area MT biases direction discrimination and decision confidence, but only transiently</article-title>. <source>Elife</source>, <volume>7</volume>:<fpage>e36523</fpage>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><surname>Yamins</surname>, <given-names>DLK</given-names></string-name>, <string-name><surname>Hong</surname>, <given-names>H</given-names></string-name>, <string-name><surname>Cadieu</surname>, <given-names>CF</given-names></string-name>, <string-name><surname>Solomon</surname>, <given-names>EA</given-names></string-name>, <string-name><surname>Seibert</surname>, <given-names>D</given-names></string-name>, and <string-name><surname>DiCarlo</surname>, <given-names>JJ</given-names></string-name> (<year>2014</year>). <article-title>Performance-optimized hierarchical models predict neural responses in higher visual cortex</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A</source>., <volume>111</volume>(<issue>23</issue>):<fpage>8619</fpage>–<lpage>8624</lpage>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><surname>Yamins</surname>, <given-names>DLK</given-names></string-name> and <string-name><surname>DiCarlo</surname>, <given-names>JJ</given-names></string-name> (<year>2016</year>). <article-title>Using goal-driven deep learning models to understand sensory cortex</article-title>. <source>Nat. Neurosci</source>., <volume>19</volume>(<issue>3</issue>):<fpage>356</fpage>–<lpage>365</lpage>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="book"><string-name><surname>Cover</surname>, <given-names>TM</given-names></string-name> and <string-name><surname>Thomas</surname>, <given-names>JA</given-names></string-name> (<year>2006</year>). <source>Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)</source>. <publisher-name>Wiley-Interscience, USA</publisher-name>. ISBN <isbn>0471241954</isbn>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="other"><string-name><surname>Tishby</surname>, <given-names>N</given-names></string-name>, <string-name><surname>Pereira</surname>, <given-names>FC</given-names></string-name>, and <string-name><surname>Bialek</surname>, <given-names>W</given-names></string-name> (<year>2000</year>). <source>The information bottleneck method</source>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><surname>Achille</surname>, <given-names>A</given-names></string-name> and <string-name><surname>Soatto</surname>, <given-names>S</given-names></string-name> (<year>2018</year>). <article-title>Emergence of Invariance and Disentanglement in Deep Representations</article-title>. <source>Journal of Machine Learning Research</source>, <volume>19</volume>(<issue>50</issue>):<fpage>1</fpage>–<lpage>34</lpage>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="web"><string-name><surname>Kleinman</surname>, <given-names>M</given-names></string-name>, <string-name><surname>Achille</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Idnani</surname>, <given-names>D</given-names></string-name>, and <string-name><surname>Kao</surname>, <given-names>J</given-names></string-name> (<year>2021</year>). <article-title>Usable Information and Evolution of Optimal Representations During Training</article-title>. <source>In International Conference on Learning Representations</source>. URL <ext-link ext-link-type="uri" xlink:href="https://openreview.net/forum?id=p8agn6bmTbr">https://openreview.net/forum?id=p8agn6bmTbr</ext-link>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="web"><string-name><surname>Xu</surname>, <given-names>Y</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>S</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>J</given-names></string-name>, <string-name><surname>Stewart</surname>, <given-names>R</given-names></string-name>, and <string-name><surname>Ermon</surname>, <given-names>S</given-names></string-name> (<year>2020</year>). <article-title>A Theory of Usable Information under Computational Constraints</article-title>. <source>In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net. URL</source> <ext-link ext-link-type="uri" xlink:href="https://openreview.net/forum?id=r1eBeyHFDH">https://openreview.net/forum?id=r1eBeyHFDH</ext-link>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="web"><string-name><surname>Tishby</surname>, <given-names>N</given-names></string-name>, <string-name><surname>Pereira</surname>, <given-names>FC</given-names></string-name>, and <string-name><surname>Bialek</surname>, <given-names>W</given-names></string-name> (<year>1999</year>). <source>The Information Bottleneck Method</source>. pages <fpage>368</fpage>–<lpage>377</lpage>. URL <ext-link ext-link-type="uri" xlink:href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.9882">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.9882</ext-link>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><surname>Chandrasekaran</surname>, <given-names>C</given-names></string-name>, <string-name><surname>Peixoto</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Newsome</surname>, <given-names>WT</given-names></string-name>, and <string-name><surname>Shenoy</surname>, <given-names>KV</given-names></string-name> (<year>2017</year>). <article-title>Laminar differences in decision-related neural activity in dorsal premotor cortex</article-title>. <source>Nature Communications</source>, <volume>8</volume>(<issue>1</issue>):<fpage>614</fpage>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="other"><string-name><surname>Kleinman</surname>, <given-names>M</given-names></string-name>, <string-name><surname>Chandrasekaran</surname>, <given-names>C</given-names></string-name>, and <string-name><surname>Kao</surname>, <given-names>J</given-names></string-name> (<year>2021</year>). <article-title>A mechanistic multi-area recurrent network model of decision-making</article-title>. <source>In Thirty-Fifth Conference on Neural Information Processing Systems</source>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><surname>Song</surname>, <given-names>HF</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>GR</given-names></string-name>, and <string-name><surname>Wang</surname>, <given-names>XJ</given-names></string-name> (<year>2016</year>). <article-title>Training excitatory-inhibitory recurrent neural networks for cognitive tasks: a simple and flexible framework</article-title>. <source>PLoS Comput. Biol</source>., <volume>12</volume>(<issue>2</issue>):<fpage>1</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><surname>Markov</surname>, <given-names>NT</given-names></string-name>, <string-name><surname>Ercsey-Ravasz</surname>, <given-names>MM</given-names></string-name>, <string-name><surname>Ribeiro Gomes</surname>, <given-names>AR</given-names></string-name>, <string-name><surname>Lamy</surname>, <given-names>C</given-names></string-name>, <string-name><surname>Magrou</surname>, <given-names>L</given-names></string-name>, <string-name><surname>Vezoli</surname>, <given-names>J</given-names></string-name>, <string-name><surname>Misery</surname>, <given-names>P</given-names></string-name>, <string-name><surname>Falchier</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Quilodran</surname>, <given-names>R</given-names></string-name>, <string-name><surname>Gariel</surname>, <given-names>MA</given-names></string-name>, <string-name><surname>Sallet</surname>, <given-names>J</given-names></string-name>, <string-name><surname>Gamanut</surname>, <given-names>R</given-names></string-name>, <string-name><surname>Huissoud</surname>, <given-names>C</given-names></string-name>, <string-name><surname>Clavagnier</surname>, <given-names>S</given-names></string-name>, <string-name><surname>Giroud</surname>, <given-names>P</given-names></string-name>, <string-name><surname>Sappey-Marinier</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Barone</surname>, <given-names>P</given-names></string-name>, <string-name><surname>Dehay</surname>, <given-names>C</given-names></string-name>, <string-name><surname>Toroczkai</surname>, <given-names>Z</given-names></string-name>, <string-name><surname>Knoblauch</surname>, <given-names>K</given-names></string-name>, <string-name><surname>Van Essen</surname>, <given-names>DC</given-names></string-name>, and <string-name><surname>Kennedy</surname>, <given-names>H</given-names></string-name> (<year>2014</year>). <article-title>A weighted and directed interareal connectivity matrix for macaque cerebral cortex</article-title>. <source>Cereb. Cortex</source>, <volume>24</volume>(<issue>1</issue>):<fpage>17</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><surname>Kaufman</surname>, <given-names>MT</given-names></string-name>, <string-name><surname>Seely</surname>, <given-names>JS</given-names></string-name>, <string-name><surname>Sussillo</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname>, <given-names>KV</given-names></string-name>, and <string-name><surname>Churchland</surname>, <given-names>MM</given-names></string-name> (<year>2016</year>). <article-title>The largest response component in motor cortex reflects movement timing but not movement type</article-title>. <source>eNeuro</source>, <volume>3</volume>(<month>August</month>):ENEURO.0085–16.2016.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><surname>Mastrogiuseppe</surname>, <given-names>F</given-names></string-name> and <string-name><surname>Ostojic</surname>, <given-names>S</given-names></string-name> (<year>2018</year>). <article-title>Linking Connectivity, Dynamics, and Computations in Low-Rank Recurrent Neural Networks</article-title>. <source>Neuron</source>, <volume>99</volume>(<issue>3</issue>):<fpage>609</fpage>–<lpage>623</lpage>.e29.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="other"><string-name><surname>Shwartz-Ziv</surname>, <given-names>R</given-names></string-name> and <string-name><surname>Tishby</surname>, <given-names>N</given-names></string-name> (<year>2017</year>). <article-title>Opening the Black Box of Deep Neural Networks via Information</article-title>. <source>CoRR, abs/1703.00810</source>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><surname>Kaufman</surname>, <given-names>MT</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>MM</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>SI</given-names></string-name>, and <string-name><surname>Shenoy</surname>, <given-names>KV</given-names></string-name> (<year>2014</year>). <article-title>Cortical activity in the null space: permitting preparation without movement</article-title>. <source>Nat. Neurosci</source>., <volume>17</volume>(<issue>3</issue>):<fpage>440</fpage>–<lpage>448</lpage>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><surname>Sengupta</surname>, <given-names>B</given-names></string-name>, <string-name><surname>Stemmler</surname>, <given-names>M</given-names></string-name>, <string-name><surname>Laughlin</surname>, <given-names>SB</given-names></string-name>, and <string-name><surname>Niven</surname>, <given-names>JE</given-names></string-name> (<year>2010</year>). <article-title>Action potential energy efficiency varies among neuron types in vertebrates and invertebrates</article-title>. <source>PLoS computational biology</source>, <volume>6</volume>(<issue>7</issue>):<fpage>e1000840</fpage>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><surname>Attwell</surname>, <given-names>D</given-names></string-name> and <string-name><surname>Laughlin</surname>, <given-names>SB</given-names></string-name> (<year>2001</year>). <article-title>An energy budget for signaling in the grey matter of the brain</article-title>. <source>Journal of Cerebral Blood Flow &amp; Metabolism</source>, <volume>21</volume>(<issue>10</issue>):<fpage>1133</fpage>–<lpage>1145</lpage>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="other"><string-name><surname>Hjelm</surname>, <given-names>RD</given-names></string-name>, <string-name><surname>Fedorov</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Lavoie-Marchildon</surname>, <given-names>S</given-names></string-name>, <string-name><surname>Grewal</surname>, <given-names>K</given-names></string-name>, <string-name><surname>Bachman</surname>, <given-names>P</given-names></string-name>, <string-name><surname>Trischler</surname>, <given-names>A</given-names></string-name>, and <string-name><surname>Bengio</surname>, <given-names>Y</given-names></string-name> (<year>2018</year>). <article-title>Learning deep representations by mutual information estimation and maximization</article-title>. <source>arXiv</source> preprint arXiv:<pub-id pub-id-type="arxiv">1808.06670</pub-id>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="other"><string-name><surname>Achille</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Paolini</surname>, <given-names>G</given-names></string-name>, and <string-name><surname>Soatto</surname>, <given-names>S</given-names></string-name> (<year>2019</year>). <article-title>Where is the information in a deep neural network?</article-title> <source>arXiv</source> preprint arXiv:<pub-id pub-id-type="arxiv">1905.12213</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="book"><string-name><surname>Fisher</surname>, <given-names>RA</given-names></string-name> (<year>1925</year>). <chapter-title>Theory of statistical estimation</chapter-title>. <source>In Mathematical proceedings of the Cambridge philosophical society</source>, volume <volume>22</volume>, pages <fpage>700</fpage>–<lpage>725</lpage>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="web"><string-name><surname>Achille</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Rovere</surname>, <given-names>M</given-names></string-name>, and <string-name><surname>Soatto</surname>, <given-names>S</given-names></string-name> (<year>2019</year>). <article-title>Critical Learning Periods in Deep Networks</article-title>. <source>In International Conference on Learning Representations</source>. URL <ext-link ext-link-type="uri" xlink:href="https://openreview.net/forum?id=BkeStsCcKQ">https://openreview.net/forum?id=BkeStsCcKQ</ext-link>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><surname>Kirkpatrick</surname>, <given-names>J</given-names></string-name>, <string-name><surname>Pascanu</surname>, <given-names>R</given-names></string-name>, <string-name><surname>Rabinowitz</surname>, <given-names>N</given-names></string-name>, <string-name><surname>Veness</surname>, <given-names>J</given-names></string-name>, <string-name><surname>Desjardins</surname>, <given-names>G</given-names></string-name>, <string-name><surname>Rusu</surname>, <given-names>AA</given-names></string-name>, <string-name><surname>Milan</surname>, <given-names>K</given-names></string-name>, <string-name><surname>Quan</surname>, <given-names>J</given-names></string-name>, <string-name><surname>Ramalho</surname>, <given-names>T</given-names></string-name>, <string-name><surname>Grabska-Barwinska</surname>, <given-names>A</given-names></string-name>, <etal>et al.</etal> (<year>2017</year>). <article-title>Overcoming catastrophic forgetting in neural networks</article-title>. <source>Proceedings of the national academy of sciences</source>, <volume>114</volume>(<issue>13</issue>):<fpage>3521</fpage>–<lpage>3526</lpage>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><surname>Dubois</surname>, <given-names>Y</given-names></string-name>, <string-name><surname>Kiela</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Schwab</surname>, <given-names>DJ</given-names></string-name>, and <string-name><surname>Vedantam</surname>, <given-names>R</given-names></string-name> (<year>2020</year>). <article-title>Learning Optimal Representations with the Decodable Information Bottleneck</article-title>. In H <person-group person-group-type="editor">Larochelle, <string-name><given-names>M</given-names> <surname>Ranzato</surname></string-name>, <string-name><given-names>R</given-names> <surname>Hadsell</surname></string-name>, <string-name><given-names>MF</given-names> <surname>Balcan</surname></string-name>, and <string-name><given-names>H</given-names> <surname>Lin</surname></string-name></person-group>, editors, <source>Advances in Neural Information Processing Systems</source>, volume <volume>33</volume>, pages <fpage>18674</fpage>–<lpage>18690</lpage>. Curran Associates, Inc. URL <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2020/file/d8ea5f53c1b1eb087ac2e356253395d8-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/d8ea5f53c1b1eb087ac2e356253395d8-Paper.pdf</ext-link>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><surname>Lillicrap</surname>, <given-names>TP</given-names></string-name>, <string-name><surname>Santoro</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Marris</surname>, <given-names>L</given-names></string-name>, <string-name><surname>Akerman</surname>, <given-names>CJ</given-names></string-name>, and <string-name><surname>Hinton</surname>, <given-names>G</given-names></string-name> (<year>2020</year>). <article-title>Backpropagation and the brain</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>21</volume>(<issue>6</issue>):<fpage>335</fpage>–<lpage>346</lpage>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><surname>Cumming</surname>, <given-names>BG</given-names></string-name> and <string-name><surname>Nienborg</surname>, <given-names>H</given-names></string-name> (<year>2016</year>). <article-title>Feedforward and feedback sources of choice probability in neural population responses</article-title>. <source>Current opinion in neurobiology</source>, <volume>37</volume>:<fpage>126</fpage>–<lpage>132</lpage>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><surname>Nienborg</surname>, <given-names>H</given-names></string-name> and <string-name><surname>Cumming</surname>, <given-names>BG</given-names></string-name> (<year>2009</year>). <article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title>. <source>Nature</source>, <volume>459</volume>(<issue>7243</issue>):<fpage>89</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><surname>Kauvar</surname>, <given-names>IV</given-names></string-name>, <string-name><surname>Machado</surname>, <given-names>TA</given-names></string-name>, <string-name><surname>Yuen</surname>, <given-names>E</given-names></string-name>, <string-name><surname>Kochalka</surname>, <given-names>J</given-names></string-name>, <string-name><surname>Choi</surname>, <given-names>M</given-names></string-name>, <string-name><surname>Allen</surname>, <given-names>WE</given-names></string-name>, <string-name><surname>Wetzstein</surname>, <given-names>G</given-names></string-name>, and <string-name><surname>Deisseroth</surname>, <given-names>K</given-names></string-name> (<year>2020</year>). <article-title>Cortical Observation by Synchronous Multifocal Optical Sampling Reveals Widespread Population Encoding of Actions</article-title>. <source>Neuron</source>, <volume>107</volume>(<issue>2</issue>):<fpage>351</fpage>–<lpage>367.e19</lpage>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><surname>Kleinman</surname>, <given-names>M</given-names></string-name>, <string-name><surname>Chandrasekaran</surname>, <given-names>C</given-names></string-name>, and <string-name><surname>Kao</surname>, <given-names>J</given-names></string-name> (<year>2021</year>). <article-title>A mechanistic multi-area recurrent network model of decision-making</article-title>. <source>Advances in neural information processing systems</source>, <volume>34</volume>:<fpage>23152</fpage>–<lpage>23165</lpage>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="book"><string-name><surname>Goodfellow</surname>, <given-names>I</given-names></string-name>, <string-name><surname>Bengio</surname>, <given-names>Y</given-names></string-name>, and <string-name><surname>Courville</surname>, <given-names>A</given-names></string-name> (<year>2016</year>). <source>Deep Learning</source>. <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="other"><string-name><surname>Pascanu</surname>, <given-names>R</given-names></string-name>, <string-name><surname>Mikolov</surname>, <given-names>T</given-names></string-name>, and <string-name><surname>Bengio</surname>, <given-names>Y</given-names></string-name> (<year>2013</year>). <article-title>On the difficulty of training recurrent neural networks</article-title>. <source>In International Conference on Machine Learning</source>, pages <fpage>1310</fpage>–<lpage>1318</lpage>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="other"><string-name><surname>Kingma</surname>, <given-names>DP</given-names></string-name> and <string-name><surname>Ba</surname>, <given-names>J</given-names></string-name> (<year>2014</year>). <article-title>Adam: A Method for Stochastic Optimization</article-title>. <source>arXiv</source> preprint arXiv:<pub-id pub-id-type="arxiv">1412.6980</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><surname>Brunton</surname>, <given-names>BW</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>MM</given-names></string-name>, and <string-name><surname>Brody</surname>, <given-names>CD</given-names></string-name> (<year>2013</year>). <article-title>Rats and humans can optimally accumulate evidence for decision-making</article-title>. <source>Science</source>, <volume>340</volume>(<issue>6128</issue>):<fpage>95</fpage>–<lpage>98</lpage>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><surname>Ratcliff</surname>, <given-names>R</given-names></string-name> (<year>1978</year>). <article-title>A theory of memory retrieval</article-title>. <source>Psychological review</source>, <volume>85</volume>(<issue>2</issue>):<fpage>59</fpage>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><string-name><surname>Kobak</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Brendel</surname>, <given-names>W</given-names></string-name>, <string-name><surname>Constantinidis</surname>, <given-names>C</given-names></string-name>, <string-name><surname>Feierstein</surname>, <given-names>CE</given-names></string-name>, <string-name><surname>Kepecs</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Mainen</surname>, <given-names>ZF</given-names></string-name>, <string-name><surname>Qi</surname>, <given-names>XL</given-names></string-name>, <string-name><surname>Romo</surname>, <given-names>R</given-names></string-name>, <string-name><surname>Uchida</surname>, <given-names>N</given-names></string-name>, and <string-name><surname>Machens</surname>, <given-names>CK</given-names></string-name> (<year>2016</year>). <article-title>Demixed principal component analysis of neural population data</article-title>. <source>Elife</source>, <volume>5</volume>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><string-name><surname>Sussillo</surname>, <given-names>D</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>MM</given-names></string-name>, <string-name><surname>Kaufman</surname>, <given-names>MT</given-names></string-name>, and <string-name><surname>Shenoy</surname>, <given-names>KV</given-names></string-name> (<year>2015</year>). <article-title>A neural network that finds a naturalistic solution for the production of muscle activity</article-title>. <source>Nat. Neurosci</source>., <volume>18</volume>(<issue>7</issue>):<fpage>1025</fpage>–<lpage>1033</lpage>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><string-name><surname>Kao</surname>, <given-names>JC</given-names></string-name> (<year>2019</year>). <article-title>Considerations in using recurrent neural networks to probe neural dynamics</article-title>. <source>J. Neurophysiol</source>., <volume>122</volume>(<issue>6</issue>):<fpage>2504</fpage>–<lpage>2521</lpage>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="book"><string-name><surname>Barber</surname>, <given-names>D</given-names></string-name> and <string-name><surname>Agakov</surname>, <given-names>F</given-names></string-name> (<year>2003</year>). <chapter-title>The IM Algorithm: A Variational Approach to Information Maximization</chapter-title>. <source>In Proceedings of the 16th International Conference on Neural Information Processing Systems, NIPS’03</source>, page <fpage>201</fpage>–<lpage>208</lpage>. <publisher-name>MIT Press, Cambridge, MA, USA</publisher-name>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="book"><string-name><surname>Poole</surname>, <given-names>B</given-names></string-name>, <string-name><surname>Ozair</surname>, <given-names>S</given-names></string-name>, <string-name><surname>Van Den Oord</surname>, <given-names>A</given-names></string-name>, <string-name><surname>Alemi</surname>, <given-names>A</given-names></string-name>, and <string-name><surname>Tucker</surname>, <given-names>G</given-names></string-name> (<year>2019</year>). <chapter-title>On Variational Bounds of Mutual Information</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>K</given-names> <surname>Chaudhuri</surname></string-name> and <string-name><given-names>R</given-names> <surname>Salakhutdinov</surname></string-name></person-group>, editors, <source>Proceedings of the 36th International Conference on Machine Learning</source>, volume <volume>97</volume> <collab>of Proceedings of Machine Learning Research</collab>, pages <fpage>5171</fpage>–<lpage>5180</lpage>. <publisher-name>PMLR, Long Beach</publisher-name>, <publisher-loc>California, USA. URL</publisher-loc> <ext-link ext-link-type="uri" xlink:href="http://proceedings.mlr.press/v97/poole19a.html">http://proceedings.mlr.press/v97/poole19a.html</ext-link>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89369.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ostojic</surname>
<given-names>Srdjan</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>École Normale Supérieure - PSL</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This manuscript reports a <bold>useful</bold> computational study of information encoding across the monkey prefrontal and pre-motor cortices during decision making. While many of the conclusions are supported with <bold>solid</bold> analyses, the evidence for the main claim, the role of an information bottleneck across areas, is <bold>incomplete</bold>. Refocusing the paper as an RNN modeling study would increase its appeal to a systems and computational neuroscience audience.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89369.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this study, the authors aim to understand why decision formation during behavioural tasks is distributed across multiple brain areas. They hypothesize that multiple areas are used in order to implement an information bottleneck (IB). Using neural activity recorded from monkey DLPFC and PMd performing a 2-AFC task, they show that DLPFC represents various task variables (decision, color, target configuration), while downstream PMd primarily represents decision information. Since decision information is the only information needed to make a decision, the authors point out that PMd has a minimal sufficient representation (as expected from an IB). They then train 3-area RNNs on the same task and show that activity in the first and third areas resemble the neural representations of DLPFC and PMd, respectively. In order to propose a mechanism, they analyse the RNN and find that area 3 ends up with primarily decision information because feedforward connections between areas primarily propagate decision information.</p>
<p>The paper addresses a deep, normative question, namely why task information is distributed across several areas.</p>
<p>Overall, it reads well and the analysis is well done and mostly correct (see below for some comments). My major problem with the paper is that I do not see that it actually provides an answer to the question posed (why is information distributed across areas?). I find that the core problem is that the information bottleneck method, which is evoked throughout the paper, is simply a generic compression method. Being a generic compressor, the IB does not make any statements about how a particular compression should be distributed across brain areas - see major points (1) and (2).</p>
<p>If I ignore the reference to the information bottleneck and the question of why pieces of information are distributed, I still see a more mechanistic study that proposes a neural mechanism of how decisions are formed, in the tradition of RNN-modelling of neural activity as in Mante et al 2013. Seen through this more limited sense, the present study succeeds at pointing out a good model-data match. I point out some suggestions for improvement below.</p>
<p>Major points</p>
<p>
(1) It seems to me that the author's use of the IB is based on the reasoning that deep neural networks form decisions by passing task information through a series of transformations/layers/areas and that these deep nets have been shown to implement an IB. Furthermore, these transformations are also loosely motivated by the data processing inequality.</p>
<p>However, assuming as a given that deep neural networks implement an IB does not mean that an IB can only be implemented through a deep neural network. In fact, IBs could be performed with a single transformation just as well. More formally, a task associates stimuli (X) with required responses (Y), and the IB principle states that X should be mapped to a representation Z, such that I(X;Z) is minimal and I(Y,Z) is maximal. Importantly, the form of the map Z=f(X) is not constrained by the IB. In other words, the IB does not impose that there needs to be a series of transformations. I therefore do not see how the IB by itself makes any statement about the distribution of information across various brain areas.</p>
<p>A related problem is that the authors really only evoke the IB to explain the representation in PMd: Fig 2 shows that PMd is almost only showing decision information, and thus one can call this a minimal sufficient representation of the decision (although ignoring substantial condition independent activity). However, there is no IB prediction about what the representation of DLPFC should look like. Consequently, there is no IB prediction about how information should be distributed across DLPFC and PMd.</p>
<p>(2) Now the authors could change their argument and state that what is really needed is an IB with the additional assumption that transformations go through a feedforward network. However, even in this case, I am not sure I understand the need for distributing information in this task. In fact, in both the data and the network model, there is a nice linear readout of the decision information in dPFC (data) or area 1 (network model). Accordingly, the decision readout could occur at this stage already, and there is absolutely no need to tag on another area (PMd, area 2+3).</p>
<p>Similarly, I noticed that the authors consider 2,3, and 4-area models, but they do not consider a 1-area model. It is not clear why the 1-area model is not considered. Given that e.g. Mante et al, 2013, manage to fit a 1-area model to a task of similar complexity, I would a priori assume that a 1-area RNN would do just as well in solving this task.</p>
<p>I think there are two more general problems with the author's approach. First, transformations or hierarchical representations are usually evoked to get information into the right format in a pure feedforward network. An RNN can be seen as an infinitely deep feedforward network, so even a single RNN has, at least in theory, and in contrast to feedforward layers, the power to do arbitrarily complex transformations. Second, the information coming into the network here (color + target) is a classical xor-task. While this task cannot be solved by a perceptron (=single neuron), it also is not that complex either, at least compared to, e.g., the task of distinguishing cats from dogs based on an incoming image in pixel format.</p>
<p>(3) I am convinced of the author's argument that the RNN reproduces key features of the neural data. However, there are some points where the analysis should be improved.</p>
<p>(a) It seems that dPCA was applied without regularization. Since dPCA can overfit the data, proper regularization is important, so that one can judge, e.g., whether the components of Fig.2g,h are significant, or whether the differences between DLPFC and PMd are significant.</p>
<p>(b) I would have assumed that the analyses performed on the neural data were identical to the ones performed on the RNN data. However, it looked to me like that was not the case. For instance, dPCA of the neural data is done by restretching randomly timed trials to a median trial. It seemed that this restretching was not performed on the RNN. Maybe that is just an oversight, but it should be clarified. Moreover, the decoding analyses used SVC for the neural data, but a neural-net-based approach for the RNN data. Why the differences?</p>
<p>(4) The RNN seems to fit the data quite nicely, so that is interesting. At the same time, the fit seems somewhat serendipitous, or at least, I did not get a good sense of what was needed to make the RNN fit the data. The authors did go to great lengths to fit various network models and turn several knobs on the fit. However, at least to me, there are a few (obvious) knobs that were not tested.</p>
<p>First, as already mentioned above, why not try to fit a single-area model? I would expect that a single area model could also learn the task - after all, that is what Mante et al did in their 2013 paper and the author's task does not seem any more complex than the task by Mante and colleagues.</p>
<p>Second, I noticed that the networks fitted are always feedforward-dominated. What happens when feedforward and feedback connections are on an equal footing? Do we still find that only the decision information propagates to the next area? Quite generally, when it comes to attenuating information that is fed into the network (e.g. color), then that is much easier done through feedforward connections (where it can be done in a single pass, through proper alignment or misalignment of the feedforward synapses) than through recurrent connections (where you need to actively cancel the incoming information). So it seems to me that the reason the attenuation occurs in the inter-area connections could simply be because the odds are a priori stacked against recurrent connections. In the real brain, of course, there is no clear evidence that feedforward connections dominate over feedback connections anatomically.</p>
<p>More generally, it would be useful to clarify what exactly is sufficient:</p>
<p>(a) the information distribution occurs in any RNN, i.e., also in one-area RNNs</p>
<p>
(b) the information distribution occurs when there are several, sparsely connected areas</p>
<p>
(c) the information distribution occurs when there are feedforward-dominated connections between areas</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89369.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Kleinman and colleagues conducted an analysis of two datasets, one recorded from DLPFC in one monkey and the other from PMD in two monkeys. They also performed similar analyses on trained RNNs with various architectures.</p>
<p>The study revealed four main findings. (1) All task variables (color coherence, target configuration, and choice direction) were found to be encoded in DLPFC. (2) PMD, an area downstream of PFC, only encoded choice direction. (3) These empirical findings align with the celebrated 'information bottleneck principle,' which suggests that FF networks progressively filter out task-irrelevant information. (4) Moreover, similar results were observed in RNNs with three modules.</p>
<p>While the analyses supporting results 1 and 2 were convincing and robust, I have some concerns and recommendations regarding findings 3 and 4, which I will elaborate on below. It is important to note that findings 2 and 4 had already been reported in a previous publication by the same authors (ref. 43).</p>
<p>Major recommendation/comments:</p>
<p>
The interpretation of the empirical findings regarding the communication subspace in relation to the information bottleneck theory is very interesting and novel. However, it may be a stretch to apply this interpretation directly to PFC-PMd, as was done with early vs. late areas of a FF neural network.</p>
<p>In the RNN simulations, the main finding indicates that a network with three or more modules lacks information about the stimulus in the third or subsequent modules. The authors draw a direct analogy between monkey PFC and PMd and Modules 1 and 3 of the RNNs, respectively. However, considering the model's architecture, it seems more appropriate to map Area 1 to regions upstream of PFC, such as the visual cortex, since Area 1 receives visual stimuli. Moreover, both PFC and PMd are deep within the brain hierarchy, suggesting a more natural mapping to later areas. This contradicts the CCA analysis in Figure 3e. It is recommended to either remap the areas or provide further support for the current mapping choice.</p>
</body>
</sub-article>
</article>