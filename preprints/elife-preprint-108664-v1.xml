<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">108664</article-id>
<article-id pub-id-type="doi">10.7554/eLife.108664</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108664.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Overcoming distortion in multidimensional predictive representation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0619-2280</contrib-id>
<name>
<surname>Prentis</surname>
<given-names>Euan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>eprentis@uchicago.edu</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6070-4945</contrib-id>
<name>
<surname>Bakkour</surname>
<given-names>Akram</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>Department of Psychology, The University of Chicago</institution></institution-wrap>, <city>Chicago</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>Institute for Mind and Biology, The University of Chicago</institution></institution-wrap>, <city>Chicago</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>Neuroscience Institute, The University of Chicago</institution></institution-wrap>, <city>Chicago</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8451-0523</contrib-id><role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-11-21">
<day>21</day>
<month>11</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP108664</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-08-25">
<day>25</day>
<month>08</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-07-31">
<day>31</day>
<month>07</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.07.29.667463"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Prentis &amp; Bakkour</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Prentis &amp; Bakkour</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-108664-v1.pdf"/>
<abstract>
<p>Predicting how our actions will affect future events is essential for effective behavior. However, learning predictive relationships is not trivial in a multidimensional world where numerous causes bring any one event about. Here we examine (1) how these multidimensional dynamics may distort predictive learning, and (2) how inductive biases may mitigate these harmful effects. We developed a theoretical framework for studying this problem using a computational successor features model. Model simulations demonstrate how spurious observations arise in such contexts to compound noise in memory and limit the generalizability of learning. We then provide behavioral evidence in human participants for a semantic inductive bias that constrains these predictive learning dynamics based on the semantic relatedness of causes and outcomes. Together, these results show that prior knowledge can shape multidimensional predictive learning, potentially minimizing severe memory distortions that may arise from complex everyday observations.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>reinforcement learning</kwd>
<kwd>memory</kwd>
<kwd>decision making</kwd>
<kwd>predictive learning</kwd>
<kwd>representation learning</kwd>
<kwd>inductive bias</kwd>
<kwd>successor features</kwd>
</kwd-group>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/021nxhr62</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>2342775</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>To make good decisions, humans must predict how actions will affect future experiences. However, making such predictions is not straightforward in a multidimensional world where numerous causal processes drive how one event leads to the next. The co-occurrence of these causes creates ambiguity about which causes produce which outcomes. Understanding how these causal mappings are disentangled in memory is essential to understanding how humans effectively predict complex futures during decision making.</p>
<p>The ability to make predictive inferences has been long thought to rely on memory representations that encode a structured model of the environment<sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c4">4</xref></sup>. An early formulation of this idea was Edward Tolman’s concept of cognitive maps, that mentally represent the spatial layouts of environments to aid flexible navigation<sup><xref ref-type="bibr" rid="c5">5</xref></sup>. The neural basis for these representations was later demonstrated through the discovery of place and grid cells in the hippocampal-entorhinal system, which are thought to encode, respectively, specific locations in space and a coordinate system for space<sup><xref ref-type="bibr" rid="c6">6</xref></sup>. More recent work has extended the apparent role of these representations beyond physical space, showing that similar neural codes organize abstract conceptual information, such as social dimensions<sup><xref ref-type="bibr" rid="c7">7</xref></sup>, conceptually relevant feature dimensions<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref></sup>, and a “bird” space that reflects differences in neck and leg length<sup><xref ref-type="bibr" rid="c10">10</xref></sup>. These codes have also been theorized to implement not just Euclidean maps, but also graph-like representations that capture the relational structure between discrete concepts, states, or events<sup><xref ref-type="bibr" rid="c4">4</xref>,<xref ref-type="bibr" rid="c11">11</xref>,<xref ref-type="bibr" rid="c12">12</xref></sup>. Importantly, these relations can be statistical regularities, such as the frequency with which events transition between one another<sup><xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c14">14</xref></sup>. These representations can therefore be used to predict how events unfold into the future.</p>
<p>The reinforcement learning framework formalizes how predictive representations are used in service of goal-directed behavior<sup><xref ref-type="bibr" rid="c15">15</xref></sup>. In this framework, an agent makes actions to transitions between states in an environment, with the aim of occupying rewarding states with desirable features. Predictive representations enable the agent to make inferences about distal states that may be several steps away, facilitating behaviors that will be the most rewarding in the long run. One influential model, successor features<sup><xref ref-type="bibr" rid="c16">16</xref>–<xref ref-type="bibr" rid="c19">19</xref></sup> (SF; a generalization of the successor representation) represents each state in terms of the <italic>features</italic> expected to be encountered over time after entering that state. Thus, if previously a state has not directly comprised desirable features but proximal states have, the agent would still choose to approach. This model has been found to capture key patterns of predictive learning in both behavior<sup><xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c21">21</xref></sup> and the brain<sup><xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c22">22</xref>–<xref ref-type="bibr" rid="c26">26</xref></sup>. However, work to date has, to our knowledge, only studied how SF representations are learned for each state rather than for each of the multiple independent features that compose states. Consequently, it has not been characterized how feature representations may be distorted when causal processes defined over features co-occur.</p>
<p>To illustrate how feature-level causal dynamics may distort representations, consider the following example (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Suppose two causal processes are defined by feature A1 producing A2 (A1→A2), and feature B1 producing B2 (B1→B2). In a one-dimensional environment, an event might comprise {A1}, which reliably produces event {A2}, allowing A1→A2 to be learned without interference. However, in a multidimensional environment, A1 and B1 may co-occur within a single event {A1, B1}, which reliably produces event {A2, B2}. Since A1→A2 and B1→B2 unfold together, spurious transitions A1⇢B2 and B1⇢A2 will also be observed. These spurious and causal observations cannot be disambiguated, leading to faulty or uncertain inference<sup><xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c28">28</xref></sup>. The first aim of the present research is to simulate a fully feature-based SF model to demonstrate how these spurious observations may distort predictive learning. We argue that because such spurious observations are inherent to our multidimensional world, predictive representations of real-world experience are inherently prone to distortion.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1:</label>
<caption><title>Feature-based model simulations.</title>
<p>Simulation environments varied in (<bold>A</bold>) dimensionality and (<bold>B</bold>) causal depth. (<bold>A</bold>) Environments had either one or two features per state. Since A1→A2 and B1→B2 unfold together in the two-dimensional environment, spurious transitions A1⇢B2 and B1⇢A2 are also observed. We additionally consider a causal learner model that fully suppresses spurious information during updating. (<bold>B</bold>) Environments consisted of either (light) 1-, 2-, 3-, or 4-step (dark) causal chains, beginning with <italic>f</italic><sup><italic>START</italic></sup>and ending with <italic>f</italic><sup><italic>TERMINAL</italic></sup>. (<bold>C</bold>) Mean learning curves in the one-dimensional environments by causal depth. (<bold>D</bold>) Mean learning curve in the two-dimensional environments by causal depth for causal learners (grey lines) and “regular” learners (red lines). For <bold>C</bold> and <bold>D</bold>, P(Reward) is the proportion of the maximum reward (<bold>C</bold> = 1, <bold>D</bold> = 2) agents could earn on each trial. (<bold>E</bold>) Proportion of spurious information in successor matrix <italic>M</italic> by environment depth and the number of steps a feature is from <italic>f</italic><sup><italic>TERMINAL</italic></sup>. (<bold>F</bold>) Schematic demonstrating how spurious information may compound in deeper feature representations (as shown in <bold>E</bold>). Causal observations (solid lines) are constrained by the deterministic causal processes that generate them, producing simple chains of observations over multiple steps. Conversely, since spurious observations (dashed lines) are not constrained by a mechanism in the environment, they can occur between a more diffuse set of features. This diffusivity expands over multiple steps, producing increasingly less constrained chains of spurious observations. Due to this, features that are deeper in causal chains (more steps away from <italic>f</italic><sup><italic>TERMINAL</italic></sup>) will compound much more spurious information through these diffuse webs (see <bold>E</bold>). In turn, predictive inferences (red arrows) about deeper features will be noisier and more diffusive, leading to poorer behavioral performance (see <bold>D</bold>). (<bold>G</bold>) The representational similarity of start feature pairs (Pearson’s correlation of <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="667463v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="667463v1_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, for features <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="667463v1_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula id="inline-eqn-4"><inline-graphic xlink:href="667463v1_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) by the rate at which they co-occurred during training in the two-dimensional environments. A separate line is plotted for each level of causal depth. (<bold>H</bold>) Proportion of reward earned on old test trials by target frequency during training. (<bold>I</bold>) Proportion of reward earned on test trials with just one possible causal and spurious inference by options novelty. All error bars indicate 95% CIs across simulated agents.</p></caption>
<graphic xlink:href="667463v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Given this susceptibility to distortion, how do humans learn accurate predictive representations? We suggest that a class of <italic>inductive bias</italic> may attenuate spurious observations during learning. Inductive biases shape learning towards certain interpretations of experience over others<sup><xref ref-type="bibr" rid="c29">29</xref>–<xref ref-type="bibr" rid="c35">35</xref></sup>. Critically, inductive biases tend to orient learning towards stable properties of the environment<sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c35">35</xref>–<xref ref-type="bibr" rid="c37">37</xref></sup>. For example, beliefs formed over the lifespan are encoded in semantic memory, which extracts the statistically regular features of our experiences<sup><xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup>. <italic>Semantic inductive biases</italic> that shape learning based on semantic knowledge thus direct learning towards stable properties of past experience<sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup>. Causal processes are one such stable property. As the generative components of experience, causal processes are stable across contexts<sup><xref ref-type="bibr" rid="c40">40</xref></sup>. Consequently, inductive biases may incidentally shape representations around the predictions of stable causal processes while suppressing unstable spurious observations. The second aim of the present research is to test whether human participants express such a semantic inductive bias on multidimensional predictive learning.</p>
<p>To summarize, the aims of the present research are two-fold. Firstly, we simulate feature-based predictive learning models to demonstrate how spurious observations in multidimensional environments make memory inherently prone to distortion. Secondly, we investigate whether human participants express a semantic inductive bias on predictive learning that theoretically attenuates the distortive effects of spurious observations. Results illustrate the crucial role inductive biases play in shaping memory for effective behavior in our complex world.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Simulations</title>
<p>To characterize how predictive learning may be inherently prone to distortion in multidimensional environments, we implemented a fully feature-based SF learner model (Methods – Computational Models, Feature-Based Model). This model learned a predictive representation for each feature rather than each state in the environment, and could update representations in parallel as features co-occurred.</p>
<p>The feature-based model was simulated on a task in which agents observed simple causal chains defined over features (<xref rid="fig1" ref-type="fig">Fig. 1A, 1B</xref>&amp;<xref ref-type="fig" rid="fig2">2B</xref>) and made compositional predictive inferences to earn reward (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). The causal chains could span a single or multiple steps (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>), but were always observed to start with feature <italic>f</italic><sup><italic>START</italic></sup> and end with feature <italic>f</italic><sup><italic>TERMINAL</italic></sup>. Crucially, these causal chains could co-occur in multidimensional environments, generating spurious observations that may interfere with learning (<xref rid="fig1" ref-type="fig">Fig. 1A</xref> &amp; <xref ref-type="fig" rid="fig2">2B</xref>). On each trial (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>), the agent was tasked with producing a target terminal state <italic>s</italic><sup><italic>TARGET</italic></sup> (or <bold><italic>w</italic></bold>). The agent was then presented a set of start feature options, grouped into a number of categories corresponding to the dimensionality of the environment. The agent selected one feature from each category to compose a start state <italic>s</italic><sup><italic>START</italic></sup> that may lead to <italic>s</italic><sup><italic>TARGET</italic></sup>. Then the causal process initiated by <italic>s</italic><sup><italic>START</italic></sup> and ending with <italic>s</italic><sup><italic>TERMINAL</italic></sup>was observed. Finally, a reward was paid corresponding to the number of features shared between <italic>s</italic><sup><italic>TERMINAL</italic></sup>and <italic>s</italic><sup><italic>TARGET</italic></sup>. The more accurately the agent learned a representation (<bold><italic>M</italic></bold>) that reflected the outcomes of these causal processes, the more reward it earned.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2:</label>
<caption><title>Robot task design.</title>
<p>(<bold>A</bold>) Trial procedure (1-step, 2-dimensional environment). Participants are presented with a blueprint for the robot they are to ultimately build. They then compose a builder robot they think will produce the target robot. During training, they then first see the builder (start) robot they composed followed by the final built (terminal) robot. Finally, they receive reward commensurate to the number of features that overlap between the terminal and target. The example here is from the semantic congruent condition, where start and terminal features are drawn from the same semantic categories. The top-bottom placement of a robot’s features was randomized within and across trials. For example, here, the start robot was displayed with the antenna on top, while the terminal robot was displayed with the antenna on the bottom. (<bold>B</bold>) Example transition structures in the semantic incongruent and congruent conditions. Causal transitions (solid arrows) are defined between start and terminal features, and the co-occurrence of start features generates spurious observations (dashed arrows). However, whereas all transitions are defined out-of-category in the semantic incongruent condition, the causal transitions are defined within category in the semantic congruent condition (e.g., head→head). Thus, a semantic bias would be expressed as upweighted learning of the causal transitions in the congruent relative to incongruent condition. (<bold>C</bold>) Feature co-occurrences at training and test, by target and options definition and semantic congruency condition. During training, a subset of feature combinations (AB or CD – old) were presented in each training block. However, at test, both these old combinations and new feature combinations comprising features from across the two training blocks were observed. Moreover, at test, all possible combinations of old and novel targets and options sets were presented (bidirectional arrows), producing 144 unique trials.</p></caption>
<graphic xlink:href="667463v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Agents completed the task in both one- and two-dimensional environments, wherein states respectively comprised one or two features (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Since causal processes could not co-occur in the one-dimensional environments but did co-occur in the two-dimensional environments, we could compare learning in the absence versus presence of spurious transitions between these environments. To probe how spurious transitions affected the formation of compressed multistep representations, we additionally varied the depth of the causal chains. That is, each agent was simulated in an environment with either one-, two-, three-, or four-step causal chains (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>).</p>
<p>We first compare agents’ behavioral performance. A strength of the SF learner is that, irrespective of an environment’s depth, the model should converge on an optimal policy if the environment is deterministic. The feature-based model demonstrated this principle in the one-dimensional environments (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>). Whereas early in training there were some differences across depths in reward earnings, these converged at the same level by the end of training. However, in the two-dimensional environments, performance converged at lower levels in deeper environments (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>). To verify that this decrement in performance was driven by learning about spurious transitions, we simulated a version of the model that was biased towards learning only the causal transitions. Specifically, when incorporating information from the successor state during updating, this causal learner model fully discounted information that would be indicative of a spurious transition (that is, <italic>b</italic>=1; see Methods – Computational Models: Feature-Based Model). Reinforcing that spurious learning drove the performance deficit in two-dimensional environments, the causal-only agents exhibited comparable performance to that of agents in the one-dimensional environments (<xref rid="fig1" ref-type="fig">Fig. 1D</xref> – grey lines).</p>
<p>Two causal and two spurious transitions were observed on each step in all two-dimensional environments – irrespective of causal depth. Given that this rate of spurious to causal transitions did not vary with causal depth, why did the spurious transitions have a more deleterious impact on performance in the deeper environments? To answer this, we inspected how spurious information accrued in the model’s learned representations. For each feature representation an agent learned, we computed the proportion of spurious information as the sum of the values corresponding to spurious associations divided by the sum of the values corresponding to spurious or causal associations. This showed that spurious information had an outsized representation in deeper features, that were more steps away from <italic>f</italic><sup><italic>TERMINAL</italic></sup>(<xref rid="fig1" ref-type="fig">Fig. 1E</xref>). Thus, even if spurious and causal transitions are observed at the same rate, spurious information can compound in deep feature representations, harming inference (red lines in <xref rid="fig1" ref-type="fig">Fig. 1D</xref>).</p>
<p>This compounding occurs due to the diffuse nature of spurious associations, that enables spurious noise to propagate widely through memory via SF updating (<xref rid="fig1" ref-type="fig">Fig. 1F</xref>). Spurious associations are more diffuse than causal associations because they are not constrained by any specific causal mechanism in the environment. That is, an environment with deterministic causal processes will always produce the same causal transition from <italic>f</italic><sup><italic>START</italic></sup>, while spurious observations will vary simply by what other features <italic>f</italic><sup><italic>START</italic></sup> co-occurs with across states. Any given feature’s diffuse spurious associations will likely in turn have their own downstream diffuse spurious associations. This broad and deep diffusivity enables spurious information to propagate widely through memory via SF updating (<xref ref-type="disp-formula" rid="eqn15">Equation 15</xref>), particularly compounding in deeper feature representations with more long-run associations. Thus, the process that produces efficient multistep representations enables spurious noise to compound through memory. Given that real-world experience is driven by deep causal processes, this effect has important implications for how predictive representations may be formed in naturalistic multidimensional environments.</p>
<p>The distortive effect of spurious transitions on learning reflects not just an injection of noise, but a tuning of representations to specific learning contexts. Spurious transitions in effect act as links between disparate causal processes. If a set of causal processes frequently co-occur, these links are reinforced. Representations of co-occurring features thus converge on common tunings that reflect conjunctive predictions of future features. In short, instead of tuning to the underlying causal processes (e.g., A1→A2, B1→B2), feature representations tune to the learning context (e.g., {A1, B1} → {A2, B2}). To demonstrate this effect, we analyzed how representations in the two-dimensional environments tuned based on the frequency with which features co-occurred during learning. To induce variation in feature co-occurrence frequency, we manipulated the rates at which different target states appeared. Specifically, half the targets occur twice as frequently as the others, while terminal features occurred at the same rate across these targets. This encouraged regular inferences on frequent trials, such that certain start features co-occurred more frequently. Then for each agent, we characterized how similarly each pair of features were represented by computing the Pearson’s correlation of their corresponding SF vectors. Reflecting a tuning to specific feature conjunctions, representational similarity increased as features co-occurred more frequently (red lines in <xref rid="fig1" ref-type="fig">Fig. 1G</xref>). The causal learners’ representations did not mirror this effect (grey lines in <xref rid="fig1" ref-type="fig">Fig. 1G</xref>), demonstrating that this specificity tuning was driven by the spurious observations.</p>
<p>High specificity tuning had ensuing effects on agents’ inferences. To characterize these inferences after training, agents completed a test phase in which outcomes were hidden to prevent continued learning. Importantly, an extensive set of targets and options were displayed to probe the generalizability of learning (<xref rid="fig2" ref-type="fig">Fig. 2C</xref> – akin to semantic congruent). Whereas each training half included only “old” targets/options (AB, CD), test also included “novel” targets/options comprising unseen combinations of features (AC, AD, BC, BD). Additionally, all combinations of target and options were shown (e.g., AB-AB, AB-AC, AB-AD, AB-BC, etc.), producing 144 unique trials. Reflecting specificity tuning, more reward was earned on: (1) old trials that occurred frequently versus infrequently during training (<xref rid="fig1" ref-type="fig">Fig. 1H</xref>); and (2) trials with old versus novel options (<xref rid="fig1" ref-type="fig">Fig. 1I</xref>; specifically, this analysis was constrained to trials where only one causal and one spurious inference was possible – see Methods, Preregistration and Deviations). The causal learner performed equivalently within both sets of comparisons (grey lines in <xref rid="fig1" ref-type="fig">Fig. 1H</xref>&amp;<xref ref-type="fig" rid="fig1">I</xref>), again demonstrating that the spurious observations drove both effects.</p>
<p>In all, these simulations demonstrate that spurious observations make predictive learning inherently prone to distortion in multidimensional environments. Specifically, this spurious information makes representations both noisier and more biased towards idiosyncratic contexts rather than underlying causal processes. Mechanisms that limit the deleterious effects of spurious transitions may thus be essential for effective predictive learning in the real world.</p>
</sec>
<sec id="s2b">
<title>Human Experiment</title>
<p>What mechanism may limit the impact of spurious observations on predictive learning? We posit that since semantic memory extracts stable properties across experiences<sup><xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup>, it may incidentally reflect stable causal associations. Therefore, inductive biases derived from semantic memory may help direct learning towards causal observations.</p>
<p>To test whether a semantic bias shapes human predictive learning, we ran a preregistered experiment in which 100 participants completed the one-step, two-dimensional task used in the simulations (<xref rid="fig2" ref-type="fig">Fig. 2</xref>; 72 training trials, 144 test trials). Crucially, we used visual stimuli (robots) where features had an implied semantic structure (robot parts were drawn from four categories: heads, antennas, arms, bodies). We then varied across two between-subjects conditions whether this semantic structure was <italic>congruent</italic> or <italic>incongruent</italic> with the causal task structure (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). If participants used a semantic bias to direct predictive learning, we hypothesized that this would be expressed as bolstered learning of the causal structure in the semantic congruent condition.</p>
</sec>
<sec id="s2c">
<title>Semantic bias directed predictive learning</title>
<p>The experiment’s key marker of a semantic bias would be upweighted learning of causal relative to spurious transitions in the semantic congruent condition. To assess this, we analyzed the extent to which observations of causal versus spurious transitions influenced choice. This involved fitting a Bayesian multinomial logistic regression to each participant’s training data that predicted the composition made on each trial based on recent causal and spurious transitions. On a trial, a participant could have produced one of four possible compositions, which we arbitrarily label 0, 1, 2, 3. Treating composition 0 as the reference class, we modelled the choice of each of the other three compositions <italic>s</italic> relative to composition 0 with a distinct logit model:
<disp-formula id="eqn1">
<graphic xlink:href="667463v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where: (1) Δ<italic>causal</italic><sub>+,1</sub> is the relative probability that composition <italic>s</italic> versus 0 will produce the target based on recently observed <italic>causal</italic> transitions; and (2) Δ<italic>spurious</italic><sub>+,1</sub> is the relative probability that composition <italic>s</italic> versus 0 will produce the target based on recently observed <italic>spurious</italic> transitions (see Methods – Causal and Spurious Transition Evidence for more information). Greater β<sub><italic>s,causal</italic></sub> amd <italic>β</italic><sub><italic>s,spurious</italic></sub> fits thus respectively reflect greater uses of causal and spurious learning during inference. Since six coefficients were fit across the three logit models, the three <italic>β</italic><sub><italic>s,causal</italic></sub> and three <italic>β</italic><sub><italic>s,spurious</italic></sub> are metrics that together reflect how much causal versus spurious information drove participants’ behavior in the task.</p>
<p>In line with a semantic bias, we found that causal relative to spurious transitions had a weaker influence on choice in the congruent condition (M = 0.875, SD = 0.352, 95% HDI = [0.173, 1.563]; <xref rid="fig3" ref-type="fig">Fig. 3A</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S1</xref>; <xref ref-type="supplementary-material" rid="supp1">Fig. S11</xref>). This suggests a semantic bias was leveraged in the congruent condition to better learn the causal predictions.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3:</label>
<caption><title>Training Performance.</title>
<p>(<bold>A</bold>) Spurious and causal transition influence coefficients by semantic congruency condition. (<bold>B</bold>). Training reward earnings by training target frequency and semantic congruency condition. (<bold>C</bold>) Training reward earnings by spurious transition influence coefficient fit. All error bars are 95% HDIs. Density plots show posteriors from the Bayesian regression models, with red lines indicating 0.</p></caption>
<graphic xlink:href="667463v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Semantic bias reduced learning specificity</title>
<p>The simulations demonstrated that spurious learning binds features into context-specific predictive representations (<xref rid="fig1" ref-type="fig">Fig. 1G</xref>&amp;<xref ref-type="fig" rid="fig1">H</xref>). Since we expected that the lack of a semantic bias in the semantic incongruent condition would produce more spurious learning, learning should also be more specific in the incongruent condition. In line with this, we found that reward earnings in the congruent compared to incongruent condition differed less by trial frequency (M = −0.139, SD = 0.034, 95% HDI = [−0.204, −0.072]; <xref rid="fig3" ref-type="fig">Fig. 3B</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S2</xref>). To validate these results, we repeated the analysis on a subset of “old” test trial, which had the same targets and feature options from training, only choice outcomes were not displayed (<xref ref-type="supplementary-material" rid="supp1">Fig. S3</xref>). Reinforcing the evidence for greater learning specificity in the semantic incongruent condition, there was a negative interaction between condition and frequency (M = −0.191, SD = 0.096, 95% HDI = [−0.366, −0.001], <xref ref-type="supplementary-material" rid="supp1">Table S3</xref>).</p>
<p>Central to the specificity hypothesis is the rationale that spurious learning tunes representations towards frequent robot transitions. It should therefore be expected that – irrespective of condition – participants whose choices were more strongly influenced by the spurious transitions should also display more sensitivity to the frequency manipulation. An exploratory analysis supported this prediction, showing that participants earned more reward on frequent than infrequent trials when their training choices were overall more strongly influenced by spurious transitions (M = 0.068, SD = 0.009, 95% HDI = [0.050, 0.087]; <xref rid="fig3" ref-type="fig">Fig. 3C</xref>, <xref ref-type="supplementary-material" rid="supp1">Table S4</xref>). Conversely, there was no relationship between causal transition influence and reward earnings on frequent versus infrequent trials (M =-0.001, SD = 0.004, 95% HDI = −0.009, 0.007]; <xref ref-type="supplementary-material" rid="supp1">Fig. S4</xref>). Together, these results demonstrate that higher learning specificity was driven by greater spurious learning.</p>
<p>We can again validate these results by repeating the analysis on old test trials. Reinforcing the evidence for greater learning specificity with more spurious learning, test reward earnings differed more by training trial frequency with greater training spurious transition influence (M = 0.093, SD = 0.024, 95% HDI = [0.043, 0.139]; <xref ref-type="supplementary-material" rid="supp1">Fig. S5, </xref><xref ref-type="supplementary-material" rid="supp1">Table S5</xref>) and did not differ by training trial frequency with greater training causal transition influence (M = −0.006, SD = 0.011, 95% HDI = −0.029, 0.015]; <xref ref-type="supplementary-material" rid="supp1">Fig. S6</xref>).</p>
</sec>
<sec id="s2e">
<title>No evidence the semantic bias improved generalization</title>
<p>The simulations demonstrated that by tuning learning to frequent state transitions, spurious learning should impair inference not only about infrequent states, but also about entirely novel states (<xref rid="fig1" ref-type="fig">Fig. 1I</xref>). A semantic bias that reduces spurious learning should thus improve generalization to novel states during the test phase.</p>
<p>We evaluated participants’ abilities to make inferences about novel states on trials with novel options and make inferences for novel tasks or goals on trials with novel targets. We predicted generalization about both would be impaired in the incongruent condition, where spurious learning was unattenuated by the semantic bias. However, we found no differences in reward earnings by condition and options or target novelty (options: M = 0.025, SD = 0.022, 95% HDI = −0.019, 0.069], <xref rid="fig4" ref-type="fig">Fig. 4A</xref>; target: M = 0.032, SD = 0.023, 95% HDI = [−0.011, 0.078], <xref rid="fig4" ref-type="fig">Fig. 4B</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S6</xref>). This may in part be because the environment was not sufficiently complex to make differences in old versus novel performance identifiable. We explore this possibility below.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Fig. 4:</label>
<caption><title>Test Performance.</title>
<p>(<bold>A</bold>) Test reward earnings by semantic congruency condition and options novelty. (<bold>B</bold>). Test reward earnings by semantic congruency condition and target novelty. For <bold>A</bold> and <bold>B</bold>, analyses were restricted to test trials where only one possible causal and spurious inference was possible based on the options and target. (<bold>C</bold>) Composition spurious predictiveness by semantic congruency condition on test trials where only spurious inferences were possible based on the options and target. All error bars are 95% HDIs. Density plots show posteriors from the Bayesian regression models, with red lines indicating 0.</p></caption>
<graphic xlink:href="667463v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We expected generalization to be less accurate in the incongruent condition because greater spurious learning would interfere with causal transition inferences. However, we also predicted that spurious learning could be associated with qualitative differences in the use of spurious information during inference on certain novel trials. Namely, there was a subset of test trials on which only spurious inferences could be made. For example, on a trial in the congruent condition with options AC and target BD, no causal transition and two spurious transitions (A⇢B, C⇢D) would have been observed during training. We hypothesized that greater spurious learning in the semantic incongruent condition would encourage participants to actively use spurious information during inference on these trials.</p>
<p>To test this, for each composition, we computed composition spurious predictiveness defined as the number of transitions between the composition and target features that would have been spuriously observed during training. This measure can also be thought of as the reward that would have been received if the causal task structure was defined in terms of these spurious transitions. However, while there was a trend towards less spurious inference in the semantic congruent condition, we did not find statistical evidence for this effect (M = −0.079, SD = 0.061, 95% HDI = [−0.201, 0.33]; <xref rid="fig4" ref-type="fig">Fig. 4C</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S7</xref>).</p>
</sec>
<sec id="s2f">
<title>Idiosyncratic biases captured by the successor features model</title>
<p>Each person’s semantic knowledge is idiosyncratic. We should therefore expect idiosyncratic differences in semantic bias between participants. However, our analyses thus far have assumed that a semantic bias in the robot task arises solely based on discrete differences between contrived categories (i.e., heads, arms, bodies, antennas) and should be common across participants. We therefore sought to capture individual differences in bias using our computational modelling framework.</p>
<p>The feature-based model was fit separately to each participant’s data. Crucially, the model included a causal-bias parameter (<italic>b</italic>=(0, 1)) that governed the extent to which information indicative of a spurious transition was downweighted during updating (<xref ref-type="disp-formula" rid="eqn15">Equation 15</xref>). Since <italic>b</italic>is agnostic to the underlying memory structure that helps the learner attenuate spurious observations, it can capture individual differences in bias that go beyond the task’s categorical semantic structure.</p>
<p>While we have assumed so far that participants learned at the level of features (feature transitions), it was entirely possible for them to learn at the level of feature conjunctions (robot transitions). Since the inductive bias acts on feature-based transition dynamics, it would be invalid to interpret differences in <italic>b</italic>for conjunctive learners. We therefore sought to identify which participants performed feature-based versus conjunctive learning, and verify that the former generally captured behavior better in the task. To do this, we compared the fit of the feature-based model to two <italic>conjunctive learner</italic> models. The basic <italic>conjunctive</italic> model represented each robot as a unique state, acquiring distinct predictive representations for different robots that may share a common feature. The <italic>conjunctive sampler</italic> model learned about robots in an identical way, only it also possessed an inference mechanism that enabled it to retroactively integrate prior learning at choice. The advantage of the latter model is it can generalize learning to novel states, better reflecting participants’ abilities to make inferences about novel options and targets during test.</p>
<p>We characterized whether participants learned at the level of features or feature conjunctions by comparing the fit of the three models (<xref ref-type="supplementary-material" rid="supp1">Table S13</xref>). For each participant, the best fitting model was identified as that which minimized the Akaike information criterion (<italic>AIC</italic>). A null model was also considered by computing an <italic>AIC</italic> based on the random choice probability for each training and test trial (p = 0.25). Statistically verifying that feature-based learning best explained participants’ choices, a multinomial logistic regression found that a larger proportion of participants (p = 0.46) were better fit by the feature-based model than each of the alternative models (null: p = 0.24, M = −0.640, SD = 0.254, 95% HDI = [−1.174, −0.176]; conjunctive: p = 0.09, M = −1.629, SD = 0.362, 95% HDI = [−2.314, −0.916]; conjunctive sampler: p = 0.21, M = −0.778, SD = 0.262, 95% HDI = [−1.130, −0.268]). To assess the relative strength of the four model fits within each participant, we converted <italic>AIC</italic> values to relative likelihoods, which reflect the plausibility of a given model relative to the alternatives. This analysis showed that those best fit by the feature-based model were strongly best fit by it, as revealed by lower relative likelihoods for alternative models among those best fit by the feature-based model (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>, <xref ref-type="supplementary-material" rid="supp1">Table S13</xref>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Fig. 5:</label>
<caption><title>Model-based analyses.</title>
<p>(<bold>A</bold>) Relative likelihoods of computational model fits by participant. (<bold>B</bold>). Spurious and causal transition influence coefficient fit by <italic>b</italic>fit. (<bold>C</bold>) Training reward earnings on trials with frequent versus infrequent targets by <italic>b</italic>fit. (<bold>D</bold>) Test reward earnings on trials with old versus novel options by <italic>b</italic>fit. (<bold>E</bold>) Composition spurious predictiveness by <italic>b</italic>fit. All error bars are 95% HDIs. Density plots show posteriors from the Bayesian regression models, with red lines indicating 0.</p></caption>
<graphic xlink:href="667463v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Having identified the participants best fit by the feature-based model, we could investigate the fit of the causal-bias parameter <italic>b</italic>amongst these participants. The transition influence analysis demonstrated that participants were biased towards causal information in the semantic congruent condition (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). We predicted that this differential bias would be captured in the fit of <italic>b</italic>. However, we found no difference in <italic>b</italic>by condition (M = −0.106, SD = 0.402, 95% HDI = [−0.880, 0.676]; <xref ref-type="supplementary-material" rid="supp1">Fig. S7</xref>).</p>
<p>The lack of difference in <italic>b</italic>fit by condition was surprising given that we observed differences in behavior by condition (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>) and the computational models and <italic>b</italic>were sufficiently recoverable (<xref ref-type="supplementary-material" rid="supp1">Fig. S1, S2</xref>). Despite this, <italic>b</italic>may still have been sensitive to idiosyncratic biases that emerge irrespective of the between-subjects conditions. We therefore ran a set of exploratory analyses to test whether the fit of <italic>b</italic>captured patterns of behavior in-line with a causal bias.</p>
<p>Firstly, we analyzed whether <italic>b</italic>captured real differences in the attenuation of spurious information. Indeed, a higher <italic>b</italic>fit was associated with greater causal relative to spurious transition influence (M = 2.638, SD = 0.752, 95% HDI = [1.190, 4.125]; <xref rid="fig5" ref-type="fig">Fig. 5B</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S8</xref>).</p>
<p>Next, we analyzed whether a higher <italic>b</italic>fit was associated with lower learning specificity. In line with this, training reward earnings differed less by trial frequency with a greater <italic>b</italic>fit (M = −0.265, SD = 0.058, 95% HDI = [−0.379, −0.149]; <xref rid="fig5" ref-type="fig">Fig. 5C</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S9</xref>). Somewhat mirroring this result, when repeating the analysis on old test trials, there was a trend towards test reward earnings differing less by training trial frequency with a greater <italic>b</italic>fit, however there was not statistical evidence for this effect (M = −0.254, SD = 0.160, 95% HDI = [−0.564, 0.058]; <xref ref-type="supplementary-material" rid="supp1">Fig. S8</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S10</xref>).</p>
<p>Our analyses of generalization performance by semantic congruency condition did not demonstrate differences in choice accuracy on test trials with old versus novel targets or options (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>&amp;<xref ref-type="fig" rid="fig4">B</xref>). Given that <italic>b</italic>may reflect idiosyncratic biases that differ from the semantic congruency manipulation, the fit of <italic>b</italic>may be able to capture difference in generalization at test. However, we did not observe differences in test reward earnings by <italic>b</italic>fit and options or target novelty (options: M = −0.012, SD = 0.037, 95% HDI = [−0.082, 0.062], <xref rid="fig5" ref-type="fig">Fig. 5D</xref>; Targets: M = −0.036, SD = 0.037, 95% HDI = [−0.107, 0.039], <xref ref-type="supplementary-material" rid="supp1">Fig. S9</xref>).</p>
<p>Finally, we found numerical differences in the spurious predictiveness of test compositions by semantic congruency condition (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). We therefore explored whether the fit of <italic>b</italic>captures individual differences in composition spurious predictiveness. Supporting this, <italic>b</italic>fit was associated with lower composition spurious predictiveness at test (M = −0.427, SD = 0.126, 95% HDI = [−0.672, −0.181]; <xref rid="fig5" ref-type="fig">Fig. 5E</xref>; <xref ref-type="supplementary-material" rid="supp1">Table S12</xref>).</p>
<p>In all, these model fits capture individual differences in causal bias that may better reflect the idiosyncrasy of semantic memory that shapes learning.</p>
</sec>
<sec id="s2g">
<title>Causal bias has an inflated benefit in more complex environments</title>
<p>The robot task captured components of environment complexity often neglected in predictive learning tasks. Namely, it allowed multiple causal processes to unfold in parallel, and imbued states with a semantic structure that could be used to direct learning. Nevertheless, the task environment was still simple relative to everyday human experiences, which are higher dimensional and involve deeper causal processes that unfold over more extended periods of time. We therefore wanted to characterize how such a bias might affect behavioral outcomes in more naturalistic settings. To do this, we simulated the feature-based models that provided best fits to participants’ data (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>, n = 46) across environments varying in dimensionality and depth.</p>
<p>The environments had two levels of dimensionality (2- and 4-dimensional) and four levels of depth (1-, 2-, 3-, or 4-step). There were eight targets in each environment, with half of the targets occurring at twice the rate as the other half of targets. Agents were tested in each environment twice: once after 72 training trials; once after 1080 training trials. The 72 trial simulations enabled us to characterize test performance given the extent of training participants received in the robot task. The 1080 trial simulations enabled us to characterize test performance after agents’ learning converged. The 1080 trial simulations could therefore quantify differences in test performance that were driven not by differences in the stage of learning, but by qualitative differences in representation.</p>
<p>To characterize how a causal bias affected behavioral outcomes, we compared test performance between agents with a low causal-bias (<italic>b</italic>&lt; 0.5) versus high causal-bias (<italic>b</italic>&gt; 0.5). With 72 trials of training (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>), the difference in participants’ performance by <italic>b</italic>fit was re-created in the one-step, two-dimensional robot task environment. That is, high-bias agents earned more reward than low-bias agents, but neither group exhibited clear differences in reward earnings on trials with old versus novel options. This pattern persisted across environments, even as performance amongst both groups generally declined with increasing dimensionality and causal depth. However, with 1080 trials of training (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>), additional differences in performance by <italic>b</italic>became apparent. While reward earnings on old versus novel trials were indistinguishable amongst high-bias agents, low-bias agents exhibited clearly poorer generalization. Namely, in the two-dimensional environments, low-bias agents earned as much, if not more, reward than high-bias agents on old trials, while earning notably less reward on novel trials. Moreover, in the four-dimensional environments, low-bias agents’ learning was so severely impaired that their performance was poor even on old trials. Therefore, while low-bias agents’ performance is equivalent on old versus novel trials, this is not because they learned fundamentally generalizable representations, it is because learning was noisy overall.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Fig. 6:</label>
<caption><title>Simulated test performance of best-fitting feature-based models.</title>
<p>Feature-based models that provided a best fit to participants’ data were simulated in environments varying in dimensionality and causal depth for either (<bold>A</bold>) 72 training trials or (<bold>B</bold>) 1080 training trials. P(Reward) is the proportion of the maximum reward (1) agents could earn on each trial. Here we compare P(Reward) on trials with old versus novel options for agents with a low bias (<italic>b</italic>&lt; 0.5) versus high bias (<italic>b</italic>&gt; 0.5). The cell outlined in black is the robot task environment.</p></caption>
<graphic xlink:href="667463v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>These results may partially explain why we failed to observe differences in participants’ generalization performance by <italic>b</italic>fit and semantic congruency condition. Firstly, the robot task may not have been complex enough to reveal differences in generalization performance given the sample size and number of training trials. Secondly, spurious information can so severely distort representations that performance even on old trials is impaired, making it more difficult to distinguish from performance on novel trials. More generally, these simulations imply that the bias we captured in the robot task should have more dramatic behavioral benefits in more naturalistic environments. This reinforces that such inductive biases on multidimensional predictive learning could be crucial to limit spurious distortions in the real world.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The present work investigated how predictive memory may be distorted in multidimensional environments, and how inductive biases may mitigate these effects. Our simulations illustrate that the spurious observations that arise from multidimensional transition dynamics may both overly tune representations to specific contexts and generate noise that compounds throughout memory. This motivates characterizing inductive biases the brain may leverage to suppress such spurious information. In line with this idea, we found that participants relied on a semantic bias that shaped learning based on the semantic relatedness of causes and outcomes. We propose that, since semantic memory reflects the stable properties of our experiences<sup><xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup>, this bias tunes learning towards stable causal information in our everyday lives, overcoming harmful distortions in memory.</p>
<p>Some may debate whether semantic biases do indeed extract causal information outside of our contrived task setting. This raises the question: can the bias still be beneficial even if it does not direct learning towards causal information? We speculate that it can. Our simulations demonstrated that the high diffusivity of spurious associations enables spurious noise to propagate widely through memory, particularly compounding in deep feature representations (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>&amp;<xref ref-type="fig" rid="fig1">F</xref>). An inaccurate inductive bias may still help mitigate these effects. By constraining learning to a subset of transitions, the feature associations become less diffusive, and the widespread propagation of spurious noise through memory may be curtailed. Therefore, even if learning is not tuned towards causal information, the memory system as a whole may benefit via the reduced compounding of spurious noise.</p>
<p>Successor features (SF; or the successor representation, originally) was introduced to enable efficient predictive inference in large, multi-step environments without relying on slower model-based planning<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c17">17</xref></sup>. Since the computational costs of model-based planning scale steeply with the size and depth of the environment, SF has been viewed as especially well-suited for modelling naturalistic inference in real-world environments<sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c18">18</xref></sup>. However, our simulations illustrate that spurious associations may more severely distort SF in these complex environments where its computational advantages are considered the greatest (<xref rid="fig1" ref-type="fig">Fig. 1D-F</xref> &amp; <xref ref-type="fig" rid="fig6">6B</xref>). This firstly reinforces the importance of building additional inductive biases into SF algorithms to mitigate these effects. Moreover, these results generate new behavioral predictions to evaluate the validity of SF as a model of human predictive learning. Since the robot task used one-step terminating transitions, we were unable to test these predictions here. Future work should therefore investigate multidimensional predictive learning and the behavioral outcomes of such inductive biases across environments that span levels of dimensionality and causal depth.</p>
<p>Prior work has shown that SF captures key characteristics of putative predictive maps in the hippocampus<sup><xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup>. This suggests that the hippocampus may also encode the feature-based predictive representations modelled with SF in the present work. On the one hand, this proposal could be at odds with influential theories about the division of labor between the cortex and hippocampus, whereby the neocortex slowly learns the general features that recur across events, while the hippocampus rapidly encodes conjunctive representations of specific events<sup><xref ref-type="bibr" rid="c39">39</xref>,<xref ref-type="bibr" rid="c41">41</xref>,<xref ref-type="bibr" rid="c42">42</xref></sup>. Relatedly, while the medial temporal lobe may support compositional generalization, the entorhinal cortex, not hippocampus, has been suggested to learn the compositional representations that underlie such inferences<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c11">11</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup>. On the other hand, the hippocampus itself may have complementary learning systems, with the trisynaptic pathway rapidly encoding conjunctive representations, while the monosynaptic pathway learns the regularities that recur across events<sup><xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c45">45</xref></sup>. Moreover, it has been shown that a biologically plausible neural network that relies on inhibitory competition (thought to support pattern separation in the hippocampus<sup><xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c46">46</xref></sup>) and a bias acquired through Hebbian learning can form generalizable representations that preserve feature information<sup><xref ref-type="bibr" rid="c31">31</xref></sup>. To resolve this tension in the literature, continuing work is investigating whether the hippocampus encodes the biased feature-based representations characterized by our findings.</p>
<p>The current work has important implications for research on artificial intelligence, which has assumed an ever more central role in society with recent developments in large language models<sup><xref ref-type="bibr" rid="c47">47</xref>–<xref ref-type="bibr" rid="c50">50</xref></sup>. The reliance of these large models on slow associative learning from vast quantities of data have raised concerns about their immense energy usage, and thus severe environmental costs<sup><xref ref-type="bibr" rid="c51">51</xref>–<xref ref-type="bibr" rid="c54">54</xref></sup>. These concerns are particularly pressing given recent proposals that performance can be improved by simply further scaling existing model architectures<sup><xref ref-type="bibr" rid="c55">55</xref>,<xref ref-type="bibr" rid="c56">56</xref></sup>. The present work supports an alternate approach. The human brain relies on a slew of inductive biases that have evolved to produce accurate learning with limited energy expenditure<sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c35">35</xref></sup>. By building such biases into new model architectures, the environmental costs of AI can be curtailed.</p>
<p>To summarize, present work introduced a framework for studying the dynamics of predictive learning in multidimensional environments that better reflect the complexity of real-world human experience. We reinforce broad perspectives that effective behavior cannot arise through slow, inefficient associative learning alone, and therefore requires the influence of inductive biases that constrain and accelerate learning<sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c57">57</xref></sup>. Particularly, we demonstrated the role existing semantic knowledge may play in disentangling webs of causal information into accurate feature-based predictive representations.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Computational Models</title>
<p>We developed our formal theoretical framework using computational modelling.</p>
<p>An agent’s interaction with its environment was modelled as a Markov Decision Process (MDP), whereby the agent makes actions (<italic>a</italic> ∈ <italic>A</italic>) to step between environment states (<italic>s</italic> ∈ <italic>S</italic>) based on transition function <italic>T</italic>(<italic>s</italic><sup>′</sup>|<italic>s, a</italic>); where the agent transitions from state <italic>s</italic> to successor state <italic>s′</italic> following action <italic>a</italic>. To render this a multidimensional framework, each state comprises <italic>d</italic> features <italic>Φ</italic>(<italic>s</italic>), and <italic>T</italic>(<italic>s</italic><sup>′</sup>|<italic>s, a</italic>) emerges from a transition function defined at the feature level:
<disp-formula id="eqn2">
<graphic xlink:href="667463v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This definition of <bold><italic>T</italic></bold> assumes that the relationship between observed events is generative, arising from a fundamental set of causal processes that may unfold in parallel. The agent’s goal is instantiated in task vector <bold><italic>w</italic></bold>, which represents preferences over <italic>Φ</italic>(<italic>s</italic>). The inner product of <bold><italic>w</italic></bold> and <italic>Φ</italic>(<italic>s</italic>) defines a reward function <bold><italic>R</italic></bold>(<bold><italic>w</italic></bold>, <italic>s</italic>), dictating the immediate reward received for entering <italic>s</italic>:
<disp-formula id="eqn3">
<graphic xlink:href="667463v1_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The agent should make actions to navigate towards states with features that will be the most rewarding given the current task <bold><italic>w</italic></bold>. To infer which actions will give cause to rewarding states, the agent must therefore learn a predictive representation that approximates the transition dynamics defined by <bold><italic>T</italic></bold>. We model such predictive learning as a successor features (SF) learner<sup><xref ref-type="bibr" rid="c16">16</xref>,<xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c19">19</xref></sup>.</p>
<p>The SF model learns a representation of each state <italic>s</italic> in the environment that reflects the quantity of features likely to be encountered upon entering <italic>s</italic> and in subsequent states following <italic>s</italic>. These expectations are represented in successor matrix <bold><italic>M</italic></bold>(<italic>s</italic>). We implemented an incremental SF learner that uses a temporal difference rule to learn <bold><italic>M</italic></bold>(<italic>s</italic>). After state transition <italic>s</italic> → <italic>s′</italic> is observed, the feature vector for the current state <italic>Φ</italic>(<italic>s</italic>) is added to vector <bold><italic>M</italic></bold>(<italic>s</italic>). Since this update incorporates the discounted feature predictions of the successor state <italic>s′</italic>, the agent gradually learns to predict distant feature visitations. Formally:
<disp-formula id="eqn4">
<graphic xlink:href="667463v1_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5">
<graphic xlink:href="667463v1_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where free parameter <italic>α</italic> =(0, 1) controls the learning rate and free parameter <italic>γ</italic> =[0, 1] controls the discount rate. Since the present task uses one-step terminating transitions, we set <italic>γ</italic> =1.</p>
<p>To estimate the value of entering <italic>s</italic> given some task <bold><italic>w, M</italic></bold>(<italic>s</italic>) is used to define a value function <bold>V</bold>(<italic>w, s</italic>) akin to <bold><italic>R</italic></bold>(<italic>w, s</italic>):
<disp-formula id="eqn6">
<graphic xlink:href="667463v1_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
On each trial of the robot task, an agent should compose the robot <italic>s</italic> which has a representation <bold><italic>M</italic></bold>(<italic>s</italic>) that maximizes <bold>V</bold>(<bold><italic>w</italic></bold>, <italic>s</italic>) for the trial’s target <bold><italic>w</italic></bold>. Lastly, a probabilistic choice policy is computed for composing state <italic>s</italic><sup>*</sup> from the set of candidate compositions <italic>C</italic><sub><italic>t</italic></sub> on trial <italic>t</italic> using a softmax with inverse temperature <italic>β</italic> =(0, <italic>∞</italic>):
<disp-formula id="eqn7">
<graphic xlink:href="667463v1_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We implemented three forms of this basic SF learner: (1) conjunctive (representing environment states as discrete conjunctions of features); (2) conjunctive sampler (conjunctive representation with a retroactive integration mechanism to generalize to novel states); and (3) feature-based (representing environment states as independent features).</p>
</sec>
<sec id="s4b">
<title>Conjunctive Model</title>
<p>In contrast to the basic SF learner model described thus far, the conjunctive model represents environment features <italic>Φ</italic>(<italic>s</italic>) in terms of the conjunctive successor state itself. That is, <italic>Φ</italic>(<italic>s</italic>) is a one-hot vector with a length equal to the number of task states (unique robots), and a 1 in the position corresponding to state <italic>s</italic>. Successor matrix <bold><italic>M</italic></bold>, is therefore square, where the number of rows and columns correspond to the number of unique states. This implementation of SF is akin to the traditional successor representation model.<sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c18">18</xref></sup></p>
<p>On each trial, the agent constructs an action set that comprises all possible candidate compositions <italic>C</italic><sub><italic>t</italic></sub> that could be built from the trial’s start feature options. The agent computes <bold>V</bold>(<bold><italic>w</italic></bold>, <italic>s</italic><sup>*</sup>) based on each candidate composition <italic>s</italic><sup>*</sup> in <italic>C</italic><sub><italic>t</italic></sub>.</p>
</sec>
<sec id="s4c">
<title>Conjunctive Sampler Model</title>
<p>The conjunctive model suffers from two limitations as a model of human behavior. Firstly, it must compute all possible combinations of features to construct a candidate composition set during inference. This approach may be computationally infeasible in high-dimensional real-world environments where the number of possible feature combinations would likely be intractably large to compute. Secondly, the conjunctive model is unable to generalize learning to make inferences about novel compositions at test. The test phase of the robot task included trials with novel options sets, comprising combinations of feature categories that were not seen during training (AC, AD, BC, BD). Since the conjunctive model would not have learned about the candidate compositions that could be constructed from these options, it could not make inferences about them, and would thus make random choices on novel trials. This does not reflect the behavior of participants, who performed above chance on test trials with novel options (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). Both limitations can be addressed by considering an alternative form of conjunctive model, which represents and learns about states as described, but uses a more flexible inference mechanism to estimate state values at choice.</p>
<p>Previous work has suggested that humans may use a retroactive integration mechanism to sample and combine memories during choice inference<sup><xref ref-type="bibr" rid="c58">58</xref>–<xref ref-type="bibr" rid="c66">66</xref></sup>. This is thought to allow humans to adaptively re-combine prior knowledge into novel configurations to generalize learning to novel problems. We thus implemented a form of retroactive integration that computes weights <bold><italic>g</italic></bold>(<italic>s</italic><sup>*</sup>) over <bold><italic>M</italic></bold> based on each represented state’s recency, frequency, and similarity to <italic>s</italic><sup>*</sup> — properties that all drive memory retrieval<sup><xref ref-type="bibr" rid="c67">67</xref>,<xref ref-type="bibr" rid="c68">68</xref></sup>. The estimated value <bold>V</bold><sup>*</sup>(<bold><italic>w</italic></bold>, <italic>s</italic><sup>*</sup>) is then computed as a weighted sum over <bold>V</bold>:
<disp-formula id="eqn8">
<graphic xlink:href="667463v1_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
To compute <bold><italic>g</italic></bold>(<italic>s</italic><sup>*</sup>), the agent represents the recency and frequency of states in memory as integer vectors (<bold><italic>g</italic></bold><sup><italic>REC</italic></sup>, <bold><italic>g</italic></bold><sup><italic>FREQ</italic></sup>) with lengths corresponding to the size of <italic>S</italic>. After composition <italic>s</italic> is made on a training trial, a count is added to <bold><italic>g</italic></bold><sup><italic>REC</italic></sup> in all positions except that corresponding to <italic>s</italic>, which is set to zero. A count is also added to the position of <italic>s</italic> in <bold><italic>g</italic></bold><sup><italic>FREQ</italic></sup>. To allow the similarity computation, the agent stores each observed <italic>Φ</italic>(<italic>s</italic>) in memory. When evaluating <italic>s</italic><sup>*</sup>, the similarity <italic>g</italic><sup><italic>SIM</italic></sup>(<italic>s</italic><sup>*</sup>, <italic>s</italic>) of <italic>s</italic><sup>*</sup> to each <italic>s</italic> in memory is calculated as the number of shared features between <italic>Φ</italic>(<italic>s</italic><sup>*</sup>) and <italic>Φ</italic>(<italic>s</italic>):
<disp-formula id="eqn9">
<graphic xlink:href="667463v1_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
At inference, <bold><italic>g</italic></bold><sup><italic>REC</italic></sup>, <bold><italic>g</italic></bold><sup><italic>FREQ</italic></sup>, and <bold><italic>g</italic></bold><sup><italic>SIM</italic></sup> (<italic>s</italic><sup>*</sup>) are normalized by dividing by their respective maximum values. We then compute <bold><italic>g</italic></bold>(<italic>s</italic><sup>*</sup>) as a weighted sum over these:
<disp-formula id="eqn10">
<graphic xlink:href="667463v1_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>ω</italic><sup><italic>REC</italic></sup>, <italic>ω</italic><sup><italic>FREQ</italic></sup>, and <italic>ω</italic><sup><italic>SIM</italic></sup> control the degree to which each vector directs memory sampling. To limit the number of free parameters, we treated <italic>ω</italic><sup><italic>SIM</italic></sup> (<italic>ω</italic><sup><italic>SIM</italic></sup> =[0, 1]) as the sole free parameter that in turn determined the values of <italic>ω</italic><sup><italic>REC</italic></sup> and <italic>ω</italic><sup><italic>FREQ</italic></sup>:
<disp-formula id="eqn11">
<graphic xlink:href="667463v1_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Finally, to capture the extent to which few versus many memories are sampled and integrated over, sampling specificity parameter <italic>Ψ</italic> (<italic>Ψ</italic> =(1, <italic>inf</italic>)) was applied to a normalized <bold><italic>g</italic></bold>(<italic>s</italic><sup>*</sup>):
<disp-formula id="eqn12">
<graphic xlink:href="667463v1_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
A larger value of <italic>Ψ</italic> produced more sampling specificity, directing sampling to the most probable states in memory.</p>
<p>The described retroactive integration mechanism addresses the conjunctive model’s limited ability to generalize. However, it does not address the model’s computationally expensive action set generation mechanism. To account for this, we simply have the model treat the feature options themselves as the action set on each trial, requiring no additional computation. The basic conjunctive model cannot make inferences about these features, since it represents them distinctly to the feature conjunctions it learns about, and does not possess a generalization mechanism to make inferences about them. Since the conjunctive sampler model possesses such a generalization mechanism, it is not limited in this regard. Thus, the conjunctive sampler model can utilize a simpler feature-based action set.</p>
</sec>
<sec id="s4d">
<title>Feature-Based Model</title>
<p>The final model reflects our primary hypothesis for this study, which is that participants will represent the environment in terms the independent features that define states. That is, <bold><italic>M</italic></bold> is again square, but the rows and columns correspond to independent feature instances rather than conjunctive states. Since a given state transition comprises multiple feature transitions, multiple rows of <bold><italic>M</italic></bold> are updated on each trial. This parallelization is implemented by updating the full matrix <bold><italic>M</italic></bold>, weighted by <italic>Φ</italic>(<italic>s</italic>):
<disp-formula id="eqn13">
<graphic xlink:href="667463v1_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Φ</italic>(<italic>s</italic>) is defined as a binarized vector representation of the state’s features, as in the basic SF learner.</p>
<p>The present study investigates an inductive bias towards causal transitions during predictive learning. We implemented this bias via matrix <bold><italic>B</italic></bold>, where each element <inline-formula id="inline-eqn-5"><inline-graphic xlink:href="667463v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,reflects the probability that features <italic>f</italic> and <italic>f′</italic> are associated. Specifically, we code: <inline-formula id="inline-eqn-6"><inline-graphic xlink:href="667463v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is a causal transition; and <inline-formula id="inline-eqn-7"><inline-graphic xlink:href="667463v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, otherwise. Causal-bias parameter <italic>b</italic>(<italic>b</italic>=[0, 1]) dictates the bias magnitude. To apply the relevant rows of the bias given some successor state <italic>s</italic>′, <bold><italic>B</italic></bold> is weighted by <italic>Φ</italic>(<italic>s′</italic>) during <bold><italic>M</italic></bold> updating:
<disp-formula id="eqn14">
<graphic xlink:href="667463v1_eqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We normalize <bold><italic>B</italic></bold><italic>′</italic> so that rows sum to 1, and then apply the bias on the temporal discounting term
<disp-formula id="eqn15">
<graphic xlink:href="667463v1_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Since true transitions were defined within semantic categories in the congruent condition, we hypothesized a semantic bias would direct participants learning towards the true transitions. However, since true transitions were defined between semantic categories in the incongruent condition, we hypothesized a semantic bias could not direct learning towards the true transitions. This pattern of results should be expressed as a higher fit <italic>b</italic> in the congruent condition compared to the incongruent condition.</p>
</sec>
<sec id="s4e">
<title>Simulations</title>
<p>In the first set of simulations (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), the feature-based model was simulated in each task environment 250 times, with random <italic>α</italic> and <italic>β</italic> values. Learning rate <italic>α</italic> was sampled from a uniform distribution bounded <italic>α</italic> =(0, 1). Inverse temperature <italic>β</italic> was sampled as <inline-formula id="inline-eqn-8"><inline-graphic xlink:href="667463v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> 1, where <italic>x</italic> was drawn from a uniform distribution bounded <italic>x</italic> =(0, 1). For the “regular” learners (red lines in <xref rid="fig1" ref-type="fig">Fig. 1</xref>), we set <italic>b</italic>=0. For the causal learners (grey lines in <xref rid="fig1" ref-type="fig">Fig. 1</xref>), we repeated the simulation procedure but set <italic>b</italic>=1. Agents in the one-dimensional environments were trained for 2160 trials. Agents in the two-dimensional environments were trained for 1080 trials.</p>
<p>For the second set of simulations (<xref rid="fig6" ref-type="fig">Fig. 6</xref>), we identified the feature-based models that provided best fits to participants’ data (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>; n = 46; <italic>α</italic>: M = 0.7631, SD = 0.3486; <italic>β</italic> (sigmoid transformed): M = 0.6153, SD = 0.1520; <italic>b</italic>: M = 0.6652, SD = 0.3927). These models were simulated on the task in environments varying in dimensionality (<italic>d</italic> =2, <italic>d</italic> =4), causal depth (1-, 2-, 3-, 4-step), and number of training trials (72, 1080).</p>
</sec>
<sec id="s4f">
<title>Model Fitting</title>
<p>The three computational models were separately fit to each participant’s choice data using maximum likelihood estimation. Given a set of parameter values, the softmax function estimates the probabilities of a participant’s sequence of choices. To fit each model, we computed the negative log likelihood from these probabilities <inline-formula id="inline-eqn-9"><inline-graphic xlink:href="667463v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and identified the set of parameter values that minimized this negative log likelihood (using the L-BFGS-B method implemented in python via scipy’s optimize.minimize function). To avoid finding local minima, this fitting procedure was repeated up to 100 times with random parameter initializations. If the negative log likelihood was not minimized further for five successive random initializations, the procedure was terminated.</p>
<p>To account for differences in model complexity during model comparison, we converted <italic>L</italic> to Akaike information criterion (<italic>AIC</italic> =2(<italic>k</italic> + <italic>L</italic>), where <italic>k</italic> is the number of free parameters), penalizing models with more free parameters. For each participant, the best fitting model was identified as the one that minimized the <italic>AIC</italic>.</p>
</sec>
<sec id="s4g">
<title>Human Experiment</title>
<sec id="s4g1">
<title>Participants</title>
<p>One-hundred and ten Amazon Mechanical Turk participants were recruited for the learning task via CloudResearch’s toolkit. Ten participants were excluded due to the preregistered criterion of composing a robot on less than 85% of trials. This left a final sample of 100 participants (mean age = 38.92; standard deviation age = 9.95; 31 female; 69 male). Participants received $13 plus a fixed bonus of $3 for completing the 60-minute task. The value of the bonus was not revealed until the end of the study. Consent was obtained in accordance with a protocol approved by the University of Chicago’s Institutional Review Board (protocol #: 20-1324).</p>
</sec>
<sec id="s4g2">
<title>Stimuli</title>
<p>The task stimuli were line drawings of robots. Each consisted of two features from four categories (antenna, head, body, arms – randomly mapped to task-relevant labels ABCD). During training, only AB targets appeared in the first block, and only CD targets appeared in the second block. Likewise, only AB/CD options appears in the first block of the congruent/incongruent conditions, and only CD/AB options appeared in the second block of congruent/incongruent conditions. During test, participants in both condition were shown robots with all combinations of feature categories (AB, AC, AD, BC, BD, CD). We label robots seen during training as “old” (AB, CD) and new robots only seen at test as “novel” (AC, AD, BC, BD; <xref rid="fig2" ref-type="fig">Fig. 2C</xref>). There were four feature instances per category (e.g., four head variations, four antenna variations, etc.). Half of these instances were “start” features composing start items (builder robots); the other half were “terminal” instances composing terminal items (output robots). Predictive associations were deterministic mappings from start to terminal instances/items (start→terminal; <xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Each start item/instance was associated with a single terminal item/instance. In all, there were 16 feature instances (8 start, 8 terminal) composing 48 items (24 start, 24 terminal; 16 old; 32 novel).</p>
<p>Every robot had a “flipped” and “upright” version, which only differed by which feature instance was in the top versus bottom position within the stimulus. We randomized which of these two versions was presented for each robot display within and across trials to control for learning and inferences effects based on features’ spatial locations rather than their identities.</p>
</sec>
<sec id="s4g3">
<title>Training</title>
<p>Participants were instructed that they will play a game in which they will act as the owner of a robot factory. Their task is to build robots according to specifications. There are two types of robots: “output” robots (terminal items) – the end products the participant is trying to produce; and “builder” robots (start items) – robots that participants themselves compose from sets of builder parts, that in turn produce the output robots. On each trial, a “target” output robot is shown. Participants’ goal is to compose the builder that will produce this target. Thus, performance in this task centrally depended on accurate start→terminal predictive inferences.</p>
<p>Trials unfolded as follows (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). At the start of each trial, a fixation cross was shown before a target terminal item was presented in the center of the screen. Next, an options set of four builder parts (start instances) from two feature categories was shown along with the target. The participant used the cursor to select a feature from each category to compose a start item. As features were selected, the composed item was shown at the bottom of the screen. The two categories were presented on either side of the screen, however which category appeared on which side randomly varied from trial-to-trial. Additionally, the position of each instance within a category randomly varied from trial-to-trial. This spatial randomization ensured that participants’ choices reflected inferences based on features’ identities rather than their spatial locations. After composition, a start→terminal sequence was shown, starting with the composed start item, and terminating with the associated terminal item produced. Again, we randomized whether an “upright” or “flipped” version of each stimulus was shown to ensure learning was based on the features’ identities rather than their spatial locations. Finally, a point reward was presented. Reward was computed as the number of feature instances that matched between the produced and target terminal items. For these two-feature items, reward values could thus be 0, 1, or 2. To earn a mean reward greater than chance (chance reward = 1), participants needed to learn the start→terminal sequences to infer which start robot they should compose to produce the target. To encourage a response on each trial, a −5 reward was given if the participant did not select two features. There were 36 trials per block, separated by a 60 second break, producing 72 training trials in total.</p>
<p>We probed the specificity of inference by manipulating the rates as which specific target items were presented. Half the targets were presented at twice the rate of the other half of targets. However, features were presented at a uniform rate across these targets. We hypothesized that if participants made consistent inferences about each target, the rates at which they composed start items and observed specific start→terminal transitions would converge on the target rates. Our simulations demonstrate that this manipulation should manifest in differential performance for frequent versus infrequent targets only if the spurious transitions are learned (<xref rid="fig1" ref-type="fig">Fig. 1GH</xref>). We thus use differential performance by target frequency as a metric of learning specificity, which we expected to vary with the degree of causal bias.</p>
</sec>
<sec id="s4g4">
<title>Test</title>
<p>Test was the same as training, only both old and novel targets and options sets were presented, and participants did not receive feedback for their responses. Specifically, every possible combination of old and novel target and options were shown, producing 144 unique trials. By comparing choice performance on trials with old versus novel options or targets, we could probe the generalizability of participants’ learning. Target frequency was not manipulated at test, and the trial order was randomized. Test was split into two blocks of 72 trials, separated by a 60 second break.</p>
</sec>
<sec id="s4g5">
<title>Semantic Congruency Condition</title>
<p>A semantic bias on predictive learning would be expressed as upweighted learning of transitions between semantically-related features, and downweighted learning of transitions between semantically-unrelated features. To test whether a semantic bias shapes multidimensional predictive learning in humans, we implemented two between-subjects conditions in the robot task (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>, n per condition = 50). In the <italic>semantic-congruent</italic> condition, start→terminal transitions were defined between feature instances from the same semantic category (e.g., start <italic>antennas</italic> always lead to terminal <italic>antennas</italic>). In the <italic>semantic-incongruent</italic> condition, start→terminal transitions were defined between feature instances from different semantic categories (e.g., start <italic>antennas</italic> may always lead to terminal <italic>arms</italic>). We hypothesized that a semantic bias would upweight learning of the semantically-congruent transitions. Thus, there should be better learning of the causal relative to spurious transitions in the congruent compared to the incongruent condition.</p>
</sec>
<sec id="s4g6">
<title>Causal and Spurious Transition Evidence</title>
<p>For the transition influence analysis, causal and spurious transition evidence variables were computed on each trial for each candidate composition as follows. A candidate composition <italic>s</italic> has two features. For each of these features, we found the most recent trial on which it was observed. We then record whether on that past trial the feature transitioned to either (or both) of the target features of the present trial. If a causal transition was observed, a count of 1 was added to the causal transition evidence for <italic>s</italic>. If a spurious transition was observed, a count of 1 was added to the spurious transition evidence for <italic>s</italic>.</p>
<p>For example, <italic>s</italic> may have features A1 and B1, and the target may have features A2 and B4. On the most recent trial A1 was seen, it may have transitions to a terminal item with features A2 and B4. Thus, the transitions including A1 are: (causal) A1→A2; (spurious) A1⇢B4. Both transitions would also be observed for <italic>s</italic> to the present target, and so a count of 1 is added to the causal and spurious evidence for <italic>s</italic>. On the most recent trial B1 was seen, it may have transitioned to a terminal item with features A2 and B2. Thus, the transitions including B1 are: (causal) B1→B2; (spurious) B1⇢A2. Only the spurious transition would also be observed for <italic>s</italic> to the present target, and so a count of 1 is added only to the spurious evidence for <italic>s</italic>. In all, the counts for <italic>s</italic> would be: causal = 1; spurious = 2. We finally divide these counts by the number of features in the composition (2) to create normalized evidence values: <italic>causal</italic><sub><italic>s</italic></sub> =0.5; <italic>spurious</italic><sub><italic>s</italic></sub> =1.</p>
<p>Lastly, we convert the transition evidence variables so that they are all relative to reference composition 0:
<disp-formula id="eqn16">
<graphic xlink:href="667463v1_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4g7">
<title>Bayesian Regression Models</title>
<p>The Bayesian regression models were fit using Markov chain Mente Carlo sampling via the Bambi python package (version 0.14.0)<sup><xref ref-type="bibr" rid="c69">69</xref></sup>. Four MCMC chains were each run for 2000 to 8000 iterations, with the first 1000 to 4000 iterations of each chain discarded as warm-up. This yielded a total of 4000 to 16000 posterior across the four chains. For all models, we assume Bambi’s default weakly informative priors<sup><xref ref-type="bibr" rid="c70">70</xref></sup>. All model formula, model fits, and MCMC sampling settings are reported in the supplementary materials.</p>
</sec>
<sec id="s4g8">
<title>Preregistration and Deviations</title>
<p>All experimental procedures and analyses were preregistered on July 7 2024 aside from those explicitly stated to be exploratory (link to preregistration: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/2CY6R">https://doi.org/10.17605/OSF.IO/2CY6R</ext-link>). However, the following deviations were made from that preregistration.</p>
<p>We preregistered a sample aged 18 to 35 years old. This age range was initially specified by the IRB at the University of Chicago, but was subsequently removed. To ease recruitment and attain a more diverse and representative sample, we therefore loosened the inclusion criterion to participants aged 18 years old and above.</p>
<p>We preregistered creating a single spurious and single causal transition influence measure per participant by averaging the three spurious and three causal transition influence coefficients fit in the multinomial logistic regression (<xref ref-type="supplementary-material" rid="supp1">Table S15</xref>). However, averaging these coefficients unnecessarily reduced the statistical power of subsequent regression models that included transition influence as a variable. To preserve this information for the subsequent regression models, we did not average over the coefficients. Instead, we included all coefficients as individual observations, with random effects terms specifying the logit comparison they came from (i.e., whether the coefficient was from the logit comparing <inline-formula id="inline-eqn-10"><inline-graphic xlink:href="667463v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>,or <inline-formula id="inline-eqn-11"><inline-graphic xlink:href="667463v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>).</p>
<p>We preregistered comparing generalization performance at test on all trials with old targets/options versus all trials with novel targets/options (<xref ref-type="supplementary-material" rid="supp1">Table S16</xref>). However, computational model simulations subsequently demonstrated that old and novel trials generally varied in the number of causal and spurious inferences they afforded, leading to differences in (1) possible reward earnings and (2) the degree to which alternative inferences can compete at choice. For example, on a trial in the congruent condition with options BC and target AB, only one causal transition (B→B) and one spurious (B→A) transition would have been seen during training. This means that, on this trial, a maximum of one reward could be received for inferring the single causal transition. Moreover, if a participant has learned the spurious transitions, an inference about B→A would interfere with the (correct) causal inference about B→B. On other trials, the ratio of spurious to causal transitions might be lower. For example, on a trial in the congruent condition with options AC and target AC, two causal transitions (A→A, C→C) can be inferred, but no spurious transitions can be inferred since A and C never co-occurred during training. This means the participant can get a maximum reward of two, and no spurious inference can interfere with the causal inferences. Thus, choice accuracy should be higher on this trial. Since novel options/targets have features from across the two training blocks, they generally limit the ability to make within-block spurious inferences. This may make performance appear superior on novel compared to old trials. To control for this, we therefore focus our generalization analysis on trials where only one causal and one spurious transition was afforded based on training observations.</p>
<p>We preregistered evaluating whether the feature-based model provided a better fit than the alternative models (conjunctive, conjunctive sampler, null) by fitting a logistic regression model that included as a depended variable whether each participant was best fit by the feature-based model (1) over any of the alternatives (0), and an intercept as the independent variable (<xref ref-type="supplementary-material" rid="supp1">Table S17</xref>). However, this analysis was limited in that it could tell us whether most participants were best fit by the feature-based model, but not whether the feature-based model fit best irrespective of whether most best fits were feature-based. This is problematic given the high rate of non-learners – the second largest proportion of participants were best fit by the null model. We therefore instead ran a multinomial logistic regression, including whether each participant was best fit by each of the alternative models (1) over the feature-based model (0) as the dependent variable, and an intercept as the independent variable.</p>
<p>The preregistered feature-based model differed from the model reported above. In the original model, bias <bold><italic>B</italic></bold> was also applied as a matrix of learning weights on the error term</p>
<p><italic>δ</italic>. That is:
<disp-formula id="eqn17">
<graphic xlink:href="667463v1_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This meant that the bias affected both the discounting of successor features and overall learning rate, reducing the interpretability of the causal-bias parameter <italic>b</italic>. As a result, <italic>b</italic>no longer cleanly reflected the intended role of the inductive bias in shaping how, specifically, predictive associations are learned. To address this fundamental flaw to the interpretability of the model, we removed <bold><italic>B</italic></bold> as a learning weight matrix.</p>
</sec>
</sec>
<sec id="s6">
<title>Stimulus and Task Availability</title>
<p>Task code and stimuli can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/BakkourLabRepo/feat-predict_robot-builder-task">https://github.com/BakkourLabRepo/feat-predict_robot-builder-task</ext-link></p>
</sec>
<sec id="s7">
<title>Computational Model Code Availability</title>
<p>Computational modelling code can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/BakkourLabRepo/feat-predict_models">https://github.com/BakkourLabRepo/feat-predict_models</ext-link></p>
</sec>
<sec id="s8">
<title>Analysis Code Availability</title>
<p>Simulation and human experiment analysis code can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/BakkourLabRepo/feat-predict_analysis">https://github.com/BakkourLabRepo/feat-predict_analysis</ext-link></p>
</sec>
</sec>
</body>
<back>
<sec id="s5" sec-type="data-availability">
<title>Data availability</title>
<p>Simulation and human participants’ data can be accessed at <ext-link ext-link-type="uri" xlink:href="https://osf.io/nqjy2/?view_only=72ad1546d2df460f9d8b574416c10644">https://osf.io/nqjy2/?view_only=72ad1546d2df460f9d8b574416c10644</ext-link></p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We kindly thank Rain Liu for assistance with preliminary analyses during the conceptualization of this work. This work was funded by award #2342775 from the U.S. National Science Foundation.</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="s9">
<title>Contributions</title>
<p>Conceptualization, E.P. and A.B.; Experiment Design, E.P. and A.B.; Computational Modeling, E.P.; Data collection, E.P.; Data Analysis, E.P.; Writing, E.P. and A.B.; Funding, A.B.</p>
</sec>
</sec>
<sec id="additional-files" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="supp1">
<label>Supplementary Materials</label>
<media xlink:href="supplements/667463_file02.pdf"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title>. <source>Neuron</source> <volume>100</volume>, <fpage>490</fpage>–<lpage>509</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>Goals and Habits in the Brain</article-title>. <source>Neuron</source> <volume>80</volume>, <fpage>312</fpage>–<lpage>325</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Momennejad</surname>, <given-names>I.</given-names></string-name></person-group> <article-title>Learning Structures: Predictive Representations, Replay, and Generalization</article-title>. <source>Curr. Opin. Behav. Sci</source>. <volume>32</volume>, <fpage>155</fpage>–<lpage>166</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brunec</surname>, <given-names>I. K.</given-names></string-name>, <string-name><surname>Newcombe</surname>, <given-names>N. S.</given-names></string-name> &amp; <string-name><surname>Epstein</surname>, <given-names>R. A.</given-names></string-name></person-group> <article-title>Structuring Knowledge with Cognitive Maps and Cognitive Graphs</article-title>. <source>Trends Cogn. Sci</source>. <volume>25</volume>, <fpage>37</fpage>–<lpage>54</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tolman</surname>, <given-names>E. C.</given-names></string-name></person-group> <article-title>Cognitive maps in rats and men</article-title>. <source>Psychol. Rev</source>. <volume>55</volume>, <fpage>189</fpage>–<lpage>208</lpage> (<year>1948</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moser</surname>, <given-names>M.-B.</given-names></string-name>, <string-name><surname>Rowland</surname>, <given-names>D. C.</given-names></string-name> &amp; <string-name><surname>Moser</surname>, <given-names>E. I.</given-names></string-name></person-group> <article-title>Place Cells, Grid Cells, and Memory</article-title>. <source>Cold Spring Harb. Perspect. Biol</source>. <volume>7</volume>, <fpage>a021808</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Park</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>D. S.</given-names></string-name> &amp; <string-name><surname>Boorman</surname>, <given-names>E. D.</given-names></string-name></person-group> <article-title>Inferences on a multidimensional social hierarchy use a grid-like code</article-title>. <source>Nat. Neurosci</source>. <volume>24</volume>, <fpage>1292</fpage>–<lpage>1301</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Theves</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Fernandez</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name></person-group> <article-title>The Hippocampus Encodes Distances in Multidimensional Feature Space</article-title>. <source>Curr. Biol</source>. <volume>29</volume>, <fpage>1226</fpage>–<lpage>1231.e3</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Theves</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Fernández</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name></person-group> <article-title>The Hippocampus Maps Concept Space, Not Feature Space</article-title>. <source>J. Neurosci</source>. <volume>40</volume>, <fpage>7318</fpage>–<lpage>7325</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Constantinescu</surname>, <given-names>A. O.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name></person-group> <article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title>. <source>Science</source> <volume>352</volume>, <fpage>1464</fpage>–<lpage>1468</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title>. <source>Cell</source> <volume>183</volume>, <fpage>1249</fpage>–<lpage>1263.e23</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name>, <string-name><surname>McCaffary</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bakermans</surname>, <given-names>J. J. W.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name></person-group> <article-title>How to build a cognitive map: insights from models of the hippocampal formation</article-title>. <source>arXiv</source> (<year>2022</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Pudhiyidath</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Representations of Temporal Community Structure in Hippocampus and Precuneus Predict Inductive Reasoning Decisions</article-title>. <source>bioRxiv</source> (<year>2021</year>) doi:<pub-id pub-id-type="doi">10.1101/2021.10.12.462707</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Rogers</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Cordova</surname>, <given-names>N. I.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name> &amp; <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name></person-group> <article-title>Neural representations of events arise from temporal community structure</article-title>. <source>Nat. Neurosci</source>. <volume>16</volume>, <fpage>486</fpage>–<lpage>492</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sutton</surname>, <given-names>R. S.</given-names></string-name> &amp; <string-name><surname>Barto</surname>, <given-names>A. G.</given-names></string-name></person-group> <source>Reinforcement Learning: An Introduction</source>. (<publisher-name>The MIT Press</publisher-name>, <publisher-loc>Cambridge, Massachusetts</publisher-loc>, <year>2018</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Carvalho</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Tomov</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>de Cothi</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> <source>Predictive representations: building blocks of intelligence</source>. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2402.06590">http://arxiv.org/abs/2402.06590</ext-link> (<year>2024</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>Improving Generalisation for Temporal Difference Learning: The Successor Representation</article-title>. <source>Neural Comput</source> <volume>5</volume>(<issue>4</issue>):<fpage>613</fpage>–<lpage>624</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> <article-title>The Successor Representation: Its Computational Logic and Neural Substrates</article-title>. <source>J. Neurosci</source>. <volume>38</volume>, <fpage>7193</fpage>–<lpage>7200</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Barreto</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dabney</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Munos</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Hunt</surname>, <given-names>J. J.</given-names></string-name> &amp; <string-name><surname>Schaul</surname>, <given-names>T.</given-names></string-name></person-group> <article-title>Successor Features for Transfer in Reinforcement Learning</article-title>. <conf-name>31st Conference on Neural Information Processing Systems</conf-name>, <conf-loc>Long Beach, CA, USA</conf-loc> (<year>2017</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Cothi</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Predictive maps in rats and humans for spatial navigation</article-title>. <source>Curr. Biol</source>. <volume>32</volume>, <fpage>3676</fpage>–<lpage>3689.e5</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Momennejad</surname>, <given-names>I.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The successor representation in human reinforcement learning</article-title>. <source>Nat. Hum. Behav</source>. <volume>1</volume>, <fpage>680</fpage>–<lpage>692</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunec</surname>, <given-names>I. K.</given-names></string-name> &amp; <string-name><surname>Momennejad</surname>, <given-names>I.</given-names></string-name></person-group> <article-title>Predictive Representations in Hippocampal and Prefrontal Hierarchies</article-title>. <source>J. Neurosci</source>. <volume>42</volume>, <fpage>299</fpage>–<lpage>312</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Cothi</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Neurobiological successor features for spatial navigation</article-title>. <source>Hippocampus</source> <volume>30</volume>, <fpage>1347</fpage>–<lpage>1355</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Russek</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Momennejad</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name> &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> <article-title>Predictive representations can link model-based reinforcement learning to model-free mechanisms</article-title>. <source>PLOS Comput. Biol</source>. <volume>13</volume>, <fpage>e1005768</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Russek</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Momennejad</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name> &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> <article-title>Neural Evidence for the Successor Representation in Choice Evaluation</article-title>. <source>bioRxiv</source> (<year>2021</year>) doi:<pub-id pub-id-type="doi">10.1101/2021.08.29.458114</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stachenfeld</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name> &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> <article-title>The hippocampus as a predictive map</article-title>. <source>Nat. Neurosci</source>. <volume>20</volume>, <fpage>1643</fpage>–<lpage>1653</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liljeholm</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>How multiple causes combine: independence constraints on causal inference</article-title>. <source>Front. Psychol</source>. <volume>6</volume>, (<year>2015</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liljeholm</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Neural Correlates of Causal Confounding</article-title>. <source>J. Cogn. Neurosci</source>. <volume>32</volume>, <fpage>301</fpage>–<lpage>314</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goyal</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>Inductive biases for deep learning of higher-level cognition</article-title>. <source>Proc. R. Soc. Math. Phys. Eng. Sci</source>. <volume>478</volume>, <fpage>20210068</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kemp</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name></person-group> <article-title>Structured statistical models of inductive reasoning</article-title>. <source>Psychol. Rev</source>. <volume>116</volume>, <fpage>20</fpage>–<lpage>58</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Reilly</surname>, <given-names>R. C.</given-names></string-name></person-group> <article-title>Generalization in Interactive Networks: The Benefits of Inhibitory Competition and Hebbian Learning</article-title>. <source>Neural Comput</source>. <volume>13</volume>, <fpage>1199</fpage>–<lpage>1241</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pouncy</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> <article-title>Inductive biases in theory-based reinforcement learning</article-title>. <source>Cognit. Psychol</source>. <volume>138</volume>, <fpage>101509</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Kemp</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name> &amp; <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name></person-group> <article-title>How to Grow a Mind: Statistics, Structure, and Abstraction</article-title>. <source>Science</source> <volume>331</volume>, <fpage>1279</fpage>–<lpage>1285</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Webb</surname>, <given-names>T. W.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The relational bottleneck as an inductive bias for efficient abstraction</article-title>. <source>Trends Cogn. Sci</source>. <volume>28</volume>, <fpage>829</fpage>–<lpage>843</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zador</surname>, <given-names>A. M.</given-names></string-name></person-group> <article-title>A critique of pure learning and what artificial neural networks can learn from animal brains</article-title>. <source>Nat. Commun</source>. <volume>10</volume>, <fpage>3770</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hedrich</surname>, <given-names>N. L.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Hall-McMaster</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name></person-group> <article-title>An inductive bias for slowly changing features in human reinforcement learning</article-title>. <source>PLOS Comput. Biol</source>. <volume>20</volume>, <fpage>e1012568</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="report"><person-group person-group-type="author"><string-name><surname>Mitchell</surname>, <given-names>T. M.</given-names></string-name></person-group> <source>The Need for Biases in Learning Generalizations</source>. <publisher-name>Rutgers University</publisher-name> (<year>1980</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Binder</surname>, <given-names>J. R.</given-names></string-name> &amp; <string-name><surname>Desai</surname>, <given-names>R. H.</given-names></string-name></person-group> <article-title>The neurobiology of semantic memory</article-title>. <source>Trends Cogn. Sci</source>. <volume>15</volume>, <fpage>527</fpage>–<lpage>536</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McClelland</surname>, <given-names>J. L.</given-names></string-name> &amp; <string-name><surname>O’Reilly</surname>, <given-names>R. C.</given-names></string-name></person-group> <article-title>Why There Are Complementary Learning Systems in the Hippocampus and Neocortex: Insights From the Successes and Failures of Connectionist Models of Learning and Memory</article-title>. <source>Psychol Rev</source>. <volume>102</volume>(<issue>3</issue>):<fpage>419</fpage>-<lpage>457</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pearl</surname>, <given-names>J.</given-names></string-name></person-group> <source>Causality: Models, Reasoning, and Inference</source>. (<publisher-name>Cambridge University Press</publisher-name>, <year>2009</year>). doi:<pub-id pub-id-type="doi">10.1017/CBO9780511803161</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kumaran</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hassabis</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>McClelland</surname>, <given-names>J. L.</given-names></string-name></person-group> <article-title>What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated</article-title>. <source>Trends Cogn. Sci</source>. <volume>20</volume>, <fpage>512</fpage>–<lpage>534</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Reilly</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Bhattacharyya</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Howard</surname>, <given-names>M. D.</given-names></string-name> &amp; <string-name><surname>Ketz</surname>, <given-names>N.</given-names></string-name></person-group> <article-title>Complementary Learning Systems</article-title>. <source>Cogn. Sci</source>. <volume>38</volume>, <fpage>1229</fpage>–<lpage>1248</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name>, <string-name><surname>McCaffary</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bakermans</surname>, <given-names>J. J. W.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name></person-group> <article-title>How to build a cognitive map</article-title>. <source>Nat. Neurosci</source>. <volume>25</volume>, <fpage>1257</fpage>–<lpage>1272</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name> &amp; <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name></person-group> <article-title>Complementary learning systems within the hippocampus: a neural network modelling approach to reconciling episodic memory with statistical learning</article-title>. <source>Philos. Trans. R. Soc. B Biol. Sci</source>. <volume>372</volume>, <fpage>20160049</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sučević</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name></person-group> <article-title>A neural network model of hippocampal contributions to category learning</article-title>. <source>eLife</source> <volume>12</volume>, <elocation-id>e77185</elocation-id> (<year>2023</year>). <pub-id pub-id-type="doi">10.7554/eLife.77185</pub-id></mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Myers</surname>, <given-names>C. E.</given-names></string-name> &amp; <string-name><surname>Scharfman</surname>, <given-names>H. E.</given-names></string-name></person-group> <article-title>A role for hilar cells in pattern separation in the dentate gyrus: A computational approach</article-title>. <source>Hippocampus</source> <volume>19</volume>, <fpage>321</fpage>–<lpage>337</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Eloundou</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Manning</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mishkin</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Rock</surname>, <given-names>D.</given-names></string-name></person-group> <article-title>GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2303.10130</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="report"><person-group person-group-type="author"><collab>Executive Office of the President</collab></person-group>. <source>Executive Order No. 88,210: Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence</source>. <volume>88 Fr</volume> <fpage>75191</fpage> (<year>2023</year>). <publisher-name>Executive Office of the President</publisher-name></mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="report"><person-group person-group-type="author"><string-name><surname>Maslej</surname>, <given-names>N.</given-names></string-name></person-group> <source>Artificial Intelligence Index Report 2025</source>. <publisher-name>Artif. Intell</publisher-name>. (<year>2025</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="report"><person-group person-group-type="author"><collab>EU</collab></person-group>. <source>Regulation 2024/1689: Artificial Intelligence Act</source>. <publisher-name>Eur. Parliam. Counc. Eur. Union</publisher-name> (<year>2024</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Bender</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Gebru</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>McMillan-Major</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Shmitchell</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</article-title>. in <conf-name>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</conf-name> <fpage>610</fpage>–<lpage>623</lpage> (<publisher-name>ACM, Virtual Event Canada</publisher-name>, <year>2021</year>). doi:<pub-id pub-id-type="doi">10.1145/3442188.3445922</pub-id>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Lacoste</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Luccioni</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>V.</given-names></string-name> &amp; <string-name><surname>Dandres</surname>, <given-names>T.</given-names></string-name></person-group> <article-title>Quantifying the Carbon Emissions of Machine Learning</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.1910.09700</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwartz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Dodge</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>N. A.</given-names></string-name> &amp; <string-name><surname>Etzioni</surname>, <given-names>O.</given-names></string-name></person-group>. <article-title>Green AI</article-title> <source>Commun. ACM</source> <volume>63</volume>, <fpage>54</fpage>–<lpage>63</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Strubell</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ganesh</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>McCallum</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Energy and Policy Considerations for Deep Learning in NLP</article-title>. in <conf-name>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</conf-name> <fpage>3645</fpage>–<lpage>3650</lpage> (<publisher-name>Association for Computational Linguistics</publisher-name>, <conf-loc>Florence, Italy</conf-loc>, <year>2019</year>). doi:<pub-id pub-id-type="doi">10.18653/v1/P19-1355</pub-id>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Henighan</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Scaling Laws for Autoregressive Generative Modeling</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2010.14701</pub-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Kaplan</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Scaling Laws for Neural Language Models</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2001.08361</pub-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Botvinick</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Reinforcement Learning, Fast and Slow</article-title>. <source>Trends Cogn. Sci</source>. <volume>23</volume>, <fpage>408</fpage>–<lpage>422</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bakkour</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The hippocampus supports deliberation during value-based decisions</article-title>. <source>eLife</source> <volume>8</volume>, <elocation-id>e46080</elocation-id> (<year>2019</year>). <pub-id pub-id-type="doi">10.7554/eLife.46080</pub-id></mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Biderman</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Bakkour</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Shohamy</surname>, <given-names>D.</given-names></string-name></person-group> <article-title>What Are Memories For? The Hippocampus Bridges Past Experience with Future Decisions</article-title>. <source>Trends Cogn. Sci</source>. <volume>24</volume>, <fpage>542</fpage>–<lpage>556</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bornstein</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Khaw</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Shohamy</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> <article-title>Reminders of past choices bias decisions for reward in humans</article-title>. <source>Nat. Commun</source>. <volume>8</volume>, <fpage>15958</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bornstein</surname>, <given-names>A. M.</given-names></string-name> &amp; <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name></person-group> <article-title>Reinstated episodic context guides sampling-based decisions for reward</article-title>. <source>Nat. Neurosci</source>. <volume>20</volume>, <fpage>997</fpage>–<lpage>1003</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name> &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> <article-title>Reinforcement Learning and Episodic Memory in Humans and Animals: An Integrative Framework</article-title>. <source>Annu. Rev. Psychol</source>. <volume>68</volume>, <fpage>101</fpage>–<lpage>128</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>Hippocampal Contributions to Control: The Third Way</article-title>. <conf-name>Advances in Neural Information Processing Systems</conf-name> (<year>2007</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Shohamy</surname>, <given-names>D.</given-names></string-name></person-group> <article-title>Decision Making and Sequential Sampling from Memory</article-title>. <source>Neuron</source> <volume>90</volume>, <fpage>927</fpage>–<lpage>939</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shohamy</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> <article-title>Integrating memories to guide decisions</article-title>. <source>Curr. Opin. Behav. Sci</source>. <volume>5</volume>, <fpage>85</fpage>–<lpage>90</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Feng</surname>, <given-names>S. F.</given-names></string-name> &amp; <string-name><surname>Bornstein</surname>, <given-names>A. M.</given-names></string-name></person-group> <article-title>Mixing memory and desire: How memory reactivation supports deliberative decision-making</article-title>. <source>WIREs Cogn. Sci</source>. <volume>13</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kahana</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Howard</surname>, <given-names>M. W.</given-names></string-name> &amp; <string-name><surname>Polyn</surname>, <given-names>S. M.</given-names></string-name></person-group> <chapter-title>Associative Retrieval Processes in Episodic Memory</chapter-title>. in <source>Learning and Memory: A Comprehensive Reference</source> <fpage>1</fpage>–<lpage>24</lpage> (<publisher-name>Elsevier</publisher-name>, <year>2008</year>). doi:<pub-id pub-id-type="doi">10.1016/B978-012370509-9.00185-6</pub-id>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratcliff</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>A theory of memory retrieval</article-title>. <source>Psychol. Rev</source>. <volume>85</volume>, <fpage>59</fpage>–<lpage>108</lpage> (<year>1978</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Capretto</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Bambi : A Simple Interface for Fitting Bayesian Linear Models</article-title> in <source>Python. J. Stat. Softw</source>. <volume>103</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Westfall</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>Statistical details of the default priors in the Bambi library</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/ARXIV.1702.01201</pub-id> (<year>2017</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108664.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This manuscript makes a <bold>valuable</bold> contribution to understanding learning in multidimensional environments with spurious associations, which is critical for understanding learning in the real world. The evidence is based on model simulations and a preregistered human behavioral study, but remains <bold>incomplete</bold> because of inconclusive empirical results and insufficiencies in the modeling. Moreover, there are open questions about the nature and extent to which the behavioral task induced semantic congruency.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108664.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper reports model simulations and a human behavioral experiment studying predictive learning in a multidimensional environment. The authors claim that semantic biases help people resolve ambiguity about predictive relationships due to spurious correlations.</p>
<p>Strengths:</p>
<p>(1) The general question addressed by the paper is important.</p>
<p>(2) The paper is clearly written.</p>
<p>(3) Experiments and analyses are rigorously executed.</p>
<p>Weaknesses:</p>
<p>(1) Showing that people can be misled by spurious correlations, and that they can overcome this to some extent by using semantic structure, is not especially surprising to me. Related literature already exists on illusory correlation, illusory causation, superstitious behavior, and inductive biases in causal structure learning. None of this work features in the paper, which is rather narrowly focused on a particular class of predictive representations, which, in fact, may not be particularly relevant for this experiment. I also feel that the paper is rather long and complex for what is ultimately a simple point based on a single experiment.</p>
<p>(2) Putting myself in the shoes of an experimental subject, I struggled to understand the nature of semantic congruency. I don't understand why the builder and terminal robots should have similar features is considered a natural semantic inductive bias. Humans build things all the time that look different from them, and we build machines that construct artifacts that look different from the machines. I think the fact that the manipulation worked attests to the ability of human subjects to pick up on patterns rather than supporting the idea that this reflects an inductive bias they brought to the experiment.</p>
<p>(3) As the authors note, because the experiment uses only a single transition, it's not clear that it can really test the distinctive aspects of the SR/SF framework, which come into play over longer horizons. So I'm not really sure to what extent this paper is fundamentally about SFs, as it's currently advertised.</p>
<p>(4) One issue with the inductive bias as defined in Equation 15 is that I don't think it will converge to the correct SR matrix. Thus, the bias is not just affecting the learning dynamics, but also the asymptotic value (if there even is one; that's not clear either). As an empirical model, this isn't necessarily wrong, but it does mess with the interpretation of the estimator. We're now talking about a different object from the SR.</p>
<p>(5) Some aspects of the empirical and model-based results only provide weak support for the proposed model. The following null effects don't agree with the predictions of the model:</p>
<p>(a) No effect of condition on reward.</p>
<p>(b) No effect of condition on composition spurious predictiveness.</p>
<p>(c) No effect of condition on the fitted bias parameter. The authors present some additional exploratory analyses that they use to support their claims, but this should be considered weaker support than the results of preregistered analyses.</p>
<p>(6) I appreciate that the authors were transparent about which predictions weren't confirmed. I don't think they're necessarily deal-breakers for the paper's claims. However, these caveats don't show up anywhere in the Discussion.</p>
<p>(7) I also worry that the study might have been underpowered to detect some of these effects. The preregistration doesn't describe any pilot data that could be used to estimate effect sizes, and it doesn't present any power analysis to support the chosen sample sizes, which I think are on the small side for this kind of study.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108664.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work by Prentis and Bakkour examines how predictive memory can become distorted in multidimensional environments and how inductive biases may mitigate these distortions. Using both computational simulations and an original human-robot building task with manipulated semantic congruency, the authors show that spurious observations can amplify noise throughout memory. They hypothesize, and preliminarily support, that humans deploy inductive biases to suppress such spurious information.</p>
<p>Strengths:</p>
<p>(1) The manuscript addresses an interesting and understudied question-specifically, how learning is distorted by spurious observations in high-dimensional settings.</p>
<p>(2) The theoretical modeling and feature-based successor representation analyses are methodologically sound, and simulations illustrate expected memory distortions due to multidimensional transitions.</p>
<p>(3) The behavioral experiment introduces a creative robot-building paradigm and manipulates transitions to test the effect of semantic congruency (more so category part congruency as explained below).</p>
<p>Weaknesses:</p>
<p>(1) The semantic manipulation may be more about category congruence (e.g., body part function) than semantic meaning. The robot-building task seems to hinge on categorical/functional relationships rather than semantic abstraction. Strong evidence for semantic learning would require richer, more genuinely semantic manipulations.</p>
<p>(2) The experimental design remains limited in dimensionality and depth. Simulated higher-dimensional or deeper tasks (or empirical follow-up) would strengthen the interpretation and relevance for real-world memory distortion.</p>
<p>(3) The identification of idiosyncratic biases appears to reflect individual variation in categorical mapping rather than semantic processing. The lack of conjunctive learning may simply reflect variability in assumed builder-target mappings, not a principled semantic effect.</p>
<p>Additional Comments:</p>
<p>(1) It is unclear whether this task primarily probes memory or reinforcement learning, since the graded reward feedback in the current design closely aligns with typical reinforcement learning paradigms.</p>
<p>(2) It may be unsurprising that the feature-based successor model fits best given task structure, so broader model comparisons are encouraged.</p>
<p>(3) Simulation-only work on higher dimensionality (lines 514-515) falls short; an empirical follow-up would greatly enhance the claims.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108664.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The article's main question is how humans handle spurious transitions between object features when learning a predictive model for decision-making. The authors conjecture that humans use semantic knowledge about plausible causal relations as an inductive bias to distinguish true from spurious links.</p>
<p>The authors simulate a successor feature (SF) model, demonstrating its susceptibility to suboptimal learning in the presence of spurious transitions caused by co-occurring but independent causal factors. This effect worsens with an increasing number of planning steps and higher co-occurrence rates. In a preregistered study (N=100), they show that humans are also affected by spurious transitions, but perform somewhat better when true transitions occur between features within the same semantic category. However, no evidence for the benefits of semantic congruency was found in test trials involving novel configurations, and attempts to model these biases within an SF framework remained inconclusive.</p>
<p>Strengths:</p>
<p>(1) The authors tackle an important question.</p>
<p>(2) Their simulations employ a simple yet powerful SF modeling framework, offering computational insights into the problem.</p>
<p>(3) The empirical study is preregistered, and the authors transparently report both positive and null findings.</p>
<p>(4) The behavioral benefit during learning in the congruent vs incongruent condition is interesting</p>
<p>Weaknesses:</p>
<p>(1) A major issue is that approximately one quarter of participants failed to learn, while another quarter appeared to use conjunctive or configural learning strategies. This raises questions about the appropriateness of the proposed feature-based learning framework for this task. Extensive prior research suggests that learning about multi-attribute objects is unlikely to involve independent feature learners (see, e.g., the classic discussion of configural vs. elemental learning in conditioning: Bush &amp; Mosteller, 1951; Estes, 1950).</p>
<p>(2) A second concern is the lack of explicit acknowledgment and specification of the essential role of the co-occurrence of causal factors. With sufficient training, SF models can develop much stronger representations of reliable vs. spurious transitions, and simple mechanisms like forgetting or decay of weaker transitions would amplify this effect. This should be clarified from the outset, and the occurrence rates used in all tasks and simulations need to be clearly stated.</p>
<p>(3) Another problem is that the modeling approach did not adequately capture participant behavior. While the authors demonstrate that the b parameter influences model behavior in anticipated ways, it remains unclear how a model could account for the observed congruency advantage during learning but not at test.</p>
<p>(4) Finally, the conceptualization of semantic biases is somewhat unclear. As I understand it, participants could rely on knowledge such as &quot;the shape of a building robot's head determines the kind of head it will build,&quot; while the type of robot arm would not affect the head shape. However, this assumption seems counterintuitive - isn't it plausible that a versatile arm is needed to build certain types of robot heads?</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108664.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Prentis</surname>
<given-names>Euan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0619-2280</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Bakkour</surname>
<given-names>Akram</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6070-4945</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We would like to thank the reviewers for their valuable feedback on this research.</p>
<p>Based on the limitations identified across the reviews, we will make four major revisions to this work. We will: (1) run a multi-step experiment to better test the successor representation framework and the predictions made by our model simulations; (2) include a task to explicitly gauge participants’ judgements about the relatedness of the robot features; (3) test additional computational models that may better capture participants’ behavior; and (4) clarify and expand the definition of the inductive bias studied in this work.</p>
<p>(1) The reviews raised the concern that while we frame our results as being about predictive learning within the successor representation framework, we investigated participants’ behavior on a one-step task that is not well suited to characterizing this form of predictive representation. Moreover, our simulations make predictions about how learning may differ in relatively more naturalistic environments, yet we do not test human participants in these more complex learning contexts. Finally, we found several null results for effects that were predicted by our simulations. This may be because the benefits of the bias are predicted to be more limited in simpler learning environments, and our experiment may not have been sufficiently powered to detect these smaller effects. To address these limitations, we will run a new experiment with a multi-step causal structure, allowing us to better test the SR framework while more comprehensively investigating the predictions of the simulations and improving our power to detect effects that were null in the one-step experiment.</p>
<p>(2) We argued that the causal-bias parameter may capture idiosyncratic differences in participants’ semantic memory that had an ensuing effect on their learning. However, the reviews identified that we did not explicitly measure participants’ judgements about the relatedness of the robot features to verify that existing conceptual knowledge drove these individual differences. In the new experiment, we will therefore include a task to quantify participants’ individual judgements about the relatedness of the robot features.</p>
<p>(3) The reviews questioned the suitability of the feature-based model for explaining behavior in the task given that only a subset of participants were best fit by the model, and not all of the model’s behavioral predictions were observed in the human subjects experiment. The reviews suggested alternative models could more validly capture behavior. In the revision, we will therefore consider alternative models (e.g., model-based planning, successor features with decay on weak associations).</p>
<p>(4) The reviews requested some clarity around our conceptualization of the inductive bias studied in this work, and questioned whether the task sufficiently captured the richness of semantic knowledge that may be required for a “semantic bias.” We acknowledge that the term semantic bias may not be an accurate descriptor of the inductive bias we measured. Instead, a more general “conceptual bias” term may better capture how any hierarchical conceptual knowledge – semantic or otherwise – may drive the studied bias. We will clarify our terminology in the revision.</p>
<p>In addition to these major revisions, we will address more minor critiques and suggestions raised by individual reviewers.</p>
</body>
</sub-article>
</article>