<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">102475</article-id>
<article-id pub-id-type="doi">10.7554/eLife.102475</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102475.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Sequence action representations contextualize during rapid skill learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0543-0304</contrib-id>
<name>
<surname>Dash</surname>
<given-names>Debadatta</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9659-4127</contrib-id>
<name>
<surname>Iwane</surname>
<given-names>Fumiaki</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9344-4203</contrib-id>
<name>
<surname>Hayward</surname>
<given-names>William</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0008-5743-6805</contrib-id>
<name>
<surname>Salamanca-Giron</surname>
<given-names>Roberto</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bonstrup</surname>
<given-names>Marlene</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5443-8222</contrib-id>
<name>
<surname>Buch</surname>
<given-names>Ethan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>ethan.buch@nih.gov</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1705-8773</contrib-id>
<name>
<surname>Cohen</surname>
<given-names>Leonardo G</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>cohenl@ninds.nih.gov</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>Human Cortical Physiology and Neurorehabilitation Section, NINDS, NIH</institution></institution-wrap>, <city>Bethesda</city>, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/028hv5492</institution-id><institution>Department of Neurology, University of Leipzig Medical Center</institution></institution-wrap>, <city>Leipzig</city>, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Gallego</surname>
<given-names>Juan Alvaro</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Imperial College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-11-11">
<day>11</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP102475</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-08-28">
<day>28</day>
<month>08</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-08-15">
<day>15</day>
<month>08</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.15.608189"/>
</event>
</pub-history>
<permissions>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">
<ali:license_ref>https://creativecommons.org/publicdomain/zero/1.0/</ali:license_ref>
<license-p>This is an open-access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0 public domain dedication</ext-link>.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-102475-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Activities of daily living rely on our ability to acquire new motor skills composed of precise action sequences. Early learning of a new sequential skill is characterized by steep performance improvements that develop predominantly during rest intervals interspersed with practice, a form of rapid consolidation. Here, we ask if the millisecond level neural representation of an action performed at different locations within a skill sequence contextually differentiates or remains stable as learning evolves. Optimization of machine learning decoders to classify sequence-embedded finger movements from MEG activity reached approximately 94% accuracy. The representation manifolds of the same action performed in different sequence contexts progressively differentiated during rest periods of early learning, predicting skill gains. We conclude that sequence action representations contextually differentiate during early skill learning, an issue relevant to brain-computer interface applications in neurorehabilitation.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Motor learning is required to perform a wide array of basic daily living activities, intricate athletic endeavors, and professional skills. Whether it’s learning to type more quickly on a keyboard<sup><xref ref-type="bibr" rid="c1">1</xref></sup>, improve one’s tennis game<sup><xref ref-type="bibr" rid="c2">2</xref></sup>, or play a piece of music on the piano<sup><xref ref-type="bibr" rid="c3">3</xref></sup> – all of these skills require the ability to execute sequences of actions with precise temporal coordination. Action sequences thus form the building blocks of fine motor skills<sup><xref ref-type="bibr" rid="c4">4</xref></sup>. Initial exposure to acquisition of a new skill results in rapid performance improvements during the initial practice session (i.e. – early learning), which is up to four times larger in magnitude compared to offline performance improvements reported following overnight sleep<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c5">5</xref></sup>.</p>
<p>The neural representation of a sequential skill binds discrete individual actions (e.g. - single piano keypress) into complex, temporally and spatially precise sequence representations (e.g. - a refrain from a piece of music)<sup><xref ref-type="bibr" rid="c6">6</xref>,<xref ref-type="bibr" rid="c7">7</xref></sup>. The neural representation or manifold<sup><xref ref-type="bibr" rid="c8">8</xref></sup> of sequential skills has been characterized in humans<sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c10">10</xref></sup>. Previous fMRI reports showed that the representation of individual motor sequence actions may remain relatively stable over days or weeks of practice, after a memory is formed<sup><xref ref-type="bibr" rid="c11">11</xref></sup>. However, it is not known if individual sequence action representations differentiate or remain stable during early skill learning, when most prominent performance improvements occur, and the memory is not yet fully formed<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. Furthermore, it is not known if performance of the same action executed at different contextual locations within a skill sequence can change as a function of learning progression, an issue crucial to the robustness of BCI applications.</p>
<p>Investigating the contextualization of discrete action representations at a millisecond level is challenging since both the individual actions and the skill sequence they are embedded within are concurrently represented in changing neural activity dynamics during learning<sup><xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c12">12</xref></sup>. To address this problem, we constructed a series of decoders aimed at predicting keypress actions from magnetoencephalographic (MEG) neural activity, dependent upon the learning state and the local sequence context (ordinal position) the keypress action is performed within. Implementing this novel approach allowed us to determine that individual sequence actions are indeed contextualized during early skill learning resulting in differentiation of their neural representations, and that the degree of this differentiation predicts skill gains. This representational contextualization was also observed to predominantly develop during rest rather than during practice intervals in parallel with rapid consolidation of skill.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>Participants engaged in a well characterized sequential skill learning task<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c13">13</xref></sup> that involved repetitive typing of a sequence (4-1-3-2-4) performed with their (non-dominant) left hand over 36 trials with alternating periods of 10s <italic>practice</italic> and 10s <italic>rest</italic> (<italic>inter-practice rest</italic>; <italic>Day 1 Training</italic>; <xref rid="fig1" ref-type="fig">Figure 1A</xref>). Individual keypress times and finger keypress identities were recorded and used to quantify skill as the correct sequence speed (keypresses/s)<sup><xref ref-type="bibr" rid="c1">1</xref></sup>.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental design and behavioral performance</title>
<p><bold><italic>A. Skill learning task.</italic></bold> Participants engaged in a procedural motor skill learning task, which required them to repeatedly type a keypress sequence, “4 − 1 − 3 − 2 − 4” (1 = little finger, 2 = ring finger, 3 = middle finger, and 4 = index finger) with their non-dominant, left hand. The <italic>Day 1 Training</italic> session included 36 trials, with each trial consisting of alternating 10s practice and rest intervals. After a 24-hour break, participants were retested on performance of the same sequence (4-1-3-2-4) for 9 trials (<italic>Day 2 Retest)</italic> as well as single-trial performance on 9 different sequences (<italic>Day 2 Control</italic>; 2-1-3-4-2, 4-2-4-3-1, 3-4-2-3-1, 1-4-3-4-2, 3-2-4-3-1, 1-4-2-3-1, 3-2-4-2-1, 3-2-1-4-2, and 4-2-3-1-4). MEG was recorded during both Day 1 and Day 2 sessions with a 275-channel CTF magnetoencephalography (MEG) system (CTF Systems, Inc., Canada). <bold><italic>B. Skill Learning</italic></bold>. As reported previously<sup><xref ref-type="bibr" rid="c1">1</xref></sup>, participants on average reached 95% of peak performance by trial 11 of the <italic>Day 1 Training</italic> session (see <xref rid="figs1" ref-type="fig">Figure 1 - figure Supplement 1A</xref> for results over all <italic>Day 1 Training</italic> and <italic>Day 2 Retest</italic> trials). At the group level, total early learning was exclusively accounted for by micro-offline gains during inter-practice rest intervals (<xref rid="fig1" ref-type="fig">Figure 1B</xref> inset). <bold>C. Keypress transition time (KTT) variability.</bold> Distribution of KTTs normalized to the median correct sequence time for each participant and centered on the mid-point for each full sequence iteration during early learning (see <xref rid="figs1" ref-type="fig">Figure 1—figure Supplement 1B</xref> for results over all <italic>Day 1 Training</italic> and <italic>Day 2 Retest</italic> trials). Note the initial variability of the relative KTT composition of the sequence (i.e. – 4-1, 1-3, 3-2, 2-4, 4-4), before it stabilizes by trial 6 in the early learning period.</p></caption>
<graphic xlink:href="608189v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Participants reached 95% of maximal skill (i.e. - Early Learning) within the initial 11 practice trials (<xref rid="fig1" ref-type="fig">Figure 1B</xref>), with improvements developing over inter-practice rest periods (micro-offline gains) accounting for almost all of total learning across participants (<xref rid="fig1" ref-type="fig">Figure 1B</xref><bold> inset</bold>)<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. In addition to the reduction in sequence duration during early learning, the relative duration of component keypress transitions displayed increased temporal regularity across sequence iterations (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). On the following day, participants were retested on performance of the same sequence (4-1-3-2-4) over 9 trials (<italic>Day 2 Retest</italic>), as well as single-trial performance on 9 different untrained sequences (<italic>Day 2 Controls</italic>: 2-1-3-4-2, 4-2-4-3-1, 3-4-2-3-1, 1-4-3-4-2, 3-2-4-3-1, 1-4-2-3-1, 3-2-4-2-1, 3-2-1-4-2, and 4-2-3-1-4). As expected, an upward shift in performance of the trained sequence (0.68 ± SD 0.56 keypresses/s; t = 7.21, <italic>p</italic> &lt; 0.001) was observed during <italic>Day 2 Retest</italic>, indicative of an overnight skill consolidation effect for the trained sequence only (<xref rid="figs1" ref-type="fig">Figure 1—figure Supplement 1C</xref>).</p>
<sec id="s2a">
<title>Keypress actions are represented in multi-scale hybrid-space manifolds</title>
<p>To investigate the possibility of contextualization of action representations, we constructed a set of decoders to predict keypress actions from MEG activity as a function of both the learning state and the ordinal position of the keypress within the sequence. We first characterized the spectral and spatial features of keypress state representations by comparing performance of decoders constructed around broadband (1-100Hz) or narrowband [delta- (1-3Hz), theta- (4-7Hz), alpha- (8-14 Hz), beta- (15-24 Hz), gamma- (25-50Hz) and high gamma-band (51-100Hz)] MEG oscillatory activity. We found that decoders trained on broadband data consistently outperformed those trained on narrowband activity, and that whole-brain parcel- (148 brain regions or parcels) or voxel-space (15684 voxels)<sup><xref ref-type="bibr" rid="c14">14</xref></sup> decoders exhibited greater accuracy (parcel: t = 1.89, <italic>p</italic> = 0.035; voxel: t = 7.18, <italic>p</italic> &lt; 0.001) than individual voxel-space intra-parcel decoders (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Specifically, while the highest performing intra-parcel decoders predicted keypresses with up to 68.77% (± SD 7.6%) accuracy, whole-brain inter-parcel decoder accuracy reached 74.51% (± SD 7.34%) (<xref rid="fig2" ref-type="fig">Figure 2</xref>, also see <xref rid="figs2" ref-type="fig">Figure 2 – figure supplement 1</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Spatial and oscillatory contributions to neural decoding of finger identities</title>
<p><bold><italic>A. Contribution of whole brain oscillatory frequencies to decoding.</italic></bold> When trained on broadband activity relative to narrow frequency band features, decoding accuracy (i.e. - test sample performance) was highest for whole-brain voxel- (74.51% ± SD 7.34%, t = 8.08, <italic>p</italic> &lt; 0.001) and parcel-space (70.11% ± SD 7.11%, t = 13.22, <italic>p</italic> &lt; 0.001) MEG activity. Thus, decoders trained on whole-brain broadband data consistently outperformed those trained on narrowband activity. Dots depict decoding accuracy for each participant. *<italic>p</italic> &lt; 0.05, **<italic>p</italic>&lt; 0.01, ***<italic>p</italic>&lt; 0.001, ns.: not significant. <italic>B. Contribution of intra-parcel brain oscillatory frequencies to decoding.</italic> Performance of the top performing decile of intra-parcel decoders (see <bold>Methods, </bold><xref rid="figs2" ref-type="fig">Figure 2—figure supplement 1</xref>) over different frequency bands (top-panel; decoding accuracy is color coded and listed for each parcel and frequency band assessed). Note that broadband activity resulted in best accuracy closely followed by delta band activity. Broadband intra-parcel decoding accuracy mapped to a standard brain surface (FreeSurfer <italic>fsaverage</italic> brain) and color-coded by accuracy (bottom panel). Note that bilateral superior frontal cortex (yellow, 69%) contributed the most to decoding accuracy followed by middle frontal, pre-and post-central regions (&gt; 60%).</p></caption>
<graphic xlink:href="608189v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we asked if the combination of intra- and inter-parcel activity patterns, constituting a multi-scale hybrid space, improve further keypress predictions. We constructed hybrid space decoders (N = 1295 ± 20) combining all inter-parcel activity with top-ranked intra-parcel features (covering 8 regions, see <bold>Methods, </bold><xref rid="fig3" ref-type="fig">Figure 3A</xref>). Decoder accuracy was higher for hybrid (78.15% ± SD 7.03% accuracy and a weighted mean F1 score of 0.78 ± SD 0.07) than for voxel- (74.51% ± SD 7.34%; paired <italic>t</italic>-test: t = 6.30, <italic>p</italic> &lt; 0.001) and parcel- (70.11% ± SD 7.48%; paired <italic>t</italic>-test = 12.08, <italic>p</italic> &lt; 0.001) spaces (<xref rid="fig3" ref-type="fig">Figure 3B</xref>, <xref rid="figs3" ref-type="fig">Figure 3 – figure supplement 1</xref>). Thus, a multi-scale hybrid-space representation best characterizes keypress action manifolds.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Hybrid spatial approach for neural decoding during skill learning <italic>A. Pipeline</italic></title>
<p>Sensor-space MEG data (<italic>N</italic> = 272 channels) were source-localized (voxel-space features; <italic>N</italic> = 15684 voxels), and then parcellated (parcel-space features; <italic>N</italic> = 148) by averaging the activity of all voxels located within an individual region defined in a standard template space (Desikan-Killiany Atlas). Individual voxel-space regional decoders (intra-parcel decoders) were then constructed and ranked. The final hybrid-space keypress state (i.e. – 4-class) decoder was constructed using all parcel-spaces and top-ranked intra-parcel voxel input features (see Methods). <bold>B. Decoding performance across parcel, voxel, and hybrid spaces.</bold> Note that decoding performance was highest for the hybrid space approach compared to performance obtained for whole-brain voxel- and parcel spaces. Addition of linear discriminant analysis (LDA)-based dimensionality reduction further improved decoding performance for both parcel- and hybrid-space approaches. Each dot represents accuracy for a single participant and method. “<bold>∗∗∗</bold>” indicates <italic>p</italic> &lt; 0.001 and “<bold>∗</bold>” indicates <italic>p</italic> &lt; 0.05. <bold><italic>C. Confusion matrix of individual finger identity decoding for hybrid-space manifold features.</italic></bold> True predictions are located on the main diagonal. Off-diagonal elements in each row depict false-negative predictions for each finger, while off-diagonal elements in each column indicate false-positive predictions. Please note that the index finger keypress had the highest misclassifications (<italic>n</italic> = 141 or 47.5% of all prediction errors).</p></caption>
<graphic xlink:href="608189v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We implemented several dimensionality reduction or manifold learning strategies including principal component analysis (PCA), multi-dimensional scaling (MDS), minimum redundant maximum relevance (MRMR), and linear discriminant analysis (LDA)<sup><xref ref-type="bibr" rid="c15">15</xref></sup> to map the input feature (parcel, voxel or hybrid) space to a low-dimensional latent space or manifold<sup><xref ref-type="bibr" rid="c8">8</xref></sup>. LDA-based manifold representation performed the best improving the keypress decoding accuracy to 90.47% ± SD 4.84% (<xref rid="fig3" ref-type="fig">Figure 3B</xref>; weighted mean F1 score = 0.91 ± SD 0.05). Consistently, LDA dimensionality reduction improved decoder performance at parcel (82.95% ± SD 5.48%) but reduced it at voxel space (40.38 % ± SD 6.78%; also see <xref rid="figs4" ref-type="fig">Figure 3 – figure supplement 2</xref>). Notably, decoding associated with index finger keypresses (executed at two different ordinal positions in the sequence) exhibited the highest number of misclassifications of all digits (N = 141 or 47.5% of all decoding errors; <xref rid="fig3" ref-type="fig">Figure 3C</xref>), raising the hypothesis that the same action could be differentially represented when executed at different learning state or sequence context locations.</p>
<p>We assessed the robustness of this hybrid strategy for decoding actions during skill learning over multiple sessions by applying it to data collected on the following day during the <italic>Day 2 Retest</italic> (9-trial retest of the same trained sequence) and <italic>Day 2 Control</italic> (single-trial performance of 9 different untrained sequences) blocks. The decoding accuracy for <italic>Day 2</italic> MEG data remained high (87.11% ± SD 8.54% for the trained sequence during <italic>Retest</italic>, and 79.44% ± SD 5.54% for the untrained <italic>Control</italic> sequences; see confusion matrices in <xref rid="figs5" ref-type="fig">Figure 3 – figure supplement 3</xref>). This indicates that the hybrid decoding strategy is particularly reliable for decoding keypress actions during skill learning and the neural representations of the learned sequence remain stable the following day. Although the keypress state decoding performance was lower for untrained <italic>Control</italic> sequences relative to the trained sequence, greater accuracy of the hybrid approach over purely parcel- or voxel-space input features was still observed. Thus, this hybrid approach allows robust sequential finger movement decoding across multiple days and sequences.</p>
</sec>
<sec id="s2b">
<title>Inclusion of keypress sequence context location optimized decoding performance</title>
<p>Next, we tracked the trial-by-trial evolution of keypress action manifolds as training progressed. Keypress neural representations were observed to progressively differentiate during early learning (<xref rid="fig4" ref-type="fig">Figure 4</xref>). A representative example in <xref rid="fig4" ref-type="fig">Figure 4A</xref> (top row) depicts progressive representational clustering of four-digit representations from trials 1, 11, and 36. The spatial representation of these clusters changed over the course of training, from predominant involvement of pre-central areas in trial 1 to post-central, superior, and middle frontal cortex contributions in later trials 11 and 36 (<xref rid="fig4" ref-type="fig">Figure 4A</xref>, bottom row). Thus, a shift in activity from pre-central areas to post-central, superior, and middle frontal cortex paralleled improvements in decoding performance (also see <xref rid="figs6" ref-type="fig">Fig. Figure 4 – figure supplement 1</xref> for trial-by-trial quantitative feature importance score changes during skill learning).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Evolution of Keypress Neural Representations with Skill Learning</title>
<p><bold><italic>A. Keypress neural representations differentiate during early learning.</italic></bold> t-SNE distribution of neural representation of each keypress (top scatter plots) is shown for trial 1 (start of training; top-left), 11 (end of early learning; top-center), and 36 (end of training; top-right) for a single representative participant. Individual keypress manifold representation clustering in trial 11 (top-center; end of early learning) depicts sub-clustering for the index finger keypress performed at the two different ordinal positions in the sequence (Index<sub>OP1</sub> and Index<sub>OP5</sub>), which remains present by trial 36 (top-right). Spatial distribution of regional contributions to decoding (bottom brain surface maps). The surface color heatmap indicates feature importance scores across the brain. Note that decoding contributions shifted from right pre-central cortex at trial 1 (bottom-left) to superior and middle frontal cortex at trials 11 (bottom-center) and 36 (bottom-right). <bold><italic>B. Confusion matrix for 5-class decoding of individual sequence items.</italic></bold> Decoders were trained to classify contextual representations of the keypresses (i.e., 5-class classification of the sequence elements 4-1-2-3-4). Note that the decoding accuracy increased to 94.15% ± SD 4.84% and the misclassification of keypress 4 was significantly reduced (from 141 to 82). <italic>C. Trial-by-trial classification accuracy for 2-class decoder (Index<sub>OP1</sub> vs. Index<sub>OP5</sub>).</italic> A decoder trained to differentiate between the two index finger keypresses embedded at different positions (Index<sub>OP1</sub> at ordinal position 1 vs. Index<sub>OP5</sub> at ordinal position 5) within the trained sequence becomes progressively more accurately over early learning, stabilizing around 96% by trial 12 (end of early learning). Taken together, these findings indicate that the neural feature space evolves over early learning to incorporate sequence location information.</p></caption>
<graphic xlink:href="608189v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Correct performance of the training sequence required pressing the index finger twice (<bold>4</bold>-1-3-2-<bold>4</bold>) at two contextually different ordinal positions (sequence positions 1 and 5). Inclusion of sequence location information (i.e. – sequence context) for each keypress action (five sequence elements with the one keypress represented twice at two different locations) improved decoding accuracy (t = 7.09, <italic>p</italic> &lt; 0.001, <xref rid="fig4" ref-type="fig">Figure 4B</xref>) from 90.47% (± SD 3.44%) to 94.15% (± SD 4.84%; weighted mean F1 score: 0.94), and reduced overall misclassifications by 54.3% (from 219 to 119; <xref rid="fig3" ref-type="fig">Figure 3C</xref><bold> and </bold><xref rid="fig4" ref-type="fig">4B</xref>). This is supported by greater differentiation in neural representations of the two different index finger keypresses embedded at different points within the sequence (<xref rid="fig4" ref-type="fig">Figure 4A</xref>), which leads to a trial-by-trial increase in 2-class decoding accuracy (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). Inclusion of contextual information to the hybrid-space decoder also increased classification accuracy of Day 2 Retest trained sequence data (from 87.11% for 4-class to 90.22% for 5-class). As expected, contextualized 5-class decoding of Day 2 Control MEG data for untrained sequences performed at or below chance levels (≤ 30.22% ± SD 0.44%) due to varied ordinal positions of keypress actions across the different sequences. Thus, inclusion of contextual information in the decoding framework only improves decoding accuracy for skill sequences which have been learned through practice.</p>
</sec>
<sec id="s2c">
<title>Neural representation of keypress sequence location diverged during early skill learning</title>
<p>Finally, we used a Euclidian distance measure to evaluate the differentiation of the neural representation manifold of the same action (i.e. - an index-finger keypress) executed within different local sequence contexts (i.e. - ordinal position 1 vs. ordinal position 5). Note that, the neural representation manifolds (i.e. - the reduced dimension hybrid-space features extracted from broadband MEG data) are the features that resulted in the best decoding performance (See Methods, <xref rid="figs7" ref-type="fig">Figure 4 – figure supplement 2</xref>).</p>
<p>The Euclidian distance between keypress sequence location manifolds of the index finger in its two ordinal positions increased progressively during both rest and practice periods of early learning before stabilizing (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). Change in this Euclidian distance was more prominent during rest than during practice periods (t = 4.84, <italic>p</italic> &lt; 0.001; <xref rid="fig5" ref-type="fig">Figure 5B</xref>), similar to early learning gains (<xref rid="fig1" ref-type="fig">Figure 1B</xref>) and strongly predicted cumulative micro-offline gains (<italic>r</italic> = 0.90, R<sup>2</sup> = 0.82, <italic>p</italic> &lt; 0.001; <xref rid="figs8" ref-type="fig">Figure 5 - figure supplement 1</xref>). Importantly, the differentiation in neural representations was not explained by differences in keypress transition pattern regularity (within-subject; t = −0.03, <italic>p</italic> = 0.976; <xref rid="figs9" ref-type="fig">Figure 5 – figure supplement 2</xref>) or typing speed (between-subject; R<sup>2</sup> = 0.028, <italic>p</italic> = 0.41; <xref rid="figs10" ref-type="fig">Figure 5 – figure supplement 3</xref>). These neural representation manifold differences remained consistent on the next day test session for the trained sequence, significantly higher than those for the untrained sequences (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). The effect of contextualization also remained stable on <italic>Day 2 Retest</italic> – at the same time that an upward shift in performance speed and slight decrease in 4-class decoding accuracy was observed – and was substantially greater than contextualization observed for groups of untrained sequences (<xref rid="fig5" ref-type="fig">Figure 5C</xref>) indicating specificity for sequence pattern, keypress finger and ordinal position.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Neural representation distance between index finger keypresses performed at two different ordinal positions within a sequence</title><p><bold>A. <italic>Contextualization increases over Early Learning during Day 1 Training.</italic></bold> Online (Practice; green line) and offline (Rest; magenta line) neural representation distances between two index finger key presses performed at ordinal positions 1 and 5 of the trained sequence (4-1-3-2-4) are shown for each trial during Day 1 Training. Both online and offline distances between the two index finger representations increase sharply over the Early Learning before stabilizing across later <italic>Day 1 Training</italic> trials. <bold>B. <italic>Contextualization primarily occurs offline during short inter-practice rest periods.</italic></bold> The neural representation difference was significantly greater when assessed offline (right distribution; purple) versus online (left distribution; green) periods (t = 4.84, p &lt; 0.001). <bold>C. <italic>Contextualization was retained after 24 hours and was specific to the trained sequence.</italic></bold> The neural representation differences assessed across both rest and practice for the trained sequence (4-1-3-2-4) were retained for <italic>Day 2 Retest</italic>. Further, contextualization was significantly reduced for several untrained sequences controlling for: 1) index finger keypresses located at the same ordinal positions 1 and 5 but with a different intervening sequence pattern (<italic>Pattern Specificity Control</italic>: 4-2-3-1-4); 2) both ordinal 1 and 5 position keypresses performed with either the little or ring finger instead of the index finger (<italic>Finger Specificity Control</italic>: 2-1-3-4-2, 1-4-2-3-1 and 2-3-1-4-2); and 3) multiple index finger keypresses occurring at ordinal positions other than 1 and 5 (<italic>Position Specificity Control</italic>: 4-2-4-3-1 and 1-4-3-4-2). The mean online neural representation distance, or degree of contextualization, was substantially lower for the untrained control sequences (51.05% lower for the <italic>Pattern Specificity Control</italic> sequence, 35.80% lower for the <italic>Finger Specificity Control</italic> sequences, and 22.06% lower for the <italic>Position Specificity Control</italic> sequences) compared with the trained sequence. Note that offline contextualization cannot be measured for the <italic>Day 2 Control</italic> sequences as each sequence was only performed over a single trial.</p></caption>
<graphic xlink:href="608189v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The main findings of this study were that individual sequence action representations differentiate during early skill learning in a manner reflecting the local sequence context in which they are performed, and that the degree of representational differentiation, particularly prominent during rest intervals, predicts skill gains.</p>
<sec id="s3a">
<title>Optimizing decoding of sequential finger movements from MEG activity</title>
<p>The initial phase of this study involved optimizing the accuracy of decoding individuated finger keypresses from MEG brain activity. The decoding of individual finger movement execution or intention is a fundamental part of many translational BCI applications<sup><xref ref-type="bibr" rid="c16">16</xref>–<xref ref-type="bibr" rid="c20">20</xref></sup>. For example, decoding of virtual keypresses can be interfaced with applications for controlling motorized wheelchairs, writing and sending emails, or even controlling robotic hands or exoskeletons<sup><xref ref-type="bibr" rid="c21">21</xref></sup>, and are currently being evaluated in patients with spinal cord and brain lesions<sup><xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c23">23</xref></sup>. Once these neural signals are characterized, they can be translated into meaningful commands or actions<sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c24">24</xref></sup>. However, achieving robustness in clinical applications necessitates enhancements in state-of-the-art decoding tools, with a particular focus on improving decoding accuracy<sup><xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c25">25</xref></sup>.</p>
<p>In the present study, we developed a novel hybrid-space decoder that captured the evolving neural representational dynamics over multiple spatial resolutions. This approach combined (1) parcel-space estimates from whole-brain activity and (2) voxel-space estimates from brain regions containing most keypress-related brain activity (see <bold>Methods</bold>). Using this approach, we achieved keypress state decoding accuracy that exceeded 90%, a substantial improvement over accuracies reported before with either non-invasive neuroimaging (i.e. – 43% to 77% for fMRI, MEG, and EEG)<sup><xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c26">26</xref>–<xref ref-type="bibr" rid="c28">28</xref></sup> or invasive neural recording decoding of imagined movements (i.e. – 77% to 86% for ECOG and micro-array implant)<sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref></sup> techniques. Given these findings, the improvement in the keypress decoding accuracy from <xref rid="fig2" ref-type="fig">Figure 2</xref> (parcel/voxel) to <xref rid="fig3" ref-type="fig">Figure 3</xref> (parcel/voxel/hybrid with dimension reduction) is likely explained by the capability of the hybrid-space architecture to capture both lower spatially resolved whole-brain and higher spatially resolved regional activity patterns that contribute unique skill-related information to the sequence-embedded keypress state representations. Importantly, this approach allowed accurate decoding during skill acquisition before a performance plateau was reached. It is possible that the ability to decode finger movements in the midst of substantial trial-by-trial performance changes as shown here could improve robustness of BCI applications in neurorehabilitation<sup><xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c31">31</xref></sup>. Accurate estimation of finger movement representations as they evolve during skill learning should also improve detection of neural replay events during wakeful rest or sleep, and enhance investigations of the role replay has in supporting skill consolidation<sup><xref ref-type="bibr" rid="c13">13</xref></sup>.</p>
<p>Best decoding performance was obtained from activity in the bilateral superior and middle frontal cortex and the pre- and post-central regions, all known contributors to skill learning<sup><xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c32">32</xref></sup>. Low-frequency oscillations (LFOs) contributed the most to decoding accuracy, consistent with previous reports<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>. LFOs, present during movement onset in the cerebral cortex of animals<sup><xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c35">35</xref></sup> and humans<sup><xref ref-type="bibr" rid="c36">36</xref>–<xref ref-type="bibr" rid="c38">38</xref></sup>, encode information about movement trajectories and velocity<sup><xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c35">35</xref></sup>. They also contain information related to movement timing<sup><xref ref-type="bibr" rid="c39">39</xref>–<xref ref-type="bibr" rid="c41">41</xref></sup>, preparation<sup><xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup>, sensorimotor integration<sup><xref ref-type="bibr" rid="c37">37</xref></sup>, kinematics<sup><xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup> and may contribute to the precise temporal coordination of movements required for sequencing<sup><xref ref-type="bibr" rid="c44">44</xref></sup>. Within clinical contexts, LFOs in the frontoparietal regions that were the main contributors to decoding performance in the present study are related to recovery of motor function after brain lesions like stroke<sup><xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c39">39</xref>,<xref ref-type="bibr" rid="c45">45</xref>,<xref ref-type="bibr" rid="c46">46</xref></sup>. Our results, in conjunction with those discussed above, suggest that LFOs contain crucial information relevant to decoding of sequence-embedded skill actions.</p>
</sec>
<sec id="s3b">
<title>Neural representations of individual sequence actions are contextualized during early skill learning</title>
<p>Previous work decoded actions from human neural activity when performed in isolation (e.g. individuated finger movement decoding)<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c26">26</xref>,<xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c47">47</xref>–<xref ref-type="bibr" rid="c50">50</xref></sup> or embedded within previously learned sequences<sup><xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c51">51</xref></sup> near stable upper performance limits. To our knowledge, decoding of individual sequence-embedded actions has not been either attempted or reported within the context of rapid performance improvements that characterize early skill learning. We addressed this gap in knowledge by investigating different decoding strategies and identified the approach that rendered the best decoding performance, which in this case was approximately 94% (5-class hybrid-space decoder). We then applied this strategy to investigate neural representations of sequential individual finger movements during the skill learning task. We found that improved 5-class decoding accuracy was linked to trial-by-trial increases in the differentiation between index finger keypresses embedded within the sequence at two different locations throughout early learning (<xref rid="fig4" ref-type="fig">Figure 4C</xref>), which occurred in parallel to skill performance improvements. Feature importance scores are initially led by the pre-central cortex during early learning followed by an intermediate shift towards post-central cortex by trial 11, which is consistent with the known role of the sensorimotor cortex in early skill acquisition<sup><xref ref-type="bibr" rid="c6">6</xref></sup>. Concurrently, the superior frontal and then middle frontal cortex continue to increase in importance over the Day 1 Training session and represent the two most important features between trials 15 and 36 after the rapid initial performance gains stabilize. This is consistent with previous findings that activity patterns within these regions represent hierarchical structures of skill sequences<sup><xref ref-type="bibr" rid="c10">10</xref></sup>.</p>
<p>Neural representations are modified by experience and practice<sup><xref ref-type="bibr" rid="c32">32</xref></sup>. For example, FMRI studies showed that weeks-long practice of a keyboard task results in representational changes of the skill (finger sequence), but not of the individual sequence actions components (individual finger movements) in the primary motor cortex<sup><xref ref-type="bibr" rid="c10">10</xref></sup>. An MEG study showed that previously learned individual sequence-embedded action (i.e. – finger movement) representations display an ordered queuing gradient when preparing to generate a previously learned sequence<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. Thus, representations of previously learned skills following prolonged practice over days and weeks appear to reflect some combination of invariant features of individual action components with higher order representations of the action sequence.</p>
<p>Less is known about changes in neural representations during rapid performance improvements that characterize early skill learning. MEG, which possesses millisecond temporal resolution, is the tool of choice to investigate this short early learning phase<sup><xref ref-type="bibr" rid="c52">52</xref></sup>. In the present study, we leveraged this feature of MEG to investigate if the representation of the same sequence action (index finger movement) differentiates over early learning when embedded at different ordinal locations within the sequence. We found that practice led to a progressive differentiation of the neural representation of index finger movements reflecting the different contextual positions within the sequence. The finding that the magnitude of representational differentiation predicts skill gains supports the view that contextualization of neural representations contributes to early learning. Further support for this view comes from the finding that adding context information to the decoding algorithm increased decoding accuracy to levels higher than previously reported<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c26">26</xref>–<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c47">47</xref>–<xref ref-type="bibr" rid="c51">51</xref></sup>. A possible neural mechanism supporting contextualization could be the emergence of conjunctive “what–where” representations of procedural memories<sup><xref ref-type="bibr" rid="c53">53</xref></sup> with the corresponding modulation of neuronal population dynamics<sup><xref ref-type="bibr" rid="c54">54</xref>,<xref ref-type="bibr" rid="c55">55</xref></sup>.</p>
</sec>
<sec id="s3c">
<title>Representational contextualization developed predominantly during rest periods of early learning</title>
<p>Representational contextualization developed to a larger extent during rest than during practice intervals. Furthermore, the magnitude of offline contextualization predicted skill gains while online contextualization did not. These findings are in line with previous work showing that most skill gains during early learning develop during rest rather than during practice intervals<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c56">56</xref></sup> and suggest that contextualization of action representations could contribute to rapid consolidation of skill. Importantly, contextualization of the learned sequence was retained the following day indicating the stability of the formed skill memory.</p>
</sec>
<sec id="s3d">
<title>Limitations</title>
<p>One limitation of this study is that contextualization was investigated for only one finger movement (index finger or digit 4) embedded within a relatively short 5-item skill sequence. It would be useful to determine if representational contextualization of multiple finger movements embedded within longer sequences (e.g. – a short piece of piano music) also exhibit similar results. While a supervised manifold learning approach was used here (LDA), unsupervised approaches (PCA and MDS) more suitable for BCI applications, also substantially improved decoding accuracy that can be used for real-time BCI applications (<xref rid="figs4" ref-type="fig">Figure 3 – figure supplement 2</xref>)</p>
</sec>
<sec id="s3e">
<title>Summary</title>
<p>In summary, individual sequence action representations contextualize during the initial practice trials of a new skill and the degree of differentiation parallels skill gains. Importantly, the neural representation of context develops to a larger extent during rest than during practice intervals of early learning in parallel with rapid consolidation of skill. It is possible that the systematic inclusion of contextualized information into sequence skill practice environments could improve learning in areas as diverse as music education, sports training, and rehabilitation of motor skills after brain lesions.</p>
</sec>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title>Study Participants</title>
<p>The study was approved by the Combined Neuroscience Institutional Review Board of the National Institutes of Health (NIH). A total of thirty-three young and healthy adults (comprising 16 females) with a mean age of 26.6 years (± 0.87 SEM) participated in the study after providing written informed consent and undergoing a standard neurological examination. No participants were actively engaged in playing musical instruments in their daily lives, as per guidelines outlined in prior research<sup><xref ref-type="bibr" rid="c57">57</xref>,<xref ref-type="bibr" rid="c58">58</xref></sup>. All study scientific data were de-identified, and permanently unlinked from all personal identifiable information (PII) before the analysis. These data are publicly available upon request (<ext-link ext-link-type="uri" xlink:href="https://nih.box.com/v/hcpsSkillLearningData">https://nih.box.com/v/hcpsSkillLearningData</ext-link>). Two participants were excluded from the analysis due to MEG system malfunction during data acquisition. An additional 5 subjects were excluded where no comparable correct sequences were generated for two or more consecutive trials. The sample size was pre-determined through a power analysis designed to characterize skill learning<sup><xref ref-type="bibr" rid="c1">1</xref></sup>.</p>
</sec>
<sec id="s4b">
<title>Experimental Setup</title>
<p>Participants practiced a novel procedural motor skill learning task that involved repetitively typing a 5-item numerical sequence (4-1-3-2-4) displayed on a computer screen. They were instructed to perform the task as quickly and accurately as possible using their non-dominant, left hand on a response pad (Cedrus LS-LINE, Cedrus Corp). Each numbered sequence item corresponded to a specific finger keypress: 1 for a little finger keypress, 2 for a ring finger keypress, 3 for a middle finger keypress, and 4 for an index finger keypress. Individual keypress times and identities were recorded and used to assess skill learning and performance.</p>
<p>Participants practiced the skill for 36 trials. Each trial spanned a total of 20 seconds and included a 10s practice round followed by a 10s inter-practice rest period. The five-item sequence was displayed on the computer screen for the duration of each practice round and participants were directed to fix their gaze on the sequence. Small asterisks were displayed above a sequence item after each successive keypress, signaling the participants’ present position within the sequence. Following the completion of a full sequence iteration, the asterisks were removed. The asterisk display did not provide error feedback as it appeared for both correct and incorrect keypresses. At the end of each practice round, the displayed number sequence was replaced by a string of five “X” symbols displayed on the computer screen, which remained for the duration of the inter-practice rest period. Participants were instructed to focus their gaze on the screen during this time.</p>
<p>On the next day, participants were tested (<italic>Day 2 Retest</italic>) with the same trained sequence (4-1-3-2-4) for 9 trials as well as for 9 different unpracticed control sequences (<italic>Day 2 Control</italic>; 2-1-3-4-2; 4-2-4-3-1; 3-4-2-3-1; 1-4-3-4-2; 3-2-4-3-1; 1-4-2-3-1; 3-2-4-2-1; 2-3-1-4-2; 4-2-3-1-4) each for one trial. The practice schedule structure for Day 2 was same as Day 1, with 10s practice trials interleaved with 10s of rest.</p>
</sec>
<sec id="s4c">
<title>Behavioral data analysis</title>
<sec id="s4c1">
<title>Skill</title>
<p>Skill, in the context of the present task, is quantified as the <italic>correct sequence typing speed</italic>, (ie. - the number of correctly typed sequence keypresses per second; kp/s). That is, improvements in the speed/accuracy trade-off equate to greater skill. Keypress transition times (KTT) were calculated as the difference in time between the KeyDown events recorded for consecutive keypresses. Since the sequence was repeatedly typed within a single trial, individual keypresses were marked as correct if they were members of a 5 consecutive keypress set that matched any possible circular shift of the displayed 5-item sequence. The instantaneous correct sequence speed was calculated as the inverse of the average KTT across a single correct sequence iteration and was updated for each correct keypress. Trial-by-trial skill changes were assessed by computing the median correct sequence typing speed for each trial.</p>
</sec>
<sec id="s4c2">
<title>Early Learning</title>
<p>The <italic>early learning</italic> period was defined as the trial range (1 - T trials) over which 95% of the total skill performance was first attained at the group level. We quantified this by fitting the group average trial-by-trial correct sequence speed data with an exponential model of the form:
<disp-formula>
<graphic xlink:href="608189v1_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here, the trial number is denoted by <italic>t</italic>, and <italic>L(t)</italic> signifies the group-averaged performance at trial <italic>t</italic>. Parameters <italic>C1</italic> and <italic>C2</italic> correspond to the pre-training performance baseline and asymptote, respectively, while <italic>k</italic> denotes the learning rate. The values for <italic>C1</italic>, <italic>C2</italic>, and <italic>k</italic> were computed using a constrained nonlinear least-squares method (MATLAB’s lsqcurvefit function, trust-region-reflective algorithm) and were determined to be 0.5, 0.15, and 0.2, respectively. The early learning trial cut-off, denoted as <italic>T</italic>, was identified as the first trial where 95% of the learning had been achieved. In this study, <italic>T</italic> was determined to be trial 11.</p>
<p>Performance improvements during rest (<italic>micro-offline gains),</italic> for each rest period of a trial, were calculated as the net change in performance (instantaneous correct sequence typing speed) from the end of one practice period to the onset of the next (i.e. – over a single inter-practice rest period). <italic>Micro-online gains</italic> (performance improvements during practice periods) were computed as the change in performance between the beginning and end of a single practice trial. Total early learning was derived as the sum of all <italic>micro-online</italic> and <italic>micro-offline</italic> gains over trials 1-11. Cumulative micro-offline gains, micro-online gains, and total early learning were statistically compared using 1-way ANOVAs and post-hoc Tukey tests.</p>
</sec>
</sec>
<sec id="s4d">
<title>MRI Acquisition</title>
<p>We acquired T1-weighted high-resolution anatomical MRI volumes images (1 mm<sup>3</sup> isotropic MPRAGE sequence) for each participant on a 3T MRI scanner (GE Excite HDxt or Siemens Skyra) equipped with a 32-channel head coil. These data allowed for spatial co-registration of an individual participant’s brain with the MEG sensors, and individual head models required for surface-based cortical dipole estimation from MEG signals (i.e. – MEG source-space modeling).</p>
</sec>
<sec id="s4e">
<title>MEG Acquisition</title>
<p>We recorded continuous magnetoencephalography (MEG) at a sampling frequency of 600 Hz using a CTF 275 MEG system (CTF Systems, Inc., Canada) while participants were seated in an upright position. The MEG system comprises a whole-head array featuring 275 radial 1<sup>st</sup>-order gradiometer/SQUID channels housed in a magnetically shielded room (Vacuumschmelze, Germany). Three of the gradiometers (two non-functional and one with high channel noise after visual inspection) were excluded from the analysis resulting in a total of 272 MEG channels for analysis. Synthetic 3<sup>rd</sup> order gradient balancing was applied to eliminate background noise in real-time data collection. Temporal alignment of behavioral and MEG data was achieved using a TTL trigger. Head position in the scanner coordinate space was monitored using head localization coils at the nasion, left, and right pre-auricular locations. These fiducial positions were co-registered in the participants’ T1-MRI coordinate space using a stereotactic neuronavigation system (BrainSight, Rogue Research Inc.). MEG data was acquired starting 6 min before the task (resting-state baseline) and continued through the end of the 12 min training session.</p>
</sec>
<sec id="s4f">
<title>MEG Data Analysis</title>
<sec id="s4f1">
<title>Preprocessing</title>
<p>MEG data were preprocessed using the FieldTrip<sup><xref ref-type="bibr" rid="c59">59</xref></sup> and EEGLAB<sup><xref ref-type="bibr" rid="c60">60</xref></sup> toolboxes on MATLAB 2022a. Continuous raw MEG data (acquired at 600 Hz) were band pass filtered between 1-100 Hz with a 4<sup>th</sup> order noncausal Butterworth filter. 60 Hz line noise was removed with a narrow-band discrete Fourier transform (DFT) notch filter. Independent component analysis (ICA) was used to remove typical MEG signal artifacts related to eye blinks or movement or cardiac pulsation. All recordings were visually inspected and marked to denoise segments containing other large amplitude artifacts due to movements.</p>
</sec>
<sec id="s4f2">
<title>Source Reconstruction and Parcellation</title>
<p>For each participant, individual volume conduction models were established to depict the propagation of brain-generated currents through tissue to externally measurable magnetic fields. This was accomplished through a single-shell head corrected-sphere approach based on the brain volume segmentation of their high-resolution T1 MRI. Source models and surface labels from the Desikan-Killiany Atlas<sup><xref ref-type="bibr" rid="c14">14</xref></sup> were created for each participant using inner-skull and pial layer surfaces obtained through FreeSurfer segmentation and connectome-workbench. Aligning sensor positions in the MEG helmet to individual head space involved warping MEG head coil positions (mean of pre and post recording) to the fiducials of the MRI, applying the same transformation matrix to all MEG sensors.</p>
<p>The individual source, volume conduction model, and sensor positions were then utilized to generate the forward solution at each source dipole location, describing the propagation of source activity from each cortical location on the grid to each MEG sensor. The Linearly Constrained Minimum-Variance (LCMV) beamformer was employed for computing the inverse solution. Each trial of MEG activity contributed to calculating the inverse solution data covariance matrix. The individual sample noise covariance matrix was derived from 6 minutes of pre-training rest MEG data recorded in the same subject during the same session. A total of 15,684 surface-based cortical dipoles (source-space voxels) were estimated. Cortical parcellation involved averaging the time series of all source dipoles within a distinct anatomical boundary defined in the Desikan-Killiany Atlas. To prevent within-parcel source cancellation during averaging, a technique called mean-flipping was applied. This process entailed flipping the sign for all sources with a sign differing from that of the average source.</p>
</sec>
</sec>
<sec id="s4g">
<title>Feature Selection for Decoding</title>
<p>Features were extracted from the MEG activity at several spatial, oscillatory, and temporal scales.</p>
<sec id="s4g1">
<title>Oscillatory Analysis</title>
<p>MEG signals were band limited to broadband (1-100 Hz) and to classic neural oscillatory frequencies defined as delta (1 – 3 Hz), theta (4 – 7 Hz), alpha (8 – 15 Hz), beta (16 – 24 Hz), gamma (25 – 50 Hz), and high-gamma (51 – 100 Hz) with a 4<sup>th</sup> order non-causal Butterworth filter. The decoding analysis was conducted independently for each band of MEG activity.</p>
</sec>
<sec id="s4g2">
<title>Spatial Analysis</title>
<p>Decoding was performed at sensor space as well as at source space. For sensor space decoding the feature dimension was 272 (corresponding to the 272 gradiometer channels). At the source space, decoding was executed at both the high-resolution voxel and low-resolution parcel space. The feature dimension for voxel-space decoding was 15,684, representing the total number of independently estimated cortical dipoles. For parcel-space decoding, the feature dimension was 148, derived from spatially averaging the voxel activities within each parcel defined by the Desikan-Killiany Atlas. In both cases, decoding was carried out across all oscillatory frequency bands (i.e. - broadband, delta, theta, alpha, beta, gamma, and high-gamma) for comprehensive comparison.</p>
</sec>
<sec id="s4g3">
<title>Temporal Analysis</title>
<p>Temporal MEG activity corresponding to each keypress was defined by taking a time window of [ t + Δt], where t ∈ [0 : 10 ms : 100 ms] and Δt ∈ [25 ms : 25 ms : 350 ms]. In other words, a sliding window of variable size (from 25 ms to 350 ms with 25 ms increments) sliding from onset until the start of the window reached 100 ms post onset (with increments of 10s) was used. This approach generated 140 different temporal windows for each keypress for each participant. Average MEG activity from each of these time widows were analyzed independently for decoding. The best time window was selected for each subject that resulted in best cross-validation performance. This temporally sliding and varying size window analysis was performed at each of the spatial and oscillatory scales.</p>
</sec>
<sec id="s4g4">
<title>Hybrid Spatial Approach</title>
<p>First, we evaluated the decoding performance of each brain region in decoding finger identity. We trained decoders on the voxel activities of each region (intra-parcel decoders) to predict finger identity. Brain regions were then ranked from 1 to 148 based on their decoding accuracy at the group level. In a stepwise manner, we incrementally incorporated voxel activities of brain regions, starting from the top-ranked region. In other words, first, we concatenated the voxel-level features of the highest-ranked region with whole-brain parcel-level features for decoding analysis. Subsequently, we added the voxel-level features of the second-ranked brain region, along with those of the top-ranked region to the parcel-level features for decoding and continued this process. This iterative addition of brain regions was performed until decoding accuracy reached saturation. The optimal feature space comprised all 148 parcel-space features in conjunction with voxel-space features from the top 8 brain regions.</p>
</sec>
<sec id="s4g5">
<title>Dimension Reduction</title>
<p>We used several supervised and unsupervised dimension reduction techniques including linear discriminant analysis (LDA), minimum redundant maximum relevance (MRMR), principal component analysis (PCA), Autoencoder, Diffusion maps, factor analysis, large margin nearest neighbor (LMNN), multi-dimensional scaling (MDS), neighbor component analysis (NCA), spatial predictor envelope (SPE)<sup><xref ref-type="bibr" rid="c15">15</xref></sup> on each of the spatial feature space (sensor, parcel, voxel, and hybrid). Among these techniques, PCA, MDS, MRMR, and LDA emerged as particularly effective in significantly improving decoding performance.</p>
<p>PCA, a method for unsupervised dimensionality reduction, transformed the high-dimensional dataset into a new coordinate system of uncorrelated principal components. These components, capturing the maximum variance in the data, were iteratively added to reconstruct the feature space and execution of decoding. MDS finds a configuration of points in a lower-dimensional space such that the distances between these points reflect the dissimilarities or similarities between the corresponding objects in the original high-dimensional space. MRMR, an approach combining relevance and redundancy metrics, ranked features based on their significance to the target variable and their non-redundancy with other features. The decoding process involved starting with the highest-ranked feature and iteratively incorporating subsequent features until decoding accuracy reached saturation. LDA finds the linear combinations of features (dimensions) that best separate different classes in a dataset. It projects the original features onto a lower-dimensional space (number of classes −1) while preserving the class-discriminatory information. This transformation maximizes the ratio of the between-class variance to the within-class variance. In our study, LDA transformed the features to a 3-dimensional hyperdimensional space that were used for decoding. Dimension reduction was applied to train data and then with the tuned parameters of the dimension reduction model test data was transformed for decoder metrics evaluation. Decoding accuracies were systematically compared between the original and reduced dimension feature spaces, providing insights into the effectiveness of each dimension reduction technique. By rigorously assessing the impact of dimension reduction on decoding accuracy, the study aimed to identify techniques that not only reduced the computational burden associated with high-dimensional data but also enhanced the discriminative power of the selected features. This comprehensive approach aimed at optimizing the neural representation of each finger keypress for decoding performance across various spatial contexts.</p>
</sec>
</sec>
<sec id="s4h">
<title>Decoding Analysis</title>
<p>Decoding analysis was conducted for each participant individually, employing a randomized split of the data into training (90%) and test (10%) samples for 8 iterations. For each iteration, to optimize decoder configuration, an 8-fold cross-validation was applied to the training samples, allowing for the fine-tuning of hyperparameters and selection of the most effective model. Across participants, on average, the total number of individual keypresses for the whole duration of training was 219 ± SD: 66 (keypress 1: little), 205 ± SD: 66 (keypress 2: ring), 209 ± 66 (keypress 3: middle), and 426 ± SD: 131 (keypress 4: index). Only keypresses belonging to correctly typed sequence iterations (94.64% ± 4.04% of all keypresses) were considered. The total number of keypresses for keypress 4 was approximately twice that of keypresses 1, 2, and 3, as it was the only action that occurred more than once in the trained sequence (4-1-3-2-4), albeit in two different sequence contexts or ordinal positions. Considering the higher (2x) number of samples for one-class, we independently oversampled the keypresses 1, 2 and 3 to avoid overfitting to the over-represented class. Importantly, oversampling was applied independently for each keypress class, ensuring that validation folds were never oversampled, and training folds did not share common oversampled patterns. The decoder configuration demonstrating the best validation performance was selected for each iteration, and subsequently, test accuracy was evaluated on the independent/unseen test samples. This process was repeated for the 8 different iterations of train-test splitting and the average test accuracy was reported. This rigorous methodology aimed at generalizing decoding performance to ensure robust and reliable results across participants. Further, decoding evaluation was performed on the Day 2 data, for both the trained (<italic>Day 2 Retest;</italic> 9 trials) and untrained sequences (<italic>Day 2 Control</italic>; 9 different single-trial tests).</p>
<sec id="s4h1">
<title>Machine Learning Classifiers</title>
<p>We employed a diverse set of machine learning decoders, including Naïve Bayes (NB), decision trees (DT), ensembles (EN), k-nearest neighbor (KNN), linear discriminant analysis (LDA), support vector machines (SVM), and artificial neural network (ANN), to train features generated with all possible combinations of spatial, temporal, and oscillatory scales for comprehensive comparative analysis. The hyperparameters of these decoders underwent fine-tuning using Bayesian optimization search.</p>
<p>The Naive Bayes classifier was configured with a normal distribution predictor and Gaussian Kernel, while the KNN classifier had a K value of 4 (for keypress decoding) and utilized the Euclidean distance metric. For decision trees, the maximum number of splits was set to 4 (for keypress decoding), with leaves being merged based on the sum of risk values greater or equal to the risk associated with the parent node. The optimal sequence of pruned trees was estimated, and the predictor selection method was ‘Standard CART,’ selecting the split predictor that maximizes the split-criterion gain over all possible splits of all predictors. The split criterion used was ‘gdi’ (Gini’s diversity index). Ensembles employed the bagging method with random predictor selections at each split, forming a random forest. The maximum number of learning cycles was set to 100 with a weak learner based on discriminant analysis. For SVM, the RBF kernel was selected through cross-validation (CV), and the ‘C’ parameter and kernel scale were optimized using Bayesian optimization search. In the case of LDA, the linear coefficient threshold and the amount of regularization were computed based on Bayesian optimization search. The ANN decoder consisted of one hidden layer with 128 nodes, followed by a sigmoid and a softmax layer, each with 4 nodes (for keypress decoding). Training utilized a scaled conjugate gradient optimizer with backpropagation, employing a learning rate of 0.01 (coarse to fine tuning) for a maximum of 100 epochs, with early stopping validation patience set to 6 epochs.</p>
<p>Additionally, we assessed long short-term memory recurrent neural networks (LSTM-RNN) and bidirectional LSTM-RNN to train the time series of each keypress for decoding. The configuration of these RNNs included two hidden (Bi)LSTM layers of 100 units, followed by three fully connected layers (50, 10, and 4), and a softmax layer with 4 nodes to decode the four keypress classes. The networks were trained using an Adam optimizer with an initial learning rate of 0.001, a learning rate drop factor of 0.1 after 20 epochs, and a maximum epoch of 400. For regularization, 20% dropouts after the (Bi)LSTM layers, 50% dropout after the fully connected layers, and L2 Norm with a gradient threshold value of 0.1 were employed. These hyperparameter values were chosen based on grid search optimization during cross-validation.</p>
</sec>
<sec id="s4h2">
<title>Decoding Performance Metrics</title>
<p>Decoding performance was assessed using several metrics, including accuracy (%), which indicates the proportion of correct classifications among all test samples. The confusion matrix provided a detailed comparison of the number of correctly predicted samples for each class against the ground truth. The F1 score for each keypress was utilized as a comprehensive metric, combining precision and recall scores. This score represents the predictive skill of the decoders by offering insights into their class-wise performance. Additionally, the weighted mean F1 score was computed to convey the overall predictive skill of the models across all classes. This metric is derived from a weighted average of the F1 scores for each class, providing a comprehensive evaluation of the models’ performance. Test accuracies were used for statistical comparisons.</p>
</sec>
<sec id="s4h3">
<title>Decoding During Skill Learning Progression</title>
<p>We systematically assessed decoding performance of the 2-class decoder (Index<sub>OP1</sub> vs Index<sub>OP5</sub>) at each trial during the skill learning process to identify the relationship between the evolution of decoding proficiency and the acquired skill. Our approach involved evaluating decoder performance individually for each <italic>Day 1 Training</italic> trial. To mitigate the influence of varying sample sizes in later trials, we ensured an equal number of samples (first k keypresses) in each trial.</p>
<p>We used t-distributed stochastic neighborhood estimation (t-SNE) to visualize the evolution of neural representations corresponding to each keypress at each trial of the learning period. Further, within t-SNE distribution, we separately labeled the keypress 4 based on their context (i.e., keypress 4 at ordinal position 1: Index<sub>OP1</sub> and keypress 4 at ordinal position 5: Index<sub>OP5</sub>). Brain regions important to decoding were determined for each trial based on MRMR based feature ranking and highlighted in topography plots.</p>
</sec>
<sec id="s4h4">
<title>Decoding Sequence Elements</title>
<p>Finally, we performed decoding of each contextual action of the sequence (i.e., Index<sub>OP1</sub>, Little, Middle, Ring, and Index<sub>OP5</sub>). We used the same decoding strategy (90%-10% split for train and test, 8-fold cross validation of training samples to select best decoder configuration, hybrid spatial features, and LDA based dimension reduction) to decode these 5-classes. Note, oversampling was not needed after sub-grouping the index finger keypresses into two separate classes based on their context. Decoding sequence elements were evaluated for both <italic>Day 1 Training</italic>, <italic>Day 2 Retest</italic> and <italic>Day 2 Control</italic> data.</p>
</sec>
</sec>
<sec id="s4i">
<title>Neural Representation analysis</title>
<p>We evaluated the <italic>online</italic> (within-trial) and <italic>offline</italic> (between-trial) changes in the neural representation of the contextual actions (Index<sub>OP1</sub> and Index<sub>OP5</sub>) for each trial during training. For offline differentiation, we evaluated the Euclidian distance between the hybrid spatial features of the last index finger keypress of a trial (Index<sub>OP5</sub>) to the first index finger keypress (Index<sub>OP1</sub>) of the subsequent trial, mirroring the approach used to calculate micro-offline gains in skill. This offline distance provided insights on the net change in contextual representation of the index finger keypress during each interspersed rest interval. For online differentiation, we calculated the mean Euclidian distance between Index<sub>OP1</sub> and Index<sub>OP5</sub> of all the correctly typed sequences within a practice trial. Online differentiation informed on the net change in the contextual representation of the index finger keypress within each practice trial. Cumulative offline and online representation distances across participants were compared using 2-sample <italic>t</italic>-tests. Additionally, we computed trial-by-trial differences in offline and online representations during early learning, exploring their relationships with cumulative micro-offline and micro-online gains in skill, respectively, through regression analysis and Pearson correlation analysis. Linear regression models were trained utilizing the <italic>fitlm</italic> function in MATLAB. The model employed M-estimation, formulating estimating equations and solving them through the Iteratively Reweighted Least Squares (IRLS) method<sup><xref ref-type="bibr" rid="c61">61</xref></sup>. Key metrics such as the square root of the mean squared error (RMSE), which estimates the standard deviation of the prediction error distribution, the coefficient of explained variance (R<sup>2</sup>), the F-statistic as a test statistic for the F-test on the regression model, examining whether the model significantly outperforms a degenerate model consisting only of a constant term, and the <italic>p</italic>-value for the F-test on the model were computed and compared across different models. This multifaceted approach aimed to uncover the nuanced dynamics of neural representation changes in response to skill acquisition.</p>
<p>As a control analysis, we also computed the difference in neural representation between Index<sub>OP1</sub> and Index<sub>OP5</sub> on <italic>Day 2 Retest</italic> data for the same sequence (<bold>4</bold>-1-3-2-<bold>4</bold>) as well as for different <italic>Day 2 Control</italic> untrained sequences where the same action was performed at ordinal positions 1 and 5 (<bold>2</bold>-1-3-4-<bold>2</bold>; <bold>1</bold>-4-2-3-<bold>1</bold>; <bold>2</bold>-3-1-4-<bold>2</bold>; <bold>4</bold>-2-3-1-<bold>4</bold>). Finally, we assessed for specificity of contextualization to the trained sequence, by evaluating differentiation between index finger keypress representations performed at two different positions within untrained sequences (<bold>4</bold>-2-<bold>4</bold>-3-1 and 1-<bold>4</bold>-3-<bold>4</bold>-2). The cumulative differences across participants were compared with 2-sample <italic>t</italic>-tests.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5" sec-type="data-availability">
<title>Data Availability</title>
<p>All de-identified and permanently unlinked from all personal identifiable information (PII) data are publicly available. (<underline>Box Repository</underline>).</p>
</sec>
<ack>
<title>Acknowledgments</title>
<p>We thank Ms. Tasneem Malik, Ms. Michele Richman, and NIMH MEG Core Facility staff for their support. This work utilized the computational resources of the NIH HPC Biowulf cluster (<ext-link ext-link-type="uri" xlink:href="http://hpc.nih.gov">http://hpc.nih.gov</ext-link>). This research was supported by the Intramural Research Program of the NINDS, NIH.</p>
</ack>
<sec id="d1e3376">
<title>Supplementary materials</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Fig 1 – figure supplement 1:</label>
<caption><title>Behavioral performance during skill learning</title>
<p><bold><italic>A. Total Skill Learning over Day 1 Training (36 trials) and Day 2 Retest (9 trials).</italic></bold> As reported previously<sup><xref ref-type="bibr" rid="c1">1</xref></sup>, participants on average reached 95% of peak performance during <italic>Day 1 Training</italic> by trial 11. Note that after trial 11 performance stabilizes around a plateau through trial 36. Following a 24-hour break, participants displayed an upward shift in performance during the <italic>Day 2 Retest</italic> – indicative of an overnight skill consolidation effect. <bold><italic>B. Keypress transition time (KTT) variability</italic></bold>. Distribution of KTTs normalized to the median correct sequence time for each participant and centered on the mid-point for each full sequence iteration during early learning. Note the initial variability of the five component transitions in the sequence (i.e. – 4-1, 1-3, 3-2, 2-4, 4-4), stabilize by trial 6 in the early learning period and remain stable throughout the rest of <italic>Day 1 Training</italic> (through trial 36) and <italic>Day 2 Retest</italic>.</p></caption>
<graphic xlink:href="608189v1_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2 – figure supplement 1:</label>
<caption><title>Oscillatory contributions at individual brain regions</title>
<p>Decoding performance of each individual brain region (intra-parcel decoder performance) at each oscillatory level is shown for both left and right hemisphere as a heatmap. Optimal decoding performances were obtained from bilateral superior frontal (Left: 68.77% ± SD 7.6%; Right: 67.52% % ± SD 6.78%), middle frontal (Left: 63.41% ± SD 7.58%; Right: 62.78% % ± SD 76.94%), pre-central (Left: 62.37% % ± SD 6.32%; Right: 62.69% ± SD 5.94%), and post-central (Left: 61.71% ± SD 6.62%; Right: 61.09% ± SD 6.2%) brain regions. Superior parietal, central, paracentral, anterior-cingulate, and precuneus regions also showed greater (&gt; 60%) decoding performance. For Delta band, only superior frontal regions showed &gt; 60% decoding performance.</p></caption>
<graphic xlink:href="608189v1_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3—figure supplement 1:</label>
<caption><title>Contribution of whole-brain oscillatory frequencies to decoding</title>
<p>Accuracy was highest when decoders were trained on broadband activity, closely followed by delta band activity, across whole-brain -parcel, -voxel, and -hybrid space. Sensor-space decoder accuracy did not differ statistically when trained on either broadband or delta-band activity. Hybrid approach resulted in best decoding accuracy for each frequency range. Interestingly, accuracy with sensor space decoders was comparable to accuracy with parcel and voxel space decoders. Dots depict decoding accuracy for each participant. “<bold>***</bold>” indicates <italic>p</italic> &lt; 0.001, “<bold>**</bold>” indicates <italic>p</italic> &lt; 0.01, and “<bold>n.s.</bold>” denotes no statistical significance (i.e. - <italic>p</italic> &gt; 0.05).</p></caption>
<graphic xlink:href="608189v1_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3 – figure supplement 2:</label>
<caption><title>Comparison of different dimensionality reduction techniques</title>
<p>Dimensionality reduction was applied to the input features for each approach [parcel (N=148)/voxel(N=15684)/hybrid(N=1295)] [16]. The results with principal component analysis (PCA, in green), multi-dimensional scaling (MDS, in blue), minimum redundant maximum relevance algorithm (MRMR, in red), linear discriminant analysis (LDA, in black) are shown in comparison to performance obtained using all input features (in magenta). For parcel space, all these approaches increased the mean decoding accuracy with PCA and LDA showing statistically significant improvement [1-way ANOVA: F= 13.05, <italic>p</italic> &lt; 0.001; post hoc Tukey tests: <italic>p</italic> =0.032 (PCA), <italic>p</italic> &lt; 0.001 (LDA), <italic>p</italic> &gt; 0.05 (MDS, MRMR)]. At the voxel space, there was no statistically significant improvement with either of the approaches (<italic>p</italic> &gt; 0.05). MRMR showed the highest improvement but not statistically significant with post hoc Tukey tests (<italic>p</italic> = 0.14). With LDA the performance dropped significantly. For hybrid space, all the dimensionality reduction techniques were significant in improving decoding performance [1-way ANOVA: F= 21.32, post hoc Tukey tests: <italic>p</italic> &lt; 0.05] and the best improvement was seen with LDA.</p></caption>
<graphic xlink:href="608189v1_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3 – figure supplement 3:</label>
<caption><title>Confusion matrices for decoding performance on Day 2 Retest (A) and Day 2 Control (B) data</title>
<p>Note that, the hybrid decoding strategy generalized to Day 2 data with 87.11% keypress decoding accuracy for the trained sequence (Day 2 Retest) and 79.44% accuracy for decoding keypresses embedded within untrained control sequences (Day 2 Control).</p></caption>
<graphic xlink:href="608189v1_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4 – figure supplement 1:</label>
<caption><title>Quantification of regional trial-by-trial feature importance score during skill learning</title>
<p>The quantification of regional importance in decoding for each trial is shown for the regions that showed highest decoding accuracy, i.e., superior frontal, middle frontal, pre-central, and post-central cortex. Please note that, the feature importance score was higher for pre-central cortex which shifted to middle frontal cortex during later trials, as can be seen with the divergence of line plots about trial 11.</p></caption>
<graphic xlink:href="608189v1_figs6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4 – figure supplement 2:</label>
<caption><p>Average decoding accuracies across participants with varying temporal scales. X-axis represents the onset of window for decoding analysis with respect to keypress onset (0). Y-axis represents the window size. The heatmap color denotes the decoding accuracy for all window size/location pairings. Note that, the best decoding accuracy across subjects is obtained by taking a window starting from 0 (i.e., onset of keypress) with a window size of 200ms.</p></caption>
<graphic xlink:href="608189v1_figs7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5. figure supplement 1.</label>
<caption><title>Relationship between offline contextualization of neural representations and micro-offline learning</title>
<p>Cumulative micro-offline gains, i.e., the net gain in skill during inter-practice rest periods increased over time during early learning. Offline representation difference, i.e., the net change in the neural representations of keypress 4 over the inter-practice rest intervals between different ordinal positions in the sequence (context) increased over time during early learning. A linear regression analysis showed a strong temporal relationship (correlation coefficient (<italic>r</italic>) = 0.9034 and coefficient of variance explained (R<sup>2</sup>) = 0.82) between amount of contextualization during rest and cumulative micro-offline gains during rest, signifying the effect of contextualization in sequential skill learning.</p></caption>
<graphic xlink:href="608189v1_figs8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5 – figure supplement 2:</label>
<caption><p>Online versus offline changes in keypress transition patterns. A. Trial-by-trial Euclidian distance between keypress transition patterns (i.e. – relative share of each keypress transition across the full sequence duration) for the first and last sequence iteration within a single trial (online; green) and last sequence iteration of the current trial versus the first sequence iteration of the subsequent trial (offline; magenta). B. Cumulative online (green; left) and offline (magenta; right) pattern distances recorded over all forty-five trials covering Days 1 and 2. Note that cumulative online and offline distances are not significantly different (t=-0.03, <italic>p</italic> = 0.976).</p></caption>
<graphic xlink:href="608189v1_figs9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5 – figure supplement 3:</label>
<caption><title>Relationship between contextualization and absolute speed</title>
<p><italic>A. Relationship between maximum speed and corresponding contextualization:</italic> The maximum typing speed and the degree of contextualization was related using a linear regression analysis that showed no significant relationship between maximum typing speed and degree of contextualization (R<sup>2</sup> = 0.028, <italic>p</italic> = 0.41). Here, each dot represents the maximum speed attained and the corresponding degree of contextualization of each participant. Thus, people with higher typing speed did not show higher degree of contextualization. <italic>B. Relationship between typing speed and degree of contextualization at each trial.</italic> We performed a regression analysis for each trial to relate the degree of contextualization at each trial and the typing speed at that trial. The violin plot represents the distribution of R<sup>2</sup> values obtained with regression analysis and here each dot represents a trial. Note that, there was no significant relationship at any trial (mean R<sup>2</sup> = 0.06; <italic>p</italic> &gt; 0.05).</p></caption>
<graphic xlink:href="608189v1_figs10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bönstrup</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A rapid form of offline consolidation in skill learning</article-title>. <source>Current Biology</source> <volume>29</volume>, <fpage>1346</fpage>–<lpage>1351</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schmidt</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Winstein</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wulf</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Zelaznik</surname>, <given-names>H. N</given-names></string-name></person-group>. <article-title>Motor Control and Learning: A Behavioral Emphasis</article-title>. (<source>Human kinetics</source>, <year>2018</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doyon</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Benali</surname>, <given-names>H</given-names></string-name></person-group>. <article-title>Reorganization and plasticity in the adult brain during learning of motor skills</article-title>. <source>Curr Opin Neurobiol</source> <volume>15</volume>, <fpage>161</fpage>–<lpage>167</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Wacongne</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Pallier</surname>, <given-names>C</given-names></string-name></person-group>. <article-title>The neural representation of sequences: from transition probabilities to algebraic patterns and linguistic trees</article-title>. <source>Neuron</source> <volume>88</volume>, <fpage>2</fpage>–<lpage>19</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bönstrup</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Iturrate</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Censor</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>L. G</given-names></string-name></person-group>. <article-title>Mechanisms of offline motor learning at a microscale of seconds in large-scale crowdsourced data</article-title>. <source>NPJ Sci Learn</source> <volume>5</volume>, <fpage>1</fpage>–<lpage>10</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kami</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Functional MRI evidence for adult motor cortex plasticity during motor skill learning</article-title>. <source>Nature</source> <volume>377</volume>, <fpage>155</fpage>–<lpage>158</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>L. G</given-names></string-name></person-group>. <article-title>Practice and sleep form different aspects of skill</article-title>. <source>Nat Commun</source> <volume>5</volume>, <fpage>3407</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Natraj</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Silversmith</surname>, <given-names>D. B.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>E. F.</given-names></string-name> &amp; <string-name><surname>Ganguly</surname>, <given-names>K</given-names></string-name></person-group>. <article-title>Compartmentalized dynamics within a common multi-area mesoscale manifold represent a repertoire of human hand movements</article-title>. <source>Neuron</source> <volume>110</volume>, <fpage>154</fpage>–<lpage>174</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ghilardi</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Moisello</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Silvestri</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Ghez</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Krakauer</surname>, <given-names>J. W</given-names></string-name></person-group>. <article-title>Learning of a sequential motor skill comprises explicit and implicit components that consolidate differently</article-title>. <source>J Neurophysiol</source> <volume>101</volume>, <fpage>2218</fpage>–<lpage>2229</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yokoi</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Diedrichsen</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>Neural organization of hierarchical motor sequence representations in the human neocortex</article-title>. <source>Neuron</source> <volume>103</volume>, <fpage>1178</fpage>–<lpage>1190</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beukema</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Verstynen</surname>, <given-names>T. D</given-names></string-name></person-group>. <article-title>Binding during sequence learning does not alter cortical representations of individual actions</article-title>. <source>Journal of Neuroscience</source> <volume>39</volume>, <fpage>6968</fpage>–<lpage>6977</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hikosaka</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Parallel neural networks for learning sequential procedures</article-title>. <source>Trends Neurosci</source> <volume>22</volume>, <fpage>464</fpage>–<lpage>471</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buch</surname>, <given-names>E. R.</given-names></string-name>, <string-name><surname>Claudino</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Quentin</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Bönstrup</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>L. G</given-names></string-name></person-group>. <article-title>Consolidation of human skill linked to waking hippocampo-neocortical replay</article-title>. <source>Cell Rep</source> <volume>35</volume>, <issue>109193</issue> (<year>2021</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Destrieux</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Fischl</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Dale</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Halgren</surname>, <given-names>E</given-names></string-name></person-group>. <article-title>Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature</article-title>. <source>Neuroimage</source> <volume>53</volume>, <fpage>1</fpage>– <lpage>15</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Der Maaten</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Postma</surname>, <given-names>E. O.</given-names></string-name> &amp; <string-name><surname>van den Herik</surname>, <given-names>H. J.</given-names></string-name></person-group> <article-title>Dimensionality reduction: A comparative review</article-title>. <source>Journal of Machine Learning Research</source> <volume>10</volume>, <issue>13</issue> (<year>2009</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Merino</surname>, <given-names>E. C.</given-names></string-name>, <string-name><surname>Faes</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Van Hulle</surname>, <given-names>M. M</given-names></string-name></person-group>. <article-title>The role of distinct ECoG frequency features in decoding finger movement</article-title>. <source>J Neural Eng</source> <volume>20</volume>, <issue>066014</issue> (<year>2023</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Decoding the EEG patterns induced by sequential finger movement for brain-computer interfaces</article-title>. <source>Front Neurosci</source> <volume>17</volume>, (<year>2023</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>H. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Individual finger movement decoding using a novel ultra-high-density electroencephalography-based brain-computer interface system</article-title>. <source>Front Neurosci</source> <volume>16</volume>, <issue>1009878</issue> (<year>2022</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Decoding finger movement patterns from microscopic neural drive information based on deep learning</article-title>. <source>Med Eng Phys</source> <volume>104</volume>, <issue>103797</issue> (<year>2022</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yao</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Shoaran</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Fast and accurate decoding of finger movements from ECoG through Riemannian features and modern machine learning techniques</article-title>. <source>J Neural Eng</source> <volume>19</volume>, <issue>016037</issue> (<year>2022</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buch</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Think to move: a neuromagnetic brain-computer interface (BCI) system for chronic stroke</article-title>. <source>Stroke</source> <volume>39</volume>, <fpage>910</fpage>–<lpage>917</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Vogel</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <chapter-title>Continuous control of the dlr light-weight robot iii by a human with tetraplegia using the braingate2 neural interface system</chapter-title>. in <source>Experimental Robotics: The 12th International Symposium on Experimental Robotics</source> <fpage>125</fpage>–<lpage>136</lpage> (<publisher-name>Springer</publisher-name>, <year>2014</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Rubin</surname>, <given-names>D. B.</given-names></string-name> &amp; <string-name><surname>Hochberg</surname>, <given-names>L. R.</given-names></string-name></person-group> <chapter-title>BrainGate: An Intracortical Brain-Computer Interface for the Restoration of Communication and Functional Independence for People with Paralysis</chapter-title>. in <source>2023 11th International Winter Conference on Brain-Computer Interface (BCI)</source> <fpage>1</fpage>–<lpage>3</lpage> (<publisher-name>IEEE</publisher-name>, <year>2023</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Birbaumer</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>L. G</given-names></string-name></person-group>. <article-title>Brain–computer interfaces: communication and restoration of movement in paralysis</article-title>. <source>J Physiol</source> <volume>579</volume>, <fpage>621</fpage>–<lpage>636</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Birbaumer</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Murguialday</surname>, <given-names>A. R.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>L</given-names></string-name></person-group>. <article-title>Brain–computer interface in paralysis</article-title>. <source>Curr Opin Neurol</source> <volume>21</volume>, <fpage>634</fpage>–<lpage>638</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liao</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Xiao</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Gonzalez</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Ding</surname>, <given-names>L</given-names></string-name></person-group>. <article-title>Decoding individual finger movements from one hand using human EEG signals</article-title>. <source>PLoS One</source> <volume>9</volume>, <fpage>e85192</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quandt</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Single trial discrimination of individual finger movements on one hand: a combined MEG and EEG study</article-title>. <source>Neuroimage</source> <volume>59</volume>, <fpage>3316</fpage>–<lpage>3324</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kornysheva</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Neural competitive queuing of ordinal structure underlies skilled sequential action</article-title>. <source>Neuron</source> <volume>101</volume>, <fpage>1166</fpage>–<lpage>1180</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Shenoy</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Ojemann</surname>, <given-names>J. G.</given-names></string-name> &amp; <string-name><surname>Rao</surname>, <given-names>R. P. N.</given-names></string-name></person-group> <chapter-title>Finger movement classification for an electrocorticographic BCI</chapter-title>. in <source>2007 3rd International IEEE/EMBS Conference on Neural Engineering 192–195</source> (<publisher-name>IEEE</publisher-name>, <year>2007</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Onaran</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Ince</surname>, <given-names>N. F.</given-names></string-name>, <string-name><surname>Cetin</surname>, <given-names>A. E.</given-names></string-name> &amp; <string-name><surname>Abosch</surname>, <given-names>A.</given-names></string-name></person-group> <chapter-title>A hybrid SVM/HMM based system for the state detection of individual finger movements from multichannel ECoG signals</chapter-title>. in <source>2011 5th International IEEE/EMBS Conference on Neural Engineering</source> <fpage>457</fpage>–<lpage>460</lpage> (<publisher-name>IEEE</publisher-name>, <year>2011</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Presacco</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Forrester</surname>, <given-names>L. W.</given-names></string-name> &amp; <string-name><surname>Contreras-Vidal</surname>, <given-names>J. L</given-names></string-name></person-group>. <article-title>Decoding intra-limb and inter-limb kinematics during treadmill walking from scalp electroencephalographic (EEG) signals</article-title>. <source>IEEE Transactions on neural systems and rehabilitation engineering</source> <volume>20</volume>, <fpage>212</fpage>–<lpage>219</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dayan</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>L. G</given-names></string-name></person-group>. <article-title>Neuroplasticity subserving motor skill learning</article-title>. <source>Neuron</source> <volume>72</volume>, <fpage>443</fpage>–<lpage>454</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reddy</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Theta-phase dependent neuronal coding during sequence learning in human single neurons</article-title>. <source>Nat Commun</source> <volume>12</volume>, <fpage>4839</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bansal</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Vargas-Irwin</surname>, <given-names>C. E.</given-names></string-name>, <string-name><surname>Truccolo</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Donoghue</surname>, <given-names>J. P</given-names></string-name></person-group>. <article-title>Relationships among low-frequency local field potentials, spiking activity, and three-dimensional reach and grasp kinematics in primary motor and ventral premotor cortices</article-title>. <source>J Neurophysiol</source> <volume>105</volume>, <fpage>1603</fpage>–<lpage>1619</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mollazadeh</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Spatiotemporal variation of multiple neurophysiological signals in the primary motor cortex during dexterous reach-to-grasp movements</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>, <fpage>15531</fpage>–<lpage>15543</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bönstrup</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Low-frequency brain oscillations track motor recovery in human stroke</article-title>. <source>Ann Neurol</source> <volume>86</volume>, <fpage>853</fpage>–<lpage>865</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cruikshank</surname>, <given-names>L. C.</given-names></string-name>, <string-name><surname>Singhal</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hueppelsheuser</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Caplan</surname>, <given-names>J. B</given-names></string-name></person-group>. <article-title>Theta oscillations reflect a putative neural mechanism for human sensorimotor integration</article-title>. <source>J Neurophysiol</source> <volume>107</volume>, <fpage>65</fpage>–<lpage>77</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tomassini</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ambrogioni</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Medendorp</surname>, <given-names>W. P.</given-names></string-name> &amp; <string-name><surname>Maris</surname>, <given-names>E</given-names></string-name></person-group>. <article-title>Theta oscillations locked to intended actions rhythmically modulate perception</article-title>. <source>Elife</source> <volume>6</volume>, <fpage>e25618</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramanathan</surname>, <given-names>D. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Low-frequency cortical activity is a neuromodulatory target that tracks recovery after stroke</article-title>. <source>Nat Med</source> <volume>24</volume>, <fpage>1257</fpage>–<lpage>1267</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hall</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Nazarpour</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Jackson</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Real-time estimation and biofeedback of single-neuron firing rates using local field potentials</article-title>. <source>Nat Commun</source> <volume>5</volume>, <fpage>5462</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stefanics</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Phase entrainment of human delta oscillations can mediate the effects of expectation on reaction speed</article-title>. <source>Journal of Neuroscience</source> <volume>30</volume>, <fpage>13578</fpage>–<lpage>13585</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Flint</surname>, <given-names>R. D.</given-names></string-name>, <string-name><surname>Ethier</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Oby</surname>, <given-names>E. R.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>L. E.</given-names></string-name> &amp; <string-name><surname>Slutzky</surname>, <given-names>M. W</given-names></string-name></person-group>. <article-title>Local field potentials allow accurate decoding of muscle activity</article-title>. <source>J Neurophysiol</source> <volume>108</volume>, <fpage>18</fpage>–<lpage>24</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Krasoulis</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hall</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Vijayakumar</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jackson</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Nazarpour</surname>, <given-names>K.</given-names></string-name></person-group> <chapter-title>Generalizability of EMG decoding using local field potentials</chapter-title>. in <source>2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society</source> <fpage>1630</fpage>–<lpage>1633</lpage> (<publisher-name>IEEE</publisher-name>, <year>2014</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Churchland</surname>, <given-names>M. M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Neural population dynamics during reaching</article-title>. <source>Nature</source> <volume>487</volume>, <fpage>51</fpage>–<lpage>56</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frohlich</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Toker</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Monti</surname>, <given-names>M. M</given-names></string-name></person-group>. <article-title>Consciousness among delta waves: a paradox?</article-title> <source>Brain</source> <volume>144</volume>, <fpage>2257</fpage>–<lpage>2277</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Recovery of consolidation after sleep following stroke—interaction of slow waves, spindles, and GABA</article-title>. <source>Cell Rep</source> <volume>38</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Decoding the individual finger movements from single-trial functional magnetic resonance imaging recordings of human brain activity</article-title>. <source>European Journal of Neuroscience</source> <volume>39</volume>, <fpage>2071</fpage>–<lpage>2082</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alazrai</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Alwanni</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Daoud</surname>, <given-names>M. I</given-names></string-name></person-group>. <article-title>EEG-based BCI system for decoding finger movements within the same hand</article-title>. <source>Neurosci Lett</source> <volume>698</volume>, <fpage>113</fpage>–<lpage>120</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiao</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Ding</surname>, <given-names>L</given-names></string-name></person-group>. <article-title>Evaluation of EEG features in decoding individual finger movements from one hand</article-title>. <source>Comput Math Methods Med</source> <volume>2013</volume>, <fpage>243257</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stankevich</surname>, <given-names>L. A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>EEG pattern decoding of rhythmic individual finger imaginary movements of one hand</article-title>. <source>Hum Physiol</source> <volume>42</volume>, <fpage>32</fpage>–<lpage>42</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nambu</surname>, <given-names>I.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Decoding sequential finger movements from preparatory activity in higher-order motor regions: a functional magnetic resonance imaging multi-voxel pattern analysis</article-title>. <source>European Journal of Neuroscience</source> <volume>42</volume>, <fpage>2851</fpage>–<lpage>2859</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baillet</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Magnetoencephalography for brain electrophysiology and imaging</article-title>. <source>Nat Neurosci</source> <volume>20</volume>, <fpage>327</fpage>–<lpage>339</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Komorowski</surname>, <given-names>R. W.</given-names></string-name>, <string-name><surname>Manns</surname>, <given-names>J. R.</given-names></string-name> &amp; <string-name><surname>Eichenbaum</surname>, <given-names>H</given-names></string-name></person-group>. <article-title>Robust conjunctive item–place coding by hippocampal neurons parallels learning what happens where</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>, <fpage>9918</fpage>–<lpage>9929</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Georgopoulos</surname>, <given-names>A. P</given-names></string-name></person-group>. <article-title>Population activity in the control of movement</article-title>. <source>Int Rev Neurobiol</source> <volume>103</volume> (<year>1994</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Georgopoulos</surname>, <given-names>AP</given-names></string-name></person-group>. <article-title>On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex</article-title>. <source>J Neurosci</source> <volume>2</volume>, <fpage>1527</fpage>–<lpage>1537</lpage> (<year>1982</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname>, <given-names>B. P.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Generalization of procedural motor sequence learning after a single practice trial</article-title>. <source>NPJ Sci Learn</source> <volume>8</volume>, <issue>45</issue> (<year>2023</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ruiz</surname>, <given-names>M. H.</given-names></string-name>, <string-name><surname>Jabusch</surname>, <given-names>H.-C.</given-names></string-name> &amp; <string-name><surname>Altenmüller</surname>, <given-names>E</given-names></string-name></person-group>. <article-title>Detecting wrong notes in advance: neuronal correlates of error monitoring in pianists</article-title>. <source>Cerebral cortex</source> <volume>19</volume>, <fpage>2625</fpage>–<lpage>2639</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maidhof</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rieger</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Prinz</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Koelsch</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Nobody is perfect: ERP effects prior to performance errors in musicians indicate fast monitoring processes</article-title>. <source>PLoS One</source> <volume>4</volume>, <fpage>e5032</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oostenveld</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Fries</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Maris</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Schoffelen</surname>, <given-names>J.-M</given-names></string-name></person-group>. <article-title>FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title>. <source>Comput Intell Neurosci</source> <volume>2011</volume>, <fpage>1</fpage>–<lpage>9</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Delorme</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Makeig</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title>. <source>J Neurosci Methods</source> <volume>134</volume>, <fpage>9</fpage>–<lpage>21</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holland</surname>, <given-names>P. W.</given-names></string-name> &amp; <string-name><surname>Welsch</surname>, <given-names>R. E</given-names></string-name></person-group>. <article-title>Robust regression using iteratively reweighted least-squares</article-title>. <source>Communications in Statistics-theory and Methods</source> <volume>6</volume>, <fpage>813</fpage>–<lpage>827</lpage> (<year>1977</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102475.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Gallego</surname>
<given-names>Juan Alvaro</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Imperial College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study investigates how the neural representation of individual finger movements changes during the early period of sequence learning. By combining a new method for extracting features from human magnetoencephalography data and decoding analyses, the authors provide <bold>incomplete</bold> evidence of an early, swift change in the brain regions correlated with sequence learning, including a set of previously unreported frontal cortical regions. The addition of more control analyses to rule out that head movement artefacts influence the findings, and to further explain the proposal of offline contextualization during short rest periods as the basis for improvement performance would strengthen the manuscript.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102475.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study addresses the issue of rapid skill learning and whether individual sequence elements (here: finger presses) are differentially represented in human MEG data. The authors use a decoding approach to classify individual finger elements, and accomplish an accuracy of around 94%. A relevant finding is that the neural representations of individual finger elements dynamically change over the course of learning. This would be highly relevant for any attempts to develop better brain machine interfaces - one now can decode individual elements within a sequence with high precision, but these representations are not static but develop over the course of learning.</p>
<p>Strengths:</p>
<p>The work follows a large body of work from the same group on the behavioural and neural foundations of sequence learning. The behavioural task is well established and neatly designed to allow for tracking learning and how individual sequence elements contribute. The inclusion of short offline rest periods between learning epochs has been influential because it has revealed that a lot, if not most of the gains in behaviour (ie speed of finger movements) occur in these so-called micro-offline rest periods.</p>
<p>The authors use a range of new decoding techniques, and exhaustively interrogate their data in different ways, using different decoding approaches. Regardless of the approach, impressively high decoding accuracies are observed, but when using a hybrid approach that combines the MEG data in different ways, the authors observe decoding accuracies of individual sequence elements from the MEG data of up to 94%.</p>
<p>Weaknesses:</p>
<p>There are a few concerns which the authors may well be able to resolve. These are not weaknesses as such, but factors that would be helpful to address as these concern potential contributions to the results that one would like to rule out.</p>
<p>Regarding the decoding results shown in Figure 2 etc, a concern is that within individual frequency bands, the highest accuracy seems to be within frequencies that match the rate of keypresses. This is a general concern when relating movement to brain activity, so is not specific to decoding as done here. As far as reported, there was no specific restraint to the arm or shoulder, and even then it is conceivable that small head movements would correlate highly with the vigor of individual finger movements. This concern is supported by the highest contribution in decoding accuracy being in middle frontal regions - midline structures that would be specifically sensitive to movement artefacts and don't seem to come to mind as key structures for very simple sequential keypress tasks such as this - and the overall pattern is remarkably symmetrical (despite being a unimanual finger task) and spatially broad. This issue may well be matching the time course of learning, as the vigor and speed of finger presses will also influence the degree to which the arm/shoulder and head move.</p>
<p>This is not to say that useful information is contained within either of the frequencies or broadband data. But it raises the question of whether a lot is dominated by movement &quot;artefacts&quot; and one may get a more specific answer if removing any such contributions.</p>
<p>A somewhat related point is this: when combining voxel and parcel space, a concern is whether a degree of circularity may have contributed to the improved accuracy of the combined data, because it seems to use the same MEG signals twice - the voxels most contributing are also those contributing most to a parcel being identified as relevant, as parcels reflect the average of voxels within a boundary. In this context, I struggled to understand the explanation given, ie that the improved accuracy of the hybrid model may be due to &quot;lower spatially resolved whole-brain and higher spatially resolved regional activity patterns&quot;. Firstly, there will be a relatively high degree of spatial contiguity among voxels because of the nature of the signal measured, ie nearby individual voxels are unlikely to be independent. Secondly, the voxel data gives a somewhat misleading sense of precision; the inversion can be set up to give an estimate for each voxel, but there will not just be dependence among adjacent voxels, but also substantial variation in the sensitivity and confidence with which activity can be projected to different parts of the brain. Midline and deeper structures come to mind, where the inversion will be more problematic than for regions along the dorsal convexity of the brain, and a concern is that in those midline structures, the highest decoding accuracy is seen.</p>
<p>Some of these concerns could be addressed by recording head movement (with enough precision) to regress out these contributions. The authors state that head movement was monitored with 3 fiducials, and their timecourses ought to provide a way to deal with this issue. The ICA procedure may not have sufficiently dealt with removing movement-related problems, but one could eg relate individual components that were identified to the keypresses as another means for checking. An alternative could be to focus on frequency ranges above the movement frequencies. The accuracy for those still seems impressive, and may provide a slightly more biologically plausible assessment.</p>
<p>One question concerns the interpretation of the results shown in Figure 4. They imply that during the course of learning, entirely different brain networks underpin the behaviour. Not only that, but they also include regions that would seem rather unexpected to be key nodes for learning and expressing relatively simple finger sequences, such as here. What then is the biological plausibility of these results? The authors seem to circumnavigate this issue by moving into a distance metric that captures the (neural network) changes over the course of learning, but the discussion seems detached from which regions are actually involved; or they offer a rather broad discussion of the anatomical regions identified here, eg in the context of LFOs, where they merely refer to &quot;frontoparietal regions&quot;.</p>
<p>If I understand correctly, the offline neural representation analysis is in essence the comparison of the last keypress vs the first keypress of the next sequence. In that sense, the activity during offline rest periods is actually not considered. This makes the nomenclature somewhat confusing. While it matches the behavioural analysis, having only key presses one can't do it in any other way, but here the authors actually do have recordings of brain activity during offline rest. So at the very least calling it offline neural representation is misleading to this reviewer because what is compared is activity during the last and during the next keypress, not activity during offline periods. But it also seems a missed opportunity - the authors argue that most of the relevant learning occurs during offline rest periods, yet there is no attempt to actually test whether activity during this period can be useful for the questions at hand here.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102475.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>Dash et al. asked whether and how the neural representation of individual finger movements is &quot;contextualized&quot; within a trained sequence during the very early period of sequential skill learning by using decoding of MEG signal. Specifically, they assessed whether/how the same finger presses (pressing index finger) embedded in the different ordinal positions of a practiced sequence (4-1-3-2-4; here, the numbers 1 through 4 correspond to the little through the index fingers of the non-dominant left hand) change their representation (MEG feature). They did this by computing either the decoding accuracy of the index finger at the ordinal positions 1 vs. 5 (index_OP1 vs index_OP5) or pattern distance between index_OP1 vs. index_OP5 at each training trial and found that both the decoding accuracy and the pattern distance progressively increase over the course of learning trials. More interestingly, they also computed the pattern distance for index_OP5 for the last execution of a practice trial vs. index_OP1 for the first execution in the next practice trial (i.e., across the rest period). This &quot;off-line&quot; distance was significantly larger than the &quot;on-line&quot; distance, which was computed within practice trials and predicted micro-offline skill gain. Based on these results, the authors conclude that the differentiation of representation for the identical movement embedded in different positions of a sequential skill (&quot;contextualization&quot;) primarily occurs during early skill learning, especially during rest, consistent with the recent theory of the &quot;micro-offline learning&quot; proposed by the authors' group. I think this is an important and timely topic for the field of motor learning and beyond.</p>
<p>Strengths</p>
<p>The specific strengths of the current work are as follows. First, the use of temporally rich neural information (MEG signal) has a large advantage over previous studies testing sequential representations using fMRI. This allowed the authors to examine the earliest period (= the first few minutes of training) of skill learning with finer temporal resolution. Second, through the optimization of MEG feature extraction, the current study achieved extremely high decoding accuracy (approx. 94%) compared to previous works. As claimed by the authors, this is one of the strengths of the paper (but see my comments). Third, although some potential refinement might be needed, comparing &quot;online&quot; and &quot;offline&quot; pattern distance is a neat idea.</p>
<p>Weaknesses</p>
<p>Along with the strengths I raised above, the paper has some weaknesses. First, the pursuit of high decoding accuracy, especially the choice of time points and window length (i.e., 200 msec window starting from 0 msec from key press onset), casts a shadow on the interpretation of the main result. Currently, it is unclear whether the decoding results simply reflect behavioral change or true underlying neural change. As shown in the behavioral data, the key press speed reached 3~4 presses per second already at around the end of the early learning period (11th trial), which means inter-press intervals become as short as 250-330 msec. Thus, in almost more than 60% of training period data, the time window for MEG feature extraction (200 msec) spans around 60% of the inter-press intervals. Considering that the preparation/cueing of subsequent presses starts ahead of the actual press (e.g., Kornysheva et al., 2019) and/or potential online planning (e.g., Ariani and Diedrichsen, 2019), the decoder likely has captured these future press information as well as the signal related to the current key press, independent of the formation of genuine sequential representation (e.g., &quot;contextualization&quot; of individual press). This may also explain the gradual increase in decoding accuracy or pattern distance between index_OP1 vs. index_OP5 (Figure 4C and 5A), which co-occurred with performance improvement, as shorter inter-press intervals are more favorable for the dissociating the two index finger presses followed by different finger presses. The compromised decoding accuracies for the control sequences can be explained in similar logic. Therefore, more careful consideration and elaborated discussion seem necessary when trying to both achieve high-performance decoding and assess early skill learning, as it can impact all the subsequent analyses.</p>
<p>Related to the above point, testing only one particular sequence (4-1-3-2-4), aside from the control ones, limits the generalizability of the finding. This also may have contributed to the extremely high decoding accuracy reported in the current study.</p>
<p>In terms of clinical BCI, one of the potential relevance of the study, as claimed by the authors, it is not clear that the specific time window chosen in the current study (up to 200 msec since key press onset) is really useful. In most cases, clinical BCI would target neural signals with no overt movement execution due to patients' inability to move (e.g., Hochberg et al., 2012). Given the time window, the surprisingly high performance of the current decoder may result from sensory feedback and/or planning of subsequent movement, which may not always be available in the clinical BCI context. Of course, the decoding accuracy is still much higher than chance even when using signal before the key press (as shown in Figure 4 Supplement 2), but it is not immediately clear to me that the authors relate their high decoding accuracy based on post-movement signal to clinical BCI settings.</p>
<p>One of the important and fascinating claims of the current study is that the &quot;contextualization&quot; of individual finger movements in a trained sequence specifically occurs during short rest periods in very early skill learning, echoing the recent theory of micro-offline learning proposed by the authors' group. Here, I think two points need to be clarified. First, the concept of &quot;contextualization&quot; is kept somewhat blurry throughout the text. It is only at the later part of the Discussion (around line #330 on page 13) that some potential mechanism for the &quot;contextualization&quot; is provided as &quot;what-and-where&quot; binding. Still, it is unclear what &quot;contextualization&quot; actually is in the current data, as the MEG signal analyzed is extracted from 0-200 msec after the keypress. If one thinks something is contextualizing an action, that contextualization should come earlier than the action itself.</p>
<p>The second point is that the result provided by the authors is not yet convincing enough to support the claim that &quot;contextualization&quot; occurs during rest. In the original analysis, the authors presented the statistical significance regarding the correlation between the &quot;offline&quot; pattern differentiation and micro-offline skill gain (Figure 5. Supplement 1), as well as the larger &quot;offline&quot; distance than &quot;online&quot; distance (Figure 5B). However, this analysis looks like regressing two variables (monotonically) increasing as a function of the trial. Although some information in this analysis, such as what the independent/dependent variables were or how individual subjects were treated, was missing in the Methods, getting a statistically significant slope seems unsurprising in such a situation. Also, curiously, the same quantitative evidence was not provided for its &quot;online&quot; counterpart, and the authors only briefly mentioned in the text that there was no significant correlation between them. It may be true looking at the data in Figure 5A as the online representation distance looks less monotonically changing, but the classification accuracy presented in Figure 4C, which should reflect similar representational distance, shows a more monotonic increase up to the 11th trial. Further, the ways the &quot;online&quot; and &quot;offline&quot; representation distance was estimated seem to make them not directly comparable. While the &quot;online&quot; distance was computed using all the correct press data within each 10 sec of execution, the &quot;offline&quot; distance is basically computed by only two presses (i.e., the last index_OP5 vs. the first index_OP1 separated by 10 sec of rest). Theoretically, the distance between the neural activity patterns for temporally closer events tends to be closer than that between the patterns for temporally far-apart events. It would be fairer to use the distance between the first index_OP1 vs. the last index_OP5 within an execution period for &quot;online&quot; distance, as well.</p>
<p>A related concern regarding the control analysis, where individual values for max speed and the degree of online contextualization were compared (Figure 5 Supplement 3), is whether the individual difference is meaningful. If I understood correctly, the optimization of the decoding process (temporal window, feature inclusion/reduction, decoder, etc.) was performed for individual participants, and the same feature extraction was also employed for the analysis of representation distance (i.e., contextualization). If this is the case, the distances are individually differently calculated and they may need to be normalized relative to some stable reference (e.g., 1 vs. 4 or average distance within the control sequence presses) before comparison across the individuals.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102475.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>One goal of this paper is to introduce a new approach for highly accurate decoding of finger movements from human magnetoencephalography data via dimension reduction of a &quot;multi-scale, hybrid&quot; feature space. Following this decoding approach, the authors aim to show that early skill learning involves &quot;contextualization&quot; of the neural coding of individual movements, relative to their position in a sequence of consecutive movements. Furthermore, they aim to show that this &quot;contextualization&quot; develops primarily during short rest periods interspersed with skill training, and correlates with a performance metric which the authors interpret as an indicator of offline learning.</p>
<p>Strengths:</p>
<p>A clear strength of the paper is the innovative decoding approach, which achieves impressive decoding accuracies via dimension reduction of a &quot;multi-scale, hybrid space&quot;. This hybrid-space approach follows the neurobiologically plausible idea of the concurrent distribution of neural coding across local circuits as well as large-scale networks. A further strength of the study is the large number of tested dimension reduction techniques and classifiers (though the manuscript reveals little about the comparison of the latter).</p>
<p>A simple control analysis based on shuffled class labels could lend further support to this complex decoding approach. As a control analysis that completely rules out any source of overfitting, the authors could test the decoder after shuffling class labels. Following such shuffling, decoding accuracies should drop to chance level for all decoding approaches, including the optimized decoder. This would also provide an estimate of actual chance-level performance (which is informative over and beyond the theoretical chance level). Furthermore, currently, the manuscript does not explain the huge drop in decoding accuracies for the voxel-space decoding (Figure 3B). Finally, the authors' approach to cortical parcellation raises questions regarding the information carried by varying dipole orientations within a parcel (which currently seems to be ignored?) and the implementation of the mean-flipping method (given that there are two dimensions - space and time - what do the authors refer to when they talk about the sign of the &quot;average source&quot;, line 477?).</p>
<p>Weaknesses:</p>
<p>A clear weakness of the paper lies in the authors' conclusions regarding &quot;contextualization&quot;. Several potential confounds, described below, question the neurobiological implications proposed by the authors and provide a simpler explanation of the results. Furthermore, the paper follows the assumption that short breaks result in offline skill learning, while recent evidence, described below, casts doubt on this assumption.</p>
<p>The authors interpret the ordinal position information captured by their decoding approach as a reflection of neural coding dedicated to the local context of a movement (Figure 4). One way to dissociate ordinal position information from information about the moving effectors is to train a classifier on one sequence and test the classifier on other sequences that require the same movements, but in different positions (Kornysheva et al., Neuron 2019). In the present study, however, participants trained to repeat a single sequence (4-1-3-2-4). As a result, ordinal position information is potentially confounded by the fixed finger transitions around each of the two critical positions (first and fifth press). Across consecutive correct sequences, the first keypress in a given sequence was always preceded by a movement of the index finger (=last movement of the preceding sequence), and followed by a little finger movement. The last keypress, on the other hand, was always preceded by a ring finger movement, and followed by an index finger movement (=first movement of the next sequence). Figure 4 - Supplement 2 shows that finger identity can be decoded with high accuracy (&gt;70%) across a large time window around the time of the key press, up to at least {plus minus}100 ms (and likely beyond, given that decoding accuracy is still high at the boundaries of the window depicted in that figure). This time window approaches the keypress transition times in this study. Given that distinct finger transitions characterized the first and fifth keypress, the classifier could thus rely on persistent (or &quot;lingering&quot;) information from the preceding finger movement, and/or &quot;preparatory&quot; information about the subsequent finger movement, in order to dissociate the first and fifth keypress. Currently, the manuscript provides no evidence that the context information captured by the decoding approach is more than a by-product of temporally extended, and therefore overlapping, but independent neural representations of consecutive keypresses that are executed in close temporal proximity - rather than a neural representation dedicated to context.</p>
<p>Such temporal overlap of consecutive, independent finger representations may also account for the dynamics of &quot;ordinal coding&quot;/&quot;contextualization&quot;, i.e., the increase in 2-class decoding accuracy, across Day 1 (Figure 4C). As learning progresses, both tapping speed and the consistency of keypress transition times increase (Figure 1), i.e., consecutive keypresses are closer in time, and more consistently so. As a result, information related to a given keypress is increasingly overlapping in time with information related to the preceding and subsequent keypresses. The authors seem to argue that their regression analysis in Figure 5 - Figure Supplement 3 speaks against any influence of tapping speed on &quot;ordinal coding&quot; (even though that argument is not made explicitly in the manuscript). However, Figure 5 - Figure Supplement 3 shows inter-individual differences in a between-subject analysis (across trials, as in panel A, or separately for each trial, as in panel B), and, therefore, says little about the within-subject dynamics of &quot;ordinal coding&quot; across the experiment. A regression of trial-by-trial &quot;ordinal coding&quot; on trial-by-trial tapping speed (either within-subject or at a group-level, after averaging across subjects) could address this issue. Given the highly similar dynamics of &quot;ordinal coding&quot; on the one hand (Figure 4C), and tapping speed on the other hand (Figure 1B), I would expect a strong relationship between the two in the suggested within-subject (or group-level) regression. Furthermore, learning should increase the number of (consecutively) correct sequences, and, thus, the consistency of finger transitions. Therefore, the increase in 2-class decoding accuracy may simply reflect an increasing overlap in time of increasingly consistent information from consecutive keypresses, which allows the classifier to dissociate the first and fifth keypress more reliably as learning progresses, simply based on the characteristic finger transitions associated with each. In other words, given that the physical context of a given keypress changes as learning progresses - keypresses move closer together in time and are more consistently correct - it seems problematic to conclude that the mental representation of that context changes. To draw that conclusion, the physical context should remain stable (or any changes to the physical context should be controlled for).</p>
<p>A similar difference in physical context may explain why neural representation distances (&quot;differentiation&quot;) differ between rest and practice (Figure 5). The authors define &quot;offline differentiation&quot; by comparing the hybrid space features of the last index finger movement of a trial (ordinal position 5) and the first index finger movement of the next trial (ordinal position 1). However, the latter is not only the first movement in the sequence but also the very first movement in that trial (at least in trials that started with a correct sequence), i.e., not preceded by any recent movement. In contrast, the last index finger of the last correct sequence in the preceding trial includes the characteristic finger transition from the fourth to the fifth movement. Thus, there is more overlapping information arising from the consistent, neighbouring keypresses for the last index finger movement, compared to the first index finger movement of the next trial. A strong difference (larger neural representation distance) between these two movements is, therefore, not surprising, given the task design, and this difference is also expected to increase with learning, given the increase in tapping speed, and the consequent stronger overlap in representations for consecutive keypresses. Furthermore, initiating a new sequence involves pre-planning, while ongoing practice relies on online planning (Ariani et al., eNeuro 2021), i.e., two mental operations that are dissociable at the level of neural representation (Ariani et al., bioRxiv 2023).</p>
<p>Given these differences in the physical context and associated mental processes, it is not surprising that &quot;offline differentiation&quot;, as defined here, is more pronounced than &quot;online differentiation&quot;. For the latter, the authors compared movements that were better matched regarding the presence of consistent preceding and subsequent keypresses (online differentiation was defined as the mean difference between all first vs. last index finger movements during practice). It is unclear why the authors did not follow a similar definition for &quot;online differentiation&quot; as for &quot;micro-online gains&quot; (and, indeed, a definition that is more consistent with their definition of &quot;offline differentiation&quot;), i.e., the difference between the first index finger movement of the first correct sequence during practice, and the last index finger of the last correct sequence. While these two movements are, again, not matched for the presence of neighbouring keypresses (see the argument above), this mismatch would at least be the same across &quot;offline differentiation&quot; and &quot;online differentiation&quot;, so they would be more comparable.</p>
<p>A further complication in interpreting the results regarding &quot;contextualization&quot; stems from the visual feedback that participants received during the task. Each keypress generated an asterisk shown above the string on the screen, irrespective of whether the keypress was correct or incorrect. As a result, incorrect (e.g., additional, or missing) keypresses could shift the phase of the visual feedback string (of asterisks) relative to the ordinal position of the current movement in the sequence (e.g., the fifth movement in the sequence could coincide with the presentation of any asterisk in the string, from the first to the fifth). Given that more incorrect keypresses are expected at the start of the experiment, compared to later stages, the consistency in visual feedback position, relative to the ordinal position of the movement in the sequence, increased across the experiment. A better differentiation between the first and the fifth movement with learning could, therefore, simply reflect better decoding of the more consistent visual feedback, based either on the feedback-induced brain response, or feedback-induced eye movements (the study did not include eye tracking). It is not clear why the authors introduced this complicated visual feedback in their task, besides consistency with their previous studies.</p>
<p>The authors report a significant correlation between &quot;offline differentiation&quot; and cumulative micro-offline gains. However, it would be more informative to correlate trial-by-trial changes in each of the two variables. This would address the question of whether there is a trial-by-trial relation between the degree of &quot;contextualization&quot; and the amount of micro-offline gains - are performance changes (micro-offline gains) less pronounced across rest periods for which the change in &quot;contextualization&quot; is relatively low? Furthermore, is the relationship between micro-offline gains and &quot;offline differentiation&quot; significantly stronger than the relationship between micro-offline gains and &quot;online differentiation&quot;?</p>
<p>The authors follow the assumption that micro-offline gains reflect offline learning. However, there is no direct evidence in the literature that micro-offline gains really result from offline learning, i.e., an improvement in skill level. On the contrary, recent evidence questions this interpretation (Gupta &amp; Rickard, npj Sci Learn 2022; Gupta &amp; Rickard, Sci Rep 2024; Das et al., bioRxiv 2024). Instead, there is evidence that micro-offline gains are transient performance benefits that emerge when participants train with breaks, compared to participants who train without breaks, however, these benefits vanish within seconds after training if both groups of participants perform under comparable conditions (Das et al., bioRxiv 2024).</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102475.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Dash</surname>
<given-names>Debadatta</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0543-0304</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Iwane</surname>
<given-names>Fumiaki</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9659-4127</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Hayward</surname>
<given-names>William</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9344-4203</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Salamanca-Giron</surname>
<given-names>Roberto</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0008-5743-6805</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Bonstrup</surname>
<given-names>Marlene</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Buch</surname>
<given-names>Ethan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5443-8222</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Cohen</surname>
<given-names>Leonardo G</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1705-8773</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>eLife Assessment</bold></p>
<p>This valuable study investigates how the neural representation of individual finger movements changes during the early period of sequence learning. By combining a new method for extracting features from human magnetoencephalography data and decoding analyses, the authors provide incomplete evidence of an early, swift change in the brain regions correlated with sequence learning, including a set of previously unreported frontal cortical regions. The addition of more control analyses to rule out that head movement artefacts influence the findings, and to further explain the proposal of offline contextualization during short rest periods as the basis for improvement performance would strengthen the manuscript.</p>
</disp-quote>
<p>We appreciate the Editorial assessment on our paper’s strengths and novelty.  We have implemented additional control analyses to show that neither task-related eye movements nor increasing overlap of finger movements during learning account for our findings, which are that contextualized neural representations in a network of bilateral frontoparietal brain regions actively contribute to skill learning.  Importantly, we carried out additional analyses showing that contextualization develops predominantly during rest intervals.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
</disp-quote>
<p>We thank the Reviewers for their comments and suggestions, prompting new analyses and additions that strengthened our report.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>This study addresses the issue of rapid skill learning and whether individual sequence elements (here: finger presses) are differentially represented in human MEG data. The authors use a decoding approach to classify individual finger elements and accomplish an accuracy of around 94%. A relevant finding is that the neural representations of individual finger elements dynamically change over the course of learning. This would be highly relevant for any attempts to develop better brain machine interfaces - one now can decode individual elements within a sequence with high precision, but these representations are not static but develop over the course of learning.</p>
<p>Strengths: The work follows a large body of work from the same group on the behavioural and neural foundations of sequence learning. The behavioural task is well established and neatly designed to allow for tracking learning and how individual sequence elements contribute. The inclusion of short offline rest periods between learning epochs has been influential because it has revealed that a lot, if not most of the gains in behaviour (ie speed of finger movements) occur in these so-called micro-offline rest periods. The authors use a range of new decoding techniques, and exhaustively interrogate their data in different ways, using different decoding approaches. Regardless of the approach, impressively high decoding accuracies are observed, but when using a hybrid approach that combines the MEG data in different ways, the authors observe decoding accuracies of individual sequence elements from the MEG data of up to 94%.</p>
</disp-quote>
<p>We have previously showed that neural replay of MEG activity representing the practiced skill correlated with micro-offline gains during rest intervals of early learning, 1 consistent with the recent report that hippocampal ripples during these offline periods predict human motor sequence learning2.  However, decoding accuracy in our earlier work1 needed improvement.  Here, we reported a strategy to improve decoding accuracy that could benefit future studies of neural replay or BCI using MEG.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>There are a few concerns which the authors may well be able to resolve. These are not weaknesses as such, but factors that would be helpful to address as these concern potential contributions to the results that one would like to rule out. Regarding the decoding results shown in Figure 2 etc, a concern is that within individual frequency bands, the highest accuracy seems to be within frequencies that match the rate of keypresses<bold>.</bold> This is a general concern when relating movement to brain activity, so is not specific to decoding as done here. As far as reported, there was no specific restraint to the arm or shoulder, and even then it is conceivable that small head movements would correlate highly with the vigor of individual finger movements. This concern is supported by the highest contribution in decoding accuracy being in middle frontal regions - midline structures that would be specifically sensitive to movement artefacts and don't seem to come to mind as key structures for very simple sequential keypress tasks such as this - and the overall pattern is remarkably symmetrical (despite being a unimanual finger task) and spatially broad. This issue may well be matching the time course of learning, as the vigor and speed of finger presses will also influence the degree to which the arm/shoulder and head move. This is not to say that useful information is contained within either of the frequencies or broadband data. But it raises the question of whether a lot is dominated by movement &quot;artefacts&quot; and one may get a more specific answer if removing any such contributions.</p>
</disp-quote>
<p>Reviewer #1 expresses concern that the combination of the low-frequency narrow-band decoder results, and the bilateral middle frontal regions displaying the highest average intra-parcel decoding performance across subjects is suggestive that the decoding results could be driven by head movement or other artefacts.</p>
<p>Head movement artefacts are highly unlikely to contribute meaningfully to our results for the following reasons. First, in addition to ICA denoising, all “recordings were visually inspected and marked to denoise segments containing other large amplitude artifacts due to movements” (see Methods). Second, the response pad was positioned in a manner that minimized wrist, arm or more proximal body movements during the task. Third, while head position was not monitored online for this study, the head was restrained using an inflatable air bladder, and head position was assessed at the beginning and at the end of each recording. Head movement did not exceed 5mm between the beginning and end of each scan for all participants included in the study. Fourth, we agree that despite the steps taken above, it is possible that minor head movements could still contribute to some remaining variance in the MEG data in our study. The Reviewer states a concern that “it is conceivable that small head movements would correlate highly with the vigor of individual finger movements”. However, in order for any such correlations to meaningfully impact decoding performance, such head movements would need to: (A) be consistent and pervasive throughout the recording (which might not be the case if the head movements were related to movement vigor and vigor changed over time); and (B) systematically vary between different finger movements, and also between the same finger movement performed at different sequence locations (see 5-class decoding performance in Figure 4B). The possibility of any head movement artefacts meeting all these conditions is extremely unlikely.</p>
<p>Given the task design, a much more likely confound in our estimation would be the contribution of eye movement artefacts to the decoder performance (an issue appropriately raised by Reviewer #3 in the comments below). Remember from Figure 1A in the manuscript that an asterisk marks the current position in the sequence and is updated at each keypress. Since participants make very few performance errors, the position of the asterisk on the display is highly correlated with the keypress being made in the sequence. Thus, it is possible that if participants are attending to the visual feedback provided on the display, they may move their eyes in a way that is systematically related to the task.  Since we did record eye movements simultaneously with the MEG recordings (EyeLink 1000 Plus; Fs = 600 Hz), we were able to perform a control analysis to address this question. For each keypress event during trials in which no errors occurred (which is the same time-point that the asterisk position is updated), we extracted three features related to eye movements: 1) the gaze position at the time of asterisk position update (or keyDown event), 2) the gaze position 150ms later, and 3) the peak velocity of the eye movement between the two positions. We then constructed a classifier from these features with the aim of predicting the location of the asterisk (ordinal positions 1-5) on the display. As shown in the confusion matrix below (Author response image 1), the classifier failed to perform above chance levels (Overall cross-validated accuracy = 0.21817):</p>
<fig id="sa4fig1">
<label>Author response image 1.</label>
<caption>
<title>Confusion matrix showing that three eye movement features fail to predict asterisk position on the task display above chance levels (Fold 1 test accuracy = 0.</title>
<p>21718; Fold 2 test accuracy = 0.22023; Fold 3 test accuracy = 0.21859; Fold 4 test accuracy = 0.22113; Fold 5 test accuracy = 0.21373; Overall cross-validated accuracy = 0.2181). Since the ordinal position of the asterisk on the display is highly correlated with the ordinal position of individual keypresses in the sequence, this analysis provides strong evidence that keypress decoding performance from MEG features is not explained by systematic relationships between finger movement behavior and eye movements (i.e. – behavioral artefacts).</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig1.jpg" mimetype="image"/>
</fig>
<p>In fact, inspection of the eye position data revealed that a majority of participants on most trials displayed random walk gaze patterns around a center fixation point, indicating that participants did not attend to the asterisk position on the display. This is consistent with intrinsic generation of the action sequence, and congruent with the fact that the display does not provide explicit feedback related to performance. A similar real-world example would be manually inputting a long password into a secure online application. In this case, one intrinsically generates the sequence from memory and receives similar feedback about the password sequence position (also provided as asterisks), which is typically ignored by the user. The minimal participant engagement with the visual task display observed in this study highlights another important point – that the behavior in explicit sequence learning motor tasks is highly generative in nature rather than reactive to stimulus cues as in the serial reaction time task (SRTT).  This is a crucial difference that must be carefully considered when designing investigations and comparing findings across studies.</p>
<p>We observed that initial keypress decoding accuracy was predominantly driven by contralateral primary sensorimotor cortex in the initial practice trials before transitioning to bilateral frontoparietal regions by trials 11 or 12 as performance gains plateaued.  The contribution of contralateral primary sensorimotor areas to early skill learning has been extensively reported in humans and non-human animals. 1,3-5  Similarly, the increased involvement of bilateral frontal and parietal regions to decoding during early skill learning in the non-dominant hand is well known.  Enhanced bilateral activation in both frontal and parietal cortex during skill learning has been extensively reported6-11, and appears to be even more prominent during early fine motor skill learning in the non-dominant hand12,13.  The frontal regions identified in these studies are known to play crucial roles in executive control14, motor planning15, and working memory6,8,16-18 processes, while the same parietal regions are known to integrate multimodal sensory feedback and support visuomotor transformations6,8,16-18, in addition to working memory19. Thus, it is not surprising that these regions increasingly contribute to decoding as subjects internalize the sequential task.  We now include a statement reflecting these considerations in the revised Discussion.</p>
<disp-quote content-type="editor-comment">
<p>A somewhat related point is this: when combining voxel and parcel space, a concern is whether a degree of circularity may have contributed to the improved accuracy of the combined data, because it seems to use the same MEG signals twice - the voxels most contributing are also those contributing most to a parcel being identified as relevant, as parcels reflect the average of voxels within a boundary. In this context, I struggled to understand the explanation given, ie that the improved accuracy of the hybrid model may be due to &quot;lower spatially resolved whole-brain and higher spatially resolved regional activity patterns&quot;.</p>
</disp-quote>
<p>We strongly disagree with the Reviewer’s assertion that the construction of the hybrid-space decoder is circular. To clarify, the base feature set for the hybrid-space decoder constructed for all participants includes whole-brain spatial patterns of MEG source activity averaged within parcels. As stated in the manuscript, these 148 inter-parcel features reflect “lower spatially resolved whole-brain activity patterns” or global brain dynamics. We then independently test how well spatial patterns of MEG source activity for all voxels distributed within individual parcels can decode keypress actions. Again, the testing of these intra-parcel spatial patterns, intended to capture “higher spatially resolved regional brain activity patterns”, is completely independent from one another and independent from the weighting of individual inter-parcel features. These intra-parcel features could, for example, provide additional information about muscle activation patterns or the task environment. These approximately 1150 intra-parcel voxels (on average, within the total number varying between subjects) are then combined with the 148 inter-parcel features to construct the final hybrid-space decoder. In fact, this varied spatial filter approach shares some similarities to the construction of convolutional neural networks (CNNs) used to perform object recognition in image classification applications. One could also view this hybrid-space decoding approach as a spatial analogue to common time-frequency based analyses such as theta-gamma phase amplitude coupling (PAC), which combine information from two or more narrow-band spectral features derived from the same time-series data.</p>
<p>We directly tested this hypothesis – that spatially overlapping intra- and inter-parcel features portray different information – by constructing an alternative hybrid-space decoder (HybridAlt) that excluded average inter-parcel features which spatially overlapped with intra-parcel voxel features, and comparing the performance to the decoder used in the manuscript (HybridOrig). The prediction was that if the overlapping parcel contained similar information to the more spatially resolved voxel patterns, then removing the parcel features (n=8) from the decoding analysis should not impact performance. In fact, despite making up less than 1% of the overall input feature space, removing those parcels resulted in a significant drop in overall performance greater than 2% (78.15% ± SD 7.03% for HybridOrig vs. 75.49% ± SD 7.17% for HybridAlt; Wilcoxon signed rank test, z = 3.7410, p = 1.8326e-04) (Author response image 2).</p>
<fig id="sa4fig2">
<label>Author response image 2.</label>
<caption>
<title>Comparison of decoding performances with two different hybrid approaches.</title>
<p>HybridAlt: Intra-parcel voxel-space features of top ranked parcels and inter-parcel features of remaining parcels. HybridOrig:  Voxel-space features of top ranked parcels and whole-brain parcel-space features (i.e. – the version used in the manuscript). Dots represent decoding accuracy for individual subjects. Dashed lines indicate the trend in performance change across participants. Note, that HybridOrig (the approach used in our manuscript) significantly outperforms the HybridAlt approach, indicating that the excluded parcel features provide unique information compared to the spatially overlapping intra-parcel voxel patterns.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig2.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>Firstly, there will be a relatively high degree of spatial contiguity among voxels because of the nature of the signal measured, i.e. nearby individual voxels are unlikely to be independent. Secondly, the voxel data gives a somewhat misleading sense of precision; the inversion can be set up to give an estimate for each voxel, but there will not just be dependence among adjacent voxels, but also substantial variation in the sensitivity and confidence with which activity can be projected to different parts of the brain. Midline and deeper structures come to mind, where the inversion will be more problematic than for regions along the dorsal convexity of the brain, and a concern is that in those midline structures, the highest decoding accuracy is seen.</p>
</disp-quote>
<p>We definitely agree with the Reviewer that some inter-parcel features representing neighboring (or spatially contiguous) voxels are likely to be correlated. This has been well documented in the MEG literature20,21 and is a particularly important confound to address in functional or effective connectivity analyses (not performed in the present study). In the present analysis, any correlation between adjacent voxels presents a multi-collinearity problem, which effectively reduces the dimensionality of the input feature space. However, as long as there are multiple groups of correlated voxels within each parcel (i.e. - the effective dimensionality is still greater than 1), the intra-parcel spatial patterns could still meaningfully contribute to the decoder performance. Two specific results support this assertion.</p>
<p>First, we obtained higher decoding accuracy with voxel-space features [74.51% (± SD 7.34%)] compared to parcel space features [68.77% (± SD 7.6%)] (Figure 3B), indicating individual voxels carry more information in decoding the keypresses than the averaged voxel-space features or parcel-space features.  Second, Individual voxels within a parcel showed varying feature importance scores in decoding keypresses (Author response image 3). This finding supports the Reviewer’s assertion that neighboring voxels express similar information, but also shows that the correlated voxels form mini subclusters that are much smaller spatially than the parcel they reside in.</p>
<fig id="sa4fig3">
<label>Author response image 3.</label>
<caption>
<title>Feature importance score of individual voxels in decoding keypresses: MRMR was used to rank the individual voxel space features in decoding keypresses and the min-max normalized MRMR score was mapped to a structural brain surface.</title>
<p>Note that individual voxels within a parcel showed different contribution to decoding.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig3.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>Some of these concerns could be addressed by recording head movement (with enough precision) to regress out these contributions. The authors state that head movement was monitored with 3 fiducials, and their time courses ought to provide a way to deal with this issue. The ICA procedure may not have sufficiently dealt with removing movement-related problems, but one could eg relate individual components that were identified to the keypresses as another means for checking. An alternative could be to focus on frequency ranges above the movement frequencies. The accuracy for those still seems impressive and may provide a slightly more biologically plausible assessment.</p>
</disp-quote>
<p>We have already addressed the issue of movement related artefacts in the first response above. With respect to a focus on frequency ranges above movement frequencies, the Reviewer states the “accuracy for those still seems impressive and may provide a slightly more biologically plausible assessment”. First, it is important to note that cortical delta-band oscillations measured with local field potentials (LFPs) in macaques is known to contain important information related to end-effector kinematics22,23 muscle activation patterns24 and temporal sequencing25 during skilled reaching and grasping actions. Thus, there is a substantial body of evidence that low-frequency neural oscillatory activity in this range contains important information about the skill learning behavior investigated in the present study. Second, our own data shows (which the Reviewer also points out) that significant information related to the skill learning behavior is also present in higher frequency bands (see Figure 2A and Figure 3—figure supplement 1). As we pointed out in our earlier response to questions about the hybrid space decoder architecture (see above), it is likely that different, yet complimentary, information is encoded across different temporal frequencies (just as it is encoded across different spatial frequencies). Again, this interpretation is supported by our data as the highest performing classifiers in all cases (when holding all parameters constant) were always constructed from broadband input MEG data (Figure 2A and Figure 3—figure supplement 1).</p>
<disp-quote content-type="editor-comment">
<p>One question concerns the interpretation of the results shown in Figure 4. They imply that during the course of learning, entirely different brain networks underpin the behaviour. Not only that, but they also include regions that would seem rather unexpected to be key nodes for learning and expressing relatively simple finger sequences, such as here. What then is the biological plausibility of these results? The authors seem to circumnavigate this issue by moving into a distance metric that captures the (neural network) changes over the course of learning, but the discussion seems detached from which regions are actually involved; or they offer a rather broad discussion of the anatomical regions identified here, eg in the context of LFOs, where they merely refer to &quot;frontoparietal regions&quot;.</p>
</disp-quote>
<p>The Reviewer notes the shift in brain networks driving keypress decoding performance between trials 1, 11 and 36 as shown in Figure 4A. The Reviewer questions whether these substantial shifts in brain network states underpinning the skill are biologically plausible, as well as the likelihood that bilateral superior and middle frontal and parietal cortex are important nodes within these networks.</p>
<p>First, previous fMRI work in humans performing a similar sequence learning task showed that flexibility in brain network composition (i.e. – changes in brain region members displaying coordinated activity) is up-regulated in novel learning environments and explains differences in learning rates across individuals26.  This work supports our interpretation of the present study data, that brain networks engaged in sequential motor skills rapidly reconfigure during early learning.</p>
<p>Second, frontoparietal network activity is known to support motor memory encoding during early learning27,28. For example, reactivation events in the posterior parietal29 and medial prefrontal30,31 cortex (MPFC) have been temporally linked to hippocampal replay, and are posited to support memory consolidation across several memory domains32, including motor sequence learning1,33,34.  Further, synchronized interactions between MPFC and hippocampus are more prominent during early learning as opposed to later stages27,35,36, perhaps reflecting “redistribution of hippocampal memories to MPFC” 27.  MPFC contributes to very early memory formation by learning association between contexts, locations, events and adaptive responses during rapid learning37. Consistently, coupling between hippocampus and MPFC has been shown during, and importantly immediately following (rest) initial memory encoding38,39.  Importantly, MPFC activity during initial memory encoding predicts subsequent recall40. Thus, the spatial map required to encode a motor sequence memory may be “built under the supervision of the prefrontal cortex” 28, also engaged in the development of an abstract representation of the sequence41.  In more abstract terms, the prefrontal, premotor and parietal cortices support novice performance “by deploying attentional and control processes” 42-44 required during early learning42-44. The dorsolateral prefrontal cortex DLPFC specifically is thought to engage in goal selection and sequence monitoring during early skill practice45, all consistent with the schema model of declarative memory in which prefrontal cortices play an important role in encoding46,47.  Thus, several prefrontal and frontoparietal regions contributing to long term learning 48 are also engaged in early stages of encoding. Altogether, there is strong biological support for the involvement of bilateral prefrontal and frontoparietal regions to decoding during early skill learning.  We now address this issue in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>If I understand correctly, the offline neural representation analysis is in essence the comparison of the last keypress vs the first keypress of the next sequence. In that sense, the activity during offline rest periods is actually not considered. This makes the nomenclature somewhat confusing. While it matches the behavioural analysis, having only key presses one can't do it in any other way, but here the authors actually do have recordings of brain activity during offline rest. So at the very least calling it offline neural representation is misleading to this reviewer because what is compared is activity during the last and during the next keypress, not activity during offline periods. But it also seems a missed opportunity - the authors argue that most of the relevant learning occurs during offline rest periods, yet there is no attempt to actually test whether activity during this period can be useful for the questions at hand here.</p>
</disp-quote>
<p>We agree with the Reviewer that our previous “offline neural representation” nomenclature could be misinterpreted. In the revised manuscript we refer to this difference as the “offline neural representational change”. Please, note that our previous work did link offline neural activity (i.e. – 16-22 Hz beta power and neural replay density during inter-practice rest periods) to observed micro-offline gains49.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary</p>
<p>Dash et al. asked whether and how the neural representation of individual finger movements is &quot;contextualized&quot; within a trained sequence during the very early period of sequential skill learning by using decoding of MEG signal. Specifically, they assessed whether/how the same finger presses (pressing index finger) embedded in the different ordinal positions of a practiced sequence (4-1-3-2-4; here, the numbers 1 through 4 correspond to the little through the index fingers of the non-dominant left hand) change their representation (MEG feature). They did this by computing either the decoding accuracy of the index finger at the ordinal positions 1 vs. 5 (index_OP1 vs index_OP5) or pattern distance between index_OP1 vs. index_OP5 at each training trial and found that both the decoding accuracy and the pattern distance progressively increase over the course of learning trials. More interestingly, they also computed the pattern distance for index_OP5 for the last execution of a practice trial vs. index_OP1 for the first execution in the next practice trial (i.e., across the rest period). This &quot;off-line&quot; distance was significantly larger than the &quot;on-line&quot; distance, which was computed within practice trials and predicted micro-offline skill gain. Based on these results, the authors conclude that the differentiation of representation for the identical movement embedded in different positions of a sequential skill (&quot;contextualization&quot;) primarily occurs during early skill learning, especially during rest, consistent with the recent theory of the &quot;micro-offline learning&quot; proposed by the authors' group. I think this is an important and timely topic for the field of motor learning and beyond.</p>
<p>
Strengths</p>
<p>The specific strengths of the current work are as follows. First, the use of temporally rich neural information (MEG signal) has a large advantage over previous studies testing sequential representations using fMRI. This allowed the authors to examine the earliest period (= the first few minutes of training) of skill learning with finer temporal resolution. Second, through the optimization of MEG feature extraction, the current study achieved extremely high decoding accuracy (approx. 94%) compared to previous works. As claimed by the authors, this is one of the strengths of the paper (but see my comments). Third, although some potential refinement might be needed, comparing &quot;online&quot; and &quot;offline&quot; pattern distance is a neat idea.</p>
<p>Weaknesses</p>
<p>Along with the strengths I raised above, the paper has some weaknesses. First, the pursuit of high decoding accuracy, especially the choice of time points and window length (i.e., 200 msec window starting from 0 msec from key press onset), casts a shadow on the interpretation of the main result. Currently, it is unclear whether the decoding results simply reflect behavioral change or true underlying neural change. As shown in the behavioral data, the key press speed reached 3~4 presses per second already at around the end of the early learning period (11th trial), which means inter-press intervals become as short as 250-330 msec. Thus, in almost more than 60% of training period data, the time window for MEG feature extraction (200 msec) spans around 60% of the inter-press intervals. Considering that the preparation/cueing of subsequent presses starts ahead of the actual press (e.g., Kornysheva et al., 2019) and/or potential online planning (e.g., Ariani and Diedrichsen, 2019), the decoder likely has captured these future press information as well as the signal related to the current key press, independent of the formation of genuine sequential representation (e.g., &quot;contextualization&quot; of individual press). This may also explain the gradual increase in decoding accuracy or pattern distance between index_OP1 vs. index_OP5 (Figure 4C and 5A), which co-occurred with performance improvement, as shorter inter-press intervals are more favorable for the dissociating the two index finger presses followed by different finger presses. The compromised decoding accuracies for the control sequences can be explained in similar logic. Therefore, more careful consideration and elaborated discussion seem necessary when trying to both achieve high-performance decoding and assess early skill learning, as it can impact all the subsequent analyses.</p>
</disp-quote>
<p>The Reviewer raises the possibility that (given the windowing parameters used in the present study) an increase in “contextualization” with learning could simply reflect faster typing speeds as opposed to an actual change in the underlying neural representation. The issue can essentially be framed as a mixing problem. As correct sequences are generated at higher and higher speeds over training, MEG activity patterns related to the planning, execution, evaluation and memory of individual keypresses overlap more in time. Thus, increased overlap between the “4” and “1” keypresses (at the start of the sequence) and “2” and “4” keypresses (at the end of the sequence) could artefactually increase contextualization distances even if the underlying neural representations for the individual keypresses remain unchanged (assuming this mixing of representations is used by the classifier to differentially tag each index finger press). If this were the case, it follows that such mixing effects reflecting the ordinal sequence structure would also be observable in the distribution of decoder misclassifications. For example, “4” keypresses would be more likely to be misclassified as “1” or “2” keypresses (or vice versa) than as “3” keypresses. The confusion matrices presented in Figures 3C and 4B and Figure 3—figure supplement 3A in the previously submitted manuscript do not show this trend in the distribution of misclassifications across the four fingers.</p>
<p>Moreover, if the representation distance is largely driven by this mixing effect, it’s also possible that the increased overlap between consecutive index finger keypresses during the 4-4 transition marking the end of one sequence and the beginning of the next one could actually mask contextualization-related changes to the underlying neural representations and make them harder to detect. In this case, a decoder tasked with separating individual index finger keypresses into two distinct classes based upon sequence position might show decreased performance with learning as adjacent keypresses overlapped in time with each other to an increasing extent. However, Figure 4C in our previously submitted manuscript does not support this possibility, as the 2-class hybrid classifier displays improved classification performance over early practice trials despite greater temporal overlap.</p>
<p>We also conducted a new multivariate regression analysis to directly assess whether the neural representation distance score could be predicted by the 4-1, 2-4 and 4-4 keypress transition times observed for each complete correct sequence (both predictor and response variables were z-score normalized within-subject). The results of this analysis affirmed that the possible alternative explanation put forward by the Reviewer is not supported by our data (Adjusted R2 = 0.00431; F = 5.62). We now include this new negative control analysis result in the revised manuscript.</p>
<p>Overall, we do strongly agree with the Reviewer that the naturalistic, self-paced, generative task employed in the present study results in overlapping brain processes related to planning, execution, evaluation and memory of the action sequence. We also agree that there are several tradeoffs to consider in the construction of the classifiers depending on the study aim. Given our aim of optimizing keypress decoder accuracy in the present study, the set of trade-offs resulted in representations reflecting more the latter three processes, and less so the planning component. Whether separate decoders can be constructed to tease apart the representations or networks supporting these overlapping processes is an important future direction of research in this area. For example, work presently underway in our lab constrains the selection of windowing parameters in a manner that allows individual classifiers to be temporally linked to specific planning, execution, evaluation or memory-related processes to discern which brain networks are involved and how they adaptively reorganize with learning. Results from the present study (Figure 4—figure supplement 2) showing hybrid-space decoder prediction accuracies exceeding 74% for temporal windows spanning as little as 25ms and located up to 100ms prior to the keyDown event strongly support the feasibility of such an approach.</p>
<disp-quote content-type="editor-comment">
<p>Related to the above point, testing only one particular sequence (4-1-3-2-4), aside from the control ones, limits the generalizability of the finding. This also may have contributed to the extremely high decoding accuracy reported in the current study.</p>
</disp-quote>
<p>The Reviewer raises a question about the generalizability of the decoder accuracy reported in our study. Fortunately, a comparison between decoder performances on Day 1 and Day 2 datasets does provide some insight into this issue. As the Reviewer points out, the classifiers in this study were trained and tested on keypresses performed while practicing a specific sequence (4-1-3-2-4). The study was designed this way as to avoid the impact of interference effects on learning dynamics. The cross-validated performance of classifiers on MEG data collected within the same session was 90.47% overall accuracy (4-class; Figure 3C). We then tested classifier performance on data collected during a separate MEG session conducted approximately 24 hours later (Day 2; see Figure 3—supplement 3). We observed a reduction in overall accuracy rate to 87.11% when tested on MEG data recorded while participants performed the same learned sequence, and 79.44% when they performed several previously unpracticed sequences. Both changes in accuracy are important with regards to the generalizability of our findings. First, 87.11% performance accuracy for the trained sequence data on Day 2 (a reduction of only 3.36%) indicates that the hybrid-space decoder performance is robust over multiple MEG sessions, and thus, robust to variations in SNR across the MEG sensor array caused by small differences in head position between scans.  This indicates a substantial advantage over sensor-space decoding approaches. Furthermore, when tested on data from unpracticed sequences, overall performance dropped an additional 7.67%. This difference reflects the performance bias of the classifier for the trained sequence, possibly caused by high-order sequence structure being incorporated into the feature weights. In the future, it will be important to understand in more detail how random or repeated keypress sequence training data impacts overall decoder performance and generalization. We strongly agree with the Reviewer that the issue of generalizability is extremely important and have added a new paragraph to the Discussion in the revised manuscript highlighting the strengths and weaknesses of our study with respect to this issue.</p>
<disp-quote content-type="editor-comment">
<p>In terms of clinical BCI, one of the potential relevance of the study, as claimed by the authors, it is not clear that the specific time window chosen in the current study (up to 200 msec since key press onset) is really useful. In most cases, clinical BCI would target neural signals with no overt movement execution due to patients' inability to move (e.g., Hochberg et al., 2012). Given the time window, the surprisingly high performance of the current decoder may result from sensory feedback and/or planning of subsequent movement, which may not always be available in the clinical BCI context. Of course, the decoding accuracy is still much higher than chance even when using signal before the key press (as shown in Figure 4 Supplement 2), but it is not immediately clear to me that the authors relate their high decoding accuracy based on post-movement signal to clinical BCI settings.</p>
</disp-quote>
<p>The Reviewer questions the relevance of the specific window parameters used in the present study for clinical BCI applications, particularly for paretic patients who are unable to produce finger movements or for whom afferent sensory feedback is no longer intact. We strongly agree with the Reviewer that any intended clinical application must carefully consider these specific input feature constraints dictated by the clinical cohort, and in turn impose appropriate and complimentary constraints on classifier parameters that may differ from the ones used in the present study.  We now highlight this issue in the Discussion of the revised manuscript and relate our present findings to published clinical BCI work within this context.</p>
<disp-quote content-type="editor-comment">
<p>One of the important and fascinating claims of the current study is that the &quot;contextualization&quot; of individual finger movements in a trained sequence specifically occurs during short rest periods in very early skill learning, echoing the recent theory of micro-offline learning proposed by the authors' group. Here, I think two points need to be clarified. First, the concept of &quot;contextualization&quot; is kept somewhat blurry throughout the text. It is only at the later part of the Discussion (around line #330 on page 13) that some potential mechanism for the &quot;contextualization&quot; is provided as &quot;what-and-where&quot; binding. Still, it is unclear what &quot;contextualization&quot; actually is in the current data, as the MEG signal analyzed is extracted from 0-200 msec after the keypress. If one thinks something is contextualizing an action, that contextualization should come earlier than the action itself.</p>
</disp-quote>
<p>The Reviewer requests that we: 1) more clearly define our use of the term “contextualization” and 2) provide the rationale for assessing it over a 200ms window aligned to the keyDown event. This choice of window parameters means that the MEG activity used in our analysis was coincident with, rather than preceding, the actual keypresses.  We define contextualization as the differentiation of representation for the identical movement embedded in different positions of a sequential skill. That is, representations of individual action elements progressively incorporate information about their relationship to the overall sequence structure as the skill is learned. We agree with the Reviewer that this can be appropriately interpreted as “what-and-where” binding. We now incorporate this definition in the Introduction of the revised manuscript as requested.</p>
<p>The window parameters for optimizing accurate decoding individual finger movements were determined using a grid search of the parameter space (a sliding window of variable width between 25-350 ms with 25 ms increments variably aligned from 0 to +100ms with 10ms increments relative to the keyDown event). This approach generated 140 different temporal windows for each keypress for each participant, with the final parameter selection determined through comparison of the resulting performance between each decoder.  Importantly, the decision to optimize for decoding accuracy placed an emphasis on keypress representations characterized by the most consistent and robust features shared across subjects, which in turn maximize statistical power in detecting common learning-related changes. In this case, the optimal window encompassed a 200ms epoch aligned to the keyDown event (t0 = 0 ms).  We then asked if the representations (i.e. – spatial patterns of combined parcel- and voxel-space activity) of the same digit at two different sequence positions changed with practice within this optimal decoding window.  Of course, our findings do not rule out the possibility that contextualization can also be found before or even after this time window, as we did not directly address this issue in the present study.  Ongoing work in our lab, as pointed out above, is investigating contextualization within different time windows tailored specifically for assessing sequence skill action planning, execution, evaluation and memory processes.</p>
<disp-quote content-type="editor-comment">
<p>The second point is that the result provided by the authors is not yet convincing enough to support the claim that &quot;contextualization&quot; occurs during rest. In the original analysis, the authors presented the statistical significance regarding the correlation between the &quot;offline&quot; pattern differentiation and micro-offline skill gain (Figure 5. Supplement 1), as well as the larger &quot;offline&quot; distance than &quot;online&quot; distance (Figure 5B). However, this analysis looks like regressing two variables (monotonically) increasing as a function of the trial. Although some information in this analysis, such as what the independent/dependent variables were or how individual subjects were treated, was missing in the Methods, getting a statistically significant slope seems unsurprising in such a situation. Also, curiously, the same quantitative evidence was not provided for its &quot;online&quot; counterpart, and the authors only briefly mentioned in the text that there was no significant correlation between them. It may be true looking at the data in Figure 5A as the online representation distance looks less monotonically changing, but the classification accuracy presented in Figure 4C, which should reflect similar representational distance, shows a more monotonic increase up to the 11th trial. Further, the ways the &quot;online&quot; and &quot;offline&quot; representation distance was estimated seem to make them not directly comparable. While the &quot;online&quot; distance was computed using all the correct press data within each 10 sec of execution, the &quot;offline&quot; distance is basically computed by only two presses (i.e., the last index_OP5 vs. the first index_OP1 separated by 10 sec of rest). Theoretically, the distance between the neural activity patterns for temporally closer events tends to be closer than that between the patterns for temporally far-apart events. It would be fairer to use the distance between the first index_OP1 vs. the last index_OP5 within an execution period for &quot;online&quot; distance, as well.</p>
</disp-quote>
<p>The Reviewer suggests that the current data is not convincing enough to show that contextualization occurs during rest and raises two important concerns: 1) the relationship between online contextualization and micro-online gains is not shown, and 2) the online distance was calculated differently from its offline counterpart (i.e. - instead of calculating the distance between last IndexOP5 and first IndexOP1 from a single trial, the distance was calculated for each sequence within a trial and then averaged).</p>
<p>We addressed the first concern by performing individual subject correlations between 1) contextualization changes during rest intervals and micro-offline gains; 2) contextualization changes during practice trials and micro-online gains, and 3) contextualization changes during practice trials and micro-offline gains (Author response image 4). We then statistically compared the resulting correlation coefficient distributions and found that within-subject correlations for contextualization changes during rest intervals and micro-offline gains were significantly higher than online contextualization and micro-online gains (t = 3.2827, p = 0.0015) and online contextualization and micro-offline gains (t = 3.7021, p = 5.3013e-04). These results are consistent with our interpretation that micro-offline gains are supported by contextualization changes during the inter-practice rest period.</p>
<fig id="sa4fig4">
<label>Author response image 4.</label>
<caption>
<title>Distribution of individual subject correlation coefficients between contextualization changes occurring during practice or rest with  micro-online and micro-offline performance gains.</title>
<p>Note that, the correlation distributions were significantly higher for the relationship between contextualization changes during rest and micro-offline gains than for contextualization changes during practice and either micro-online or offline gain.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig4.jpg" mimetype="image"/>
</fig>
<p>With respect to the second concern highlighted above, we agree with the Reviewer that one limitation of the analysis comparing online versus offline changes in contextualization as presented in the reviewed manuscript, is that it does not eliminate the possibility that any differences could simply be explained by the passage of time (which is smaller for the online analysis compared to the offline analysis). The Reviewer suggests an approach that addresses this issue, which we have now carried out.   When quantifying online changes in contextualization from the first IndexOP1 the last IndexOP5 keypress in the same trial we observed no learning-related trend (Author response image 5, right panel). Importantly, offline distances were significantly larger than online distances regardless of the measurement approach and neither predicted online learning (Author response image 6).</p>
<fig id="sa4fig5">
<label>Author response image 5.</label>
<caption>
<title>Trial by trial trend of offline (left panel) and online (middle and right panels) changes in contextualization.</title>
<p>Offline changes in contextualization were assessed by calculating the distance between neural representations for the last IndexOP5 keypress in the previous trial and the first IndexOP1 keypress in the present trial. Two different approaches were used to characterize online contextualization changes. The analysis included in the reviewed manuscript (middle panel) calculated the distance between IndexOP1 and IndexOP5 for each correct sequence, which was then averaged across the trial. This approach is limited by the lack of control for the passage of time when making online versus offline comparisons. Thus, the second approach controlled for the passage of time by calculating distance between the representations associated with the first IndexOP1 keypress and the last IndexOP5 keypress within the same trial. Note that while the first approach showed an increase online contextualization trend with practice, the second approach did not.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig5.jpg" mimetype="image"/>
</fig>
<fig id="sa4fig6">
<label>Author response image 6.</label>
<caption>
<title>Relationship between online contextualization and online learning is shown for both within-sequence (left; note that this is the online contextualization measure used in the reviewd manuscript) and across-sequence (right) distance calculation.</title>
<p>There was no significant relationship between online learning and online contextualization regardless of the measurement approach.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig6.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>A related concern regarding the control analysis, where individual values for max speed and the degree of online contextualization were compared (Figure 5 Supplement 3), is whether the individual difference is meaningful. If I understood correctly, the optimization of the decoding process (temporal window, feature inclusion/reduction, decoder, etc.) was performed for individual participants, and the same feature extraction was also employed for the analysis of representation distance (i.e., contextualization). If this is the case, the distances are individually differently calculated and they may need to be normalized relative to some stable reference (e.g., 1 vs. 4 or average distance within the control sequence presses) before comparison across the individuals.</p>
</disp-quote>
<p>The Reviewer makes a good point here. We have now implemented the suggested normalization procedure in the analysis provided in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Summary:</p>
<p>One goal of this paper is to introduce a new approach for highly accurate decoding of finger movements from human magnetoencephalography data via dimension reduction of a &quot;multi-scale, hybrid&quot; feature space. Following this decoding approach, the authors aim to show that early skill learning involves &quot;contextualization&quot; of the neural coding of individual movements, relative to their position in a sequence of consecutive movements. Furthermore, they aim to show that this &quot;contextualization&quot; develops primarily during short rest periods interspersed with skill training and correlates with a performance metric which the authors interpret as an indicator of offline learning.</p>
<p>
Strengths:</p>
<p>A clear strength of the paper is the innovative decoding approach, which achieves impressive decoding accuracies via dimension reduction of a &quot;multi-scale, hybrid space&quot;. This hybrid-space approach follows the neurobiologically plausible idea of the concurrent distribution of neural coding across local circuits as well as large-scale networks. A further strength of the study is the large number of tested dimension reduction techniques and classifiers (though the manuscript reveals little about the comparison of the latter).</p>
</disp-quote>
<p>We appreciate the Reviewer’s comments regarding the paper’s strengths.</p>
<disp-quote content-type="editor-comment">
<p>A simple control analysis based on shuffled class labels could lend further support to this complex decoding approach. As a control analysis that completely rules out any source of overfitting, the authors could test the decoder after shuffling class labels. Following such shuffling, decoding accuracies should drop to chance level for all decoding approaches, including the optimized decoder. This would also provide an estimate of actual chance-level performance (which is informative over and beyond the theoretical chance level). Furthermore, currently, the manuscript does not explain the huge drop in decoding accuracies for the voxel-space decoding (Figure 3B). Finally, the authors' approach to cortical parcellation raises questions regarding the information carried by varying dipole orientations within a parcel (which currently seems to be ignored?) and the implementation of the mean-flipping method (given that there are two dimensions - space and time - what do the authors refer to when they talk about the sign of the &quot;average source&quot;, line 477?).</p>
</disp-quote>
<p>The Reviewer recommends that we: 1) conduct an additional control analysis on classifier performance using shuffled class labels, 2) provide a more detailed explanation regarding the drop in decoding accuracies for the voxel-space decoding following LDA dimensionality reduction (see Fig 3B), and 3) provide additional details on how problems related to dipole solution orientations were addressed in the present study.</p>
<p>In relation to the first point, we have now implemented a random shuffling approach as a control for the classification analyses. The results of this analysis indicated that the chance level accuracy was 22.12% (± SD 9.1%) for individual keypress decoding (4-class classification), and 18.41% (± SD 7.4%) for individual sequence item decoding (5-class classification), irrespective of the input feature set or the type of decoder used. Thus, the decoding accuracy observed with the final model was substantially higher than these chance levels.</p>
<p>Second, please note that the dimensionality of the voxel-space feature set is very high (i.e. – 15684). LDA attempts to map the input features onto a much smaller dimensional space (number of classes-1; e.g. –  3 dimensions, for 4-class keypress decoding). Given the very high dimension of the voxel-space input features in this case, the resulting mapping exhibits reduced accuracy. Despite this general consideration, please refer to Figure 3—figure supplement 3, where we observe improvement in voxel-space decoder performance when utilizing alternative dimensionality reduction techniques.</p>
<p>The decoders constructed in the present study assess the average spatial patterns across time (as defined by the windowing procedure) in the input feature space.  We now provide additional details in the Methods of the revised manuscript pertaining to the parcellation procedure and how the sign ambiguity problem was addressed in our analysis.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>A clear weakness of the paper lies in the authors' conclusions regarding &quot;contextualization&quot;. Several potential confounds, described below, question the neurobiological implications proposed by the authors and provide a simpler explanation of the results. Furthermore, the paper follows the assumption that short breaks result in offline skill learning, while recent evidence, described below, casts doubt on this assumption.</p>
</disp-quote>
<p>We thank the Reviewer for giving us the opportunity to address these issues in detail (see below).</p>
<disp-quote content-type="editor-comment">
<p>The authors interpret the ordinal position information captured by their decoding approach as a reflection of neural coding dedicated to the local context of a movement (Figure 4). One way to dissociate ordinal position information from information about the moving effectors is to train a classifier on one sequence and test the classifier on other sequences that require the same movements, but in different positions50. In the present study, however, participants trained to repeat a single sequence (4-1-3-2-4). As a result, ordinal position information is potentially confounded by the fixed finger transitions around each of the two critical positions (first and fifth press). Across consecutive correct sequences, the first keypress in a given sequence was always preceded by a movement of the index finger (=last movement of the preceding sequence), and followed by a little finger movement. The last keypress, on the other hand, was always preceded by a ring finger movement, and followed by an index finger movement (=first movement of the next sequence). Figure 4 - Supplement 2 shows that finger identity can be decoded with high accuracy (&gt;70%) across a large time window around the time of the key press, up to at least +/-100 ms (and likely beyond, given that decoding accuracy is still high at the boundaries of the window depicted in that figure). This time window approaches the keypress transition times in this study. Given that distinct finger transitions characterized the first and fifth keypress, the classifier could thus rely on persistent (or &quot;lingering&quot;) information from the preceding finger movement, and/or &quot;preparatory&quot; information about the subsequent finger movement, in order to dissociate the first and fifth keypress. Currently, the manuscript provides no evidence that the context information captured by the decoding approach is more than a by-product of temporally extended, and therefore overlapping, but independent neural representations of consecutive keypresses that are executed in close temporal proximity - rather than a neural representation dedicated to context.</p>
<p>Such temporal overlap of consecutive, independent finger representations may also account for the dynamics of &quot;ordinal coding&quot;/&quot;contextualization&quot;, i.e., the increase in 2-class decoding accuracy, across Day 1 (Figure 4C). As learning progresses, both tapping speed and the consistency of keypress transition times increase (Figure 1), i.e., consecutive keypresses are closer in time, and more consistently so. As a result, information related to a given keypress is increasingly overlapping in time with information related to the preceding and subsequent keypresses. The authors seem to argue that their regression analysis in Figure 5 - Figure Supplement 3 speaks against any influence of tapping speed on &quot;ordinal coding&quot; (even though that argument is not made explicitly in the manuscript). However, Figure 5 - Figure Supplement 3 shows inter-individual differences in a between-subject analysis (across trials, as in panel A, or separately for each trial, as in panel B), and, therefore, says little about the within-subject dynamics of &quot;ordinal coding&quot; across the experiment. A regression of trial-by-trial &quot;ordinal coding&quot; on trial-by-trial tapping speed (either within-subject or at a group-level, after averaging across subjects) could address this issue. Given the highly similar dynamics of &quot;ordinal coding&quot; on the one hand (Figure 4C), and tapping speed on the other hand (Figure 1B), I would expect a strong relationship between the two in the suggested within-subject (or group-level) regression. Furthermore, learning should increase the number of (consecutively) correct sequences, and, thus, the consistency of finger transitions. Therefore, the increase in 2-class decoding accuracy may simply reflect an increasing overlap in time of increasingly consistent information from consecutive keypresses, which allows the classifier to dissociate the first and fifth keypress more reliably as learning progresses, simply based on the characteristic finger transitions associated with each. In other words, given that the physical context of a given keypress changes as learning progresses - keypresses move closer together in time and are more consistently correct - it seems problematic to conclude that the mental representation of that context changes. To draw that conclusion, the physical context should remain stable (or any changes to the physical context should be controlled for).</p>
</disp-quote>
<p>The issues raised by Reviewer #3 here are similar to two issues raised by Reviewer #2 above and agree they must both be carefully considered in any evaluation of our findings.</p>
<p>As both Reviewers pointed out, the classifiers in this study were trained and tested on keypresses performed while practicing a specific sequence (4-1-3-2-4). The study was designed this way as to avoid the impact of interference effects on learning dynamics. The cross-validated performance of classifiers on MEG data collected within the same session was 90.47% overall accuracy (4-class; Figure 3C). We then tested classifier performance on data collected during a separate MEG session conducted approximately 24 hours later (Day 2; see Figure 3—supplement 3). We observed a reduction in overall accuracy rate to 87.11% when tested on MEG data recorded while participants performed the same learned sequence, and 79.44% when they performed several previously unpracticed sequences. This classification performance difference of 7.67% when tested on the Day 2 data could reflect the performance bias of the classifier for the trained sequence, possibly caused by mixed information from temporally close keypresses being incorporated into the feature weights.</p>
<p>Along these same lines, both Reviewers also raise the possibility that an increase in “ordinal coding/contextualization” with learning could simply reflect an increase in this mixing effect caused by faster typing speeds as opposed to an actual change in the underlying neural representation. The basic idea is that as correct sequences are generated at higher and higher speeds over training, MEG activity patterns related to the planning, execution, evaluation and memory of individual keypresses overlap more in time. Thus, increased overlap between the “4” and “1” keypresses (at the start of the sequence) and “2” and “4” keypresses (at the end of the sequence) could artefactually increase contextualization distances even if the underlying neural representations for the individual keypresses remain unchanged (assuming this mixing of representations is used by the classifier to differentially tag each index finger press). If this were the case, it follows that such mixing effects reflecting the ordinal sequence structure would also be observable in the distribution of decoder misclassifications. For example, “4” keypresses would be more likely to be misclassified as “1” or “2” keypresses (or vice versa) than as “3” keypresses. The confusion matrices presented in Figures 3C and 4B and Figure 3—figure supplement 3A in the previously submitted manuscript do not show this trend in the distribution of misclassifications across the four fingers.</p>
<p>Following this logic, it’s also possible that if the ordinal coding is largely driven by this mixing effect, the increased overlap between consecutive index finger keypresses during the 4-4 transition marking the end of one sequence and the beginning of the next one could actually mask contextualization-related changes to the underlying neural representations and make them harder to detect. In this case, a decoder tasked with separating individual index finger keypresses into two distinct classes based upon sequence position might show decreased performance with learning as adjacent keypresses overlapped in time with each other to an increasing extent. However, Figure 4C in our previously submitted manuscript does not support this possibility, as the 2-class hybrid classifier displays improved classification performance over early practice trials despite greater temporal overlap.</p>
<p>As noted in the above replay to Reviewer #2, we also conducted a new multivariate regression analysis to directly assess whether the neural representation distance score could be predicted by the 4-1, 2-4 and 4-4 keypress transition times observed for each complete correct sequence (both predictor and response variables were z-score normalized within-subject). The results of this analysis affirmed that the possible alternative explanation put forward by the Reviewer is not supported by our data (Adjusted R2 = 0.00431; F = 5.62). We now include this new negative control analysis result in the revised manuscript.</p>
<p>Finally, the Reviewer hints that one way to address this issue would be to compare MEG responses before and after learning for sequences typed at a fixed speed. However, given that the speed-accuracy trade-off should improve with learning, a comparison between unlearned and learned skill states would dictate that the skill be evaluated at a very low fixed speed. Essentially, such a design presents the problem that the post-training test is evaluating the representation in the unlearned behavioral state that is not representative of the acquired skill. Thus, this approach would not address our experimental question: “do neural representations of the same action performed at different locations within a skill sequence contextually differentiate or remain stable as learning evolves”.</p>
<disp-quote content-type="editor-comment">
<p>A similar difference in physical context may explain why neural representation distances (&quot;differentiation&quot;) differ between rest and practice (Figure 5). The authors define &quot;offline differentiation&quot; by comparing the hybrid space features of the last index finger movement of a trial (ordinal position 5) and the first index finger movement of the next trial (ordinal position 1). However, the latter is not only the first movement in the sequence but also the very first movement in that trial (at least in trials that started with a correct sequence), i.e., not preceded by any recent movement. In contrast, the last index finger of the last correct sequence in the preceding trial includes the characteristic finger transition from the fourth to the fifth movement. Thus, there is more overlapping information arising from the consistent, neighbouring keypresses for the last index finger movement, compared to the first index finger movement of the next trial. A strong difference (larger neural representation distance) between these two movements is, therefore, not surprising, given the task design, and this difference is also expected to increase with learning, given the increase in tapping speed, and the consequent stronger overlap in representations for consecutive keypresses. Furthermore, initiating a new sequence involves pre-planning, while ongoing practice relies on online planning (Ariani et al., eNeuro 2021), i.e., two mental operations that are dissociable at the level of neural representation (Ariani et al., bioRxiv 2023).</p>
</disp-quote>
<p>The Reviewer argues that the comparison of last finger movement of a trial and the first in the next trial are performed in different circumstances and contexts. This is an important point and one we tend to agree with. For this task, the first sequence in a practice trial (which is pre-planned offline) is performed in a somewhat different context from the sequence iterations that follow, which involve temporally overlapping planning, execution and evaluation processes.  The Reviewer is particularly concerned about a difference in the temporal mixing effect issue raised above between the first and last keypresses performed in a trial. However, in contrast to the Reviewers stated argument above, findings from Korneysheva et. al (2019) showed that neural representations of individual actions are competitively queued during the pre-planning period in a manner that reflects the ordinal structure of the learned sequence.  Thus, mixing effects are likely still present for the first keypress in a trial. Also note that we now present new control analyses in multiple responses above confirming that hypothetical mixing effects between adjacent keypresses do not explain our reported contextualization finding. A statement addressing these possibilities raised by the Reviewer has been added to the Discussion in the revised manuscript.</p>
<p>In relation to pre-planning, ongoing MEG work in our lab is investigating contextualization within different time windows tailored specifically for assessing how sequence skill action planning evolves with learning.</p>
<disp-quote content-type="editor-comment">
<p>Given these differences in the physical context and associated mental processes, it is not surprising that &quot;offline differentiation&quot;, as defined here, is more pronounced than &quot;online differentiation&quot;. For the latter, the authors compared movements that were better matched regarding the presence of consistent preceding and subsequent keypresses (online differentiation was defined as the mean difference between all first vs. last index finger movements during practice).  It is unclear why the authors did not follow a similar definition for &quot;online differentiation&quot; as for &quot;micro-online gains&quot; (and, indeed, a definition that is more consistent with their definition of &quot;offline differentiation&quot;), i.e., the difference between the first index finger movement of the first correct sequence during practice, and the last index finger of the last correct sequence. While these two movements are, again, not matched for the presence of neighbouring keypresses (see the argument above), this mismatch would at least be the same across &quot;offline differentiation&quot; and &quot;online differentiation&quot;, so they would be more comparable.</p>
</disp-quote>
<p>This is the same point made earlier by Reviewer #2, and we agree with this assessment. As stated in the response to Reviewer #2 above, we have now carried out quantification of online contextualization using this approach and included it in the revised manuscript. We thank the Reviewer for this suggestion.</p>
<disp-quote content-type="editor-comment">
<p>A further complication in interpreting the results regarding &quot;contextualization&quot; stems from the visual feedback that participants received during the task. Each keypress generated an asterisk shown above the string on the screen, irrespective of whether the keypress was correct or incorrect. As a result, incorrect (e.g., additional, or missing) keypresses could shift the phase of the visual feedback string (of asterisks) relative to the ordinal position of the current movement in the sequence (e.g., the fifth movement in the sequence could coincide with the presentation of any asterisk in the string, from the first to the fifth). Given that more incorrect keypresses are expected at the start of the experiment, compared to later stages, the consistency in visual feedback position, relative to the ordinal position of the movement in the sequence, increased across the experiment. A better differentiation between the first and the fifth movement with learning could, therefore, simply reflect better decoding of the more consistent visual feedback, based either on the feedback-induced brain response, or feedback-induced eye movements (the study did not include eye tracking). It is not clear why the authors introduced this complicated visual feedback in their task, besides consistency with their previous studies.</p>
</disp-quote>
<p>We strongly agree with the Reviewer that eye movements related to task engagement are important to rule out as a potential driver of the decoding accuracy or contextualization effect. We address this issue above in response to a question raised by Reviewer #1 about the impact of movement related artefacts in general on our findings.</p>
<p>First, the assumption the Reviewer makes here about the distribution of errors in this task is incorrect. On average across subjects, 2.32% ± 1.48% (mean ± SD) of all keypresses performed were errors, which were evenly distributed across the four possible keypress responses. While errors increased progressively over practice trials, they did so in proportion to the increase in correct keypresses, so that the overall ratio of correct-to-incorrect keypresses remained stable over the training session. Thus, the Reviewer’s assumptions that there is a higher relative frequency of errors in early trials, and a resulting systematic trend phase shift differences between the visual display updates (i.e. – a change in asterisk position above the displayed sequence) and the keypress performed is not substantiated by the data. To the contrary, the asterisk position on the display and the keypress being executed remained highly correlated over the entire training session. We now include a statement about the frequency and distribution of errors in the revised manuscript.</p>
<p>Given this high correlation, we firmly agree with the Reviewer that the issue of eye movement-related artefacts is still an important one to address. Fortunately, we did collect eye movement data during the MEG recordings so were able to investigate this. As detailed in the response to Reviewer #1 above, we found that gaze positions and eye-movement velocity time-locked to visual display updates (i.e. – a change in asterisk position above the displayed sequence) did not reflect the asterisk location above chance levels (Overall cross-validated accuracy = 0.21817; see Author response image 1). Furthermore, an inspection of the eye position data revealed that a majority of participants on most trials displayed random walk gaze patterns around a center fixation point, indicating that participants did not attend to the asterisk position on the display. This is consistent with intrinsic generation of the action sequence, and congruent with the fact that the display does not provide explicit feedback related to performance. As pointed out above, a similar real-world example would be manually inputting a long password into a secure online application. In this case, one intrinsically generates the sequence from memory and receives similar feedback about the password sequence position (also provided as asterisks), which is typically ignored by the user. Notably, the minimal participant engagement with the visual task display observed in this study highlights an important difference between behavior observed during explicit sequence learning motor tasks (which is highly generative in nature) with reactive responses to stimulus cues in a serial reaction time task (SRTT).  This is a crucial difference that must be carefully considered when comparing findings across studies. All elements pertaining to this new control analysis are now included in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>The authors report a significant correlation between &quot;offline differentiation&quot; and cumulative micro-offline gains. However, it would be more informative to correlate trial-by-trial changes in each of the two variables. This would address the question of whether there is a trial-by-trial relation between the degree of &quot;contextualization&quot; and the amount of micro-offline gains - are performance changes (micro-offline gains) less pronounced across rest periods for which the change in &quot;contextualization&quot; is relatively low? Furthermore, is the relationship between micro-offline gains and &quot;offline differentiation&quot; significantly stronger than the relationship between micro-offline gains and &quot;online differentiation&quot;?</p>
</disp-quote>
<p>In response to a similar issue raised above by Reviewer #2, we now include new analyses comparing correlation magnitudes between (1) “online differention” vs micro-online gains, (2) “online differention” vs micro-offline gains and (3) “offline differentiation” and micro-offline gains (see Author response images 4, 5 and 6 above). These new analyses and results have been added to the revised manuscript. Once again, we thank both Reviewers for this suggestion.</p>
<disp-quote content-type="editor-comment">
<p>The authors follow the assumption that micro-offline gains reflect offline learning.</p>
</disp-quote>
<p>This statement is incorrect. The original Bonstrup et al (2019) 49 paper clearly states that micro-offline gains must be carefully interpreted based upon the behavioral context within which they are observed, and lays out the conditions under which one can have confidence that micro-offline gains reflect offline learning.  In fact, the excellent meta-analysis of Pan &amp; Rickard (2015) 51, which re-interprets the benefits of sleep in overnight skill consolidation from a “reactive inhibition” perspective, was a crucial resource in the experimental design of our initial study49, as well as in all our subsequent work. Pan &amp; Rickard stated:</p>
<p>“Empirically, reactive inhibition refers to performance worsening that can accumulate during a period of continuous training (Hull, 1943). It tends to dissipate, at least in part, when brief breaks are inserted between blocks of training. If there are multiple performance-break cycles over a training session, as in the motor sequence literature, performance can exhibit a scalloped effect, worsening during each uninterrupted performance block but improving across blocks52,53. Rickard, Cai, Rieth, Jones, and Ard (2008) and Brawn, Fenn, Nusbaum, and Margoliash (2010) 52,53 demonstrated highly robust scalloped reactive inhibition effects using the commonly employed 30 s–30 s performance break cycle, as shown for Rickard et al.’s (2008) massed practice sleep group in Figure 2. The scalloped effect is evident for that group after the first few 30 s blocks of each session. The absence of the scalloped effect during the first few blocks of training in the massed group suggests that rapid learning during that period masks any reactive inhibition effect.”</p>
<p>Crucially, Pan &amp; Rickard51 made several concrete recommendations for reducing the impact of the reactive inhibition confound on offline learning studies. One of these recommendations was to reduce practice times to 10s (most prior sequence learning studies up until that point had employed 30s long practice trials). They stated:</p>
<p>“The traditional design involving 30 s-30 s performance break cycles should be abandoned given the evidence that it results in a reactive inhibition confound, and alternative designs with reduced performance duration per block used instead 51. One promising possibility is to switch to 10 s performance durations for each performance-break cycle Instead 51. That design appears sufficient to eliminate at least the majority of the reactive inhibition effect 52,53.”</p>
<p>We mindfully incorporated recommendations from Pan and Rickard51  into our own study designs including 1) utilizing 10s practice trials and 2) constraining our analysis of micro-offline gains to early learning trials (where performance monotonically increases and 95% of overall performance gains occur), which are prior to the emergence of the “scalloped” performance dynamics that are strongly linked to reactive inhibition effects.</p>
<disp-quote content-type="editor-comment">
<p>However, there is no direct evidence in the literature that micro-offline gains really result from offline learning, i.e., an improvement in skill level.</p>
</disp-quote>
<p>We strongly disagree with the Reviewer’s assertion that “there is no direct evidence in the literature that micro-offline gains really result from offline learning, i.e., an improvement in skill level.”  The initial Bönstrup et al. (2019) 49 report was followed up by a large online crowd-sourcing study (Bönstrup et al., 2020) 54. This second (and much larger) study provided several additional important findings supporting our interpretation of micro-offline gains in cases where the important behavioral conditions clarified above were met (see Author response image 7 below for further details on these conditions<bold>)</bold>.</p>
<fig id="sa4fig7">
<label>Author response image 7.</label>
<caption>
<title>Micro-offline gains observed in learning and non-learning contexts are attributed to different underlying causes.</title>
<p>(A) Micro-offline and online changes relative to overall trial-by-trial learning. This figure is based on data from Bönstrup et al. (2019) 49. During early learning, micro-offline gains (red bars) closely track trial-by-trial performance gains (green line with open circle markers), with minimal contribution from micro-online gains (blue bars). The stated conclusion in Bönstrup et al. (2019) is that micro-offline gains only during this Early Learning stage reflect rapid memory consolidation (see also 54). After early learning, about practice trial 11, skill plateaus. This plateau skill period is characterized by a striking emergence of coupled (and relatively stable) micro-online drops and micro-offline increases. Bönstrup et al. (2019) as well as others in the literature 55-57, argue that micro-offline gains during the plateau period likely reflect recovery from inhibitory performance factors such as reactive inhibition or fatigue, and thus must be excluded from analyses relating micro-offline gains to skill learning.  The Non-repeating groups in Experiments 3 and 4 from Das et al. (2024) suffer from a lack of consideration of these known confounds.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig7.jpg" mimetype="image"/>
</fig>
<p>Evidence documented in that paper54 showed that micro-offline gains during early skill learning were: 1) replicable and generalized to subjects learning the task in their daily living environment (n=389); 2) equivalent when significantly shortening practice period duration, thus confirming that they are not a result of recovery from performance fatigue (n=118);  3) reduced (along with learning rates) by retroactive interference applied immediately after each practice period relative to interference applied after passage of time (n=373), indicating stabilization of the motor memory at a microscale of several seconds consistent with rapid consolidation; and 4) not modified by random termination of the practice periods, ruling out a contribution of predictive motor slowing (N = 71) 54.  Altogether, our findings were strongly consistent with the interpretation that micro-offline gains reflect memory consolidation supporting early skill learning. This is precisely the portion of the learning curve Pan and Rickard51 refer to when they state “…rapid learning during that period masks any reactive inhibition effect”.</p>
<p>This interpretation is further supported by brain imaging evidence linking known memory-related networks and consolidation mechanisms to micro-offline gains. First, we reported that the density of fast hippocampo-neocortical skill memory replay events increases approximately three-fold during early learning inter-practice rest periods with the density explaining differences in the magnitude of micro-offline gains across subjects1. Second, Jacobacci et al. (2020) independently reproduced our original behavioral findings and reported BOLD fMRI changes in the hippocampus and precuneus (regions also identified in our MEG study1) linked to micro-offline gains during early skill learning. 33 These functional changes were coupled with rapid alterations in brain microstructure in the order of minutes, suggesting that the same network that operates during rest periods of early learning undergoes structural plasticity over several minutes following practice58. Third, even more recently, Chen et al. (2024) provided direct evidence from intracranial EEG in humans linking sharp-wave ripple events (which are known markers for neural replay59) in the hippocampus (80-120 Hz in humans) with micro-offline gains during early skill learning. The authors report that the strong increase in ripple rates tracked learning behavior, both across blocks and across participants. The authors conclude that hippocampal ripples during resting offline periods contribute to motor sequence learning. 2</p>
<p>Thus, there is actually now substantial evidence in the literature directly supporting the assertion “that micro-offline gains really result from offline learning”.  On the contrary, according to Gupta &amp; Rickard (2024) “…the mechanism underlying RI [reactive inhibition] is not well established” after over 80 years of investigation60, possibly due to the fact that “reactive inhibition” is a categorical description of behavioral effects that likely result from several heterogenous processes with very different underlying mechanisms.</p>
<disp-quote content-type="editor-comment">
<p>On the contrary, recent evidence questions this interpretation (Gupta &amp; Rickard, npj Sci Learn 2022; Gupta &amp; Rickard, Sci Rep 2024; Das et al., bioRxiv 2024). Instead, there is evidence that micro-offline gains are transient performance benefits that emerge when participants train with breaks, compared to participants who train without breaks, however, these benefits vanish within seconds after training if both groups of participants perform under comparable conditions (Das et al., bioRxiv 2024).</p>
</disp-quote>
<p>It is important to point out that the recent work of Gupta &amp; Rickard (2022,2024) 55 does not present any data that directly opposes our finding that early skill learning49 is expressed as micro-offline gains during rest breaks. These studies are essentially an extension of the Rickard et al (2008) paper that employed a massed (30s practice followed by 30s breaks) vs spaced (10s practice followed by 10s breaks) to assess if recovery from reactive inhibition effects could account for performance gains measured after several minutes or hours. Gupta &amp; Rickard (2022) added two additional groups (30s practice/10s break and 10s practice/10s break as used in the work from our group). The primary aim of the study was to assess whether it was more likely that changes in performance when retested 5 minutes after skill training (consisting of 12 practice trials for the massed groups and 36 practice trials for the spaced groups) had ended reflected memory consolidation effects or recovery from reactive inhibition effects. The Gupta &amp; Rickard (2024) follow-up paper employed a similar design with the primary difference being that participants performed a fixed number of sequences on each trial as opposed to trials lasting a fixed duration. This was done to facilitate the fitting of a quantitative statistical model to the data.  To reiterate, neither study included any analysis of micro-online or micro-offline gains and did not include any comparison focused on skill gains during early learning. Instead, Gupta &amp; Rickard (2022), reported evidence for reactive inhibition effects for all groups over much longer training periods. Again, we reported the same finding for trials following the early learning period in our original Bönstrup et al. (2019) paper49 (Author response image 7). Also, please note that we reported in this paper that cumulative micro-offline gains over early learning did not correlate with overnight offline consolidation measured 24 hours later49 (see the Results section and further elaboration in the Discussion). Thus, while the composition of our data is supportive of a short-term memory consolidation process operating over several seconds during early learning, it likely differs from those involved over longer training times and offline periods, as assessed by Gupta &amp; Rickard (2022).</p>
<p>In the recent preprint from Das et al (2024) 61,  the authors make the strong claim that “micro-offline gains during early learning do not reflect offline learning” which is not supported by their own data.   The authors hypothesize that if “micro-offline gains represent offline learning, participants should reach higher skill levels when training with breaks, compared to training without breaks”.  The study utilizes a spaced vs. massed practice group between-subjects design inspired by the reactive inhibition work from Rickard and others to test this hypothesis. Crucially, the design incorporates only a small fraction of the training used in other investigations to evaluate early skill learning1,33,49,54,57,58,62.  A direct comparison between the practice schedule designs for the spaced and massed groups in Das et al., and the training schedule all participants experienced in the original Bönstrup et al. (2019) paper highlights this issue as well as several others (Author response image 8):</p>
<fig id="sa4fig8">
<label>Author response image 8.</label>
<caption>
<title>(A) Comparison of Das et al.</title>
<p>Spaced &amp; Massed group training session designs, and the training session design from the original Bönstrup et al. (2019) 49 paper. Similar to the approach taken by Das et al., all practice is visualized as 10-second practice trials with a variable number (either 0, 1 or 30) of 10-second-long inter-practice rest intervals to allow for direct comparisons between designs. The two key takeaways from this comparison are that (1) the intervention differences (i.e. – practice schedules) between the Massed and Spaced groups from the Das et al. report are extremely small (less than 12% of the overall session schedule) and (2) the overall amount of practice is much less than compared to the design from the original Bönstrup report 49  (which has been utilized in several subsequent studies). (B) Group-level learning curve data from Bönstrup et al. (2019) 49 is used to estimate the performance range accounted for by the equivalent periods covering Test 1, Training 1 and Test 2 from Das et al (2024). Note that the intervention in the Das et al. study is limited to a period covering less than 50% of the overall learning range.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102475-sa4-fig8.jpg" mimetype="image"/>
</fig>
<p>First, participants in the original Bönstrup et al. study 49 experienced 157.14% more practice time and 46.97% less inter-practice rest time than the Spaced group in the Das et al. study (Author response image 8).  Thus, the overall amount of practice and rest differ substantially between studies, with much more limited training occurring for participants in Das et al.</p>
<p>Second, and perhaps most importantly, the actual intervention (i.e. – the difference in practice schedule between the Spaced and Massed groups) employed by Das et al. covers a very small fraction of the overall training session. Identical practice schedule segments for both the Spaced &amp; Massed groups are indicated by the red shaded area in Author response image 8. Please note that these identical segments cover 94.84% of the Massed group training schedule and 88.01% of the Spaced group training schedule (since it has 60 seconds of additional rest). This means that the actual interventions cover less than 5% (for Massed) and 12% (for Spaced) of the total training session, which minimizes any chance of observing a difference between groups.</p>
<p>Also note that the very beginning of the practice schedule (during which Figure R9 shows substantial learning is known to occur) is labeled in the Das et al. study as Test 1.  Test 1 encompasses the first 20 seconds of practice (alternatively viewed as the first two 10-second-long practice trials with no inter-practice rest). This is immediately followed by the Training 1 intervention, which is composed of only three 10-second-long practice trials (with 10-second inter-practice rest for the Spaced group and no inter-practice rest for the Massed group). Author response image 8 also shows that since there is no inter-practice rest after the third Training practice trial for the Spaced group, this third trial (for both Training 1 and 2) is actually a part of an identical practice schedule segment shared by both groups (Massed and Spaced), reducing the magnitude of the intervention even further.</p>
<p>Moreover, we know from the original Bönstrup et al. (2019) paper49 that 46.57% of all overall group-level performance gains occurred between trials 2 and 5 for that study. Thus, Das et al. are limiting their designed intervention to a period covering less than half of the early learning range discussed in the literature, which again, minimizes any chance of observing an effect.</p>
<p>This issue is amplified even further at Training 2 since skill learning prior to the long 5-minute break is retained, further constraining the performance range over these three trials. A related issue pertains to the trials labeled as Test 1 (trials 1-2) and Test 2 (trials 6-7) by Das et al. Again, we know from the original Bönstrup et al. paper 49 that 18.06% and 14.43% (32.49% total) of all overall group-level performance gains occurred during trials corresponding to Das et al Test 1 and Test 2, respectively. In other words, Das et al averaged skill performance over 20 seconds of practice at two time-points where dramatic skill improvements occur. Pan &amp; Rickard (1995) previously showed that such averaging is known to inject artefacts into analyses of performance gains.</p>
<p>Furthermore, the structure of the Test in Das et. al study appears to have an interference effect on the Spaced group performance after the training intervention.  This makes sense if you consider that the Spaced group is required to now perform the task in a Massed practice environment (i.e., two 10-second-long practice trials merged into one long trial), further blurring the true intervention effects. This effect is observable in Figure 1C,E of their pre-print. Specifically, while the Massed group continues to show an increase in performance during test relative to the last 10 seconds of practice during training, the Spaced group displays a marked decrease. This decrease is in stark contrast to the monotonic increases observed for both groups at all other time-points.</p>
<p>Interestingly, when statistical comparisons between the groups are made at the time-points when the intervention is present (as opposed to after it has been removed) then the stated hypothesis, “If micro-offline gains represent offline learning, participants should reach higher skill levels when training with breaks, compared to training without breaks”, is confirmed.</p>
<p>The data presented by Gupta and Rickard (2022, 2024) and Das et al. (2024) is in many ways more confirmatory of the constraints employed by our group and others with respect to experimental design, analysis and interpretation of study findings, rather than contradictory. Still, it does highlight a limitation of the current micro-online/offline framework, which was originally only intended to be applied to early skill learning over spaced practice schedules when reactive inhibition effects are minimized49. Extrapolation of this current framework to post-plateau performance periods, longer timespans, or non-learning situations (e.g. – the Non-repeating groups from Experiments 3 &amp; 4 in Das et al. (2024)), when reactive inhibition plays a more substantive role, is not warranted. Ultimately, it will be important to develop new paradigms allowing one to independently estimate the different coincident or antagonistic features (e.g. - memory consolidation, planning, working memory and reactive inhibition) contributing to micro-online and micro-offline gains during and after early skill learning within a unifying framework.</p>
<p>References</p>
<p>(1) Buch, E. R., Claudino, L., Quentin, R., Bonstrup, M. &amp; Cohen, L. G. Consolidation of human skill linked to waking hippocampo-neocortical replay. Cell Rep 35, 109193 (2021). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.celrep.2021.109193</p>
<p>(2) Chen, P.-C., Stritzelberger, J., Walther, K., Hamer, H. &amp; Staresina, B. P. Hippocampal ripples during offline periods predict human motor sequence learning. bioRxiv, 2024.2010.2006.614680 (2024). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1101/2024.10.06.614680</p>
<p>(3) Classen, J., Liepert, J., Wise, S. P., Hallett, M. &amp; Cohen, L. G. Rapid plasticity of human cortical movement representation induced by practice. J Neurophysiol 79, 1117-1123 (1998).</p>
<p>(4) Karni, A. et al. Functional MRI evidence for adult motor cortex plasticity during motor skill learning. Nature 377, 155-158 (1995). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/377155a0</p>
<p>(5) Kleim, J. A., Barbay, S. &amp; Nudo, R. J. Functional reorganization of the rat motor cortex following motor skill learning. J Neurophysiol 80, 3321-3325 (1998).</p>
<p>(6) Shadmehr, R. &amp; Holcomb, H. H. Neural correlates of motor memory consolidation. Science 277, 821-824 (1997).</p>
<p>(7) Doyon, J. et al. Experience-dependent changes in cerebellar contributions to motor sequence learning. Proc Natl Acad Sci U S A 99, 1017-1022 (2002).</p>
<p>(8) Toni, I., Ramnani, N., Josephs, O., Ashburner, J. &amp; Passingham, R. E. Learning arbitrary visuomotor associations: temporal dynamic of brain activity. Neuroimage 14, 1048-1057 (2001).</p>
<p>(9) Grafton, S. T. et al. Functional anatomy of human procedural learning determined with regional cerebral blood flow and PET. J Neurosci 12, 2542-2548 (1992).</p>
<p>(10) Kennerley, S. W., Sakai, K. &amp; Rushworth, M. F. Organization of action sequences and the role of the pre-SMA. J Neurophysiol 91, 978-993 (2004). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1152/jn.00651.2003 00651.2003 [pii]</p>
<p>(11) Hardwick, R. M., Rottschy, C., Miall, R. C. &amp; Eickhoff, S. B. A quantitative meta-analysis and review of motor learning in the human brain. Neuroimage 67, 283-297 (2013). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.neuroimage.2012.11.020</p>
<p>(12) Sawamura, D. et al. Acquisition of chopstick-operation skills with the non-dominant hand and concomitant changes in brain activity. Sci Rep 9, 20397 (2019). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/s41598-019-56956-0</p>
<p>(13) Lee, S. H., Jin, S. H. &amp; An, J. The difference in cortical activation pattern for complex motor skills: A functional near- infrared spectroscopy study. Sci Rep 9, 14066 (2019). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/s41598-019-50644-9</p>
<p>(14) Battaglia-Mayer, A. &amp; Caminiti, R. Corticocortical Systems Underlying High-Order Motor Control. J Neurosci 39, 4404-4421 (2019). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1523/JNEUROSCI.2094-18.2019</p>
<p>(15) Toni, I., Thoenissen, D. &amp; Zilles, K. Movement preparation and motor intention. Neuroimage 14, S110-117 (2001). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1006/nimg.2001.0841</p>
<p>(16) Wolpert, D. M., Goodbody, S. J. &amp; Husain, M. Maintaining internal representations: the role of the human superior parietal lobe. Nat Neurosci 1, 529-533 (1998). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/2245</p>
<p>(17) Andersen, R. A. &amp; Buneo, C. A. Intentional maps in posterior parietal cortex. Annu Rev Neurosci 25, 189-220 (2002). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1146/annurev.neuro.25.112701.142922 112701.142922 [pii]</p>
<p>(18) Buneo, C. A. &amp; Andersen, R. A. The posterior parietal cortex: sensorimotor interface for the planning and online control of visually guided movements. Neuropsychologia 44, 2594-2606 (2006). <ext-link ext-link-type="uri" xlink:href="https://doi.org">https://doi.org</ext-link>:S0028-3932(05)00333-7 [pii] 10.1016/j.neuropsychologia.2005.10.011</p>
<p>(19) Grover, S., Wen, W., Viswanathan, V., Gill, C. T. &amp; Reinhart, R. M. G. Long-lasting, dissociable improvements in working memory and long-term memory in older adults with repetitive neuromodulation. Nat Neurosci 25, 1237-1246 (2022). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/s41593-022-01132-3</p>
<p>(20) Colclough, G. L. et al. How reliable are MEG resting-state connectivity metrics? Neuroimage 138, 284-293 (2016). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.neuroimage.2016.05.070</p>
<p>(21) Colclough, G. L., Brookes, M. J., Smith, S. M. &amp; Woolrich, M. W. A symmetric multivariate leakage correction for MEG connectomes. NeuroImage 117, 439-448 (2015). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.neuroimage.2015.03.071</p>
<p>(22) Mollazadeh, M. et al. Spatiotemporal variation of multiple neurophysiological signals in the primary motor cortex during dexterous reach-to-grasp movements. J Neurosci 31, 15531-15543 (2011). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1523/JNEUROSCI.2999-11.2011</p>
<p>(23) Bansal, A. K., Vargas-Irwin, C. E., Truccolo, W. &amp; Donoghue, J. P. Relationships among low-frequency local field potentials, spiking activity, and three-dimensional reach and grasp kinematics in primary motor and ventral premotor cortices. J Neurophysiol 105, 1603-1619 (2011). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1152/jn.00532.2010</p>
<p>(24) Flint, R. D., Ethier, C., Oby, E. R., Miller, L. E. &amp; Slutzky, M. W. Local field potentials allow accurate decoding of muscle activity. J Neurophysiol 108, 18-24 (2012). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1152/jn.00832.2011</p>
<p>(25) Churchland, M. M. et al. Neural population dynamics during reaching. Nature 487, 51-56 (2012). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/nature11129</p>
<p>(26) Bassett, D. S. et al. Dynamic reconfiguration of human brain networks during learning. Proc Natl Acad Sci U S A 108, 7641-7646 (2011). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1073/pnas.1018985108</p>
<p>(27) Albouy, G., King, B. R., Maquet, P. &amp; Doyon, J. Hippocampus and striatum: dynamics and interaction during acquisition and sleep-related motor sequence memory consolidation. Hippocampus 23, 985-1004 (2013). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1002/hipo.22183</p>
<p>(28) Albouy, G. et al. Neural correlates of performance variability during motor sequence acquisition. Neuroimage 60, 324-331 (2012). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.neuroimage.2011.12.049</p>
<p>(29) Qin, Y. L., McNaughton, B. L., Skaggs, W. E. &amp; Barnes, C. A. Memory reprocessing in corticocortical and hippocampocortical neuronal ensembles. Philos Trans R Soc Lond B Biol Sci 352, 1525-1533 (1997). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1098/rstb.1997.0139</p>
<p>(30) Euston, D. R., Tatsuno, M. &amp; McNaughton, B. L. Fast-forward playback of recent memory sequences in prefrontal cortex during sleep. Science 318, 1147-1150 (2007). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1126/science.1148979</p>
<p>(31) Molle, M. &amp; Born, J. Hippocampus whispering in deep sleep to prefrontal cortex--for good memories? Neuron 61, 496-498 (2009). <ext-link ext-link-type="uri" xlink:href="https://doi.org">https://doi.org</ext-link>:S0896-6273(09)00122-6 [pii] 10.1016/j.neuron.2009.02.002</p>
<p>(32) Frankland, P. W. &amp; Bontempi, B. The organization of recent and remote memories. Nat Rev Neurosci 6, 119-130 (2005). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/nrn1607</p>
<p>(33) Jacobacci, F. et al. Rapid hippocampal plasticity supports motor sequence learning. Proc Natl Acad Sci U S A 117, 23898-23903 (2020). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1073/pnas.2009576117</p>
<p>(34) Albouy, G. et al. Maintaining vs. enhancing motor sequence memories: respective roles of striatal and hippocampal systems. Neuroimage 108, 423-434 (2015). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.neuroimage.2014.12.049</p>
<p>(35) Gais, S. et al. Sleep transforms the cerebral trace of declarative memories. Proc Natl Acad Sci U S A 104, 18778-18783 (2007). <ext-link ext-link-type="uri" xlink:href="https://doi.org:0705454104">https://doi.org:0705454104</ext-link> [pii] 10.1073/pnas.0705454104</p>
<p>(36) Sterpenich, V. et al. Sleep promotes the neural reorganization of remote emotional memory. J Neurosci 29, 5143-5152 (2009). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1523/JNEUROSCI.0561-09.2009</p>
<p>(37) Euston, D. R., Gruber, A. J. &amp; McNaughton, B. L. The role of medial prefrontal cortex in memory and decision making. Neuron 76, 1057-1070 (2012). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.neuron.2012.12.002</p>
<p>(38) van Kesteren, M. T., Fernandez, G., Norris, D. G. &amp; Hermans, E. J. Persistent schema-dependent hippocampal-neocortical connectivity during memory encoding and postencoding rest in humans. Proc Natl Acad Sci U S A 107, 7550-7555 (2010). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1073/pnas.0914892107</p>
<p>(39) van Kesteren, M. T., Ruiter, D. J., Fernandez, G. &amp; Henson, R. N. How schema and novelty augment memory formation. Trends Neurosci 35, 211-219 (2012). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.tins.2012.02.001</p>
<p>(40) Wagner, A. D. et al. Building memories: remembering and forgetting of verbal experiences as predicted by brain activity. Science (New York, N.Y.) 281, 1188-1191 (1998).</p>
<p>(41) Ashe, J., Lungu, O. V., Basford, A. T. &amp; Lu, X. Cortical control of motor sequences. Curr Opin Neurobiol 16, 213-221 (2006).</p>
<p>(42) Hikosaka, O., Nakamura, K., Sakai, K. &amp; Nakahara, H. Central mechanisms of motor skill learning. Curr Opin Neurobiol 12, 217-222 (2002).</p>
<p>(43) Penhune, V. B. &amp; Steele, C. J. Parallel contributions of cerebellar, striatal and M1 mechanisms to motor sequence learning. Behav. Brain Res. 226, 579-591 (2012). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.bbr.2011.09.044</p>
<p>(44) Doyon, J. et al. Contributions of the basal ganglia and functionally related brain structures to motor learning. Behavioural brain research 199, 61-75 (2009). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.bbr.2008.11.012</p>
<p>(45) Schendan, H. E., Searl, M. M., Melrose, R. J. &amp; Stern, C. E. An FMRI study of the role of the medial temporal lobe in implicit and explicit sequence learning. Neuron 37, 1013-1025 (2003). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/s0896-6273(03)00123-5</p>
<p>(46) Morris, R. G. M. Elements of a neurobiological theory of hippocampal function: the role of synaptic plasticity, synaptic tagging and schemas. The European journal of neuroscience 23, 2829-2846 (2006). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1111/j.1460-9568.2006.04888.x</p>
<p>(47) Tse, D. et al. Schemas and memory consolidation. Science 316, 76-82 (2007). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1126/science.1135935</p>
<p>(48) Berlot, E., Popp, N. J. &amp; Diedrichsen, J. A critical re-evaluation of fMRI signatures of motor sequence learning. Elife 9 (2020). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.7554/eLife.55241</p>
<p>(49) Bonstrup, M. et al. A Rapid Form of Offline Consolidation in Skill Learning. Curr Biol 29, 1346-1351 e1344 (2019). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.cub.2019.02.049</p>
<p>(50) Kornysheva, K. et al. Neural Competitive Queuing of Ordinal Structure Underlies Skilled Sequential Action. Neuron 101, 1166-1180 e1163 (2019). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1016/j.neuron.2019.01.018</p>
<p>(51) Pan, S. C. &amp; Rickard, T. C. Sleep and motor learning: Is there room for consolidation? Psychol Bull 141, 812-834 (2015). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1037/bul0000009</p>
<p>(52) Rickard, T. C., Cai, D. J., Rieth, C. A., Jones, J. &amp; Ard, M. C. Sleep does not enhance motor sequence learning. J Exp Psychol Learn Mem Cogn 34, 834-842 (2008). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1037/0278-7393.34.4.834</p>
<p>1. Brawn, T. P., Fenn, K. M., Nusbaum, H. C. &amp; Margoliash, D. Consolidating the effects of waking and sleep on motor-sequence learning. J Neurosci 30, 13977-13982 (2010). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1523/JNEUROSCI.3295-10.2010</p>
<p>(54) Bonstrup, M., Iturrate, I., Hebart, M. N., Censor, N. &amp; Cohen, L. G. Mechanisms of offline motor learning at a microscale of seconds in large-scale crowdsourced data. NPJ Sci Learn 5, 7 (2020). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/s41539-020-0066-9</p>
<p>(55) Gupta, M. W. &amp; Rickard, T. C. Dissipation of reactive inhibition is sufficient to explain post-rest improvements in motor sequence learning. NPJ Sci Learn 7, 25 (2022). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/s41539-022-00140-z</p>
<p>(56) Jacobacci, F. et al. Rapid hippocampal plasticity supports motor sequence learning. Proceedings of the National Academy of Sciences 117, 23898-23903 (2020).</p>
<p>(57) Brooks, E., Wallis, S., Hendrikse, J. &amp; Coxon, J. Micro-consolidation occurs when learning an implicit motor sequence, but is not influenced by HIIT exercise. NPJ Sci Learn 9, 23 (2024). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/s41539-024-00238-6</p>
<p>(58) Deleglise, A. et al. Human motor sequence learning drives transient changes in network topology and hippocampal connectivity early during memory consolidation. Cereb Cortex 33, 6120-6131 (2023). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1093/cercor/bhac489</p>
<p>(59) Buzsaki, G. Hippocampal sharp wave-ripple: A cognitive biomarker for episodic memory and planning. Hippocampus 25, 1073-1188 (2015). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1002/hipo.22488</p>
<p>(60) Gupta, M. W. &amp; Rickard, T. C. Comparison of online, offline, and hybrid hypotheses of motor sequence learning using a quantitative model that incorporate reactive inhibition. Sci Rep 14, 4661 (2024). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1038/s41598-024-52726-9</p>
<p>(61) Das, A., Karagiorgis, A., Diedrichsen, J., Stenner, M.-P. &amp; Azanon, E. “Micro-offline gains” convey no benefit for motor skill learning. bioRxiv, 2024.2007.2011.602795 (2024). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1101/2024.07.11.602795</p>
<p>(62) Mylonas, D. et al. Maintenance of Procedural Motor Memory across Brief Rest Periods Requires the Hippocampus. J Neurosci 44 (2024). <ext-link ext-link-type="uri" xlink:href="https://doi.org:10">https://doi.org:10</ext-link>.1523/JNEUROSCI.1839-23.2024</p>
</body>
</sub-article>
</article>