<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">109096</article-id>
<article-id pub-id-type="doi">10.7554/eLife.109096</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.109096.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Verbal Episodic Processing in Newborns</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-7149-3066</contrib-id>
<name>
<surname>Visibelli</surname>
<given-names>Emma</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Fló</surname>
<given-names>Ana</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Baraldi</surname>
<given-names>Eugenio</given-names>
</name>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Benavides-Varela</surname>
<given-names>Silvia</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
<email>silvia.benavidesvarela@unipd.it</email>
</contrib>
<aff id="a1"><label>a</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>Padova Neuroscience Center, University of Padua</institution></institution-wrap>, <city>Padua</city>, <country country="IT">Italy</country></aff>
<aff id="a2"><label>b</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>Department of Developmental Psychology and Socialization, University of Padua</institution></institution-wrap>, <city>Padua</city>, <country country="IT">Italy</country></aff>
<aff id="a3"><label>c</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>Department of Women’s and Children’s Health, Neonatal Intensive Care Unit, University Hospital of Padova</institution></institution-wrap>, <city>Padua</city>, <country country="IT">Italy</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Tian</surname>
<given-names>Xing</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1629-6304</contrib-id><role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02vpsdb40</institution-id><institution>New York University Shanghai</institution>
</institution-wrap>
<city>Shanghai</city>
<country country="CN">China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>*</label><p>The authors equally contributed to the article</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-12-12">
<day>12</day>
<month>12</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP109096</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-09-19">
<day>19</day>
<month>09</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-09-19">
<day>19</day>
<month>09</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.09.19.677368"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Visibelli et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Visibelli et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-109096-v1.pdf"/>
<abstract>
<p>During the first period of life, human infants rapidly and effortlessly acquire the languages they are exposed to. Although memory is central to this process, the nature of early verbal memory systems and the factors that determine retention and forgetting remain largely unknown. Behavioural and brain measures have demonstrated memory formation in newborns. However, word traces fade in the face of acoustic overlap, leading to interference and forgetting. Here, we investigate whether speakers’ identity changes facilitate the separation into distinct acoustic episodes and the creation of non-overlapping verbal memories. Newborns (0-4 days-old) were tested in a familiarization-interference-test protocol, while neural cortical activity was recorded using functional Near-Infrared Spectroscopy (fNIRS). The results showed higher neural activation for novel words compared to familiar ones in the test phase, indicating that the infants recognized the familiar words despite the presence of potentially interfering sounds. The recognition response was measured over the left inferior frontal (IFG) and superior temporal gyrus (STG) areas, known to be crucial for encoding auditory information and language processing. The neural response also involved the right IFG and STG, involved in interpreting vocal social cues and speaker recognition. These data show that speaker identity is a key feature of speech, enabling episodic-like memories from birth and evolutionary advantages at the outset of human communication.</p>
</abstract>
<abstract abstract-type="teaser">
<title>Impact Statement</title>
<p>Speaker identity is a distinguishing element at birth and highlights the episodic nature of the human’s first stored verbal memories.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Verbal memory</kwd>
<kwd>acoustic variability</kwd>
<kwd>speaker identity</kwd>
<kwd>newborns</kwd>
<kwd>functional near-infrared spectroscopy</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Word recognition entails processing and integrating various linguistic features, such as phonological content, along with contextual or indexical information, like speaker identity, accent, and emotional content, which are crucial for communication. Theoretical approaches to speech representation hold contrasting views on the role of indexical features in word recognition. Abstractionist models assumed that variability needs to be normalized or stripped away so that speech sounds could be recognized (e.g., <xref ref-type="bibr" rid="c35">Halle, 1985</xref>; <xref ref-type="bibr" rid="c50">McClelland &amp; Elman, 1986</xref>; <xref ref-type="bibr" rid="c55">Norris et al., 2000</xref>; <xref ref-type="bibr" rid="c64">Pisoni &amp; Luce, 1987</xref>). Episodic or exemplar approaches adopt an alternative perspective, assuming that memories of linguistic utterances are bound to indexical information (e.g., (<xref ref-type="bibr" rid="c33">Goldinger, 1996</xref>; <xref ref-type="bibr" rid="c57">Nygaard et al., 1994</xref>; <xref ref-type="bibr" rid="c58">Palmeri et al., 1993</xref>). The balance between forming exemplar memories and creating normalized word prototypes is crucial during language acquisition. Indexical information may aid in distinguishing memories, while abstract representations are necessary for generalization. However, how infants encode language as they develop is still not well understood.</p>
<p>When encoding word forms, young infants remember not just the words themselves but also specific indexical properties such as speaker (<xref ref-type="bibr" rid="c37">Houston &amp; Jusczyk, 2000</xref>), stress, amplitude, and affect (<xref ref-type="bibr" rid="c72">Singh et al., 2004</xref>; see <xref ref-type="bibr" rid="c77">Van Heugten et al., 2015</xref>). However, their learning is context-dependent: low-variability conditions promote the learning of specific examples (<xref ref-type="bibr" rid="c37">Houston &amp; Jusczyk, 2000</xref>; <xref ref-type="bibr" rid="c41">Jusczyk &amp; Aslin, 1995</xref>; <xref ref-type="bibr" rid="c72">Singh et al., 2004</xref>) and high-variability conditions facilitate the learning of abstract word prototypes (<xref ref-type="bibr" rid="c71">Singh, 2008</xref>). Current models of infant language comprehension (<xref ref-type="bibr" rid="c40">Jusczyk, 1997</xref>; <xref ref-type="bibr" rid="c78">Werker &amp; Curtin, 2005</xref>) propose that in early stages, infants match specific sounds to stored instances of words and subsequently generate abstract word prototypes. In line with this, we hypothesize that speaker changes play a critical role in verbal memories’ formation at birth by providing indexical information for memory separation.</p>
<p>Verbal memory formation at birth is not well understood. Vast research on language processing supports the storage of both linguistic and speaker-specific information in newborns. They readily distinguish phonetic changes (<xref ref-type="bibr" rid="c18">Cheour-Luhtanen et al., 1995</xref>; <xref ref-type="bibr" rid="c23">Dehaene-Lambertz &amp; Pena, 2001</xref>), extract words from continuous speech (<xref ref-type="bibr" rid="c29">Fló et al., 2019</xref>, <xref ref-type="bibr" rid="c27">2022</xref>), and detect speech structure (<xref ref-type="bibr" rid="c8">Benavides-Varela &amp; Gervain, 2017</xref>; <xref ref-type="bibr" rid="c31">Gervain et al., 2008</xref>; <xref ref-type="bibr" rid="c48">Martinez-Alvarez et al., 2023</xref>), even amidst variability in speakers (<xref ref-type="bibr" rid="c28">Fló et al., 2025</xref>; <xref ref-type="bibr" rid="c46">Mahmoudzadeh et al., 2013a</xref>). Newborns also react to indexical features such as between-accent differences (<xref ref-type="bibr" rid="c32">Giordano et al., 2021</xref>) and are particularly sensitive to familiar voices (<xref ref-type="bibr" rid="c20">DeCasper &amp; Fifer, 1980</xref>; <xref ref-type="bibr" rid="c51">Mehler et al., 1978</xref>; <xref ref-type="bibr" rid="c73">Spence &amp; Freeman, 1996</xref>). Moreover, phonological processing is lateralized to the left hemisphere, while voice-related information shows right lateralization already in young infants (<xref ref-type="bibr" rid="c11">Blasi et al., 2011</xref>; <xref ref-type="bibr" rid="c73">Spence &amp; Freeman, 1996</xref>; see review <xref ref-type="bibr" rid="c34">Grossmann et al., 2010</xref>). While these findings support normalized phonological representations and parallel processing of phonological and contextual features, it remains unclear how these features are integrated to form verbal memories at birth and how they can determine memory formation or forgetting.</p>
<p>Benavides-Varela and colleagues used functional near-infrared spectroscopy (fNIRS) to investigate the formation of word memories at birth, including the areas supporting this cognitive capacity and some factors determining their loss or retention. The authors found that newborns familiarized with a 2-syllable word sound (hereafter referred to as word) show a recognition response after a few minutes-long retention period, which was characterized by a decreased activity towards the familiar word and increased response to a novel word over temporal, frontal, and parietal areas (<xref ref-type="bibr" rid="c7">Benavides-Varela, 2012</xref>; <xref ref-type="bibr" rid="c9">Benavides-Varela et al., 2011</xref>, <xref ref-type="bibr" rid="c10">2012</xref>). This research also indicated that under some circumstances, newborns’ memories appear fragile and highly vulnerable to interference. For example, recognition does not persist when neonates hear another word produced by the same speaker during the retention period. Interestingly, unlike speech, instrumental music presented during this retention phase does not interfere with the familiar memory trace (<xref ref-type="bibr" rid="c9">Benavides-Varela et al., 2011</xref>). The phenomenon could be partly explained in terms of retroactive interference, which occurs when novel information disrupts the retention of previously learned items (<xref ref-type="bibr" rid="c54">Müller &amp; Pilzecker, 1900</xref>). One factor that may influence retroactive interference is the degree of neural overlap in processing the information that needs to be encoded and the interfering stimuli. Since instrumental music and speech processing recruit partially distinct neural (in adults: <xref ref-type="bibr" rid="c62">Peretz et al., 2015</xref>; <xref ref-type="bibr" rid="c81">Zatorre et al., 2002</xref>; infants: <xref ref-type="bibr" rid="c22">Dehaene-Lambertz et al., 2002</xref>; and newborns: <xref ref-type="bibr" rid="c43">Kotilahti et al., 2010</xref>; <xref ref-type="bibr" rid="c61">Perani et al., 2010</xref>), this could explain the absence of music-speech interference. However, if this were the sole factor determining interference, speech-speech retroactive interference would render language learning impossible in real-life conditions. Here we propose a complementary explanation for the retroactive interference described in previous studies: various features may be integrated to assess the similarities or differences between two auditory events, facilitating the separability of new arriving information and, therefore, memory storage. Specifically, non-phonological information in speech, such as a speaker change, could serve as indexical information—acting as markers that signify the end of one event and the beginning of another—thereby facilitating the contrast and separability of verbal memories early in life. According to this hypothesis, the presence of speech during the retention period will not always lead to forgetting.</p>
<p>To test our hypothesis, we implemented a protocol derived from the work of <xref ref-type="bibr" rid="c9">Benavides-Varela et al. (2011</xref>, <xref ref-type="bibr" rid="c10">2012</xref>). Newborns were first familiarized with a pseudoword produced by a single speaker. Immediately after, they were exposed to an interfering word. Then, in the test, the familiarization word or a completely novel word was presented. Like in Benavides-Varela et al., the interfering, the familiar, and the novel words had similar intensity, duration, pitch, syllable structure, etc. (see Supplementary Table 1 in Supplementary Materials (SI)). Instead, the amount of familiarization was reduced from ten to five blocks, and the retention interval increased from two to three minutes, making the paradigm more challenging. These methodological adjustments allow for a meaningful comparison with previous studies: if newborns forgot the word in <xref ref-type="bibr" rid="c9">Benavides-Varela et al. (2011)</xref>, they would also be expected to forget it under a more challenging paradigm. Crucially, unlike the previous work, the interfering word was uttered by a different speaker. We hypothesize that if the voice distinction promotes memory separation, there should be a differential hemodynamic response between the familiar and a novel word in the test phase, signalling recognition. Instead, a failure in word recognition would reveal that a voice change is not sufficient to overcome the interference effect previously reported with this paradigm. Another remarkable difference between this and previous studies is the implementation of a within-subject design by having two familiarization-interference-test sequences (one testing the responses to novel words and another one testing the responses to familiar words). This design controls for differences in anatomy, physiology, and brain activity across individuals while increasing statistical power.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>In this paradigm, responses are expected to change over time due to habituation and recognition dynamics. Accordingly, it is not appropriate to average responses across blocks belonging to the familiarization and test phases. Block-level analyses were thus conducted using Linear Mixed Models (LMM), which are suited to handle missing values. This approach was necessary because each subject provides a unique instance for each block, which inevitably leads to missing values in the dataset— for example, when a motion artifact renders an entire block invalid for that subject. We used the mean hemodynamic response over each block and the six Regions of Interest (ROIs) covered by the probe as the dependent variable. We decided to analyse the data over ROIs since channel-level analysis is potentially more susceptible to optodes placement differences, and increasing the number of comparisons in a protocol that already needs to compare activation over multiple blocks. Nevertheless, analysing the data at the channel level yielded similar results (see Supplementary Table 2). The ROIs were symmetric between hemispheres and included the inferior frontal gyrus left and right (IFGl, IFGr), the superior temporal gyrus left and right (STGl, STGr), and the parietal lobe left and right (PLl, PLr) (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). We modelled fixed effects (e.g., condition: <italic>same</italic> or <italic>novel</italic>) nested within the block number and the ROIs, while including participants as random effects. Each such model provides whether there are significant fixed effects in each block and ROI without the need for correction for multiple comparisons for the number of blocks and ROIs. Only results for oxy-haemoglobin (HbO) are presented here. Results for deoxy-haemoglobin (HbR) were less clear and are presented in the SI (Supplementary Figure 2).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental protocol.</title>
<p><bold>(A)</bold> Illustrative 42-channel fNIRS Montage. S (red) = source, D (blue) = detector. Placement indicated using the 10-10 standard EEG system. Regions of interest are indicated in yellow = inferior frontal gyrus (IFG), in green = superior temporal gyrus (STG), and in pink = parietal lobes (PL). <bold>(B)</bold> Familiarization-interference-test paradigm. Each subject was tested in two sequences separated by 9 minutes of silence: in one sequence, newborns heard the same word during familiarization and test (same-word condition; X u X), and in the other sequence, a novel word was presented during the test phase (novel-word condition; Y w Z). The order of the conditions, the words and the voices used in the different phases were counterbalanced across participants.</p></caption>
<graphic xlink:href="677368v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s2a">
<title>Activity during familiarization</title>
<p>To assess potential habituation and novelty effects commonly seen in fNIRS data, we first tested when the activity differed from zero by fitting the LMM <italic>act ∼-1+block:ROI+(1|sub)</italic> during the familiarization blocks. This model provides one coefficient for each ROI and block (<italic>β(ROI<sub>j</sub>, block<sub>i</sub>)</italic>) representing the activation. The model showed a positive activation in block 2 within left IFG (<italic>β(IFGl, b2)=0.194, SE=0.064, p = 0.024</italic>) and during blocks 4 and 5 within left STG (<italic>β(STGl, b4)=0.173, SE=0.065, p = 0.008; β(STGl, b5)=0.128, SE=0.063, p = 0.044</italic>) (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). Additionally, we tested for linear changes in activity by fitting the LMM <italic>act ∼-1+ROI+ROI:blocknumber+(1|sub)</italic>, with <italic>blocknumber</italic> ranging from 0 to 4. By fitting this model, in each ROI, one coefficient for the intercept representing the activity at the first block, and one coefficient for the slope quantifying any linear change are obtained. The model showed a significant intercept on the left IFG (intercept=0.1105, SE=0.0535, p=0.040), representing an initial positive activation and a significant positive slope in the left STG (slope=0.0396, SE=0.018, p=0.029), denoting a sustained increase in activity (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). An analogue analysis for the interference phase can be found in the SI (Supplementary Figure 4).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Standard recognition response with decreased activity for the familiar words and increased activity for the novel words in the test phase.</title>
<p><bold>(A)</bold> Mean activity for HbO per block during the familiarization, interference, and test phases. Error bars represent the standard errors. The black continuous line depicts responses averaged across all participants and conditions. The same-word condition (green) and the novel-word condition (purple) are plotted in the test phase. The black asterisks during the familiarization and interference phases indicate that the response differed from zero. The red lines indicate a significant linear trend, as indicated by the red asterisks. Black asterisks during the test phase indicate significant differences between conditions. <bold>(B)</bold> HRFs for HbO during the second block of the test phase, when relevant differences were observed between conditions. Shaded areas represent the standard error.</p></caption>
<graphic xlink:href="677368v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>Word recognition</title>
<p>We assessed recognition responses in the test phase by testing whether the activation pattern differed between the familiar and novel words. We employed an LMM, including condition as a fixed factor nested within the ROIs and blocks of the test phase <italic>act∼-1+block:ROI+block:ROI:condition+(1|sub)</italic>. Such a model provides for each ROI and block one coefficient quantifying the activation in one of the conditions and another the difference between conditions. The model showed a significantly higher activation during the second block of the test phase for the <italic>novel-word</italic> than the <italic>same-word</italic> condition over IFG and STG (<italic>β(IFGl, b2)=0.322, SE=0.133, p = 0.015; β(IFGr, b2)=0.265, SE=0.133, p = 0.045; β(STGl, b2)=0.443, SE=0.133, p = 0.0009; β(STGr, b2)=0.348, SE=0.133, p = 0.009</italic>). Activity was higher for the <italic>same-word</italic> than the <italic>novel-word</italic> condition in the fifth block over STG right (<italic>β(STGr, b5)=-0.320, SE=0.127, p = 0.012</italic>). To investigate the presence of hemispheric differences in the main effect of condition revealed by the primary analysis, we ran an LMM restricted to the second block and the IFG and the STG separately (<italic>act ∼cond*hemisphere+ (1 | sub)</italic>). We found no significant effects of hemisphere or interaction, neither over IFG nor on STG (p&gt;0.1) (see <xref rid="fig2" ref-type="fig">Figure 2A-B</xref>).</p>
</sec>
<sec id="s2c">
<title>Effects of the sequences order</title>
<p>In our within-subject design, group A first completed the same-word condition (X u X) and later the novel-word condition (Y w Z), while group B did the opposite (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). Thus, the first sequence might influence the processing of the second sequence, potentially leading to differences between sequences and groups.</p>
<p>We looked for differences during the familiarization and interference phases by fitting an LMM contrasting (1) first and second sequence, (2) groups within the first sequence, and (3) groups within the second sequence. The contrasts were nested within blocks and ROIs such that for each ROI and block, a coefficient was fitted for each contrast (see details in SI). The model showed higher activation during the second than the first familiarization in the first block over IFG and STG (<italic>β(IFGl, b1, contrast 1)=-0.254, SE=0.191, p = 0.033; β(STGl, b1, contrast 1)=-0.249, SE=0.191, p = 0.036; β(STGr, b1, contrast 1)=-0.322, SE=0.191, p = 0.0069</italic>) (Supplementary Figure 3). Differences between groups were weak and restricted to higher activation in group B than A in the first block of the first sequence over the left STG (<italic>β(STGl, b1, contrast 2)=-0.368, SE=0.182, p = 0.043</italic>) and on the first block of the second sequence over the right STG <italic>(β(STGr, b2, contrast 3)=-0.355, SE=0.175, p = 0.042</italic>). Considering the small number of data points per group and sequence, these differences are likely due to noise. See in SI the analysis for the interference phase (Supplementary Figure 4).</p>
<p>Given the differences in activation between the first and second sequences during the familiarization, we quantify linear changes in activity separately, as we did before, for both sequences together. For the first familiarization, the model showed a significant increase in activity in the left and right STG and left PL (p&lt;0.05), while during the second familiarization, the activity was higher than zero in the first block and decreased with block number on the right STG and IFG (p&lt;0.05) (detailed results are presented in Supplementary Figure 3).</p>
<p>To check for differences between the two groups during the testing phase, we fitted an LMM contrasting (1) the <italic>same-word</italic> and <italic>novel-word</italic> conditions, (2) the groups within the <italic>same-word</italic> condition (i.e., <italic>same-word</italic> presented in sequence 1 or sequence 2), and (3) the groups within the <italic>novel-word</italic> condition (i.e., <italic>novel-word</italic> presented in sequence 1 or sequence 2). The contrasts were nested within blocks and ROIs, yielding a coefficient representing the effect of each contrast in each ROI and block. In agreement with the overall results obtained when merging the two groups, the model showed a significant main effect of condition during the second block over IFG and STG (<italic>β(IFGl, b2, contrast 1)=0.334, SE=0.131, p = 0.011; β(IFGr, b2, contrast 1)=0.293, SE=0.131, p = 0.026; β(STGl, b2, contrast 1)=0.459, SE=0.131, p = 0.00050; β(STGr, b2, contrast 1)=0.367, SE=0.131, p = 0.0053</italic>), and during the fifth block over right STG (<italic>β(STGr, b5, contrast 1)=-0.358, SE=0.128, p = 0.0051</italic>). No significant differences were observed between groups (sequences) for the <italic>same-word</italic> condition (p&gt; 0.05). However, the model showed significant group differences for the <italic>novel-word</italic>. Activation was higher for the <italic>novel-word</italic> in group A (<italic>novel-word</italic> in sequence 2) than B (<italic>novel-word</italic> in sequence 1) in the second block over right IFG (<italic>β(IFGr, b2, contrast 3)=0.538, SE=0.183, p = 0.0031</italic>) and in the third block over left and right STG (<italic>β(STGl, b3, contrast 3)=0.394, SE=0.182, p = 0.031; STGr: β=0.533, SE=0.182, p = 0.0036</italic>). Instead, activity for the <italic>novel-word</italic> was higher for group B than A in the fourth block over IFG and STG (<italic>β(IFGl, b4, contrast 3)=-0.443, SE=0.198, p = 0.025; β(IFGr, b4, contrast 3)=-0.390, SE=0.198, p = 0.049; β(STGr, b4, contrast 3)=-0.403, SE=0.198, p = 0.042</italic>). Crucially, the effect observed in the second block over IFG implies an interaction effect between condition and group, since a main effect of condition was detected there. Tukey multiple comparisons showed higher activation for <italic>novel-word</italic> in group A than all the other conditions (<italic>novel-word</italic> in group B: p=0.07, <italic>same-word</italic> in group A: p=0.096, and <italic>same-word</italic> in group B: p=0.0073), confirming that the difference between conditions on the right IFG during the second block was driven by group A (<xref rid="fig3" ref-type="fig">Figure 3</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Differences in the response across groups during the second test block.</title>
<p>Boxplots represent the mean HbO activity during the second block of the test phase separated by condition (same=green, novel=purple), group (A or B), and sequence (first=full pattern or second=dotted pattern). Whiskers of the boxplot are defined based on 1.5 times the interquartile range, and data points outside these limits are plotted as circles. Asterisks indicated significant differences between conditions or groups. A significant effect of conditions was observed in left IFG and left and right STG. Instead, an interaction effect was present in right IFG with higher activity in the <italic>novel-word</italic> condition for group A.</p></caption>
<graphic xlink:href="677368v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>The role of variability in early memory processes</title>
<p>In the current study, we investigated the conditions that promote the formation of separate memory traces of linguistic stimuli at birth. We observed a persistent neural signature of recognition, namely a differential response between the familiar and novel words, by introducing a change in the speaker uttering the interference word. In <xref ref-type="bibr" rid="c9">Benavides-Varela et al. (2011)</xref>, word recognition in neonates vanished when they hear an interference word pronounced by the same speaker that uttered the familiarization word, thus the shared voice feature could have increased the level of perceived acoustic overlap (<xref ref-type="bibr" rid="c4">Apfelbaum &amp; McMurray, 2011</xref>), causing interference. In our study, the presence of a new speaker might rather act as a conspicuous cue signalling the beginning of a new acoustic episode and facilitating the separation of linguistic memory traces.</p>
<p>These results demonstrate that, under certain conditions, newborns can retain verbal memories even when the brain language networks continuously receive new verbal information, as in real life. These results are in line with episodic models of early speech perception assuming that infants initially store words in an instance-specific fashion comprising both phonological details and speaker identity (<xref ref-type="bibr" rid="c40">Jusczyk, 1997</xref>; <xref ref-type="bibr" rid="c78">Werker &amp; Curtin, 2005</xref>). Furthermore, the findings extend these models by offering empirical evidence of episodic encoding even in newborns. This suggests that early word-form representations are, at least to some extent, linked to the acoustic realization of the word and that, when it comes to early signal-to-word form mappings, the newborn brain attributes significant relevance to voices. The speaker’s identity may thus represent a critical distinguishing factor essential for early human communication and memory. <xref ref-type="bibr" rid="c30">Forgács et al. (2022)</xref> recently showed that alternation between female and male voices, combined with partial variability in the syllable stream, elicited greater activation in the left fronto-temporal regions. This finding suggests that the facilitation of verbal memory in newborns might also be related to the heightened neural activation associated with communicative attribution. In this view, infants may interpret such vocal alternations as indicative of a communicative exchange, thereby enhancing their ability to segregate and store the pseudo-words presented as stimuli.</p>
<p>These findings speak to the relevance of certain cues in the sequential processing of speech input, but do not inform us about the possibility that newborns can handle indexical variation (i.e., speaker changes or changes in intonation and emotional content) during the presentation of the word in the familiarization phase or recognize the familiar word irrespective of possible indexical variations in the test. There are some hints in the literature suggesting that this might be the case. Newborns robustly encode words presented in concomitance with other words, suggesting that word-memories can be formed in the face of input variability (<xref ref-type="bibr" rid="c10">Benavides-Varela et al., 2012</xref>). Moreover, newborns show recognition of pseudowords despite prosodic differences (<xref ref-type="bibr" rid="c29">Fló et al., 2019</xref>) and compute regularities over phonetic content, disregarding the voice content (<xref ref-type="bibr" rid="c28">Fló et al., 2025</xref>). Thus, it is possible that if a variety of diverse tokens are presented during learning, a robust and generalizable representation could emerge as early as birth. While this question lies beyond the scope of the present study, it could provide additional insights into early word recognition processes.</p>
</sec>
<sec id="s3b">
<title>Signature of word recognition and areas recruited for memory retrieval</title>
<p>In the current study, we observed the typical recognition response characterized by an increase in activity for the novel word and a decrease for the familiar one, consistent with the results of previous studies using a similar paradigm. Although the fNIRS system and optodes positioning slightly differed from those of previous studies (e.g., Benavides-Varela and colleagues’ system covered more prefrontal areas, whilst our configuration only reached the IFG), the activation pattern in the temporal and frontal areas is generally consistent across studies. In the present study, the effect was bilateral over the IFG and STG, known to play a crucial role in language processing and in interpreting vocal social cues in the left and right hemisphere respectively. In particular, left frontal regions, including the IFG, are associated with processing, retrieving, and manipulating phonological information (e.g., <xref ref-type="bibr" rid="c15">Bunge, 2001</xref>; <xref ref-type="bibr" rid="c36">Hickok &amp; Poeppel, 2007</xref>; <xref ref-type="bibr" rid="c56">Novick et al., 2010</xref>; <xref ref-type="bibr" rid="c75">Thompson-Schill et al., 1997</xref>), and the left STG plays a crucial role in phonological and semantic processing (<xref ref-type="bibr" rid="c36">Hickok &amp; Poeppel, 2007</xref>) by encoding fast temporal (phonetic) information (<xref ref-type="bibr" rid="c24">DeWitt &amp; Rauschecker, 2012</xref>; <xref ref-type="bibr" rid="c52">Mesgarani et al., 2014</xref>; <xref ref-type="bibr" rid="c80">Zatorre &amp; Belin, 2001</xref>) and integrating auditory information within verbal memory (<xref ref-type="bibr" rid="c16">Cabeza &amp; Nyberg, 2000</xref>). Conversely, speaker recognition relies primarily on a right-lateralized network (<xref ref-type="bibr" rid="c49">Mathias &amp; Von Kriegstein, 2014</xref>), with the right IFG and STG essential for processing prosody, rhythm, and vocal social cues such as emotional state and intent (<xref ref-type="bibr" rid="c1">Agus et al., 2017</xref>; <xref ref-type="bibr" rid="c6">Belin et al., 2000</xref>, <xref ref-type="bibr" rid="c5">2002</xref>; <xref ref-type="bibr" rid="c12">Bodin et al., 2018</xref>; <xref ref-type="bibr" rid="c25">Fecteau et al., 2004</xref>; <xref ref-type="bibr" rid="c63">Pernet et al., 2015</xref>; <xref ref-type="bibr" rid="c79">Wildgruber et al., 2006</xref>; <xref ref-type="bibr" rid="c81">Zatorre et al., 2002</xref>).</p>
<p>Precursors of the same organization and hemispheric specialization seem to be in place early on in life (<xref ref-type="bibr" rid="c21">Dehaene-Lambertz &amp; Baillet, 1998</xref>; <xref ref-type="bibr" rid="c47">Mahmoudzadeh et al., 2013b</xref>; <xref ref-type="bibr" rid="c74">Telkemeyer et al., 2009</xref>), including the activation of left fronto-temporal areas associated with language processing (<xref ref-type="bibr" rid="c3">Alexopoulos et al., 2021</xref>, <xref ref-type="bibr" rid="c2">2022</xref>; <xref ref-type="bibr" rid="c22">Dehaene-Lambertz et al., 2002</xref>; <xref ref-type="bibr" rid="c60">Peña et al., 2003</xref>) and functional specialization of the right STS for voice processing (<xref ref-type="bibr" rid="c11">Blasi et al., 2011</xref>; <xref ref-type="bibr" rid="c17">Cheng et al., 2012</xref>; <xref ref-type="bibr" rid="c34">Grossmann et al., 2010</xref>; <xref ref-type="bibr" rid="c69">Schönwiesner et al., 2005</xref>; <xref ref-type="bibr" rid="c70">Simon et al., 2009</xref>). The different responses we observed between new and familiar words after a three-minute retention period align with the retrieval of the verbal memory. Therefore, the bilateral concurrent responses over the IFG and STG suggest that linguistic and nonlinguistic features of the word contribute to the recognition response in this context.</p>
</sec>
<sec id="s3c">
<title>Timing of the response: word recognition in the second block of the test phase</title>
<p>Factors including experimental design and stimulus complexity are known to influence hemodynamic responses in newborns and infants across tasks (<xref ref-type="bibr" rid="c39">Issard &amp; Gervain, 2018</xref>). In this paradigm, an interplay between familiarization length and the presence of interfering sounds might determine when the differential response between a novel and a familiar stimulus emerges. In simple experiments, recognition is detected in the first block of the test when a single identical word is repeated over 6 minutes in the familiarization and when no interfering sounds are presented during the retention interval (e.g., <xref ref-type="bibr" rid="c9">Benavides-Varela et al., 2011</xref>). In more complex designs, the recognition was delayed to the second block when an interfering word alternates with the to-be-remembered word during encoding (<xref ref-type="bibr" rid="c10">Benavides-Varela et al., 2012</xref>). Similarly, in the current study, the recognition emerged in the second block of the test phase when an interfering word sound was presented in the retention phase. Thus, while newborns can recognize word sounds under complex conditions, facing these challenges influences the timing of the recognition response in the test phase, requiring additional cues or extended processing time for activation.</p>
</sec>
<sec id="s3d">
<title>Familiarization phase</title>
<p>Stable activity was registered with no obvious attenuation of the neural response over the three minutes in the familiarization phase. This general pattern was observed in most areas but in the left STG, where the neural response showed repetition enhancement over time. Neural suppression (habituation) or enhancement, while expected in the context of repeated stimuli, is not consistently found across fNIRS studies in infants and newborns. There might be various factors that influence the hemodynamic patterns over time. First, some studies using a protocol similar to ours found habituation over the left frontal areas in newborns when target words are presented in “ecological conditions”, that is, interleaved with other words (<xref ref-type="bibr" rid="c10">Benavides-Varela et al., 2012</xref>). By contrast, habituation is not reported when the familiarization is homogeneous (<xref ref-type="bibr" rid="c7">Benavides-Varela, 2012</xref>; <xref ref-type="bibr" rid="c9">Benavides-Varela et al., 2011</xref>), as in the current study. This suggests that the amount of information present during the learning phase modulates newborns’ fNIRS neural dynamics. The role of stimulus complexity has also been demonstrated in fNIRS studies of rule-learning in newborns. While highly variable speech sequences elicited left-lateralized repetition enhancement across blocks for ABB artificial grammar and no variations for ABC grammar (<xref ref-type="bibr" rid="c31">Gervain et al., 2008</xref>), simpler stimuli and presentation conditions (blocked rather than interleaved) evoked a stable response for the simpler ABB grammars and a repetition enhancement effect over time for ABC grammars (<xref ref-type="bibr" rid="c14">Bouchon et al., 2015</xref>). Second, methodological factors such as the frequency and number of stimulus repetitions are known to influence the habituation (<xref ref-type="bibr" rid="c66">Rankin et al., 2009</xref>). Thus, the sparse stimuli presentation typical of fNIRS block-designs (with stimuli followed by periods of 20-25s of silence), along with the reduced number of blocks employed in the present study, may have also contributed to the patterns observed. Third, <xref ref-type="bibr" rid="c42">Katus et al. (2023)</xref> recently tested habituation to a female voice in 1-month-old (asleep), 5-month-old (awake), and 18-month-old (awake) infants. They found that habituation began to emerge at five months and became strong by eighteen months. Similarly, another study revealed stronger effects of habituation in 8-month-old awake infants compared to 5-month-olds (<xref ref-type="bibr" rid="c44">Lloyd-Fox et al., 2019</xref>). Altogether, these studies suggest that characteristics of the infant may also influence habituation as measured by fNIRS. It is therefore likely that all these factors (i.e., variability of stimuli, frequency of stimulus presentation, duration of familiarization, participants’ age, and behavioural state) modulated the responses observed in the current study. Future research should carefully control these variables to further explore their role in learning and memory formation at birth.</p>
</sec>
<sec id="s3e">
<title>Habituation, recognition, and novelty detection differences between groups</title>
<p>When interpreting the patterns in the familiarization, it is important to consider baseline activity. This consideration is especially relevant in within-subject designs, as the responses in the second session might be influenced by what newborns experienced in the first session. Our analysis captured these effects by showing higher activity in the first block of the second compared to the first familiarization sequence. These results likely reflect a novelty response since all participants in the second familiarization session heard a new speaker pronouncing a completely novel word. At the same time, there is evidence that newborns can retain information from the first session over a 9-minute silent pause, allowing them to compare previously experienced episodes with newly encountered ones. These baseline differences result in distinct patterns over time: there is initial stronger activity followed by attenuation over blocks in the second sequences, while significant enhancement of the hemodynamic response is observed in the first sequences (Supplementary Figure 3A).</p>
<p>The within-subjects design also offers a valuable opportunity to investigate the responses to familiar and novel words when infants first heard a familiar word at the test, followed by a novel one in the second sequence, or vice versa. The recognition response to the familiar word showed no modulation by group. However, group A, which encountered the novel word condition during the second testing sequence, showed a stronger response in the right IFG compared to group B, which experienced it in the first testing sequence. This effect, although unexpected, could be explained by the number of phonological or speaker changes newborns experienced until the novel stimulus was presented. Indeed, while the novel word corresponds to the fourth change for newborns in group A, it constitutes the second one for participants in group B. Variability of the stimulus facilitates learning and induces significant increments in attentional arousal (<xref ref-type="bibr" rid="c19">Cooper &amp; Aslin, 1989</xref>; <xref ref-type="bibr" rid="c26">Fernald &amp; Kuhl, 1987</xref>; <xref ref-type="bibr" rid="c76">Trainor et al., 1997</xref>), which might be reflected in the greater reactivity to novel information observed in group A. While more data should be gathered to better understand this phenomenon, the localization of the differential response in the right-lateralized areas (IFG and STG) further indicates that it pertains to the processing of various vocal cues.</p>
<p>Understanding the mechanisms governing memory and the factors enhancing it is crucial for comprehending language development. This study assessed newborns’ ability to retain a combination of speech sounds in the presence of acoustically novel interference. The findings showed that acoustic variability promotes separate memory traces of linguistic content rather than fully interfering with them. The presence of a new speaker may thus signal a new acoustic episode and facilitate the separation of linguistic memory traces. This suggests that the ability to encode information about the speaker is a fundamental process, potentially rooted in early brain mechanisms of cognitive development. The study carries significant theoretical implications. It suggests that humans are capable of binding content and source information, a hallmark of episodic memory processes (i.e., <italic>what</italic> and <italic>who</italic>), far earlier than previously assumed. In practical terms, the study highlights the relevance of multiple speakers to facilitate memory formation, tracing a possible link between everyday experiences and early emerging language-learning abilities in human infants.</p>
</sec>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Healthy full-term human newborns from a normal pregnancy (i.e., with no pathologies, perinatal, or neurological complications attested) were tested. Selection criteria included gestational age (GA) 37-42 weeks (range [37+1, 41+1]), Apgar scores ≥ 8 in the fifth and tenth minutes, absence of cephalohematoma or other conditions that could possibly affect cortical hemodynamics, intact hearing, head diameter within 32.5–37.0 cm range, and weight ≥ 2.5 Kg. Neonates were recruited from the Neonatal Care of the Obstetric Division of the University Hospital of Padova between May 2023 and September 2023. Informed consent for participation in the experiment was obtained from parents. The Ethics Committee for Clinical Research of the Province of Padova, Italy, approved the study. Thirty-two infants who provided good quality data were included in the study (18 females; age range [0, 4] days; mean weight 3.364 Kg, SD 0.308 Kg). Eleven additional neonates were tested but not included in the analyses due to fussiness (not even five blocks free of artefacts in at least one of the testing sequences) (n=4), bad quality signal (more than 15 channels out of 42 marked as non-functional) (n=6), and technical problems (n=1).</p>
</sec>
<sec id="s4b">
<title>Stimuli</title>
<p>Five pseudowords (CVCV structure, stressed on the first syllable) were used in the study (target and test words: /<italic>mita</italic>/, /<italic>pelu</italic>/, /<italic>voli</italic>/; interference words: /<italic>noke</italic>/, /<italic>dafo</italic>/). Two female speakers recorded the target/test words (/<italic>mita</italic>/, /<italic>pelu</italic>/, /<italic>voli</italic>/), while two male speakers recorded the interference words (/<italic>noke</italic>/, /<italic>dafo</italic>/). Pseudowords were edited using the open-source Praat software (<xref ref-type="bibr" rid="c13">Boersma &amp; van Heuven, 2001</xref>) to have a mean intensity of 70 dB and a duration of 700 ms. Detailed acoustic information can be found in the SI (Supplementary Table 1).</p>
</sec>
<sec id="s4c">
<title>Procedure and data acquisition</title>
<p>Neonates were tested in a dimly lit hospital room while lying in their cribs (N=23) or mothers’ arms (N=9), in quiet rest or sleeping, to ensure their comfort and maintain an ecologically valid environment. Pseudowords were presented through two loudspeakers using the Psychopy software (<xref ref-type="bibr" rid="c59">Peirce et al., 2019</xref>), while fNIRS data were recorded using the NIRx NIRSPort system (light sources of 760 and 850 nm, maximum intensity 25 mW per fiber per wavelength). We designed a probe configuration with 16 sources and 15 detectors forming 42 channels. The optodes were positioned according to the 10-20 system, with locations selected using the devfOLD toolbox (Fu &amp; Richards, 2021) to cover the IFG, STG, and PL (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). The average distance between sources and detectors was 2.13 cm (range = [1.75, 2.62] cm, SD = 0.21 cm), and the sampling rate was 7.63 Hz.</p>
<p>The experiment consisted of a Familiarization phase, an Interference/Retention phase, and a Test phase. Each phase lasted 3 minutes and comprised five blocks. In each of the five blocks, six pseudowords were presented (inter-stimulus interval = 0.5-1.5 s; inter-block interval = 25-35 s) (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). The same pseudoword was presented in each phase.</p>
<p>A within-subject design was implemented by having two testing sequences separated by 9 minutes of silence: in Sequence 1, neonates heard the same word during familiarization and test (same-word condition; X u X), while in Sequence 2, a novel word was presented during the test phase (novel-word condition; Y w Z). The speakers and pseudowords were completely different in the two sequences. The pseudowords used in the different phases and the speakers were counterbalanced across participants. The order of the sequences was also counterbalanced across participants, resulting in Group A, presented with Sequence 1 and then Sequence 2, and Group B, presented with Sequence 2, followed by Sequence 1.</p>
<p>The paradigm was a modified version of a previously used experimental protocol (<xref ref-type="bibr" rid="c7">Benavides-Varela, 2012</xref>; <xref ref-type="bibr" rid="c9">Benavides-Varela et al., 2011</xref>, <xref ref-type="bibr" rid="c10">2012</xref>). The Familiarization phase was reduced from ten to five blocks based on previous data showing that five blocks already result in habituation (<xref ref-type="bibr" rid="c10">Benavides-Varela et al., 2012</xref>) and to accommodate the two sequences within a single testing session. In addition, the retention period was extended from two to three minutes.</p>
</sec>
<sec id="s4d">
<title>Data Processing and Analysis</title>
<sec id="s4d1">
<title>Preprocessing</title>
<p>The first steps of data pre-processing were performed using custom functions and functions of the Homer3 fNIRS package (<ext-link ext-link-type="uri" xlink:href="https://openfnirs.org/software/homer/homer3/">https://openfnirs.org/software/homer/homer3/</ext-link>; (<xref ref-type="bibr" rid="c38">Huppert et al., 2009</xref>) in Matlab 2024a. We first converted intensity to optical density using the Homer3 function hmrR_Intensity2OD and detected motion artifacts on optical density using a custom function. In brief, a copy of the data was created, and band-pass filtered between 0.01 and 0.7 Hz. Then, the maximum change in sliding time windows of 2 s (time step one sample) was computed, and a relative rejection threshold was obtained for each channel as <italic>thresh</italic> = <italic>q</italic><sub>3</sub> + 2 × (<italic>q</italic><sub>3</sub> − <italic>q</italic><sub>1</sub>), where <italic>q</italic><sub>3</sub> is the third quartile of the maximum changes distribution and <italic>q</italic><sub>1</sub> the first quartile. Using relative thresholds results in a better trade-off between data recovery and artifact detection without needing to optimize the thresholds for each experiment and subject (<xref ref-type="bibr" rid="c29">Fló et al., 2019</xref>, <xref ref-type="bibr" rid="c27">2022</xref>). Time windows with a maximum change above the threshold were rejected, obtaining a rejection/inclusion matrix (tIncCh_MotArt) of the same size as the data. The procedure was repeated thrice or until less than 0.5 % of the data was rejected. Finally, a mask of 1 s was applied to the rejected data.</p>
<p>We used three metrics for channel pruning (i.e., defining non-functional channels): signal saturation, signal-to-noise ratio (SNR), and Scalp Coupling Index (SCI); for each of them, a matrix of the size of the data containing the metric per channel and sample was obtained. The saturation matrix was computed, marking saturated samples per channel when the intensity was outside the range [10<sup>-6</sup>, 2.5]. The SNR was computed in sliding time windows (length 5 s, step 2.5 s) as <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="677368v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> where <italic>int</italic> is the measured intensity. The matrix with the SNR was obtained based on the SNR in each time window. The SCI (<xref ref-type="bibr" rid="c65">Pollonini et al., 2014</xref>) was computed in sliding time windows (length 5 s, step 2.5 s) on the optical density band-pass filtered around the heartbeat frequency (heartbeat rate ± 0.4 Hz). The SCI matrix was then obtained. The heartbeat was estimated using the fNIRS recording in sliding time windows (length 60 s, step 15 s) as follows: the optical density was band pass filtered between 0.8 and 3.3 Hz, PCA was applied, and the autocorrelation was computed for the first principal component. Then, the cardiac frequency was estimated as <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="677368v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> where <italic>δ</italic> is the time of the first peak of the autocorrelation –after the peak at zero-lag peak. The three metrics were evaluated on data segments free of motion artifacts for pruning channels (we call them <italic>tInc_prunning</italic>). <italic>tInc_prunning</italic> segments were defined as those with less than 30 % of the channels affected by motion artifacts and lasting at least 15 s (rejected segments shorter than 2 s were re-included). A channel was pruned if more than 30 % of the samples included in <italic>tInc_prunning</italic> showed: (1) saturation, (2) SNR&lt;15, or (3) SCI&lt;0.6. Subjects with more than 15 out of 42 channels pruned were excluded from the analysis.</p>
<p>Artifact correction techniques can reduce artifacts’ size, but no meaningful data can be recovered if the duration of the artifact is longer than an HRF. Since infants’ data might be contaminated with strong and long motion artifacts, we used the rejection matrix obtained from the artifacts detection step (<italic>tIncCh_MotArt</italic>) to define long segments heavily contaminated by motion and later reject blocks overlapping with them. These contaminated long-segments were defined as samples with more than 50% of channels contaminated with motion artifacts and lasting at least 10s. Note that before the bad-segments definition, included segments lasting less than 5 seconds were also rejected. This decision was made because sandwiched periods (i.e., rejected-included-rejected) usually correspond to fully bad segments where the rejection algorithm did not mark all as bad). We call the included segments <italic>tInc</italic>. Afterward, we corrected motion artifacts by applying Spline interpolation (<xref ref-type="bibr" rid="c67">Scholkmann et al., 2010</xref>) using the Homer3 function hmrR_MotionCorrectSpline (p = 0.99), followed by Wavelet correction (<xref ref-type="bibr" rid="c53">Molavi &amp; Dumont, 2012</xref>) using the Homer3 function hmrR_MotionCorrectWavelet (iqr = 1.5). Finally, we re-detected motion artifacts on the corrected data, and if new segments had more than 50 % of channels rejected, they were marked as bad in <italic>tInc</italic>. A final rejection matrix (<italic>tIncCh</italic>) was obtained based on the last artifacts detection, saturation, SNR&lt;15, and SCI&lt;0.6, and later used to reject specific channels from included blocks.</p>
<p>Subsequent steps of the analysis were performed in Python using MNE (version 1.7.0) and MNE-NIRS (version 0.6.0) (<xref ref-type="bibr" rid="c45">Luke et al., 2021</xref>). The data were band-passed filtered using an FIR filter between 0.01 and 0.3 Hz (transition bandwidth 0.005 Hz for high pass and 0.1 Hz for low pass) and converted to optical density using the modified Beer-Lambert law (partial path length factor 4.75; <xref ref-type="bibr" rid="c68">Scholkmann &amp; Wolf, 2013</xref>). To obtain the HRF, data were segmented from -5 to 20 s from the onset of each stimulus block, linearly detrended, and baseline corrected using the pre-stimulus interval. Channels for specific blocks were rejected if: (1) marked as bad during more than 50 % of the block in the rejection matrix <italic>tIncCh</italic>, (2) had an outlier peak-to-peak signal change defined as &gt; <italic>q</italic><sub>3</sub> + 2 × (<italic>q</italic><sub>3</sub> – <italic>q</italic><sub>1</sub>), computed on normalized data across channels and blocks. Blocks were rejected if: (1) overlapped with not included segments (i.e., <italic>tInc</italic>=0), (2) had more than 35% of the active channels rejected. Subjects were rejected if more than 35% (more than 15 out of 42) of the channels were excluded from the recording (pruned channels). A testing sequence (familiarization/retention/test) for a given subject was excluded if less than five blocks were retained out of the 15 blocks (5 familiarization, 5 interference, 5 test). Of the 32 subjects with included data, 31 completed the same-word condition sequence, and 26 completed the novel-word condition sequence (25 both). On average, we obtained data for 23.5 subjects (range=[19, 28], std=2.47) for each experimental block. Finally, the data recorded per channel were combined into six symmetric ROIs: IFG left and right, STG left and right, and PL left and right (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). The mean activity for each block over the time window [0, 15] s was used for statistical analysis. The time window was determined based on the grand average HRF across all blocks and subjects, which peaked at ∼7 s from the onset of the stimulus and went back to baseline level at ∼15 s (Supplementary Figure 1).</p>
</sec>
</sec>
<sec id="s4e">
<title>Statistical analysis</title>
<p>Changes in the concentration of oxygenated hemoglobin (HbO) and deoxygenated hemoglobin (HbR) were calculated. We used LMM for the analysis, with the mean activation as the dependent variable. Fixed effects were nested within the block number and the ROIs, while the participant was included as a random effect. The models were solved in R (version 4.2.1) using the lme4 package (version 1.1.31).</p>
</sec>
</sec>
</body>
<back>
<sec id="s6a" sec-type="data-availability">
<title>Data availability</title>
<p>The anonymized data collected are available as open data via the University of Padova online data repository: <ext-link ext-link-type="uri" xlink:href="https://researchdata.cab.unipd.it/1403/">https://researchdata.cab.unipd.it/1403/</ext-link> (DOI: 10.25430/researchdata.cab.unipd.it.00001403).</p>
<sec id="s6b">
<title>Code availability</title>
<p>The code used for data preprocessing and analysis is available from the corresponding author upon request.</p>
</sec>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We would like to express our gratitude to the Neonatal Care Unit of the Obstetric Division of the University Hospital of Padova for the recruitment of neonates and to the parents of newborns for their participation.</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6c">
<title>Author Contributions</title>
<p>Conceptualisation: E.V., A.F., SB-V; Methodology: E.V., A.F., SB-V; Data collection: E.V., A.F., E.B.; Formal analysis: A.F.; Writing – original draft preparation; review &amp; editing: E.V., A.F., E.B., SB-V; Supervision: SB-V; Project administration: SB-V; Funding acquisition: SB-V.</p>
</sec>
<sec id="s5">
<title>Funding information</title>
<p>This work was funded by the European Union (ERC-2021-STG, IN-MIND, Grant 101043216).</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Agus</surname>, <given-names>T. R.</given-names></string-name>, <string-name><surname>Paquette</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Suied</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Pressnitzer</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Belin</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Voice selectivity in the temporal voice area despite matched low-level acoustic cues</article-title>. <source>Scientific Reports</source>, <volume>7</volume>(<issue>1</issue>), <fpage>11526</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-017-11684-1</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alexopoulos</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Giordano</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Doering</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Seidl</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Russwurm</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Greenwood</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Berger</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Bartha-Doering</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Sex differences in neural processing of speech in neonates</article-title>. <source>Cortex</source>, <volume>157</volume>, <fpage>117</fpage>–<lpage>128</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2022.09.007</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alexopoulos</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Giordano</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Janda</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Seidl</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Doering</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Berger</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Bartha-Doering</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The duration of intrauterine development influences discrimination of speech prosody in infants</article-title>. <source>Developmental Science</source>, <volume>24</volume>(<issue>5</issue>), <fpage>e13110</fpage>. <pub-id pub-id-type="doi">10.1111/desc.13110</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Apfelbaum</surname>, <given-names>K. S.</given-names></string-name>, &amp; <string-name><surname>McMurray</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Using Variability to Guide Dimensional Weighting: Associative Mechanisms in Early Word Learning</article-title>. <source>Cognitive Science</source>, <volume>35</volume>(<issue>6</issue>), <fpage>1105</fpage>–<lpage>1138</lpage>. <pub-id pub-id-type="doi">10.1111/j.1551-6709.2011.01181.x</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Belin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Zatorre</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Ahad</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Human temporal-lobe response to vocal sounds</article-title>. <source>Cognitive Brain Research</source>, <volume>13</volume>(<issue>1</issue>), <fpage>17</fpage>–<lpage>26</lpage>. <pub-id pub-id-type="doi">10.1016/S0926-6410(01)00084-2</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Belin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Zatorre</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Lafaille</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Ahad</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Pike</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Voice-selective areas in human auditory cortex</article-title>. <source>Nature</source>, <volume>403</volume>(<issue>6767</issue>), <fpage>309</fpage>–<lpage>312</lpage>. <pub-id pub-id-type="doi">10.1038/35002078</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2012</year>). <source>The Origin of Memory for Language</source>. <publisher-name>SISSA</publisher-name>, <publisher-loc>Trieste - Italy</publisher-loc>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Gervain</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Learning word order at birth: A NIRS study</article-title>. <source>Developmental Cognitive Neuroscience</source>, <volume>25</volume>, <fpage>198</fpage>–<lpage>208</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2017.03.003</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gómez</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Macagno</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Bion</surname>, <given-names>R. A. H.</given-names></string-name>, <string-name><surname>Peretz</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Mehler</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Memory in the Neonate Brain</article-title>. <source>PLoS ONE</source>, <volume>6</volume>(<issue>11</issue>), <fpage>e27497</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0027497</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hochmann</surname>, <given-names>J.-R.</given-names></string-name>, <string-name><surname>Macagno</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Nespor</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Mehler</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Newborn’s brain activity signals the origin of word memories</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>109</volume>(<issue>44</issue>), <fpage>17908</fpage>–<lpage>17913</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1205413109</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blasi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mercure</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lloyd-Fox</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Thomson</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brammer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sauter</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Deeley</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Barker</surname>, <given-names>G. J.</given-names></string-name>, <string-name><surname>Renvall</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Deoni</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gasston</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>S. C. R.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>M. H.</given-names></string-name>, <string-name><surname>Simmons</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Murphy</surname>, <given-names>D. G. M</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Early Specialization for Voice and Emotion Processing in the Infant Brain</article-title>. <source>Current Biology</source>, <volume>21</volume>(<issue>14</issue>), <fpage>1220</fpage>–<lpage>1224</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2011.06.009</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bodin</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Takerkart</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Belin</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Coulon</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Anatomo-functional correspondence in the superior temporal sulcus</article-title>. <source>Brain Structure and Function</source>, <volume>223</volume>(<issue>1</issue>), <fpage>221</fpage>–<lpage>232</lpage>. <pub-id pub-id-type="doi">10.1007/s00429-017-1483-2</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boersma</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>van Heuven</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Speak and unSpeak with PRAAT</article-title>. <source>Glot International</source>, <volume>5</volume>, <fpage>341</fpage>–<lpage>347</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bouchon</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Nazzi</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Gervain</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Hemispheric Asymmetries in Repetition Enhancement and Suppression Effects in the Newborn Brain</article-title>. <source>PLOS One</source>, <volume>10</volume>(<issue>10</issue>), <fpage>e0140160</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0140160</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bunge</surname>, <given-names>S. A</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Prefrontal regions involved in keeping information in and out of mind</article-title>. <source>Brain</source>, <volume>124</volume>(<issue>10</issue>), <fpage>2074</fpage>–<lpage>2086</lpage>. <pub-id pub-id-type="doi">10.1093/brain/124.10.2074</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cabeza</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Nyberg</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Neural bases of learning and memory: Functional neuroimaging evidence</article-title> <source>Current Opinion in Neurology</source>, <volume>13</volume>(<issue>4</issue>), <fpage>415</fpage>–<lpage>421</lpage>. <pub-id pub-id-type="doi">10.1097/00019052-200008000-00008</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>S.-Y.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>H.-Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>P.-Y.</given-names></string-name>, &amp; <string-name><surname>Decety</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Voice and Emotion Processing in the Human Neonatal Brain</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>24</volume>(<issue>6</issue>), <fpage>1411</fpage>–<lpage>1419</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00214</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheour-Luhtanen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Alho</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kujala</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Sainio</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Reinikainen</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Renlund</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Aaltonen</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Eerola</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Näätänen</surname>, <given-names>R</given-names></string-name></person-group>. (<year>1995</year>). <article-title>Mismatch negativity indicates vowel discrimination in newborns</article-title>. <source>Hearing Research</source>, <volume>82</volume>(<issue>1</issue>), <fpage>53</fpage>–<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1016/0378-5955(94)00164-L</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cooper</surname>, <given-names>R. P.</given-names></string-name>, &amp; <string-name><surname>Aslin</surname>, <given-names>R. N</given-names></string-name></person-group>. (<year>1989</year>). <article-title>The language environment of the young infant: Implications for early perceptual development</article-title>. <source>Canadian Journal of Psychology / Revue Canadienne de Psychologie</source>, <volume>43</volume>(<issue>2</issue>), <fpage>247</fpage>–<lpage>265</lpage>. <pub-id pub-id-type="doi">10.1037/h0084216</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DeCasper</surname>, <given-names>A. J.</given-names></string-name>, &amp; <string-name><surname>Fifer</surname>, <given-names>W. P</given-names></string-name></person-group>. (<year>1980</year>). <article-title>Of Human Bonding: Newborns Prefer Their Mothers’ Voices</article-title>. <source>Science</source>, <volume>208</volume>(<issue>4448</issue>), <fpage>1174</fpage>–<lpage>1176</lpage>. <pub-id pub-id-type="doi">10.1126/science.7375928</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dehaene-Lambertz</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Baillet</surname>, <given-names>S</given-names></string-name></person-group>. (<year>1998</year>). <article-title>A phonological representation in the infant brain</article-title>. <source>NeuroReport</source>, <volume>9</volume>(<issue>8</issue>), <fpage>1885</fpage>–<lpage>1888</lpage>. <pub-id pub-id-type="doi">10.1097/00001756-199806010-00040</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dehaene-Lambertz</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Hertz-Pannier</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Functional Neuroimaging of Speech Perception in Infants</article-title>. <source>Science</source>, <volume>298</volume>(<issue>5600</issue>), <fpage>2013</fpage>–<lpage>2015</lpage>. <pub-id pub-id-type="doi">10.1126/science.1077066</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dehaene-Lambertz</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Pena</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Electrophysiological evidence for automatic phonetic processing in neonates</article-title>. <source>Neuroreport</source>, <volume>12</volume>(<issue>14</issue>), <fpage>3155</fpage>–<lpage>3158</lpage>. <pub-id pub-id-type="doi">10.1097/00001756-200110080-00034</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DeWitt</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Rauschecker</surname>, <given-names>J. P</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Phoneme and word recognition in the auditory ventral stream</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>109</volume>(<issue>8</issue>). <pub-id pub-id-type="doi">10.1073/pnas.1113427109</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fecteau</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Armony</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Joanette</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Belin</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Priming of non-speech vocalizations in male adults: The influence of the speaker’s gender</article-title>. <source>Brain and Cognition</source>, <volume>55</volume>(<issue>2</issue>), <fpage>300</fpage>–<lpage>302</lpage>. <pub-id pub-id-type="doi">10.1016/j.bandc.2004.02.024</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fernald</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Kuhl</surname>, <given-names>P</given-names></string-name></person-group>. (<year>1987</year>). <article-title>Acoustic determinants of infant preference for motherese speech</article-title>. <source>Infant Behavior and Development</source>, <volume>10</volume>(<issue>3</issue>), <fpage>279</fpage>–<lpage>293</lpage>. <pub-id pub-id-type="doi">10.1016/0163-6383(87)90017-8</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fló</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Benjamin</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Palu</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Dehaene-Lambertz</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Sleeping neonates track transitional probabilities in speech but only retain the first syllable of words</article-title>. <source>Scientific Reports</source>, <volume>12</volume>(<issue>1</issue>), <fpage>4391</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-022-08411-w</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fló</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Benjamin</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Palu</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Dehaene-Lambertz</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2025</year>). <article-title>Statistical learning beyond words in human neonates</article-title>. <source>eLife</source> <volume>13</volume>:<elocation-id>RP101802</elocation-id> <pub-id pub-id-type="doi">10.7554/eLife.101802.2</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fló</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brusini</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Macagno</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Nespor</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mehler</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Ferry</surname>, <given-names>A. L</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Newborns are sensitive to multiple cues for word segmentation in continuous speech</article-title>. <source>Developmental Science</source>, <volume>22</volume>(<issue>4</issue>), <fpage>e12802</fpage>. <pub-id pub-id-type="doi">10.1111/desc.12802</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Forgács</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Tauzin</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Gergely</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Gervain</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2022</year>). <article-title>The newborn brain is sensitive to the communicative function of language</article-title>. <source>Scientific Reports</source>, <volume>12</volume>(<issue>1</issue>), <fpage>1220</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-022-05122-0</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gervain</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Macagno</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Cogoi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Peña</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Mehler</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2008</year>). <article-title>The neonate brain detects speech structure</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>105</volume>(<issue>37</issue>), <fpage>14222</fpage>– <lpage>14227</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0806530105</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giordano</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Alexopoulos</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Spagna</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Peganc</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kothgassner</surname>, <given-names>O. D.</given-names></string-name>, <string-name><surname>Klebermass-Schrehof</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Olischar</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Berger</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Bartha-Doering</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Accent discrimination abilities during the first days of life: An fNIRS study</article-title>. <source>Brain and Language</source>, <volume>223</volume>, <fpage>105039</fpage>. <pub-id pub-id-type="doi">10.1016/j.bandl.2021.105039</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldinger</surname>, <given-names>S. D</given-names></string-name></person-group>. (<year>1996</year>). <article-title>Words and voices: Episodic traces in spoken word identification and recognition memory. <italic>Journal of Experimental Psychology: Learning</italic></article-title>, <source>Memory, and Cognition</source>, <volume>22</volume>(<issue>5</issue>), <fpage>1166</fpage>–<lpage>1183</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.22.5.1166</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grossmann</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Oberecker</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Koch</surname>, <given-names>S. P.</given-names></string-name>, &amp; <string-name><surname>Friederici</surname>, <given-names>A. D</given-names></string-name></person-group>. (<year>2010</year>). <article-title>The Developmental Origins of Voice Processing in the Human Brain</article-title>. <source>Neuron</source>, <volume>65</volume>(<issue>6</issue>), <fpage>852</fpage>–<lpage>858</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.001</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Halle</surname>, <given-names>M.</given-names></string-name></person-group><year>1985</year>). <chapter-title>Speculations about the Representations of Words in Memory</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>V. A.</given-names> <surname>Fromkin</surname></string-name></person-group> (Ed.), <source>From Memory to Speech and Back</source> (pp. <fpage>101</fpage>–<lpage>114</lpage>). .</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hickok</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Poeppel</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2007</year>). <article-title>The cortical organization of speech processing</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>8</volume>(<issue>5</issue>), <fpage>393</fpage>–<lpage>402</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2113</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Houston</surname>, <given-names>D. M.</given-names></string-name>, &amp; <string-name><surname>Jusczyk</surname>, <given-names>P. W</given-names></string-name></person-group>. (<year>2000</year>). <article-title>The role of talker-specific information in word segmentation by infants</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>26</volume>(<issue>5</issue>), <fpage>1570</fpage>–<lpage>1582</lpage>. <pub-id pub-id-type="doi">10.1037/0096-1523.26.5.1570</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huppert</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Diamond</surname>, <given-names>S. G.</given-names></string-name>, <string-name><surname>Franceschini</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Boas</surname>, <given-names>D. A</given-names></string-name></person-group>. (<year>2009</year>). <article-title>HomER: A review of time-series analysis methods for near-infrared spectroscopy of the brain</article-title>. <source>Applied Optics</source>, <volume>48</volume>(<issue>10</issue>), <fpage>D280</fpage>. <pub-id pub-id-type="doi">10.1364/AO.48.00D280</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Issard</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Gervain</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Variability of the hemodynamic response in infants: Influence of experimental design and stimulus complexity</article-title>. <source>Developmental Cognitive Neuroscience</source>, <volume>33</volume>, <fpage>182</fpage>–<lpage>193</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2018.01.009</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jusczyk</surname>, <given-names>P. W.</given-names></string-name></person-group> (<year>1997</year>). <source>The discovery of spoken language</source> (1st MIT Press pbk. ed). <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jusczyk</surname>, <given-names>P. W.</given-names></string-name>, &amp; <string-name><surname>Aslin</surname>, <given-names>R. N.</given-names></string-name></person-group> (<year>1995</year>). <article-title>Infants′ Detection of the Sound Patterns of Words in Fluent Speech</article-title>. <source>Cognitive Psychology</source>, <volume>29</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1006/cogp.1995.1010</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katus</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Blasi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>McCann</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mason</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Mbye</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Touray</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ceesay</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>De Haan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Moore</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Elwell</surname>, <given-names>C. E.</given-names></string-name>, &amp; <string-name><surname>Lloyd-Fox</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Longitudinal fNIRS and EEG metrics of habituation and novelty detection are correlated in 1–18-month-old infants</article-title>. <source>NeuroImage</source>, <volume>274</volume>, <fpage>120153</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120153</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotilahti</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nissilä</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Näsi</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Lipiäinen</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Noponen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Meriläinen</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Huotilainen</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Fellman</surname>, <given-names>V</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Hemodynamic responses to speech and music in newborn infants</article-title>. <source>Human Brain Mapping</source>, <volume>31</volume>(<issue>4</issue>), <fpage>595</fpage>–<lpage>603</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.20890</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lloyd-Fox</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Blasi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>McCann</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rozhko</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Katus</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Mason</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Austin</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Moore</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Elwell</surname>, <given-names>C. E.</given-names></string-name>, &amp; <collab>The BRIGHT project team</collab></person-group>. (<year>2019</year>). <article-title>Habituation and novelty detection fNIRS brain responses in 5- and 8-month-old infants: The Gambia and UK</article-title>. <source>Developmental Science</source>, <volume>22</volume>(<issue>5</issue>), <fpage>e12817</fpage>. <pub-id pub-id-type="doi">10.1111/desc.12817</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luke</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Larson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Shader</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Innes-Brown</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Van Yper</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>A. K. C.</given-names></string-name>, <string-name><surname>Sowman</surname>, <given-names>P. F.</given-names></string-name>, &amp; <string-name><surname>McAlpine</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Analysis methods for measuring passive auditory fNIRS responses generated by a block-design paradigm</article-title>. <source>Neurophotonics</source>, <volume>8</volume>(<issue>2</issue>):<elocation-id>025008</elocation-id>. <pub-id pub-id-type="doi">10.1117/1.NPh.8.2.025008</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahmoudzadeh</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dehaene-Lambertz</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Fournier</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kongolo</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Goudjil</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Dubois</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Grebe</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Wallois</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2013a</year>). <article-title>Syllabic discrimination in premature human infants prior to complete formation of cortical layers</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume>(<issue>12</issue>), <fpage>4846</fpage>–<lpage>4851</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1212220110</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahmoudzadeh</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dehaene-Lambertz</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Fournier</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kongolo</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Goudjil</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Dubois</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Grebe</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Wallois</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2013b</year>). <article-title>Syllabic discrimination in premature human infants prior to complete formation of cortical layers</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume>(<issue>12</issue>), <fpage>4846</fpage>–<lpage>4851</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1212220110</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Martinez-Alvarez</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Benavides-Varela</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lapillonne</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gervain</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Newborns discriminate utterance-level prosodic contours</article-title>. <source>Developmental Science</source>, <volume>26</volume>(<issue>2</issue>), <fpage>e13304</fpage>. <pub-id pub-id-type="doi">10.1111/desc.13304</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathias</surname>, <given-names>S. R.</given-names></string-name>, &amp; <string-name><surname>Von Kriegstein</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2014</year>). <article-title>How do we recognise who is speaking. <italic>Frontiers in Bioscience</italic></article-title>, <source>S</source><volume>6</volume>(<issue>1</issue>), <fpage>92</fpage>–<lpage>109</lpage>. <pub-id pub-id-type="doi">10.2741/S417</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McClelland</surname>, <given-names>J. L.</given-names></string-name>, &amp; <string-name><surname>Elman</surname>, <given-names>J. L</given-names></string-name></person-group>. (<year>1986</year>). <article-title>The TRACE model of speech perception</article-title>. <source>Cognitive Psychology</source>, <volume>18</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>86</lpage>. <pub-id pub-id-type="doi">10.1016/0010-0285(86)90015-0</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mehler</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bertoncini</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Barriere</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Jassik-Gerschenfeld</surname>, <given-names>D</given-names></string-name></person-group>. (<year>1978</year>). <article-title>Infant Recognition of Mother’s Voice</article-title>. <source>Perception</source>, <volume>7</volume>(<issue>5</issue>), <fpage>491</fpage>–<lpage>497</lpage>. <pub-id pub-id-type="doi">10.1068/p070491</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mesgarani</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Cheung</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Chang</surname>, <given-names>E. F</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Phonetic Feature Encoding in Human Superior Temporal Gyrus</article-title>. <source>Science</source>, <volume>343</volume>(<issue>6174</issue>), <fpage>1006</fpage>–<lpage>1010</lpage>. <pub-id pub-id-type="doi">10.1126/science.1245994</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Molavi</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Dumont</surname>, <given-names>G. A</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Wavelet-based motion artifact removal for functional near-infrared spectroscopy</article-title>. <source>Physiological Measurement</source>, <volume>33</volume>(<issue>2</issue>), <fpage>259</fpage>–<lpage>270</lpage>. <pub-id pub-id-type="doi">10.1088/0967-3334/33/2/259</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Müller</surname> <given-names>G. E.</given-names></string-name> &amp; <string-name><surname>Pilzecker</surname> <given-names>A</given-names></string-name></person-group>. (<year>1900</year>). <article-title>Experimentelle Beiträge zur Lehre vom Gedächtnis</article-title>. <source>Zeitschrift Für Psychologie</source>, <volume>1</volume>, <fpage>1</fpage>–<lpage>300</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Norris</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>McQueen</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Cutler</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Merging information in speech recognition: Feedback is never necessary</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>23</volume>(<issue>3</issue>), <fpage>299</fpage>–<lpage>325</lpage>. <pub-id pub-id-type="doi">10.1017/S0140525X00003241</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Novick</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Trueswell</surname>, <given-names>J. C.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Broca’s Area and Language Processing: Evidence for the Cognitive Control Connection</article-title>. <source>Language and Linguistics Compass</source>, <volume>4</volume>(<issue>10</issue>), <fpage>906</fpage>–<lpage>924</lpage>. <pub-id pub-id-type="doi">10.1111/j.1749-818X.2010.00244.x</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nygaard</surname>, <given-names>L. C.</given-names></string-name>, <string-name><surname>Sommers</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Pisoni</surname>, <given-names>D. B</given-names></string-name></person-group>. (<year>1994</year>). <article-title>Speech Perception as a Talker-Contingent Process</article-title>. <source>Psychological Science</source>, <volume>5</volume>(<issue>1</issue>), <fpage>42</fpage>–<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.1994.tb00612.x</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palmeri</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Goldinger</surname>, <given-names>S. D.</given-names></string-name>, &amp; <string-name><surname>Pisoni</surname>, <given-names>D. B</given-names></string-name></person-group>. (<year>1993</year>). <article-title>Episodic encoding of voice attributes and recognition memory for spoken words. <italic>Journal of Experimental Psychology: Learning</italic></article-title>, <source>Memory, and Cognition</source>, <volume>19</volume>(<issue>2</issue>), <fpage>309</fpage>–<lpage>328</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.19.2.309</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peirce</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gray</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Simpson</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>MacAskill</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Höchenberger</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Sogo</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kastman</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Lindeløv</surname>, <given-names>J. K</given-names></string-name></person-group>. (<year>2019</year>). <article-title>PsychoPy2: Experiments in behavior made easy</article-title>. <source>Behavior Research Methods</source>, <volume>51</volume>(<issue>1</issue>), <fpage>195</fpage>–<lpage>203</lpage>. <pub-id pub-id-type="doi">10.3758/s13428-018-01193-y</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peña</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Maki</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kovac̆ić</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Dehaene-Lambertz</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Koizumi</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Bouquet</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Mehler</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Sounds and silence: An optical topography study of language recognition at birth</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>100</volume>(<issue>20</issue>), <fpage>11702</fpage>–<lpage>11705</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1934290100</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Perani</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Saccuman</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Scifo</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Spada</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Andreolli</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rovelli</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Baldoli</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Koelsch</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Functional specializations for music processing in the human newborn brain</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>107</volume>(<issue>10</issue>), <fpage>4758</fpage>–<lpage>4763</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0909074107</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peretz</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Vuvan</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Lagrois</surname>, <given-names>M.-É.</given-names></string-name>, &amp; <string-name><surname>Armony</surname>, <given-names>J. L</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Neural overlap in processing music and speech</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>370</volume>(<issue>1664</issue>), <fpage>20140090</fpage>. <pub-id pub-id-type="doi">10.1098/rstb.2014.0090</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pernet</surname>, <given-names>C. R.</given-names></string-name>, <string-name><surname>McAleer</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Latinus</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Charest</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Bestelmeyer</surname>, <given-names>P. E. G.</given-names></string-name>, <string-name><surname>Watson</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Fleming</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Crabbe</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Valdes-Sosa</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Belin</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2015</year>). <article-title>The human voice areas: Spatial organization and inter-individual variability in temporal and extra-temporal cortices</article-title>. <source>NeuroImage</source>, <volume>119</volume>, <fpage>164</fpage>–<lpage>174</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.050</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pisoni</surname>, <given-names>D. B.</given-names></string-name>, &amp; <string-name><surname>Luce</surname>, <given-names>P. A</given-names></string-name></person-group>. (<year>1987</year>). <article-title>Acoustic-phonetic representations in word recognition</article-title>. <source>Cognition</source>, <volume>25</volume>(<issue>1–2</issue>), <fpage>21</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1016/0010-0277(87)90003-5</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pollonini</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Olds</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Abaya</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Bortfeld</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Beauchamp</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Oghalai</surname>, <given-names>J. S</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Auditory cortex activation to natural speech and simulated cochlear implant speech measured with functional near-infrared spectroscopy</article-title>. <source>Hearing Research</source>, <volume>309</volume>, <fpage>84</fpage>–<lpage>93</lpage>. <pub-id pub-id-type="doi">10.1016/j.heares.2013.11.007</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rankin</surname>, <given-names>C. H.</given-names></string-name>, <string-name><surname>Abrams</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Barry</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Bhatnagar</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Clayton</surname>, <given-names>D. F.</given-names></string-name>, <string-name><surname>Colombo</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Coppola</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Geyer</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Glanzman</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>Marsland</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>McSweeney</surname>, <given-names>F. K.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>C.-F.</given-names></string-name>, &amp; <string-name><surname>Thompson</surname>, <given-names>R. F</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Habituation revisited: An updated and revised description of the behavioral characteristics of habituation</article-title>. <source>Neurobiology of Learning and Memory</source>, <volume>92</volume>(<issue>2</issue>), <fpage>135</fpage>–<lpage>138</lpage>. <pub-id pub-id-type="doi">10.1016/j.nlm.2008.09.012</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scholkmann</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Spichtig</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Muehlemann</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Wolf</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2010</year>). <article-title>How to detect and reduce movement artifacts in near-infrared imaging using moving standard deviation and spline interpolation</article-title>. <source>Physiological Measurement</source>, <volume>31</volume>(<issue>5</issue>), <fpage>649</fpage>–<lpage>662</lpage>. <pub-id pub-id-type="doi">10.1088/0967-3334/31/5/004</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scholkmann</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Wolf</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2013</year>). <article-title>General equation for the differential pathlength factor of the frontal human head depending on wavelength and age</article-title>. <source>Journal of Biomedical Optics</source>, <volume>18</volume>(<issue>10</issue>), <fpage>105004</fpage>. <pub-id pub-id-type="doi">10.1117/1.JBO.18.10.105004</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schönwiesner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rübsamen</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Von Cramon</surname>, <given-names>D. Y.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Spectral and Temporal Processing in the Human Auditory Cortex—Revisited</article-title>. <source>Annals of the New York Academy of Sciences</source>, <volume>1060</volume>(<issue>1</issue>), <fpage>89</fpage>–<lpage>92</lpage>. <pub-id pub-id-type="doi">10.1196/annals.1360.051</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simon</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lazeyras</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Sigrist</surname>, <given-names>A.-D.</given-names></string-name>, <string-name><surname>Ecoffey</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Guatieri</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Van De Ville</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Borradori-Tolsa</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Pelizzone</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Hüppi</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2009</year>). <article-title>FMRI study of newborn perception of mother’s voice: A comparative study of premature infants at term age and term born neonates</article-title>. <source>NeuroImage</source>, <volume>47</volume>, <fpage>S54</fpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(09)70181-8</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Influences of high and low variability on infant word recognition</article-title>. <source>Cognition</source>, <volume>106</volume>(<issue>2</issue>), <fpage>833</fpage>–<lpage>870</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2007.05.002</pub-id></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Morgan</surname>, <given-names>J. L.</given-names></string-name>, &amp; <string-name><surname>White</surname>, <given-names>K. S</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Preference and processing: The role of speech affect in early spoken word recognition</article-title>. <source>Journal of Memory and Language</source>, <volume>51</volume>(<issue>2</issue>), <fpage>173</fpage>–<lpage>189</lpage>. <pub-id pub-id-type="doi">10.1016/j.jml.2004.04.004</pub-id></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spence</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Freeman</surname>, <given-names>M. S</given-names></string-name></person-group>. (<year>1996</year>). <article-title>Newborn infants prefer the maternal low-pass filtered voice, but not the maternal whispered voice</article-title>. <source>Infant Behavior and Development</source>, <volume>19</volume>(<issue>2</issue>), <fpage>199</fpage>–<lpage>212</lpage>. <pub-id pub-id-type="doi">10.1016/S0163-6383(96)90019-3</pub-id></mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Telkemeyer</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rossi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Koch</surname>, <given-names>S. P.</given-names></string-name>, <string-name><surname>Nierhaus</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Steinbrink</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Poeppel</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Obrig</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Wartenburger</surname>, <given-names>I</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Sensitivity of Newborn Auditory Cortex to the Temporal Structure of Sounds</article-title>. <source>The Journal of Neuroscience</source>, <volume>29</volume>(<issue>47</issue>), <fpage>14726</fpage>–<lpage>14733</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1246-09.2009</pub-id></mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thompson-Schill</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>D’Esposito</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Aguirre</surname>, <given-names>G. K.</given-names></string-name>, &amp; <string-name><surname>Farah</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>1997</year>). <article-title>Role of left inferior prefrontal cortex in retrieval of semantic knowledge: A reevaluation</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>94</volume>(<issue>26</issue>), <fpage>14792</fpage>–<lpage>14797</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.94.26.14792</pub-id></mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trainor</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>E. D.</given-names></string-name>, <string-name><surname>Huntley</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Adams</surname>, <given-names>B. A</given-names></string-name></person-group>. (<year>1997</year>). <article-title>The acoustic basis of preferences for infant-directed singing</article-title>. <source>Infant Behavior and Development</source>, <volume>20</volume>(<issue>3</issue>), <fpage>383</fpage>–<lpage>396</lpage>. <pub-id pub-id-type="doi">10.1016/S0163-6383(97)90009-6</pub-id></mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Van Heugten</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bergmann</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Cristia</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2015</year>). <chapter-title>The effects of talker voice and accent on young children’s speech perception</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>S.</given-names> <surname>Fuchs</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Pape</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Petrone</surname></string-name>, &amp; <string-name><given-names>P.</given-names> <surname>Perrier</surname></string-name></person-group> (Eds.) <source>Individual Differences in Speech Production and Perception</source> (pp. <fpage>57</fpage>–<lpage>88</lpage>).</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Werker</surname>, <given-names>J. F.</given-names></string-name>, &amp; <string-name><surname>Curtin</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2005</year>). <article-title>PRIMIR: A Developmental Framework of Infant Speech Processing</article-title>. <source>Language Learning and Development</source>, <volume>1</volume>(<issue>2</issue>), <fpage>197</fpage>–<lpage>234</lpage>. <pub-id pub-id-type="doi">10.1080/15475441.2005.9684216</pub-id></mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wildgruber</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Ackermann</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kreifelts</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Ethofer</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2006</year>). <chapter-title>Cerebral processing of linguistic and emotional prosody: fMRI studies</chapter-title>. In <source>Progress in Brain Research</source> (Vol. <volume>156</volume>, pp. <fpage>249</fpage>–<lpage>268</lpage>). <publisher-name>Elsevier</publisher-name>. <pub-id pub-id-type="doi">10.1016/S0079-6123(06)56013-3</pub-id></mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zatorre</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Belin</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Spectral and Temporal Processing in Human Auditory Cortex</article-title>. <source>Cerebral Cortex</source>, <volume>11</volume>(<issue>10</issue>), <fpage>946</fpage>–<lpage>953</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/11.10.946</pub-id></mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zatorre</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Belin</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Penhune</surname>, <given-names>V. B</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Structure and function of auditory cortex: Music and speech</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>6</volume>(<issue>1</issue>), <fpage>37</fpage>–<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1016/S1364-6613(00)01816-7</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109096.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Tian</surname>
<given-names>Xing</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1629-6304</contrib-id>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02vpsdb40</institution-id><institution>New York University Shanghai</institution>
</institution-wrap>
<city>Shanghai</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Fundamental</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>fundamental</bold> study reports <bold>solid</bold> evidence for early verbal episodic memory formation. The findings demonstrate that speaker identity is a crucial feature, enabling episodic-like memories from birth, and will be of interest to cognitive neuroscientists working on brain development, memory, language learning and social cognition.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109096.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This manuscript investigates whether newborns can use speaker identity to separate verbal memories, aiming to shed light on the earliest mechanisms of language learning and memory formation. The authors employ a well-designed experimental paradigm using functional near-infrared spectroscopy (fNIRS) to measure neural responses in newborns exposed to familiar and novel words, with careful counterbalancing and acoustic controls. Their main finding is that newborns show differential neural activation to novel versus familiar words, particularly when speaker identity changes, suggesting that even at birth, infants can use indexical cues to support memory.</p>
<p>Strengths:</p>
<p>Major strengths of the work include its innovative approach to a longstanding question in developmental science, the use of appropriate and state-of-the-art neuroimaging methods for this age group, and a thoughtful experimental design that attempts to control for order and acoustic confounds. The study addresses a significant gap in our understanding of how infants process and remember speech, and the data are presented transparently, with clear reporting of both significant and non-significant results.</p>
<p>Weaknesses:</p>
<p>However, there are notable weaknesses that limit the strength of the conclusions. The main recognition effect is restricted to a specific subgroup of participants and emerges only during a particular testing window, raising questions about the robustness and generalizability of the findings. The sample size, while typical for infant neuroimaging, is modest, and the statistical power is further reduced by missing data and group-dependent effects. Additionally, the claims regarding episodic memory and evolutionary implications are somewhat overstated, as the paradigm primarily demonstrates memory retention over a few minutes without evidence of the rich, contextually bound recall characteristic of fully developed episodic memory.</p>
<p>Overall, the authors have achieved their primary aim of demonstrating that speaker identity can facilitate memory separation in newborns, providing valuable preliminary evidence for early indexical processing in language learning. The results are intriguing and likely to stimulate further research, but the limitations in effect robustness and theoretical interpretation mean that the findings should be viewed as an important step forward rather than a definitive answer. The methods and data will be of interest to researchers studying infant cognition, memory, and language, and the study highlights both the promise and the challenges of probing complex cognitive processes in the earliest stages of life.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109096.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Previous studies by some of the same authors of the actual manuscript showed that healthy human newborns memorize recently learned nonsense words. They exposed neonates to a familiarization period (several minutes) when multiple repetitions of a bisyllabic word were presented, uttered by the same speaker. Then they exposed neonates to an &quot;interference period&quot; when newborns listened to music or the same speaker uttering a different pseudoword. Finally, neonates were exposed to a test period when infants hear the familiarized word again. Interestingly, when the interference was music, the recognition of the word remained. The word recognition of the word was measured by using the NIRS technique, which estimates the regional brain oxygenation at the scalp level. Specifically, the brain response to the word in the test was reduced, unveiling a familiarity effect, while an increase in regional brain oxygenation corresponds to the detection of a &quot;new word&quot; due to a novelty effect. In previous studies, music does not erase the memory traces for a word (familiarity effect), while a different word uttered by the same speaker does.</p>
<p>The current study aims at exploring whether and how word memory is interfered with by other speech properties, specifically the changes in the speaker, while young children can distinguish speakers by processing the speech. The author's main hypothesis anticipates that new speaker recognition would produce less interference in the familiarized word because somehow neonates &quot;separate&quot; the processing of both words (familiarized uttered by one speaker, and interfering word, uttered by a different speaker), memorizing both words as different auditory events.</p>
<p>From my point of view, this hypothesis is interesting, since the results would contribute to estimating the role of the speaker in word learning and speech processing early in life.</p>
<p>Strengths:</p>
<p>(1) New data from neonates. Exploring neonates' cognitive abilities is a big challenge, and we need more data to enrich the knowledge of the early steps of language acquisition.</p>
<p>(2) The study contributes new data showing the role of speaker (recognition) on word learning (word memory), a quite unexplored factor. The idea that neonates include speakers in speech processing is not new, but its role in word memory has not been evaluated before. The possible interpretation is that neonates integrate the process of the linguistic and communicative aspects of speech at this early age.</p>
<p>(3) The study proposes a quite novel analytic approach. The new mixed models allow exploring the brain response considering an unbalanced design. More than the loss of data, which is frequent in infants' studies, the familiarization, interference and learning processes may take place at different moments of the experiment (e.g. related to changes in behavioural states along the experiment) or expressed in different regions (e.g. related to individual variations in optodes' locations and brain anatomy).</p>
<p>Weaknesses:</p>
<p>I did not find major weaknesses. However, I would like to have more discussion or explanation on the following points.</p>
<p>(1) It would be fine to report the contribution of each infant to the analysis, i.e. how many good blocks, 1 to 5 in sequence 1 and 2, were provided by each infant.</p>
<p>(2) Why did the factor &quot;blocknumber&quot; range from 0 to 4? The authors should explain what block zero means and why not 1 to 5.</p>
<p>(3) I may suggest intending to integrate the changes in brain activity across the 3 phases. That is, whether changes in familiarization relate to changes in the test and interference phases. For instance, in Figure 2, the brain response distinguishes between same and novel words that occurred over IFG and STG in both hemispheres. However, in the right STG there was no initial increase in the brain response, and the response for the same was higher than the one for novels in the 5th block.</p>
<p>(4) Similarly, it is quite amazing that the brain did not increase the activity with respect to the familiarization during the interference phase, mainly over the left hemisphere, even if both the word and speaker changed. Although the discussion considers these findings, an integrated discussion of the detection of novel words and the detection of a novel speaker over time may benefit from a greater integration of the results.</p>
<p>Appraisal:</p>
<p>The authors achieved their aims because the design and analytic approaches showed significant differences. The conclusions are based on these results. Specifically, the hypothesis that neonates would memorize words after interference, when interfered speech is pronounced by a different speaker, was supported by the data in blocks 2 and 5, and the potential mechanisms underlying these findings were discussed, such as separate processing for different speakers, likely related to the recognition of speaker identity.</p>
<p>I think the discussion is well-structured, although I may suggest integrating the changes into the three phases of the study. Maybe comparing with other regions, not related to speech processing.</p>
<p>Evaluating neonates is a challenge. Because physiology is constantly changing. For instance, in 9 minutes, newborns may transit from different behavioral states and experience different physiological needs.</p>
<p>This study offers the opportunity to inspire looking for commonalities and individual differences when investigating early memory capacities of newborns.</p>
</body>
</sub-article>
</article>