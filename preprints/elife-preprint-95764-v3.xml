<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">95764</article-id>
<article-id pub-id-type="doi">10.7554/eLife.95764</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95764.3</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.6</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Shortcutting from self-motion signals: quantifying trajectories and active sensing in an open maze</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Xu</surname>
<given-names>Jiayun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9111-4905</contrib-id>
<name>
<surname>Girardi-Schappo</surname>
<given-names>Mauricio</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n2">†</xref>
<xref ref-type="author-notes" rid="n1">‡</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7278-4906</contrib-id>
<name>
<surname>Béïque</surname>
<given-names>Jean-Claude</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0678-9893</contrib-id>
<name>
<surname>Longtin</surname>
<given-names>André</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7666-2754</contrib-id>
<name>
<surname>Maler</surname>
<given-names>Leonard</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>lmaler@uottawa.ca</email>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Cellular and Molecular Medicine, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1H 8M5</aff>
<aff id="a2"><label>2</label><institution>Department of Physics, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1N 6N5</aff>
<aff id="a3"><label>3</label><institution>Brain and Mind Institute, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1H 8M5</aff>
<aff id="a4"><label>4</label><institution>Center for Neural Dynamics and Artificial Intelligence, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1H 8M5</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Cowan</surname>
<given-names>Noah J</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Johns Hopkins University</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Wassum</surname>
<given-names>Kate M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of California, Los Angeles</institution>
</institution-wrap>
<city>Los Angeles</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="present-address"><label>‡</label><p>Present address: Departamento de Física, Universidade Federal de Santa Catarina, 88040-900, Florianópolis, Santa Catarina, Brazil</p></fn>
<fn id="n2" fn-type="equal"><label>†</label><p>Contributed equally to this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-05-09">
<day>09</day>
<month>05</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2024-10-17">
<day>17</day>
<month>10</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP95764</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-12">
<day>12</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-12-28">
<day>28</day>
<month>12</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.24.529984"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-05-09">
<day>09</day>
<month>05</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95764.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.95764.1.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95764.1.sa2">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95764.1.sa1">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95764.1.sa0">Reviewer #3 (Public Review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.95764.1.sa4">Author response:</self-uri>
</event>
<event>
<event-desc>Reviewed preprint v2</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-09-20">
<day>20</day>
<month>09</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95764.2"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.95764.2.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95764.2.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.95764.2.sa1">Reviewer #3 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.95764.2.sa0">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Xu et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Xu et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-95764-v3.pdf"/>
<abstract>
<title>Abstract</title>
<p>Animals navigate by learning the spatial layout of their environment. We investigated spatial learning of mice in an open maze where food was hidden in one of a hundred holes. Mice leaving from a stable entrance learned to efficiently navigate to the food without the need for landmarks. We developed a quantitative framework to reveal how the mice estimate the food location based on analyses of trajectories and active hole checks. After learning, the computed “target estimation vector” (TEV) closely approximated the mice’s route and its hole check distribution. The TEV required learning both the direction and distance of the start to food vector, and our data suggests that different learning dynamics underlie these estimates. We propose that the TEV can be precisely connected to the properties of hippocampal place cells. Finally, we provide the first demonstration that, after learning the location of two food sites, the mice took a shortcut between the sites, demonstrating that they had generated a cognitive map.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Added text. P21 and just before the heading: &quot; Implications for theories of hippocampal representations of spatial maps&quot; There were no other changes made in the paper.
&quot;Path integration uses self-motion signals to update the animal's estimated location on its internal cognitive map. Path integration gain has been shown to be plastic and regulated by landmarks (52). Remarkably, a recent study has revealed that path integration gain can also be directly recalibrated by self-motion signals alone (53), albeit not as effectively as by landmarks (52, 53). An interesting question for future research is whether self-motion signals can also recalibrate the coordinates of a cognitive map. From this perspective, the Target B to Target A shortcut requires a transformation of the cognitive map coordinates so that the start point is now Target B.
 Extensive research has shown that external cues can control hippocampal neuron place fields (11, 12, 54) and the gain of the path integrator (52), making the failure of mice in our study to use such cues puzzling. The failure to use landmarks may be related to our task being low stakes and our pretraining procedure teaching the mouse that such cues are not necessary. Our results may not generalize to more natural conditions where many reliable prominent cues are available, and where there is urgency to find food or water while avoiding predation (55). Under these more naturalistic conditions the use of distal cues to rapidly find a food reward is more likely to be observed.&quot;
</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/neuro-physics/mouse-cogmap">https://github.com/neuro-physics/mouse-cogmap</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://www.dropbox.com/s/ikts0dn1qcog4oi/mouse_36_Probe2_hole_check_synchronized.mp4?dl=0">https://www.dropbox.com/s/ikts0dn1qcog4oi/mouse_36_Probe2_hole_check_synchronized.mp4?dl=0</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Animals must learn the spatial layout of their environment to successfully forage and then return home. Local (<xref ref-type="bibr" rid="c1">1</xref>) or distal (<xref ref-type="bibr" rid="c2">2</xref>) landmark(s) are typically important spatial cues. Landmarks can act as simple beacons, as stimuli for response learning or for more flexible “place” learning strategies (<xref ref-type="bibr" rid="c2">2</xref>-<xref ref-type="bibr" rid="c5">5</xref>). Experimental studies addressing this issue have used one (<xref ref-type="bibr" rid="c6">6</xref>) or many (<xref ref-type="bibr" rid="c7">7</xref>) distal landmarks that provide allocentric coordinates for learning trajectories from a start site to a hidden location. A second source of spatial information derives from idiothetic cues that provide a reference frame via path integration of self-motion signals (<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>). Research on the interaction of landmark and self-motion cues has concluded that a “spatial map” can be generated by self-motion cues anchored to stable landmarks (<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c10">10</xref>-<xref ref-type="bibr" rid="c12">12</xref>). This spatial map can link start sites to important locations via efficient trajectories. However, it is not clear whether such a map is sufficient for flexible navigation using entirely novel routes.</p>
<p>We designed a circular open maze where navigation trajectories are unconstrained, the mice’s allocentric reference frame is determined by large visual cues and food is hidden in one of 100 holes. We found that mice did not use the landmarks but required only minimal cues, namely a stable start location, self-motion signals and active sensing (hole checks), to learn to find food. Trajectories and hole checking strategies dramatically changed as the mice learned to efficiently navigate to the hidden food. Averaged trajectory directions converged to a “mean displacement direction”, and hole checking became concentrated near the expected food hole. These analyses resulted in a computed target estimation vector (TEV) that closely approximated the most direct route between the start location and food. When, after learning, the mice were transferred to another start site, their TEVs also rotated and then pointed to the “rotationally equivalent location” (REL) instead of the target, therefore demonstrating that they were utilizing self-motion cues for navigation. We propose ways to link the mean displacement and hole checking components of the TEV to the properties of hippocampal place cells and suggest a neural equivalent of the TEV that might be computed by downstream hippocampal targets.</p>
<p>The cognitive map hypothesis proposes that animals can learn a metric map of their environment and use it to flexibly guide their navigation, that is, they can take shortcuts, detours and novel routes when needed (<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref>). It is further proposed that the hippocampus and closely connected cortical areas generate a cognitive map (<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>). We found that, after training to find food in two distinct sites, mice were able to take an unrehearsed shortcut between the sites on a final probe (<italic>i</italic>.<italic>e</italic>., no food) trial. The trajectories and hole check analyses demonstrated that the computed TEVs were accurate and efficient. To the best of our knowledge, this is the first demonstration that a stable start location and self-motion cues are sufficient for a rodent to compute a cognitive map. It is not clear whether current theories based on electrophysiological studies of the hippocampus and associated cortices can account for the cognitive map we have observed (<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c17">17</xref>).</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We designed a behavioural framework, the Hidden Food Maze (HFM), to tease apart the roles of idiothetic and allothetic cues for navigation in a foraging task (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Mice are trained to find a food reward hidden inside one hole (the target) out of 100 in a large, circular open maze (120 cm in diameter). The target hole has a “rotationally equivalent location” (REL) in each of the arena’s quadrants (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>; see “REL” in Methods for a description). In the mouse’s perspective, the displacement from the entrance location to the target is the same as from the entrance in any quadrant to their respective REL. The HFM has several unique features such as 90° rotational symmetry to eliminate geometric cues and control for distal cues, movable home cage entrance-ways, and experimenter-controlled visual cues (see Methods). More importantly, our framework gives the mice freedom to explore the arena with minimum stress, yielding variable trajectories due to the nonstereotyped environment. These features allow us to control whether mice orient to allothetic or idiothetic cues, enabling us to investigate the respective role of landmarks versus path integration in spatial navigation.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Hidden Food Maze and experimental setup.</title>
<p><bold>A</bold>. The floor of the arena is 120cm in diameter, and the walls are 45cm tall. Note 20 cm scale bar in this panel. The home cage has a 10.5×6.5cm<sup>2</sup> floor area. The door slides upward (mice enter without handling). The floor is washed and rotated between every trial to avoid predictable scratch marks and odor trails. The subfloor containing food is not illustrated. <bold>B</bold>. Camera view of a mouse searching for hidden food (target, pointed by the target vector). The REL of the target is marked for each entrance (from the mouse’s perspective, the displacement from the start in each quadrant to its respective REL is the same for any entrance; <italic>e</italic>.<italic>g</italic>., “70cm forward + 30cm to the left”; and it is equal to the displacement from the trained start to target). <bold>C</bold>. “Random entrances” experiment. Mice enter from any of the four entrances randomly over trials to search for food (“A”-labeled star) always in front of the X landmark. Arrows show the four possible displacements. <bold>D</bold>. “Static entrances” experiment. Mice start from the same entrance (labeled “Start”) in every trial to search for food in front of the same landmark. Blue/cyan arrows=food vector (start→food); Orange arrow=REL vector (start→REL). After training, the start position in a probe trial can be rotated (“180° Start”) to check whether mice follow idiothetic (start→REL; ignoring landmarks) or allothetic (start→A; following landmarks) cues; going via the REL vector is regarded as evidence of path integration. <bold>E</bold>. “Two food location” experiment. Mice start from a static entrance to search for food (red vector to target A). Afterwards, mice are trained to find food in a different location (blue vector to target B). After learning both targets, a probe trial (i.e., a trial without food) is designed to check whether mice can compute shortcuts from B to A (B-A vector, orange arrow).</p></caption>
<graphic xlink:href="529984v6_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We first analyzed the effects of randomizing the entrance location taken by the mouse on successive trials (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>), versus maintaining a static entrance throughout training (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>). We quantified the geometric and kinetic features of the trajectories and the behavior of hole checking throughout the arena. The variability of the trajectories resulted in the development of statistical methods to directly infer the mice estimation of the target location (the “target estimation vector”, or TEV). We showed that it coincides with the actual target vector only for the static entrance protocol. In order to eliminate the effect of visual cues, we performed rotated probe trials after training in static entrance, where mice went either to the target (following landmarks) or to the REL (ignoring landmarks; see <xref rid="fig1" ref-type="fig">Fig. 1D</xref>).</p>
<p>Finally, we investigated the features of the mice trajectories and active sensing behavior when trained on two targets consecutively under the static entrance protocol (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>). In this case, the TEV method was employed to demonstrate the learning of both target directions and the use of shortcuts, one manifestation of a cognitive map (<xref ref-type="bibr" rid="c14">14</xref>). See Methods and the Supplementary Material for the definition of all measured quantities and details on experimental protocols.</p>
<sec id="s2a">
<title>Pretraining trials</title>
<p>Initially, naïve mice were introduced to our maze. In agreement with previous work (<xref ref-type="bibr" rid="c18">18</xref>), we observed that mice initially explored the maze by following the wall (thigmotaxis) on round trips of increasing complexity before they explored the maze center. Our pretraining protocol induced the mice to explore the arena center (see Fig. S1A, Methods). Thigmotaxis was still observed after pretraining (see, e.g., <xref rid="fig2" ref-type="fig">Figs. 2A,B</xref> and <xref rid="fig3" ref-type="fig">3A,B</xref>), though now the mice spent more time in the central regions of the maze. In the Static trial experiments, there was not a distinct class of thigmotactic trajectories, but rather a continuum of trajectory distances from the wall. Furthermore, the mice were initially equally likely to take trajectories at any angle from the start-to-food line as evidenced by the variation of the TEV deviation from the target vector in trial 1 of <xref rid="fig4" ref-type="fig">Fig. 4I</xref>.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Mouse spatial learning with random entrances.</title>
<p><bold>A</bold>. Two examples of mouse search trajectories during early learning (trial 3) when the entrance changes from trial to trial. They are irregular and vary unpredictably across trials. <bold>A, B</bold>. Star = target location. Yellow Square = entrance site. <bold>B</bold>. Two examples of mouse search trajectories during late learning (trial 14) after starting from different entrances. Trajectories look as irregular as in early trials. <bold>C. (Top)</bold> Heatmap of the first 2min of a probe trial done after trial 18 (red=more time in a given region). <bold>(Bottom)</bold> Mice spent about the same time (25%) in each of the four sectors, regardless of being close to the target (blue) or to its REL (white). <bold>D</bold>. Some significant reduction in latency to reach target is seen across trials (p=0.008; N=8). <bold>D-I:</bold> Error bars = S.E. Shaded area = data range. <bold>E</bold>. Some significant increase in speed is seen (p=0.002; N=8). <bold>F</bold>. Average normalized distance traveled to reach target (<italic>d</italic><sub>total</sub>/<italic>d</italic><sub>target</sub>=1 is optimal; p=0.05, N=8). <bold>G</bold>. Hole-checking density (number of hole checks per distance traveled) in each half of the trajectory. The density remains constant for both halves and across trials, suggesting that mice remained uncertain as to the food location. <bold>G-inset</bold>. The S.D. of the density over the mice sample remains constant for both halves (N=8). <bold>H</bold>. The average distance of the checked holes to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> remains almost constant across trials. Horizontal lines are just guides to the eye. <bold>I</bold>. The probability density of the distance of hole checks to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> for the first and last learning trials (the corresponding averages over trials are in panel <bold>H</bold>). The density remains unaltered. Vertical dotted lines mark the same distances as the horizontal lines in panel <bold>H</bold>.</p></caption>
<graphic xlink:href="529984v6_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Mouse spatial learning with static entrances.</title>
<p><bold>A</bold>. Two examples of mouse search trajectories during early learning (trial 3). They are irregular and variable similarly to those in the random entrance experiments. <bold>A, B</bold>. Star = target location. Yellow Square = entrance site. <bold>B</bold>. Two examples of mouse search trajectories during late learning (trial 14). They go directly towards the food or go along the wall before turning to the food, creating variation across mice and trials. <bold>C. (Top)</bold> Heatmap of the first 2min of a probe trial done after trial 14 (red=more time in a given region). <bold>(Bottom)</bold> Mice spent almost 50% of the time within 15cm radius of the target (blue) compared to the RELs (white). <bold>D</bold>. Latency dramatically decreases (p&lt;10<sup>−7</sup>; N=8). <bold>D-I:</bold> Error bars = S.E. Shaded area = data range. <bold>E</bold>. Speed significantly increases during trials (p=0.0001; N=8). <bold>F</bold>. Normalized distance to reach target (<italic>d</italic><sub>total</sub>/<italic>d</italic><sub>target</sub>=1 is optimal) becomes almost optimal (p&lt;10<sup>−7</sup>; N=8). <bold>G</bold>. Hole-checking density over distance in each half of the trajectory. It significantly decreases in the first half (p=0.05), and stays constant in the second. <bold>G-inset:</bold> The S.D. of the density is larger in the second half. <bold>H</bold>. The average distance of the checked holes to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> decreases for both halves of the trajectory. After learning, the hole checks happen closer to the food (<italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> is almost zero), although there are more checks per distance. <bold>I</bold>. The probability density of the distance of hole checks to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> for the first and last trials (the corresponding averages over trials are in panel h). After learning (trial 14), the density is larger closer to the food, a feature that does not appear in the random entrance experiments.</p></caption>
<graphic xlink:href="529984v6_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Trajectory directionality and active sensing for random and static experiments.</title>
<p>Arenas on the top row (mean displacement vector – see color scale between panels b and e) correspond to the ones immediately below them (hole checking spatial distribution); the red “A” label marks the target (food site), which is pointed by the food (target) vector (purple arrow). <bold>Top row (A</bold>,<bold>B</bold>,<bold>E</bold>,<bold>F)</bold>: the color and arrows indicate the most probable route taken (red=more probable; only p&lt;0.001 displacements shown; pink arrow=inferred target position, or TEV; shaded pink sector=S.D. of TEV; see Methods, and Fig. S7). <bold>Bottom row (C</bold>,<bold>D</bold>,<bold>G</bold>,<bold>H)</bold>: spatial distribution of hole-checks; size and color of circles=normalized frequency that a hole was checked (larger pink circles=higher frequency); Black ellipse (x=mean): covariance of spatial distribution. Green ellipse (+=mean): covariance of spatial distribution restricted to ≤20cm of the target. <bold>Random entrance</bold> experiments (N=8; panels <bold>A</bold>,<bold>C: trial 1; B</bold>,<bold>D: trial 14</bold>): regardless of training stage, no significant preferred routes and the TEV does not point to target (<bold>A</bold>,<bold>B</bold>); hole checks are randomly distributed throughout the arena, and shift from the walls (c) to near the center (d) after learning. <bold>Static entrance</bold> experiments (N=8; panels <bold>E</bold>,<bold>G: trial 1; F</bold>,<bold>H: trial 14</bold>): after learning (f) the TEV and significant displacements go straight to the target (although individual trajectories are variable); and hole checks align along the start-target path (h). <bold>Panel I:</bold> deviation between the TEV (pink arrow) and the target vector (purple arrow) illustrated in top panels. Directionality is quickly learned (static case). <bold>Panels J</bold>,<bold>K:</bold> hole-check area density corresponding to the spatial profiles in bottom panels. Density after learning is larger near the target (static case), supporting the path integration hypothesis. Asterisks/star: p&lt;0.05 (paired t-test). Note the presence of more significant displacements in late learning for static entrances only, and the associated alignment of the TEV and food vector.</p></caption>
<graphic xlink:href="529984v6_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2b">
<title>Mice used self-motion sensory input but did not utilize 2D wall cues for spatial learning</title>
<sec id="s2b1">
<title>Random Entrance experiments</title>
<p>Mice were trained with their cage being moved randomly between quadrant entrances from trial to trial without directly manipulating the animals. Thus, they never entered from the same start position for consecutive trials, making the wall pictures their only reliable orienting landmarks. These cues were 15×15cm black shapes on a white background (see Methods). The configuration of the 4 cues varied relative to the entrance, but the food was always placed in the same hole and nearest the X-shaped landmark (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, Methods). The food-restricted mice showed persistent complex search trajectories throughout the learning period (<xref rid="fig2" ref-type="fig">Fig. 2A, B</xref>). The latency to reach the food target was significantly negatively correlated with trial number (statistics in <xref rid="fig2" ref-type="fig">Fig. 2D</xref>) but with a non-significant difference between the first and last trials (N=8; First trial mean±SD = 151.34 ± 148.91 s; Last trial mean±SD = 80.38 ± 43.86 s; P=0.2602). Despite the decrease in latency, mice did not appear to exhibit spatial search strategies (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>) given that the time spent in each quadrant during the probe trial is similar (target quadrant=28.78%, other quadrants=24.93%, 28.04%, 18.25%; 1-Way ANOVA: P=0.070574, F-ratio=2.71621; see Behavioral Analysis in Methods). This suggests latency decreased for reasons independent of spatial learning.</p>
<p>We found a corresponding significant positive correlation of speed and trial number (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>) with non-significant differences between first and last trials (N=8; First trial mean±SD = 6.68 ± 3.79 cm/s; Last trial mean±SD = 11.40 ± 5.07 cm/s; P=0.0704). Since the distance from start to target (<italic>d</italic><sub><italic>target</italic></sub>) varies over trials due to changing entrance location, we defined the normalized trajectory length (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>). It is the ratio between total traveled distance (<italic>d</italic><sub><italic>total</italic></sub>) and <italic>d</italic><sub><italic>target</italic></sub>; <italic>d</italic><sub><italic>total</italic></sub>/<italic>d</italic><sub><italic>target</italic></sub>=1 is optimal. There is no significant correlation of this quantity and trial number (P=0.295). The first and last normalized trajectory lengths were not significantly different either (N=8; First trial mean±SD = 11.79 ± 8.25; Last trial mean±SD = 15.51 ± 9.92; P=0.4241).</p>
<p>Fitting the function <italic>d</italic><sub><italic>total</italic></sub> = <italic>B</italic><sub>*</sub>exp(-Trial/<italic>K</italic>) reveals the characteristic timescale of learning, <italic>K</italic>, in trial units (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>). We obtained K= 26±24 giving a coefficient of variation (CV) of 0.92. The mean, K=26, is therefore very uncertain and far greater than the actual number of trials. Thus, we hypothesize that the mice did not significantly reduce their distance travelled (<xref rid="fig2" ref-type="fig">Fig. 2A,B,F</xref>) because they had not learned the food location – the decrease in latency (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>) was due to its increased running speed and familiarity with non-spatial task parameters.</p>
<p>We next examined hole checking as an active sensing indicator of the mouse’s expectation of the food location (see Methods, Fig. S2A,B and the Shortcut Video (Video 1)) for hole-check detection after spatial learning). Even though hole check counts increase with the total trajectory length and latency (Fig. S4B,C), we expected that the mice would increase the number of hole checks near the expected food location, or along their path toward it. Thus, we split the trajectories into two halves of same duration to identify whether hole checks would increase in the second half (being closer to the target). However, the hole checking density (ratio between number of checks and distance travelled) remains constant between the first and second halves of any trial (<xref rid="fig2" ref-type="fig">Fig. 2G</xref>), suggesting mice did not anticipate where the food is placed. Mice also did not increase their hole sampling rate as they approached the target as shown by the distance of hole checks to the target, <italic>d</italic><sub><italic>checks</italic>→<italic>food</italic></sub> (<xref rid="fig2" ref-type="fig">Fig. 2H,I</xref>), again suggesting no expectation of its location. Mice do not appear to learn a landmark-based allocentric spatial map.</p>
</sec>
<sec id="s2b2">
<title>Static Entrance Experiments</title>
<p>We tested whether the mice might acquire an allocentric spatial map if, contrary to the random entrance case, they had a single stable view of the landmarks and could associate one cue configuration with the food location (see Methods). For this, each mouse entered the arena from the same entrance during the training trials (hence “static entrance”). Mice greatly improved their trajectory efficiency after training (<xref rid="fig3" ref-type="fig">Fig. 3A,B</xref>), with distance and latency to food plateauing around trial 7. During early learning, mice showed random search trajectories that transformed to stereotyped trajectories towards food by late learning (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>). Typical trajectories were either (i) directly to the food, (ii) initially displaced towards the maze center then returning to a food-oriented trajectory, or (iii) initially along the wall and then turning and heading to the food (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>).</p>
<p>During the probe trial, mice spent the most time searching in the target quadrant (44.26%; <xref rid="fig3" ref-type="fig">Fig. 3C</xref>), compared to the time spent in the other quadrants, respectively 19.38% (P=0.007), 16.55% (P=0.0065), 19.81% (P=0.007; p-values obtained for a pairwise t-test and adjusted for multiple comparisons via the Benjamini-Hochberg method). The latency to target strongly decreased over trials (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>) and the last trial latency was significantly reduced compared to the first (N=8; First trial mean±SD = 255.39 ± 153.28 s; Last trial mean±SD = 7.38 ± 4.03 s; P=0.004). The speed dramatically increased over trials (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>) and the ending speed was significantly greater than the initial speed (N=8, First trial mean±SD = 6.04 ± 2.48 cm/s; Last trial mean±SD = 17.25 ± 4.64 cm/s; P=0.0002). The normalized trajectory length strongly negatively correlated with trial number (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>) and the final normalized length greatly reduced (N=8; First trial mean±SD = 18.02 ± 11.36; Last trial mean±SD = 1.40 ± 0.50; P=0.0061), becoming almost optimal (<xref ref-type="bibr" rid="c1">1</xref>).</p>
<p>Now the fitting of the function <italic>d</italic><sub><italic>total</italic></sub>=<italic>B</italic> exp(-Trial/<italic>K</italic>) yielded <italic>K</italic>=5.6±0.5 with a CV = 0.08; the mean is therefore a reliable estimate of total distance travelled. We interpret this to indicate that it takes a minimum number of K= 6 trials for learning the distance to the target (see also Fig. S4D,E,F,G). Learning is still not complete because it takes 14 trials before the trajectories become near optimal.</p>
<p>Hole checking density varied across trajectories and differed between early and late learning trials. The density significantly decreased with trial number in the first half of trajectories (R=-0.54; P=0.0455, <xref rid="fig3" ref-type="fig">Fig. 3G</xref>) but not the second half (R=0.17; P= 0.559, <xref rid="fig3" ref-type="fig">Fig. 3G</xref>). The hole checks also happened significantly closer to the target in the second half of the trajectory (<xref rid="fig3" ref-type="fig">Fig. 3H</xref>; First trial mean±SD = 48.06 ± 11.50 cm; Last trial mean±SD = 3.13 ± 5.70 cm; P=3×10<sup>−6</sup>). A remarkable effect of learning is that the probability of checking holes increases as the mouse approaches the food (<xref rid="fig3" ref-type="fig">Fig. 3I</xref>). These results (<xref rid="fig3" ref-type="fig">Fig. 3H,I</xref>) suggest that the mice may be predicting the food location and checking their prediction as they approach the estimated food location (see also Figs. S4 and S5 for other quantities and scatter plots of trajectory features vs. hole checking). Hole checking near the food site also implies that the mice are not using odorant or visual cues to sense the precise food location, but instead rely on a memory-based estimate of the food-containing hole (see also <xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>). This motivated us to look at the spatial configuration of these variables to get a detailed picture of the random vs. static condition.</p>
</sec>
<sec id="s2b3">
<title>Revealing the mouse estimate of target position from behavior</title>
<p>Although quantitative, the analysis so far only showed a broad comparison between random versus static entrance experimental conditions. We developed a method to map out the directions that the mice stepped towards more frequently from each particular location in the arena, yielding a <italic>displacement map</italic> (see Statistical Analysis of Trajectories in Methods). This map can generate a precise estimate of the mean directionality of the trajectories for each experimental condition (<xref rid="fig4" ref-type="fig">Fig. 4A,B,E,F</xref>, P-values in Fig. S7A,B,C,D). Additionally, we also made a frequency plot of the checks for each particular hole in the arena, yielding the spatial distribution of hole checks (<xref rid="fig4" ref-type="fig">Fig. 4C,D,G,H</xref>). These two maps are combined to give the Target Estimation Vector (TEV;). The TEV is interpreted as the mouse’s estimate of the target position (pink vectors in <xref rid="fig4" ref-type="fig">Fig. 4A,B,E,F</xref>).</p>
<p>In random entrance training, no significant directionality was found in the arena (<xref rid="fig4" ref-type="fig">Fig. 4A,B</xref>), again consistent with a random search. The spatial distribution of hole checks migrated from near the walls towards the center of the arena but remained random and displaced from the target (<xref rid="fig4" ref-type="fig">Fig. 4C,D</xref>, and also Fig. S8), consistent with the broad results of <xref rid="fig2" ref-type="fig">Fig. 2</xref>. Conversely, there was a clear and significant flow of trajectories for mice trained with static entrance (<xref rid="fig4" ref-type="fig">Fig. 4E,F</xref>; P&lt;0.0001; see Methods for the definition of the p-values assigned to directions). The hole checks reflected this and became solely concentrated along the route from start to target (<xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>). In the static entrance condition, the entropy (uncertainty) of the number of hole checks near (&lt;20 cm) the target was lower than that for the far (&gt;20 cm) condition (Fig. S7F,G). In other words, mice were more consistent in the number of their hole checks near the target compared to far from the target, suggesting that they had an internal representation of their proximity to the food site.</p>
<p>We compared the deviation between the TEV and the true target vector (that points from start directly to the food hole; <xref rid="fig4" ref-type="fig">Fig. 4I</xref>). While the random entrance mice had a persistent deviation between TEV and target of more than 70°, the static entrance mice were able to learn the direction of the target almost perfectly by trial 6 (TEV-target deviation in first trial mean±SD = 57.27°± 41.61°; last trial mean±SD = 5.16°± 0.20°; P=0.0166). A minimum of 6 trials is sufficient for learning both the direction and distance to food (<xref rid="fig4" ref-type="fig">Fig. 4I</xref>) (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>) (see Discussion). The kinetics of learning direction to food are clearly different from learning distance to food since the direction to food remains stable after Trial 6 while the distance to food continues to approach the optimal value.</p>
<p>Under the path integration hypothesis, it is expected that error accumulates as the mouse walks (<xref ref-type="bibr" rid="c15">15</xref>). This motivated us to investigate the frequency of hole checks per area near the target (within 20 cm) vs. far (further from 20 cm away), <xref rid="fig4" ref-type="fig">Fig. 4J,K</xref>. The density of hole checks in both conditions remained constant for random entrance mice, regardless of training duration. However, static entrance mice had significantly higher density of hole checks near the target (<xref rid="fig4" ref-type="fig">Fig. 4K</xref>; P-values: random-far vs. static-far=0.005; static-far vs. random-near=0.03; random-near vs. static-near=0.01). The mean position of hole checks near (≤20cm) the target is interpreted as the mouse estimated target (<xref rid="fig4" ref-type="fig">Fig. 4C,D,G,H</xref>; green + sign=mean position; green ellipses = covariance of spatial hole check distribution restricted to 20cm near the target). This finding together with the displacement and spatial hole check maps (<xref rid="fig4" ref-type="fig">Figs. 4F</xref> and <xref rid="fig4" ref-type="fig">4H</xref>, respectively) corroborates the heatmap of time spent in the target quadrant (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>), suggesting a positive correlation between hole checks and time searching (see also Fig. S4C). Thus, we use the distance from this point to the entrance as the magnitude of the TEV. This definition reveals that the TEV is nearly coincident with the direct route between start location and the food-containing hole (pink vectors in <xref rid="fig4" ref-type="fig">Fig. 4F</xref>), consistent with the near optimal normalized trajectory length previously discussed (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>).</p>
</sec>
<sec id="s2b4">
<title>Ruling out landmarks</title>
<p>These results demonstrated that mice can learn the spatial location of the food target from a static entrance. We next investigated whether the performance gain can be attributed to the cues by manipulating the mouse’s entrance. Well-trained static entrance mice were subject to rotation of their home cage by 180°, +90°, or -90° for probe trials in order to start from a different location. We used a different cohort of N=8 mice for each rotation. The mice were not directly handled during the rotation procedure. If the mice were using the distal landmarks, they would still be expected to find the correct food location. If they relied on self-motion cues, they should travel to the REL, since this is the spot where the target would have been if the mouse had been trained from that entrance. In other words, going to the REL means that the trajectory is anchored to the mouse’s start point and not to the wall cues. As illustrated in <xref rid="fig1" ref-type="fig">Fig. 1B</xref>, the displacement between each start-REL pair is exactly equal from the mouse’s point of view (<italic>e</italic>.<italic>g</italic>., going 70 cm forward then 30 cm to the left reaches the respective REL of the target).</p>
<p>Following all rotations, mice searched at the REL instead of the correct location for the food reward regardless of the arena having wall cues (<xref rid="fig5" ref-type="fig">Fig. 5A,B,C</xref>), meaning that they were not using landmarks to compensate for rotation. In fact, the trajectory kinetics of the 180°-rotated probe for reaching the REL target (mean±SD latency = 4.80 ± 3.06 s; speed = 14.60 ± 5.21 cm/s; normalized distance to REL = 1.96 ± 0.90) is indistinguishable (within one SD or less) from the kinetics of the last trial of static entrance for reaching the true target. The criterion for reaching the REL target was getting within 5cm of its position (the average inter-hole distance is 10cm).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Changing start position after training in static protocol.</title>
<p>Mice are trained in the static entrance protocol to find food at the target labeled “A” (blue circle), and a probe trial is executed with mice entering from a rotated entrance after 18 trials. Panels <bold>A</bold>,<bold>B</bold>,<bold>C</bold> show the comparison between trajectories from the last learning trial (blue) versus the probe (red). The training was performed without landmarks (<bold>A:</bold> N=8, -90° rotation) and with landmarks (<bold>B:</bold> N=8, 90° rotation; <bold>c:</bold> N=8, 180° rotation). In all instances, mice ignored landmarks and went to the REL location (“REL A” label, red triangle), something that is expected under the path integration hypothesis. <bold>Panel D:</bold> trajectory directionality analysis and TEV (pink arrow; shaded sector: S.D.) show that significant paths of all mice (p&lt;0.001; N=8; see Methods) point to the REL-A location in the same way that it pointed to the target without rotated entrance in <xref rid="fig4" ref-type="fig">Fig. 4F</xref><bold>. Panel E:</bold> the spatial distribution shows that hole checks accumulate along the start-REL vector, instead of the start-target vector of the case without rotation in <xref rid="fig4" ref-type="fig">Fig. 4H</xref>. Black ellipse (x=mean): covariance of hole check distribution. Green ellipse (+=mean): covariance of the data within 20cm of the REL-A location. This suggests that mice follow trajectories anchored to their start location (idiothetic frame of reference).</p></caption>
<graphic xlink:href="529984v6_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We also show the displacement maps (mean trajectory directionality), hole check spatial profile and TEV for the 180°-rotated probe trial (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>). The TEV now points to the REL, and the hole checks accumulate along the route to the REL. These maps are also very similar to the static entrance maps in <xref rid="fig4" ref-type="fig">Fig. 4</xref>. Thus, the mice failed to use allothetic cues for navigation in the novel start location test.</p>
</sec>
<sec id="s2b5">
<title>Further controls</title>
<p>It is possible that mice, like gerbils (<xref ref-type="bibr" rid="c6">6</xref>), choose one landmark and learn the food location relative to that landmark (e.g., the “X” in <xref rid="fig3" ref-type="fig">Fig. 3B</xref>); in this case, the mice would only have to associate their initial orientation to that landmark without identifying the image on it. We used two additional controls to assess this possibility. Mice were trained without any cues on the wall, eliminating the possibility that they provided orienting guides. The learning curve of mice with or without the 2D wall cues were not significantly different (Fig. S6A,B).</p>
<p>Mice that were well trained in the lighted maze were given trials in complete darkness. These mice still showed the same learning curve compared to untrained mice or mice following rotation (Fig. S6C,D).</p>
<p>Finally, to completely rule out both landmark and possible olfactory cues, we trained and tested mice in total darkness. Head direction tuning may be impaired in sighted mice navigating in darkness (<xref ref-type="bibr" rid="c19">19</xref>), but spatial learning was not affected in our experiments. Mice can also use localized odor sources as landmarks for spatial learning (<xref ref-type="bibr" rid="c20">20</xref>) and we therefore attempted to eliminate such cues (see Discussion and Methods). The mice were still able to learn the food location in the absence of visual and olfactory cues (Fig. S6E,F). These experiments demonstrate that the mice can learn to efficiently navigate from a fixed start location to the food location using path integration of self-motion cues.</p>
<p>Furthermore, the location of the targets in all instances of the experiment was carefully chosen to avoid cues from the arena’s circular geometry. If the target was placed near the center of the arena, the learning task would be trivial and would involve little spatial inference. Conversely, if the target was placed too close to the wall, thigmotaxis would be sufficient to get near the food. Also, the line going through the center of the arena that is perpendicular to the line connecting start to center has to be avoided (see <xref rid="fig1" ref-type="fig">Fig. 1B</xref> for reference), otherwise the system would be symmetric to rotation or could be simplified to a left-or-right choice that would involve little spatial learning. Finally, the target cannot be placed near the start positions. Thus, in the static entrance experiments, the chosen target position is always more than 35cm away from the wall, and more than 60cm away from the start. In the random entrance case, the target is placed more than 30cm away from the wall, and more than 40cm away from the closest starting location.</p>
</sec>
</sec>
<sec id="s2c">
<title>Mice can use a shortcut to navigate between remembered targets</title>
<p>Our results established that mice learn the spatial location of a food reward using path integration of self-motion cues. Have the mice learned a flexible cognitive map? A test of cognitive mapping would be if mice could take a short cut and navigate from one remembered location to another along a novel, unreinforced path. The “two food location experiment” set out to test this possibility by training mice to travel to food from their home cage to two very differently located sites (chosen according to the rules mentioned in the previous section). The two locations were trained sequentially so that one site was trained first (target A) followed by training on the second site (target B). A probe trial without food after training target A was designed to check if mice had learned it successfully. Only one hole was filled with food in any given training trial. In a second probe trial after training on B, mice were tested to see whether they can travel between the two remembered locations (food is absent; probe B-A trial) despite no prior training nor reinforced experience on the short cut route (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>).</p>
<p>Mice successfully learned the location of target A, evidenced by their direct search trajectories and significant decreases in distance traveled (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>), with the same performance as in the static entrance case. During the learning of target A, the distance of the mouse to the future location of target B was always larger than that expected by chance, <italic>i</italic>.<italic>e</italic>., to a randomly chosen location in the maze (see Methods, Fig. S10A,B). In fact, the trajectories stayed, on average, approximately 40 cm away from the forthcoming target B position. In other words, the mice did not learn, by chance, direct unreinforced routes from “near B to A”. In <xref rid="fig6" ref-type="fig">Fig. 6A</xref>, for example, the mouse passed within 16 cm of the future target B site in an early learning trial, but this close approach does not appear to constitute a B-&gt;A trajectory. The first probe trial (without food) confirmed that mice had learned the location of target A. After not finding food in A, the mice re-initiated a random search (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Two food location experiment.</title>
<p><bold>Panels A-D</bold>. Trajectory exemplars of four sequential stages of the experiment (all trials done with static entrance, N=8): <bold>(A)</bold> training target A (trials 1-A and 16-A for early and late learning, respectively); <bold>(B)</bold> probe A (no food is found, triggering a random search); <bold>(C)</bold> training target B (keeping A empty; trials 1-B and 8-B for early and late learning); <bold>(D)</bold> probe B-A (where both targets are trained and empty, and the mice take a shortcut from B to A; see Fig. S8 for all exemplars). Filled circles=filled target hole; empty circles=empty target. In the A and B learning stages, the trajectories evolve from random to going straight from start to the respective target. <bold>Panels E-F</bold>. Standard boxplot statistics of learning versus probe (diamonds are averages; asterisks: p&lt;0.05 in a paired t-test comparison). Quantities are defined in Fig. S4<bold>A</bold>. Significant differences between early and late learning were observed for the traveled distance <bold>(E)</bold>, heading angle <bold>(F)</bold>, and distance to the food line <bold>(G)</bold>. Density of hole checks <bold>(H)</bold> remained nearly constant, as expected. In all instances, the values of all quantities in the B-A probe resembled the values of the late learning trials, whereas the randomized B-A probe (gray) had values that resembled early learning, suggesting the B-A behavior is not random. In the Probe B→A trials, the “food line” is the straight line that connects B to A, along which the reference distance <italic>d</italic><sub><italic>target</italic></sub> is measured between A and B. In the other trials, the food line is a straight line from start to the specific target, either A or B, along which <italic>d</italic><sub><italic>target</italic></sub> is measured between start and target.</p></caption>
<graphic xlink:href="529984v6_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>After the probe trial, mice were trained to learn target B. During this training, 3 mice (Mouse 33, 35, 36) first learned a route to target B but, on subsequent searches, they would sometimes first check the site of the previous target A and then travel to the correct target B along a direct short cut route (see Discussion). Nevertheless, on average the mice kept farther from the previous site A than the expected by chance (Fig. S10A,B). A first visit to B then to A was never observed during training because mice go back home after getting the food in B.</p>
<p>After learning the location of target B (<xref rid="fig6" ref-type="fig">Fig. 6C</xref>), food was also omitted from this target for Probe B-A. As illustrated in <xref rid="fig6" ref-type="fig">Fig. 6D</xref> and the Shortcut video (Video 1) (all mice shown in Fig.S8B), 5 of 8 mice were observed to go from B to A via varying trajectories (namely, mice numbered 33, 35, 36, 57 and 59). Two (number 58 and 60) of the remaining three mice went first to A and subsequently to B via direct or indirect routes; these mice had previously taken direct routes to B, suggesting that going to A first is not due to a learning deficiency. The remaining one, mouse 34, went from B to the start location and then, to A. This mouse had previously taken the B-A route during training. In all cases, the mice clearly remembered the location of both targets, even though target A had not been presented or rewarded for 4 days.</p>
<p>The geometric and kinetic features of these experiments for early and late learning of each target, and for Probe B-A, are presented in <xref rid="fig6" ref-type="fig">Fig. 6E-H</xref>. For defining the trajectory quantities in the Probe B-A trial, the “start” position is taken as target B, and the “target” is the A site (<italic>e</italic>.<italic>g</italic>., the normalized trajectory length is the ratio between total traveled and direct B-A distances). The quantities in probe B-A are statistically indistinguishable from late learning of targets (<italic>i</italic>.<italic>e</italic>., trials 14-A and 8-B). Conversely, all the Probe B-A values are significantly different both from trial 1-B and from randomized B-A trajectories (see Methods; P&lt;0.05; except for the density of hole checks which is statistically equal for all considered trials, <xref rid="fig6" ref-type="fig">Fig. 6H</xref>). Therefore, the behavior of the mice when going from B to A in the probe is compatible with the behavior of an animal that acquired spatial memory about the trajectory, even though this trajectory was never reinforced. This suggests that the mouse computed the shortcuts without prior experience (see Shortcut video (Video 1)) for an example of shortcutting and associated hole checks).</p>
<p>We calculated the displacement and hole check maps and the TEV for the whole training protocol, including the probe B-A (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). Again, the data show that, after training for A, the TEV pointed directly to A and hole checks accumulated along its path (<xref rid="fig7" ref-type="fig">Fig. 7A,B</xref>). The beginning of training for B (trial 1-B) generated random search patterns, while the TEV and hole checks tended towards A. After learning B, we see that the TEV and hole checks completely shifted to it (<xref rid="fig7" ref-type="fig">Fig. 7C,D,E,F</xref>). Remarkably, the probe B-A trajectories revealed a strong directed flow with a TEV pointing from B to A, whilst hole checks visibly accumulated along this route (<xref rid="fig7" ref-type="fig">Fig. 7G,H</xref>). The TEV-target deviation remained close to zero in late learning and probe B-A (<xref rid="fig7" ref-type="fig">Fig. 7I</xref>), whereas the area density of hole checks is increased near the target compared to far only after learning and in probe B-A (<xref rid="fig7" ref-type="fig">Fig. 7J</xref>). These maps suggest the emergence of a cognitive map guiding the mice when taking the B to A unrehearsed shortcut routes.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Trajectory directionality and active sensing in two food location experiment.</title>
<p>Arenas on the top row (mean displacement vector) correspond to the ones immediately below them (hole checking spatial distribution); the red “A” and blue “B” labels mark the targets (food sites), which are pointed by the target vector (purple arrow). <bold>Top row (A</bold>,<bold>C</bold>,<bold>D</bold>,<bold>G)</bold>: the color and arrows indicate the most probable route taken (red=more probable; only p&lt;0.001 displacements shown; pink arrow=inferred target position, or TEV; shaded pink sector=S.D. of TEV; see Methods, and Fig. S7). <bold>Bottom row (B</bold>,<bold>E</bold>,<bold>F</bold>,<bold>H)</bold>: spatial distribution of hole-checks; size and color of circles=normalized frequency at which a hole was checked (larger pink circles=higher frequency); Black ellipse (x=mean): covariance of spatial distribution. Green ellipse (+=mean): covariance of spatial distribution restricted to ≤20cm of the target. Three stages of the experiment are shown (N=8; all training done in <bold>static entrance with no landmarks</bold>): after learning the target A (<bold>A</bold>,<bold>B:</bold> trial 16-A; significant routes and hole checks are observed only along the target vector, as expected); training of the target B (<bold>C</bold>,<bold>E</bold>: trial 1-B; <bold>D</bold>,<bold>F</bold>: trial 8-B; it shows the evolution of the TEV from pointing to A to pointing to B, and the hole checks distribution becomes limited to the newly learned target vector towards B); probe B-A (<bold>G</bold>,<bold>H</bold>) shows significant routes from B to A (shortcuts; N=5 out of 8 performed the route Start→B→A; see Fig. S8 for all samples); hole-checks accumulated along the B-A path suggesting that mice remember both locations. <bold>Panels I</bold>,<bold>J:</bold> TEV-target deviation and hole-check area density, respectively. Probe B-A measures are compatible with trials where trajectories have already been learned. Standard boxplot statistics. Diamond: mean. Asterisks/star: p&lt;0.05 (t-test).</p></caption>
<graphic xlink:href="529984v6_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>As a stringent control, we performed a two-food-locations experiment with a 180°-rotated probe B-A trial (<xref rid="fig8" ref-type="fig">Fig. 8</xref>; N=8). Landmarks were never present (neither for training nor for probe). In the rotated probe B-A, the mice went to the REL of B and then to the REL of A. The displacement map, hole check spatial distribution and TEV now all pointed from REL B to REL A (instead of B to A). This is consistent with both the independent experiments of the rotated probe with static entrance training and of the two-food location. Mice can thus take a novel short cut and have therefore computed a cognitive map based on a fixed starting point and self-motion cues alone.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Two food location training with 180° rotated probe.</title>
<p>Mice (N=8) are trained to find food in the target labeled “A” (red circle, panel <bold>A</bold>), and in target labeled “B” (blue circle, panel <bold>B</bold>) afterwards; then a 180° rotated probe trial (no food; panel <bold>c</bold>) is realized to check whether the mice are able to generalize and take the shortcut from REL-B (blue triangle) to REL-A (red triangle), instead of the A and B targets. No landmarks are present. Panels <bold>A</bold>,<bold>C</bold>,<bold>E</bold> show exemplars of trajectories in three stages of the experiment, and <bold>B</bold>,<bold>D</bold>,<bold>F</bold> show their time course and hole-check locations marked with circles that increase with elapsed time. <bold>G</bold>. Trajectory directionality analysis and TEV (pink arrow; shaded sector: S.D.) show that significant paths (p&lt;0.001; N=8; see Methods) point from REL-B to REL-A in the same way that it pointed from B to A without rotated entrance in <xref rid="fig7" ref-type="fig">Fig. 7G</xref><bold>. Panel H:</bold> the spatial density shows that hole checks accumulate along the REL-B to REL-A direction, instead of the B-A direction in the case without rotation in <xref rid="fig7" ref-type="fig">Fig. 7H</xref>. Black ellipse (x=mean): covariance of hole check density. Green ellipse (+=mean): covariance of the same data restricted to ≤20cm of the REL-A location. This suggests that mice follow shortcut trajectories anchored to their start location (idiothetic frame of reference).</p></caption>
<graphic xlink:href="529984v6_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have shown that mice can learn the location of a hidden food site when their entrance to an open maze remains the same across trials. Trajectories initially appeared random and took on average, over 100 seconds and covered a distance of about 10-fold that of the direct route between start and food sites (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). After a maximum of 14 trials, mice reached asymptotic performance taking, on average, &lt;10 s to reach the food site and with trajectories reaching a near optimal distance: 1.4 times greater than the direct route (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>). In the spatial learning trials, mice frequently checked holes for food along their start to food trajectories. Analyses of hole checks demonstrated the distribution of hole check sites was also modified during learning (<xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>). Hole check density decreased with learning in the first half of trajectories but remained constant during the second half. At higher spatial resolution, hole checks occurred most frequently closer to the food site after learning (<xref rid="fig4" ref-type="fig">Fig. 4K</xref>). Finally, the number of holes sampled near the food site became more consistent with learning (lower entropy: see Fig. S7G). We conclude that, given a static entrance, the mice can learn an accurate estimate of food location that guides their trajectories and associated hole check distribution.</p>
<p>Similar results have been reported for rats trained to find food in a virtual reality (VR) 2D spatial navigation task (<xref ref-type="bibr" rid="c21">21</xref>). During spatial learning, the reward check rate increased as the rat approached the reward edge for both visual and auditory reward location cues. Navigation (trajectories) and reward checking were, however, in register only for distal visual cues. In our experiments, hole checking at a reward site was not dependent on distal visual cues (see REL discussion below) suggesting that a different source (or sources) of spatial sensory input permits registration of trajectories and hole checking during real world (RW) spatial learning.</p>
<sec id="s3a">
<title>What cues are required for learning the food location?</title>
<p>A number of exogenous (tactile, localized and global visual, odorant) and self-motion (optic flow, proprioceptive and vestibular) cues might contribute to the spatial learning we observed. For any cue to be effective, it must be stable under the experimental perturbations we impose, and therefore provide unambiguous information about the location of the food reward relative to the mouse’s starting point. Below we describe which cues might be relevant for spatial learning.</p>
<sec id="s3a1">
<title>Allothetic cues</title>
<sec id="s3a1a">
<title>Tactile</title>
<p>There were no obvious scratches on the maze floor, but we cannot exclude fine scratches detectable by the mice. We wash the floor and randomly turn it between trials so that any scratches or odor trails are not consistently correlated with the food location. We also performed a specific control experiment with an exhaust fan to eliminate food scent. We conclude that tactile cues are likely not used for spatial learning under our experimental conditions.</p>
</sec>
<sec id="s3a1b">
<title>Localized visual landmarks</title>
<p>Rodent vision is important for tasks such as navigating complex environments, finding shelter, prey capture and predator avoidance (see (<xref ref-type="bibr" rid="c22">22</xref>) for a review). Previous behavioral and physiological studies suggested that our wall cues could be resolved by the mouse visual system (<xref ref-type="bibr" rid="c23">23</xref>-<xref ref-type="bibr" rid="c27">27</xref>). It was therefore surprising that the mice were unable to find the food site when its start location was randomly switched between trials. A comparison of static versus random start sites after learning revealed that, unlike the static case, there was no reduction of trajectory length or increase of hole checks near the food site in the random start experiments. We considered whether the mice were learning slowly and simply needed more trials to learn the random start site task. We therefore checked if there was any improvement in target estimation over 4 successive trials. As shown in Fig. S8, actual hole checks over the 4 trials are no different from randomized hole checks suggesting that the mice are randomly choosing holes to check.</p>
<p>The random start task requires the mouse to learn the relative location of food with respect to a changing view of the landmarks. Rats have been shown to be able to solve this task in the Morris Water Maze (MWM) (<xref ref-type="bibr" rid="c7">7</xref>). Previous studies showed that mice can use distal cues for spatial learning under different experimental conditions, such as in a one-dimensional T-maze, linear track, or when there are multiple highly salient cues (<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c28">28</xref>-<xref ref-type="bibr" rid="c31">31</xref>). Our random start task would therefore seem to have all the requirements for spatial learning. The simplest explanation is that, unlike some of the cited papers, the cues we used were not sufficiently salient.</p>
<p>An alternate factor might be the lack of reliability of distal spatial cues in predicting the food location. The mice, during pretraining trials, learned to find multiple food locations without landmarks. In the random trials, the continuous change of relative landmark location may lead the mice to not identifying them as “stable landmarks”. This view is supported by behavioral experiments that showed the importance of landmark stability for spatial learning (<xref ref-type="bibr" rid="c32">32</xref>-<xref ref-type="bibr" rid="c34">34</xref>) and that place cells are not controlled by “unreliable landmarks” (<xref ref-type="bibr" rid="c35">35</xref>-<xref ref-type="bibr" rid="c38">38</xref>). Control experiments without landmarks (Fig. S6A,B) or in the dark (Fig. S6C-F) confirmed that the mice did not need landmarks for spatial learning of the food location.</p>
</sec>
<sec id="s3a1c">
<title>Arena geometry</title>
<p>The mice might use the distance and bearing from its start location to the three other maze entrances. Triangulation might then enable it to estimate the food location based on such global features and continuously update its position by using the relative location of the entrances. Our control experiments (Fig. S6C,D,E,F) showed that such information is not needed for spatial learning but do not rule out that this information is an additional cue available to the mice under more natural foraging conditions.</p>
</sec>
<sec id="s3a1d">
<title>Odor cues</title>
<p>The mouse’s cage will be saturated by its own odor. Transferring the mouse to a different cage might enable it to recognize the change in its starting point. However, our maze was designed to eliminate this “self-cage” odor cue as each mouse stays in its own home cage during the entire experiment. In the Random trials, the entire cage + mouse is moved to a different entrance on each trial. In the Static trials, the cage + mouse is only moved to a different entrance on the REL trials.</p>
<p>Odor cues might come from odor trails left during a preceding trajectory to food, from the odor of the hidden food or from an odor gradient emerging from the mouse’s home as it leaves to find food. The odor trails were reduced by washing the floor between trials. Any remaining odour was made unreliable as the floor was rotated between trials. A subfloor beneath the maze floor was covered with crumbled fragments of the same food within the capped hole. We assume that the entire maze was saturated with the food odor and that this would mask the odor coming from the accessible food. Mice would search in holes adjacent to the food without successfully locating the food, suggesting no detectable odour at that distance. In addition, the mouse ran to and searched at the food hole on probe trials confirming that it did not require a food odor to find the food hole.</p>
<p>Mice can also use localized odor sources as landmarks for spatial learning (<xref ref-type="bibr" rid="c20">20</xref>), and might therefore use odor gradients emanating from their home cage as a cue. We reduced this potential cue by applying negative pressure via exhaust fans covering the cage top that were turned on 5 minutes before an experiment commenced and its full air volume evacuated 30 times/minute (150 evacuations) to equilibrate it to the room air. After the door to the maze was opened, the fans induced negative pressure to draw air from the maze into the cage and thereby reduce a potential outward gradient (see Methods). The mice were still able to learn the food location after such reduction of olfactory cues (Fig. S6E,F) suggesting that odor gradients are not required for spatial learning under our experimental conditions.</p>
</sec>
</sec>
<sec id="s3a2">
<title>Idiothetic cues</title>
<sec id="s3a2a">
<title>Optic flow cues</title>
<p>Although the mice can take varying trajectories, the TEV suggests that they continuously update their knowledge of the direction from start to food throughout their trajectories. This further suggests that the neurons coding for head direction are essential for spatial learning in our maze. Heading direction can be derived from optic flow signals (<xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c40">40</xref>). In the static entrance experiments, the heading direction is constantly updated throughout the entire run (Fig. S4G), having the mouse veer toward the food only in the last segment of the trajectory (Fig. S4Giii). Hippocampal neurons of rats randomly foraging in a real world or virtual reality environment can develop directional responses based on rich and stable optic flow signals and without requiring vestibular input (<xref ref-type="bibr" rid="c41">41</xref>). In our maze, landmarks and home cage openings may drive optic flow signalling irrespective of whether they act as local visual cues. This is consistent with the hypothesis that visual input can guide navigation via a central retinal stream for landmarks and a peripheral retinal stream for optic flow input (<xref ref-type="bibr" rid="c42">42</xref>). Our in the dark experiments suggest that other sensory input might also drive the head direction network.</p>
</sec>
<sec id="s3a2b">
<title>Vestibular and proprioceptive cues</title>
<p>The vestibular system encodes natural motion (<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c44">44</xref>) and contributes to the generation of head direction responses (<xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c46">46</xref>). We hypothesize that, in the “dark” experiments, vestibular cues are a major signal supporting spatial learning. In agreement with VR studies (<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>), we hypothesize that contextual visual cues of the starting point and arena boundary anchor directional information derived from optic flow, vestibular and perhaps proprioceptive signals to fixed environmental features.</p>
</sec>
</sec>
</sec>
<sec id="s3b">
<title>A fixed start location and self-motion cues are required for spatial learning</title>
<p>We also considered that mice, unlike rats (<xref ref-type="bibr" rid="c7">7</xref>), may be unable to learn the random entrance task because it requires associating four different spatial cue configurations with a food location. This would hold when the visual cues were local. In the static entrance task, the mice might be learning a unique configuration of the cues or even the relative location of a single cue and the food location (<xref ref-type="bibr" rid="c6">6</xref>). In the REL experiments we therefore first fully trained the mice with a static entrance and, in a probe trial, randomly switched them to another entrance rotated by 90°, 180°, or -90°. Unlike rats in the MWM (<xref ref-type="bibr" rid="c7">7</xref>), the mice ran to the REL location (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) clearly demonstrating that they assume that their start location has not changed and that the local visual cues did not guide the mice. We hypothesize that the optic flow signals emanating from the distinct landmarks, derived from low resolution peripheral retina (<xref ref-type="bibr" rid="c42">42</xref>), are invariant to and thus cannot differentiate between the mouse’s start sites. Additional control experiments made without landmarks or in darkness also showed that visual input is not required for spatial learning in our maze (Fig. S6). We hypothesize that the minimal conditions for the mice learning the heading direction from start to food is based on self-motion cues (optic flow, proprioception and vestibular) and one fixed local cue – the start site.</p>
</sec>
<sec id="s3c">
<title>Combining trajectory direction and hole check locations yields a Target Estimation Vector</title>
<p>Here we follow a review by Knierim and Hamilton (<xref ref-type="bibr" rid="c12">12</xref>) that hypothesized independent mechanisms for extraction of target direction versus target distance information. Our data strongly supports their hypothesis. Target direction is nearly perfectly estimated at trial 6 (<xref rid="fig4" ref-type="fig">Fig. 4I</xref> and Results). The deviation of the TEV from the start to food vector is rapidly reduced to its minimal value (5.16°) and with minimal variability (SD=0.20°). Learning the distance from start to food is also evident at trial 6 but only reaches an asymptotic near optimal value at trial 14 (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>). The learning dynamics are therefore very different for target direction versus target distance. As noted below, the food direction is likely estimated from the activity of head direction cells. The neural mechanisms by which distance from start to food is estimated are not known (but see (<xref ref-type="bibr" rid="c49">49</xref>)).</p>
<p>Averaging across trajectories gave a mean displacement direction, an estimate of the average heading direction as the mouse ran from start to food. The heading direction must be continuously updated as the mice runs towards the food (which is suggested in Fig. S4G), given that the mean displacement direction remains straight despite the variation across individual trajectories. Heading direction might be extracted from optic flow and/or vestibular system and be encoded by head direction cells. However, the distance from home to food is not encoded by head direction signals.</p>
<p>The mice, after learning with static entrances, made the greatest number of hole checks in the vicinity of the food-containing hole. We therefore used the mean of the “near food” hole check distribution (see <xref rid="fig4" ref-type="fig">Fig. 4</xref>) to give a magnitude to the displacement direction, thus generating the TEV. With learning, the TEV rapidly converged to closely align with the direct start-to-food vector (<xref rid="fig4" ref-type="fig">Fig. 4E,F,I</xref>). In REL trials, the calculated TEV pointed to the REL despite the lack of food at the hole check sites (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). A close analysis of individual trajectories revealed that, while some closely aligned to the TEV and went directly to food, others deviated from the TEV/direct route and then returned to it (<xref rid="fig4" ref-type="fig">Fig. 4F</xref> and S7D). The standard assumption is that deviations from a direct route are due to path integration errors (<xref ref-type="bibr" rid="c50">50</xref>). It is not obvious why errors only occur on some routes. A second possibility is that the deviations are intended and meant to prevent route predictability and therefore predation (<xref ref-type="bibr" rid="c51">51</xref>). It is not clear why the mouse does hole checks if it is only reducing route predictability. A plausible hypothesis is that the mice deliberately deviate from the TEV in order to continue exploring for food-containing holes, <italic>en route</italic> to exploit the food reward. We hypothesize, following Knierim and Hamilton (<xref ref-type="bibr" rid="c12">12</xref>), that a path integration mechanism operates continuously to return the mouse to its current TEV estimate no matter what the reason for the deviations from the TEV.</p>
<p>We hypothesize that path integration over trajectories is used to estimate the distance from start to food. The stimuli used for integration might include proprioception or acceleration (vestibular) signals as neither depends on visual input. Our conclusion is in accord with a literature survey that concluded that the distance of a target from a start location was based on path integration and separate from the coding of target heading direction (<xref ref-type="bibr" rid="c12">12</xref>). Our “in the dark” experiments reveal the minimal stimuli required for spatial learning – an anchoring starting point and directional information based on vestibular and perhaps proprioceptive signals. This view is in accord with recent studies using VR (<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>).</p>
<p>Path integration uses self-motion signals to update the animal’s estimated location on its internal cognitive map. Path integration gain has been shown to be plastic and regulated by landmarks (<xref ref-type="bibr" rid="c52">52</xref>). Remarkably, a recent study has revealed that path integration gain can also be directly recalibrated by self-motion signals (<xref ref-type="bibr" rid="c53">53</xref>), albeit not as effectively as by landmarks (<xref ref-type="bibr" rid="c52">52</xref>, <xref ref-type="bibr" rid="c53">53</xref>). An interesting question for future research is whether self-motion signals can also recalibrate the coordinates of a cognitive map. From this perspective, the Target B to Target A shortcut requires transformation of the cognitive map coordinates so that the start point is now Target B.</p>
<p>Extensive research has shown that external cues can control hippocampal neuron place fields (<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c54">54</xref>) and the gain of the path integrator (<xref ref-type="bibr" rid="c52">52</xref>), making the failure of mice in our study to use such cues puzzling. The failure to use landmarks may be related to our task being low stakes and our pretraining procedure teaching the mouse that such cues are not necessary. Our results may not generalize to more natural conditions where many reliable prominent cues are available, and where there is urgency to find food or water while avoiding predation (<xref ref-type="bibr" rid="c55">55</xref>). Under these more naturalistic conditions the use of distal cues to rapidly find a food reward is more likely to be observed.</p>
</sec>
<sec id="s3d">
<title>Implications for theories of hippocampal representations of spatial maps</title>
<p>The TEV is learned using self-motion cues alone and we hypothesize that it guides locomotion to the food hole via a path integration mechanism. This conclusion is in accord with an extensive literature that emphasizes the importance of self-motion cues and path integration for spatial learning (<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c56">56</xref>). The conclusion is also not surprising given studies on weakly electric fish that demonstrate that, with a fixed initial location, active sensing and self-motion cues are sufficient for learning the location of a food site in the dark (<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c57">57</xref>), and that accumulation of path integration error degrades performance as a function of trajectory length (<xref ref-type="bibr" rid="c58">58</xref>, <xref ref-type="bibr" rid="c59">59</xref>). Given the presumed accumulation of error by the mammalian path integration mechanism (<xref ref-type="bibr" rid="c50">50</xref>), it is generally assumed that proximal and/or distal exogenous cues must calibrate the putative path integrator in order to determine not only target direction but also target distance from a start site (<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c52">52</xref>, <xref ref-type="bibr" rid="c56">56</xref>). Path integration gain of hippocampal neurons is a plastic variable that can be altered by conflicts between self-motion cues and cues and feedback from landmarks (<xref ref-type="bibr" rid="c52">52</xref>). The independence of the TEV from landmark cues (REL experiments) again demonstrates that, in absence of such “conflicts”, self-motion provides consistent cues for path integration and spatial map formation.</p>
<p>The use of hole checking to compute a mouse’s estimate of the food location allows us to refine these conclusions. The TEV provides not only an estimate of the food location, but also of the distance from start to food site; this is especially clear in the REL experiments where, given the lack of food, a mouse’s search is clearly centered at the expected food location (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). Sophisticated analyses have been used to link the spatial coding neurons of entorhinal, subicular and hippocampal neurons to behavioral studies on the interaction of exogenous and self-motion signals (<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c60">60</xref>). Here, we provide strong behavioral evidence to support the role of hippocampal place cells in encoding the trajectories and food site locations observed in our study. Two studies suggest that, in the rat, CA1 place fields will remain stable in the absence of visual cues. Many place cells responses observed in the presence of visual cues will remain after these cues are removed; the authors conclude that self-motion cues are sufficient to maintain normal place fields (<xref ref-type="bibr" rid="c11">11</xref>). Experiments with blind rats have shown vision is not necessary for the development of normal firing of hippocampal place cells (<xref ref-type="bibr" rid="c61">61</xref>). Together, these studies suggest that mice CA1 cells will exhibit place fields in our open maze. Analyses of spatial learning in VR versus RW (rats) suggested that distal visual cues, and self-motion (i.e., proprioceptive, vestibular) cues may be required to activate place cells representing allocentric space. In the absence of distal visual cues, CA1 cells preferentially encoded distance traveled during learned trajectories toward a food goal (<xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c63">63</xref>).</p>
<p>Rats can learn to navigate, in VR, from different start locations to a hidden goal using very salient distal visual cues (<xref ref-type="bibr" rid="c64">64</xref>). Unlike RW spatial learning, CA1 pyramidal cells then only weakly encoded allocentric spatial information (place fields) but instead, primarily encoded trajectory distance and head direction – thus, these cells may comprise a possible neural implementation of the behavioral TEV. These experiments demonstrate great flexibility in the hippocampal encoding of trajectories and location both across pyramidal cells and, for individual cells, across the learned trajectory. An important question is how CA1 pyramidal cells will discharge as a mouse runs along the stereotyped trajectories learned with only self-motion cues as in our experiments. A stringent prediction of the discussion above is that mouse CA1 cells activated along trajectories towards the hidden food should be activated at equivalent locations in REL experiments, and in response to the same multiplexed cues: trajectory distance, head direction and allocentric location.</p>
<p>A subset of hippocampal (CA1) neurons in the bat were reported to encode the direction and/or distance of a hidden goal (<xref ref-type="bibr" rid="c65">65</xref>). The vectorial representation of goals by such cells could be the substrate of the start-to-food location trajectories we have observed. Recently described CA1 convergence sink (ConSink) place cells (<xref ref-type="bibr" rid="c66">66</xref>) may also have the properties needed to account for the learned start-to-food trajectories we observed. ConSink cells are directional place cells that can encode local direction towards a goal. ConSink cells will, with training, shift their direction tuning to a new goal. The ConSink population vector average, like the TEV, then points directly from start to goal. In both cited studies, landmarks were present, and it is unknown whether such cells will be found in the absence of visual cues.</p>
<p>ConSink-like cells were reported in the CA1 of a mouse foraging in an open field, but their direction tuning was not pointed towards a singular goal (<xref ref-type="bibr" rid="c67">67</xref>). We hypothesize that in the pretraining foraging phase of our spatial learning task, ConSink cells will also have random direction tuning. Upon fixed start location training, we hypothesize that the ConSink direction tuning will become aligned with the mouse’s trajectories and their population average will closely approximate the computed behavioral TEV. The TEV and the ConSink cell population average are statistical measures derived from behavioral and electrophysiological data respectively. An important question is whether an explicit TEV is computed and defines the spatial map guiding the mouse’s food-finding trajectories. An equally plausible hypothesis is that the “spatial map” remains a distributed computation in the CA1 targeted neural networks. Experimental tests of these alternatives address an essential question: how is spatial information represented in neural networks?</p>
<p>Numerous studies have reported that goal sites are overrepresented by CA1 place cells (<xref ref-type="bibr" rid="c4">4</xref>). The requirements for such overrepresentation are that there are stereotyped trajectories directed towards an invisible memory-based goal associated with reward (<xref ref-type="bibr" rid="c4">4</xref>). The stereotyped trajectories and the hidden memory-based goal of our study imply that these requirements are met. Interestingly, the “goal-related place cells” are activated before the goal is reached (<xref ref-type="bibr" rid="c4">4</xref>), just as hole checks mostly occur as the mice approach the food containing hole from any direction (<xref rid="fig4" ref-type="fig">Fig. 4F,H</xref>). We hypothesize that, after learning, CA1 place cells will overrepresent the maze region containing the goal location, and that their place fields therefore overlap the hole check sites surrounding the hidden food hole.</p>
<p>Behavioral time scale plasticity (BTSP) has been proposed to be the cellular mechanism that generates new CA1 place fields at important locations, including those associated with reward (<xref ref-type="bibr" rid="c68">68</xref>-<xref ref-type="bibr" rid="c70">70</xref>). BTSP operates up to a ∼3 s time frame. If BTSP is operating during spatial learning in our maze, there will be excessive place fields within the &lt;3 s search time before it finds the food hole. BTSP is bidirectional and can result in CA1 place fields translocating with experience (<xref ref-type="bibr" rid="c70">70</xref>) and the location of CA1 cell place fields may therefore evolve during static entrance training. We note that the cited experiments were done with virtual movement constrained to 1D and in the presence of landmarks. It remains to be shown whether similar results obtain in our unconstrained 2D maze and with only self-motion cues available.</p>
<p>The putative emergent CA1 place fields might be randomly distributed but might also be connected with the “special” hole check locations. We plotted the evolution of &lt;3 s from target hole checks in the static and random entrance experiments (Fig. S9). With spatial learning (static entrance), temporally “close to target” hole checks increase relative to temporally distant hole checks and converge to the target site. Active sensing is critical for electric fish spatial learning (<xref ref-type="bibr" rid="c49">49</xref>), and is also known to potentiate or induce CA1 cell place fields (<xref ref-type="bibr" rid="c71">71</xref>). We hypothesize that the persistent &lt;3s hole checks near the food site that increase during training will, via the BTSP mechanism, drive the emergence and translocation of CA1 cell place fields so that they accumulate centered on checked holes near the rewarded food site (<xref ref-type="bibr" rid="c4">4</xref>). This leads to the prediction that a place cell discharging during a hole check near the food site should also discharge after the mouse start site has been rotated and it checks an empty REL hole.</p>
</sec>
<sec id="s3e">
<title>Shortcutting – Evidence for a cognitive map derived from self-motion signals</title>
<p>The O’Keefe and Nadel text (<xref ref-type="bibr" rid="c16">16</xref>) connected hippocampal place cells to the abstract concept of a cognitive map developed by Tolman (<xref ref-type="bibr" rid="c13">13</xref>), and this linkage has been generally supported with few dissenting views (<xref ref-type="bibr" rid="c72">72</xref>-<xref ref-type="bibr" rid="c75">75</xref>). The criteria for a cognitive map are of animals taking unrehearsed shortcuts (<xref ref-type="bibr" rid="c14">14</xref>), detours (<xref ref-type="bibr" rid="c13">13</xref>) or novel routes (<xref ref-type="bibr" rid="c7">7</xref>). In this literature animals typically have both landmark and self-motion cues available for spatial learning. To the best of our knowledge, unrehearsed shortcut behavior using only self-motion cues and a fixed start location has only been shown in humans (<xref ref-type="bibr" rid="c56">56</xref>, <xref ref-type="bibr" rid="c76">76</xref>). Our result on shortcutting after spatial learning based entirely on a fixed start location and self-motion cues (<xref rid="fig7" ref-type="fig">Fig. 7</xref>) is therefore the first behavioral demonstration of a rodent cognitive map learned without exogenous cues and using the strict Tolman definition. The TEV for the shortcut trajectories well approximates the direct route between the Site B and Site A food locations (<xref rid="fig7" ref-type="fig">Fig. 7G,H</xref>) demonstrating the accuracy of the putative cognitive map food location estimate.</p>
<p>The shortcut trajectory from Site B to Site A (<xref rid="fig7" ref-type="fig">Fig. 7G,H</xref>) might be formally computed in two ways. For the 3 mice that had taken the Site A to Site B route during training, the following vector arithmetic is required for the final probe trial when it went from Site B to Site A:
<disp-formula id="ueqn1">
<graphic xlink:href="529984v6_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="529984v6_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. For the 4 mice that had never taken the Site A to Site B route during training, the following vector arithmetic is required for the final Site B to Site A shortcut:
<disp-formula id="ueqn2">
<graphic xlink:href="529984v6_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The TEVs for Start→A and Start→B appear to be still remembered by the mice in the probe trial, since the accumulation of hole checks at both sites is still evident (<xref rid="fig7" ref-type="fig">Fig. 7H</xref>). The hypothesized ConSink place cells directed to Targets A and B and the accumulation of cells with place fields at both sites will therefore, as described above, still encode the trajectories to each location. To our knowledge, neurons that might compute the required vector arithmetic have not been identified in any part of the rodent brain.</p>
<p>We hypothesize that the TEVs estimated by neural networks downstream of goal vector cells, CA1 ConSink cells and goal location place field cells will be used to compute the shortcut trajectories. Discovering the networks that do these putative computation(s) may provide insight into the neural bases of the spatial cognitive map.</p>
</sec>
</sec>
<sec id="d1e1785" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1861">
<label>Supplemental figures</label>
<media xlink:href="supplements/529984_file02.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<sec id="s4">
<title>Author Contributions</title>
<p>All experiments were carried out in the L.M. laboratory at the University of Ottawa. J.X ran all experiments, analysed learning and contributed to experiment design, writing the manuscript and preparing figures. M.G-S. developed analysis for trajectories and hole checks, and carried out the analyses plus associated figures and contributed to writing the manuscript. J-C. B. contributed to writing the manuscript. A.L. contributed to developing trajectory analysis methods and writing the manuscript. L.M. developed the conceptual framework for the experiments and contributed to and supervised all aspects of the experiments and data analyses and wrote the manuscript.</p>
</sec>
<ack>
<title>Acknowledgments</title>
<p>We would like to thank Dr. Érik Harvey-Girard for technical support, and William Moldenhauer de Jesus for joining the short cut experiment video with the hole check data. This work was supported by the Canadian Institutes for Health Research Grant # 153143 to AL and LM and J-C B, a Brockhouse award (493076-2017) to AL and LM, an NSERC award (RGPIN/06204-2014) to AL, an NSERC award to LM (RGPIN/2017-147489-2017) and a grant from the Krembil Foundation to AL, LM and J-C B.</p>
</ack>
<sec id="s5">
<title>Data availability</title>
<p>All codes and data are available in <ext-link ext-link-type="uri" xlink:href="https://github.com/neuro-physics/mouse-cogmap">https://github.com/neuro-physics/mouse-cogmap</ext-link></p>
</sec>
<sec id="s6">
<title>Declaration of interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec id="s6a">
<title>Video 1 Legend</title>
<p>The Shortcut video (Video 1) illustrates a two-food site experiment including hole checks; there were no landmarks. The mouse was first trained with food at Site A (6 days, 18 trials) and, after training was complete, trained with food at Site B (3 days, 9 trials). The video was taken on a probe trial (Day 10) with no food at either Site A or Site B. The mouse is observed to proceed along a TEV to Site B with a departure from the TEV at the second hole check, followed by a third hole check as it loops back to Site B. After hole checking Site B, the mouse goes on a TEV to Site A with a departure after its third hole check. It then returns to the TEV with further hole checks. Just before reaching Site A the mouse turns and moves very slowly to a hole 16 cm from Site A; this hole check was missed by our algorithm and had to be manually added for statistics. The mouse spends ∼2 s at this hole, although it had never contained food; other holes were visited for &lt;1s. Over the course of the experiment, the mouse visited this hole 5 times prior to finding the food, but did not visit it in the 4 trials preceding this Probe trial. Other holes within 15 cm of the target were visited at equal or greater rates. In other words, there was no special sensory input that would have made this hole interesting.</p>
<p>We hypothesize that this was the hole predicted by the mouse’s cognitive map to be Site A. The mouse subsequently continued to check Site A and a site near the wall. At this point the experiment was terminated. Our “wash and rotate the floor” protocol to eliminate odor trails or “floor scratch cues” results in the floor of the maze being washed and rotated 108 times from the first Site A learning trial to the final Probe trial when Site B and Site A were empty. The floor rotation results in the same configuration of hole positions relative to every entrance, making the environment identical at every trial for all the mice (see Methods).</p>
<p>Note that the mouse makes its first hole check at a hole near the entrance and a final hole check near the maze wall far from an entrance. Food was never given at either site and there were no features differentiating these holes to make them “interesting”. These “near the wall” hole checks were also seen in other mice, but we have no compelling hypothesis as to why they occur at these holes.</p>
</sec>
<sec id="s7">
<title>Material and Methods</title>
<sec id="s7a">
<title>Animals</title>
<p>All animals were housed in the University of Ottawa Animal Care and Veterinary Services (ACVS) facility. C57Bl/6 wild-type male and female mice were ordered from Charles River, arriving at 8-9 weeks old. Mice were individually housed in 12h light/12h dark cycles (lights on at 11:00PM EST, lights off at 11:00AM EST). Animals had had food and water available <italic>ad libitum</italic>. The temperature of the room was kept at 22.5°C and the humidity was 40%. Mice were habituated in ACVS facilities for 1 week and began testing when they were 10-11 weeks old. Testing of each cohort took place over the course of approximately 2 weeks, 1 hour after the lights turned off. Subjects weighed 22-27 grams at the start of behavioural training. Both male and female mice were used; the same results were obtained in both sexes and were therefore pooled. All animal procedures were conducted with the approval of the University of Ottawa’s Animal Care Committee and in accordance with guidelines set out by the Canadian Council of Animal Care.</p>
</sec>
<sec id="s7b">
<title>Apparatus Design &amp; Setup</title>
<p>The Hidden Food Maze (HFM) is a framework that trains mice to search for a food reward hidden in an open, circular arena (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). The protocol for the task was inspired by an open maze protocol used to study electric fish spatial learning (<xref ref-type="bibr" rid="c57">57</xref>) and by the Cheese Board spatial task in which rats are placed inside an arena with many holes in the floor, one of which contains a food reward (<xref ref-type="bibr" rid="c77">77</xref>). Unlike the Kesner et al task, the HFM does not require the animal to be handled, and the pattern of holes is arbitrary rather than grid-like. This task design was also chosen to mirror the setup of the Morris Water Maze (MWM) (<xref ref-type="bibr" rid="c7">7</xref>), which can test allothetic or idiothetic navigation. Like the MWM and the electric fish arena, mice are searching for a food reward location in a circular environment after starting from one of four starting home locations. External landmarks can, if desired, be placed on the maze walls or local cues placed in the maze. In contrast to the MWM, this spatial learning task is a dry maze that is food motivated, which is more naturalistic and less stressful than motivation by the aversion to swimming and fear of drowning. Notably, the task has specific design features to control for against unwanted cues, such as odours, visual cues, and handling.</p>
<p>The maze has a removable floor that is washed &amp; rotated between trials to eliminate odor trails which mice from previous trials might leave behind. The circular floor is 120 cm in diameter and has 100 holes (1.2cm diameter) randomly dispersed throughout the surface, with 25 holes in each quadrant. The distance between each hole is, on average, 10 cm. The pattern of the holes is rotationally symmetrical, so the pattern looks the same regardless of whether the floor is rotated 90°, 180°, or 270° with respect to the mouse’s entrance. This ensures that the mouse will have the same initial view of the holes regardless of which entrance it starts from and how the floor is rotated. Each hole is encircled by a 1 cm plastic rib, sticking downwards, which can be capped at the bottom to hold food that remains invisible from the surface. Thus, the mice cannot discern the contents of the hole just by looking across the floor from their home, but instead need to approach the hole and look inside. The surface of the floor is sanded to be matte to avoid generating reflections from the lights which might interfere with the cameras or distract the mice.</p>
<p>The maze floor is circular and uniform from the inside so as not to provide any directional cues. The floor of the arena is encircled by tall black walls. The walls are made of solid black PVC plastic which forms a cylinder around the maze and is open at the top. The walls are 1 cm thick and 45 cm tall, which is tall enough so the mice cannot jump out. The walls are symmetrical and designed to eliminate geometric cues that would give away directional information from asymmetries in the environment shape. Mice can use odors as landmarks for spatial learning (<xref ref-type="bibr" rid="c20">20</xref>) and we wanted to eliminate local food odour from a filled hole as a landmark. The arena is resting on a subfloor that contains crumbled food; food odor will diffuse through the open holes and saturate the maze thus masking the odor from a food-filled hole.</p>
<p>The home cages attach to the main arena by being slotted into each entrance. The home cages are 27cm x 16.5cm x 45cm and are open at the top. They contain a food hopper and a water bottle feeder. The dimensions of the home cage are based on commercial mouse cages and comply with the Canadian Council on Animal Care mouse housing standards.</p>
<p>When moving mice to a different starting quadrant, the home cages are designed to slide out from the maze and into a new entrance so the mice do not need to be handled and will therefore not be stressed. The home cages include their own doors, separate from the doors that provide entry into the maze, so the home cage can be freely moved and the mice remain securely confined. The detachable home cages allow the mice to be moved to different starting locations, allowing us to control against navigational strategies that rely solely on response learning or path-integration from a fixed starting point.</p>
<p>Mice can perform the entirety of the trial without experimenter handling. The maze doors are designed to slide upwards and provide access to the main arena. When the trial is finished, the experimenter can slide the doors back into place and the mouse is confined to its home cage once again. To not disturb the mice, the doors are left open while they navigate.</p>
<p>Four LED flashlights were aimed at a white ceiling in order to create dim, diffuse lighting throughout the maze. The illuminance is measured to be 50 lux at the surface of the arena. Dim light was used to allow the mice to properly see all visual cues as well as the maze details. This procedure is assumed to not perturb the nocturnal cycle of mice (<xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c79">79</xref>). Black curtains surrounded the maze to prevent the interference of non-controlled visual cues.</p>
<p>We used additional experiments to control for possible visual or odorant cues from the open home door. We did some experiments in total darkness using infrared LEDs with emission spectra detected by our camera. In order to exclude any potential olfactory cues emanating from the open cage door we did experiments where odor absorbent kitty litter was placed on the cage floor and two connected exhaust fans (AC Infinity MULTIFAN S5, Quiet Dual 80mm USB Fan) placed above the home cage. At their lowest (quiet) setting, the fans drew air from the home cage and blew it to the outside; replacement air from the outside came in via small openings at the bottom of the home cage. The home cage air volume was evacuated 30 times/minute, effectively equilibrating the cage and open maze air before the doors were slid upwards. Fans were turned on for 5 minutes (150 evacuations) before the trial started and for the duration of the trial. After the door was opened, the fans induced negative pressure to eliminate diffusion of odors from the home cage to the maze. The two fans were placed over each home cage and turned on to eliminate a potential directional noise cue.</p>
</sec>
<sec id="s7c">
<title>Behavioural Training</title>
<sec id="s7c1">
<title>Pre-training</title>
<p>Five days before training, mice are transferred from standard animal facility cages to the experimental home cages for habituation. On the first day, mice are allowed to habituate to their new home cages. On the second day, the door dividing the home cage and the arena is removed and each mouse is given free access to explore the empty arena for 10 minutes. There are no extra-maze landmarks present during pretraining. Animals are food restricted, with 10% of their body weight in food given back each day which they could consume <italic>ad libitum</italic>. On day 3, randomly chosen 50% of the holes in the arena are filled with food treats (a piece of Cheerio), and each mouse is given 10 minutes to forage for food. This is repeated on day 4, where 25% of the arena’s holes are filled with food treats. On day 5, only four holes placed at the maze center contained treats. Mice pass the pre-training stage when they successfully found treats at all locations within 20 minutes. Mice mostly confined their search to circular trajectories near the wall of the maze for Days 3 and 4 but, after training with food near the maze center (Day 5), they checked holes throughout the maze (Fig. S1A). Training in the spatial learning task then commenced.</p>
</sec>
<sec id="s7c2">
<title>Visual Cues + Randomized Entrances Training</title>
<p>The mice are trained to locate a food reward that has a fixed relationship with four visual cues on the walls. The protocol mimics classic Morris Water Maze setups to test allocentric landmark-based learning. One of the holes in the area is capped from the bottom with a food-containing insert that is not visible from the surface. Extra-maze landmarks (described in the Visual Cues section) are placed on the walls of the maze to serve as location cues. At the start of the trial, the door is slid upwards so the mice can enter the maze, and the mice are given a maximum of 20 minutes to find the target hole. The home door is kept open to permit the mice free access to return to their home cage during the trial; preliminary experiments indicated that closing the door perturbed the mice. The door is re-inserted after the mouse has found the food reward and returned home. If the mouse has not returned home by itself after 1 minute of finishing the food reward, it is gently guided back by the experimenter. There is an inter-trial interval of approximately 20 minutes.</p>
<p>Initial experiments used two trials per day but this was increased to speed up learning; our analyses and graphs are truncated at 14 trials to permit averaging over all the mice. In most experiments, three trials a day were given, over six days; at the end of each trial the mouse’s home is moved to a different entrance. The home location was changed for each trial; the floor was washed and rotated by 90°, 180°, or 270° between trials, independent on whether the home entrance was the same (static trials) or rotated (random trials). The location of the entrance is randomized with the following constraints: no two trials in a row have the same entrance, and all entrances are selected the same number of times so there is no bias. On the 7th day, a probe trial is given where the mouse is allowed to search for food in the absence of any food. Learning continues over 1 more day and, on the 9<sup>th</sup> day, a reversal trial is given where the visual landmarks are rotated by 180°. The location of the home cage is randomized before every trial. In this task, the mouse would have to learn the invariant relation between the food hole and up to four visual cues in order to locate the food.</p>
<sec id="s7c2a">
<title>Visual Cues</title>
<p>Four black symbols on white backgrounds: a square, a cross, vertical bars, and horizontal bars. The cues are taped 5 cm above the floor. The square was 15 by 15 cm. The cross consisted of two 2.5 cm wide and 14 cm long bars. The four vertical and four horizontal bars were 2.5 cm wide and 14 cm long. Previous behavioral studies have shown that mice can discriminate the visual stimuli we use (<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>). Recording of neurons in mouse V1 have additionally shown that orientation selective cells in mice visual cortex can discriminate our visual stimuli (<xref ref-type="bibr" rid="c24">24</xref>).</p>
</sec>
</sec>
<sec id="s7c3">
<title>Visual Cues + Static Entrance Training</title>
<p>This protocol allows mice to navigate by potentially using visual cues in cooperation with path integration or by path integration alone. The setup is the same as visual cues training, except mice enter from the same entrance each trial instead of a randomized entrance. Mice are considered well trained once their latency learning curve has plateaued for 3 successive trials. The mice’s latencies had plateaued by 14 trials but training continued till 18 trials.</p>
<p>After 18 trials, reversal trials were done with no food present and the mouse’s home cage rotated 180°. The mouse was allowed to search for food for 10 minutes. If the mice were able to learn the invariant landmark/food spatial relationship, we would expect them to search at the learned food site. If they had used path integration of self-motion cues to navigate from the fixed entrance to the food, we would expect them to search at the rotationally equivalent location (REL).</p>
</sec>
</sec>
<sec id="s7d">
<title>Rotationally Equivalent Location (REL)</title>
<p>The four quadrants of the arena’s floor are identical. This means that the position of the holes in the second quadrant (Q2, <xref rid="fig1" ref-type="fig">Fig. 1B</xref>; also Fig. S4A) is equal to the position of the holes in the first quadrant (Q1) rotated by 90° counter clockwise (CCW) about the center of the arena. Q3 is Q1 rotated by 180° (CCW) and Q4 is Q1 rotated by -90° (i.e., 90° CW). In other words, every hole in Q1 has an REL in each quadrant achieved by the respective rotation. The REL target works in the same way: it is the position (relative to the entrance used in the trial) where the food would have been had the mouse been trained from the entrance it used in the trial. To illustrate this, consider <xref rid="fig1" ref-type="fig">Fig. 1D</xref>: we put the food (target) in a particular hole in Q1 for a mouse that is trained to enter from Q2 (such as the example in <xref rid="fig1" ref-type="fig">Fig. 1B</xref>) in the static entrance protocol. The vector that points from the mouse’s start point (in Q2) to the target in Q1 (i.e., the target vector) is “anchored” to the start position at Q2. For example, in the mouse’s perspective, the target vector is equivalent to going forward for 70cm, and then turn left and follow for another 30cm. If in a probe trial, we now let the mouse enter from Q4 instead, there are two options: either the mouse uses the landmarks and searches for the food in Q1 (where the food actually used to be), or it follows the target vector (70cm forward + 30cm left) and goes to the REL location of the target in Q3. Following the target vector is a sign of path integration using self-motion signals (idiothetic cues).</p>
</sec>
<sec id="s7e">
<title>Control Experiments</title>
<sec id="s7e1">
<title>Rotations following Static Entrances – with and without visual cues</title>
<p>We performed additional tests for the use of visual landmarks in the Visual Cues + Static Entrance protocol. Well-trained mice had their home cages rotated to another quadrant and tested on how well they found the food from a new starting location. Mice were rotated 180°, 90°, and then -90° with respect to their original location (<xref rid="fig5" ref-type="fig">Fig. 5A,B,C</xref>). Mice were given 6 consecutive trials at each new location. One control group of mice had the visual cues on the arena wall removed during rotation training. If mice were able to use visual cues, we would expect them to improve their search efficiency when visual cues were available. Lack of improvement or similar performance compared to the control group without visual cues suggests that the mice do not rely on the type of visual cues we provided for spatial learning and navigation.</p>
</sec>
<sec id="s7e2">
<title>Navigating and Training without visual cues and in Darkness</title>
<p>To control for the effects of all visual information, one cohort (4 mice) was trained and tested without any cues (Fig. S6A,B). A second cohort (4 mice) was trained in the light according to the Visual Cues + Static Entrance protocol, then the lights are turned off and the mice are given a trial in darkness (Fig. S6C,D). The lights were opened in between trials so the mice did not acclimatize to the darkness. Mice were tracked using infrared LEDs with emission spectra detected by our camera. The following conditions were tested: darkness during a regular trial with food present in the arena and during a probe trial where there is no food present in the arena; both conditions gave the same results.</p>
<p>We additionally both trained and tested a cohort (4 mice) in darkness and with control of potential odors. A recent study has shown that placing sighted mice in darkness impairs entorhinal cortex head direction cell tuning(<xref ref-type="bibr" rid="c19">19</xref>), but here the mice successfully learned to find food and with the same time course of learning (Fig. S6E,F).</p>
</sec>
<sec id="s7e3">
<title>Two Food Location Training</title>
<p>This protocol aims to test flexibility of spatial learning using only path integration (N=8 mice). No visual cues are placed on the arena walls. Mice entered the arena from the same entrance each trial. Food was placed in a target well in “Target A” and mice were trained to find this location for 18 trials, 3 trials a day. A probe trial (“Probe A”) was done after trial 18. For trials 19-26, the food was moved to a different location, “Target B”, and mice are trained to find the new location. We were careful to choose Target B so that Target A and B were not symmetric with respect to the mouse’s entrance. A second probe trial (“Probe B-A”) was done after trial 26. The purpose of the “Probe B-A” trial is to check whether mice take a shortcut between B (latest learned target position) and A (first learned target position). For some cohorts, the training continued until trial 34 and a third probe was given.</p>
</sec>
<sec id="s7e4">
<title>Two Food Location Training with rotated probe</title>
<p>The mice (N=8) were trained exactly as in the “Two food location” experiment described above. However, the mice start location was rotated by 180° prior to the second probe trial. This protocol joins the “Static entrances with rotated probe” protocol with the “Two food location protocol”, and is designed to provide further support for our path integration hypothesis. Each of the trained targets have their REL counterparts (180° rotated around the center of the arena). Now, the purpose of the rotated “Probe B-A” trial is to check which of the two options will happen: either mice take shortcuts between B (latest learned target position) and A (first learned target position); or they take shortcuts between REL B and REL A, supporting path integration via self-motion cues.</p>
</sec>
</sec>
<sec id="s7f">
<title>Behavioural Analysis</title>
<p>Path tracking was done with Ethovision XT15 (Noldus) based on contrast detection. Mice were tracked according to 3 body points at 30 frames per second on a 1080P USB camera with OV2710 CMOS. Videos were first recorded on AMCap webcam recording software and imported into Ethovision in order to preserve high quality videos. Trajectory plotting was done in Python.</p>
<p>Latency to target was calculated from when the nose point of the mouse enters the arena until the nose of the mouse enters the target hole. Trajectory analyses are based on the nose point sequence of the mouse. Speed and distance were calculated based on trajectory coordinates exported from Ethovision.</p>
<p>Search bias during probe trials is calculated by totalling the time a mouse spent within a 30×30cm square centered around the target vs. the RELs in the other 3 quadrants during a 2-minute trial (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, <xref rid="fig3" ref-type="fig">Fig. 3C</xref>).</p>
</sec>
<sec id="s7g">
<title>Statistical Tests</title>
<p>Significance testing was conducted in a manner that was appropriate for each dataset. Paired comparisons utilized the t-test for parametric data and the Wilcoxon signed-rank test for non-parametric data. The significance cut-off was set at 0.05. Statistics were calculated either using R (URL <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/">http://www.R-project.org/</ext-link>) or scipy 1.8.0 in python 3.8.2. The statistical significance testing of the trajectory directionality analysis was developed from first principles, since it involves angular variables (the direction of each vector). It is presented in the “Analysis of Trajectories” section ahead.</p>
<p>Figures showing a quantity evolution over trials [<xref rid="fig2" ref-type="fig">Fig. 2D-I</xref>; <xref rid="fig3" ref-type="fig">Fig. 3D-I</xref>; <xref rid="fig4" ref-type="fig">Fig. 4I</xref>; Fig. S4; Fig. S7E; Fig. S10A,B] have symbols as averages, error bars as standard error, and the shading around the curve corresponds to the full data range (lower and upper shading limits correspond to minimum and maximum sampled data points, respectively).</p>
<p>Boxplot figures [<xref rid="fig4" ref-type="fig">Fig. 4J,K</xref>; <xref rid="fig6" ref-type="fig">Fig. 6E-H</xref>; <xref rid="fig7" ref-type="fig">Fig. 7I,J</xref>; Fig. S7L] have the diamond symbol as the average, the thick black line as the median, the box covering the interquartile range (IQR), and the whiskers extend from the box limits to ± 1.5IQR in both directions. No outliers were detected in any of these plots.</p>
</sec>
<sec id="s7h">
<title>Randomized trials</title>
<p>For the Two Food Location experiment, we calculated a randomized version of the Probe B-A trial for comparison. It consisted of extracting ten random pieces of the trajectory. Each piece was defined by randomly selecting a pair of points in the trial trajectory that are separated by the B to A distance. Then, the particular quantity of interest was averaged over each piece of the trajectory, and these averages were then averaged to obtain a single value for the “Probe B-A Rand.” condition in <xref rid="fig6" ref-type="fig">Figs. 6</xref> and <xref rid="fig7" ref-type="fig">7</xref>. See Fig. S8 for a definition of the quantities.</p>
</sec>
<sec id="s7i">
<title>Statistical Analysis of Trajectories</title>
<sec id="s7i1">
<title>Experiment Alignment</title>
<p>The procedure described in this section is applied to calculate trajectory directionality (and hence the target estimation vector, TEV) and the hole checking spatial distributions. Each mouse in the Random Entrance experiment started from a different quadrant of the arena, for each consecutive trial, and the target was fixed relative to the arena (global reference frame). However, in order to increase sampling, we need to coherently align the mice entrances, generating the mouse’s perspective reference frame (see Fig. S1B-F). Each experiment batch was performed with four mice, such that at any given trial, a given mouse entered from quadrant 1 [Fig. S1C], another entered from quadrant 2 [Fig. S1D], the next entered from quadrant 3 [Fig. S1E], and the last entered the arena from quadrant 4 [Fig. S1F]. Most of the experiments, then, consisted of two different batches of four mice that had to be conveniently aligned to increase sampling. In this figure, we aligned all the entrances to the Start point at the top of the arena (trajectories were rotated accordingly), emphasizing the four possible positions of the target from the mouse’s perspective.</p>
<p>We had to find a way to align all the targets in a given trial to one of the four possible positions, such that the experiment stays coherent over trials (i.e., the target randomly switches in between these four positions from trial to trial). For example, in Fig. S1B-F, we show trial 14. The target position for each starting quadrant is labeled with a red letter A and a red circle, whereas the target for the previous trial is labeled with a green circle and a green letter A subscripted with “trial 13”. These two positions (trial and previous trial) must always be different to keep the random characteristic of the experiment.</p>
<p>Notice that the target positions in each of the panels D, E and F in Fig. S1 are simply rotated relative to the target positions in panel C. The target configuration in panel D is 90° clock-wise rotated relative to the target configuration in panel C. The configuration in panel E is 180° clockwise rotated, and panel F, 270° clockwise rotated; both angles are relative to the configuration in panel C. Thus, in order to sample all the mice together, we simply rotate the trajectories from the mice that started in quadrant 2 [panel D] counter-clockwise by 90°; the trajectories from the mice that started in quadrant 3 [panel E] are rotated by 180° counter-clockwise; and the trajectories starting from quadrant 4 [panel F] are rotated by 270° counter-clockwise. This reduces all the experiments to the first quadrant, allowing us to sample all the trajectories of all the mice together in each individual trial.</p>
</sec>
<sec id="s7i2">
<title>Active sensing and hole-check detection</title>
<p>We developed an algorithm to detect the mouse’s behavior of sniffing holes to detect food as a measure of active sensing. The hole checking events are used to infer the mouse’s memory and uncertainty about its environment. The procedure described here is applied independently to each trial. We compute the spatial distribution 𝒫(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) for the count of hole checks for each hole <italic>i</italic> positioned in (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) in the arena, accumulated across all mice in a given experiment (<xref rid="fig4" ref-type="fig">Fig. 4C,D,G,H</xref>; <xref rid="fig5" ref-type="fig">Fig. 5C</xref>; <xref rid="fig7" ref-type="fig">Fig. 7B,E,F,H</xref>; <xref rid="fig8" ref-type="fig">Fig. 8C</xref>; and Fig. S1B-F; usually N=8 mice for each experiment), and normalized by the total count. The frequency of checks in each hole is coded both in the color and size of the filled circles: larger and darker shaded circles correspond to larger number of checks in that particular hole (lighter shaded pink small circles are a small number of checks). The black ellipsis marks the covariance of the 𝒫(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) spatial distribution (“x” in the figures marking the mean position of hole checks). It is constructed from the eigenvalues and eigenvectors of the covariance matrix <italic>C</italic> of the hole check coordinates (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) weighted by 𝒫(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>): the eigenvectors give the directions of the ellipsis semi-axes, whereas the eigenvalues give the width of each semi-axes. The center of the ellipsis (mean of the ellipsis’ foci) is aligned with the mean of the spatial distribution.</p>
<p>Under the path integration hypothesis, it is expected that error accumulates as the mouse walks(<xref ref-type="bibr" rid="c15">15</xref>). This is consistent with the increase in number of hole checks per unit area near the target (<xref rid="fig4" ref-type="fig">Fig. 4J,K</xref>; “near”=less than 20cm away from the target). We consider that the change in number of hole checks measures the variability of the mouse’s estimate of the target position.</p>
<p>We therefore calculate the mean and covariance of the distribution of hole check events restricted to within 20cm of the target (again, the green “x”=mean). The distance from the start to this restricted mean is used to scale the TEV vector (see Target Estimation Vector).</p>
<p>The arena design forces the mouse to put its nose very close to the hole to be able to see the food or detect any food odour. With that in mind, we defined two methods for detecting a hole check (see Fig. S2A,B, and the Shortcut video (Video 1)). The two methods are complementary, and the second can find hole-check events missed by the first method: we apply the first method, then perform a visual check on the data to see if there were potential hole-checks that were missed. Then, we apply the second method to capture any remaining events.</p>
<p>The first method is the minimum velocity criterion and provides a high threshold for hole check identification. Four conditions must be satisfied simultaneously to detect an event: (i) the nose of the mouse must be within 3 cm of an arena hole; (ii) the velocity has to be less than 20% its maximum value; (iii) the velocity must be at a minimum; and (iv) the velocity has to have dropped by at least 5 cm/s to reach that minimum.</p>
<p>The second method is more inclusive and defines a hole-checking event by a simple slowing down event, provided that: the nose is within 3 cm of an arena hole, and the slowing down is enough for the velocity to drop past the 20% threshold of its maximum.</p>
<p>The detected events by the application of these two methods in sequence are marked for all trajectory samples of the Probe B-A in Fig. S8B as examples. A particular case is shown in more details in Fig. S2, and in the Shortcut video (Video 1) with the recording of a mouse’s performance. It is worth mentioning, there is a clear hole-check missed by our algorithm in the 25 to 27 second range. This is because the velocity of the mouse was already below the 20% maximum before and after the hole check, hence the two sets of criteria defined above were not met for this particular event and it was counted by the manual check. Otherwise, we clearly see that all the other events are captured by sequential use our two methods.</p>
</sec>
<sec id="s7i3">
<title>Trajectory directionality (displacement map)</title>
<p>This analysis is a way to visualize mouse trajectories and directionality across all the mice for each trial. It is related to a velocity map of the arena, except that here, the arrows point in the direction of most probable movement instead of the direction of the velocity. Fig. S2B shows a scheme for how we compute this map, and we detail it below. We call this quantity as the “displacement map”, since it gives the displacement of the mouse for each position in the arena. In this section, we explain how to calculate the displacement map for a single sample of <italic>N</italic> mice. The procedure here is applied to each individual trial independently (either during learning, or for a probe trial). This map is used for inferring the learned directionality of the target (relative to entrance). The error, average and significance of this quantity is estimated from first principles by a jackknife procedure explained in the next section. In the figures we show the average displacement map vectors that were found to be significant. These maps are then used to compute the target estimation vector (TEV; detailed in the last section).</p>
<p>We start by overlaying a lattice of size <italic>L</italic> on top of the arena recording. This means that there are <italic>L</italic> boxes on the <italic>x</italic> (horizontal) direction, and <italic>L</italic> boxes on the <italic>y</italic> (vertical) direction, making a total of <italic>L</italic><sup>2</sup> boxes in the lattice. Each box defines a lattice site with coordinates (<italic>x, y</italic>), such that <italic>x</italic> and <italic>y</italic> are integers between 1 and <italic>L</italic>. Each mouse corresponds to an independent observation of a trajectory, so we overlay all mice trajectories for each trial separately in the calculations below. Next, we map the coordinates of the trajectories into the lattice coordinates in order to obtain a temporal sequence of visited lattice sites in each trial. We are interested in counting the number of times that each subsequent pair of adjacent lattice sites appears in this sequence, regardless of what mouse it came from. This will be used to define the displacement map, detailed in what follows.</p>
<p>The displacement map <inline-formula><inline-graphic xlink:href="529984v6_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a vector field defined on the lattice that assigns to each site the preferential direction of movement. This direction is estimated from the trajectories data. Mathematically, it can be written as <inline-formula><inline-graphic xlink:href="529984v6_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where <italic>M</italic><sub><italic>h</italic></sub> is the horizontal component and <italic>M</italic><sub><italic>v</italic></sub> is the vertical component. The horizontal component expresses the trend to move to the left or right (along the lattice <italic>x</italic>-axis), and the vertical component in the perpendicular direction, <italic>i</italic>.<italic>e</italic>., “up” or “down” in the top view of the lattice of Fig. S2D (along the lattice <italic>y</italic>-axis). Each component is a function of the lattice coordinates, (<italic>x, y</italic>). The vector <inline-formula><inline-graphic xlink:href="529984v6_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is defined as the spatial gradient of the probabilities to move out of (<italic>x, y</italic>) towards one of its adjacent sites. Thus, its components are given by
<disp-formula id="eqn1">
<graphic xlink:href="529984v6_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>P</italic><sub>→</sub>(<italic>x, y</italic>) is the probability of stepping right, <italic>i</italic>.<italic>e</italic>., from (<italic>x, y</italic>) to (<italic>x</italic> + 1, <italic>y</italic>); <italic>P</italic><sub>←</sub>(<italic>x, y</italic>) is the probability of stepping left [from (<italic>x, y</italic>) to (<italic>x</italic> − 1, <italic>y</italic>) ]; <italic>P</italic><sub>↑</sub>(<italic>x, y</italic>) is the probability of stepping up [from (<italic>x, y</italic>) to (<italic>x, y</italic> + 1)]; and <italic>P</italic><sub>↓</sub>(<italic>x, y</italic>) is the probability of stepping down [from (<italic>x, y</italic>) to (<italic>x, y</italic> − 1)]. The probabilities of stepping out of (<italic>x, y</italic>) must be normalized, therefore <italic>P</italic><sub>→</sub>(<italic>x, y</italic>) + <italic>P</italic><sub>←</sub>(<italic>x, y</italic>) + <italic>P</italic><sub>↑</sub>(<italic>x, y</italic>) + <italic>P</italic><sub>↓</sub>(<italic>x, y</italic>) = 1. If there is no trajectory going through a particular site, the probability of going from that site into each of the directions is equal to the “null” probability, <italic>P</italic><sub>1</sub> = 1/4. Time sequences where the mouse does not move are ignored, since we are only interested in the movement between adjacent sites.</p>
<p>The stepping-out probabilities are computed from the mouse trajectory in the following way. This procedure is applied to all mice overlayed together in each individual trial. First, a step is defined as moving from a box at (<italic>x, y</italic>) to one of its four adjacent boxes, say the one on the right (<italic>x</italic> + 1, <italic>y</italic>). Now, if we wanted to calculate the probability of going right from a position (<italic>x, y</italic>), we need to go through the sequence of visited lattice sites looking for (<italic>x, y</italic>) in an instant followed by (<italic>x</italic> + 1, <italic>y</italic>) in the immediately next instant. We count the number of times <italic>S</italic><sub>→</sub>(<italic>x, y</italic>) that this pair appears. The count of the transitions of (<italic>x, y</italic>) to (<italic>x</italic> + 1, <italic>y</italic>), in this example, is made regardless of when these transitions happened during the trajectory. The only condition is that the position (<italic>x, y</italic>) must be immediately followed by (<italic>x</italic> + 1, <italic>y</italic>). The same counting is made for the transitions from (<italic>x, y</italic>) to (<italic>x</italic> − 1, <italic>y</italic>) and stored in <italic>S</italic><sub>←</sub>(<italic>x, y</italic>), from (<italic>x, y</italic>) to (<italic>x, y</italic> + 1) in <italic>S</italic><sub>↑</sub>(<italic>x, y</italic>), and from (<italic>x, y</italic>) to (<italic>x, y</italic> − 1) in <italic>S</italic><sub>↓</sub>(<italic>x, y</italic>).</p>
<p>With these sums of steps performed, we can calculate the probability of stepping right, left, up or down. First, note that initially the chance of going to any direction is <italic>P</italic><sub>1</sub>, assuming we know nothing about the trajectories. Now, given that we observed <italic>S</italic><sub>→</sub>(<italic>x, y</italic>) steps going to the right, we need to update the chance of going to the right using the union (i.e. sum) of the observed chance <italic>S</italic><sub>→</sub>(<italic>x, y</italic>)/<italic>n</italic><sub>2</sub> with <italic>P</italic><sub>1</sub>, where <italic>n</italic><sub>2</sub> is the total number of steps counted toward any direction in all lattice sites in a given trial:
<disp-formula id="eqn2">
<graphic xlink:href="529984v6_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>W</italic><sub>→</sub>(<italic>x, y</italic>) is the direction weight of the action “step to the right from (<italic>x, y</italic>)”. Alternatively, this can be written as a weighted sum of memory-driven stepping with probability 1 and random stepping with probability <italic>P</italic><sub>1</sub>:
<disp-formula id="ueqn3">
<graphic xlink:href="529984v6_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We employ <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref> because the mouse could, in principle, have chosen any of the other three directions. This ensures that every time the memory is increased (adding <italic>S</italic><sub>→</sub>/<italic>n</italic><sub><italic>s</italic></sub> to the weight), the random contribution for that step decreases; this justifies the last term in <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref>, where the intersection between the memory term and the “null” probability, <italic>S</italic><sub>→</sub><italic>P</italic><sub>1</sub>/<italic>n</italic><sub><italic>s</italic></sub>, is subtracted from the aforementioned union. One can easily see that the formula guarantees that the null probability is automatically recovered, <italic>i</italic>.<italic>e. W</italic><sub>→</sub>(<italic>x, y</italic>) = <italic>P</italic><sub><italic>o</italic></sub>, when there are zero observed steps in a given direction at position (<italic>x, y</italic>), and that <italic>W</italic><sub>→</sub>(<italic>x, y</italic>) = 1 if all steps are to the right at position (<italic>x, y</italic>).</p>
<p>Finally, we use these weights to calculate the probabilities, first defining the total weight of stepping out of (<italic>x, y</italic>),
<disp-formula id="eqn3">
<graphic xlink:href="529984v6_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and then calculating the probabilities by
<disp-formula id="eqn4">
<graphic xlink:href="529984v6_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The same is made for the other directions (left, up and down). Equation (<xref ref-type="bibr" rid="c4">4</xref>) ensures that the probability of stepping out of (<italic>x, y</italic>) is always normalized. This is then applied to <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> to obtain the displacement map.</p>
<p>Let us go through the simple example shown in Fig. S2C-F. In this case, the accumulated trajectories in the center box located at (<italic>x, y</italic>) = (<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) are such that there are two passes going up and one pass going down. Thus, each direction has the following weight [given by <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref>]: <inline-formula><inline-graphic xlink:href="529984v6_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p>Applying <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref>, we obtain the probabilities <italic>P</italic><sub>↑</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) ≈ 0.43, <italic>P</italic><sub>↓</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) ≈ 0.29, and <italic>P</italic><sub>→</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) = <italic>P</italic><sub>←</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) ≈ 0.14. This results in a step map vector <inline-formula><inline-graphic xlink:href="529984v6_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. This vector represents the preferred direction of movement out of site (<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>), meaning the mice are likely to pass in the vertical direction, going from bottom to top (hence a positive vertical quantity); and are not picky regarding left or right (hence a null horizontal quantity).</p>
<p>The trajectories of the mice obey box-scaling independently of trial or experimental condition. Box-scaling is a standard method to measure the dimensionality of curves, and is described in Falconer(<xref ref-type="bibr" rid="c80">80</xref>). In other words, the number of boxes needed to cover any trajectory scales linearly with the lattice dimension <italic>L</italic>; see Fig. S2F. This means that the choice of <italic>L</italic> is somewhat arbitrary, and we chose <italic>L</italic> = 11 to make each box the size of a few centimeters as expected for the size of a place field from a DG cell (<xref ref-type="bibr" rid="c81">81</xref>).</p>
</sec>
<sec id="s7i4">
<title>Trajectory directionality statistical significance</title>
<p>The method above gives a single displacement map <inline-formula><inline-graphic xlink:href="529984v6_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and enables the calculation of the TEV <inline-formula><inline-graphic xlink:href="529984v6_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (see below) for each trial of an experiment containing <italic>N</italic> mice. We have to generate multiple samples for the same experiment using different mice to estimate the significance of the mean displacement direction calculation. We employ a jackknife procedure to achieve this goal. It consists of the “leave one out” rule: this means that a sample of <italic>N</italic> mice give <italic>N</italic> unique jackknife samples, each of which containing <italic>N</italic> − 1 unique mice. Then, we get <italic>N</italic> estimates <inline-formula><inline-graphic xlink:href="529984v6_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with <italic>k</italic> from 1 to <italic>N</italic>, by applying the previously described procedure to each jackknife sample of <italic>N</italic> − 1 mice (instead of the whole sample). Finally, we calculate the average, <inline-formula><inline-graphic xlink:href="529984v6_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for the displacement map. This is the vector map that we show as small arrows colored from blue to red (<xref rid="fig4" ref-type="fig">Fig. 4A,B,E,F</xref>; <xref rid="fig5" ref-type="fig">Fig. 5C</xref>; <xref rid="fig7" ref-type="fig">Fig. 7A,C,D,G</xref>; <xref rid="fig8" ref-type="fig">Fig. 8C</xref>; and Fig. S7; we only show statistically significant averages).</p>
<p>The statistical significance of the average <inline-formula><inline-graphic xlink:href="529984v6_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> map in each lattice position (<italic>x, y</italic>) is built from first principles as follows (see Fig. S3). The main feature of each of the vectors in this map is its direction (<italic>i</italic>.<italic>e</italic>., the angle it makes with the positive x-axis). Strong directionality means that the vectors <inline-formula><inline-graphic xlink:href="529984v6_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula> all pointed roughly in the same direction (<italic>i</italic>.<italic>e</italic>., roughly same angles), whereas weak directionality means uniformly distributed angles around the circle (Fig. S3A,B). The stronger the directionality of the sample <inline-formula><inline-graphic xlink:href="529984v6_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula> the more significant the average <inline-formula><inline-graphic xlink:href="529984v6_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. A simple measure of the spread of the angles (<italic>i</italic>.<italic>e</italic>., the directionality strength) is the standard deviation (S.D.) of the sample angles that <inline-formula><inline-graphic xlink:href="529984v6_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula> make with the positive x-axis: stronger directionality implies a smaller S.D. (Fig. S3C). Thus, the significance (<italic>p</italic>) of directionality is how likely it is for a sample of <italic>N</italic> uniformly distributed angles to display a given S.D. value collectively.</p>
<p>The S.D. of <italic>N</italic> angles (with zero average) is <inline-formula><inline-graphic xlink:href="529984v6_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where the <italic>θ</italic><sub><italic>k</italic></sub> are uniformly distributed from -180° to 180°. If we could determine the probability density function <italic>ρ</italic>(<italic>σ</italic>), then the significance would be given by (<xref ref-type="bibr" rid="c82">82</xref>)<inline-formula><inline-graphic xlink:href="529984v6_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which is the probability of observing a given S.D. from the sample. In other words, <italic>p</italic>(<italic>S. D</italic>.) is the probability that an observed S.D. came from a set of <italic>N</italic> uniformly distributed angles with zero mean. Thus, given an experimental observation S.D. from the jackknife sample, we will know what is the probability <italic>p</italic> that the angles from the sample were uniformly distributed in the circle (<italic>i</italic>.<italic>e</italic>., have weak directionality). A small <italic>p</italic> value, therefore, indicates strong directionality (since having small S.D. is very unlikely for uniformly distributed angles – Fig. S3D).</p>
<p>We need to estimate <italic>ρ</italic>(<italic>σ</italic>) to be able to calculate <italic>p</italic> for any S.D. Although it has an integral representation similar to the Chi distribution(<xref ref-type="bibr" rid="c83">83</xref>), it is easier to make a numerical estimation: we fix, for instance, <italic>N</italic> = 8 (since we have 8 jackknife samples) and generate 10,000 independent <italic>σ</italic> values applying the S.D. formula above to <italic>N</italic> independent uniform angles <italic>θ</italic><sub><italic>k</italic></sub> from -180° to 180°.</p>
<p>The normalized histogram of all the observed <italic>σ</italic> is a good estimate of <italic>ρ</italic>(<italic>σ</italic>) (Fig. S3D). The <italic>p</italic> value is obtained by numerically integrating <italic>ρ</italic>(<italic>σ</italic>) from 0 to the observed S.D. value (Fig. S3E).</p>
<p>Now, it suffices to calculate the S.D. of the angles of the vectors <inline-formula><inline-graphic xlink:href="529984v6_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in the jackknife sample (unbiased to make the average vector <inline-formula><inline-graphic xlink:href="529984v6_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula> have <italic>θ</italic> = 0<sup>∘</sup>). An observed <italic>S</italic>.<italic>D</italic>.=30° corresponds to <italic>p</italic>=10<sup>−4</sup> (i.e., the sample has very strong directionality). We only show in the figures the displacement vectors that have <italic>S</italic>.<italic>D</italic>.≤5°, yielding vanishing <italic>p</italic>&lt;10<sup>−7</sup> (all vectors regardless of significance are shown in Fig. S7 for comparison for random and static entrance experiments). Comparing Fig. S7 to <xref rid="fig4" ref-type="fig">Fig. 4</xref>, we notice that, as expected, only vectors from trials that are supposed to have random directionality vanish (i.e., trials for random entrance experiments, and trial 1 for static entrance). The vectors in strongly directed flow trials (such as trial 14 in static entrance experiments) remain. The same happens for the two-food location experiment.</p>
</sec>
<sec id="s7i5">
<title>Target Estimation Vector (TEV)</title>
<p>The target estimation vector (TEV) is an estimate of the position of the target based only on the observed trajectories and hole checks of the mice. We write the average TEV as<inline-formula><inline-graphic xlink:href="529984v6_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="529984v6_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the TEV for a particular jackknife sample <italic>k</italic>. The magnitude <italic>D</italic> is inferred from the hole checks and the direction <italic>û</italic><sub><italic>k</italic></sub> is calculated from the displacement map <inline-formula><inline-graphic xlink:href="529984v6_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula> as follows. The total sum of the displacement map <inline-formula><inline-graphic xlink:href="529984v6_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula> over all arena sites (<italic>x, y</italic>) gives the estimate of the learned direction <inline-formula><inline-graphic xlink:href="529984v6_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="529984v6_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The magnitude <italic>D</italic> is the distance from start to the average of the hole check distribution restricted to 20cm around the target (<italic>i</italic>.<italic>e</italic>., <italic>D</italic> is the distance from the start to the “x” in the green ellipsis in <xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>; <xref rid="fig5" ref-type="fig">Fig. 5C</xref>; <xref rid="fig7" ref-type="fig">Fig. 7B,F,H</xref>; <xref rid="fig8" ref-type="fig">Fig. 8C</xref>; and Fig. S1B-F). In the case of the Probe B-A trial, we use <italic>D</italic> as the distance from B (instead of “start”) to the restricted average of the hole check distribution around target A. In trials where no preferred direction is detected (such as in the random entrances experiment, or in the first trial after switching from target A to B), the magnitude <inline-formula><inline-graphic xlink:href="529984v6_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is already roughly the distance from start to the arena’s center (expressing the randomness in the displacement map), and hence we take the TEV to be just <inline-formula><inline-graphic xlink:href="529984v6_inline27.gif" mime-subtype="gif" mimetype="image"/></inline-formula> instead.</p>
<p>The error in the magnitude <italic>D</italic> of the TEV is obtained from the covariance matrix <italic>C</italic>of the spatial distribution of hole checks restricted to less than 20cm of the target. It is given by <inline-formula><inline-graphic xlink:href="529984v6_inline28.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where <italic>λ</italic><sub>1,2</sub> are the eigenvalues of <italic>C</italic>. In the plots [<xref rid="fig4" ref-type="fig">Figs. 4</xref>, <xref rid="fig5" ref-type="fig">5</xref>, <xref rid="fig7" ref-type="fig">7</xref>, <xref rid="fig8" ref-type="fig">8</xref>], we simply represent the covariance matrix by the green ellipses in the same way we do for the uncensored distribution (see Active sensing and hole-check detection). The error in the direction of <inline-formula><inline-graphic xlink:href="529984v6_inline29.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is simply the S.D. of the angles of <inline-formula><inline-graphic xlink:href="529984v6_inline30.gif" mime-subtype="gif" mimetype="image"/></inline-formula> with respect to the positive x-axis (calculated by shifting <inline-formula><inline-graphic xlink:href="529984v6_inline31.gif" mime-subtype="gif" mimetype="image"/></inline-formula> to 0°, and making the angles of <inline-formula><inline-graphic xlink:href="529984v6_inline32.gif" mime-subtype="gif" mimetype="image"/></inline-formula> between -180° and 180°, similarly to what is done for the displacement map). This gives the pink shaded circular sector accompanying the TEV in the figures of the displacement maps and the error bars in the TEV-target deviation plot (<xref rid="fig4" ref-type="fig">Figs. 4I</xref> and <xref rid="fig7" ref-type="fig">7I</xref>).</p>
</sec>
</sec>
</sec>
<sec id="s8">
<title>Data Availability</title>
<p>All codes and data are available in <ext-link ext-link-type="uri" xlink:href="https://github.com/neuro-physics/mouse-cogmap">https://github.com/neuro-physics/mouse-cogmap</ext-link></p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Rosenberg</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Perona</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Meister</surname></string-name></person-group>, <article-title>Mice in a labyrinth show rapid learning, sudden insight, and efficient exploration</article-title>. <source>eLife</source> <volume>10</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Chan</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Baumann</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Bellgrove</surname></string-name>, <string-name><given-names>J. B.</given-names> <surname>Mattingley</surname></string-name></person-group>, <article-title>From objects to landmarks: the function of visual location information in spatial navigation</article-title>. <source>Frontiers in psychology</source> <volume>3</volume>, <fpage>304</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Goodman</surname></string-name></person-group>, <article-title>Place vs. Response Learning: History, Controversy, and Neurobiology</article-title>. <source>Front Behav Neurosci</source> <volume>14</volume>, <fpage>598570</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Nyberg</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Duvelle</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>H. J.</given-names> <surname>Spiers</surname></string-name></person-group>, <article-title>Spatial goal coding in the hippocampal formation</article-title>. <source>Neuron</source> <volume>110</volume>, <fpage>394</fpage>–<lpage>422</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. C.</given-names> <surname>Tolman</surname></string-name>, <string-name><given-names>B. F.</given-names> <surname>Ritchie</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kalish</surname></string-name></person-group>, <article-title>Studies in spatial learning; place learning versus response learning</article-title>. <source>J Exp Psychol</source> <volume>36</volume>, <fpage>221</fpage>–<lpage>229</lpage> (<year>1946</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. S.</given-names> <surname>Collett</surname></string-name>, <string-name><given-names>B. A.</given-names> <surname>Cartwright</surname></string-name>, <string-name><given-names>B. A.</given-names> <surname>Smith</surname></string-name></person-group>, <article-title>Landmark learning and visuo-spatial memories in gerbils</article-title>. <source>J Comp Physiol A</source> <volume>158</volume>, <fpage>835</fpage>–<lpage>851</lpage> (<year>1986</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. G. M.</given-names> <surname>Morris</surname></string-name></person-group>, <article-title>Spatial Localization Does Not Require the Presence of Local Cues</article-title>. <source>LEARNING AND MOTIVATION</source> <volume>12</volume>, <fpage>239</fpage>–<lpage>260</lpage> (<year>1981</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name>, <string-name><given-names>C. A.</given-names> <surname>Barnes</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Gerrard</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Gothard</surname></string-name>, <string-name><given-names>M. W.</given-names> <surname>Jung</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Kudrimoti</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Qin</surname></string-name>, <string-name><given-names>W. E.</given-names> <surname>Skaggs</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Suster</surname></string-name>, <string-name><given-names>K. L.</given-names> <surname>Weaver</surname></string-name></person-group>, <article-title>Deciphering the hippocampal polyglot: the hippocampus as a path integration system</article-title>. <source>J Exp Biol</source> <volume>199</volume>, <fpage>173</fpage>–<lpage>185</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Mittelstaedt</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Mittelstaedt</surname></string-name></person-group>, <article-title>Homing by path integration in a mammal</article-title>. <source>Naturwissenschaften</source> <volume>67</volume>, <fpage>566</fpage>–<lpage>567</lpage> (<year>1980</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name></person-group>, <article-title>Spatial memory: how egocentric and allocentric combine</article-title>. <source>Trends Cogn Sci</source> <volume>10</volume>, <fpage>551</fpage>–<lpage>557</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>King</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name></person-group>, <article-title>How vision and movement combine in the hippocampal place code</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>110</volume>, <fpage>378</fpage>–<lpage>383</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <string-name><given-names>D. A.</given-names> <surname>Hamilton</surname></string-name></person-group>, <article-title>Framing spatial cognition: neural representations of proximal and distal frames of reference and their roles in navigation</article-title>. <source>Physiol Rev</source> <volume>91</volume>, <fpage>1245</fpage>–<lpage>1279</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. C.</given-names> <surname>Tolman</surname></string-name></person-group>, <article-title>Cognitive maps in rats and men</article-title>. <source>Psychological review</source> <volume>55</volume>, <fpage>189</fpage>–<lpage>208</lpage> (<year>1948</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. C.</given-names> <surname>Tolman</surname></string-name>, <string-name><given-names>B. F.</given-names> <surname>Ritchie</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kalish</surname></string-name></person-group>, <article-title>Studies in spatial learning: Orientation and the short-cut</article-title>. <source>J Exp Psychol</source> <volume>36</volume>, <fpage>13</fpage>–<lpage>24</lpage> (<year>1946</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name>, <string-name><given-names>F. P.</given-names> <surname>Battaglia</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Jensen</surname></string-name>, <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, <string-name><given-names>M. B.</given-names> <surname>Moser</surname></string-name></person-group>, <article-title>Path integration and the neural basis of the ‘cognitive map’</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>, <fpage>663</fpage>–<lpage>678</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Nadel</surname></string-name></person-group>, <source>The Hippocampus as a Cognitive Map</source> (<publisher-name>Oxford University Press</publisher-name>, <publisher-loc>Oxford, U.K</publisher-loc>., <year>1978</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Banino</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Uria</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Blundell</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Lillicrap</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Mirowski</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Pritzel</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Chadwick</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Degris</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Modayil</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Wayne</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Soyer</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Viola</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Goroshin</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Rabinowitz</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Pascanu</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Beattie</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Petersen</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Sadik</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gaffney</surname></string-name>, <string-name><given-names>H.</given-names> <surname>King</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Kavukcuoglu</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Hassabis</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Hadsell</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kumaran</surname></string-name></person-group>, <article-title>Vector-based navigation using grid-like representations in artificial agents</article-title>. <source>Nature</source> <volume>557</volume>, <fpage>429</fpage>–<lpage>433</lpage> (<year>2018</year>).</mixed-citation></ref>
 <ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Fonio</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Benjamini</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Golani</surname></string-name></person-group>, <article-title>Freedom of movement and the stability of its unfolding in free exploration of mice</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>106</volume>, <fpage>21335</fpage>–<lpage>21340</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Asumbisa</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Peyrache</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Trenholm</surname></string-name></person-group>, <article-title>Flexible cue anchoring strategies enable stable head direction coding in both sighted and blind animals</article-title>. <source>Nature communications</source> <volume>13</volume>, <fpage>5483</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W.</given-names> <surname>Fischler-Ruiz</surname></string-name>, <string-name><given-names>D. G.</given-names> <surname>Clark</surname></string-name>, <string-name><given-names>N. R.</given-names> <surname>Joshi</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Devi-Chou</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Kitch</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Schnitzer</surname></string-name>, <string-name><given-names>L. F.</given-names> <surname>Abbott</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Axel</surname></string-name></person-group>, <article-title>Olfactory landmarks and path integration converge to form a cognitive spatial map</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>4036</fpage>–<lpage>4049</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. D.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Aharoni</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Willers</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Ravassard</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Kees</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Vuong</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Popeney</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Arisaka</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name></person-group>, <article-title>Multisensory control of multimodal behavior: do the legs know what the tongue is doing?</article-title> <source>PLoS One</source> <volume>8</volume>, <fpage>e80465</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Busse</surname></string-name></person-group>, <article-title>Interactions between rodent visual and spatial systems during navigation</article-title>. <source>Nat Rev Neurosci</source> <volume>24</volume>, <fpage>487</fpage>–<lpage>501</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. L.</given-names> <surname>Jacobs</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Fridman</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Douglas</surname></string-name>, <string-name><given-names>N. M.</given-names> <surname>Alam</surname></string-name>, <string-name><given-names>P. E.</given-names> <surname>Latham</surname></string-name>, <string-name><given-names>G. T.</given-names> <surname>Prusky</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Nirenberg</surname></string-name></person-group>, <article-title>Ruling out and ruling in neural codes</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>106</volume>, <fpage>5936</fpage>–<lpage>5941</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Long</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Jiang</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Yao</surname></string-name></person-group>, <article-title>Contrast-dependent orientation discrimination in the mouse</article-title>. <source>Sci Rep</source> <volume>5</volume>, <fpage>15830</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. T.</given-names> <surname>Prusky</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Douglas</surname></string-name></person-group>, <article-title>Characterization of mouse cortical spatial vision</article-title>. <source>Vision Res</source> <volume>44</volume>, <fpage>3411</fpage>–<lpage>3418</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G. T.</given-names> <surname>Prusky</surname></string-name>, <string-name><given-names>P. W.</given-names> <surname>West</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Douglas</surname></string-name></person-group>, <article-title>Behavioral assessment of visual acuity in mice and rats</article-title>. <source>Vision Res</source> <volume>40</volume>, <fpage>2201</fpage>–<lpage>2209</lpage> (<year>2000</year>).</mixed-citation></ref>
 <ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name>, <string-name><given-names>E. M.</given-names> <surname>Diamanti</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Fournier</surname></string-name>, <string-name><given-names>K. D.</given-names> <surname>Harris</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Carandini</surname></string-name></person-group>, <article-title>Coherent encoding of subjective spatial position in visual cortex and hippocampus</article-title>. <source>Nature</source> <volume>562</volume>, <fpage>124</fpage>–<lpage>127</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>Chapillon</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Roullet</surname></string-name></person-group>, <article-title>Use of proximal and distal cues in place navigation by mice changes during ontogeny</article-title>. <source>Dev Psychobiol</source> <volume>29</volume>, <fpage>529</fpage>–<lpage>545</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Hebert</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Bulla</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Vivien</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Agin</surname></string-name></person-group>, <article-title>Are Distal and Proximal Visual Cues Equally Important during Spatial Learning in Mice? A Pilot Study of Overshadowing in the Spatial Domain</article-title>. <source>Front Behav Neurosci</source> <volume>11</volume>, <fpage>109</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Rogers</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Churilov</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Hannan</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Renoir</surname></string-name></person-group>, <article-title>Search strategy selection in the Morris water maze indicates allocentric map formation during learning that underpins spatial memory formation</article-title>. <source>Neurobiol Learn Mem</source> <volume>139</volume>, <fpage>37</fpage>–<lpage>49</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>I. A.</given-names> <surname>Youngstrom</surname></string-name>, <string-name><given-names>B. W.</given-names> <surname>Strowbridge</surname></string-name></person-group>, <article-title>Visual landmarks facilitate rodent spatial navigation in virtual reality environments</article-title>. <source>Learn Mem</source> <volume>19</volume>, <fpage>84</fpage>–<lpage>90</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Biegler</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Morris</surname></string-name></person-group>, <article-title>Landmark stability: studies exploring whether the perceived stability of the environment influences spatial representation</article-title>. <source>J Exp Biol</source> <volume>199</volume>, <fpage>187</fpage>–<lpage>193</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Biegler</surname></string-name>, <string-name><given-names>R. G.</given-names> <surname>Morris</surname></string-name></person-group>, <article-title>Landmark stability is a prerequisite for spatial but not discrimination learning</article-title>. <source>Nature</source> <volume>361</volume>, <fpage>631</fpage>–<lpage>633</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Biegler</surname></string-name>, <string-name><given-names>R. G.</given-names> <surname>Morris</surname></string-name></person-group>, <article-title>Landmark stability: further studies pointing to a role in spatial learning</article-title>. <source>Q J Exp Psychol B</source> <volume>49</volume>, <fpage>307</fpage>–<lpage>345</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. J.</given-names> <surname>Jeffery</surname></string-name></person-group>, <article-title>Learning of landmark stability and instability by hippocampal place cells</article-title>. <source>Neuropharmacology</source> <volume>37</volume>, <fpage>677</fpage>–<lpage>687</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <string-name><given-names>H. S.</given-names> <surname>Kudrimoti</surname></string-name>, <string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name></person-group>, <article-title>Place cells, head direction cells, and the learning of landmark stability</article-title>. <source>J Neurosci</source> <volume>15</volume>, <fpage>1648</fpage>–<lpage>1659</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Save</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Nerad</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Poucet</surname></string-name></person-group>, <article-title>Contribution of multiple sensory information to place field stability in hippocampal place cells</article-title>. <source>Hippocampus</source> <volume>10</volume>, <fpage>64</fpage>–<lpage>76</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Schonfeld</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Wiskott</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Manahan-Vaughan</surname></string-name></person-group>, <article-title>Spatial representations of place cells in darkness are supported by path integration and border information</article-title>. <source>Front Behav Neurosci</source> <volume>8</volume>, <fpage>222</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C. S.</given-names> <surname>Burlingham</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>Heeger</surname></string-name></person-group>, <article-title>Heading perception depends on time-varying evolution of optic flow</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>117</volume>, <fpage>33161</fpage>–<lpage>33169</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. A. B.</given-names> <surname>Horrocks</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Mareschal</surname></string-name>, <string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name></person-group>, <article-title>Walking humans and running mice: perception and neural encoding of optic flow during self-motion</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>378</volume>, <fpage>20210450</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.</given-names> <surname>Acharya</surname></string-name>, <string-name><given-names>Z. M.</given-names> <surname>Aghajan</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Vuong</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Moore</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name></person-group>, <article-title>Causal Influence of Visual Cues on Hippocampal Directional Selectivity</article-title>. <source>Cell</source> <volume>164</volume>, <fpage>197</fpage>–<lpage>207</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name></person-group>, <article-title>Two stream hypothesis of visual processing for navigation in mouse</article-title>. <source>Current Opinion in Neurobiology</source> <volume>64</volume>, <fpage>70</fpage>–<lpage>78</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. E.</given-names> <surname>Cullen</surname></string-name></person-group>, <article-title>Vestibular processing during natural self-motion: implications for perception and action</article-title>. <source>Nat Rev Neurosci</source> <volume>20</volume>, <fpage>346</fpage>–<lpage>363</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Mohammadi</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Carriot</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Mackrous</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Cullen</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Chacron</surname></string-name></person-group>, <article-title>Neural populations within macaque early vestibular pathways are adapted to encode natural self-motion</article-title>. <source>PLoS Biol</source> <volume>22</volume>, <fpage>e3002623</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. E.</given-names> <surname>Cullen</surname></string-name>, <string-name><given-names>J. S.</given-names> <surname>Taube</surname></string-name></person-group>, <article-title>Our sense of direction: progress, controversies and challenges</article-title>. <source>Nat Neurosci</source> <volume>20</volume>, <fpage>1465</fpage>–<lpage>1473</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. S.</given-names> <surname>Taube</surname></string-name></person-group>, <article-title>The head direction signal: origins and sensory-motor integration</article-title>. <source>Annu Rev Neurosci</source> <volume>30</volume>, <fpage>181</fpage>–<lpage>207</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Mao</surname></string-name>, <string-name><given-names>L. A.</given-names> <surname>Molina</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Bonin</surname></string-name>, <string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name></person-group>, <article-title>Vision and Locomotion Combine to Drive Path Integration Sequences in Mouse Retrosplenial Cortex</article-title>. <source>Curr Biol</source> <volume>30</volume>, <fpage>1680</fpage>–<lpage>1688 e1684</lpage> (<year>2020</year>).</mixed-citation></ref>
 <ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>X.</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Cacucci</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, <string-name><given-names>T. J.</given-names> <surname>Wills</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Chen</surname></string-name></person-group>, <article-title>Visual boundary cues suffice to anchor place and grid cells in virtual reality</article-title>. <source>Curr Biol</source> <volume>34</volume>, <fpage>2256</fpage>–<lpage>2264.e3</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Engelmann</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name></person-group>, <article-title>Linking active sensing and spatial learning in weakly electric fish</article-title>. <source>Curr Opin Neurobiol</source> <volume>71</volume>, <fpage>1</fpage>–<lpage>10</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. S.</given-names> <surname>Etienne</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Maurer</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Seguinot</surname></string-name></person-group>, <article-title>Path integration in mammals and its interaction with visual landmarks</article-title>. <source>J Exp Biol</source> <volume>199</volume>, <fpage>201</fpage>–<lpage>209</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. J.</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Longtin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name></person-group>, <article-title>Enhanced sensory sampling precedes self-initiated locomotion in an electric fish</article-title>. <source>J Exp Biol</source> <volume>217</volume>, <fpage>3615</fpage>–<lpage>3628</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. P.</given-names> <surname>Jayakumar</surname></string-name>, <string-name><given-names>M. S.</given-names> <surname>Madhav</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Savelli</surname></string-name>, <string-name><given-names>H. T.</given-names> <surname>Blair</surname></string-name>, <string-name><given-names>N. J.</given-names> <surname>Cowan</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name></person-group>, <article-title>Recalibration of path integration in hippocampal place cells</article-title>. <source>Nature</source> <volume>566</volume>, <fpage>533</fpage>–<lpage>537</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. S.</given-names> <surname>Madhav</surname></string-name>, <string-name><given-names>R. P.</given-names> <surname>Jayakumar</surname></string-name>, <string-name><given-names>B. Y.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>S. G.</given-names> <surname>Lashkari</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Wright</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Savelli</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <string-name><given-names>N. J.</given-names> <surname>Cowan</surname></string-name></person-group>, <article-title>Control and recalibration of path integration in place cells using optic flow</article-title>. <source>Nat Neurosci</source> <volume>27</volume>, <fpage>1599</fpage>–<lpage>1608</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. U.</given-names> <surname>Muller</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Kubie</surname></string-name></person-group>, <article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells</article-title>. <source>J Neurosci</source> <volume>7</volume>, <fpage>1951</fpage>–<lpage>1968</lpage> (<year>1987</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. T.</given-names> <surname>Lai</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Espinosa</surname></string-name>, <string-name><given-names>G. E.</given-names> <surname>Wink</surname></string-name>, <string-name><given-names>C. F.</given-names> <surname>Angeloni</surname></string-name>, <string-name><given-names>D. A.</given-names> <surname>Dombeck</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>MacIver</surname></string-name></person-group>, <article-title>A robotrodent interaction arena with adjustable spatial complexity for ethologically relevant behavioral studies</article-title>. <source>Cell Rep</source> <volume>43</volume>, <fpage>113671</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. S.</given-names> <surname>Etienne</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Jeffery</surname></string-name></person-group>, <article-title>Path integration in mammals</article-title>. <source>Hippocampus</source> <volume>14</volume>, <fpage>180</fpage>–<lpage>192</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. J.</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Longtin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name></person-group>, <article-title>Active sensing associated with spatial learning reveals memory-based attention in an electric fish</article-title>. <source>Journal of Neurophysiology</source> <volume>115</volume>, <fpage>2577</fpage>–<lpage>2592</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C.</given-names> <surname>Mirmiran</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Fraser</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name></person-group>, <article-title>Finding food in the dark: how trajectories of a gymnotiform fish change with spatial learning</article-title>. <source>J Exp Biol</source> <volume>225</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Harvey-Girard</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Longtin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name></person-group>, <article-title>A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations</article-title>. <source>eLife</source> <volume>7</volume>, <fpage>e36769</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.</given-names> <surname>Savelli</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name></person-group>, <article-title>Origin and role of path integration in the cognitive representations of the hippocampus: computational insights into open questions</article-title>. <source>J Exp Biol</source> <volume>222</volume>, (<year>2019</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Save</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Cressant</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Thinus-Blanc</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Poucet</surname></string-name></person-group>, <article-title>Spatial firing of hippocampal place cells in blind rats</article-title>. <source>J Neurosci</source> <volume>18</volume>, <fpage>1818</fpage>–<lpage>1826</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Z. M.</given-names> <surname>Aghajan</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Acharya</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Moore</surname></string-name>, <string-name><given-names>J. D.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Vuong</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name></person-group>, <article-title>Impaired spatial selectivity and intact phase precession in two-dimensional virtual reality</article-title>. <source>Nat Neurosci</source> <volume>18</volume>, <fpage>121</fpage>–<lpage>128</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>Ravassard</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Kees</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Willers</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Ho</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Aharoni</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>Z. M.</given-names> <surname>Aghajan</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name></person-group>, <article-title>Multisensory control of hippocampal spatiotemporal selectivity</article-title>. <source>Science</source> <volume>340</volume>, <fpage>1342</fpage>–<lpage>1346</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. J.</given-names> <surname>Moore</surname></string-name>, <string-name><given-names>J. D.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Acharya</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Popeney</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name></person-group>, <article-title>Linking hippocampal multiplexed tuning, Hebbian plasticity and navigation</article-title>. <source>Nature</source> <volume>599</volume>, <fpage>442</fpage>–<lpage>448</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Sarel</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Finkelstein</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Las</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Ulanovsky</surname></string-name></person-group>, <article-title>Vectorial representation of spatial goals in the hippocampus of bats</article-title>. <source>Science</source> <volume>355</volume>, <fpage>176</fpage>–<lpage>180</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Ormond</surname></string-name>, <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name></person-group>, <article-title>Hippocampal place cells have goal-oriented vector fields during navigation</article-title>. <source>Nature</source> <volume>607</volume>, <fpage>741</fpage>–<lpage>746</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P. E.</given-names> <surname>Jercog</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Ahmadian</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Woodruff</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Deb-Sen</surname></string-name>, <string-name><given-names>L. F.</given-names> <surname>Abbott</surname></string-name>, <string-name><given-names>E. R.</given-names> <surname>Kandel</surname></string-name></person-group>, <article-title>Heading direction with respect to a reference point modulates place-cell activity</article-title>. <source>Nature communications</source> <volume>10</volume>, <fpage>2333</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. C.</given-names> <surname>Bittner</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Grienberger</surname></string-name>, <string-name><given-names>S. P.</given-names> <surname>Vaidya</surname></string-name>, <string-name><given-names>A. D.</given-names> <surname>Milstein</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Macklin</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Suh</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Tonegawa</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Magee</surname></string-name></person-group>, <article-title>Conjunctive input processing drives feature selectivity in hippocampal CA1 neurons</article-title>. <source>Nat Neurosci</source> <volume>18</volume>, <fpage>1133</fpage>–<lpage>1142</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. C.</given-names> <surname>Bittner</surname></string-name>, <string-name><given-names>A. D.</given-names> <surname>Milstein</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Grienberger</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Romani</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Magee</surname></string-name></person-group>, <article-title>Behavioral time scale synaptic plasticity underlies CA1 place fields</article-title>. <source>Science</source> <volume>357</volume>, <fpage>1033</fpage>–<lpage>1036</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. D.</given-names> <surname>Milstein</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>K. C.</given-names> <surname>Bittner</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Grienberger</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Soltesz</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Magee</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Romani</surname></string-name></person-group>, <article-title>Bidirectional synaptic plasticity rapidly modifies hippocampal representations</article-title>. <source>eLife</source> <volume>10</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. D.</given-names> <surname>Monaco</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Rao</surname></string-name>, <string-name><given-names>E. D.</given-names> <surname>Roth</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name></person-group>, <article-title>Attentive scanning behavior drives one-trial potentiation of hippocampal place fields</article-title>. <source>Nat Neurosci</source> <volume>17</volume>, <fpage>725</fpage>–<lpage>731</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. T.</given-names> <surname>Bennett</surname></string-name></person-group>, <article-title>Do animals have cognitive maps?</article-title> <source>J Exp Biol</source> <volume>199</volume>, <fpage>219</fpage>–<lpage>224</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Grieves</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dudchenko</surname></string-name></person-group>, <article-title>Cognitive maps and spatial inference in animals: Rats fail to take a novel shortcut, but can take a previously experienced one</article-title>. <source>Learning and Motivation</source> <volume>84</volume>, <fpage>81</fpage>–<lpage>92</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Benhamou</surname></string-name></person-group>, <article-title>No evidence for cognitive mapping in rats</article-title>. <source>Animal Behaviour</source> <volume>52</volume>, <fpage>201</fpage>–<lpage>212</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>Shamash</surname></string-name>, <string-name><given-names>S. F.</given-names> <surname>Olesen</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Iordanidou</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Campagner</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Banerjee</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Branco</surname></string-name></person-group>, <article-title>Mice learn multi-step routes by memorizing subgoal locations</article-title>. <source>Nat Neurosci</source> <volume>24</volume>, <fpage>1270</fpage>–<lpage>1279</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B.</given-names> <surname>Landau</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Spelke</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Gleitman</surname></string-name></person-group>, <article-title>Spatial knowledge in a young blind child</article-title>. <source>Cognition</source> <volume>16</volume>, <fpage>225</fpage>–<lpage>260</lpage> (<year>1984</year>).</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. P.</given-names> <surname>Kesner</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Farnsworth</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Kametani</surname></string-name></person-group>, <article-title>Role of parietal cortex and hippocampus in representing spatial information</article-title>. <source>Cereb Cortex</source> <volume>1</volume>, <fpage>367</fpage>–<lpage>373</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Kronfeld-Schor</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Dominoni</surname></string-name>, <string-name><given-names>H.</given-names> <surname>de la Iglesia</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Levy</surname></string-name>, <string-name><given-names>E. D.</given-names> <surname>Herzog</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Dayan</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Helfrich-Forster</surname></string-name></person-group>, <article-title>Chronobiology by moonlight</article-title>. <source>Proc Biol Sci</source> <volume>280</volume>, <fpage>20123088</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Upham</surname></string-name>, <string-name><given-names>S. J. C.</given-names> <surname>Hafner</surname></string-name></person-group>, <article-title>Do nocturnal rodents in the great basin desert avoid moonlight?</article-title> <source>Journal of Mammology</source> <volume>94</volume>, <fpage>59</fpage>–<lpage>72</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Falconer</surname></string-name></person-group>, <source>Fractal Geometry: Mathematical Foundations and Application</source> (<publisher-name>John Wiley and Sons</publisher-name>, <year>2004</year>).</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>GoodSmith</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>S. H.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Song</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Burgalossi</surname></string-name>, <string-name><given-names>K. M.</given-names> <surname>Christian</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name></person-group>, <article-title>Spatial Representations of Granule Cells and Mossy Cells of the Dentate Gyrus</article-title>. <source>Neuron</source> <volume>93</volume>, <fpage>677</fpage>–<lpage>690.e675-677–690.e675</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>J. F.</given-names> <surname>Hair</surname></string-name>, <string-name><given-names>W. C.</given-names> <surname>Black</surname></string-name>, <string-name><given-names>B. J.</given-names> <surname>Babin</surname></string-name>, <string-name><given-names>R. E.</given-names> <surname>Anderson</surname></string-name></person-group>, <source>Multivariate Data Analysis</source> (<publisher-loc>Pearson</publisher-loc>, ed. <edition>7th</edition>, <year>2013</year>).</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Tomé</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Oliveira</surname></string-name></person-group>, <source>Stochastic Dynamics and Irreversibility</source> (<publisher-name>Springer International Publishing</publisher-name>, <year>2015</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.3.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Cowan</surname>
<given-names>Noah J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Johns Hopkins University</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Fundamental</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>fundamental</bold> work provides creative and thoughtful analysis of rodent foraging behavior and its dependence on body reference frame-based vs world reference frame-based cues. <bold>Compelling</bold> evidence demonstrates that a robust map, capable of supporting taking novel shortcuts, can be learned primarily if not exclusively based on self-motion cues, which has rarely if ever been reported outside of the human literature. The work, which will be of interest to a broad audience of neuroscientists, provides a rich discussion about the role of the hippocampus in supporting the behavior that should guide future neurophysiological investigations.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.3.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Assessment:</p>
<p>This fundamental work advances our understanding of navigation and path integration in mammals by using a clever behavioral paradigm. The paper provides compelling evidence that mice are able to create and use a cognitive map to find &quot;short cuts&quot; in an environment, using only the location of rewards relative to the point of entry to the environment and path integration, and need not rely on visual landmarks.</p>
<p>Summary:</p>
<p>The authors have designed a novel experimental apparatus called the 'Hidden Food Maze (HFM)' and a beautiful suite of behavioral experiments using this apparatus to investigate the interplay between allothetic and idiothetic cues in navigation. The results presented provide a clear demonstration of the central claim of the paper, namely that mice only need a fixed start location and path integration to develop a cognitive map. The experiments and analyses conducted to test the main claim of the paper -- that the animals have formed a cognitive map -- are conclusive and include many thoughtfully designed control experiments to eliminate alternatives.</p>
<p>Strengths:</p>
<p>The 90 degree rotationally symmetric design and use of 4 distal landmarks and 4 quadrants with their corresponding rotationally equivalent locations (REL) lends itself to teasing apart the influence of path integration and landmark-based navigation in a clever way. The authors use a complete set of experiments and associated controls to show that mice can use a start location and path integration to develop a cognitive map and generate shortcut routes to new locations.</p>
<p>Weaknesses:</p>
<p>There were no major weaknesses identified that were not addressed during revisions.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.3.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>How is it that animals find learned food locations in their daily life? Do they use landmarks to home in on these learned locations or do they learn a path based on self-motion (turn left, take ten steps forward, turn right, etc.). This study carefully examines this question in a well-designed behavioral apparatus. A key finding is that to support the observed behavior in the hidden food arena, mice appear to not use the distal cues that are present in the environment for performing this task. Removal of such cues did not change the learning rate, for example. In a clever analysis of whether the resulting cognitive map based on self-motion cues could allow a mouse to take a shortcut, it was found that indeed they are. The work nicely shows the evolution of the rodent's learning of the task, and the role of active sensing in the targeted reduction of uncertainty of food location proximal to its expected location.</p>
<p>Strengths:</p>
<p>A convincing demonstration that mice can synthesize a cognitive map for the finding of a static reward using body frame-based cues. Showing that uncertainty of final target location is resolved by an active sensing process of probing holes proximal to the expected location. Showing that changing the position of entry into the arena rotates the anticipated location of the reward in a manner consistent with failure to use distal cues.</p>
<p>Weaknesses:</p>
<p>Weaknesses: The Reviewing Editor felt that previously identified weaknesses from Reviewer #3 were adequately addressed in the final manuscript.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.3.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Jiayun</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Girardi-Schappo</surname>
<given-names>Mauricio</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9111-4905</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Béïque</surname>
<given-names>Jean-Claude</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7278-4906</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Longtin</surname>
<given-names>André</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0678-9893</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Maler</surname>
<given-names>Leonard</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7666-2754</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the previous reviews.</p>
<p>I have added a paragraph that addresses the issue of how landmarks might be used and why they are not. The suggestions made in the &quot;Weaknesses&quot; paragraph were concise and excellent and have directly incorporated them into my revised manuscript. This text appears on Page 21 and is shown below. I hope that this is what the editors and reviewers were looking.</p>
<p>The requested revision is the second paragraph.</p>
<p>The first paragraph was not written in response to reviews but inspired by a recent paper by Mahdev et al (2024) - <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41593-024-01681-9">https://doi.org/10.1038/s41593-024-01681-9</ext-link>.  I had already requested to add this reference and was encouraged to do so by the Editors. The Mahdev et al paper was very surprising in that it showed that path integration is not constant but that its &quot;gain&quot; can be recalibrated by selfmotion signals. I wondered whether this unexpected capacity extended to path integration also recalibrating the cognitive map and thereby generating the shortcutting behavior we observe. I suggested that, at an abstract level, this would correspond to &quot;coordinate transformation&quot; of the cognitive map. I realize that this is entirely speculative. If the Editors feel that it does not add much to the manuscript and that the speculation goes to far, I will remove the first paragraph and re-submit.</p>
<p>Added text. P21 and just before the heading: &quot; Implications for theories of hippocampal representations of spatial maps&quot; There were no other changes made in the paper.</p>
<p>&quot;Path integration uses self-motion signals to update the animal's estimated location on its internal cognitive map. Path integration gain has been shown to be plastic and regulated by landmarks (<italic>52</italic>). Remarkably, a recent study has revealed that path integration gain can also be directly recalibrated by self-motion signals alone (<italic>53</italic>), albeit not as effectively as by landmarks (<italic>52, 53</italic>). An interesting question for future research is whether self-motion signals can also recalibrate the coordinates of a cognitive map. From this perspective, the Target B to Target A shortcut requires a transformation of the cognitive map coordinates so that the start point is now Target B.</p>
<p>Extensive research has shown that external cues can control hippocampal neuron place fields (<italic>11, 12, 54</italic>) and the gain of the path integrator (<italic>52</italic>), making the failure of mice in our study to use such cues puzzling. The failure to use landmarks may be related to our task being low stakes and our pretraining procedure teaching the mouse that such cues are not necessary. Our results may not generalize to more natural conditions where many reliable prominent cues are available, and where there is urgency to find food or water while avoiding predation (<italic>55</italic>). Under these more naturalistic conditions the use of distal cues to rapidly find a food reward is more likely to be observed.&quot;</p>
</body>
</sub-article>
</article>