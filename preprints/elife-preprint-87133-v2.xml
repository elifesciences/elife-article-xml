<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">87133</article-id>
<article-id pub-id-type="doi">10.7554/eLife.87133</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87133.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Cancer Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>GENIUS: GEnome traNsformatIon and spatial representation of mUltiomicS data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9896-1544</contrib-id>
<name>
<surname>Sokač</surname>
<given-names>Mateo</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kjær</surname>
<given-names>Asbjørn</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7061-9851</contrib-id>
<name>
<surname>Dyrskjøt</surname>
<given-names>Lars</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7684-0079</contrib-id>
<name>
<surname>Haibe-Kains</surname>
<given-names>Benjamin</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2122-2003</contrib-id>
<name>
<surname>Aerts</surname>
<given-names>Hugo J.W.L.</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1613-9587</contrib-id>
<name>
<surname>Birkbak</surname>
<given-names>Nicolai J</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Molecular Medicine, Aarhus University Hospital</institution>, Aarhus, <country>Denmark</country></aff>
<aff id="a2"><label>2</label><institution>Department of Clinical Medicine, Aarhus University</institution>, Aarhus, <country>Denmark</country></aff>
<aff id="a3"><label>3</label><institution>Bioinformatics Research Center, Aarhus University</institution>, Aarhus, <country>Denmark</country></aff>
<aff id="a4"><label>4</label><institution>Princess Margaret Cancer Centre, University Health Network, Temerty Faculty of Medicine, University of Toronto</institution>, Toronto, ON, <country>Canada</country></aff>
<aff id="a5"><label>5</label><institution>Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard Medical School</institution>, Boston, MA</aff>
<aff id="a6"><label>6</label><institution>Departments of Radiation Oncology and Radiology, Brigham and Women’s Hospital, Dana-Farber Cancer Institute, Harvard Medical School</institution>, Boston, MA</aff>
<aff id="a7"><label>7</label><institution>Radiology and Nuclear Medicine, CARIM &amp; GROW, Maastricht University</institution>, <country>The Netherlands</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Weigel</surname>
<given-names>Detlef</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Biology Tübingen</institution>
</institution-wrap>
<city>Tübingen</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Weigel</surname>
<given-names>Detlef</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Biology Tübingen</institution>
</institution-wrap>
<city>Tübingen</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence to: Nicolai J Birkbak Department of Molecular Medicine (MOMA), Aarhus University Hospital Science Center Skejby, Brendstrupgårdsvej 21A 8200 Aarhus N, Denmark E-mail: <email>nbirkbak@clin.au.dk</email> Phone number: (+45) 78455347</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-05-31">
<day>31</day>
<month>05</month>
<year>2023</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2023-08-10">
<day>10</day>
<month>08</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP87133</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-03-01">
<day>01</day>
<month>03</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-02-13">
<day>13</day>
<month>02</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.09.525144"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2023-05-31">
<day>31</day>
<month>05</month>
<year>2023</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.87133.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.87133.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.87133.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.87133.1.sa0">Reviewer #2 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Sokač et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Sokač et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-87133-v2.pdf"/>
<abstract>
<title>Abstract</title><p>The application of next-generation sequencing (NGS) has transformed cancer research. As costs have decreased, NGS has increasingly been applied to generate multiple layers of molecular data from the same samples, covering genomics, transcriptomics, and methylomics. Integrating these types of multi-omics data in a combined analysis is now becoming a common issue with no obvious solution, often handled on an ad-hoc basis, with multi-omics data arriving in a tabular format and analyzed using computationally intensive statistical methods. These methods particularly ignore the spatial orientation of the genome and often apply stringent p-value corrections that likely result in the loss of true positive associations. Here, we present GENIUS (GEnome traNsformatIon and spatial representation of mUltiomicS data), a framework for integrating multi-omics data using deep learning models developed for advanced image analysis. The GENIUS framework is able to transform multi-omics data into images with genes displayed as spatially connected pixels and successfully extract relevant information with respect to the desired output. Here, we demonstrate the utility of GENIUS by applying the framework to multi-omics datasets from the Cancer Genome Atlas. Our results are focused on predicting the development of metastatic cancer from primary tumors, and demonstrate how through model inference, we are able to extract the genes which are driving the model prediction and likely associated with metastatic disease progression. We anticipate our framework to be a starting point and strong proof of concept for multi-omics data transformation and analysis without the need for statistical correction.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>We have therefore published a new GitHub repository, with a thoroughly reworked code base and highly detailed instructions. We have included an additional author who has focused on these aspects, and on running the code without prior insight. Additionally, following a very relevant comment from reviewers, we have added a new analysis that investigates the correlation between gene expression and methylation. This is added as supplementary figure 10 and has been used to filter genes prior validation. This analysis resulted in updated main figures 4 and 5, and updated text.
Furthermore, we have reworked the methods section, results section, and discussion, according to the comments from the reviewers. Detailed responses are included in the submitted rebuttal letter.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The recent advent of Next Generation Sequencing (NGS) has revolutionized research and has been applied extensively to investigate complex biological questions. As the cost of sequencing continues to drop, it has become increasingly common to apply NGS technology to investigate complementary aspects of the biological processes on the same samples, particularly through analysis of DNA to resolve genomic architecture and single nucleotide variants, RNA to investigate gene expression, and methylation to explore gene regulation and chromatin structure. Such multi-omics data provides opportunities to perform integrated analysis, which investigates multiple layers of biological data together. Over the years, this has resulted in the generation of an incredible amount of very rich data derived from the genome itself, either directly or indirectly. The genome is spatially organized, with genes positioned on chromosomes sequentially and accessed by biological processes in blocks based on chromatin organization[<xref ref-type="bibr" rid="c1">1</xref>]. However, genome-derived NGS data is usually stored in and analyzed from a tabular format, where the naturally occurring spatial connectivity is lost. Furthermore, while genomic data is rich, the feature space is generally much larger than the number of samples. As the number of features to evaluate in statistical tests increases, the risk of chance associations increases as well. To correct for such multiple hypothesis testing, drastic adjustments of p-values are often applied which ultimately leads to the rejection of all but the most significant results, likely eliminating a large number of weaker but true associations. While this is a significant issue when analyzing a single type of data, the problem is exacerbated with performing multi-omics analysis where different types of data are combined, often in an ad-hoc manner tailored to specific use cases. Importantly, a common theme in multi-omics analytical approaches is that observations are processed individually, thereby discarding potential spatial information that may originate from the organization of genes on individual chromosomes.</p>
<p>Using artificial intelligence methods may help overcome this problem. Over the past decade, the development of artificial intelligence methods, particularly within deep learning architectures, has thoroughly revolutionized several technical fields, such as computer vision, voice recognition, advertising, and finance. Within the medical field, the roll-out of AI-based technologies has been slower, hampered in part by considerable regulatory hurdles that have proven difficult for machine-learning applications where the systems may accurately classify patients or samples by some parameter, but the logical reason behind this is unclear[<xref ref-type="bibr" rid="c2">2</xref>]. Nevertheless, AI systems have proven successful in a multitude of medical studies, and in recent years some AI-powered tools have started to move past testing to deployment[<xref ref-type="bibr" rid="c3">3</xref>]. A major benefit of deep neural networks is that they can capture nonlinear patterns in the data without necessitating correction for multiple hypothesis testing. Additionally, the use of convolutional layers within the networks has shown to improve performance by decreasing the impact of noise[<xref ref-type="bibr" rid="c4">4</xref>,<xref ref-type="bibr" rid="c5">5</xref>]. However, the problem with complex deep learning models is not the analysis itself but their interpretation[<xref ref-type="bibr" rid="c6">6</xref>]. Simpler models tend to have high interpretability; however, they are unable to capture complex nonlinear connections in data. This often leads to the utilization of “black box” models at the cost of interpretability[<xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c8">8</xref>]. “Black box” models are popular in the artificial intelligence industry, especially in computer vision applications, where immense progress is being made in technologies such as self-driving cars and computer interpretation of images. However, in many of those applications, the interpretability of models is not as important as in medicine[<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c10">10</xref>].</p>
<p>In medicine, the interpretability of models is crucial since there is a need for discovering new biomarkers as well as identifying underlying biological processes[<xref ref-type="bibr" rid="c11">11</xref>]. In addition to advancements in artificial intelligence and NGS, a vast amount of research has been conducted to interpret highly complex machine learning models; frameworks such as DeepLIFT[<xref ref-type="bibr" rid="c12">12</xref>], Integrated Gradients[<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c14">14</xref>], and DeepExplain [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c16">16</xref>] were developed in recent years with the purpose of debugging complicated machine learning models[<xref ref-type="bibr" rid="c17">17</xref>]. These frameworks enable the usage of deep learning models for integrated multi-omics analysis through their ability to evaluate input attribution in models that are traditionally considered a “black box”. In multiomics analysis, this means that it is possible to combine the entirety of the data from multiple data sources into a high-dimensional data structure and process it with deep learning models without losing interpretability. As output, an attribution score can be produced for every input, which may be interpreted as the relative importance of the feature in the model and used for further analysis.</p>
<p>Here, we present a framework for multi-omics analysis based on a convolutional deep learning network to find hidden, non-linear patterns in spatially connected feature-rich multi-layered data. The spatial connection of the data is made by transforming the data into a multi-channel image in such a way that spatial connections between genes are captured and analyzed using convolutional layers. Using spatial connections between the data showed superior performance when compared to non-spatially data transformations. Furthermore, the trained model is combined with Integrated Gradients, which allows us to evaluate the relative contribution of individual features and thus decipher the underlying biology that drives the classification provided by the deep learning models. Integrated Gradients is a non-parametric approach that evaluates the trained model relative to input data and output label, resulting in attribution scores for each input with respect to the output label. In other words, Integrated Gradients represent the integral of gradients with respect to inputs along the path from a given baseline. By using Integrated Gradients, we provide an alternative solution to the problem posed by performing multiple independent statistical tests. Here, instead of performing multiple tests, a single analysis is performed by transforming multiomics data into genome images, training a model, and inspecting it with Integrated Gradients. Integrated Gradients will output an attribution score for every gene included in the genome image. These can be ranked in order to retrieve a subset of the most associated genes relative to the output variable. We named the framework GENIUS (GEnome traNsformatIon and spatial representation of mUltiomicS data), and the methodology may be split into two parts, classification and interpretation. First, the key feature of GENIUS is that for classification, multi-omics data is transformed into multi-channel images where each gene is presented as a pixel in an image that covers the whole genome (<xref rid="fig1" ref-type="fig">Figure 1A-B</xref>). We then incorporate multiple types of omics data, such as mutation, expression, methylation, and copy-number data, into the image as distinct layers. These layers are then used as input into the deep learning model for training against a binary or continuous outcome variable. Next, for interpretation, an attribution score is assigned to each feature using integrated gradients, allowing the user to extract information about which feature or features may drive a specific prediction based on deep learning analysis of input from multiple-omics data sources. In this work, we describe the development of the GENIUS framework and demonstrate its utility in predicting the development of metastatic cancer, patient age, chromosomal instability, cancer type, and as proof of concept, loss of TP53.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Study overview.</title>
<p>(A) The study utilized 2332 tumor samples representing six cancer types (bladder, uterine, stomach, ovarian, kidney and colon) and transformed multiomics data into images based on chromosome interaction networks. After the model was trained, we validated found genes with two independent cohorts representing early stage BLCA (UROMOL) and late stage BLCA (Mariathasan). (B) The validation included looking at the most important genes driving metastatic disease, similar/different methylation patterns between cancer types, latent representation of genome data and looking at survival data. (C) The model architecture where the first part of the network encodes genome data into latent vector, L, followed by decoding where image is reconstructed. Next layers aim to extract information from the reconstructed image, concat it with L and make a final prediction.</p></caption>
<graphic xlink:href="525144v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>All predictions are based on multi-omics input through the GENIUS framework. Users may train their own or publicly sourced multi-omics data against a specified endpoint tailored to the user’s choice. The GENIUS framework thus overcomes the issue of multiple hypothesis testing and may provide new insights into the biology behind classification by deep learning models. The GENIUS framework is made available as a GitHub repository and may be used without restrictions to develop stratification models and inform about genome biology using multi-omics input.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>GENIUS Model Architecture and Hyperparameters</title>
<p>We designed a four-part convolutional neural network with the purpose of extracting the features from multi-dimensional data while minimizing the impact of noise in the data (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). The network was implemented using the PyTorch framework. The structure of the network is similar to an autoencoder architecture; however, the reconstruction of the genome image is not penalized. The motivation behind the implemented network structure is to use an encoder in order to learn how to compact genomic information into a small vector, L, forcing the network to extract relevant information from up to five data sources. The next module reconstructs the image from vector L, learns which features are important, reorganizes them optimally, and removes noise. The final module of the network uses a series of convolutions and max pooling layers in order to extract information from the reconstructed image and, finally, predicts the outcome variable using a fully connected dense network.</p>
<p>The first part of the network is called the encoder, as its purpose is to encode the entire image to a vector of size 128, representing the latent representation of the input data, “L”. Next, the original image is reconstructed from L into its original size using a decoder module in the network. In this step, since we are not using the reconstruction loss, the network reconstructs the image of a genome which is optimal for information extraction. This is followed by the extractor module containing convolution and max-pooling layers aiming to extract relevant information from the reconstructed image. The final part of the network flattens the learned features obtained from previous layers, concatenates them with the L vector, and forwards it to a fully connected dense feed-forward network where the final prediction is made (<xref rid="fig1" ref-type="fig">Figure 1C</xref>) [<xref ref-type="bibr" rid="c18">18</xref>]. During training, the last module of this model was adopted to predict qualitative as well as quantitative types of data.</p>
<p>All models were trained with Adagrad optimizer with the following hyperparameters: starting learning rate = 9.9e-05 (including learning rate scheduler and early stopping), learning rate decay and weight decay = 1e-6, batch size = 256, except for memory-intensive chromosome images where the batch size of 240 was used. Adding chromosome interaction information to the data transformation showed improvement during training; Next question was whether we should penalize the reconstruction of genome image during the training process. After multiple training scenarios and hyperparameter exploration, we concluded that by forcing the network to reconstruct genome images in the process of learning, we are limiting network performance. Instead, we used the appropriate loss function for prediction and allowed the network to reconstruct genome images that are optimal for making predictions.</p>
</sec>
<sec id="s2b">
<title>Evaluating input image design</title>
<p>To evaluate the performance of GENIUS with an image-based transformation of input omics data, we tested four different image layouts of the genome. For each layout, we created a set of images where each sample is represented by one multichannel image and each channel represented a specific type of omics data (gene expression, methylation, mutation, deletion, amplification) (Supplementary Figure 2A). Each data type was encoded for each gene as a continuous value, where each gene was defined by a single pixel in each layer. We then tested the performance of the deep neural network on four different image layouts. First, we assembled the genome as a square image, measuring 198 x 198 pixels in total. Here, all genes were placed on the image sequentially according to their chromosomal locations, and individual chromosomes were organized by how close they were oriented in 3D space[<xref ref-type="bibr" rid="c19">19</xref>]. Second, we tested an image organized by 24 x 3760 pixels, with 3760 pixels representing the most gene-rich chromosome, and each chromosome placed below the other on the image following the same order as in 198x198 images. Chromosomes containing fewer than 3760 genes had black pixels added to the end to create a rectangular image. Third, we tested a random 2D location, with each gene placed as a random pixel in a 198x198 pixel square image. Lastly, we tested an image of a single vector with all genes placed in a randomly ordered sequence. Data transformation we performed and tested:
<list list-type="order">
<list-item><p>Square image (198 x 198 pixels), each gene represented by one pixel ordered by chromosome position. Chromosomes are ordered by interaction coefficient based on Hi-C sequencing [<xref ref-type="bibr" rid="c19">19</xref>].</p></list-item>
<list-item><p>Square image (198 x 198 pixels), each gene is represented by one pixel located on the image in random order; thus, the 2D location carries no information.</p></list-item>
<list-item><p>Rectangular image (24 x 3760 pixels), each gene represented by one pixel ordered by chromosome position. Chromosomes are ordered by interaction coefficient based on Hi-C sequencing [<xref ref-type="bibr" rid="c19">19</xref>]</p></list-item>
<list-item><p>A flat, one-dimensional vector containing all features from the five data sources in random order.</p></list-item>
</list>
By using different image layouts, we wanted to investigate the spatial dependency of observations. Images were created by making a matrix for each source of data where each cell was represented by a single gene (<xref rid="fig1" ref-type="fig">Figure 1A</xref>, Supplementary Figure 2A-B). The genes in 198x 198 and 24 x 3760 images were ordered by position as well as by chromosome interaction coefficients resulting in the following order of chromosomes: 4, X, 7, 2, 5, 6, 13, 3, 8, 9, 18, 12, 1, 10, 11, 14, 22, 19, 17, 20, 16, 15, 21. Finally, newly created observations for each data source were merged as a multi-channel image where each channel represents a single source of data (Supplementary Figure 2A).</p>
</sec>
<sec id="s2c">
<title>Samples &amp; Training Data</title>
<p>We obtained gene expression, exome mutation, methylation and copy number data from six cancer types from the Cancer Genome Atlas (TCGA). These were picked to filter out cancer types with less than 400 samples. Next, cancer types with an extremely high proportion of metastatic samples (0.85 &lt; Proportion &gt; 0.15) were removed, resulting in ovarian serous cystadenocarcinoma (OV), colon adenocarcinoma (COAD), uterine corpus Endometrial carcinoma (UCEC), kidney renal clear cell carcinoma (KIRC), urothelial bladder carcinoma (BLCA) and stomach adenocarcinoma (STAD) (Supplementary Figure 1). RNAseq was obtained from the UCSC Toil pipeline [<xref ref-type="bibr" rid="c20">20</xref>] and summarized to transcript per million (TPM) on the gene level. SNP6 copy number data were segmented using ASCAT v2.4[<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref>] and converted into a ploidy and purity normalized logR value by dividing the total copy number with ploidy and taking the log2 value. The weighted genome integrity index (wGII)[<xref ref-type="bibr" rid="c23">23</xref>] was calculated on the available segmented copy number data, as previously described. Mutation calls were annotated using Polyphen2 to assess the mutation’s impact on the protein structure. Methylation was summarized by the mean methylation score for each gene.</p>
</sec>
<sec id="s2d">
<title>Validation cohorts acquisition and processing</title>
<p>Two independent cohorts of bladder cancer patients were used for validation. The UROMOL cohort [<xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c25">25</xref>] contains molecular data from 535 tumors from patients with early-stage bladder cancer (Ta and T1) and was included to evaluate the progression to muscle-invasive bladder cancer. The Mariathasan cohort[<xref ref-type="bibr" rid="c26">26</xref>] contains molecular data from 348 tumors from patients with advanced or metastatic bladder cancer (stage III and IV), treated with checkpoint immunotherapy. This cohort was included to evaluate the ability of the GENIUS framework to predict the likelihood of developing metastatic disease.</p>
<p>For both cohorts, RNAseq data was aligned against hg38 using STAR[<xref ref-type="bibr" rid="c27">27</xref>] version 2.7.2 and processed to generate count and transcript per million (TPM) expression values with Kallisto [<xref ref-type="bibr" rid="c28">28</xref>] version 0.46.2. Whole exome sequence (WES) data was processed using GATK [<xref ref-type="bibr" rid="c29">29</xref>] version 4.1.5 and ASCAT version 2.4.2 to obtain mutation and allele-specific copy number, purity, and ploidy estimates.</p>
</sec>
<sec id="s2e">
<title>Data transformation</title>
<p>All mutations were ranked by PolyPhen scores, ranging between 0 and 1. LogR segmented copy number data was analyzed as deletion and amplification separately. Copy number deletion was defined as logR scores &lt; log2 of 0.5/2, copy number amplification was defined as logR scores &gt; log2 of 5/2. All data types were defined on the gene level. For copy number alterations, we defined genes as amplified if the entirety of the gene was found within the amplified DNA segment. Genes were defined as deleted if they were partially within the deleted DNA segment (<xref rid="fig1" ref-type="fig">Figure 1A</xref>, Supplementary Figure 2A-B). Finally, to enable data integration and for more stable training of machine learning models, we generated mathematically equivalent values for each data source ranging from 0 to 1 through a simple linear transformation (min-max scaling). This enabled comparisons between individual data types, and was performed on each data source.</p>
</sec>
<sec id="s2f">
<title>Training scenarios</title>
<p>We used the GENIUS framework to make six models predicting the following conditions:
<list list-type="order">
<list-item><p>Metastatic cancer (binary classification), defined as Stage IV vs Stages I, II and III.</p></list-item>
<list-item><p>TP53 mutation (binary classification), where the TP53 mutation was removed from the input data and used only as a binary outcome label.</p></list-item>
<list-item><p>The tissue of origin (multi-class classification).</p></list-item>
<list-item><p>Age (continuous variable).</p></list-item>
<list-item><p>Weighted genome integrity index (wGII)[<xref ref-type="bibr" rid="c23">23</xref>], a chromosomal instability marker (continuous variable).</p></list-item>
<list-item><p>Randomized tissue of origin (multi-class variable). By randomizing the tissue of origin labels, a negative control was created. The purpose of this negative control was to confirm the model would fail to predict a pattern when none existed.</p></list-item>
</list>
In order to adapt the network for predicting different variables, we simply changed the output layer and loss function for training. Binary classifications and the multi-class classification used softmax as the output layer and the cross entropy loss function. When predicting continuous values, the model used the output from the activation function with the mean squared error loss function. When predicting multi-class labels, the performance measure was defined by the F1 score, a standard measure for multiclass classification that combines the sensitivity and specificity scores and is defined as the harmonic mean of its precision and recall. To evaluate model performance against the binary outcome, ROC analysis was performed, and the area under the curve (AUC) was used as the performance metric.</p>
</sec>
<sec id="s2g">
<title>Latent representation of genome</title>
<p>The purpose of latent vectors is to capture the most significant information from the entire genome data and compress it into a vector of size 128. This vector was later appended into a feed-forward network when making the final prediction. This way, the model had access to extracted information before and after image reconstruction. After successful model training, we extracted the latent representations of each genome and performed the Uniform Manifold Approximation and Projection (UMAP) of the data for the purpose of visual inspection of a model. The UMAP projected latent representations into two dimensions which could then be visualized. In order to avoid modeling noise, this step was used to inspect if the model is distinguishing between variables of interest. We observed that all training scenarios successfully utilized genome images to make predictions with the exception of Age, where no pattern was found from the genomic data, and randomized cancer type, which served as negative control where no pattern was expected (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). Information in latent vectors extracted from Age-Model and randomized cancer type showed no obvious patterns, which is likely the cause of poor performance.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Data transformation overview.</title>
<p>(A) The multiomics genome data was transformed into 4 image types; square image organized by chromosome interaction network, chromosome image organized by chromosome interaction network, randomly organized image and flat vector containing all multiomics data. (B) The x-axis represents epochs and the y-axis represents AUC score of fixed 25% data we used for accuracy assessment within the TCGA cohort. All four image types were used in training for metastatic disease prediction and the square image organized by chromosome interaction network resulted in best model performance (green color). The red line shows where the model resulted in the best loss. All curves stopped when the loss started increasing, indicating overfitting. The bar plot shows the proportion of correctly predicted (metastatic disease) in every cancer type included in the study. (C) 2-dimensional representation of vector L using UMAP for each predicted variable. Colors indicate the output variable which was used in the specific run.</p></caption>
<graphic xlink:href="525144v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2h">
<title>Identifying genes relevant to the tested outcome</title>
<p>Once the model was trained on the data, the appropriate loss function and output layer, including the model weights, were stored in a .pb file. The model and final weights were analyzed using the Integrated Gradients method (IG) implemented by Capture [<xref ref-type="bibr" rid="c14">14</xref>]. IG is an attribution method that assigns an “attribution score” to each feature of the input data based on predictions the model makes. The attribution score is calculated based on the gradient associated with each feature of each image channel with respect to the output of the model. This information indicates to the neural network the extent of weight decrease or increases needed for certain features during the backpropagation process. Next, the created attribution images are used to extract information for each image channel and for every pixel. Since the pixels represent individual genes, this information can be reformatted and filtered to show the most important genes from every data source included in the analysis. All attribution scores were scaled using a min-max scaler for every cancer type to address biological differences between cancer types.</p>
</sec>
<sec id="s2i">
<title>Code Availability</title>
<p>All code is available on the public GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/mxs3203/GENIUS">https://github.com/mxs3203/GENIUS</ext-link>), where the framework is easily available for analysis of private or public data. The framework provides tools to transform gene-oriented data into an image, train a model using existing model architecture and infer the most informative genes from the model using integrated gradients. The GitHub repository contains example data and instructions on how to use the GENIUS framework.</p>
</sec>
<sec id="s2j">
<title>Computational Requirements</title>
<p>In order to train the model, we used the following hardware configuration: Nvidia RTX3090 GPU, AMD Ryzen 9 5950X 16 core CPU, and 32Gb of RAM memory. In our study, we used a batch size of 256, which occupied around 60% of GPU memory. Training of the model was dependent on the output variable. For metastatic disease prediction, we trained the model for approximately 4 hours. This could be changed since we used early stopping in order to prevent overfitting. By reducing the batch size to smaller numbers, the technical requirements are reduced making it possible to run GENIUS on most modern laptops.</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Building genome images to utilize spatial connections in genomic data</title>
<p>We endeavored to present genomic data as an image with genes represented as individual pixels to be processed by our deep-learning architecture. To evaluate the relevance of the spatial orientation of the genes relative to model performance, we tested four different image layouts (Methods, <xref rid="fig2" ref-type="fig">Figure 2A</xref>): (1) Square image (198 x 198 pixels), each gene represented by one pixel ordered by chromosome position. Chromosomes are ordered by interaction coefficient based on Hi-C sequencing [<xref ref-type="bibr" rid="c9">9</xref>]. (2) Square image (198 x 198 pixels), each gene is represented by one pixel located on the image in random order; thus, the 2D location carries no information. (3) Chromosome image (24 x 3760 pixels), each gene represented by one pixel ordered by chromosome position. Chromosomes are ordered by interaction coefficient based on Hi-C sequencing [<xref ref-type="bibr" rid="c9">9</xref>]. (4) A flat, one-dimensional vector containing all features from the five data sources in random order. To evaluate the image layout, we used each type of layout to train against six biological states: (1) metastatic disease (stage IV vs. I-III), (2) cancer type, (3) burden of copy number alterations (defined by the weighted genome instability index, wGII), (4) patient age, (5) TP53 status (where the TP53 pixel was set to “0” for all samples), and (6) randomized tissue type (negative control). Every model output variable was trained until we observed no change in loss function or until validation loss values started increasing, indicating overfitting, which we handled by implementing early stopping.</p>
<p>While predicting metastatic disease, we observed that the Square Image data transformation outperformed all other data transformations, reaching a validation AUC of 0.87. The chromosome image and shuffled squared image performed similarly with AUC of 0.72 and 0.70, respectively. Interestingly, the flat vector of features scored validation AUC around 0.84; however, the loss function started increasing as training epochs increased, indicating that the model was overfitted (<xref rid="fig2" ref-type="fig">Figure 2B</xref>, Supplementary Figure 4 C-D). In the second scenario, we tested multiclass prediction using six cancer types in our dataset. Square Image outperformed other image layouts, reaching an F1 score of 0.81. Chromosome Image followed with an F1 score of 0.74, and the flat vector of features performed similarly to the random square image, reaching F1 scores of 0.66 and 0.71, respectively (Supplementary Figure 4 E-F). In order to address the framework’s capabilities for predicting numeric output variables, we used wGII and patient age. Predicting wGII showed that the flat vector of features reached the least favorable RMSE score of 0.22, where chromosome image, shuffled square image, and square image reached similar RMSE scores of 0.16, 0.15, and 0.14, respectively (Supplementary Figure 5 C-D).</p>
<p>These results suggest that data layout does not play a major role when predicting wGII as the number of events in the genome would be predictive regardless of location. The age prediction model using square image data transformation outperformed other data transformations and obtained a validation RMSE of 0.19. The shuffled image performed the worst, reaching an RMSE of 0.49, while the chromosome-organized image and flat vector of features scored similar RMSE values of 0.38 and 0.31, respectively. Additionally, the flat vector was inconsistent during training, but it did outperform the chromosome image (Supplementary Figure 5 A-B). In the fifth scenario, we predicted the TP53 mutation status but removed the TP53 mutation itself from the data. Square Image performed the best, reaching a validation AUC of 0.83, whereas no major difference could be observed between a flat vector of features and Chromosome Image, reaching a validation AUC of 0.75 (Supplementary Figure 4 A-B). Finally, we tested the framework by predicting randomized cancer types as the negative control. All data transformations had similar and poor results (Supplementary Figure 6). For each output variable, we trained four different models utilizing the four data transformations. In all cases, the square image (198x198, ordered by chromosomes) outperformed the other transformations and was chosen as the layout for the final GENIUS framework, which was used for all subsequent analyses.</p>
</sec>
<sec id="s3b">
<title>Latent representation of genome captures relevant biology</title>
<p>The model architecture contains an encoder and decoder connected by a latent vector of size 128 (L), which provides the opportunity to inspect model performance (<xref rid="fig1" ref-type="fig">Figure 1</xref>). The L vector is considered the latent representation of the genome data because it extracts and captures the most relevant data with respect to the output variable. This implies that an optimally trained model would show a perfect latent representation of the genome when overlaid with the output variable. Furthermore, this vector was later appended into a feed-forward network when making the final prediction. This way, the model had access to extracted information before and after image reconstruction. In order to visually inspect patterns captured by the model, we extracted the latent representations of each genome and performed the Uniform Manifold Approximation and Projection (UMAP) of the data to project it into two dimensions. We observed that all training scenarios successfully utilized genome images to make predictions that clustered into distinct groups, with the exception of Age. As expected, randomized cancer type, which served as negative control, also performed poorly (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). Information in latent vectors extracted from Age-Model and randomized cancer type-model showed no obvious patterns, which is likely the cause of poor performance.</p>
</sec>
<sec id="s3c">
<title>GENIUS classification identifies tumors likely to become metastatic</title>
<p>To explore the utility of the GENIUS framework to classify tumors from multiomics data and to interpret the biological drivers behind the classification, we further investigated the GENIUS model trained against metastatic disease using the TCGA datasets (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). This analysis included primary tumors from six cancer types, a total of 2307 tumors, with 53 percent progressing to metastatic disease (bladder cancer [BLCA, 277 metastatic/133 not-metastatic], ovarian cancer [OV, 535 metastatic/47 not-metastatic], colon adenocarcinoma [COAD, 196 metastatic/254 not-metastatic], stomach adenocarcinoma [STAD, 230 metastatic/189 not-metastatic], kidney clear cell renal cancer [KIRC, [208 metastatic/326 not-metastatic], uterine endometrial cancer [UCEC, 117 metastatic/394 not-metastatic]). The omics data types included somatic mutations, gene expression, methylation, copy number gain and copy number loss. Using holdout type cross-validation, where we split the data into training (75%) and validation (25%), we observed a generally high performance of GENIUS, with a validation AUC of 0.83 for predicting metastatic disease (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). The GENIUS framework allows us to explore the attribution of individual data layers to the final prediction. Across the cohort, gene expression and methylation data were generally the most informative data layers when it comes to classifying metastatic disease (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). We noted that expression and methylation overall ranked the highest in terms of mean scaled attribution, with the exception of OV, which showed enrichment in methylation followed by copy number gain and loss. The same analysis was performed for cancer type, wGII, patient age, TP53 status and randomized tissue type, (Supplementary Figures 7 - 8).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>The most important events in metastatic disease development.</title>
<p>(A) Pieplot showing the relative importance of each data source when predicting metastatic disease for each cancer type included in the study. (B) Top 50 genes for every cancer type scale by cancer type. The star symbol below the gene names indicates that the gene is part of COSMIC gene consensus. The color of the gene name indicates the data source and color of the bar indicates the cancer type.</p></caption>
<graphic xlink:href="525144v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3d">
<title>Interpreting the GENIUS model classifying metastatic cancer biology</title>
<p>Analyzing raw attribution scores we concluded the most informative data type overall regarding the development of metastatic disease was methylation (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). To identify the individual genes driving the prediction, we pulled the 100 genes with the highest methylation attribution according to the GENIUS classification. We observed that many methylated regions overlapped between the six cancer types. These regions included methylation on specific regions of chromosomes 1, 6, 11, 17, and 19 (Supplementary Figure 9). Additionally, OV showed a unique methylation pattern spanning most of chromosome 7, while KIRC, COAD, and BLCA displayed regions of overlapping methylation on chromosome 22. We also noticed that mutation data often had a single mutation with a large attribution score while expression and methylation showed multiple genes with high attribution scores. To determine the genes that overall across the multi-omics data analysis contributed the most to the GENIUS classification of metastatic disease, we normalized gene attribution by cancer type and compared the top 50 genes for each cancer type (total of 152 genes, <xref rid="fig3" ref-type="fig">Figure 3B</xref>, Supplementary Table 1). Unsurprisingly, we observed that TP53 mutations held the highest attribution score, followed by mutations to VHL. Both of these genes are well-established drivers of cancer and were previously reported as enriched in metastatic cancer [<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c31">31</xref>], likely representing a more aggressive disease. However, of the 152 top genes, we noted only 11 genes previously reported as either oncogenes or tumor suppressor genes in the COSMIC cancer gene census (<xref rid="fig3" ref-type="fig">Figure 3B</xref>, indicated with a star), leaving 141/152 as potentially novel cancer genes. The highest-scoring gene not previously associated with cancer was SLC3A1, the expression of which was found to be strongly associated with metastatic disease in clear-cell renal cancer. SLC3A1 gene is a protein-coding gene associated with the transportation of amino acids in the renal tubule and intestinal tract, and aberrations in this gene have been associated with cystinuria, a metabolic disorder of the kidneys, bladder, and ureter [<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref>]. Furthermore, we identified PLVAP, often involved in MAPK cascades as well as in cellular regulatory pathways and the tumor necrosis factor-mediated signaling pathway. In BLCA, one of our most significant findings was increased expression of KRT17, a gene associated with a cytoskeletal signaling pathway, glucocorticoid receptor regulatory network, and MHC class II receptor activity [<xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c35">35</xref>]. KRT17 has previously been reported as a potential cancer gene, but with an uncertain role[<xref ref-type="bibr" rid="c36">36</xref>]. Across cancer types, TOP3A was found to be commonly methylated in BLCA, COAD, STAD and UCEC. TOP3A is associated with homology-directed repair and methylation may lead to increased chromosomal instability, a hallmark of cancer[<xref ref-type="bibr" rid="c37">37</xref>]. The top ten most important events driving the prediction of every output variable included in the study are summarized in Supplementary Table 2-3.</p>
</sec>
<sec id="s3e">
<title>Validation of bladder cancer metastasis-associated genes in an independent cohort of advanced and metastatic bladder cancer</title>
<p>To investigate if the genes with the highest attribution score in the TCGA bladder cancer analysis were indeed associated with metastatic bladder cancer, we utilized an immunotherapy-treated predominantly late-stage (mainly stage III and IV) bladder cancer cohort with gene expression data available for 348 tumors[<xref ref-type="bibr" rid="c26">26</xref>]. For this analysis, we considered only the methylation and gene-expression-associated genes from the TCGA analysis. For methylation, we restricted the analysis to genes showing a significantly negative correlation between gene expression and gene-specific methylation levels (Supplementary Figure 10). We then combined the methylation and gene-expression-based attribution scores and took the top 10 genes: RBMX, COL7A1, KRT17, JUP, WIPI2, TOP3A, EIF3B, WTAP, POTEI, and MRRF. Next, we implemented 10 multivariate Cox proportional hazard models (one for each gene), including available clinical parameters such as tumor stage, gender, neoantigen burden and baseline performance status (Supplementary Table 4). This showed that in multivariate analysis, 7/10 genes had a significant association with outcome (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). To evaluate the results of this analysis, we compared it to an identical model run 1,000 times, but where the 10 genes were randomly picked. In 1,000 runs, not one returned at least 7 significant genes (P &lt; 0.001) (Supplementary Figure 11A). The median percentage of significant genes for each run is reported in <xref rid="fig4" ref-type="fig">Figure 4B</xref>. Next, we performed two independent analyses, comparing the expression values of the top 10 genes between either (1) tumors defined as stage IV versus stage I-III, and (2) patients that responded to immunotherapy (CR and PR) versus patients that did not respond to immunotherapy (SD and PD). Following correction for multiple hypothesis testing, we observed that TOP3A showed significantly increased expression in stage IV tumors, while JUP and KRT17 were significantly increased in stage I-III tumors (<xref rid="fig4" ref-type="fig">Figure 4C</xref>, brown dots). When comparing gene expression to response to immunotherapy, TOP3A, RBMX, and WIPI2 were significantly more expressed in CR/PR while KRT17 and COL7A1 were significantly more expressed in SD/PD. Interestingly, we observed increased expression of TOP3A in stage IV tumors, suggesting a role in metastatic disease, yet we also observed that the same gene was more expressed in tumors that responded to immunotherapy. This suggests that TOP3A is associated with the development of metastatic disease, but its expression may result in the development of a bladder cancer phenotype that is more sensitive to checkpoint immunotherapy.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Validation on late stage immunotherapy treated bladder cancer (Mariathasan).</title>
<p>(A) Forest plot showing top 10 expressed/methylated genes in multivariate cox proportional hazard model. (B) Comparison of median percent of randomly selected genes vs. genes picked by GENIUS in cox proportional hazard model. (C) Volcano plot showing top 10 expressed/methylated genes and their enrichment in two comparisons; Stages I-III vs Stage IV and immunotherapy response (CR: complete response, PR: partial response) versus no response (SD: stable disease, PD: progressive disease). Two genes show association in opposite directions, indicated by red lines (KRT17, associated with low stage and poor immunotherapy response, and TOP3A, associated with high stage and improved immunotherapy response).</p></caption>
<graphic xlink:href="525144v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3f">
<title>Validation of metastasis-associated genes in an independent cohort of early-stage bladder cancer</title>
<p>To investigate if the metastasis-associated genes found through the GENIUS framework also plays a role in the development of aggressive features in early stage bladder cancer, we acquired the UROMOL dataset[<xref ref-type="bibr" rid="c25">25</xref>], which includes gene expression data from 535 low-stage tumors. We again investigated the top 10 methylated or expressed genes found in the TCGA analysis of BLCA, using the gene expression data from UROMOL. First, we performed Cox proportional hazard analysis with progression-free survival (PFS) using the top 10 genes found by the GENIUS framework, again creating 10 individual models containing the selected genes and available clinical factors such as age, tumor stage, and sex. This showed that in multivariate analysis, 5/10 genes had a significant association with outcome (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). The results were compared with cox proportional hazard models utilizing random sets of ten genes, repeated 1,000 times. Of these, 216 runs showed at least five significant genes (P = 0.216) (Supplementary Figure 11B), indicating that in early stage bladder cancer, the genes found by GENIUS to be associated with cancer metastasis were not uniquely relevant for disease progression. However, when we computed the median percentage of significant genes and compared it to the top 10 genes picked by the GENIUS framework, by random chance, only 20% of genes overall were found to be significantly associated with PFS compared to 50% of GENIUS genes (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). To further investigate the top 10 genes picked by GENIUS, we compared the mean expression of each gene between different clinical risk groups (EORTC status [<xref ref-type="bibr" rid="c38">38</xref>]) and tumor grade. In this analysis, six of the 10 genes were significantly associated with EORTC status (<xref rid="fig5" ref-type="fig">Figure 5C</xref>, Supplementary Table 4), and seven with grade (<xref rid="fig5" ref-type="fig">Figure 5D</xref>, Supplementary Table 5).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Validation on early stage bladder cancer (UROMOL).</title>
<p>(A) Forest plot showing top 10 expressed/methylated genes picked by GENIUS for BLCA. (B) Comparison of median percent of randomly selected genes vs. genes picked by GENIUS in cox proportional hazard model. (C) Volcano plot showing association of the top 10 expressed/methylated genes relative to EORTC-Low and EORTC-High groups. (D) Volcano plot showing association of the top 10 expressed/methylated genes relative to low grade and high grade BLCA tumors.</p></caption>
<graphic xlink:href="525144v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>In this work, we explored multiple options on how to transform multi-omics data into an image, leading to the utilization of deep learning models, which are often described as “black box” models. The model architecture was evaluated in six different training scenarios, with a focus on validating the prediction of metastatic cancer. In this process, we also evaluated four different image layouts, concluding that of these, projecting the genome into a 198x198 square image with genes organized based on chromosome interaction[<xref ref-type="bibr" rid="c19">19</xref>] performed the best. While that spatial organization improved the prediction, we recognize that there may exist a more optimal representation of multi-omics data which should be explored further in future work. Potential methods for organizing gene orientation in a multi-channel image could consider integrating topologically associating domains[<xref ref-type="bibr" rid="c39">39</xref>] along with the spatial information from HiC. With the current implementation of GENIUS, gene layout can be set manually by the user to explore this issue further. For GENIUS, we have also included an auto-encoder in the network to recreate the input information without reconstruction loss. In this manner, the model itself can reconstruct the image of a genome in a format that is optimal for the prediction it is trying to make. The model also produces a latent representation of multi-omics data in a shape of a vector of a size 128 (L), which is later concatenated in a model when making final predictions. In order to investigate training effectiveness, we performed a UMAP clustering analysis of the L vector, where we compared the 2D representation of L with the variables of interest (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). It is clear from this analysis that the L vector itself holds information that may be particularly relevant for multi-class prediction, but further analysis is needed to decipher what information is encoded in the L vector.</p>
<p>The main purpose behind the study was to demonstrate the feasibility of leveraging the power of deep learning techniques optimized for image analysis to interpret genome-derived multi-omics data. A key element of this approach includes the transformation of genomic data into images with genes arranged as pixels organized by chromosomal location. Beyond the readout from multi-omics data, this approach provides spatial information to the deep-learning framework, which significantly improves the performance of the models (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). To the best of our knowledge, we are the first to demonstrate the utility of spatial information and to provide a ready-to-use framework that incorporates spatial information and deep learning for the analysis of genome-derived multi-omics data. Furthermore, within the GENIUS framework, we facilitate the interpretation of the trained model in order to explore the biology behind the prediction without the need for data preprocessing and multiple hypothesis correction. This was achieved by combining a deep learning network with Integrated Gradients[<xref ref-type="bibr" rid="c14">14</xref>], allowing us to infer the attribution score for the input, resulting in non-parametric, ready-to-analyze output.</p>
<p>For every cancer type included in the dataset, we listed the top 10 genes driving metastatic disease and investigated in detail genes associated with BLCA metastasis and aggressiveness. For this, we used two independent cohorts, one representing late-stage and metastatic cancer, and one representing early stage cancer. In both cohorts, we tested if methylation and expression of genes found by the GENIUS framework were associated with survival at higher rates than when compared to randomly picked genes. In the late stage BLCA cohort, seven out of 10 genes were significantly associated with overall survival, while in the early stage BLCA cohort, we found that five out of 10 were significantly associated with progression-free survival. That the results in the early stage bladder cancer cohort (UROMOL) are less significant may relate to the model being trained to predict metastatic cancer. It is likely that the drivers of malignancy are different in early relative to late stage disease, thus the top 10 genes found by GENIUS might not be prognostic in early stage setting. In this regard it is also worth noting that two of the top 10 genes (RBMX and KRT17) were associated with poor outcome in late stage disease, while they were associated with improved outcome in early stage disease. Interestingly, in the late stage bladder cancer cohort, we observed that high expression of TOP3A associated with stage IV disease (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). However, we also observed that high expression associated with improved response to immunotherapy. It is known that TOP3A has an important role in homology-directed repair and loss may be associated with chromosomal instability, which has shown a positive association with immunotherapy response [<xref ref-type="bibr" rid="c40">40</xref>–<xref ref-type="bibr" rid="c42">42</xref>], potentially offering a likely explanation for this finding. Similarly, we observed that KRT17 was enriched in stages I-III, suggesting it may be associated with a less aggressive disease type. However, in the immunotherapy-treated cohort, KRT17 is associated with poor response to immunotherapy. In previous studies, KRT17 has been reported as associated with the development of metastatic disease, MHC type II receptor activity and angiogenesis [<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c43">43</xref>]. This indicates that the KRT17 gene plays an important role as tumor suppressor gene in early-stage cancer, and that loss may further promote the development of aggressive, metastatic disease. While further research in this field is required to properly assess the utility of the reported genes, this work provides a framework that unlocks powerful machine-learning for more direct analysis of multi-omics data.</p>
<p>Taken together, we provide here the GENIUS framework along with analysis demonstrating the utility in multi-omics analysis. While we have focused on cancer analysis here, we believe GENIUS may find utility in a diverse range of genome-based multi-omics analyses. We have provided a git-hub repository that can be used to transform data into images and train the same model predicting variables of user’s interest and inferring the importance of input with respect to the desired output.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Summary of BLCA genes in two validation cohorts</p></caption>
<graphic xlink:href="525144v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="d1e843" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e965">
<label>Supplementary Material</label>
<media xlink:href="supplements/525144_file07.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>N.J.B. is a fellow of the Lundbeck Foundation (R272-2017-4040), and acknowledges funding from Aarhus University Research Foundation (AUFF-E-2018-7-14), and the Novo Nordisk Foundation (NNF21OC0071483). The results published here are in whole or part based upon data generated by the TCGA Research Network: <ext-link ext-link-type="uri" xlink:href="https://www.cancer.gov/tcga">https://www.cancer.gov/tcga</ext-link>.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Franke</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ibrahim</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Andrey</surname> <given-names>G</given-names></string-name>, <string-name><surname>Schwarzer</surname> <given-names>W</given-names></string-name>, <string-name><surname>Heinrich</surname> <given-names>V</given-names></string-name>, <string-name><surname>Schöpflin</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> <article-title>Formation of new chromatin domains determines pathogenicity of genomic duplications</article-title>. <source>Nature</source>. <year>2016</year>;<volume>538</volume>: <fpage>265</fpage>–<lpage>269</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Wiens</surname> <given-names>J</given-names></string-name>, <string-name><surname>Saria</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sendak</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ghassemi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>VX</given-names></string-name>, <string-name><surname>Doshi-Velez</surname> <given-names>F</given-names></string-name>, <etal>et al.</etal> <article-title>Do no harm: a roadmap for responsible machine learning for health care</article-title>. <source>Nature Medicine</source>. <year>2019</year>. pp. <fpage>1337</fpage>–<lpage>1340</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41591-019-0548-6</pub-id></mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Benjamens</surname> <given-names>S</given-names></string-name>, <string-name><surname>Dhunnoo</surname> <given-names>P</given-names></string-name>, <string-name><surname>Meskó</surname> <given-names>B.</given-names></string-name> <article-title>The state of artificial intelligence-based FDA-approved medical devices and algorithms: an online database</article-title>. <source>NPJ Digit Med</source>. <year>2020</year>;<volume>3</volume>: <fpage>118</fpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Jang</surname> <given-names>H</given-names></string-name>, <string-name><surname>McCormack</surname> <given-names>D</given-names></string-name>, <string-name><surname>Tong</surname> <given-names>F</given-names></string-name>. <article-title>Noise-trained deep neural networks effectively predict human vision and its neural responses to challenging images</article-title>. <source>PLoS Biol</source>. <year>2021</year>;<volume>19</volume>: <fpage>e3001418</fpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Du</surname> <given-names>R</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>W</given-names></string-name>, <string-name><surname>Fu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Meng</surname> <given-names>L</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Z</given-names></string-name>. <article-title>Random noise attenuation via convolutional neural network in seismic datasets</article-title>. <source>Alex Eng J</source>. <year>2022</year>;<volume>61</volume>: <fpage>9901</fpage>–<lpage>9909</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Rudin</surname> <given-names>C</given-names></string-name>. <article-title>Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead</article-title>. <source>Nat Mach Intell</source>. <year>2019</year>;<volume>1</volume>: <fpage>206</fpage>–<lpage>215</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Elmarakeby</surname> <given-names>HA</given-names></string-name>, <string-name><surname>Hwang</surname> <given-names>J</given-names></string-name>, <string-name><surname>Arafeh</surname> <given-names>R</given-names></string-name>, <string-name><surname>Crowdis</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal> <article-title>Biologically informed deep neural network for prostate cancer discovery</article-title>. <source>Nature</source>. <year>2021</year>;<volume>598</volume>: <fpage>348</fpage>–<lpage>352</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Wolfe</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Mikheeva</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Hagras</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zabet</surname> <given-names>NR</given-names></string-name>. <article-title>An explainable artificial intelligence approach for decoding the enhancer histone modifications code and identification of novel enhancers in Drosophila</article-title>. <source>Genome Biol</source>. <year>2021</year>;<volume>22</volume>: <fpage>308</fpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Yang</surname> <given-names>G</given-names></string-name>, <string-name><surname>Ye</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Xia</surname> <given-names>J</given-names></string-name>. <article-title>Unbox the black-box for the medical explainable AI via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond</article-title>. <source>Inf Fusion</source>. <year>2022</year>;<volume>77</volume>: <fpage>29</fpage>–<lpage>52</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Petch</surname> <given-names>J</given-names></string-name>, <string-name><surname>Di</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nelson</surname> <given-names>W</given-names></string-name>. <article-title>Opening the Black Box: The Promise and Limitations of Explainable Machine Learning in Cardiology</article-title>. <source>Can J Cardiol</source>. <year>2022</year>;<volume>38</volume>: <fpage>204</fpage>–<lpage>213</lpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Picard</surname> <given-names>M</given-names></string-name>, <string-name><surname>Scott-Boyer</surname> <given-names>M-P</given-names></string-name>, <string-name><surname>Bodein</surname> <given-names>A</given-names></string-name>, <string-name><surname>Périn</surname> <given-names>O</given-names></string-name>, <string-name><surname>Droit</surname> <given-names>A</given-names></string-name>. <article-title>Integration strategies of multi-omics data for machine learning analysis</article-title>. <source>Comput Struct Biotechnol J</source>. <year>2021</year>;<volume>19</volume>: <fpage>3735</fpage>–<lpage>3746</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="other"><string-name><surname>Shrikumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Greenside</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kundaje</surname> <given-names>A</given-names></string-name>. <article-title>Learning Important Features Through Propagating Activation Differences</article-title>. <year>2017</year> [cited 8 Feb 2023]. doi:<pub-id pub-id-type="doi">10.48550/arXiv.1704.02685</pub-id></mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="other"><string-name><surname>Ancona</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ceolini</surname> <given-names>E</given-names></string-name>, <string-name><surname>Öztireli</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gross</surname> <given-names>M</given-names></string-name>. <article-title>Towards better understanding of gradient-based attribution methods for Deep Neural Networks</article-title>. <year>2017</year> [cited 8 Feb 2023]. doi:<pub-id pub-id-type="doi">10.48550/arXiv.1711.06104</pub-id></mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="other"><string-name><surname>Sundararajan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Taly</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yan</surname> <given-names>Q</given-names></string-name>. <article-title>Axiomatic Attribution for Deep Networks</article-title>. <year>2017</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1703.01365">http://arxiv.org/abs/1703.01365</ext-link></mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Samek</surname> <given-names>W</given-names></string-name>, <string-name><surname>Montavon</surname> <given-names>G</given-names></string-name>, <string-name><surname>Vedaldi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hansen</surname> <given-names>LK</given-names></string-name>, <string-name><surname>Müller</surname> <given-names>K-R.</given-names></string-name> <article-title>Explainable AI: Interpreting, Explaining and Visualizing Deep Learning</article-title>. <source>Springer Nature</source>; <year>2019</year>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Bach</surname> <given-names>S</given-names></string-name>, <string-name><surname>Binder</surname> <given-names>A</given-names></string-name>, <string-name><surname>Montavon</surname> <given-names>G</given-names></string-name>, <string-name><surname>Klauschen</surname> <given-names>F</given-names></string-name>, <string-name><surname>Müller</surname> <given-names>K-R</given-names></string-name>, <string-name><surname>Samek</surname> <given-names>W</given-names></string-name>. <article-title>On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation</article-title>. <source>PLoS One</source>. <year>2015</year>;<volume>10</volume>: <fpage>e0130140</fpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="confproc"><string-name><surname>Despraz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gomez</surname> <given-names>S</given-names></string-name>, <string-name><surname>Satizábal</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Peña-Reyes</surname> <given-names>CA</given-names></string-name>. <article-title>Towards a Better Understanding of Deep Neural Networks Representations using Deep Generative Networks</article-title>. <conf-name>Proceedings of the 9th International Joint Conference on Computational Intelligence</conf-name>. <year>2017</year>. doi:<pub-id pub-id-type="doi">10.5220/0006495102150222</pub-id></mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>LeNail</surname> <given-names>A</given-names></string-name>. <article-title>NN-SVG: Publication-Ready Neural Network Architecture Schematics</article-title>. <source>Journal of Open Source Software</source>. <year>2019</year>. p. <fpage>747</fpage>. doi:<pub-id pub-id-type="doi">10.21105/joss.00747</pub-id></mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Sarnataro</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chiariello</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Esposito</surname> <given-names>A</given-names></string-name>, <string-name><surname>Prisco</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nicodemi</surname> <given-names>M</given-names></string-name>. <article-title>Structure of the human chromosome interaction network</article-title>. <source>PLoS One</source>. <year>2017</year>;<volume>12</volume>: <fpage>e0188201</fpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Vivian</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rao</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Nothaft</surname> <given-names>FA</given-names></string-name>, <string-name><surname>Ketchum</surname> <given-names>C</given-names></string-name>, <string-name><surname>Armstrong</surname> <given-names>J</given-names></string-name>, <string-name><surname>Novak</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>Toil enables reproducible, open source, big biomedical data analyses</article-title>. <source>Nat Biotechnol</source>. <year>2017</year>;<volume>35</volume>: <fpage>314</fpage>–<lpage>316</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Adzhubei</surname> <given-names>IA</given-names></string-name>, <string-name><surname>Schmidt</surname> <given-names>S</given-names></string-name>, <string-name><surname>Peshkin</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ramensky</surname> <given-names>VE</given-names></string-name>, <string-name><surname>Gerasimova</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bork</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal> <article-title>A method and server for predicting damaging missense mutations</article-title>. <source>Nat Methods</source>. <year>2010</year>;<volume>7</volume>. doi:<pub-id pub-id-type="doi">10.1038/nmeth0410-248</pub-id></mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Raine</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Van Loo</surname> <given-names>P</given-names></string-name>, <string-name><surname>Wedge</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Jones</surname> <given-names>D</given-names></string-name>, <string-name><surname>Menzies</surname> <given-names>A</given-names></string-name>, <string-name><surname>Butler</surname> <given-names>AP</given-names></string-name>, <etal>et al.</etal> <article-title>ascatNgs: Identifying Somatically Acquired Copy-Number Alterations from Whole-Genome Sequencing Data</article-title>. <source>Curr Protoc Bioinformatics</source>. <year>2016</year>;<volume>56</volume>: <fpage>15.9.1</fpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Burrell</surname> <given-names>RA</given-names></string-name>, <string-name><surname>McClelland</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Endesfelder</surname> <given-names>D</given-names></string-name>, <string-name><surname>Groth</surname> <given-names>P</given-names></string-name>, <string-name><surname>Weller</surname> <given-names>M-C</given-names></string-name>, <string-name><surname>Shaikh</surname> <given-names>N</given-names></string-name>, <etal>et al.</etal> <article-title>Replication stress links structural and numerical cancer chromosomal instability</article-title>. <source>Nature</source>. <year>2013</year>;<volume>494</volume>: <fpage>492</fpage>–<lpage>496</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Zuiverloon</surname> <given-names>TCM</given-names></string-name>, <string-name><surname>Beukers</surname> <given-names>W</given-names></string-name>, <string-name><surname>van der Keur</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Nieuweboer</surname> <given-names>AJM</given-names></string-name>, <string-name><surname>Reinert</surname> <given-names>T</given-names></string-name>, <string-name><surname>Dyrskjot</surname> <given-names>L</given-names></string-name>, <etal>et al.</etal> <article-title>Combinations of urinary biomarkers for surveillance of patients with incident nonmuscle invasive bladder cancer: the European FP7 UROMOL project</article-title>. <source>J Urol</source>. <year>2013</year>;<volume>189</volume>: <fpage>1945</fpage>–<lpage>1951</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Lindskrog</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Prip</surname> <given-names>F</given-names></string-name>, <string-name><surname>Lamy</surname> <given-names>P</given-names></string-name>, <string-name><surname>Taber</surname> <given-names>A</given-names></string-name>, <string-name><surname>Groeneveld</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Birkenkamp-Demtröder</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal> <article-title>An integrated multi-omics analysis identifies prognostic molecular subtypes of non-muscle-invasive bladder cancer</article-title>. <source>Nat Commun</source>. <year>2021</year>;<volume>12</volume>: <fpage>2301</fpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Mariathasan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Turley</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Nickles</surname> <given-names>D</given-names></string-name>, <string-name><surname>Castiglioni</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yuen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Y</given-names></string-name>, <etal>et al.</etal> <article-title>TGFβ attenuates tumour response to PD-L1 blockade by contributing to exclusion of T cells</article-title>. <source>Nature</source>. <year>2018</year>;<volume>554</volume>: <fpage>544</fpage>–<lpage>548</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Dobin</surname> <given-names>A</given-names></string-name>, <string-name><surname>Davis</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Schlesinger</surname> <given-names>F</given-names></string-name>, <string-name><surname>Drenkow</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zaleski</surname> <given-names>C</given-names></string-name>, <string-name><surname>Jha</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal> <article-title>STAR: ultrafast universal RNA-seq aligner</article-title>. <source>Bioinformatics</source>. <year>2013</year>;<volume>29</volume>: <fpage>15</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Ayers</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lunceford</surname> <given-names>J</given-names></string-name>, <string-name><surname>Nebozhyn</surname> <given-names>M</given-names></string-name>, <string-name><surname>Murphy</surname> <given-names>E</given-names></string-name>, <string-name><surname>Loboda</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>DR</given-names></string-name>, <etal>et al.</etal> <article-title>IFN-γ-related mRNA profile predicts clinical response to PD-1 blockade</article-title>. <source>J Clin Invest</source>. <year>2017</year>;<volume>127</volume>: <fpage>2930</fpage>–<lpage>2940</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Van der Auwera</surname> <given-names>GA</given-names></string-name>, <string-name><surname>O’Connor</surname> <given-names>BD</given-names></string-name>. <article-title>Genomics in the Cloud: Using Docker</article-title>, <source>GATK, and WDL in Terra. O’Reilly Media</source>; <year>2020</year>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Pandey</surname> <given-names>R</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>N</given-names></string-name>, <string-name><surname>Cooke</surname> <given-names>L</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>B</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Pandey</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>TP53 Mutations as a Driver of Metastasis Signaling in Advanced Cancer Patients</article-title>. <source>Cancers</source>. <year>2021</year>. p. <volume>597</volume>. doi:<pub-id pub-id-type="doi">10.3390/cancers13040597</pub-id></mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Christensen</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Ahrenfeldt</surname> <given-names>J</given-names></string-name>, <string-name><surname>Sokač</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kisistók</surname> <given-names>J</given-names></string-name>, <string-name><surname>Thomsen</surname> <given-names>MK</given-names></string-name>, <string-name><surname>Maretty</surname> <given-names>L</given-names></string-name>, <etal>et al.</etal> <article-title>Treatment represents a key driver of metastatic cancer evolution</article-title>. <source>Cancer Res</source>. <year>2022</year>. doi:<pub-id pub-id-type="doi">10.1158/0008-5472.CAN-22-0562</pub-id></mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Jiang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Cao</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Li</surname> <given-names>W</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Lv</surname> <given-names>Y</given-names></string-name>, <etal>et al.</etal> <article-title>Cysteine transporter SLC3A1 promotes breast cancer tumorigenesis</article-title>. <source>Theranostics</source>. <year>2017</year>;<volume>7</volume>: <fpage>1036</fpage>–<lpage>1046</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Woodard</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Welch</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Veach</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Beckermann</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Sha</surname> <given-names>F</given-names></string-name>, <string-name><surname>Weinman</surname> <given-names>EJ</given-names></string-name>, <etal>et al.</etal> <article-title>Metabolic consequences of cystinuria</article-title>. <source>BMC Nephrol</source>. <year>2019</year>;<volume>20</volume>: <issue>227</issue>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Wu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Xu</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ji</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zhai</surname> <given-names>B</given-names></string-name>, <string-name><surname>Zhu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gao</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>Low Expression of Keratin17 is Related to Poor Prognosis in Bladder Cancer</article-title>. <source>Onco Targets Ther</source>. <year>2021</year>;<volume>14</volume>: <fpage>577</fpage>–<lpage>587</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Li</surname> <given-names>C</given-names></string-name>, <string-name><surname>Su</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ruan</surname> <given-names>C</given-names></string-name>, <string-name><surname>Li</surname> <given-names>X</given-names></string-name>. <article-title>Keratin 17 knockdown suppressed malignancy and cisplatin tolerance of bladder cancer cells, as well as the activation of AKT and ERK pathway</article-title>. <source>Folia Histochem Cytobiol</source>. <year>2021</year>;<volume>59</volume>: <fpage>40</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Xia</surname> <given-names>T</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>L</given-names></string-name>, <string-name><surname>Luo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <etal>et al.</etal> <article-title>The Role of Keratin17 in Human Tumours</article-title>. <source>Front Cell Dev Biol</source>. <year>2022</year>;<volume>10</volume>: <fpage>818416</fpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Hanahan</surname> <given-names>D</given-names></string-name>, <string-name><surname>Weinberg</surname> <given-names>RA</given-names></string-name>. <article-title>Hallmarks of cancer: the next generation</article-title>. <source>Cell</source>. <year>2011</year>;<volume>144</volume>: <fpage>646</fpage>–<lpage>674</lpage>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><collab>European Organisation For Research And Treatment Of Cancer</collab>. In: <source>EORTC [Internet]</source>. 17 Jan <year>2017</year> [cited 13 Jul 2022]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.eortc.org/">https://www.eortc.org/</ext-link></mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Beagan</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Phillips-Cremins</surname> <given-names>JE</given-names></string-name>. <article-title>On the existence and functionality of topologically associating domains</article-title>. <source>Nat Genet</source>. <year>2020</year>;<volume>52</volume>: <fpage>8</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Bakhoum</surname> <given-names>SF</given-names></string-name>, <string-name><surname>Cantley</surname> <given-names>LC</given-names></string-name>. <article-title>The Multifaceted Role of Chromosomal Instability in Cancer and Its Microenvironment</article-title>. <source>Cell</source>. <year>2018</year>;<volume>174</volume>: <fpage>1347</fpage>–<lpage>1360</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Chen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Linstra</surname> <given-names>R</given-names></string-name>, <string-name><surname>van Vugt</surname> <given-names>MATM</given-names></string-name>. <article-title>Genomic instability, inflammatory signaling and response to cancer immunotherapy</article-title>. <source>Biochim Biophys Acta Rev Cancer</source>. <year>2022</year>;<volume>1877</volume>: <fpage>188661</fpage>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Sokač</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ahrenfeldt</surname> <given-names>J</given-names></string-name>, <string-name><surname>Litchfield</surname> <given-names>K</given-names></string-name>, <string-name><surname>Watkins</surname> <given-names>TBK</given-names></string-name>, <string-name><surname>Knudsen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dyrskjøt</surname> <given-names>L</given-names></string-name>, <etal>et al.</etal> <article-title>Classifying cGAS-STING Activity Links Chromosomal Instability with Immunotherapy Response in Metastatic Bladder Cancer</article-title>. <source>Cancer Research Communications</source>. <year>2022</year>;<volume>2</volume>: <fpage>762</fpage>–<lpage>771</lpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Ji</surname> <given-names>R</given-names></string-name>, <string-name><surname>Ji</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ge</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal> <article-title>Keratin 17 upregulation promotes cell metastasis and angiogenesis in colon adenocarcinoma</article-title>. <source>Bioengineered</source>. <year>2021</year>;<volume>12</volume>: <fpage>12598</fpage>–<lpage>12611</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>de Nonneville</surname> <given-names>A</given-names></string-name>, <string-name><surname>Salas</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bertucci</surname> <given-names>F</given-names></string-name>, <string-name><surname>Sobinoff</surname> <given-names>AP</given-names></string-name>, <string-name><surname>Adélaïde</surname> <given-names>J</given-names></string-name>, <string-name><surname>Guille</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>TOP3A amplification and ATRX inactivation are mutually exclusive events in pediatric osteosarcomas using ALT</article-title>. <source>EMBO Mol Med</source>. <year>2022</year>;<volume>14</volume>: <fpage>e15859</fpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Song</surname> <given-names>Y</given-names></string-name>, <string-name><surname>He</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zhuang</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal> <article-title>RBMX contributes to hepatocellular carcinoma progression and sorafenib resistance by specifically binding and stabilizing BLACAT1</article-title>. <source>Am J Cancer Res</source>. <year>2020</year>;<volume>10</volume>: <fpage>3644</fpage>–<lpage>3665</lpage>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Yu</surname> <given-names>L</given-names></string-name>, <string-name><surname>Luo</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ding</surname> <given-names>X</given-names></string-name>, <string-name><surname>Tang</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gao</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> <article-title>WIPI2 enhances the vulnerability of colorectal cancer cells to erastin via bioinformatics analysis and experimental verification</article-title>. <source>Front Oncol</source>. <year>2023</year>;<volume>13</volume>: <fpage>1146617</fpage>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Qin</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>S</given-names></string-name>, <string-name><surname>Qiao</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Wan</surname> <given-names>X</given-names></string-name>, <etal>et al.</etal> <article-title>Effects of differential distributed-JUP on the malignancy of gastric cancer</article-title>. <source>J Advert Res</source>. <year>2021</year>;<volume>28</volume>: <fpage>195</fpage>–<lpage>208</lpage>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Oh</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Oh</surname> <given-names>MY</given-names></string-name>, <string-name><surname>An</surname> <given-names>JY</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Sohn</surname> <given-names>TS</given-names></string-name>, <string-name><surname>Bae</surname> <given-names>JM</given-names></string-name>, <etal>et al.</etal> <article-title>Prognostic Value of Highly Expressed Type VII Collagen (COL7A1) in Patients With Gastric Cancer</article-title>. <source>Pathol Oncol Res</source>. <year>2021</year>;<volume>27</volume>: <fpage>1609860</fpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87133.2.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Weigel</surname>
<given-names>Detlef</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Biology Tübingen</institution>
</institution-wrap>
<city>Tübingen</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> manuscript presents a new approach to transform multi-omics datasets into images and to exploit Deep Learning methods for image analysis of the transformed datasets. As an example, the method is applied to multi-omics datasets on different cancers. While the evidence in this specific case is <bold>solid</bold>, whether the method is working as advertised in other settings is not yet known.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87133.2.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This study by Sokač et al. entitled &quot;GENIUS: GEnome traNsformatIon and spatial representation of mUltiomicS data&quot; presents an integrative multi-omics approach which maps several genomic data sources onto an image structure on which established deep-learning methods are trained with the purpose of classifying samples by their metastatic disease progression signatures. Using published samples from the Cancer Genome Atlas the authors characterize the classification performance of their method which only seems to yield results when mapped onto one out of four tested image-layouts.</p>
<p>A few remaining issues are unclear to me:</p>
<p>1. While the authors have now extended the documentation of the analysis script they refer to as GENIUS, I assume that the following files are not part of the script anymore, since they still contain hard-coded file paths or hard-coded gene counts:</p>
<list list-type="bullet">
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://github.com/mxs3203/GENIUS/blob/master/GenomeImage/make_images_by_chr.py">https://github.com/mxs3203/GENIUS/blob/master/GenomeImage/make_images_by_chr.py</ext-link></p>
</list-item><list-item><p><ext-link ext-link-type="uri" xlink:href="https://github.com/mxs3203/GENIUS/blob/master/GenomeImage/randomize_normal_imgs.py">https://github.com/mxs3203/GENIUS/blob/master/GenomeImage/randomize_normal_imgs.py</ext-link></p>
</list-item><list-item><p><ext-link ext-link-type="uri" xlink:href="https://github.com/mxs3203/GENIUS/blob/master/GenomeImage/utils.py">https://github.com/mxs3203/GENIUS/blob/master/GenomeImage/utils.py</ext-link></p>
</list-item></list>
<p>If these files are indeed not part of the script anymore, then I would recommend removing them from the GitHub repo to avoid confusion. If, however, they are still part of the script, the authors failed to remove all hard-coded file paths and the software will fail when users attempt to use their own datasets.</p>
<p>1. The authors leave most of the data formatting to the user when attempting to use datasets other than their own presented for this study:</p>
<p>Script arguments:</p>
<list list-type="bullet">
<list-item><p>a. clinical_data: Path to CSV file that must contain ID and label column we will use for prediction</p>
</list-item><list-item><p>b. ascat_data: Path to output matrix of ASCAT tool. Check the example input for required columns</p>
</list-item><list-item><p>c. all_genes_included: Path to the CSV file that contains the order of the genes which will be used to create Genome Image</p>
</list-item><list-item><p>d. mutation_data: Path CSV file representing mutation data. This file should contain Polyphen2 score and HugoSymbol</p>
</list-item><list-item><p>e. gene_exp_data: Path to the csv file representing gene expression data where columns=sample_ids and there should be a column named &quot;gene&quot; representing the HugoSymbol of the gene</p>
</list-item><list-item><p>f. gene_methyl_data: Path to the csv file representing gene methylation data wherecolumns=sample_ids and there should be a column named &quot;gene1&quot; representing the HugoSymbol of the gene</p>
</list-item></list>
<p>While this suggests that users will have a difficult time adjusting this analysis script to their own data, this issue is exacerbated by the fact that their analysis script has almost no internal checks whether data format standards were met. Thus, the user will be left with cryptic error messages and will likely give up soon after. I therefore strongly recommend adding internal data format checks and helpful error or warning messages to their script to guide users in the input data adoption process.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87133.2.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this manuscript, Birkbak and colleagues use a novel approach to transform multi-omics datasets in images and apply Deep Learning methods for image analysis. Interestingly they find that the spatial representation of genes on chromosomes and the order of chromosomes based on 3D contacts leads to best performance. This supports that both 1D proximity and 3D proximity could be important for predicting different phenotypes. I appreciate that the code is made available as a github repository. The authors use their method to investigate different cancers and identify novel genes potentially involved in these cancers. Overall, I found this study important for the field.</p>
<p>In the original submission there were several major points with this manuscript could be grouped in three parts:</p>
<p>1. While the authors have provided validation for their model, it is not always clear that best approaches have been used. This has now been addressed in the revised version of the manuscript.</p>
<p>2. Potential improvement to the method</p>
<p>a. It is very encouraging the use of HiC data, but the authors used a very coarse approach to integrate it (by computing the chromosome order based on interaction score). We know that genes that are located far away on the same chromosome can interact more in 3D space than genes that are relatively close in 1D space. Did the authors consider this aspect? Why not group genes based on them being located in the same TAD? In the revised version of the manuscript, the authors discussed this possibility but did not do any new additional analysis.</p>
<p>b. Authors claim that &quot;given that methylation negatively correlates with gene expression, these were considered together&quot;. This is clearly not always the case. See for example <ext-link ext-link-type="uri" xlink:href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02728-5">https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02728-5</ext-link>. In the revised version of the manuscript, the authors addressed fully this comment.</p>
<p>3. Interesting results that were not explained.</p>
<p>a. In Figure 3A methylation seems to be most important omics data, but in 3B, mutations and expression are dominating. The authors need to explain why this is the case. In the revised version of the manuscript, the authors have clarified this.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87133.2.sa3</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sokač</surname>
<given-names>Mateo</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9896-1544</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Kjær</surname>
<given-names>Asbjørn</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dyrskjøt</surname>
<given-names>Lars</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7061-9851</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Haibe-Kains</surname>
<given-names>Benjamin</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7684-0079</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Aerts</surname>
<given-names>Hugo J.W.L.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2122-2003</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Birkbak</surname>
<given-names>Nicolai J</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1613-9587</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>This study by Sokač et al. entitled &quot;GENIUS: GEnome traNsformatIon and spatial representation of mUltiomicS data&quot; presents an integrative multi-omics approach which maps several genomic data sources onto an image structure on which established deep-learning methods are trained with the purpose of classifying samples by their metastatic disease progression signatures. Using published samples from the Cancer Genome Atlas the authors characterize the classification performance of their method which only seems to yield results when mapped onto one out of four tested image-layouts.</p>
<p>Major recommendations:</p>
<list list-type="bullet">
<list-item><p>In its current form, GENIUS analysis is neither computationally reproducible nor are the presented scripts on GitHub generic enough for varied applications with other data. The GENIUS GitHub repository provides a collection of analysis scripts and not a finished software solution (e.g. command line tool or other user interface) (the presented scripts do not even suffice for a software prototype). In detail, the README on their GitHub repository is largely incomplete and reads analogous to an incomplete and poorly documented analysis script and is far from serving as a manual for a generic software solution (this claim was made in the manuscript).</p>
</list-item></list>
</disp-quote>
<p>We apologize for this oversight, and we have now invested considerable resources into making the documentation more detailed and accurate. We have created a new GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/mxs3203/GENIUS">https://github.com/mxs3203/GENIUS</ext-link>) that contains a small set of example data and all the necessary scripts to run GENIUS. The README file guides the user through each step of the GENIUS framework but it also contains a bash script that runs all the steps at once. When a user would like to use it on their own data, they need to replace the input data with their data but in the same format as the example input data. This is now fully documented in the README file. All scripts have arguments that can be used to point to custom data. The entire pipeline using example data can be run using run_<ext-link ext-link-type="uri" xlink:href="http://genius.sh">genius.sh</ext-link> script. This script will produce CSV files and PNG files inside the ExtractWithIG folder containing attribution scores for every cancer type tested.</p>
<disp-quote content-type="editor-comment">
<p>The authors should invest substantially into adding more details on how data can be retrieved (with example code) from the cited databases and how such data should then be curated alongside the input genome to generically create the &quot;genomic image&quot;.</p>
</disp-quote>
<p>Data for analysis can be sourced from multiple locations, what we have used in our examples and for development was based on data from the TCGA. It can be retrieved from the official TCGA data hub or through Xena Browser (<ext-link ext-link-type="uri" xlink:href="https://xenabrowser.net/">https://xenabrowser.net/</ext-link>). However, the data formats are generic, and similar data types (mutation, expression, methylation, copy number) can be obtained from multiple sources. We have added example data to demonstrate the layout, and we have a script included that creates the layout from standard mutation, expression, methylation and copy number data formats. We have substantially improved the annotations, including detailed descriptions of the data layout along with examples, and we have, as part of our validation, had an independent person test run the scripts using TCGA example data we provided on the new GitHub page.</p>
<disp-quote content-type="editor-comment">
<p>In addition, when looking at the source code, parameter configurations for training and running various modules of GENIUS were hard-coded into the source code and users would have to manually change them in the source code rather than as command line flags in the software call. Furthermore, file paths to the local machine of the author are hard-coded in the source code, suggesting that images are sourced from a local folder and won't work when other users wish to replicate the analysis with other data. I would strongly recommend building a comprehensive command line tool where parameter and threshold configurations can be generically altered by the user via command line flags.</p>
</disp-quote>
<p>Apologies, we have changed the code and removed all hard-coded paths. All paths are now relative to the script using them. Furthermore, we made the config file more visible and easier to use. The example run can be found on the new github repository we linked in the previous comment.</p>
<p>We also inserted the following text in the manuscript</p>
<p>The GitHub repository contains example data and instructions on how to use the GENIUS framework.</p>
<disp-quote content-type="editor-comment">
<p>A comprehensive manual would need to be provided to ensure that users can easily run GENIUS with other types of input data (since this is the claim of the manuscript). Overall, due to the lack of documentation and hard-coded local-machine folder paths it was impossible to computationally reproduce this study or run GENIUS in general.</p>
</disp-quote>
<p>Apologies, we have completely reworked the code base, and extensively annotated the code. We have also made highly detailed step-by-step instructions that should enable any user to run GENIUS on their own or public data.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>In the Introduction the authors write: &quot;To correct for such multiple hypothesis testing, drastic adjustments of p-values are often applied which ultimately leads to the rejection of all but the most significant results, likely eliminating a large number of weaker but true associations.&quot;. While this is surely true for any method attempting to separate noise from signal, their argument fails to substantiate how their data transformation will solve this issue. Data transformation and projection onto an image for deep-learning processing will only shift the noise-to-signal evaluation process to the postprocessing steps and won't &quot;magically&quot; solve it during training.</p>
</list-item></list>
</disp-quote>
<p>The data transformation does not solve the problem of multiple hypothesis testing but it facilitates the use of computer vision algorithms and frameworks on rich multi-omics data. Importantly, transforming the data into genome images, training the model, and inspecting it with integrated gradients can be interpreted as running a single test on all of the data.</p>
<p>Analyzing multiomics data using classical statistical methods typically means that we perform extensive filtering of the data, removing genes with poor expression/methylation/mutation scores, and then e.g. perform logistic regression against a desired outcome, or alternatively, perform multiple statistical tests comparing each genomic feature independently against a desired outcome. Either way, information is lost during initial filtering and we must correct the analysis for each statistical test performed. While this increases confidence in whichever observation remains significant, it also undoubtedly means that we discard true positives. Additionally, classical statistical methods such as those mentioned here do not assume a spatial connection between data points, thus any relevant information relating to spatial organization is lost.</p>
<p>Instead, we propose the use of the GENIUS framework for multiomics analysis. The GENIUS framework is based on deep neural nets and relies on Convolutions and their ability to extract interactions between the data points. This particularly considers spatial information, which is not possible using classical statistical methods such as logistic regression where the most similar approach to this would include creating many models with many interactions.</p>
<p>Furthermore, integrated gradients is a non-parametric approach that simply evaluates the trained model relative to input data and output label, resulting in attribution for each input with respect to the output label. In other words, integrated gradients represent the integral of gradients with respect to inputs along the path from a given baseline to input. The integral is described in Author response image 1:</p>
<fig id="sa3fig1">
<label>Author response image 1.</label>
<graphic mime-subtype="jpg" xlink:href="elife-87133-sa3-fig1.jpg" mimetype="image"/>
</fig>
<p>More about integrated gradients can be read on the Captum webpage
(<ext-link ext-link-type="uri" xlink:href="https://captum.ai/docs/introduction">https://captum.ai/docs/introduction</ext-link>) or in original paper <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1703.01365">https://arxiv.org/abs/1703.01365</ext-link>.</p>
<p>Since we transformed the data into a data structure (genome image) that assumes a spatial connection between genes, trained the model using convolutional neural networks and analyzed the model using integrated gradients, we can treat the results without any parametric assumption. As a particular novelty, we can sort the list based on attribution score and take top N genes as our candidate biomarkers for the variable of interest and proceed with downstream analysis or potentially functional validation in an in vitro setting. In this manner, the reviewer is correct that the signal-to-noise evaluation is shifted to the post-processing steps. However, the benefit of the GENIUS framework is particularly that it enables integration of multiple data sources without any filtering, and with constructing a novel data structure that facilitates investigation of spatial dependency between data points, thus potentially revealing novel genes or biomarkers that were previously removed through filtering steps. However, further downstream validation of these hits remains critical.</p>
<p>We added the following paragraph to make this more clear</p>
<p>&quot;Integrated Gradients is a non-parametric approach that evaluates the trained model relative to input data and output label, resulting in attribution scores for each input with respect to the output label. In other words, Integrated Gradients represent the integral of gradients with respect to inputs along the path from a given baseline. By using Integrated Gradients, we provide an alternative solution to the problem posed by performing multiple independent statistical tests. Here, instead of performing multiple tests, a single analysis is performed by transforming multiomics data into genome images, training a model, and inspecting it with Integrated Gradients. Integrated Gradients will output an attribution score for every gene included in the genome image and those can be ranked in order to retrieve a subset of the most associated genes relative to the output variable.&quot;</p>
<disp-quote content-type="editor-comment">
<p>In addition, multiple-testing correction is usually done based on one particular data source (e.g.
expression data), while their approach claims to integrate five very different genomic data sources with different levels and structures of technical noise. How are these applications comparable and how is the training procedure able to account for these different structures of technical noise? Please provide sufficient evidence for making this claim (especially in the postprocessing steps after classification).</p>
</disp-quote>
<p>The reviewer is correct that there will be different technical noise for each data source. However, each data source is already processed by standardized pipelines used for interpreting sequence-level data into gene expression, mutations, copy number alterations and methylation levels. Thus, sequence-level technical noise is not evaluated as part of the GENIUS analysis. Nevertheless, the reviewer is correct that sample-level technical noise, such as low tumor purity or poor quality sequencing, undoubtedly can affect the GENIUS predictions, as is true for all types of sequence analysis. As part of GENIUS, an initial data preprocessing step (which is performed automatically as part of the image generation), is that each data source is normalized within that source and linearly scaled in range zero to one (min-max scaling). This normalization step means that the impact of different events within and between data sources are comparable since the largest/smallest value from one data source will be comparable to the largest/smallest value from another data source.</p>
<p>Additionally, deep neural networks, particularly convolutional networks, have been shown to be very robust to different levels of technical noise (Jang, McCormack, and Tong 2021; Du et al. 2022). In the manuscript we show the attribution scores for different cancer types in figure 3B of the paper. Here, the top genes include established cancer genes such as P53, VHL, PTEN, APC and PIK3CA, indicating that the attribution scores based on GENIUS analysis is a valid tool to identify potential genes of interest. Furthermore, when focusing the analysis on predicting metastatic bladder cancer, we were able to show that of the top 10 genes with the highest attribution scores, 7 showed significant association with poor outcome in an independent validation cohort of mostly metastatic patients (shown in figure 4).</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>I didn't find any computational benchmark of GENIUS. What are the computational run times, hardware requirements (e.g. memory usage) etc that a user will have to deal with when running an analogous experiment, but with different input data sources? What kind of hardware is required GPUs/CPUs/Cluster?</p>
</list-item></list>
</disp-quote>
<p>We apologize for not including this information in the manuscript. We added the following section in to the manuscript:</p>
<p>&quot;Computational Requirements</p>
<p>In order to train the model, we used the following hardware configuration: Nvidia RTX3090 GPU, AMD Ryzen 9 5950X 16 core CPU, and 32Gb of RAM memory. In our study, we used a batch size of 256, which occupied around 60% of GPU memory. Training of the model was dependent on the output variable. For metastatic disease prediction, we trained the model for approximately 4 hours. This could be changed since we used early stopping in order to prevent overfitting. By reducing the batch size to smaller numbers, the technical requirements are reduced making it possible to run GENIUS on most modern laptops.&quot;</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>A general comment about the Methods section: Models, training, and validation are very vaguely described and the source code on GitHub is very poorly documented so that parameter choices, model validation, test and validation frameworks and parameter choices are neither clear nor reproducible.</p>
</list-item></list>
</disp-quote>
<p>Apologies, we have updated the methods section with more details on models, training and validation. Additionally, we have moved the section on evaluating model performance from the methods section to the results section, with more details on how training was performed.</p>
<p>We also agree that the GitHub page is not sufficiently detailed and well structured. To remedy this, we have made a new GitHub page that only has the code needed for analysis, example input data, example runs, and environment file with all library versions. The GitHub repository is also updated in the manuscript.</p>
<p>The new GitHub page can be found on: <ext-link ext-link-type="uri" xlink:href="https://github.com/mxs3203/GENIUS">https://github.com/mxs3203/GENIUS</ext-link></p>
<disp-quote content-type="editor-comment">
<p>Please provide a sufficient mathematical definition of the models, thresholds, training and testing frameworks.</p>
</disp-quote>
<p>We sincerely apologize, but we do not entirely follow the reviewers request on this regard. The mathematical definitions of deep neural networks are extensive and not commonly included in research publications utilizing deep learning. We have used PyTorch to implement the deep neural net, a commonly used platform, which is now referenced in the methods. The design of the deep learning network used for GENIUS is described in figure 1, and the relevant parameters are described in methods. The hyper parameters are described in the methods section, and are as follows:</p>
<p>&quot;All models were trained with Adagrad optimizer with the following hyperparameters: starting learning rate = 9.9e-05 (including learning rate scheduler and early stopping), learning rate decay and weight decay = 1e-6, batch size = 256, except for memory-intensive chromosome images where the batch size of 240 was used.&quot;</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>In chapter &quot;Latent representation of genome&quot; the authors write: &quot;After successful model training, we extracted the latent representations of each genome and performed the Uniform Manifold Approximation and Projection (UMAP) of the data. The UMAP projected latent representations into two dimensions which could then be visualized. In order to avoid modeling noise, this step was used to address model accuracy and inspect if the model is distinguishing between variables of interest.&quot;. In the recent light of criticism when using the first two dimensions of UMAP projections with omics data, what is the evidence in support of the author's claim that model accuracy can be quantified with such a 2D UMAP projection? How is 'model accuracy' objectively quantified in this visual projection?</p>
</list-item></list>
</disp-quote>
<p>We apologize for not clarifying this. The UMAP was done on L, the latent vector, which by assumption should capture the most important information from the “genome image”. In order to confirm this, we plotted the first two dimensions of UMAP transformation and colored the points by the output variable. If the model was capturing noise, there should not be any patterns on the plot (randomized cancer-type panel). Since, in most cases, we do see an association between the first two UMAP dimensions and the output variable, we were confident that the model was not modeling (extracting) noise.</p>
<p>To clarify this, we changed the sentence in the manuscript so it is more clear that this is not an estimation of accuracy but only an initial inspection of the models:</p>
<p>The UMAP projected latent representations into two dimensions which could then be visualized. In order to avoid modeling noise, this step was used to inspect if the model is distinguishing between variables of interest.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>In the same paragraph &quot;Latent representation of genome&quot; the authors write: &quot;We observed that all training scenarios successfully utilized genome images to make predictions with the exception of Age and randomized cancer type (negative control), where the model performed poorly (Figure 2B).&quot;. Did I understand correctly that all negative controls performed poorly? How can the authors make any claims if the controls fail? In general, I was missing sufficient controls for any of their claims, but openly stating that even the most rudimentary controls fail to deliver sufficient signals raises substantial issues with their approach. A clarification would substantially improve this chapter combined with further controls.</p>
</list-item></list>
</disp-quote>
<p>We apologize for not stating this more clearly. Randomized cancer type was used as a negative control since we expect that model would not be able to make sense of the data if predicting randomized cancer type. As expected, the model failed to predict the randomized cancer types. This can be seen in Figure 2C, where UMAP representations (based on the latent representation of the data, the vector L) are made for each output variable. Not seeing any patterns in UMAP shows that, as expected, the model does not know how to extract useful information from “genome image” when predicting randomized cancer type (as when randomly shuffling the labels there is no genomic information to decipher). Similar patterns were observed for Age, indicating that patient age cannot be determined from the multi-omics data. Conversely, when GENIUS was trained against wGII, TP53, metastatic status, and cancer type, we observed that samples clustered according to the output label.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>In this manuscript, Birkbak and colleagues use a novel approach to transform multi-omics datasets in images and apply Deep Learning methods for image analysis. Interestingly they find that the spatial representation of genes on chromosomes and the order of chromosomes based on 3D contacts leads to best performance. This supports that both 1D proximity and 3D proximity could be important for predicting different phenotypes. I appreciate that the code is made available as a github repository. The authors use their method to investigate different cancers and identify novel genes potentially involved in these cancers. Overall, I found this study important for the field.</p>
<p>The major points of this manuscript could be grouped in three parts:</p>
<p>1. While the authors have provided validation for their model, it is not always clear that best approaches have been used.</p>
<p>a) In the methods there is no mention of a validation dataset. I would like to see the authors training on a cancer from one cohort and predict on the same cancer from a different cohort. This will convince the reader that their model can generalise. They do something along those lines for the bladder cancer, but no performance is reported. At the very least they should withhold a percentage of the data for validation. Maybe train on 100 and validate on the remaining 300 samples. They might have already done something along these lines, but it was not clear from the methods.</p>
</disp-quote>
<p>Apologize for not being sufficiently clear in the manuscript. We did indeed validate the performance within the TCGA cohort, using holdout cross validation. Here, we trained the network on 75% of the cohort samples (N = 3825), and tested on the remaining 25% (N = 1276).</p>
<p>To make this more clear, we have rewritten section “GENIUS classification identifies tumors likely to become metastatic” as such:</p>
<p>&quot;The omics data types included somatic mutations, gene expression, methylation, copy number gain and copy number loss. Using holdout type cross-validation, where we split the data into training (75%) and validation (25%), we observed a generally high performance of GENIUS, with a validation AUC of 0.83 for predicting metastatic disease (Figure 2B).&quot;</p>
<p>We also added the following sentence in the legend of Figure 2:</p>
<p>&quot;The x-axis represents epochs and y-axis represents AUC score of fixed 25% data we used for accuracy assessment within TCGA cohort.&quot;</p>
<p>The accuracy of GENIUS could not be validated on the other two bladder cohorts since they do not contain all the data for the creation of five-dimensional genome images. However, we were able to investigate if the genes with the highest attribution scores towards metastatic bladder cancer obtained based on the TCGA samples also showed a significant association with poor outcome in the two independent bladder cancer cohorts. Here, we observed that of the top 10 genes with the highest attribution scores, 5 were associated with poor outcome in the early stage bladder cancer cohort, and 7 were associated with poor outcome in the late stage/metastatic bladder cancer cohort.</p>
<disp-quote content-type="editor-comment">
<p>b) It was not clear how they used &quot;randomised cancer types as the negative control&quot;. Why not use normal tissue data or matched controls?</p>
</disp-quote>
<p>In the study, we built six models, one for each variable of interest. One of them was cancer type which performed quite well. In order to assess the model on randomized data, we randomized the labels of cancer type and tried predicting that. This served as “negative control” since we expected the model to perform poorly in this scenario. To make this more clear in the manuscript, we have expanded the description in the main text. We have also added the description of this to each supplementary plot to clarify this further.</p>
<p>While normal tissue and matched controls would have been an optimal solution, unfortunately, such data is not available.</p>
<disp-quote content-type="editor-comment">
<p>c) If Figure 2B, the authors claim they have used cross validation. Maybe I missed it, but what sort of cross validation did they use?</p>
</disp-quote>
<p>We apologize for not being sufficiently clear. As described above, we used holdout cross-validation to train and evaluate the model. We clarified this in the text:</p>
<p>&quot;Using holdout type cross-validation, where we split the data into training (80%) and validation
(20%), we observed a generally high performance of GENIUS, with a mean validation AUC of
0.83 (Figure 2B)&quot;</p>
<disp-quote content-type="editor-comment">
<p>1. Potential improvement to the method</p>
<p>a) It is very encouraging the use of HiC data, but the authors used a very coarse approach to integrate it (by computing the chromosome order based on interaction score). We know that genes that are located far away on the same chromosome can interact more in 3D space than genes that are relatively close in 1D space. Did the authors consider this aspect? Why not group genes based on them being located in the same TAD?</p>
</disp-quote>
<p>We thank the reviewer for this suggestion and we will start looking into how to use TAD information to create another genome representation. In this study, we tried several genome transformations, which proved to be superior compared to a flat vector of features (no transformation). We are aware that squared genome transformation might not be optimal, so we designed the network that reconstructs the genome image during the training. This way, the genome image is optimized for the output variable of choice by the network itself. However, we note that the order of the genes themselves, while currently based on HiC, can be changed by the user. The order is determined by a simple input file which can be changed by the user with the argument “all_genes_included”. Thus, different orderings can be tested within the overall square layout. This is now detailed in the instructions on the new GitHub page.</p>
<p>The convolutional neural network uses a kernel size of 3x3, which captures the patterns of genes positioned close to each other but also genes that are far away from each other (potentially on another chromosome). Once convolutions extract patterns from the image, the captured features are used in a feed-forward neural network that makes a final prediction using all extracted features/patterns regardless of their location in the genome image.</p>
<p>We also inserted the following sentence in discussion:</p>
<p>&quot;Given that spatial organization improved the prediction, we recognize that there may exist a more optimal representation of multi-omics data which should be explored further in future work. Potential methods for organizing gene orientation in a 2D image could consider integrating topologically associating domains[39] along with the spatial information from HiC. This is already possible to explore with the current implementation of GENIUS, where gene layout can be set manually by the user.&quot;</p>
<disp-quote content-type="editor-comment">
<p>b) Authors claim that &quot;given that methylation negatively correlates with gene expression, these were considered together&quot;. This is clearly not always the case. See for example <ext-link ext-link-type="uri" xlink:href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02728-5">https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02728-5</ext-link>. What would happen if they were not considered together?</p>
</disp-quote>
<p>We thank the reviewer for this insightful comment. We agree with the reviewer that methylation does not always result in lower expression, although methylation levels in most cases should correlate negatively to RNA expression, but with a gene-specific factor. Indeed, there are tools developed that infer RNA expression based on methylation, making use of gene-specific correction factors. E.g. Mattesen et al (Mattesen, Andersen, and Bramsen 2021).</p>
<p>However, upon reflection we agree with the reviewer that we cannot assume for all genes that methylation equals low expression. Therefore, we have performed an analysis where we compared the methylation level to gene expression levels for all tested genes within bladder cancer. We computed Pearson’s correlation of 16,456 genes that have both methylation and expression scores. Of these, 8528 showed a negative correlation. After p-value correction, this resulted in 4774 genes where methylation was significantly negatively associated with expression. For these genes we performed the subsequent analysis in bladder cancer, where methylation and expression were considered together. This updated analysis has been included in supplementary figure 10, and the results section has been amended to reflect this. Overall, this analysis resulted in 4 of 10 genes being replaced in the downstream analysis. However, we note that the final results did not materially change, nor did the conclusions.</p>
<fig id="sa3fig2">
<label>Author response image 2.</label>
<caption>
<title>Correlation between gene-level methylation and gene expression in TCGA BLCA cohort</title>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-87133-sa3-fig2.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>1. Interesting results that were not explained.</p>
<p>a) In Figure 3A methylation seems to be the most important omics data, but in 3B, mutations and expression are dominating. The authors need to explain why this is the case.</p>
</disp-quote>
<p>We apologize for not explaining this in more detail. Figure 3B shows the attribution scores scaled within the cancer type, where Figure 3A shows raw attribution scores for each data source included. The reason for this is that methylation and expression have in general, smaller attribution scores but more events where a single mutation often is characterized with large attribution scores and the rest of them with very small attribution. In order to make those numbers comparable and take into account biological differences between the cancer type, we scaled the scores within each cancer type.</p>
<p>To make this more clear we modified the first sentence in “Interpreting the GENIUS model classifying metastatic cancer biology” section:</p>
<p>&quot;Analysing raw attribution scores we concluded the most informative data type overall regarding the development of metastatic disease was methylation (Figure 3A).
…We also noticed that mutation data often had a single mutation with large attribution score where expression and methylation showed multiple genes with high attribution scores… … The normalization step is crucial to make results comparable as underlying biology is different in each cancer type included in the study.&quot;</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<list list-type="bullet">
<list-item><p>While I appreciate the creative acronym of the presented software solution (GENIUS), it may easily be confused with the prominent software Geneious | Bioinformatics Software for Sequence Data Analysis which is often employed in molecular life science research. I would suggest renaming the tool.</p>
</list-item></list>
</disp-quote>
<p>We appreciate the comment but prefer to keep the name. Given that the abbreviation is not exactly the same and the utility is different, we are confident that there will be no accidental mixup between these tools.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>A huge red flag is the evaluation of the input image design which clearly shows that classification power after training is insufficient for three out of four image layouts (and even for the fourth AUC is between 0.70-0.84 depending on the pipeline step and application). Could the authors please clarify why this isn't cherry-picking (we use the one layout that gave some form of results)? In light of the poor transformation capacity of this multi-omics data onto images, why weren't other image layouts tried and their classification performance assessed? Why should a user assume that this image layout that worked for this particular input dataset will also work with other datasets if image transformation is performing poorly in most cases?</p>
</list-item></list>
</disp-quote>
<p>We apologize for not describing this further in the manuscript. We wrote in the manuscript that we could not know what genome representation is optimal as it is difficult to know. A flat vector represents a simple (or no) transformation since we simply take all of the genes from all of the data sources and append them into a single list. Chromosome image and square image are two transformations we tried, and we focused on the square image since in our hands it showed superior performance relative to other transformations.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>Minor points:</p>
<p>1. Legends of supplementary Figures are missing.</p>
</disp-quote>
<p>We thank the reviewer for this comment and apologize for missing it. All legends have been added now.</p>
<disp-quote content-type="editor-comment">
<p>1. For some tests the authors use F1 score while for other AUC, they should be consistent. Report all metrics for all comparisons or report one and justify why that only metric.</p>
</disp-quote>
<p>We apologize for not being sufficiently clear. AUC is a standard score used for binary classification, while the F1 score is used for multiclass classification. We have now described this in the methods section, and hope this is now sufficiently clear.</p>
<p>&quot;When predicting continuous values, the model used the output from the activation function with the mean squared error loss function. When predicting multi-class labels, the performance measure was defined by the F1 score, a standard measure for multiclass classification that combines the sensitivity and specificity scores and is defined as the harmonic mean of its precision and recall. To evaluate model performance against the binary outcome, ROC analysis was performed, and the area under the curve (AUC) was used as the performance metric.&quot;</p>
<disp-quote content-type="editor-comment">
<p>1. not sure how representation using UMAP in Figure 2C is helping understand the performance.</p>
</disp-quote>
<p>Apologies for the poor wording in the results section. The purpose of the UMAP representation was to visually inspect if the model was distinguishing between variables of interest, not to estimate model performance. We have rephrased the text in the methods section to make this clear:</p>
<p>&quot;After successful model training, we extracted the latent representations of each genome and performed the Uniform Manifold Approximation and Projection (UMAP) of the data for the purpose of visual inspection of a model.&quot;</p>
<p>And</p>
<p>&quot;In order to avoid modeling noise, this step was used to inspect if the model is distinguishing between variables of interest.&quot;</p>
<p>And also in the results section:</p>
<p>&quot;In order to visually inspect patterns captured by the model, we extracted the latent representations of each genome and performed the Uniform Manifold Approximation and Projection (UMAP) of the data to project it into two dimensions.&quot;</p>
<disp-quote content-type="editor-comment">
<p>1. Instead of pie chart in 3A, the authors should plot stacked barplots (to 100%) so it would be easier to compare between the different cancer types.</p>
</disp-quote>
<p>We thank the reviewer for the suggestion; however, since we wanted to compare the relative impact of each data source with each other, we used pie charts. Piecharts are often better for describing relative values, whereas bar plots are better for absolute values.</p>
<p>References</p>
<p>Du, Ruishan, Wenhao Liu, Xiaofei Fu, Lingdong Meng, and Zhigang Liu. 2022. “Random Noise Attenuation via Convolutional Neural Network in Seismic Datasets.” Alexandria Engineering Journal 61 (12): 9901–9.</p>
<p>Jang, Hojin, Devin McCormack, and Frank Tong. 2021. “Noise-Trained Deep Neural Networks Effectively Predict Human Vision and Its Neural Responses to Challenging Images.” PLoS Biology 19 (12): e3001418.</p>
<p>Mattesen, Trine B., Claus L. Andersen, and Jesper B. Bramsen. 2021. “MethCORR Infers Gene
Expression from DNA Methylation and Allows Molecular Analysis of Ten Common Cancer Types Using Fresh-Frozen and Formalin-Fixed Paraffin-Embedded Tumor Samples.” Clinical Epigenetics 13 (1): 20.</p>
</body>
</sub-article>
</article>