<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">100287</article-id>
<article-id pub-id-type="doi">10.7554/eLife.100287</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100287.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Stimulus representation in human frontal cortex supports flexible control in working memory</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-0886-4606</contrib-id>
<name>
<surname>Shao</surname>
<given-names>Zhujun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">3</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-9197-1698</contrib-id>
<name>
<surname>Zhang</surname>
<given-names>Mengya</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8480-7634</contrib-id>
<name>
<surname>Yu</surname>
<given-names>Qing</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>qingyu@ion.ac.cn</email>
</contrib>
    <aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00vpwhm04</institution-id><institution>Institute of Neuroscience, Key Laboratory of Brain Cognition and Brain-inspired Intelligence Technology, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences</institution></institution-wrap>, <city>Shanghai</city>, <country>China</country></aff>
    <aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qbk4x57</institution-id><institution>University of Chinese Academy of Sciences</institution></institution-wrap>, <city>Beijing</city>, <country>China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Xue</surname>
<given-names>Gui</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>3</label><p>These authors contributed equally</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-09-03">
<day>03</day>
<month>09</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-01-07">
<day>07</day>
<month>01</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP100287</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-06-06">
<day>06</day>
<month>06</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-07">
<day>07</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.28.551058"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-09-03">
<day>03</day>
<month>09</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100287.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.100287.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.100287.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.100287.1.sa0">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.100287.1.sa3">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>Â© 2024, Shao et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Shao et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-100287-v2.pdf"/>
<abstract>
<title>Abstract</title><p>When holding visual information temporarily in working memory (WM), the neural representation of the memorandum is distributed across various cortical regions, including visual and frontal cortices. However, the role of stimulus representation in visual and frontal cortices during WM has been controversial. Here we tested the hypothesis that stimulus representation persists in the frontal cortex to facilitate flexible control demands in WM. During functional MRI, participants flexibly switched between simple WM maintenance of visual stimulus or more complex rule-based categorization of maintained stimulus on a trial-by-trial basis. Our results demonstrated enhanced stimulus representation in the frontal cortex that tracked demands for active WM control and enhanced stimulus representation in the visual cortex that tracked demands for precise WM maintenance. This differential frontal stimulus representation traded off with the newly-generated category representation with varying control demands. Simulation using multi-module recurrent neural networks replicated human neural patterns when stimulus information was preserved for network readout. Altogether, these findings help reconcile the long-standing debate in WM research, and provide empirical and computational evidence that flexible stimulus representation in the frontal cortex during WM serves as a potential neural coding scheme to accommodate the ever-changing environment.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>visual working memory</kwd>
<kwd>cognitive flexibility</kwd>
<kwd>frontal cortex</kwd>
<kwd>visual cortex</kwd>
<kwd>fMRI</kwd>
<kwd>recurrent neural network</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>new analyses, results, figures, and text added.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Real-world flexible behavior relies largely on working memory (WM), which allows the maintenance and manipulation of information in the brain in order to serve diverse behavioral goals (<xref ref-type="bibr" rid="c2">Baddeley, 2003</xref>). One central problem in the field of WM is to understand how stimulus information is represented and maintained in WM. Over the past decade, mounting evidence has demonstrated stimulus-specific representation during WM maintenance in a distributed cortical network, including sensory, parietal, and frontal cortices (<xref ref-type="bibr" rid="c11">Christophel et al., 2012</xref>; <xref ref-type="bibr" rid="c22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c31">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="c34">Harrison &amp; Tong, 2009</xref>; <xref ref-type="bibr" rid="c53">Riggall &amp; Postle, 2012</xref>; <xref ref-type="bibr" rid="c54">Serences et al., 2009</xref>; <xref ref-type="bibr" rid="c57">Sprague &amp; Serences, 2013</xref>; <xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>, <xref ref-type="bibr" rid="c62">2019</xref>). However, the exact nature and functions of stimulus representation in different cortical regions remain controversial. Specifically, while neurophysiological studies in non-human primates have mostly emphasized stimulus representation in the frontal cortex (<xref ref-type="bibr" rid="c27">Funahashi et al., 1989</xref>; <xref ref-type="bibr" rid="c29">Fuster &amp; Alexander, 1971</xref>; <xref ref-type="bibr" rid="c38">Leavitt et al., 2017</xref>), neuroimaging work in humans has reported disparate findings. During maintenance of simple visual features, stimulus representation is robustly encoded in the early visual cortex (EVC), which has been taken as the evidence in support of the sensorimotor recruitment hypothesis of WM (<xref ref-type="bibr" rid="c34">Harrison &amp; Tong, 2009</xref>; <xref ref-type="bibr" rid="c53">Riggall &amp; Postle, 2012</xref>; <xref ref-type="bibr" rid="c54">Serences et al., 2009</xref>). Meanwhile, those in the higher-order frontoparietal cortex are typically weaker and less stable (<xref ref-type="bibr" rid="c19">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="c31">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="c53">Riggall &amp; Postle, 2012</xref>; <xref ref-type="bibr" rid="c62">Yu &amp; Shim, 2019</xref>). However, in dynamic environments such as those involving distraction, stimulus representation in EVC could be greatly interrupted or biased (<xref ref-type="bibr" rid="c6">Bettencourt &amp; Xu, 2016</xref>; <xref ref-type="bibr" rid="c33">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c42">Lorenc et al., 2018</xref>). In contrast, stimulus representation in the frontal cortex could be robust under certain circumstances including attentional prioritization (<xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>), categorization (<xref ref-type="bibr" rid="c39">Lee et al., 2013</xref>) and after extensive training (<xref ref-type="bibr" rid="c48">Miller et al., 2022</xref>). To summarize, stimulus representation could vary markedly depending on specific brain regions and memory tasks, complicating the interpretation of potential functions of stimulus representation in WM.</p>
<p>In this study, we consider these apparent discrepancies from the perspective of cognitive flexibility (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c28">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="c50">Musslick &amp; Cohen, 2021</xref>). We propose that changes in stimulus representation in different cortical regions might reflect a global reconfiguration in coding strategy and resource allocation in response to varied WM functions (<xref ref-type="bibr" rid="c35">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="c39">Lee et al., 2013</xref>). To elaborate, beyond the passive maintenance of incoming sensory information, WM provides an online mental workspace for active manipulation and control of stimulus contents (<xref ref-type="bibr" rid="c2">Baddeley, 2003</xref>; <xref ref-type="bibr" rid="c47">Miller &amp; Cohen, 2001</xref>). As control functions often result in the generation and maintenance of new information, the brain needs to manage not only the original stimulus information but also the newly generated information in WM. Due to the limited cognitive resources available, it is likely that original stimulus representation in WM could adapt flexibly to various task goals beyond simple maintenance of WM contents, which might also co-vary with changes in the representation of the newly-generated information, leading to a systematic reconfiguration in representations of all levels across various cortices. We make two specific predictions from this account. First, in accordance with the findings of elevated neural activity in the frontal cortex with increasing demand for memory manipulation (<xref ref-type="bibr" rid="c17">DâEsposito et al., 1999</xref>; <xref ref-type="bibr" rid="c18">DâEsposito et al., 2000</xref>) and cognitive control (<xref ref-type="bibr" rid="c3">Badre, 2008</xref>; <xref ref-type="bibr" rid="c5">Badre et al., 2010</xref>; <xref ref-type="bibr" rid="c47">Miller &amp; Cohen, 2001</xref>), stimulus representation in frontal cortex should be enhanced for active-control-related functions in WM. By contrast, due to the precise nature of stimulus representation in visual cortex, stimulus representation in this region should be enhanced for precise-maintenance-related functions in WM (<xref ref-type="bibr" rid="c35">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="c39">Lee et al., 2013</xref>). Second, within the brain regions that encode the newly generated information, a dynamic tradeoff between representations of original and new information should be observed to achieve flexible allocation of limited cognitive resources (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c24">Flesch et al., 2022</xref>).</p>
<p>Using functional magnetic resonance imaging (fMRI), we directly tested this account by systematically investigating stimulus representation in visual, parietal, and frontal cortices during WM tasks with varying demands for active control. In particular, we surmised that stimulus representation in the frontal cortex would increase to accommodate complex control demands such as rule-based categorization. To this end, we employed a visual WM paradigm that required flexible switching between maintenance and categorization tasks. Specifically, in the maintenance task, participants maintained one visual orientation throughout a delay period, whereas in the categorization task participants were required to categorize the remembered orientation into one of two categories in accordance with previously learned rules, which could be either switched randomly between two rules on a block-by-block basis (Experiment 1) or fixed with one rule (Experiment 2). Thus, compared with the maintenance task, the categorization task imposed additional control demand of WM information at two different levels: the first level of control being stimulus categorization, because participants needed to adapt the stimulus based on the categorization rule in working memory for subsequent category judgements; the second level of control being flexibility of rules, because with two categorization rules, the flexibility in control increased.</p>
<p>In line with our prediction, our results showed that stimulus information was more prominently represented in the frontal cortex during categorization than maintenance task, and this differential representation was enhanced with increasing demands for control. Importantly, the strength of stimulus representation in the frontal cortex was predictive of WM behavioral performance in the categorization but not in the maintenance task, implicating a selective involvement of the frontal cortex in control functions. By contrast, stimulus representation in the visual cortex was found to exhibit an opposite pattern, with higher strength for maintenance than for categorization task. Moreover, varying control demands across experiments revealed a dynamic tradeoff between stimulus and the newly-generated category representations. To further examine whether the enhanced stimulus representation in the frontal cortex during categorization task could be explained by global coding strategy, we simulated our flexible WM tasks with multi-module recurrent neural networks (RNNs). The results of this computational modeling well replicated our human data when precise stimulus information was preserved at the output during network training. Taken together, our results indicate the importance of the frontal cortex for flexible control in WM and highlight the relative changes of stimulus representation in different cortical regions for varying task demands of WM.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Behavioral learning and performance of WM tasks</title>
<p>In the fMRI session of Experiment 1, human participants (n = 24) completed two tasks, maintenance and categorization, inside an MRI scanner. The maintenance task was a delayed match-to-sample working memory task of orientations. Participants only needed to maintain the cued orientation throughout a memory delay. In categorization task, participants also started with maintaining an orientation. After the task cue, they needed to categorize the remembered orientation into one of two categories using the cued categorization rule. Within an experimental block of nine trials, participants randomly switched between the two tasks. Across blocks, participants randomly switched between two categorization rules acquired during a preceding learning session. We randomized response mapping across trials to avoid potential influence by motor-planning signals (see <xref rid="fig1" ref-type="fig">Figure 1A</xref> for probe design). Prior to the main session, participants first completed a behavioral learning session to learn two categorization rules (Rule A and Rule B, see <xref rid="fig1" ref-type="fig">Figure 1B</xref>) that were orthogonal to each other. Participants acquired the two rules with equal familiarity (<italic>t</italic>(23) = 0.24, <italic>p</italic> = 0.813; for Rule A, <italic>M</italic> = 0.85, <italic>SD</italic> = 0.050; for Rule B, <italic>M</italic> = 0.85, <italic>SD</italic> = 0.05; <xref rid="fig1" ref-type="fig">Figure 1C</xref>) and comparable precision (averaged error in reported boundaries for Rule A were 8.80Â° Â± 6.29Â° and that for Rule B was 9.02Â° Â± 5.69Â°; <xref rid="fig1" ref-type="fig">Figure 1D</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental design and behavioral performance.</title><p>(A) Main task procedure. Each block started with a rule cue indicating the categorization rule for this block. On each trial, participants saw two orientations consecutively and were then cued to remember one of the orientations. In maintenance task (cued by letter âPâ), participants needed to maintain the remembered orientation as precisely as possible. In categorization task (cued by letter âCâ), participants needed to categorize the remembered orientation following the categorization rule of the current block. Maintenance and categorization trials were interleaved within an experimental block of nine trials. Categorization rule (Rule A or Rule B) switched randomly on a block-by-block basis. Response keys (âFâ and âJâ) for categorization task were randomly assigned to the two categories. Each pair of keys displayed at random locations within the category to eliminate information on rule boundaries. (B) Illustration of the two orthogonal categorization rules (Rule A and Rule B). (C) Rule learning performance during learning session for Rule A (purple) and Rule B (pink). (D) Errors in participantsâ self-reported rule boundaries. Errors were calculated as the average distance from reported boundaries to ground truth boundaries. (E) Accuracy compared between tasks. Boxplots show the median and the 25<sup>th</sup> and 75<sup>th</sup> percentiles. Whiskers extend to 1.5 Inter quartile range (IQR) from the quartiles. Asterisks denote significant results, n.s.: not significant; **: <italic>p</italic> &lt; 0.01. (F) Reaction time compared between tasks. Same conventions as (E). (G) Upper panel: accuracy in relation to distance from categorization boundaries. Lower panel: reaction time in relation to distance from categorization boundaries. Shaded areas represent Â± SEM.</p></caption>
<graphic xlink:href="551058v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Overall, participants performed equally well on both tasks in the fMRI session. Accuracy for the maintenance task (<italic>M</italic> Â± <italic>SD</italic>: 0.81 Â± 0.07) and that for the categorization task (0.82 Â± 0.05) did not significantly differ (<italic>t</italic>(23) = 1.51, <italic>p</italic> = 0.144; <xref rid="fig1" ref-type="fig">Figure 1E</xref>), suggesting that the two tasks were matched in terms of task difficulty. In line with previous categorization studies demonstrating a boundary effect (<xref ref-type="bibr" rid="c23">Ester et al., 2020</xref>; <xref ref-type="bibr" rid="c25">Freedman &amp; Assad, 2006</xref>), only in the categorization task but not in the maintenance task did participants perform better for trials distant from category boundaries in terms of both accuracy and reaction time (see <xref rid="fig1" ref-type="fig">Figure 1G</xref>). These results demonstrated the effect of categorization and confirmed that participants faithfully followed task instructions.</p>
</sec>
<sec id="s2b">
<title>Enhanced stimulus representation in frontal cortex during categorization task</title>
<p>The primary goal of this study was to determine the role of stimulus representation in various cortices in WM. Using conventional multivariate encoding and decoding methods, we tracked stimulus (i.e., orientation) representation in three brain regions of interest (ROIs) that have been implicated in representing WM information, including early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS) (<xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="c22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c33">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>), see <xref rid="figs1" ref-type="fig">Figure S1</xref> for a visualization of the anatomical locations of the ROIs.</p>
<p>First, we used multivariate inverted encoding models (IEMs) (<xref ref-type="bibr" rid="c9">Brouwer &amp; Heeger, 2009</xref>, <xref ref-type="bibr" rid="c10">2011</xref>; <xref ref-type="bibr" rid="c22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c52">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>) to reconstruct orientation representation at the population level in each ROI. <xref rid="fig2" ref-type="fig">Figure 2A</xref> shows example orientation reconstructions from representative time points. To quantify the strength of orientation reconstructions, we calculated the reconstruction fidelity by first projecting the channel response at each orientation onto a vector at the cued orientation and then averaging the projected vectors to obtain the representational fidelity (<xref ref-type="bibr" rid="c52">Rademaker et al., 2019</xref>). A larger fidelity value indicates a stronger positive representation of orientation (See <xref rid="fig2" ref-type="fig">Figure 2B</xref> for illustration). <xref rid="fig2" ref-type="fig">Figure 2C</xref> demonstrates the time course of orientation reconstruction as quantified by representational fidelity. Critically, by comparing the representational fidelity values within the same ROI across conditions (maintenance vs. categorization), we minimized the impact of effect size on our comparisons between ROIs, as all the comparisons were primarily performed within the same ROI with a comparable effect size. In EVC, we found significant orientation representation in both maintenance and categorization tasks starting from the sample period (<xref rid="fig2" ref-type="fig">Figure 2C</xref> left panel; see <xref rid="tbls1" ref-type="table">Supplemental Table 1</xref> for full statistics), even when the categorization task did not require explicit memory of stimulus information. Additionally, the strength of orientation representation in the maintenance task became significantly higher than that in the categorization task after the task cue during the delay, suggesting the strength of orientation representations in EVC reflected the degrees of task demands for maintaining visual details. In IPS, orientation representation was significant in both tasks, but did not differ from each other at most time points (<xref rid="fig2" ref-type="fig">Figure 2C</xref> middle panel). In sPCS, a reversed pattern was observed. In the maintenance task, orientation information was maintained during early delay period and then dropped to baseline level during late delay period. By contrast, in the categorization task, orientation representation was persistent throughout the delay and response periods. The strength of orientation representation in the categorization task became statistically higher than that in the maintenance task in late delay period (<xref rid="fig2" ref-type="fig">Figure 2C</xref> right panel), suggesting that this differential representations of visual stimulus in the frontal cortex reflected the demand for active control of memory contents. To facilitate comparison of the differential stimulus representation across ROIs, we averaged the difference in representational strength across a late task epoch (11 â 16 s), and the difference in stimulus representation between ROIs remained (<xref rid="fig2" ref-type="fig">Figure 2D</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Orientation reconstructions at the population level using IEMs.</title><p>(A) Reconstructed population-level orientation representations from selected time points at EVC, IPS, and sPCS for maintenance (blue) and categorization (orange) tasks, respectively. X axis represents distance from the cued orientation (at 0Â°), and y axis represents reconstructed channel responses in arbitrary units. Significant orientation representation was observed at 6 s and 12 s but not at 0 s. Shaded areas represent Â± SEM. (B) To quantify the strength of orientation reconstructions, we calculated the reconstruction fidelity by first projecting the channel response at each orientation onto a vector at the cued orientation and then averaging the projected vectors. (C) Time course of representational strength of orientations at EVC, IPS and sPCS. Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent Â± SEM. (D) Average difference of representational strength across 11 â 16 s in each ROI (from EVC to sPCS: <italic>p</italic> &lt; 0.00001, <italic>p</italic> = 0.063, <italic>p</italic> = 0.007, respectively). Positive difference indicates higher representational strength for categorization, and vice versa for negative difference. Black asterisks denote FDR-corrected significance, **: <italic>p</italic> &lt; 0.01; ***: <italic>p</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="551058v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We validated the difference in stimulus representations through a series of control analyses. First, we demonstrated that these results cannot be explained by the specific model used to train the data (<xref ref-type="bibr" rid="c41">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="c56">Sprague et al., 2018</xref>) nor the specific analytical approach used, because similar patterns were observed when we trained the IEM separately for each condition (<xref rid="figs2" ref-type="fig">Figure S2A</xref>) or adopted a Support Vector Machine (SVM) decoding approach (<xref rid="figs2" ref-type="fig">Figure S2B</xref>) (<xref ref-type="bibr" rid="c35">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="c52">Rademaker et al., 2019</xref>). Mean activation differences between tasks cannot account for the results either, because when we removed the mean differences in BOLD activity between tasks, the difference in representational strength remained (<xref rid="figs2" ref-type="fig">Figure S2C</xref>). Furthermore, to remove the potential impact of voxel number on IEM, we selected the top 500 of most sample- or delay-selective voxels from each ROI and trained IEM using the selected voxels. Again, this analysis yielded similar findings (<xref rid="figs2" ref-type="fig">Figure S2D</xref>). Lastly, when repeating the IEM analyses in primary motor cortex (M1), no similar patterns were observed, suggesting that our results cannot be explained by motor- or response-related activity (<xref rid="figs3" ref-type="fig">Figure S3</xref>).</p>
<p>Together, these results demonstrated enhanced stimulus representation in the frontal cortex with increased demand for active control, as well as those in the visual cortex with increased demand for precise WM maintenance.</p>
</sec>
<sec id="s2c">
<title>Prediction of categorization behavior by frontal stimulus representation</title>
<p>Previous WM studies have shown that the strength of stimulus representation in EVC positively correlated with memory performance (<xref ref-type="bibr" rid="c19">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="c21">Ester et al., 2013</xref>; <xref ref-type="bibr" rid="c31">Gosseries et al., 2018</xref>), suggesting that EVC plays an important role in precise WM maintenance. However, stimulus representation in the frontal cortex rarely predicted behavioral performance in maintenance task (<xref ref-type="bibr" rid="c33">Hallenbeck et al., 2021</xref>), although univariate activation in the same brain region can predict memory-guided saccade performance (<xref ref-type="bibr" rid="c15">Curtis et al., 2004</xref>). Nevertheless, if frontal stimulus representation is involved in WM control, its behavioral relevance should be subject to observation with increased control demands. Therefore, we assessed the behavioral predictability of stimulus representation during the delay period in EVC, IPS, and sPCS. <xref rid="fig3" ref-type="fig">Figure 3A</xref>, 3B, and 3C illustrate the time course of correlation results, results from representative time points, and results collapsed across the late epoch, respectively. Consistent with previous findings, we found the strength of stimulus representation in EVC during the early delay period predicted behavioral accuracies in both maintenance and categorization tasks (see <xref rid="tbls2" ref-type="table">Supplemental Table 2</xref> for full statistics). Similar predictability was found in IPS, with stimulus representation predicted behavior in the maintenance task during early delay and in the categorization task throughout the entire memory delay. Interestingly, we found that, throughout the entire memory delay, the strength of stimulus representation in sPCS predicted behavioral accuracies only in the categorization task but not in the maintenance task. These results highlighted the functional significance of stimulus representation in sPCS exclusively for the categorization task.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Behavioral correlation of stimulus representation for maintenance (blue) and categorization (orange) tasks.</title><p>(A) Time course of correlation coefficients between behavioral performance and orientation representational fidelity in EVC, IPS, and sPCS. Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the top indicate significance of correlation (uncorrected) at each time point at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). (B) Correlation scatter plots at representative time points (7 s and at 12 s) in EVC, IPS, and sPCS. R denotes Pearson correlation coefficients. (C) Correlation between behavioral performance and orientation representational fidelity collapsed across the late epoch (11 â 16 s). Asterisks denote significant results, *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01.</p></caption>
<graphic xlink:href="551058v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2d">
<title>Reduced frontal stimulus representation with lower control demand</title>
<p>In Experiment 1, participants flexibly switched between two categorization rules to prompt the manipulation of WM content on a trial-by-trial basis. The rule switching increased control demand but also complicated the interpretation of our results. To exclude potential impact of rule switching, we conducted Experiment 2, in which participants performed maintenance and categorization tasks with only one fixed rule. Behavioral results of Experiment 2 again demonstrated a classic boundary effect and were comparable to Experiment 1, with no significant difference between experiments in terms of either accuracy or reaction time (<italic>F</italic>s &lt; 1.28, <italic>p</italic>s &gt; 0.26; <xref rid="figs4" ref-type="fig">Figure S4</xref>). When using IEMs to reconstruct stimulus representation, we found EVC and IPS both showed patterns similar to those in Experiment 1 (<xref rid="fig4" ref-type="fig">Figure 4A</xref> left and middle panels), with stimulus representation decreased in EVC in categorization task and remained at the same level in IPS between the two tasks (see <xref rid="tbls3" ref-type="table">Supplemental Table 3</xref> for full statistics). The frontal region, sPCS, also showed a differential enhancement of stimulus representation in categorization task as in Experiment 1, but in an earlier period (<xref rid="fig4" ref-type="fig">Figure 4A</xref> right panel). To validate such a temporal difference, we defined an additional early task epoch (5 â 10 s), and confirmed a significant difference in stimulus representation in sPCS during the early (<italic>p</italic> = 0.015; <xref rid="fig4" ref-type="fig">Figure 4B</xref>) but not during the late epoch (<italic>p</italic> = 0.372; <xref rid="fig4" ref-type="fig">Figure 4C</xref>). In addition, we performed a mixed ANOVA on experiments (Experiment 1 vs. 2) and epochs (early vs. late epoch) and observed a significant interaction effect between the two, <italic>F</italic>(1, 46) = 7.43, <italic>p</italic> = 0.009, suggesting that the two experiments differed in terms of the temporal emergence of the differential stimulus representation in the frontal cortex. Taken together, these results are consistent with our expectation that, with reduced control demand, the differential enhancement of stimulus representation in frontal cortex was still present but decreased during late memory delay. Nevertheless, stimulus representation in Experiment 2 still predicted behavioral performance as in Experiment 1, although the difference between task was reduced (<xref rid="figs5" ref-type="fig">Figure S5</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Orientation reconstructions in Experiment 2 at the population level using IEMs.</title><p>(A) Time course of representational strength of orientations at EVC, IPS and sPCS. Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent Â± SEM. (B) Average difference of representational strength across an early (top, 5 â 10 s) and a late (bottom, 11 â 16 s) task epoch in each ROI. Positive difference indicates higher representational strength for categorization, and vice versa for negative difference (FDR-corrected). *: <italic>p</italic> &lt; 0.05; ***: <italic>p</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="551058v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2e">
<title>Category representation in WM in various cortices</title>
<p>Having observed a differential representation of stimulus in the frontal cortex, we next asked how newly generated information in WM during the categorization task emerged and sustained in the distributed WM network and how representations of the original stimulus and new information interacted. The categorization task could demand additional generation of category information in WM. We therefore trained SVMs to decode category information during the categorization task. For each rule, the SVM decoder was trained to discriminate between the two categories. In both experiments, we found that during the late epoch, category information could be well decoded across ROIs (<italic>ps</italic> &lt; 0.044, <xref rid="fig5" ref-type="fig">Figure 5A</xref>; also see <xref rid="figs6" ref-type="fig">Figure S6A</xref> for full decoding time course), with a marginal difference between experiments in sPCS (<italic>p</italic> = 0.055).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Decoding performance for category and abstract category information.</title><p>(A) Average category decoding accuracy using category labels under true rule across the late task epoch (11 â 16 s) in each ROI of both experiments. (B) Average category decoding accuracy using category labels under orthogonal rule across the late task epoch (11 â 16 s) in each ROI of both experiments. (C) Schematic illustration of abstract category decoding. In categorization task, category information can be decoded using category labels according to the true categorization rule. On the other hand, category can also be decoded due to stimulus similarity. Thus, to remove stimulus-dependent categorical information, we calculated an abstract category index by removing decoding accuracy using orthogonal category boundaries (assuming comparable stimulus-dependent effect) from that using true rule boundaries. (D) Average abstract category decoding index across the late task epoch (11 â 16 s) in each ROI of both experiments. Black asterisks denote FDR-corrected significance, *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01; ***: <italic>p</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="551058v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>One might argue that the category decoding results could at least be partially attributed to stimulus similarity. To minimize the impact of stimulus similarity on category decoding, we additionally trained another decoder using the opposite rule (i.e., using category labels from the orthogonal rule; see <xref rid="fig5" ref-type="fig">Figure 5B</xref> for results). We then calculated an abstract category index by subtracting decoding accuracy under the opposite rule from that under the true rule (<xref ref-type="bibr" rid="c49">Mok &amp; Love, 2020</xref>) (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). The rationale was that the amount of stimulus similarity would be comparable for the opposite rule, but additional category information, if existed, should result in higher decoding accuracy for the true rule. In other words, positive abstract category index indicates evidence for stimulus-independent category representation. After removing stimulus-related signals, average decoding performance of abstract category was only evident in Experiment 2 (<italic>p</italic>s &lt; 0.017) but not in Experiment 1 (<italic>p</italic>s &gt; 0.14) for all ROIs. Moreover, decoding performance of abstract category was significantly higher in Experiment 2 than Experiment 1 in sPCS (<italic>p</italic> = 0.034; <xref rid="fig5" ref-type="fig">Figure 5D</xref>). These results together suggest a potential tradeoff between stimulus difference and category representation in the frontal cortex.</p>
<p>Lastly, for completeness, we repeated the IEM and category decoding analyses on additional ROIs in the frontal cortex, to investigate whether the observed results were specific to sPCS. Specifically, we defined three additional ROIs based on the HCP atlas (<xref ref-type="bibr" rid="c30">Glasser et al., 2016</xref>), including the inferior precentral sulcus (iPCS), inferior frontal sulcus (IFS), and middle frontal gyrus (MFG) (<xref ref-type="bibr" rid="c22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c44">Mackey et al., 2017</xref>; <xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>). Overall, results in the three ROIs were comparably weaker than sPCS (<xref rid="figs7" ref-type="fig">Figure S7</xref>). There was some indication that the MFG might share some results for orientation representation and category decoding, although this pattern was weaker and was only observed in some analyses in Experiment 2.</p>
</sec>
<sec id="s2f">
<title>Differential stimulus representation in frontal cortex replicated by RNN modeling</title>
<p>Finally, we tested how stimulus representation could emerge in frontal cortex at the mechanistic level using recurrent neural network (RNN) models. Our hypothesis is that precise stimulus representation during WM might emerge in frontal cortex in response to complex task demands such as rule-based categorization. In other words, instead of relying (solely) on category representations, the cortical network might have adopted a different strategy to accommodate the flexible task requirements in the current study, for instance, by preserving stimulus information until a later stage of information processing. This different strategy can be implemented by altering the RNNâs output structure. Therefore, the logic of this modeling analysis was to examine whether explicitly placing a demand for the model to preserve stimulus representation would recapitulate our fMRI findings in frontal cortex, in comparison to a model that did not specify such a demand.</p>
<p>Two types of modular RNNs were trained on the maintenance and categorization tasks simultaneously (<xref ref-type="bibr" rid="c45">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="c63">Zhou et al., 2021</xref>). The networks shared common input and hidden layer structures (i.e., orientation-tuned and retro/task cue-related units as the input layer, recurrent units with short-term synaptic plasticity in the hidden layer [80% excitatory + 20% inhibitory units, equally distributed in three separate modules]). The only difference was in the structure of the output layer. The first type of RNN (RNN1; n = 20) had only two units in the output layer to indicate networksâ choice (<xref rid="fig6" ref-type="fig">Figure 6A</xref>), whereas the second type of RNN (RNN2; n = 20) had additional units in the output layer corresponding to the original stimulus information. In other words, the second RNN was designed to maintain stimulus information throughout the network modules. For the common hidden layer, we included three hierarchically organized (posterior, middle, and anterior) modules of recurrent units generated according to neurobiological principles of neuronal connections (e.g., denser connectivity within than between modules) to simulate the interconnected brain areas in our ROI-based fMRI analyses above: the posterior module (Module 1, simulating EVC) was directly connected with the input layer, the middle module (Module 2, simulating IPS) received projections from the posterior module and relaying information to the anterior module, and the anterior module (Module 3, simulating sPCS) projected to the output layer. Task events were simulated as numerical inputs to the model, matching the procedures of Experiment 1 (see Methods for details).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Architecture of RNNs and simulation results.</title><p>(A) All networks consist of 3 layers of artificial units: the input, hidden and output layers. For both RNN1 and RNN2, the input layer contains 20 units including 15 orientation-tuned units (red) and 5 cue units (retro-cue and task cue, orange and yellow). The hidden layer consists of three modules of 200 recurrent units with short-term synaptic plasticity (STSP), further divided into 80% excitatory (black) and 20% inhibitory (white). Connectivity within each module (black arrow) is denser compared to between modules (red and green arrows), which only occur between excitatory units. Only excitatory units in Module 1 receive projections from the input layer and only excitatory units in Module 3 project to the output units. For RNN1, networks output (0,1) or (1,0) through the 2 units in the output layer to indicate responses. For RNN2, the network output (0,1) or (1,0) to report the category to which the cued orientation belonged in the categorization task, or (0,0) in the maintenance task (blue units). Importantly, the models also output the orientation itself through 15 additional orientation-tuned units (red). (B) Difference in stimulus decoding between tasks in RNN1 (upper panel) and RNN2 (lower panel). Results were averaged across the delay period. Positive difference indicates higher decoding accuracy for categorization, and negative difference indicates higher decoding accuracy for maintenance. The inset above illustrates stimulus difference in human fMRI results during late epoch in Experiment 1 to provide a reference for expected patterns in RNNs. (C) Average abstract category information across the delay period for RNN1 (upper panel) and RNN2 (lower panel). The inset above illustrates abstract category representation in human fMRI. Error bars represent Â± SEM. Black asterisks denote FDR-corrected significance, *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01; ***: <italic>p</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="551058v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>After successful training, defined as reaching at least 90% accuracies in all tasks in the same training batch, we applied an SVM decoding approach to investigate population-level stimulus representations in neuronal spiking activities of the RNNs. We found that in RNN1, both the middle and anterior modules showed stronger stimulus representation in the maintenance task than the categorization task during the delay period (<italic>p<sub>posterior</sub></italic> = 0.09, <italic>p</italic><sub>middle</sub> = 0.011, <italic>p</italic><sub>anterior</sub> = 0.007; <xref rid="fig6" ref-type="fig">Figure 6B</xref> upper panel), opposite to our fMRI observation in IPS and sPCS (<xref rid="fig6" ref-type="fig">Figure 6B</xref> inset). In comparison, decoding performance in RNN2, which was explicitly required to maintain stimulus information for the output, yielded results consistent with our human findings, with increased stimulus decoding performance during categorization only in the anterior module (<italic>p</italic><sub>posterior</sub> = 0.436<italic>, p</italic><sub>middle</sub> = 0.212, <italic>p</italic><sub>anterior</sub> = 0.026; <xref rid="fig6" ref-type="fig">Figure 6B</xref> lower panel).</p>
<p>Besides the difference in stimulus representation, we further tested whether RNN2 could also replicate the human results on category representation. For this analysis we focused on abstract category representation to fully remove the impact of stimulus on category decoding. To examine the influence of control demand on category decoding, following our fMRI experiment we trained 20 additional RNNs with the same output structure as RNN2 (preserving stimulus information) to perform the tasks with a fixed categorization rule, mimicking the task structure of Experiment 2. Consistent with our human findings, we observed increased abstract category decoding performance in the fixed-rule models compared to the flexible-rule RNNs, throughout the modules (<italic>p<sub>posterior</sub> =</italic> 0.045<italic>, p</italic><sub>middle</sub> = 0.003, <italic>p</italic><sub>anterior</sub> &lt; 0.001; <xref rid="fig6" ref-type="fig">Figure 6C</xref> lower panel). Similar differences between fixed-rule and flexible-rule models were also observed in RNN1 (all <italic>p</italic>s &lt; 0.001; <xref rid="fig6" ref-type="fig">Figure 6C</xref> upper panel).</p>
<p>Altogether, these findings demonstrated that our fMRI results could be simulated by RNN models when stimulus information for readout was preserved, suggesting that the requirement for flexible control of WM content could demand high-fidelity stimulus representation at the output stage of the model. Notably, we found that RNN2 generally took fewer iterations for training and had fewer failures in learning the task (with a defined maximal number of iterations).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we investigated the emergence and maintenance of stimulus representation with varied control demands of WM. In a distributed human cortical network encompassing visual, parietal, and frontal cortex, we found enhanced stimulus representations in the frontal cortex that tracked increasing demands on active WM control, as well as enhanced stimulus representations in the visual cortex that tracked the demand for the precise maintenance of WM content. The enhanced stimulus representation in frontal cortex was well predicted by RNNs that preserved stimulus information for readout at the output stage. Together, these results highlight the unique and critical contributions of stimulus representations in different cortical regions for distinct aspects of WM, and help to resolve the current controversy in the roles of various cortices in WM.</p>
<sec id="s3a">
<title>Role of visual cortex in WM maintenance</title>
<p>The visual cortex has been considered a critical site for maintaining visual WM in the context of sensorimotor recruitment hypothesis (<xref ref-type="bibr" rid="c16">DâEsposito &amp; Postle, 2015</xref>; <xref ref-type="bibr" rid="c34">Harrison &amp; Tong, 2009</xref>). This idea, however, has been challenged in recent years due to some seemingly contradictory findings from the human neuroimaging studies. For example, compared to the frontoparietal cortex, mnemonic representations in EVC were found to be more vulnerable to distractors (<xref ref-type="bibr" rid="c6">Bettencourt &amp; Xu, 2016</xref>; <xref ref-type="bibr" rid="c33">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c42">Lorenc et al., 2018</xref>). The decodability of memory contents in visual cortex also depends on the specific task type. A previous study showed that in nonvisual tasks that required judgements on object category instead of visual details, memory contents were no longer decodable in the visual cortex (<xref ref-type="bibr" rid="c39">Lee et al., 2013</xref>). In this study, we found that, although the strength of stimulus representation in EVC differed between WM maintenance and categorization tasks, a copy of stimulus representation remained in EVC during the categorization task. Moreover, stimulus representations in both tasks were equally predictive of subsequent memory performance, suggesting the functional significance of EVC representations in WM.</p>
<p>The discrepancy between our results and that of the previous work (<xref ref-type="bibr" rid="c39">Lee et al., 2013</xref>) could be attributed to the fact that our categorization task required participants to manipulate remembered information according to arbitrary yet flexible categorization rules, rather than simply paying selective attention to different aspects (visual details vs. category membership) of everyday objects. In our case, maintaining visual details of the memoranda was critical for accurate behavioral responses. Our finding is consistent with the prediction of sensorimotor recruitment hypothesis that representation of memory contents in the visual cortex is necessary for the precise maintenance of visual information. The observation of robust category representation in EVC during the response period further indicated the recruitment of EVC in categorization, possibly for boundary comparison and rule implementation. In fact, our results are consistent with a recent study demonstrating significant stimulus representation in EVC even when memoranda had been transformed into a motor format (<xref ref-type="bibr" rid="c35">Henderson et al., 2022</xref>). In addition, electrophysiological research in non-human primates has also shown robust feature selectivity in the visual cortex during a categorization task (<xref ref-type="bibr" rid="c8">Brincat et al., 2018</xref>), and recent computational modeling work has suggested intact maintenance of sensory information during categorical judgements (<xref ref-type="bibr" rid="c43">Luu &amp; Stocker, 2021</xref>).</p>
</sec>
<sec id="s3b">
<title>Role of frontal cortex in active WM control</title>
<p>Compared to the prominent role of EVC in memory maintenance, sPCS in the frontal cortex played a dominant role in WM tasks that require active control of memory contents such as categorization. Although stimulus representations in sPCS have been observed during WM in previous studies, the nature of these representations remained debatable. In WM tasks that required mere maintenance of memoranda, stimulus was not always decodable in the frontal cortex (<xref ref-type="bibr" rid="c19">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="c31">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="c53">Riggall &amp; Postle, 2012</xref>), raising the issue of functional significance of stimulus representation in the frontal cortex. On the other hand, stimulus representation in the frontal cortex could become robust in the face of tasks that require attentional prioritization and extensive training (<xref ref-type="bibr" rid="c6">Bettencourt &amp; Xu, 2016</xref>; <xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="c33">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c42">Lorenc et al., 2018</xref>; <xref ref-type="bibr" rid="c48">Miller et al., 2022</xref>). Our current study contributes to the resolution of this issue by demonstrating that stimulus representation in sPCS increased with increasing demands for WM control. This finding is in line with recent computational studies proposing that active WM functions may involve neuronal mechanisms different from that for passive maintenance. For example, passive maintenance could rely mainly on synaptic plasticity mechanisms, whereas active control functions such as distractor resistance and information manipulation involve more neuronal spiking activity (<xref ref-type="bibr" rid="c45">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="c59">Wang, 2021</xref>). In this study, we provided the first empirical evidence that the frontal cortex exhibits enhanced stimulus representation in categorization task requiring active WM control and this representation is predictive of WM performance. In contrast, stimulus representation of WM maintenance failed to predict WM performance at high control demand. Moreover, by examining additional ROIs in the frontal cortex (i.e., iPCS, IFS, and MFG), we found that results in these brain regions were overall weaker, with the MFG demonstrating the most comparable, albeit much weaker, results to sPCS. The specific involvement of sPCS in our experiment could be due to the type of stimulus (i.e., orientation) we used, as previous work has highlighted a prominent role of sPCS in encoding stimulus-specific information in spatial (<xref ref-type="bibr" rid="c33">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c57">Sprague &amp; Serences, 2013</xref>) and orientation working memory (<xref ref-type="bibr" rid="c22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>, <xref ref-type="bibr" rid="c62">2019</xref>), but to a lesser extent in other working memory tasks such as color (<xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>, <xref ref-type="bibr" rid="c62">2019</xref>). It would be of interest to further investigate whether this active control in the sPCS could be generalized to other frontal regions and tasks that require other types of WM control such as mental rotation (<xref ref-type="bibr" rid="c55">Shi &amp; Yu, 2024</xref>), and how other types of control task may adapt to changing flexible control demands.</p>
</sec>
<sec id="s3c">
<title>WM representations in frontal cortex support cognitive flexibility</title>
<p>Our results in the frontal cortex are also in line with recent theoretical proposals in the field of cognitive flexibility. To behave flexibly in complex environments with limited cognitive resources, two mechanisms have been proposed: low-dimensional abstraction of stimulus representation for generalization and efficient learning, and high-dimensional stimulus representation for separability and flexible readout (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c24">Flesch et al., 2022</xref>; <xref ref-type="bibr" rid="c28">Fusi et al., 2016</xref>). Within this framework, high-dimensional stimulus representations during WM might emerge in the frontal cortex in response to complex control demands such as rule-based categorization. The results of the two fMRI experiments in the current study jointly demonstrate a dynamic tradeoff between high-dimensional stimulus and low-dimensional category representations depending on the control demand. Specifically, when control demand was reduced with a single categorization rule in Experiment 2 compared to Experiment 1, the differential stimulus representation in the frontal cortex was also reduced during the late delay period, accompanied by an increase in category decoding performance especially in the frontal cortex. This result is consistent with neurophysiological findings in non-human primates: while robust category selectivity was observed in frontoparietal cortex during the delay period of categorization tasks when the animal was trained on the categorization task only (<xref ref-type="bibr" rid="c8">Brincat et al., 2018</xref>; <xref ref-type="bibr" rid="c25">Freedman &amp; Assad, 2006</xref>; <xref ref-type="bibr" rid="c26">Freedman et al., 2001</xref>; <xref ref-type="bibr" rid="c46">McKee et al., 2014</xref>), category selectivity in the parietal cortex was significantly reduced when the animal had been exposed to a maintenance task prior to categorization training (<xref ref-type="bibr" rid="c37">Latimer &amp; Freedman, 2023</xref>). Our RNN simulation further confirmed that this dynamic reconfiguration in information coding at the network level can be well explained by a change in the coding strategy for the network readout. In other words, in flexible environments, and with rich prior experience, the brain might adopt an entirely different strategy for processing information in WM. High-dimensional stimulus information might be preserved in its original identity in the higher-order cortex, potentially reducing processing demands in dealing with each task and thereby facilitating efficiency and flexibility (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c24">Flesch et al., 2022</xref>; <xref ref-type="bibr" rid="c28">Fusi et al., 2016</xref>). One important future direction would be to further address the meta-control mechanisms that determine the flexible selection of coding strategies for WM (<xref ref-type="bibr" rid="c20">Eppinger et al., 2021</xref>).</p>
</sec>
<sec id="s3d">
<title>Differentiating between frontal and parietal cortex in WM functions</title>
<p>While many previous WM studies have focused on the functional distinction between sensory and frontoparietal cortex, it has remained less clear how frontal and parietal cortex might differ in terms of WM functions. Some studies have reported stimulus representations with similar functionality in frontal and parietal cortex (<xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="c62">Yu &amp; Shim, 2019</xref>), while others have observed differential patterns (<xref ref-type="bibr" rid="c36">Hu &amp; Yu, 2023</xref>; <xref ref-type="bibr" rid="c39">Lee et al., 2013</xref>; <xref ref-type="bibr" rid="c40">Li et al., 2023</xref>). We interpret the differential patterns as reflecting a difference in the potential origin of the corresponding cognitive functions. For example, in our study, sPCS demonstrated the most prominent effect for enhanced stimulus representation during categorization as well as the tradeoff between stimulus difference and category representation, suggesting that sPCS might serve as the source region for such effects. On the other hand, IPS did show visually similar patterns to sPCS in some analyses. For instance, stimulus representation in IPS was visually but not statistically higher in the categorization task. Additionally, stimulus representation in IPS also predicted behavioral performance in the categorization task. These results together support the view that our findings in sPCS do not occur in isolation, but rather reflect a dynamic reconfiguration of functional gradients along the cortical hierarchy from early visual to parietal and then to frontal cortex.</p>
</sec>
<sec id="s3e">
<title>The alignment between RNN and fMRI results</title>
<p>Although the current RNNs effectively captured our key fMRI findings, including increased stimulus representation in the frontal cortex as well as the tradeoff in category representation with varying control demands, we acknowledge that differences remain between the two modalities. For instance, all three RNN modules demonstrated significant abstract category decoding as well as difference in category decoding between experiments, which differed from our fMRI results. This discrepancy could partially be due to the higher signal sensitivity in RNNs. In addition, RNN2 did not show decreased stimulus decoding for categorization in the EVC module. However, we found that applying IEMs to the RNN data revealed a similar negative trend in the EVC module (<xref rid="figs8" ref-type="fig">Figure S8</xref>), though it was not statistically significant. This result suggests that any negative difference between categorization and maintenance in EVC module was weaker compared to fMRI, if existed. We speculate that enhancing the negative difference in the EVC module might require additional modules or inputs to strengthen fine-grained stimulus representation in EVC, a mechanism that could be of interest for future research.</p>
</sec>
</sec>
<sec id="s4">
<title>Conclusion</title>
<p>In conclusion, we observed a distributed cortical network, including early visual, parietal, and frontal cortex, in representing stimulus-specific information in WM. These stimulus representations in visual and frontal cortex played distinct functional roles, with those in EVC contributing primarily to precise maintenance and those in frontal cortex contributing primarily to active control in WM. RNN simulations indicated that the stimulus representation in the frontal cortex might have emerged as a result of output selection to facilitate cognitive flexibility. Collectively, these results help to reconcile current debates on the functional roles of different cortical regions in WM, and provide new insights into how a unified WM framework could support varied control demands.</p>
</sec>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<title>Participants</title>
<p>A total of 54 participants were recruited at Chinese Academy of Sciences, Shanghai Branch. Twenty-six healthy participants (21 female, all right-handed, mean age = 24.0 Â± 1.4 years) were recruited for Experiment 1. Two were excluded due to failure in completing the experiment or low conformity to task instructions, remaining 24 participants who completed the main experiment (19 female, mean age = 23.92 Â± 1.41 years). Twenty-eight (22 female, mean age = 24.14 Â± 1.51 years) participants were recruited for Experiment 2. Two quitted after behavioral training and two did not finish scanning due to technical problems with the scanner, resulting in 24 participants (20 female, mean age = 24.13 Â± 1.60 years) in the final analyses. All participants were neurologically healthy and eligible for MRI, had normal or corrected-to-normal vision, provided written informed consent approved by the Ethics Committee of Institute of Neuroscience, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, and were monetarily compensated for their participation. Sample sizes were not estimated a priori but were comparable and even superior to those in previous studies.</p>
</sec>
<sec id="s5b">
<title>Stimuli and Procedure</title>
<p>All stimuli were generated and presented using MATLAB (The MathWorks) and Psychtoolbox 3 extensions (<xref ref-type="bibr" rid="c7">Brainard, 1997</xref>; <xref ref-type="bibr" rid="c51">Pelli, 1997</xref>). During behavioral training, stimuli were presented on a ThinkVision monitor at a viewing distance of 45 cm. Behavioral responses were acquired with a keyboard. During scanning, stimuli were projected onto a SinoRad monitor (1280 Ã 1024 pixels, refreshing at 60 Hz) viewed through a coil-mounted mirror in the scanner at a viewing distance of 90.5 cm. Participantsâ behavioral responses were acquired with a Sinorad MRI-compatible button box.</p>
<sec id="s5b1">
<title>Behavioral Training</title>
<p>In Experiment 1, prior to scanning, participants were trained to learn two novel rules, Rule A and Rule B, for categorizing orientations. Thirty oriented bars were used as sample stimuli, ranging from 5Â° to 179Â° (in increments of 6Â°; two participants used another set of thirty orientations ranging from 4Â° to 178Â°). Each abstract rule was constructed by two orthogonal boundaries that divided the thirty orientations into two categories with fifteen orientations each. Rule A and Rule B were orthogonal to each other. Corresponding boundaries were 20Â°/110Â° and 65Â°/155Â° (15Â°/105Â° and 60Â°/150Â° for the two participants using different stimuli sets).</p>
<p>Participants learned new rules through a rule learning task. Each run of learning started with a rule disk informing the target rule. To avoid any potential verbal coding, rule specifics were visually illustrated as rule disks containing two distinct colors (colors randomly assigned to categories every time; see <xref rid="fig1" ref-type="fig">Figure 1A</xref> for an example). Rule disk was presented on the screen for 2 s followed by 1 s of fixation. On each trial, an oriented bar (radius=7Â°) was presented for 1 s followed by a delay of 1 s. Participants were instructed to report the category of the orientation by pressing a response key (âFâ or âJâ). To avoid category-response mapping, we randomized the relationship between categories and key buttons across trials. Moreover, to avoid presenting rule boundaries explicitly, we presented key names at random positions within the range defining each category. In other words, participants had to memorize the exact rule boundaries as accurately as possible in order to find the correct key buttons for each trial. Feedback was given at the end of each trial to assist learning.</p>
<p>Participants completed 30 learning trials in each run. They reviewed rule disks after every 10 trials for memory reconsolidation. Each participant completed at least two runs for each rule. After achieving an average accuracy above 86% (26 out of 30 trials) for the first rule, they proceeded to learn the other rule and then to practice the main task for scanning (see next section). Learning order of rules was counterbalanced across subjects. Upon completion of practicing, participants needed to report the boundaries of learned rules as a qualification of behavioral training. If the total error in reported boundaries had exceeded 20Â°, participants had one more chance to learn by repeating the learning task. Two participants completed one additional behavioral training to recap rule knowledge prior to scanning.</p>
<p>Behavioral training for Experiment 2 followed the same procedure and used the identical sample set (30 orientations ranging from 4Â° to 178Â°, in increments of 6Â°) as Experiment 1, except that only one rule was trained. Half of the participants in Experiment 2 learned rule boundaries of 19Â°/109Â°; the other half learned rule boundaries of 67Â°/157Â°.</p>
</sec>
<sec id="s5b2">
<title>Flexible WM Task (fMRI Task)</title>
<p>In Experiment 1, during scanning, participants completed a flexible WM task which implemented levels of control demand with different rules. To be specific, participants randomly switched between a maintenance task and a categorization task. In the maintenance task, participants needed to memorize stimulus information (i.e., orientations). In the categorization task, participants needed to categorize orientations following the rule that was randomly assigned and cued on a block basis. Procedure of the main task was visualized in <xref rid="fig1" ref-type="fig">Figure 1A</xref>. At the beginning of each block, participants were presented with a rule disk for 3 s, followed by a 2-s interval, instructing the categorization rule of the current block. For each trial, participants saw two oriented bars presented successively. Each bar was presented for 0.75 s, with an inter-stimulus-interval of 0.5 s. Sample sets were the same as those used in behavioral training. After a 0.5-s interval, a retro-cue occurred for 0.5 s, indicating the orientation of which participants should remember. After a 1.5-s delay, a task cue was displayed at fixation for 0.5 s, following by an 8-s memory delay. The task cue was either a letter âPâ on maintenance trials, instructing participants to maintain the cued orientation during memory delay as precisely as possible; or the task cue was a letter âCâ on categorization trials, asking participants to categorize the cued orientation using the block rule during the delay. Then, participants were probed to respond within 2 s. On maintenance trials, participants needed to select the memorized orientation from two probe orientations; while on categorization trials, participants needed to report the category of the cued orientation. Response mapping followed the same operation as in the learning tasks. Inter-trial-intervals were randomly selected from 3, 5, and 7 s with an equal trial number, resulting in an average trial length of 20 s. Participants switched to the next block after every six categorization trials and three maintenance trials. Each run contained two blocks (i.e., 18 trials).</p>
<p>In Experiment 2, to isolate potential effect of rule switching, the categorization rule stayed the same throughout the experiment. In Experiment 2, participants randomly switched between the maintenance task and the categorization task. Each trial followed the same procedure as Experiment 1.</p>
<p>In Experiment 1, orientations, tasks, and cued target order (1st or 2nd) were counterbalanced across trials, resulting in an equal trial number of 90 across all three conditions (categorization-Rule A, categorization-Rule B, and maintenance). Nineteen out of the twenty-four participants completed 15 runs of the main task. One participant completed 13 runs due to technical difficulties with the scanner. Another four participants completed 30 runs across two scan sessions. The same counterbalancing procedure was conducted for Experiment 2 (90 trials for maintenance task and 180 trials for categorization task). In Experiment 2, six participants completed 15 runs of 18 trials; the other seven completed 18 runs of 15 trials each due to scanner limitations. At the end of scanning, participants reported the rule boundaries three times as a final check of their rule memory.</p>
</sec>
</sec>
<sec id="s5c">
<title>Data Acquisition</title>
<p>MRI data of Experiment 1 were collected using a 3 Tesla Siemens MRI scanner (Tim Trio; Siemens Healthineers) with a 32-channel head coil at the Functional Brain Imaging Platform at Institute of Neuroscience, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences. Functional scanning was performed using a gradient-echo echo-planar sequence with the following parameters: repetition time (TR) = 1000 ms; echo time (TE) = 30 ms; flip angle (FA) = 40Â°; voxel size = 3 x 3 x 3 mm; multi-band accelerate factor = 4; matrix size = 74 x 74; slice number = 60. A high-resolution anatomical T1 image was collected before functional scanning (TR = 2300 ms; TE = 2.98 ms; FOV = 256 x 240 x 192 mm; voxel size = 1 x 1 x 1 mm). During scanning, participantsâ head positions were restricted with surrounding paddings to prevent head movements. MRI data of Experiment 2 were collected using identical procedure and settings except that the last eleven participants were scanned using a newly installed 3 Tesla Siemens MRI scanner (Prisma; Siemens Healthineers) at the Functional Brain Imaging Platform.</p>
</sec>
<sec id="s5d">
<title>Preprocessing</title>
<p>All preprocessing of individual MRI data was performed using AFNI (<ext-link ext-link-type="uri" xlink:href="https://afni.nimh.nih.gov">afni.nimh.nih.gov</ext-link>) (<xref ref-type="bibr" rid="c13">Cox, 1996</xref>; <xref ref-type="bibr" rid="c14">Cox &amp; Hyde, 1997</xref>). Functional data of all runs were registered to the last volume of the final run with the first eight volumes of each run removed. Then, individualsâ aligned functional data were registered to their corresponding T1 volume. Alignment of registration was manually checked for each subject to ensure quality. The registered data were further motion corrected and detrended.</p>
</sec>
<sec id="s5e">
<title>ROI Definition</title>
<p>Our primary ROI-based analyses focused on three most commonly-studied, WM-related brain areas: early visual cortex (EVC), intraparietal sulcus (IPS) in parietal cortex, and superior precentral sulcus (sPCS) in frontal cortex (<xref ref-type="bibr" rid="c22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c33">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>). We created anatomical ROI masks based on the probabilistic atlas by Wang and colleagues (<xref ref-type="bibr" rid="c58">Wang et al., 2015</xref>). EVC (merging bilateral V1, V2, and V3), IPS (merging bilateral IPS0-5), and sPCS (merging bilateral FEF) masks were generated by warping masks from the probabilistic atlas to individualsâ anatomical image in their native space. In order to generate functional ROI masks, we then performed general linear models (GLMs) to quantify task-related univariate activity changes in each voxel. Task events were modeled using boxcar functions convolved with a canonical hemodynamic response function (durations of event epochs for sample, post retro-cue delay, memory delay, and response were 2.5 s, 2 s, 8.5 s, and 2 s, respectively). Six nuisance regressors were also included to account for head motion artifacts in the six dimensions of rigid body motion. Functional EVC mask was defined by the 500 most active voxels during sample display. Functional IPS and sPCS masks were defined by the 500 most active voxels during memory delay. Additional ROIs in the frontal cortex were defined using the HCP atlas (<xref ref-type="bibr" rid="c30">Glasser et al., 2016</xref>), including the inferior precentral sulcus (iPCS, generated by merging 6v, 6r, and PEF), inferior frontal sulcus (IFS, generated by merging IFJp, IFJa, IFSp, IFSa, and p47r), middle frontal gyrus (MFG, generated by merging 9-46d, 46, a9-46v, and p9-46v), and primary motor cortex (M1).</p>
</sec>
<sec id="s5f">
<title>MRI Data Analyses</title>
<sec id="s5f1">
<title>Multivariate Inverted Encoding Modeling (IEM)</title>
<p>Neural representations of orientations were reconstructed using inverted encoding modeling (IEM) (<xref ref-type="bibr" rid="c9">Brouwer &amp; Heeger, 2009</xref>, <xref ref-type="bibr" rid="c10">2011</xref>; <xref ref-type="bibr" rid="c22">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c52">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="c61">Yu &amp; Shim, 2017</xref>) with custom MATLAB scripts on individualsâ BOLD activation patterns in the ROIs. IEM provides an estimate of population-level reconstructions of stimulus-specific information. The general procedure for IEM includes using training data to train model weights and then applying weights to testing data to obtain reconstructed channel responses. For the main analyses, we used trials from all conditions to train and to test IEM in order to avoid potential biases from a specific task condition. Results for categorization task were averaged across rules for Experiment 1. Training and testing were performed for each TR separately. As a control, IEMs were also estimated for each condition separately (within-condition IEM). Training and testing underwent a leave-one-run-out cross-validation procedure, in which each run was taken out as the testing run, and the rest of the data served as the training run. This procedure was iterated until all runs had served as training and testing runs. Results from all cross-validated folds were averaged. Detailed computations for each fold were elucidated below:</p>
<p>We first modeled responses of voxels into nine equidistant orientation channels (initial channels were 1Â°, 21Â°, 41Â°, 61Â°, 81Â°, 101Â°, 121Â°, 141Â°, 161Â°), characterizing voxel selectivity for orientations. At each channel, the modeled orientation tuning curve was a half-wave-rectified and squared sinusoid raised to eighth power, defined as the function below (<italic>c</italic> was the center of the channel):
<disp-formula>
<graphic xlink:href="551058v3_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>Population-level tuning responses of voxels was described using the function:
<disp-formula>
<graphic xlink:href="551058v3_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p><italic>B</italic><sub>1</sub> was the training dataset from our fMRI data (<italic>v</italic> voxels Ã <italic>n</italic> trials). <italic>C</italic><sub>1</sub> represented the hypothesized channel responses (<italic>k</italic> channels Ã <italic>n</italic> trials) which were modulated by <italic>W</italic>, a weight matrix (<italic>v</italic> voxels Ã <italic>k</italic> channels).</p>
<p>The least-squared estimates of the weight matrix (<italic>WÌ</italic>) was computed using linear regression:
<disp-formula>
<graphic xlink:href="551058v3_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>The weight matrix was then applied on the test dataset to reconstruct estimated channel responses (<italic>CÌ</italic><sub>2</sub>):
<disp-formula>
<graphic xlink:href="551058v3_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>The analysis above were repeated for 20 times in step of 1Â° using leave-one-run-out cross-validation so that the nine channel centers covered all 180 orientations (<xref ref-type="bibr" rid="c52">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="c60">Yu &amp; Postle, 2021</xref>). All channel responses were combined to create responses for all 180 orientation channels. For statistical comparisons and for visualization, all channel responses were shifted to a common center of 0Â° (true orientation of trials). The responses from all trials were averaged to obtain reconstructed orientation representations for the test datasets.</p>
<p>To quantify the strength of each IEM reconstruction, we calculated reconstruction fidelity of channel responses (<xref ref-type="bibr" rid="c52">Rademaker et al., 2019</xref>). First, channel responses of each trial were shifted so that the orientation of each trial was centered in stimulus space. Thus, for each shifted channel response with a vector length of <italic>r</italic> at orientation <italic>Î¸</italic>, the orientation was wrapped onto a 2Ï circular space, and <italic>r</italic> was projected to the vector at the true orientation (center of stimulus space, 0Â°) using the absolute angle between the channel and the center following the equation:
<disp-formula>
<graphic xlink:href="551058v3_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<p>The reconstruction fidelity was then calculated as the mean of all projected vectors <italic>d</italic>. A larger fidelity value indicates a stronger positive representation of orientation.</p>
</sec>
<sec id="s5f2">
<title>Multivariate Pattern Analysis (MVPA)</title>
<p>Besides IEM, we tracked neural representations of stimulus and of category using linear Support Vector Machine (SVM) decoders. All decoding analyses were performed using the templateSVM and fitcecoc functions in MATLAB.</p>
<p>Decoding of stimulus was performed for every TR. We divided the thirty orientations into four bins of 45Â° each, two cardinal bins centered at 90Â° or 180Â° and two oblique bins centered at 45Â° or 135Â°. We then performed two two-way classifications, one trained and tested on cardinal bins, and the other trained and tested on oblique bins. We trained and tested decoders separately for each condition using the same leave-one-run-out cross-validation procedure as in IEM analyses. To avoid biases in model training, we randomly balanced the trial numbers for each bin in the training set. Decoding accuracies were then computed by averaging performance of cardinal and oblique classifiers. For the categorization task, we averaged accuracies across rules.</p>
<p>Decoding of category information for Experiment 1 was performed under each rule (90 trials for each rule) using a leave-one-trial-out cross-validation procedure (see next paragraph for details), and the decoding accuracies were then averaged across rules. Since Experiment 2 adopted a fixed rule with 180 trials in the categorization task, we randomly divided categorization trials into two halves with 90 trials each, and decoded category information for Experiment 2 using identical procedures as for Experiment 1.</p>
<p>Because closer orientations are more similar to each other inherently, orientations per se could contain categorical information by visual similarity. Thus, to isolate the influence of stimulus on category, in addition to the decoder using true category labels, we trained an opposite category decoder using category labels based on the opposite rule. If the two-way classification on categories only captured stimulus information, then true category and opposite category decoding should have had comparable performance. If abstract category information existed beyond stimulus information, then true category decoder should have outperformed the opposite category decoder. Thus, an abstract category index was calculated by subtracting opposite category decoding accuracy from true category decoding accuracy (i.e., chance level = 0). Since the opposite category decoding used re-assigned labels, to eliminate imbalance in trial number between true and opposite categories, we used a leave-one-trial-out cross-validation procedure for true category and opposite category decoders. Decoding for Experiment 1 was performed separately for each rule and were then averaged. Decoding for Experiment 2 was performed separately for randomly divided halves and averaged.</p>
</sec>
<sec id="s5f3">
<title>Recurrent Neural Network Simulations</title>
<sec id="s5f3a">
<title>RNN architecture</title>
<p>The network model was built following the details in previous work (<xref ref-type="bibr" rid="c45">Masse et al., 2019</xref>), and implemented in TensorFlow (version: Nvidia-tensorflow 1.15.0) (<xref ref-type="bibr" rid="c1">Abadi et al., 2016</xref>). The general network architecture consisted of three layers of artificial units: the input, hidden, and output layers. The input layer contains units served to present various task-related signals corresponding to those in the fMRI paradigm, including orientations, retro-cues, task cues. In order to simulate neural activity patterns in hierarchically connected brain regions (EVC, IPS and sPCS), we separated the hidden layer into three modules, each containing 200 recurrent units with short-term synaptic plasticity (STSP). Within each module, units were further divided into 80% excitatory and 20% inhibitory following Daleâs principle. Similar to previous work (<xref ref-type="bibr" rid="c63">Zhou et al., 2021</xref>), modularity was achieved by constraining the recurrent connectivity in the hidden layer. Specifically, only posterior moduleâs (Module 1) excitatory units received inputs from the input layer and only anterior moduleâs (Module 3) excitatory units projected to the output units. Between-module connections were culled so that only 50% of a moduleâs excitatory units were randomly connected to their counterparts in the neighboring module(s), and vice versa (feedforward and feedback connections). Connections among inhibitory units remained strictly within-module in accordance with the observation that inhibitory connections in cortex are largely local. Thus, posterior, middle and anterior modules were intended to simulate the three interconnected ROIs we used in the fMRI analyses that posited differently at the processing hierarchy. We specifically manipulated the output demand to investigate whether it would alter similarity of the results to the fMRI observations. To this end, one type of network architecture (RNN1) implemented a two-unit output layer with each unit corresponding to one of two possible response options, presented through the input units before the test period; In contrast, the other type of RNN architecture (RNN2) had additional units in the output layer, creating a demand for preserving the original stimulus information alongside categorical representations.</p>
</sec>
<sec id="s5f3b">
<title>Task simulation</title>
<p>Orientations were simulated as Gaussian signals from 15 orientation-tuned units in the input layer distributed equally across 0-180 degrees, forming a ring of receptive field. The magnitude of an orientation-tuned input unit represented the closeness of its preferred orientation to the input angle. Stimulus values were selected from an array of 20 orientations evenly spanned from [0 to 180) degrees. The sequentially-presented stimuli were presented through the same receptive field, followed by retro-cue and task cue indicated through the separate input units. For RNN1, before the test period when the network was required to make a choice, two response options were presented sequentially through the same input receptive field. The selection of the options varied slightly between the maintenance and categorization tasks: in maintenance, one orientation was always the cued sample while the other was randomly chosen from all other possible angles. In categorization, one option was taken from the same category as the cued sample but not necessarily the exact angle, while the other option was randomly chosen from orientations belonging to the other category. The network output (0,1) or (1,0) in the output units to report its choice. In comparison, RNN2 output (0,1) or (1,0) to report the category to which the cued orientation belonged in the categorization task, or (0,0) in the maintenance task. Importantly, the model also needed to report the cued orientation itself through a receptive field consisting of 15 orientation -tuned units in the output layer.</p>
</sec>
<sec id="s5f3c">
<title>Training parameters and procedure</title>
<p>The hyperparameters and procedure for training the models were consistent with those detailed in previous work (<xref ref-type="bibr" rid="c45">Masse et al., 2019</xref>), with the following exceptions: standard deviations of input and recurrent noise were set to 0.01 as our tasks were much harder to train compared to those used in the reference study (especially networks were trained on both tasks simultaneously). Lowering the noise level may provide an edge for the models to successfully learn to perform the tasks. In a similar vein, we also expanded the number of hidden units to 600 and number of training iteration to a maximum of 10000. Additionally, spike penalty was set to 0 for both RNN models to remove constraints on neuronal activity.</p>
<p>We trained 20 models for each type of RNN and results were obtained by averaging over all of them (for single-rule RNN, 10 models for each categorization rule). The goal of the training process was to minimize the mean square error between the model outputs and correct outputs during the test period via back propagation (with a 50 ms grace period at onset when model output was not taken into account in calculating error). Training was conducted in a block-interleaved fashion in which each gradient batch consisted of 300 maintenance, 300 categorization Rule A and 300 categorization Rule B trials, with the task block order randomized (for single rule RNN, each batch consisted of 300 maintenance and 300 categorization trials). Training would automatically stop if the model achieved 90% accuracy in the last training batch on all tasks. For RNN2, the accuracies for category and stimulus outputs were calculated separately to ensure precision of the stimulus outputs.</p>
</sec>
<sec id="s5f3d">
<title>Population decoding</title>
<p>We measured the strength of stimulus and category representations through training SVMs on time-resolved neuronal activity. Activities were obtained by feeding new batches of tasks into the already-successfully trained networks after freezing all connection weights to prevent further changes to the modelsâ behaviors. The intrinsic noise for the recurrent layer was also set to 0 for decoding analyses. To ensure accurate decoding results, we sampled large number of trials (900 trials for each condition) and implemented a 5-fold cross-validation procedure in which 80% of trials were used as training set and the remaining 20% as testing set in each fold. Decoders were trained separately for each module and time point.</p>
</sec>
<sec id="s5f3e">
<title>Statistical Testing</title>
<p>Participantsâ behavioral performance for the main task was assessed using accuracy and reaction time. Paired t-test was conducted for the two task types (maintenance &amp; categorization) to evaluate differences between conditions.</p>
<p>Statistical significance was evaluated via a sign-flip permutation procedure for all other analyses. For example, to characterize the significance of IEM fidelity, we computed the p-value by comparing the true mean fidelity of our sample with a null distribution reflecting no IEM fidelity. The null distribution was created by randomly assigning 1 or â1 to fidelity scores of our sample and then averaging the sign-flipped samples for 10,000 times, resulting in a null distribution of 10,000 fidelity scores. To characterize the difference of IEM fidelity between tasks, we sign-flipped the fidelity sample for each condition and then averaged the difference for 10,000 times. The p-value was calculated by comparing the true mean difference with the generated null distribution of difference. P-values were corrected using FDR across ROIs, time (TRs), and tasks for all analyses unless specified. An early (5-10 s; 6<sup>th</sup>-11<sup>th</sup> TR) and late (11-16 s; 12<sup>th</sup>-17<sup>th</sup> TR) task epoch was also defined to facilitate comparisons between ROIs and experiments when needed.</p>
<p>For RNN decoding results, we adopted a cluster-based permutation approach (using MNE-Python (<xref ref-type="bibr" rid="c32">Gramfort et al., 2013</xref>) function <italic>permutation_cluster_1samp_test</italic> to accommodate the large number of time points to be corrected for) to determine statistical significance of the time course, for stimulus decoding accuracies in maintenance/categorization, difference between stimulus decoding accuracies between tasks, and abstract category decoding accuracy in categorization task. Moreover, we also pooled decoding accuracies across a critical task period (50-75 time points during delay) to produce summary statistics aligning with what was reported in the fMRI results. Average decoding results were corrected using the FDR method.</p>
</sec>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank Dr. Mu-ming Poo for valuable comments on an earlier version of the manuscript, and Dr. Tianming Yang for helpful discussions. This work was supported by the Strategic Priority Research Program of the Chinese Academy of Sciences (Grant No. XDB1010202), the Ministry of Science and Technology of China (STI2030-Major Projects 2021ZD0203701, 2021ZD0204202), the National Natural Science Foundation of China (32271089), CAS Project for Young Scientists in Basic Research (YSBR-071), and Shanghai Pujiang Program (22PJ1414400) to Q.Y..</p>
</ack>
<ref-list>
<title>Reference</title>
<ref id="c1"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Abadi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Barham</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dean</surname>, <given-names>J.</given-names></string-name>, <etal>â¦</etal> <string-name><surname>Zheng</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2016</year>). <article-title>TensorFlow: A System for Large-Scale Machine Learning</article-title>. <conf-name>12th USENIX Symposium on Operating Systems Design and Implementation</conf-name>, <fpage>265</fpage>â<lpage>283</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baddeley</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Working memory: looking back and looking forward</article-title>. <source>Nat Rev Neurosci</source>, <volume>4</volume>(<issue>10</issue>), <fpage>829</fpage>â<lpage>839</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn1201</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes</article-title>. <source>Trends Cogn Sci</source>, <volume>12</volume>(<issue>5</issue>), <fpage>193</fpage>â<lpage>200</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2008.02.004</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bhandari</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Keglovits</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Kikumoto</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The dimensionality of neural representations for control</article-title>. <source>Curr Opin Behav Sci</source>, <volume>38</volume>, <fpage>20</fpage>â<lpage>28</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cobeha.2020.07.002</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kayser</surname>, <given-names>A. S.</given-names></string-name>, &amp; <string-name><surname>DâEsposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Frontal cortex and the discovery of abstract action rules</article-title>. <source>Neuron</source>, <volume>66</volume>(<issue>2</issue>), <fpage>315</fpage>â<lpage>326</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.025</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bettencourt</surname>, <given-names>K. C.</given-names></string-name>, &amp; <string-name><surname>Xu</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Decoding the content of visual short-term memory under distraction in occipital and parietal areas</article-title>. <source>Nat Neurosci</source>, <volume>19</volume>(<issue>1</issue>), <fpage>150</fpage>â<lpage>157</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.4174</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brainard</surname>, <given-names>D. H</given-names></string-name></person-group>. (<year>1997</year>). <article-title>The Psychophysics Toolbox</article-title>. <source>Spat Vis</source>, <volume>10</volume>(<issue>4</issue>), <fpage>433</fpage>â<lpage>436</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/9176952">https://www.ncbi.nlm.nih.gov/pubmed/9176952</ext-link></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brincat</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Siegel</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>von Nicolai</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Gradual progression from sensory to task-related processing in cerebral cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>115</volume>(<issue>30</issue>), <fpage>E7202</fpage>â<lpage>E7211</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1717075115</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Decoding and reconstructing color from responses in human visual cortex</article-title>. <source>J Neurosci</source>, <volume>29</volume>(<issue>44</issue>), <fpage>13992</fpage>â<lpage>14003</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3577-09.2009</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Cross-orientation suppression in human visual cortex</article-title>. <source>J Neurophysiol</source>, <volume>106</volume>(<issue>5</issue>), <fpage>2108</fpage>â<lpage>2119</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00540.2011</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Christophel</surname>, <given-names>T. B.</given-names></string-name>, <string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, &amp; <string-name><surname>Haynes</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Decoding the contents of visual short-term memory from human visual and parietal cortex</article-title>. <source>J Neurosci</source>, <volume>32</volume>(<issue>38</issue>), <fpage>12983</fpage>â<lpage>12989</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0184-12.2012</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Christophel</surname>, <given-names>T. B.</given-names></string-name>, <string-name><surname>Iamshchinina</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Allefeld</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Haynes</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Cortical specialization for attended versus unattended working memory</article-title>. <source>Nat Neurosci</source>, <volume>21</volume>(<issue>4</issue>), <fpage>494</fpage>â<lpage>496</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-018-0094-4</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cox</surname>, <given-names>R. W</given-names></string-name></person-group>. (<year>1996</year>). <article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title>. <source>Comput Biomed Res</source>, <volume>29</volume>(<issue>3</issue>), <fpage>162</fpage>â<lpage>173</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/8812068">https://www.ncbi.nlm.nih.gov/pubmed/8812068</ext-link></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name>, &amp; <string-name><surname>Hyde</surname>, <given-names>J. S</given-names></string-name></person-group>. (<year>1997</year>). <article-title>Software tools for analysis and visualization of FMRI Data</article-title>. <source>NMR in Biomedicine</source>, <volume>10</volume>, <fpage>171</fpage>â<lpage>178</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Curtis</surname>, <given-names>C. E.</given-names></string-name>, <string-name><surname>Rao</surname>, <given-names>V. Y.</given-names></string-name>, &amp; <string-name><surname>DâEsposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Maintenance of spatial and motor codes during oculomotor delayed response tasks</article-title>. <source>J Neurosci</source>, <volume>24</volume>(<issue>16</issue>), <fpage>3944</fpage>â<lpage>3952</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5640-03.2004</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DâEsposito</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2015</year>). <article-title>The cognitive neuroscience of working memory</article-title>. <source>Annu Rev Psychol</source>, <volume>66</volume>, <fpage>115</fpage>â<lpage>142</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015031</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DâEsposito</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Postle</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Ballard</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Lease</surname>, <given-names>J</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Maintenance versus manipulation of information held in working memory: an event-related fMRI study</article-title>. <source>Brain Cogn</source>, <volume>41</volume>(<issue>1</issue>), <fpage>66</fpage>â<lpage>86</lpage>. doi:<pub-id pub-id-type="doi">10.1006/brcg.1999.1096</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DâEsposito</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Postle</surname>, <given-names>B. R.</given-names></string-name>, &amp; <string-name><surname>Rypma</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Prefrontal cortical contributions to working memory: evidence from event-related fMRI studies</article-title>. <source>Exp Brain Res</source>, <volume>133</volume>(<issue>1</issue>), <fpage>3</fpage>â<lpage>11</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s002210000395</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emrich</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Riggall</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Larocque</surname>, <given-names>J. J.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory</article-title>. <source>J Neurosci</source>, <volume>33</volume>(<issue>15</issue>), <fpage>6516</fpage>â<lpage>6523</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5732-12.2013</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eppinger</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Goschke</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Musslick</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Meta-control: From psychology to computational neuroscience</article-title>. <source>Cogn Affect Behav Neurosci</source>, <volume>21</volume>(<issue>3</issue>), <fpage>447</fpage>â<lpage>452</lpage>. doi:<pub-id pub-id-type="doi">10.3758/s13415-021-00919-4</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Serences</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Awh</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2013</year>). <article-title>A neural measure of precision in visual working memory</article-title>. <source>J Cogn Neurosci</source>, <volume>25</volume>(<issue>5</issue>), <fpage>754</fpage>â<lpage>761</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00357</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Parietal and Frontal Cortex Encode Stimulus-Specific Mnemonic Representations during Visual Working Memory</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>4</issue>), <fpage>893</fpage>â<lpage>905</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.013</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Categorical Biases in Human Occipitoparietal Cortex</article-title>. <source>J Neurosci</source>, <volume>40</volume>(<issue>4</issue>), <fpage>917</fpage>â<lpage>931</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2700-19.2019</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Flesch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Juechems</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dumbalska</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Orthogonal representations for robust context-dependent task performance in brains and neural networks</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>7</issue>), <fpage>1258</fpage>â<lpage>1270.e1211.</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.005</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Assad</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Experience-dependent representation of visual categories in parietal cortex</article-title>. <source>Nature</source>, <volume>443</volume>(<issue>7107</issue>), <fpage>85</fpage>â<lpage>88</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature05078</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Poggio</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Miller</surname>, <given-names>E. K</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Categorical representation of visual stimuli in the primate prefrontal cortex</article-title>. <source>Science</source>, <volume>291</volume>(<issue>5502</issue>), <fpage>312</fpage>â<lpage>316</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.291.5502.312</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Funahashi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bruce</surname>, <given-names>C. J.</given-names></string-name>, &amp; <string-name><surname>Goldman-Rakic</surname>, <given-names>P. S</given-names></string-name></person-group>. (<year>1989</year>). <article-title>Mnemonic coding of visual space in the monkeyâs dorsolateral prefrontal cortex</article-title>. <source>J Neurophysiol</source>, <volume>61</volume>(<issue>2</issue>), <fpage>331</fpage>â<lpage>349</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.1989.61.2.331</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Rigotti</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Why neurons mix: high dimensionality for higher cognition</article-title>. <source>Curr Opin Neurobiol</source>, <volume>37</volume>, <fpage>66</fpage>â<lpage>74</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fuster</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Alexander</surname>, <given-names>G. E</given-names></string-name></person-group>. (<year>1971</year>). <article-title>Neuron activity related to short-term memory</article-title>. <source>Science</source>, <volume>173</volume>(<issue>3997</issue>), <fpage>652</fpage>â<lpage>654</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/4998337">https://www.ncbi.nlm.nih.gov/pubmed/4998337</ext-link></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Coalson</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>E. C.</given-names></string-name>, <string-name><surname>Hacker</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Harwell</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <etal>â¦</etal> <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>2016</year>). <article-title>A multi-modal parcellation of human cerebral cortex</article-title>. <source>Nature</source>, <volume>536</volume>(<issue>7615</issue>), <fpage>171</fpage>â<lpage>178</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature18933</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gosseries</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>LaRocque</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Starrett</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Rose</surname>, <given-names>N. S.</given-names></string-name>, <string-name><surname>Cowan</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Parietal-Occipital Interactions Underlying Control- and Representation-Related Processes in Working Memory for Nonspatial Visual Features</article-title>. <source>J Neurosci</source>, <volume>38</volume>(<issue>18</issue>), <fpage>4357</fpage>â<lpage>4366</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2747-17.2018</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Luessi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Larson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Engemann</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Strohmeier</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Brodbeck</surname>, <given-names>C.</given-names></string-name>, <etal>â¦</etal> <string-name><surname>Hamalainen</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2013</year>). <article-title>MEG and EEG data analysis with MNE-Python</article-title>. <source>Front Neurosci</source>, <volume>7</volume>, <fpage>267</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hallenbeck</surname>, <given-names>G. E.</given-names></string-name>, <string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Rahmati</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sreenivasan</surname>, <given-names>K. K.</given-names></string-name>, &amp; <string-name><surname>Curtis</surname>, <given-names>C. E</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Working memory representations in visual cortex mediate distraction effects</article-title>. <source>Nat Commun</source>, <volume>12</volume>(<issue>1</issue>), <fpage>4714</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-021-24973-1</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harrison</surname>, <given-names>S. A.</given-names></string-name>, &amp; <string-name><surname>Tong</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Decoding reveals the contents of visual working memory in early visual areas</article-title>. <source>Nature</source>, <volume>458</volume>(<issue>7238</issue>), <fpage>632</fpage>â<lpage>635</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature07832</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Henderson</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Rademaker</surname>, <given-names>R. L.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Flexible utilization of spatial- and motor-based codes for the storage of visuo-spatial information</article-title>. <source>Elife</source>, <volume>11</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.75688</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hu</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>Q</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Spatiotemporal dynamics of self-generated imagery reveal a reverse cortical hierarchy from cue-induced imagery</article-title>. <source>Cell Rep</source>, <volume>42</volume>(<issue>10</issue>), <fpage>113242</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.celrep.2023.113242</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Latimer</surname>, <given-names>K. W.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Low-dimensional encoding of decisions in parietal cortex reflects long-term training history</article-title>. <source>Nat Commun</source>, <volume>14</volume>(<issue>1</issue>), <fpage>1010</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-023-36554-5</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leavitt</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Mendoza-Halliday</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Martinez-Trujillo</surname>, <given-names>J. C</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Sustained Activity Encoding Working Memories: Not Fully Distributed</article-title>. <source>Trends Neurosci</source>, <volume>40</volume>(<issue>6</issue>), <fpage>328</fpage>â<lpage>346</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2017.04.004</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>S. H.</given-names></string-name>, <string-name><surname>Kravitz</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Baker</surname>, <given-names>C. I</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Goal-dependent dissociation of visual and prefrontal cortices during working memory</article-title>. <source>Nat Neurosci</source>, <volume>16</volume>(<issue>8</issue>), <fpage>997</fpage>â<lpage>999</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3452</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zeng</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Shao</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>Q</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Neural Representations in Visual and Parietal Cortex Differentiate between Imagined, Perceived, and Illusory Experiences</article-title>. <source>J Neurosci</source>, <volume>43</volume>(<issue>38</issue>), <fpage>6508</fpage>â<lpage>6524</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0592-23.2023</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Cable</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Gardner</surname>, <given-names>J. L</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Inverted Encoding Models of Human Population Response Conflate Noise and Neural Tuning Width</article-title>. <source>J Neurosci</source>, <volume>38</volume>(<issue>2</issue>), <fpage>398</fpage>â<lpage>408</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2453-17.2017</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lorenc</surname>, <given-names>E. S.</given-names></string-name>, <string-name><surname>Sreenivasan</surname>, <given-names>K. K.</given-names></string-name>, <string-name><surname>Nee</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Vandenbroucke</surname>, <given-names>A. R. E.</given-names></string-name>, &amp; <string-name><surname>DâEsposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Flexible coding of visual working memory representations during distraction</article-title>. <source>J Neurosci</source>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3061-17.2018</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luu</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Stocker</surname>, <given-names>A. A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Categorical judgments do not modify sensory representations in working memory</article-title>. <source>PLoS Comput Biol</source>, <volume>17</volume>(<issue>6</issue>), <fpage>e1008968</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1008968</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mackey</surname>, <given-names>W. E.</given-names></string-name>, <string-name><surname>Winawer</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Curtis</surname>, <given-names>C. E</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Visual field map clusters in human frontoparietal cortex</article-title>. <source>Elife</source>, <volume>6</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.22974</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masse</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title>. <source>Nat Neurosci</source>, <volume>22</volume>(<issue>7</issue>), <fpage>1159</fpage>â<lpage>1167</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McKee</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Task dependence of visual and category representations in prefrontal and inferior temporal cortices</article-title>. <source>J Neurosci</source>, <volume>34</volume>(<issue>48</issue>), <fpage>16065</fpage>â<lpage>16075</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1660-14.2014</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2001</year>). <article-title>An integrative theory of prefrontal cortex function</article-title>. <source>Annu Rev Neurosci</source>, <volume>24</volume>, <fpage>167</fpage>â<lpage>202</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Tambini</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kiyonaga</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>DâEsposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Long-term learning transforms prefrontal cortex representations during working memory</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>22</issue>), <fpage>3805</fpage>â<lpage>3819.e3806.</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2022.09.019</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mok</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Love</surname>, <given-names>B. C</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Abstract Neural Representations of Category Membership beyond Information Coding Stimulus or Response</article-title>. <source>J Cogn Neurosci</source>, <fpage>1</fpage>â<lpage>17</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_01651</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Musslick</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Rationalizing constraints on the capacity for cognitive control</article-title>. <source>Trends Cogn Sci</source>, <volume>25</volume>(<issue>9</issue>), <fpage>757</fpage>â<lpage>775</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2021.06.001</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pelli</surname>, <given-names>D. G</given-names></string-name></person-group>. (<year>1997</year>). <article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title>. <source>Spat Vis</source>, <volume>10</volume>(<issue>4</issue>), <fpage>437</fpage>â<lpage>442</lpage>. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/9176953">https://www.ncbi.nlm.nih.gov/pubmed/9176953</ext-link></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rademaker</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>Chunharas</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Coexisting representations of sensory and mnemonic information in human visual cortex</article-title>. <source>Nat Neurosci</source>, <volume>22</volume>(<issue>8</issue>), <fpage>1336</fpage>â<lpage>1344</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0428-x</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Riggall</surname>, <given-names>A. C.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2012</year>). <article-title>The Relationship between Working Memory Storage and Elevated Activity as Measured with Functional Magnetic Resonance Imaging</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>38</issue>), <fpage>12990</fpage>â<lpage>12998</lpage>. doi:<pub-id pub-id-type="doi">10.1523/Jneurosci.1892-12.2012</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Serences</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Vogel</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Awh</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Stimulus-specific delay activity in human primary visual cortex</article-title>. <source>Psychol Sci</source>, <volume>20</volume>(<issue>2</issue>), <fpage>207</fpage>â<lpage>214</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02276.x</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shi</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>Q</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Distinct neural signatures underlying information maintenance and manipulation in working memory</article-title>. <source>Cereb Cortex</source>, <volume>34</volume>(<issue>3</issue>). doi:<pub-id pub-id-type="doi">10.1093/cercor/bhae063</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Adam</surname>, <given-names>K. C. S.</given-names></string-name>, <string-name><surname>Foster</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Rahmati</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sutterer</surname>, <given-names>D. W.</given-names></string-name>, &amp; <string-name><surname>Vo</surname>, <given-names>V. A</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Inverted Encoding Models Assay Population-Level Stimulus Representations, Not Single-Unit Neural Tuning</article-title>. <source>eNeuro</source>, <volume>5</volume>(<issue>3</issue>). doi:<pub-id pub-id-type="doi">10.1523/ENEURO.0098-18.2018</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices</article-title>. <source>Nat Neurosci</source>, <volume>16</volume>(<issue>12</issue>), <fpage>1879</fpage>â<lpage>1887</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3574</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Mruczek</surname>, <given-names>R. E.</given-names></string-name>, <string-name><surname>Arcaro</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Kastner</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Probabilistic Maps of Visual Topography in Human Cortex</article-title>. <source>Cereb Cortex</source>, <volume>25</volume>(<issue>10</issue>), <fpage>3911</fpage>â<lpage>3931</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhu277</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>X. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>50 years of mnemonic persistent activity: quo vadis?</article-title> <source>Trends Neurosci</source>, <volume>44</volume>(<issue>11</issue>), <fpage>888</fpage>â<lpage>902</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2021.09.001</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The Neural Codes Underlying Internally Generated Representations in Visual Working Memory</article-title>. <source>J Cogn Neurosci</source>, <fpage>1</fpage>â<lpage>16</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_01702</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Shim</surname>, <given-names>W. M</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Occipital, parietal, and frontal cortices selectively maintain task-relevant features of multi-feature objects in visual working memory</article-title>. <source>Neuroimage</source>, <volume>157</volume>, <fpage>97</fpage>â<lpage>107</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.05.055</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Shim</surname>, <given-names>W. M</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Temporal-Order-Based Attentional Priority Modulates Mnemonic Representations in Parietal and Frontal Cortices</article-title>. <source>Cereb Cortex</source>, <volume>29</volume>(<issue>7</issue>), <fpage>3182</fpage>â<lpage>3192</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhy184</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Rosen</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Swaminathan</surname>, <given-names>S. K.</given-names></string-name>, <string-name><surname>Masse</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Distributed functions of prefrontal and parietal cortices during sequential categorical decisions</article-title>. <source>Elife</source>, <volume>10</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.58782</pub-id></mixed-citation></ref>
</ref-list>
<sec id="s6">
<title>Supplemental Figures</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><title>Visualization of the anatomical locations of the ROIs on the MNI brain.</title></caption>
<graphic xlink:href="551058v3_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Control analyses for stimulus representation results in Experiment 1.</title><p>(A) Time course of representational strength of orientations in EVC, IPS and sPCS using IEMs trained separately for each condition. Bar plot on the right shows corresponding averaged difference between tasks across the late task epoch (11 â 16 s) in each ROI. Positive difference indicates higher representational strength for categorization, and vice versa for negative difference. Gray shaded areas indicate the entire memory delay following task cue. Horizontal dashed lines represent a baseline of 0 or 0.5. Blue and orange dots at the bottom indicate the significance of representational fidelity at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks. Shaded areas represent Â± SEM. black asterisks denote significance, *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01; ***: <italic>p</italic> &lt; 0.001. Gray asterisk denotes marginal significance p &lt; 0.1. (B) Time course of stimulus decoding accuracy. Same conventions as (A). (C) Time course of representational strength of orientations after removing voxel-wise mean activation for each condition at each TR. Same conventions as (A). (D) Time course of representational strength of orientations in functional ROIs defined by top 500 most selective voxels during sample or delay period. Same conventions as (A).</p></caption>
<graphic xlink:href="551058v3_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Orientation reconstructions in primary motor cortex (M1) at the population level using IEMs.</title><p>(A) Time course of representational strength of orientations at M1 in Experiment 1. Gray shaded areas indicate the entire memory delay following task cue. The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected) at <italic>p</italic> &lt; 0.05. Horizontal dashed lines represent a baseline of 0. Shaded areas represent Â± SEM. (B) Time course of representational strength of orientations at M1 in Experiment 2. Same conventions as (A).</p></caption>
<graphic xlink:href="551058v3_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><title>Behavioral performance of Experiment 2.</title><p>(A) Accuracy (upper) and reaction time (lower) of maintenance (blue) and categorization (orange) tasks in Experiment 2. Asterisks denote significant results, n.s.: not significant; **: <italic>p</italic> &lt; 0.01. (B) Accuracy (upper) and reaction time (lower) for orientations based on their distances from category center for categorization task. Shaded areas represent Â± SEM. Vertical dashed line represents category center.</p></caption>
<graphic xlink:href="551058v3_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5.</label>
<caption><title>Behavioral correlation of stimulus representation in Experiment 2.</title><p>Time course of correlation coefficients in EVC, IPS, and sPCS. Correlation was performed between strength of stimulus representations and behavioral performance (accuracy) for maintenance (blue) and categorization (orange) tasks. Gray shaded areas indicate the entire memory delay following task cue. Horizontal dashed lines represent a baseline of 0. Bottom dots indicate the significance of corresponding analyses at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). Shaded areas represent Â± SEM.</p></caption>
<graphic xlink:href="551058v3_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Figure S6.</label>
<caption><title>Time course of category and abstract category decoding performance in Experiment 1 and 2.</title><p>(A) Time course of category decoding strength in Experiment 1 with flexible rule (orange) and in Experiment 2 with fixed rule (light orange). Horizontal dashed lines represent the chance level of 0.5. Gray shaded areas indicate the entire memory delay following task cue. Bottom dots indicate uncorrected significance of decoding accuracy at each time point at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). Shaded areas represent Â± SEM. (B) Time course of abstract category decoding strength in Experiment 1 (dark blue) and in Experiment 2 (light blue). Horizontal dashed lines represent a baseline of 0.</p></caption>
<graphic xlink:href="551058v3_figs6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Figure S7.</label>
<caption><title>Stimulus, category, and abstract category results in additional frontal ROIs in Experiment 1 and 2.</title><p>(A) Time course of representational strength of orientations in iPCS, IFS, and MFG in Experiment 1 (top panel) and Experiment 2 (bottom panel). Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent Â± SEM. (B) Average category decoding accuracy across the late task epoch (11 â 16 s) in iPCS, IFS, and MFG of both experiments. (C) Average abstract category decoding index across the late task epoch (11 â 16 s) in the same regions of both experiments, black asterisks denote FDR-corrected significance, n.s.: not significant; *: <italic>p</italic> &lt; 0.05.</p></caption>
<graphic xlink:href="551058v3_figs7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs8" position="float" orientation="portrait" fig-type="figure">
<label>Figure S8.</label>
<caption><title>RNN results using IEMs.</title><p>Difference in the IEM fidelity of orientation representations between tasks in RNN2. Results were averaged across the delay period. Uncorrected p-values from Module 1 to 3: 0.10, 0.48, 0.01. Positive difference indicates higher fidelity for categorization, and negative difference indicates higher fidelity for maintenance. Error bars represent Â± SEM.</p></caption>
<graphic xlink:href="551058v3_figs8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s7">
<title>Supplemental Tables</title>
<table-wrap id="tbls1" orientation="portrait" position="float">
<label>Supplemental Table 1.</label>
<caption><title>P-values for the time course of IEM results in <xref rid="fig2" ref-type="fig">Figure 2</xref>.</title><p>Underline denotes significant results (<italic>p</italic> &lt; 0.05).</p></caption>
<graphic xlink:href="551058v3_tbls1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbls2" orientation="portrait" position="float">
<label>Supplemental Table 2.</label>
<caption><title>P-values for the time course of correlation results in <xref rid="fig3" ref-type="fig">Figure 3</xref>.</title><p>Underline denotes significant results (<italic>p</italic> &lt; 0.05).</p></caption>
<graphic xlink:href="551058v3_tbls2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbls3" orientation="portrait" position="float">
<label>Supplemental Table 3.</label>
<caption><title>P-values for the time course of IEM results in <xref rid="fig4" ref-type="fig">Figure 4</xref>.</title><p>Underline denotes significant results (<italic>p</italic> &lt; 0.05).</p></caption>
<graphic xlink:href="551058v3_tbls3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Xue</surname>
<given-names>Gui</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This work presents <bold>important</bold> findings that the human frontal cortex is involved in a flexible, dual role in both maintaining information in short-term memory, and controlling this memory content to guide adaptive behavior and decisions. The evidence supporting the conclusions is <bold>compelling</bold>, with a well-designed task, best-practice decoding methods, and careful control analyses. The work will be of broad interest to cognitive neuroscience researchers working on working memory and cognitive control.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this manuscript, Shao et al. investigate the contribution of different cortical areas to working memory maintenance and control processes, an important topic involving different ideas about how the human brain represents and uses information when no longer available to sensory systems. In two fMRI experiments, they demonstrate that human frontal cortex (area sPCS) represents stimulus (orientation) information both during typical maintenance, but even more so when a categorical response demand is present. That is, when participants have to apply an added level of decision control to the WM stimulus, sPCS areas encode stimulus information more than conditions without this added demand. These effects are then expanded upon using multi-area neural network models, recapitulating the empirical gradient of memory vs control effects from visual to parietal and frontal cortices. Multiple experiments and analysis frameworks provide support for the authors' conclusions, and control experiments and analysis are provided to help interpret and isolate the frontal cortex effect of interest. While some alternative explanations/theories may explain the roles of frontal cortex in this study and experiments, important additional analyses have been added that help ensure a strong level of support for these results and interpretations.</p>
<p>Strengths:</p>
<p>- The authors use an interesting and clever task design across two fMRI experiments that is able to parse out contributions of WM maintenance alone along with categorical, rule-based decisions. Importantly, the second experiment only uses one fixed rule, providing both an internal replication of Experiment 1's effects and extending them to a different situation when rule switching effects are not involved across mini-blocks.</p>
<p>- The reported analyses using both inverted encoding models (IEM) and decoders (SVM) demonstrate the stimulus reconstruction effects across different methods, which may be sensitive to different aspects of the relationship between patterns of brain activity and the experimental stimuli.</p>
<p>- Linking the multivariate activity patterns to memory behavior is critical in thinking about the potential differential roles of cortical areas in sub-serving successful working memory. Figure 3's nicely shows a similar interaction to that of Figure 2 in the role of sPCS in the categorization vs. maintenance tasks. This is an important contribution to the field when we consider how a distributed set of interacting cortical areas supports successful working memory behavior.</p>
<p>- The cross-decoding analysis in Figure 4 is a clever and interesting way to parse out how stimulus and rule/category information may be intertwined, which would have been one of the foremost potential questions or analyses requested by careful readers.</p>
<p>- Additional ROI analyses in more anterior regions of the PFC help to contextualize the main effects of interest in the sPCS (and no effect in the inferior frontal areas, which are also retinotopic, adds specificity). And, more explanation for how motor areas or preparation are likely not involved strengthens the takeaways of the study (M1 control analysis).</p>
<p>Weaknesses:</p>
<p>- An explicit, quantitative link between the RNN and fMRI data is perhaps a last point that would integrate the RNN conclusion and analyses in line with the human imaging data.</p>
<p>- As Rev 2 mentions, multiple types of information codes may be present, and the response letter Figure 5 using representational similarity (RSA) gets at this question. It would strengthen the work to, at minimum, include this analysis as an extended or supplemental figure.</p>
<p>To sum up the results, a possible, brief schematic of each cortical area analyzed and its contribution to information coding in WM and successful subsequent behavior may help readers take away important conclusions of the cortical circuitry involved.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The author provide evidence that helps resolve long-standing questions about the differential involvement of frontal and posterior cortex in working memory. They show that whereas early visual cortex shows stronger decoding of memory content in a memorization task vs a more complex categorization task, frontal cortex shows stronger decoding during categorization tasks than memorization tasks. They find that task-optimized RNNs trained to reproduce the memorized orientations show some similarities in neural decoding to people. Together, this paper presents interesting evidence for differential responsibilities of brain areas in working memory.</p>
<p>Strengths:</p>
<p>This paper was overall strong. It had a well-designed task, best-practice decoding methods, and careful control analyses. The neural network modeling adds additional insight into the potential computational roles of different regions.</p>
<p>Weaknesses:</p>
<p>Few. While more could be perhaps done to understand the RNN-fMRI correspondence, the paper contributes a compelling set of empirical findings and interpretations that can inform future research.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Shao</surname>
<given-names>Zhujun</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-0886-4606</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Mengya</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-9197-1698</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Yu</surname>
<given-names>Qing</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8480-7634</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authorsâ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>In this manuscript, Shao et al. investigate the contribution of different cortical areas to working memory maintenance and control processes, an important topic involving different ideas about how the human brain represents and uses information when it is no longer available to sensory systems. In two fMRI experiments, they demonstrate that the human frontal cortex (area sPCS) represents stimulus (orientation) information both during typical maintenance, but even more so when a categorical response demand is present. That is, when participants have to apply an added level of decision control to the WM stimulus, sPCS areas encode stimulus information more than conditions without this added demand. These effects are then expanded upon using multi-area neural network models, recapitulating the empirical gradient of memory vs control effects from visual to parietal and frontal cortices. In general, the experiments and analyses provide solid support for the authors' conclusions, and control experiments and analyses are provided to help interpret and isolate the frontal cortex effect of interest. However, I suggest some alternative explanations and important additional analyses that would help ensure an even stronger level of support for these results and interpretations.</p>
<p>Strengths:</p>
<p>-  The authors use an interesting and clever task design across two fMRI experiments that is able to parse out contributions of WM maintenance alone along with categorical, rule-based decisions. Importantly, the second experiment only uses one fixed rule, providing both an internal replication of Experiment 1's effects and extending them to a different situation when rule-switching effects are not involved across mini-blocks.</p>
<p>- The reported analyses using both inverted encoding models (IEM) and decoders (SVM) demonstrate the stimulus reconstruction effects across different methods, which may be sensitive to different aspects of the relationship between patterns of brain activity and the experimental stimuli.</p>
<p>- Linking the multivariate activity patterns to memory behavior is critical in thinking about the potential differential roles of cortical areas in sub-serving successful working memory. Figure 3 nicely shows a similar interaction to that of Figure 2 in the role of sPCS in the categorization vs. maintenance tasks.</p>
<p>- The cross-decoding analysis in Figure 4 is a clever and interesting way to parse out how stimulus and rule/category information may be intertwined, which would have been one of the foremost potential questions or analyses requested by careful readers. However, I think more additional text in the Methods and Results to lay out the exact logic of this abstract category metric will help readers bet0ter interpret the potential importance of this analysis and result.</p>
</disp-quote>
<p>We thank the reviewer for the positive assessment of our manuscript. Please see lines 366-372, 885-894 in the revised manuscript for a detailed description of the abstract category index, and see below for a detailed point-by-point response.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>- Selection and presentation of regions of interest: I appreciate the authors' care in separating the sPCS region as &quot;frontal cortex&quot;, which is not necessarily part of the prefrontal cortex, on which many ideas of working memory maintenance activity are based. However, to help myself and readers interpret these findings, at a minimum the boundaries of each ROI should be provided as part of the main text or extended data figures. Relatedly, the authors use a probabilistic visual atlas to define ROIs in the visual, parietal, and frontal cortices. But other regions of both lateral frontal and parietal cortices show retinotopic responses (Mackey and Curtis, eLife, 2017: <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/22974">https://elifesciences.org/articles/22974</ext-link>) and are perhaps worth considering. Do the inferior PCS regions or inferior frontal sulcus show a similar pattern of effects across tasks? And what about the middle frontal gyrus areas of the prefrontal cortex, which are most analogous to the findings in NHP studies that the authors mention in their discussion, but do not show retinotopic responses? Reporting the effects (or lack thereof) in other areas of the frontal cortex will be critical for readers to interpret the role of the frontal cortex in guiding WM behavior and supporting the strongly worded conclusions of broad frontal cortex functioning in the paper. For example, to what extent can sPCS results be explained by visual retinotopic responses? (Mackey and Curtis, eLife, 2017: <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/22974">https://elifesciences.org/articles/22974</ext-link>).</p>
</disp-quote>
<p>We thank the reviewer for the suggestions. We have added a Supplemental Figure 1 to better illustrate the anatomical locations of ROIs.</p>
<p>Following the reviewerâs suggestion, we defined three additional subregions in the frontal cortex based on the HCP atlas [1], including the inferior precentral sulcus (iPCS, generated by merging 6v, 6r, and PEF), inferior frontal sulcus (IFS, generated by merging IFJp, IFJa, IFSp, IFSa, and p47r), and middle frontal gyrus (MFG, generated by merging 9-46d, 46, a9-46v, and p9-46v). We then performed the same analyses as in the main text using both mixed-model and within-condition IEMs. Overall, we found that none of the ROIs demonstrated significant orientation representation in Experiment 1, for either IEM analysis (Author response image 1A and 1C). In Experiment 2, however, the IFS and MFG (but not iPCS) demonstrated a similar pattern to sPCS for orientation representation, though these results did not persist in the within-condition IEM with lower SNR (Author response image 1B and 1D). Moreover, when we performed the abstract category decoding analysis in the three ROIs, only the MFG in Experiment 2 showed significant abstract category decoding results, with no significant difference between experiments (Author response image 1E). To summarize, the orientation and category results observed in sPCS in the original manuscript were largely absent in other frontal regions. There was some indication that the MFG might share some results for orientation representation and category decoding, although this pattern was weaker and was only observed in some analyses in Experiment 2. Therefore, although we did not perform retinotopic mapping and cannot obtain a direct measure of retinotopic responses in the frontal cortex, these results suggest that our findings are unlikely to be explained by visual retinotopic responses: the iPCS, which is another retinotopic region, did not show the observed pattern in any of the analyses. Notably, the iPCS results are consistent with our previous work demonstrating that orientation information cannot be decoded from iPCS during working memory delay [2]. We have included these results on lines 395-403, 563-572 in the revised manuscript to provide a more comprehensive understanding of the current findings.</p>
<fig id="sa3fig1">
<label>Author response image 1.</label>
<caption>
<title>Orientation reconstruction and abstract category decoding results in iPCS, IFS, and MFG.</title>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-100287-sa3-fig1.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>- When looking at the time course of effects in Figure 2, for example, the sPCS maintenance vs categorization effects occur very late into the WM delay period. More information is needed to help separate this potential effect from that of the response period and potential premotor/motor-related influences. For example, are the timecourses shifted to account for hemodynamic lag, and if so, by how much? Do the sPCS effects blend into the response period? This is critical, too, for a task that does not use a jittered delay period, and potential response timing and planning can be conducted by participants near the end of the WM delay. For example, the authors say that &quot; significant stimulus representation in EVC even when memoranda had been transformed into a motor format (24)&quot;. But, I *think* this paper shows the exact opposite interpretation - EVC stimulus information is only detectable when a motor response *cannot* be planned (<ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/75688">https://elifesciences.org/articles/75688</ext-link>). Regardless, parsing out the timing and relationship to response planning is important, and an ROI for M1 or premotor cortex could also help as a control comparison point, as in reference (24).</p>
</disp-quote>
<p>We thank the reviewer for raising this point. We agree that examining the contribution of response-related activity in our study is crucial, as we detail below:</p>
<p>First, the time course results in the manuscript are presented without time shifting. The difference in orientation representation in Figure 2 emerged at around 7 s after task cue onset and 1 s before probe onset. Considering a 4-6 s hemodynamic response lag, the difference should occur around 1-3 s after task cue onset and 5-7 s prior to probe onset. This suggests that a substantial portion of the effect likely occurred during the delay rather than response period.</p>
<p>Second, our experimental design makes it unlikely that response planning would have influenced our results, as participants were unable to plan their motor responses in advance due to randomized response mapping at the probe stage on a trial-by-trial basis. Moreover, even if response planning had impacted the results in sPCS, it would have affected both conditions similarly, which again, would not explain the observed differences between conditions.</p>
<p>Third, following the reviewerâs suggestion, we defined an additional ROI (the primary motor cortex, M1) using the HCP atlas and repeated the IEM analysis. No significant orientation representation was observed in either condition in M1, even during the response period (Figure S3), further suggesting that our results are unlikely to be explained by motor responses or motor planning.</p>
<p>Based on the evidence above, we believe motor responses or planning are unlikely to account for our current findings. We have included these results on lines 264-267 to further clarify this issue.</p>
<p>Lastly, upon re-reading the Henderson et al. paper [3], we confirmed that stimulus information was still decodable in EVC when a motor response could be planned (Figure 2 of Henderson et al.). In fact, the authors also discussed this result in paragraph 5 of their discussion. This finding, together with our results in EVC, indicates that EVC maintains stimulus information in working memory even when the information is no longer task-relevant, the functional relevance of which warrants further investigation in future research.</p>
<disp-quote content-type="editor-comment">
<p>- Interpreting effect sizes of IEM and decoding analysis in different ROIs. Here, the authors are interested in the interaction effects across maintenance and categorization tasks (bar plots in Figure 2), but the effect sizes in even the categorization task (y-axes) are always larger in EVC and IPS than in the sPCS region... To what extent do the authors think this representational fidelity result can or cannot be compared across regions? For example, a reader may wonder how much the sPCS representation matters for the task, perhaps, if memory access is always there in EVC and IPS? Or perhaps late sPCS representations are borrowing/accessing these earlier representations? Giving the reader some more intuition for the effect sizes of representational fidelity will be important. Even in Figure 3 for the behavior, all effects are also seen in IPS as well. More detail or context at minimum is needed about the representational fidelity metric, which is cited in ref (35) but not given in detail. These considerations are important given the claims of the frontal cortex serving such an important for flexible control, here.</p>
</disp-quote>
<p>We thank the reviewer for raising this point. We agree that the effect sizes are always larger in EVC and IPS. This is because the specific decoding method we adopted, IEM, is based on the concept of population-level feature-selective responses, and decoding results would be most robust in regions with strong feature-tuning responses, such as EVC and parts of IPS. Therefore, to minimize the impact of effect size on our results, we avoided direct comparisons of representational strength across ROIs, focusing instead on differences in representational strength between conditions within the same ROI. With this approach, we found that EVC and IPS showed high representational fidelity throughout the trial, but only in sPCS did we observe significant higher fidelity in categorization condition, where orientation was actually not a behavioral goal but was manipulated in working memory to achieve the goal. Moreover, although representational fidelity in the EVC was the highest, its behavioral predictability decreased during the delay period, unlike sPCS. These results suggest that the magnitude of fidelity alone is not the determining factor for the observed categorization vs. maintenance effect or for behavioral performance. We have included further discussion on this issue on lines 208-211 of the revised manuscript.</p>
<p>The reviewer also raised a good point that IPS showed similar behavioral correlation results as sPCS. In the original manuscript, we discussed the functional similarities and distinctions between IPS and sPCS in the discussion. We have expanded on this point on lines 610-627 in the revised manuscript:</p>
<p>âWhile many previous WM studies have focused on the functional distinction between sensory and frontoparietal cortex, it has remained less clear how frontal and parietal cortex might differ in terms of WM functions. Some studies have reported stimulus representations with similar functionality in frontal and parietal cortex [4, 5], while others have observed differential patterns [6-8]. We interpret the differential patterns as reflecting a difference in the potential origin of the corresponding cognitive functions. For example, in our study, sPCS demonstrated the most prominent effect for enhanced stimulus representation during categorization as well as the tradeoff between stimulus difference and category representation, suggesting that sPCS might serve as the source region for such effects. On the other hand, IPS did show visually similar patterns to sPCS in some analyses. For instance, stimulus representation in IPS was visually but not statistically higher in the categorization task. Additionally, stimulus representation in IPS also predicted behavioral performance in the categorization task. These results together support the view that our findings in sPCS do not occur in isolation, but rather reflect a dynamic reconfiguration of functional gradients along the cortical hierarchy from early visual to parietal and then to frontal cortex.â</p>
<p>Lastly, following the reviewerâs suggestion, we have included more details on the representational fidelity metric on lines 201-206, 856-863 in the revised manuscript for clarity.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations:</bold></p>
<p>Figure 3 layout - this result is very interesting and compelling, but I think could be presented to have the effect demonstrated more simply for readers. The scatter plots in the second and third rows take up a lot of space, and perhaps having a barplot as in Figure 2 showing the effects of brain-behavior correlations collapsed across the WM delay period timing would make the effect stand out more.</p>
</disp-quote>
<p>We thank the reviewer for the suggestion. We have added a subplot (C) to Figure 3 to demonstrate the brain-behavior correlation collapsed across the late task epoch.</p>
<disp-quote content-type="editor-comment">
<p>When discussing the link between sPCS representations and behavior, I think this paper should likely be cited ([<ext-link ext-link-type="uri" xlink:href="https://www.jneurosci.org/content/24/16/3944](https://www.jneurosci.org/content/24/">https://www.jneurosci.org/content/24/16/3944](https://www.jneurosci.org/content/24/</ext-link> 16/3944)), which shows univariate relationships between sPCS delay activity and memory-guided saccade performance.</p>
</disp-quote>
<p>We thank the reviewer for the suggestion and have included this citation on lines 278-279 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Interpretation of &quot;control&quot; versus categorization - the authors interpret that &quot;It would be of interest to further investigate whether this active control in the frontal cortex could be generalized to tasks that require other types of WM control such as mental rotation.&quot; I think more discussion on the relationship between categorization and &quot;control&quot; is needed, especially given the claim of &quot;flexible control&quot; throughout. Is stimulus categorization a form of cognitive control, and if so, how?</p>
</disp-quote>
<p>We thank the reviewer for raising this point. Cognitive control is generally defined as the process by which behavior is flexibly adapted based on task context and goals, and most theories agree that this process occurs within working memory [9, 10]. With this definition, we consider stimulus categorization to be a form of cognitive control, because participants needed to adapt the stimulus based on the categorization rule in working memory for subsequent category judgements. With two categorization rules, the flexibility in cognitive control increased, because participants need to switch between the two rules multiple times throughout the experiment, instead of being fixed on one rule. We now clarify these two types of controls on lines 112-116 in the introduction.</p>
<p>However, we agree that the latter form of control could be more related to rule switching that might not be specific to categorization per se. For instance, if participants perform rule switching in another type of WM task that requires WM control such as mental rotation, it remains to be tested whether similar results would be observed and/or whether same brain regions would be recruited. We have included further information on this issue on lines 572-575 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>The authors provide evidence that helps resolve long-standing questions about the differential involvement of the frontal and posterior cortex in working memory. They show that whereas the early visual cortex shows stronger decoding of memory content in a memorization task vs a more complex categorization task, the frontal cortex shows stronger decoding during categorization tasks than memorization tasks. They find that task-optimized RNNs trained to reproduce the memorized orientations show some similarities in neural decoding to people. Together, this paper presents interesting evidence for differential responsibilities of brain areas in working memory.</p>
<p>Strengths:</p>
<p>This paper was strong overall. It had a well-designed task, best-practice decoding methods, and careful control analyses. The neural network modelling adds additional insight into the potential computational roles of different regions.</p>
</disp-quote>
<p>We thank the reviewer for the positive assessment of our manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>While the RNN model matches some of the properties of the task and decoding, its ability to reproduce the detailed findings of the paper was limited. Overall, the RRN model was not as well-motivated as the fMRI analyses.</p>
</disp-quote>
<p>We are grateful for the reviewerâs suggestions on improving our RNN results. Please see below for a detailed point-by-point response.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations:</bold></p>
<p>Overall, I thought that this paper was excellent. I have some conceptual concerns about the RNN model, and minor recommendations for visualization.</p>
<p>(1) I think that the RNN modelling was certainly interesting and well-executed. However, it was not clear how much it contributed to the results. On the one hand, it wasn't clear why reproducing the stimulus was a critical objective of the task (ie could be more strongly motivated on biological grounds). On the other hand, the agreement between the model and the fMRI results is not that strong. The model does not reproduce stronger decoding in 'EVC' for maintenance vs categorization. Also, the pattern of abstract decoding is very different from the fMRI (eg the RNN has stronger categorical encoding in 'EVC' than 'PFC' and larger differences between fixed and flexible rules in earlier areas than is evident in the fMRI). Together, the RNN modelling comes across as a little ad hoc, without really nailing the performance.</p>
</disp-quote>
<p>We thank the reviewer for prompting us to further elaborate on the rationale for our RNN analysis. In our fMRI results, we observed a tradeoff between maintaining stimulus information in more flexible tasks (Experiment 1) and maintaining abstract category information in less flexible tasks (Experiment 2). This led to the hypothesis that participants might have employed different coding strategies in the two experiments. Specifically, in flexible environments, stimulus information might be preserved in its original identity in the higher-order cortex, potentially reducing processing demands in each task and thereby facilitating efficiency and flexibility; whereas in less flexible tasks, participants might generate more abstract category representations based on task rules to facilitate learning. To directly test this idea, we examined whether explicitly placing a demand for the RNN to preserve stimulus representation would recapitulate our fMRI findings in frontal cortex by having stimulus information as an output, in comparison to a model that did not specify such a demand. Meanwhile, we totally agree with the reviewer that there are alternative ways to implement this objective in the model. For instance, changing the network encoding weights (lazy vs. rich regime) to make feedforward neural networks either produce high-dimensional stimulus or low-dimensional category representations [11]. However, we feel that exploring these alternatives may fall outside the scope of the current study.</p>
<p>Regarding the alignment between the fMRI and RNN results: for the stimulus decoding results in EVC, we found that with an alternative decoding method (IEM), a similar maintenance &gt; categorization pattern was observed in EVC-equivalent module, suggesting that our RNN was capable of reproducing EVC results, albeit in a weaker manner (please see our response to the reviewerâs next point). For the category decoding results, we would like to clarify that the category decoding results in EVC was <italic>not</italic> necessarily better than those in sPCS. Although category decoding accuracy was numerically higher in EVC, it was more variable compared to IPS and sPCS. To illustrate this point, we calculated the Bayes factor for the category decoding results of RNN2 in Figure 6C, and found that the amount of evidence for category decoding as well as for the decoding difference between RNNs in IPS and sPCS modules was high, whereas the evidence in the EVC was insufficient (Response Table 1).</p>
<table-wrap id="sa3table1">
<label>Author response table 1.</label>
<caption>
<title>Bayes factors for category decoding and decoding differences in Figure 6C lower panel.</title>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-100287-sa3-table1.jpg" mimetype="image"/>
</table-wrap>
<p>Nevertheless, we agree with the reviewer that all three modules demonstrated the category decoding difference between experiments, which differs from our fMRI results. This discrepancy may be partially due to differences in signal sensitivity. RNN signals typically have a higher SNR compared to fMRI signals, as fMRI aggregates signals from multiple neurons and single-neuron tuning effects can be reduced. We have acknowledged this point on lines 633-636 in the revised manuscript. Nonetheless, the current RNNs effectively captured our key fMRI findings, including increased stimulus representation in frontal cortex as well as the tradeoff in category representation with varying levels of flexible control. We believe the RNN results remain valuable in this regard.</p>
<disp-quote content-type="editor-comment">
<p>Honestly, I think the paper would have a very similar impact without the modelling results, but I appreciate that you put a lot of work into the modeling, and this is an interesting direction for future research. I have a few suggestions, but nothing that I feel too strongly about.</p>
<p>- It might be informative to use IEM to better understand the RNN representations (and how similar they are to fMRI). For example, this could show whether any of the modules just encode categorical information.</p>
<p>- You could try providing the task and/or retro cue directly to the PFC units. This is a little unrealistic, but may encourage a stronger role for PFC.</p>
<p>- You might adjust the ratio of feedforward/feedback connections, if you can find good anatomical guidance on what these should be.</p>
<p>Obviously, I don't have much - it's a tricky problem!</p>
</disp-quote>
<p>We thank the reviewer for the suggestions. To better align the fMRI and RNN results, we first performed the same IEM analyses used in the fMRI analyses on the RNN data. We found that with IEM, the orientation representation in the EVC module demonstrated a pattern similar to that in the fMRI data, showing a negative trend for the difference between categorization and maintenance, although the trend did not reach statistical significance (Author response image 2A). Meanwhile, the difference between categorization and maintenance remained a positive trend in the sPCS module.</p>
<p>Second, following the reviewerâs suggestion, we adjusted the ratio of feedforward/feedback connections between modules to 1:2, such that between Modules 1 and 2 and between Modules 2 and 3, there were always more feedback than feedforward connections, consistent with recent theoretical proposals [12]. We found that, this change preserved the positive trend for orientation differences in the sPCS module, but in the meantime also made the orientation difference in the EVC and IPS modules more positive (Author response image 2B).</p>
<p>To summarize, we found that the positive difference between categorization and maintenance in the sPCS module was robust across difference RNNs and analytical approaches, further supporting that RNNs with stimulus outputs can replicate our key fMRI findings in the frontal cortex. By contrast, the negative difference between categorization and maintenance in EVC was much weaker. It was weakly present using some analytical methods (i.e., the IEM) but not others (i.e., SVMs), and increasing the feedback ratio of the entire network further weakened this difference. We believe that this could be due to that the positive difference was mainly caused by top-down, feedback modulations from higher cortex during categorization, such that increasing the feedback connection strengthens this pattern across modules. We speculate that enhancing the negative difference in the EVC module might require additional modules or inputs to strengthen fine-grained stimulus representation in EVC, a mechanism that might be of interest to future research. We have added a paragraph to the discussion on the limitations of the RNN results on lines 629-644.</p>
<p><bold>Author response Image 2.</bold></p>
<p>Stimulus difference across RNN modules.  (A). Results using IEM (p-values from Module 1 to 3: 0.10, 0.48, 0.01). (B). Results using modified RNN2 with changed connection ratio (p-values from Module 1 to 3: 0.12, 0.22, 0.08). All p-values remain uncorrected.</p>
<disp-formula id="sa3equ1">
<graphic mime-subtype="jpg" xlink:href="elife-100287-sa3-equ1.jpg" mimetype="image"/>
</disp-formula>
<disp-quote content-type="editor-comment">
<p>(2) Can you rule out that during the categorization task, the orientation encoding in PFC isn't just category coding? You had good controls for category coding, but it would be nice to see something for orientation coding. e.g., fit your orientation encoding model after residualizing category encoding, or show that category encoding has worse CV prediction than orientation encoding.</p>
</disp-quote>
<p>We thank the reviewer for raising this point. To decouple orientation and category representations, we performed representational similarity analysis (RSA) in combination with linear mixed-effects modeling (LMEM) on the fMRI data. Specifically, we constructed three hypothesized representational dissimilarity matrices (RDMs), one for graded stimulus (increasing distance between orientations as they move farther apart, corresponding to graded feature tuning responses), one for abstract category (0 for all orientations within the same category and 1 for different categories), and another for discrete stimulus (indicating equidistant orientation representations). We then fit the three model RDMs together using LMEM with subject as the random effect (Author response image 3A). This approach is intended to minimize the influence of collinearity between RDMs on the results [13].</p>
<p>Overall, the LMEM results (Author response image 3B-D) replicated the decoding results in the main text, with significant stimulus but not category representation in sPCS in Experiment 1, and marginally significant category representation in the same brain region in Experiment 2. These results further support the validity of our main findings and emphasize the contribution of stimulus representation independent of category representation.</p>
<fig id="sa3fig2">
<label>Author response image 3.</label>
<caption>
<title>Delineating stimulus and category effects using LMEM.</title>
<p>(A) Schematic illustration of this method. (B) Results for late epoch in Experiment 1, showing the fit of each model RDM. (C) Results for early epoch in Experiment 2. (D) Results for late epoch in Experiment 2.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-100287-sa3-fig2.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>(3) Is it possible that this region of PFC is involved in categorization in particular and not 'control-demanding working memory'?</p>
</disp-quote>
<p>We thank the reviewer for raising this possibility. Cognitive control is generally defined as the process by which behavior is flexibly adapted based on task context and goals, and most theories agree that this process occurs within working memory [9, 10]. With this definition, we consider stimulus categorization to be a form of cognitive control, because participants need to adapt the stimulus based on the categorization rule in working memory for subsequent category judgements.  However, in the current study we only used one type of control-demanding working memory task (categorization) to test our hypothesis, and therefore it remains unclear whether the current results in sPCS can generalize to other types of WM control tasks.</p>
<p>We have included a discussion on this issue on lines 572-575 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(4) Some of the figures could be refined to make them more clear:</p>
<p>a.  Figure 4 b/c should have informative titles and y-axis labels.</p>
<p>b.  Figure 5, the flexible vs fixed rule isn't used a ton up to this point - it would help to (also include? Replace?) with something like exp1/exp2 in the legend. It would also help to show the true &amp; orthogonal rule encoding in these different regions (in C, or in a separate panel), especially to the extent that this is a proxy for stimulus encoding.</p>
<p>c.  Figure 6: B and C are very hard to parse right now. (i) The y-axis on B could use a better label. (ii) It would be useful to include an inset of the relevant data panel from fMRI that you are reproducing. (iii) Why aren't there fixed rules for RNN1?</p>
</disp-quote>
<p>We thank the reviewer for the suggestions and have updated the figures accordingly as following:</p>
<disp-quote content-type="editor-comment">
<p>Overall I think this is excellent - my feedback is mostly on interpretation and presentation. I think the work itself is really well done, congrats!</p>
</disp-quote>
<p>References</p>
<p>(1) Glasser, M.F., et al., A multi-modal parcellation of human cerebral cortex. Nature, 2016. 536(7615): p. 171-178.</p>
<p>(2) Yu, Q. and Shim, W.M., Occipital, parietal, and frontal cortices selectively maintain taskrelevant features of multi-feature objects in visual working memory. Neuroimage, 2017. 157: p. 97-107.</p>
<p>(3) Henderson, M.M., Rademaker, R.L., and Serences, J.T., Flexible utilization of spatial- and motor-based codes for the storage of visuo-spatial information. Elife, 2022. 11.</p>
<p>(4) Christophel, T.B., et al., Cortical specialization for attended versus unattended working memory. Nat Neurosci, 2018. 21(4): p. 494-496.</p>
<p>(5) Yu, Q. and Shim, W.M., Temporal-Order-Based Attentional Priority Modulates Mnemonic Representations in Parietal and Frontal Cortices. Cereb Cortex, 2019. 29(7): p. 3182-3192.</p>
<p>(6) Li, S., et al., Neural Representations in Visual and Parietal Cortex Differentiate between Imagined, Perceived, and Illusory Experiences. J Neurosci, 2023. 43(38): p. 6508-6524.</p>
<p>(7) Hu, Y. and Yu, Q., Spatiotemporal dynamics of self-generated imagery reveal a reverse cortical hierarchy from cue-induced imagery. Cell Rep, 2023. 42(10): p. 113242.</p>
<p>(8) Lee, S.H., Kravitz, D.J., and Baker, C.I., Goal-dependent dissociation of visual and prefrontal cortices during working memory. Nat Neurosci, 2013. 16(8): p. 997-9.</p>
<p>(9) Miller, E.K. and Cohen, J.D., An integrative theory of prefrontal cortex function. Annu Rev Neurosci, 2001. 24: p. 167-202.</p>
<p>(10) Badre, D., et al., The dimensionality of neural representations for control. Curr Opin Behav Sci, 2021. 38: p. 20-28.</p>
<p>(11) Flesch, T., et al., Orthogonal representations for robust context-dependent task performance in brains and neural networks. Neuron, 2022. 110(7): p. 1258-1270 e11.</p>
<p>(12) Wang, X.J., Theory of the Multiregional Neocortex: Large-Scale Neural Dynamics and Distributed Cognition. Annu Rev Neurosci, 2022. 45: p. 533-560.</p>
<p>(13) Bellmund, J.L.S., et al., Mnemonic construction and representation of temporal structure in the hippocampal formation. Nat Commun, 2022. 13(1): p. 3395.</p>
</body>
</sub-article>
</article>