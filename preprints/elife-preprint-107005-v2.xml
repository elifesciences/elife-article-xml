<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107005</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107005</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107005.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Synaptic Encoding of Time in Working Memory</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6885-9394</contrib-id>
<name>
<surname>Mongillo</surname>
<given-names>Gianluigi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>gianluigi.mongillo@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5661-4349</contrib-id>
<name>
<surname>Tsodyks</surname>
<given-names>Misha</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f809463</institution-id><institution>School of Natural Sciences, Institute for Advanced Study</institution></institution-wrap>, <city>Princeton</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02en5vm52</institution-id><institution>Sorbonne Université, INSERM, CNRS, Institut de la Vision</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02feahw73</institution-id><institution>Centre National de la Recherche Scientifique</institution></institution-wrap>, <city>Paris</city>, <country country="FR">France</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0316ej306</institution-id><institution>Department of Brain Sciences, Weizmann Institute of Science</institution></institution-wrap>, <city>Rehovot</city>, <country country="IL">Israel</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country country="GR">Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-07-22">
<day>22</day>
<month>07</month>
<year>2025</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2026-01-22">
<day>22</day>
<month>01</month>
<year>2026</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107005</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-04-21">
<day>21</day>
<month>04</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-04-23">
<day>23</day>
<month>04</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.04.21.649874"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-07-22">
<day>22</day>
<month>07</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.107005.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.107005.1.sa3">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.107005.1.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.107005.1.sa1">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.107005.1.sa0">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Mongillo &amp; Tsodyks</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Mongillo &amp; Tsodyks</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107005-v2.pdf"/>
<abstract>
<p>The processing of temporally-extended sequences of stimuli critically relies on Working Memory (WM). Yet, how WM supports the encoding and retrieval of novel sequences is unknown. Existing theories rely on associative learning driven by repetitions and are, thus, unable to explain how people can reproduce novel sequences of stimuli immediately. Here, we propose that detailed temporal information about a novel sequence can be rapidly stored in WM by short-term synaptic plasticity over multiple time scales. To substantiate this proposal, we extend our previously-proposed synaptic theory of WM to include synaptic augmentation, besides more short-lived depression and facilitation, consistently with experimental observations. The long time scales associated with augmentation naturally lead to the emergence of a temporal gradient in the synaptic efficacies, which can be used to immediately replay, at normal speed or in a time-compressed way, novel sequences. The theory is consistent with behavioral and neurophysiological observations.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>sequences</kwd>
<kwd>interval timing</kwd>
<kwd>working memory</kwd>
<kwd>synaptic augmentation</kwd>
</kwd-group>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id>
<institution>Agence Nationale de la Recherche (ANR)</institution>
</institution-wrap>
</funding-source>
<award-id>ANR-19-CE16-0024-01</award-id>
<principal-award-recipient>
<name>
<surname>Mongillo</surname>
<given-names>Gianluigi</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001665</institution-id>
<institution>Agence Nationale de la Recherche (ANR)</institution>
</institution-wrap>
</funding-source>
<award-id>ANR-20-CE16-0011-02</award-id>
<principal-award-recipient>
<name>
<surname>Mongillo</surname>
<given-names>Gianluigi</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-3">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id>
<institution>Simons Foundation (SF)</institution>
</institution-wrap>
</funding-source>
<award-id>89185</award-id>
<principal-award-recipient>
<name>
<surname>Mongillo</surname>
<given-names>Gianluigi</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-4">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003977</institution-id>
<institution>Israel Science Foundation (ISF)</institution>
</institution-wrap>
</funding-source>
<award-id>1657/19</award-id>
<principal-award-recipient>
<name>
<surname>Tsodyks</surname>
<given-names>Misha Misha</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-5">
<funding-source>
<institution-wrap>
<institution>Foundation Adelis</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Tsodyks</surname>
<given-names>Misha Misha</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The manuscript has been updated to address reviewers' comments. These comments, as well as our response to them and the resulting changes to the manuscript, can be accessed by following the link 'TRIP Peer Reviews' on the bioRxiv page associated to the manuscript.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Purposeful behavior requires storing and retrieving relevant information over multiple time scales. Typically, this information also includes a temporal component that is key to achieve the goal. For instance, to reach the closest coffee place we just asked directions to, we have to turn left at the next corner, walk one block, and then turn right. We’ll get no espresso following the directions in the <italic>wrong</italic> order.</p>
<p>The Working Memory (WM) – a specialized, low-capacity component of the memory system – is believed to be responsible for rapidly encoding and maintaining novel information (e.g., the directions we just asked) over short time scales [<xref ref-type="bibr" rid="c1">Cowan, 2001</xref>, <xref ref-type="bibr" rid="c2">Baddeley, 2003</xref>]. But, exactly, which information about a novel sequence of stimuli is stored in WM?</p>
<p>People effortlessly remember short but otherwise arbitrary (i.e., novel) sequences of familiar stimuli. For instance, people routinely hum short tunes they have just heard while musicians can even replay them with fidelity. A person can finger-tap, out of memory and with good accuracy, a pattern of irregularly spaced clicks spread over a few seconds which has been just experienced. The encoding of serial order, in particular, has been extensively investigated in the <italic>serial recall</italic> task [<xref ref-type="bibr" rid="c3">Kahana, 2012</xref>]. In this task, a list of randomly chosen items (e.g., words) is presented sequentially to the subject that, then, has to recall them in the presented order. This task is thought to rely on WM and, indeed, the number of correctly recalled items – typically about 4 items – is a standard measure of WM capacity. Interestingly, people almost invariably recall short lists (i.e., within WM capacity) in the presented order, even without explicit instructions to do so, as in the <italic>free recall</italic> task [<xref ref-type="bibr" rid="c4">Dimperio et al., 2005</xref>, <xref ref-type="bibr" rid="c5">Ward et al., 2010</xref>, <xref ref-type="bibr" rid="c6">Grenfell-Essam and Ward, 2012</xref>].</p>
<p>These observations suggest that WM rapidly and automatically stores quite detailed temporal information about a novel sequence of familiar stimuli, in addition to information about the stimuli themselves.</p>
<p>The models originally proposed for the computational architecture of WM have no mechanism for the encoding of temporal information [<xref ref-type="bibr" rid="c1">Cowan, 2001</xref>, <xref ref-type="bibr" rid="c2">Baddeley, 2003</xref>]. As to neuronal models of WM (i.e., short-term memory maintenance), there have been different proposals. The most popular idea is that active maintenance relies on the co-existence of stable steady states of activity in the memory network (attractors) that are selected by stimulus presentations [<xref ref-type="bibr" rid="c7">Amit, 1995</xref>, <xref ref-type="bibr" rid="c8">Amit and Brunel, 1997</xref>, <xref ref-type="bibr" rid="c9">Wang, 2021</xref>]. The current state of activity, thus, reflects the recent history of stimulation. This mechanism can store the identity of the stimuli in the sequence but not information about their relative timing (e.g., the order of occurrence); this information would then need to be learned in the course of multiple repetitions of the <italic>same</italic> sequence [<xref ref-type="bibr" rid="c10">Kleinfeld, 1986</xref>, <xref ref-type="bibr" rid="c11">Sompolinsky and Kanter, 1986</xref>].</p>
<p>Partly to address the inability of attractor networks to <italic>rapidly</italic> store temporal information, an alternative account has been proposed [<xref ref-type="bibr" rid="c12">Maass et al., 2002</xref>, <xref ref-type="bibr" rid="c13">Buonomano and Maass, 2009</xref>]. In this account, active maintenance relies on the transitory, but high-dimensional, responses elicited by stimulus presentation in the memory network (liquid state machine). Such a mechanism can rapidly store the identity of the stimuli as well as detailed information about their times of occurrence, thanks to the high-dimensionality of the response. However, it is now the read-out of this information that needs to be learned, again in the course of multiple repetitions [<xref ref-type="bibr" rid="c14">Cueva et al., 2020</xref>, <xref ref-type="bibr" rid="c15">Zhou et al., 2023</xref>].</p>
<p>Somehow surprisingly in view of their profound differences, these two accounts make one identical prediction; temporal information about a <italic>novel</italic> sequence of stimuli is not immediately available (e.g., to produce some behavior), either because it has not been stored yet (attractor networks) or because it cannot yet be read-out (liquid state machines). We have just discussed evidence contrary to this prediction.</p>
<p>We have proposed that information is maintained in WM by synaptic facilitation within the neuronal populations that code for the items, rather than by the enhanced, persistent activity of those populations [<xref ref-type="bibr" rid="c16">Mongillo et al., 2008</xref>]. Facilitation is an experimentally well-characterized transient enhancement of the synaptic efficacy that is quickly induced by pre-synaptic spiking activity and can last for up to several seconds [<xref ref-type="bibr" rid="c17">Markram et al., 1998</xref>, <xref ref-type="bibr" rid="c18">Zucker and Regehr, 2002</xref>]. In particular, facilitation was reported at inter-pyramidal connections in the prefrontal cortex, a region heavily implicated in WM [<xref ref-type="bibr" rid="c19">Hempel et al., 2000</xref>, <xref ref-type="bibr" rid="c20">Wang et al., 2006</xref>]. The theory is compatible with multiple experimental observations and motivated further experiments aimed at disentangling persistent activity and information maintenance [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>, <xref ref-type="bibr" rid="c22">Wolff et al., 2017</xref>, <xref ref-type="bibr" rid="c23">Panichello et al., 2024</xref>].</p>
<p>In the framework of the synaptic theory of WM, the maintenance of information can be achieved by different regimes of neuronal activity, depending on the background input to the network; at increasing levels of the background input, these regimes are: (i) activity-silent, where the information is transiently maintained without enhanced spiking activity; (ii) low-activity, where the information is periodically refreshed, at low rate, by brief spontaneous reactivations of corresponding neuronal populations (i.e., population spikes, PSs); (iii) persistent-activity, where the information is maintained by tonically active neuronal populations.</p>
<p>Facilitation is not the only form of transient synaptic enhancement induced by repetitive pre-synaptic activity. Experiments reveal other forms, such as augmentation and potentiation, which build up more slowly than facilitation but are significantly more long-lived [<xref ref-type="bibr" rid="c24">Fisher et al., 1997</xref>, <xref ref-type="bibr" rid="c25">Thomson, 2000</xref>, <xref ref-type="bibr" rid="c26">Fioravante and Regehr, 2011</xref>]. As a result, the instantaneous value of the synaptic efficacy can reflect the history of pre-synaptic activation over tens of seconds (i.e., the time scale of augmentation) or even minutes (i.e., the time scale of potentiation) rather than just seconds (i.e., the time scale of facilitation). In the present contribution, we propose that such a transient synaptic enhancement over multiple time scales allows the encoding of <italic>both</italic> stimulus <italic>and</italic> temporal information in the instantaneous synaptic efficacies.</p>
<p>To substantiate this proposal, we extend the synaptic theory of WM to include synaptic augmentation, observed in the prefrontal cortex at the same synapses that exhibit significant short-term facilitation [<xref ref-type="bibr" rid="c19">Hempel et al., 2000</xref>, <xref ref-type="bibr" rid="c20">Wang et al., 2006</xref>].</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<p>To illustrate the putative role of synaptic augmentation in the encoding of temporal information, we consider the simplified setting used in [<xref ref-type="bibr" rid="c27">Mi et al., 2017</xref>]. The network is composed of <italic>P</italic> distinct excitatory populations, that represent the memory items, and one inhibitory population, that prevents simultaneous activity at enhanced rates in the excitatory populations. The recurrent synaptic connections within each excitatory population display short-term synaptic plasticity according to the Tsodyks-Markram (TM) model [<xref ref-type="bibr" rid="c17">Markram et al., 1998</xref>]. The population-averaged synaptic input to population <italic>a</italic> (<italic>a</italic> = 1, …, <italic>P</italic>), <italic>h</italic><sub><italic>a</italic></sub>, evolves in time according to
<disp-formula id="eqn1">
<graphic xlink:href="649874v2_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>τ</italic> is the neuronal time constant; <italic>I</italic><sub><italic>a</italic></sub>(<italic>t</italic>), the external input to population <italic>a</italic>, is the sum of two components: a background input, to control the activity regime of the network, and a selective input, to elicit enhanced activity during the presentation of the corresponding item; <italic>A</italic><sub><italic>a</italic></sub> is the average strength of the synapses within excitatory population <italic>a</italic>; <italic>r</italic><sub><italic>a</italic></sub>, the average activity of population <italic>a</italic>, is a smoothed threshold-linear function of <italic>h</italic><sub><italic>a</italic></sub>, i.e.,
<disp-formula id="eqn2">
<graphic xlink:href="649874v2_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>α &gt;</italic> 0 is a parameter controlling the smoothing; <italic>u</italic><sub><italic>a</italic></sub> and <italic>x</italic><sub><italic>a</italic></sub> are, respectively, the levels of short-term facilitation and depression of the recurrent synapses within population <italic>a</italic>; <italic>A</italic><sub><italic>EI</italic></sub> is the strength of the synapses from the inhibitory population to any excitatory population; <italic>r</italic><sub><italic>I</italic></sub> = <italic>ϕ</italic> (<italic>h</italic><sub><italic>I</italic></sub>) is the average activity of the inhibitory population, and
<disp-formula id="eqn3">
<graphic xlink:href="649874v2_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>I</italic><sub><italic>I</italic></sub> is the constant background input to the inhibitory population and <italic>A</italic><sub><italic>IE</italic></sub> is the strength of the synapses from any excitatory population to the inhibitory population.</p>
<p>The levels of short-term facilitation and depression, <italic>u</italic><sub><italic>a</italic></sub> and <italic>x</italic><sub><italic>a</italic></sub>, evolve in time according to [<xref ref-type="bibr" rid="c28">Tsodyks et al., 1998</xref>]:
<disp-formula id="eqn4">
<graphic xlink:href="649874v2_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn5">
<graphic xlink:href="649874v2_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>U</italic> is the baseline release probability; <italic>τ</italic><sub><italic>F</italic></sub> and <italic>τ</italic><sub><italic>D</italic></sub> are the facilitation and depression time constants, respectively. In words: Activity in the population induces both facilitation, i.e., it increases <italic>u</italic><sub><italic>a</italic></sub>, and depression, i.e., it decreases <italic>x</italic><sub><italic>a</italic></sub>, while, in the absence of activity (i.e., <italic>r</italic><sub><italic>a</italic></sub> = 0), facilitation and depression decay to their respective baseline levels, <italic>u</italic><sub><italic>a</italic></sub> = <italic>U</italic> and <italic>x</italic><sub><italic>a</italic></sub> = 1.</p>
<p>In [<xref ref-type="bibr" rid="c27">Mi et al., 2017</xref>], the <italic>A</italic><sub><italic>a</italic></sub>’s in <xref ref-type="disp-formula" rid="eqn1">Equation (1)</xref> are time-independent parameters with the same value for all the excitatory populations. By contrast here, to model synaptic augmentation, the <italic>A</italic><sub><italic>a</italic></sub>’s are activity-dependent dynamic variables that increase with the <italic>r</italic><sub><italic>a</italic></sub>’s according to
<disp-formula id="eqn6">
<graphic xlink:href="649874v2_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="649874v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the basal strength of the synapses within an excitatory population observed when there is no presynaptic activity (i.e., <italic>r</italic><sub><italic>a</italic></sub> = 0); <italic>τ</italic><sub><italic>A</italic></sub> is the augmentation time constant, <italic>K</italic><sub><italic>A</italic></sub> controls how fast the average strength of the synapses, <italic>A</italic><sub><italic>a</italic></sub>, increases with the activity, and <italic>A</italic><sub><italic>M</italic></sub> is the maximal synaptic strength that can be induced by augmentation. In the following, we take <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="649874v2_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p>The physiological mechanisms responsible for synaptic augmentation are poorly understood [<xref ref-type="bibr" rid="c24">Fisher et al., 1997</xref>, <xref ref-type="bibr" rid="c25">Thomson, 2000</xref>, <xref ref-type="bibr" rid="c26">Fioravante and Regehr, 2011</xref>]. <xref ref-type="disp-formula" rid="eqn6">Equation (6)</xref> provides a minimal phenomenological description of synaptic augmentation in the spirit of the original TM model [<xref ref-type="bibr" rid="c17">Markram et al., 1998</xref>]. However, as it will become clear in the following, our results do not depend critically on this modeling choice. For instance, one would obtain the same results by modeling augmentation as an activity-dependent increase in the baseline release probability <italic>U</italic> (data not shown). Facilitating synaptic transmission observed at inter-pyramidal synapses in the prefrontal cortex is well described by the above model with the following choice of synaptic parameters: <italic>U</italic> ~ 0.2, <italic>τ</italic><sub><italic>F</italic></sub> ~ 1s, <italic>τ</italic><sub><italic>D</italic></sub> ~ 0.1s, <italic>τ</italic><sub><italic>A</italic></sub> ~ 10s and <italic>K</italic><sub><italic>A</italic></sub> ≪ 1 [<xref ref-type="bibr" rid="c19">Hempel et al., 2000</xref>, <xref ref-type="bibr" rid="c20">Wang et al., 2006</xref>, <xref ref-type="bibr" rid="c29">Barri et al., 2016</xref>]. The full set of network and short-term plasticity parameters used in the simulations can be found in the caption of <xref rid="fig1" ref-type="fig">Fig. 1</xref>.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Network activity encodes sequence information.</title>
<p>Network responses to 3 sequentially presented items with (A) and without synaptic augmentation (B). The bottom panel in (A) shows the level of synaptic augmentation in the corresponding synaptic populations. The presentation of an item is simulated by a 10-fold increase of the background input selectively to the corresponding neuronal population for 250ms (gray areas). The background input to the remaining populations is kept constant at its baseline level. Network parameters: <italic>P</italic> = 16, <italic>τ</italic> = 8ms, <italic>α</italic> = 1.5Hz, <italic>A</italic><sub><italic>EE</italic></sub> = 6.0, <italic>A</italic><sub><italic>EI</italic></sub> = 1.1, <italic>A</italic><sub><italic>IE</italic></sub> = 1.75, <italic>I</italic><sub><italic>bkg</italic></sub> = 8.0Hz; Short-term plasticity parameters: <italic>U</italic> = 0.3, <italic>K</italic><sub><italic>A</italic></sub> = 0.01, <italic>τ</italic><sub><italic>D</italic></sub> = 0.3s, <italic>τ</italic><sub><italic>F</italic></sub> = 1.5s, <italic>τ</italic><sub><italic>A</italic></sub> = 20s.</p></caption>
<graphic xlink:href="649874v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In <xref rid="fig1" ref-type="fig">Fig. 1A</xref>, we show the response of the model network to a sequence of 3 items with variable inter-item intervals. The interval between the onset of the first and second item is 1 second, while the interval between the onset of the second and the third item is 2 seconds. Following the presentation of the last item, the neuronal populations that have been stimulated reactivate in a repeating cycle, indicating that the corresponding items are being actively maintained in WM. Importantly, this regime of activity does not correspond to a steady state of the network dynamics. This is evident from the amplitudes of the PS and from the levels of synaptic augmentation in the reactivating neuronal populations (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>, bottom panel) that are still changing with time. Note that the amplitudes of the PS are different for the different populations.</p>
<p>For comparison, we show in <xref rid="fig1" ref-type="fig">Fig. 1B</xref> the response of the network to the same sequence in the absence of synaptic augmentation (i.e., <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="649874v2_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <italic>K</italic><sub><italic>A</italic></sub> = 0). In this case the network dynamics rapidly converge to a steady, attractor state (on a time scale ~ <italic>τ</italic><sub><italic>F</italic></sub>); the amplitude of the PS is the same for all the reactivating populations. Once this state is reached, the network carries no information about the sequence beyond the identity of the stimuli composing the sequence.</p>
<p>The transient regime exhibited by the model network in the presence of augmentation is long-lived because the level of augmentation grows slowly with neural activity. As can be seen in the bottom panel of <xref rid="fig1" ref-type="fig">Fig. 1A</xref>, significant augmentation only occurs during the reactivations. The increase of the augmentation level with each reactivation is mainly controlled by <italic>K</italic><sub><italic>A</italic></sub> and <italic>K</italic><sub><italic>A</italic></sub> is small, consistently with the experiments. As a result, the levels of synaptic augmentation in the reactivating neuronal populations are still changing with time long after the presentation of the last item in the sequence. At the same time, the decay of the level of augmentation between two consecutive reactivations of the same population ( ~ <italic>τ</italic><sub><italic>D</italic></sub>) is negligible, because <italic>τ</italic><sub><italic>D</italic></sub> ≪ <italic>τ</italic><sub><italic>A</italic></sub>. Therefore, the longer an item has been active in WM – that is, the larger the number of reactivations – the larger the corresponding level of augmentation. Indeed, the level of augmentation encodes, quite accurately, the time elapsed since item’s presentation (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>, bottom panel).</p>
<p>If augmentation was the only form of synaptic plasticity present in the network, the encoding of an item in WM would require long presentation times, or alternatively high firing rates upon presentation, precisely because <italic>K</italic><sub><italic>A</italic></sub> is small. Instead, rapid encoding is made possible by the presence of the short-term facilitation, which builds up significantly faster than augmentation, as <italic>U</italic> ≫ <italic>K</italic><sub><italic>A</italic></sub>. For the same reason, however, the level of facilitation rapidly reaches the steady state; therefore, short-term facilitation alone is unable to encode temporal order (see <xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Thus, our model requires the existence of transitory synaptic enhancement on at least two time scales, such that longer decays are accompanied by slower build-ups. Intriguingly, this pattern is experimentally observed [<xref ref-type="bibr" rid="c24">Fisher et al., 1997</xref>].</p>
<p>In summary, in the presence of synaptic augmentation, WM activity naturally encodes the temporal structure of a novel sequence of familiar items, besides encoding information about the identity of the single items. As this information is present in the levels of synaptic augmentation and in the amplitudes of the PSs during the reactivations, it is readily accessible to a downstream read-out network.</p>
<p>To illustrate this important point, we consider a simple read-out mechanism to reconstruct/replay the sequence stored in WM (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). Each item-selective population in the memory network provides excitatory inputs to the corresponding item-selective population in a read-out network. For simplicity, we assume that the excitatory synapses between the memory and the read-out network exhibit the same dynamics as the excitatory synapses within the memory network. The activation of a population in the read-out network signals the retrieval of the corresponding item. The item-selective populations in the read-out network do not interact with each other. Rather, they receive a uniform background input (i.e., the same for all populations) that effectively sets the threshold for their activation. To read-out the contents of WM, following the presentation of the last stimulus, the background input ramps up until the first population in the read-out network activates and then remains constant.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Replay of a novel sequence.</title>
<p>(A) Architecture of the memory and read-out network (see main text for details). (B) Top panel: Input to the read-out network from the memory network. Middle panel: Activation state of the item-selective populations in the read-out network, as determined by comparing the sum of the input from the memory network and of the background input to the threshold. Bottom panel: Time course of the background input to the read-out network. (C) Same as (B) for a different sequence. Note that the time course of the background input to the read-out network is the same in (B) and (C).</p></caption>
<graphic xlink:href="649874v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>This mechanism results in an approximate replay of the sequence stored in WM. We illustrate this in <xref rid="fig2" ref-type="fig">Fig. 2B</xref> and <xref rid="fig2" ref-type="fig">C</xref> for two different sequences and the <italic>same</italic> read-out network. This is because the temporal evolution of the level of augmentation and of the amplitude of the PSs in the active populations are approximately time-translation invariant; that is, they are approximately the same when aligned to stimulus onset. Hence, the inputs from the memory to the read-out network will reach the same level (i.e., the same threshold) at time intervals that (approximately) match the time intervals between the presentations of the corresponding items. For the same reason, the accuracy of the replay is rather robust against (reasonable) changes in the rate of increase of the input to the read-out network.</p>
<p>The augmentation gradient can also be used to fast-replay the sequence stored in WM. Fast replay has been suggested as a mechanism for consolidating the storage of information in the long-term memory, by bringing patterns of neuronal activity representing temporally distant events within a time window in which long-term synaptic plasticity can most effectively operate [<xref ref-type="bibr" rid="c30">Melamed et al., 2004</xref>, <xref ref-type="bibr" rid="c31">Jensen and Lisman, 2005</xref>]. The time-compressed replay of the sequence is initiated by decreasing the level of background input to the WM network for a time ~ <italic>τ</italic><sub><italic>F</italic></sub> (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, bottom panel, downward arrow). This prevents further reactivations (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, top panel) and the corresponding synaptic variables start decaying toward their baseline levels (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, middle panel). The background input is then raised again to a suitably larger level (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, bottom panel, upward arrow). In the time interval where reactivations are suppressed, the levels of augmentation, i.e., the <italic>A</italic><sub><italic>a</italic></sub>’s, do not change significantly because <italic>τ</italic><sub><italic>F</italic></sub> ≪ <italic>τ</italic><sub><italic>A</italic></sub>. However by the end of the same time interval, short-term depression and facilitation variables will be close to their corresponding baseline levels (i.e., <italic>x</italic><sub><italic>a</italic></sub> ≃ 1 and <italic>u</italic><sub><italic>a</italic></sub> ≃ <italic>U</italic> for <italic>a</italic> = 1, …, <italic>P</italic>). When the background input is raised above a critical level, the steady, low-rate state of activity becomes unstable for the once-active neuronal populations. Therefore, they will start reactivating, with the most unstable one (i.e., the one with the larger <italic>A</italic><sub><italic>a</italic></sub>) reactivating first, the next most unstable one reactivating second, and so on [<xref ref-type="bibr" rid="c27">Mi et al., 2017</xref>], hence replaying the sequence in the order of stimuli presentation (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, top panel). Note that the network replays the sequence in about 250 ms, thus achieving a compression factor of about 10.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Fast-replay of a novel sequence.</title>
<p>The top panel shows the response of the network to the external inputs depicted in the bottom panel. After the presentation of the sequence, the background input is first decreased (downward red arrow in the bottom panel) for 3 seconds and then increased (upward red arrow in the bottom panel) for 250 milliseconds. The middle panel shows the resulting time course of <italic>Aux</italic> in the corresponding synaptic populations. Immediately before the background input is increased again, <italic>Aux</italic> ≃ <italic>AU</italic>.</p></caption>
<graphic xlink:href="649874v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>There is significant experimental evidence that items can be maintained in WM in different <italic>representational</italic> states and that these states can be rapidly altered by task demand [<xref ref-type="bibr" rid="c32">LaRocque et al., 2014</xref>, <xref ref-type="bibr" rid="c33">Oberauer and Awh, 2022</xref>]. A case in point is the study of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>], who used a retro-cue design to manipulate these putative representational states (see <xref rid="fig4" ref-type="fig">Fig. 4A</xref>). Briefly, human subjects performed a two-item delayed recognition task, with two retro-cues and two recognition probes per trial. Following the presentation of the items and a delay period, the first retro-cue informed the subject about which of the two items will be probed in the impending recognition test, after a delay period. The cued item is considered <italic>prioritized</italic> for upcoming behavior. After the first recognition test, a second retro-cue indicated the item to be probed in the second recognition test, following another delay period. Importantly, each retro-cue randomly prioritized either of the two items with the same probability and, hence, both items had to be kept in WM until the second retro-cue. Rose et al. [2016] found that, during the initial delay period, both items could be reliably decoded from the fMRI signal. By contrast, during the delay period between a retro-cue and the subsequent recognition test, only the prioritized item could be reliably decoded. However, the decodability of the de-prioritized item was recovered by transcranial magnetic stimulation.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Reactivation of an activity-silent memory.</title>
<p>(A) Cartoon illustrating the task events in the study of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>]. Circles indicate items presentation, triangles indicate cue instructions, squares indicate recognition tests. In this example, the first retro-cue prioritizes the ‘blue’ item, that is then probed during the first recognition test, and the second retro-cue prioritizes the ‘red’ item, which is probed in the second recognition test. See main text and [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>] for details. (B) The top panel shows the response of the network to the external inputs depicted in the bottom panel. 8 seconds after the presentation of the two items, the background input to the neuronal population selective to second item (red) is decreased for 8 seconds, and then restored to its original level, while decreasing the background input to the neuronal population selective to the first item (blue). The middle panel shows the resulting time course of the level of augmentation in the corresponding synaptic populations.</p></caption>
<graphic xlink:href="649874v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The experimental observations of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>] (see also [<xref ref-type="bibr" rid="c22">Wolff et al., 2017</xref>]) suggest that there are at least two different states of ‘maintenance’ in WM with distinct neurophysiological signatures. Though the relationship between the fMRI signal and neural activity is not an obvious one, these results have been interpreted as indicating that these two states differ in their level of neural activity. In particular, the failure to decode would indicate the absence of enhanced spiking activity (but see [<xref ref-type="bibr" rid="c34">Barbosa et al., 2021</xref>]).</p>
<p>Our model network can reproduce these experimental observations, as illustrated in <xref rid="fig4" ref-type="fig">Fig. 4B</xref>. Similarly to the experiment of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>], two items are presented and, after the initial delay period, one of the two is prioritized. We simulate the effect of the retro-cue on neural activity by assuming that the de-prioritized item receives a lower external input as compared to the prioritized item (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>, bottom panel). Following the first retro-cue, the neuronal population encoding the prioritized item keeps reactivating while the neuronal population encoding the de-prioritized item stops reactivating (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>, top panel). We account for the results of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>] by assuming that only reactivating items can be decoded.</p>
<p>In the absence of neural activity, the ‘working memory’ of the de-prioritized item is kept by the augmentation level (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>, middle panel). To illustrate this, we prioritize the previously de-prioritized item with the second retro-cue and, indeed, the corresponding neuronal population resumes its reactivating dynamics (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>, top panel). In the presence of synaptic augmentation, the maximal time span of the activity-silent regime is controlled by <italic>τ</italic><sub><italic>A</italic></sub>, which is of the order of 10 seconds, which is consistent with the experimental observations of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>]. We note that in the model originally proposed in [<xref ref-type="bibr" rid="c16">Mongillo et al., 2008</xref>], the time span of the activity-silent regime is limited by <italic>τ</italic><sub><italic>F</italic></sub> ( ~ 1 s), which is not consistent with the results of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>].</p>
</sec>
<sec id="s3">
<label>3</label>
<title>Discussion</title>
<p>We propose that transient, non-associative synaptic plasticity over multiple time scales can support the temporally-structured encoding of a sequence of stimuli. We have illustrated this idea in a minimal model network that extends the synaptic theory of WM to include synaptic augmentation, besides synaptic depression and facilitation. Our model allows the storage and the retrieval of short sequences of items by relying on synaptic plasticity mechanisms that are well-characterized experimentally, that is, the transient enhancement on multiple time scales of the synaptic efficacy driven <italic>solely</italic> by pre-synaptic activity [<xref ref-type="bibr" rid="c24">Fisher et al., 1997</xref>, <xref ref-type="bibr" rid="c25">Thomson, 2000</xref>, <xref ref-type="bibr" rid="c26">Fioravante and Regehr, 2011</xref>]. In the low-activity regime, where items are maintained by short-lived reactivations of the corresponding neuronal populations, the presence of synaptic augmentation naturally leads to a temporal gradient in the synaptic efficacies that encodes both the items and their relative times of occurrence. This gradient can then be used to replay the sequence either at normal speed or in a time-compressed way. The mechanism that generates the temporal gradient is robust, because it relies on the order-of-magnitude differences between the build-up and the decay time of the augmentation and those of the depression and facilitation.</p>
<p>A key prediction of our theory is that items are maintained in a low-activity regime. Indeed, if the items are maintained either in an activity-silent regime or by persistent, high firing rates, the proposed mechanism fails. In the first case, because in the absence of reactivations the gradient does not build up; in the second case, because the augmentation levels quickly saturate due to the high firing rates. This prediction is consistent with multiple experimental observations [<xref ref-type="bibr" rid="c35">Siegel et al., 2009</xref>, <xref ref-type="bibr" rid="c36">Fuentemilla et al., 2010</xref>, <xref ref-type="bibr" rid="c37">Lundqvist et al., 2016</xref>, <xref ref-type="bibr" rid="c23">Panichello et al., 2024</xref>, <xref ref-type="bibr" rid="c38">Liebe et al., 2025</xref>].</p>
<p>In multi-item working memory tasks, neural activity during the maintenance period is characterized by short episodes of spiking synchrony, detected as brief gamma bursts in the local field potential [<xref ref-type="bibr" rid="c35">Siegel et al., 2009</xref>, <xref ref-type="bibr" rid="c37">Lundqvist et al., 2016</xref>] or in the MEG/EEG signal [<xref ref-type="bibr" rid="c36">Fuentemilla et al., 2010</xref>]. Importantly, during a given gamma burst, only one of the items can be reliably decoded [<xref ref-type="bibr" rid="c36">Fuentemilla et al., 2010</xref>, <xref ref-type="bibr" rid="c37">Lundqvist et al., 2016</xref>], suggesting that the items are reactivated briefly and sequentially (i.e., one at a time) during maintenance. More direct support to this interpretation comes from recent electrophysiological studies [<xref ref-type="bibr" rid="c23">Panichello et al., 2024</xref>, <xref ref-type="bibr" rid="c38">Liebe et al., 2025</xref>]. By recording large neuronal populations ( ~ 300) simultaneously in the prefrontal cortex of monkeys performing a WM task, [<xref ref-type="bibr" rid="c23">Panichello et al., 2024</xref>] found that, during the maintenance period, the decoding of the actively held item from neural activity was ‘intermittent’; that is, decoding was only possible during short epochs ( ~ 100ms) interleaved with epochs (also ~ 100ms) where decoding was at chance level. The inability to decode resulted from a loss of selectivity at the population level, with a return of the single-neuron firing rates to their spontaneous (pre-stimulus) activity levels. The transitions between these two activity states (decodable/not-decodable) were coordinated across large populations of neurons in PFC. By recording single-neuron activity in the medial temporal lobe of humans performing a sequential multi-item WM task, [<xref ref-type="bibr" rid="c38">Liebe et al., 2025</xref>] found that during maintenance, neurons coding for a given item tended to fire at a specific phase of the underlying theta rhythm, again suggesting that the corresponding neuronal populations reactivate briefly and sequentially. In summary, these experimental results suggest that active memory maintenance relies on brief reactivations of the neural representations of the items, which we identify with the population spikes in our model, and that these reactivatations occur sequentially in time, as predicted by our theory.</p>
<p>We note that the proposed mechanism would still work if the items were maintained by tonically-enhanced firing rates, instead of population spikes, provided that those firing rates were suitably low. However, obtaining low firing rates in model networks of persistent activity is quite difficult.</p>
<p>Behavioral data in serial recall tasks strongly support the idea that serial order encoding is based on a <italic>primacy gradient</italic> [<xref ref-type="bibr" rid="c39">Grossberg, 1978</xref>, <xref ref-type="bibr" rid="c40">Farrell and Lewandowsky, 2004</xref>, <xref ref-type="bibr" rid="c41">Hurlstone and Hitch, 2015</xref>, <xref ref-type="bibr" rid="c42">2018</xref>]. Our theory makes an explicit proposal as to its neurophysiological substrate: The primacy gradient is encoded by augmentation levels emerging due to interplay between synaptic and neuronal dynamics (as described above). As such, the generation of the gradient is an inescapable consequence of the active maintenance of an item in WM. This would naturally explain why the recall order tends to be the same as the presentation order also in free-recall tasks, provided that the sequence does not exceed WM capacity.</p>
<p>In the behavioral context, our theory also makes novel predictions. For example, the temporal gradient builds up gradually with the reactivations of the corresponding neuronal populations between consecutive presentations. This requires a presentation rate that is slow enough for these reactivations to occur in sufficient numbers. Hence, as the presentation rate is increased, the theory predicts that encoding of the serial order should degrade. Consistently with this prediction, increasing the presentation rate results in a larger number of transposition errors, that is, some items are recalled at the wrong serial position (see, e.g., [<xref ref-type="bibr" rid="c40">Farrell and Lewandowsky, 2004</xref>]). Experiments with very rapid serial visual presentation (RSVP) show that subjects cannot report the correct presentation order, even when the number of items is below capacity [<xref ref-type="bibr" rid="c43">Reeves and Sperling, 1986</xref>]. At the other extreme, if the presentation rate is too slow, or the list is too long, then the primacy gradient will also degrade either because of the saturation of synaptic augmentation or failure to actively maintain all the items. Consistent with this prediction, the spontaneous tendency to recall the items with the presented order in free recall tasks rapidly degrades with increasing list lengths [<xref ref-type="bibr" rid="c6">Grenfell-Essam and Ward, 2012</xref>].</p>
<p>To illustrate our theory in a simple setting, we used a minimal model network that neglects many physiological details. This, however, constitutes a limitation of the present study. It would be reassuring to see that the mechanism we propose here is robust enough to reliably operate also in spiking networks, in the presence of heterogeneity in both single-cell and synaptic properties. While we are fairly confident that this is the case, a spiking implementation of our model is beyond the scope of the present study and will be addressed in the future. Also, because of the simplicity of the model network, a comparison between the model behavior and the electrophysiological observations cannot be completely direct. Nevertheless the model qualitatively accounts for a diverse set of experimental data.</p>
<p>The model naturally generates ramping activity as a consequence of active maintenance, that is, the average level of activity in a reactivating neuronal population increases with time (see, e.g., <xref rid="fig1" ref-type="fig">Fig. 1</xref>). Ramping activity has been indeed proposed as a potential neuronal mechanism to encode time and it is commonly observed in electrophysiological studies of WM. A case in point is the recent study of [<xref ref-type="bibr" rid="c14">Cueva et al., 2020</xref>], who found ramping activity during the maintenance period in different delayed response tasks, regardless of whether timing was relevant for the task.</p>
<p>In neurophysiological studies of WM for sequences the conjunctive coding of item identity and serial-order information at the single-neuron level has been observed [<xref ref-type="bibr" rid="c44">Barone and Joseph, 1989</xref>, <xref ref-type="bibr" rid="c45">Funahashi et al., 1997</xref>, <xref ref-type="bibr" rid="c46">Xie et al., 2022</xref>]. Conjunctive coding refers to the modulation of neuron’s activity by both item and order information, so that, for instance, the average firing rate of the neuron during the delay period following different sequences with the same item changes depending on the position of the item in the sequence [<xref ref-type="bibr" rid="c46">Xie et al., 2022</xref>]. In our model the firing rate of a neuron is naturally sensitive to the temporal order due to the augmentation gradient (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). It remains to be seen whether our model in a more physiologically detailed setting can quantitatively account for some features of conjunctive coding as observed in experiments [<xref ref-type="bibr" rid="c46">Xie et al., 2022</xref>]. In this respect, an important caveat is that animals in these studies have been extensively trained on the task with a limited number of sequences. Extensive training and sequences’ repetition could lead to the emergence of stimulus-adapted neuronal representations via associative plasticity mechanisms [<xref ref-type="bibr" rid="c47">Botvinick and Watanabe, 2007</xref>, <xref ref-type="bibr" rid="c48">Gillett et al., 2020</xref>, <xref ref-type="bibr" rid="c49">Ryom et al., 2021</xref>].</p>
<p>The long time scales brought about by synaptic augmentation significantly extend the time span of memories maintained in the activity-silent state. As discussed in the Results section, the time scales of synaptic augmentation are fully compatible with the experimental observations, such as those of [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>], suggesting that a memory that has been <italic>silent</italic> for ~ 10 seconds can still be retrieved upon cuing (see <xref rid="fig4" ref-type="fig">Fig. 4</xref>). Accordingly one would expect a large <italic>storage</italic> capacity in the activity-silent mode. For instance, by assuming that an item is to be refreshed every 10 seconds to prevent its loss (based on [<xref ref-type="bibr" rid="c21">Rose et al., 2016</xref>]), and that refreshing takes 100 milliseconds (based on [<xref ref-type="bibr" rid="c23">Panichello et al., 2024</xref>]), one would estimate a storage capacity of 100 items for the activity-silent WM. This raises the possibility that classical WM capacity, experimentally estimated with uncued <italic>recall</italic>, could result from the inability to retrieve the information, rather than from the inability to encode and/or maintain it. In this scenario, WM capacity is ultimately determined by the degree of <italic>selectivity</italic> that the background control – that we identify with the “central executive” or the “focus of attention” of cognitive theories – can attain.</p>
</sec>
</body>
<back>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>The current manuscript is a computational study, so no data have been generated for this manuscript.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>G.M. work is supported by grants ANR-19-CE16-0024-01 and ANR-20-CE16-0011-02 from the French National Research Agency and by a grant from the Simons Foundation (891851, G.M.). M.T. is supported by the Israeli Science Foundation grant 1657/19 and Foundation Adelis.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N</given-names> <surname>Cowan</surname></string-name></person-group>. <article-title>The magical number 4 in short-term memory: A reconsideration of mental storage capacity</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>24</volume>:<fpage>87</fpage>–<lpage>114</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alan</given-names> <surname>Baddeley</surname></string-name></person-group>. <article-title>Working memory: looking back and looking forward</article-title>. <source>Nature reviews neuroscience</source>, <volume>4</volume>(<issue>10</issue>):<fpage>829</fpage>–<lpage>839</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Michael Jacob</given-names> <surname>Kahana</surname></string-name></person-group>. <source>Foundations of human memory</source>. <publisher-name>Oxford University Press</publisher-name>, <year>2012</year>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Krystal</given-names> <surname>Dimperio</surname></string-name>, <string-name><given-names>Kelly</given-names> <surname>Addis</surname></string-name>, and <string-name><given-names>Michael</given-names> <surname>Kahana</surname></string-name></person-group>. <article-title>A comparative analysis of serial and free recall</article-title>. <source>Memory &amp; Cognition</source>, <volume>33</volume>:<fpage>833</fpage>–<lpage>839</lpage>, 08 <year>2005</year>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Geoff</given-names> <surname>Ward</surname></string-name>, <string-name><given-names>Lydia</given-names> <surname>Tan</surname></string-name>, and <string-name><given-names>Rachel</given-names> <surname>Grenfell-Essam</surname></string-name></person-group>. <article-title>Examining the relationship between free recall and immediate serial recall: the effects of list length and output order</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>36</volume>(<issue>5</issue>):<fpage>1207</fpage>–<lpage>1241</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Rachel</given-names> <surname>Grenfell-Essam</surname></string-name> and <string-name><given-names>Geoff</given-names> <surname>Ward</surname></string-name></person-group>. <article-title>Examining the relationship between free recall and immediate serial recall: The role of list length, strategy use, and test expectancy</article-title>. <source>Journal of Memory and Language</source>, <volume>67</volume>(<issue>1</issue>):<fpage>106</fpage>–<lpage>148</lpage>, <year>2012</year>. ISSN <issn>0749-596X</issn>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Daniel J.</given-names> <surname>Amit</surname></string-name></person-group>. <article-title>The hebbian paradigm reintegrated: Local reverberations as internal representations</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>18</volume>(<issue>4</issue>):<fpage>617</fpage> – <lpage>626</lpage>, <year>1995</year>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Daniel J</given-names> <surname>Amit</surname></string-name> and <string-name><given-names>Nicolas</given-names> <surname>Brunel</surname></string-name></person-group>. <article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title>. <source>Cerebral cortex (New York, NY: 1991)</source>, <volume>7</volume>(<issue>3</issue>):<fpage>237</fpage>–<lpage>252</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name></person-group>. <article-title>50 years of mnemonic persistent activity: quo vadis?</article-title> <source>Trends in Neurosciences</source>, <volume>44</volume>(<issue>11</issue>):<fpage>888</fpage>–<lpage>902</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>David</given-names> <surname>Kleinfeld</surname></string-name></person-group>. <article-title>Sequential state generation by model neural networks</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>83</volume>(<issue>24</issue>):<fpage>9469</fpage>–<lpage>9473</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Haim</given-names> <surname>Sompolinsky</surname></string-name> and <string-name><given-names>Ido</given-names> <surname>Kanter</surname></string-name></person-group>. <article-title>Temporal association in asymmetric neural networks</article-title>. <source>Physical review letters</source>, <volume>57</volume> (<issue>22</issue>):<fpage>2861</fpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Natschläger</surname></string-name>, and <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name></person-group>. <article-title>Real-time computing without stable states: A new framework for neural computation based on perturbations</article-title>. <source>Neural computation</source>, <volume>14</volume>(<issue>11</issue>):<fpage>2531</fpage>–<lpage>2560</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Dean V</given-names> <surname>Buonomano</surname></string-name> and <string-name><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name></person-group>. <article-title>State-dependent computations: spatiotemporal processing in cortical networks</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>(<issue>2</issue>):<fpage>113</fpage>–<lpage>125</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christopher J</given-names> <surname>Cueva</surname></string-name>, <string-name><given-names>Alex</given-names> <surname>Saez</surname></string-name>, <string-name><given-names>Encarni</given-names> <surname>Marcos</surname></string-name>, <string-name><given-names>Aldo</given-names> <surname>Genovesio</surname></string-name>, <string-name><given-names>Mehrdad</given-names> <surname>Jazayeri</surname></string-name>, <string-name><given-names>Ranulfo</given-names> <surname>Romo</surname></string-name>, <string-name><given-names>C Daniel</given-names> <surname>Salzman</surname></string-name>, <string-name><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>, and <string-name><given-names>Stefano</given-names> <surname>Fusi</surname></string-name></person-group>. <article-title>Low-dimensional dynamics for working memory and time encoding</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>117</volume>(<issue>37</issue>):<fpage>23021</fpage>–<lpage>23032</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Shanglin</given-names> <surname>Zhou</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Seay</surname></string-name>, <string-name><given-names>Jiannis</given-names> <surname>Taxidis</surname></string-name>, <string-name><given-names>Peyman</given-names> <surname>Golshani</surname></string-name>, and <string-name><given-names>Dean V</given-names> <surname>Buonomano</surname></string-name></person-group>. <article-title>Multiplexing working memory and time in the trajectories of neural networks</article-title>. <source>Nature Human Behaviour</source>, <volume>7</volume>(<issue>7</issue>):<fpage>1170</fpage>–<lpage>1184</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gianluigi</given-names> <surname>Mongillo</surname></string-name>, <string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name>, and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name></person-group>. <article-title>Synaptic theory of working memory</article-title>. <source>Science</source>, <volume>319</volume>(<issue>5869</issue>):<fpage>1543</fpage>–<lpage>1546</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name>, <string-name><given-names>Yun</given-names> <surname>Wang</surname></string-name>, and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name></person-group>. <article-title>Differential signaling via the same axon of neocortical pyramidal neurons</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>95</volume>(<issue>9</issue>):<fpage>5323</fpage>–<lpage>5328</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Robert S.</given-names> <surname>Zucker</surname></string-name> and <string-name><given-names>Wade G.</given-names> <surname>Regehr</surname></string-name></person-group>. <article-title>Short-term synaptic plasticity</article-title>. <source>Annual Review of Physiology</source>, <volume>64</volume>(<issue>1</issue>):<fpage>355</fpage>–<lpage>405</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Chris M</given-names> <surname>Hempel</surname></string-name>, <string-name><given-names>Kenichi H</given-names> <surname>Hartman</surname></string-name>, <string-name><given-names>X-J</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Gina G</given-names> <surname>Turrigiano</surname></string-name>, and <string-name><given-names>Sacha B</given-names> <surname>Nelson</surname></string-name></person-group>. <article-title>Multiple forms of short-term plasticity at excitatory synapses in rat medial prefrontal cortex</article-title>. <source>Journal of neurophysiology</source>, <volume>83</volume>(<issue>5</issue>):<fpage>3031</fpage>–<lpage>3041</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yun</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name>, <string-name><given-names>Philip H</given-names> <surname>Goodman</surname></string-name>, <string-name><given-names>Thomas K</given-names> <surname>Berger</surname></string-name>, <string-name><given-names>Junying</given-names> <surname>Ma</surname></string-name>, and <string-name><given-names>Patricia S</given-names> <surname>Goldman-Rakic</surname></string-name></person-group>. <article-title>Heterogeneity in the pyramidal network of the medial prefrontal cortex</article-title>. <source>Nature neuroscience</source>, <volume>9</volume>(<issue>4</issue>):<fpage>534</fpage>—<lpage>542</lpage>, <year>2006</year>. ISSN <issn>1097-6256</issn>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nathan S.</given-names> <surname>Rose</surname></string-name>, <string-name><given-names>Joshua J.</given-names> <surname>LaRocque</surname></string-name>, <string-name><given-names>Adam C.</given-names> <surname>Riggall</surname></string-name>, <string-name><given-names>Olivia</given-names> <surname>Gosseries</surname></string-name>, <string-name><given-names>Michael J.</given-names> <surname>Starrett</surname></string-name>, <string-name><given-names>Emma E.</given-names> <surname>Meyering</surname></string-name>, and <string-name><given-names>Bradley R.</given-names> <surname>Postle</surname></string-name></person-group>. <article-title>Reactivation of latent working memories with transcranial magnetic stimulation</article-title>. <source>Science</source>, <volume>354</volume> (<issue>6316</issue>):<fpage>1136</fpage>–<lpage>1139</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael J</given-names> <surname>Wolff</surname></string-name>, <string-name><given-names>Janina</given-names> <surname>Jochim</surname></string-name>, <string-name><given-names>Elkan G</given-names> <surname>Akyürek</surname></string-name>, and <string-name><given-names>Mark G</given-names> <surname>Stokes</surname></string-name></person-group>. <article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title>. <source>Nature neuroscience</source>, <volume>20</volume>(<issue>6</issue>):<fpage>864</fpage>–<lpage>871</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew F</given-names> <surname>Panichello</surname></string-name>, <string-name><given-names>Donatas</given-names> <surname>Jonikaitis</surname></string-name>, <string-name><given-names>Yu Jin</given-names> <surname>Oh</surname></string-name>, <string-name><given-names>Shude</given-names> <surname>Zhu</surname></string-name>, <string-name><given-names>Ethan B</given-names> <surname>Trepka</surname></string-name>, and <string-name><given-names>Tirin</given-names> <surname>Moore</surname></string-name></person-group>. <article-title>Intermittent rate coding and cue-specific ensembles support working memory</article-title>. <source>Nature</source>, <year>2024</year>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Stephen A</given-names> <surname>Fisher</surname></string-name>, <string-name><given-names>Thomas M</given-names> <surname>Fischer</surname></string-name>, and <string-name><given-names>Thomas J</given-names> <surname>Carew</surname></string-name></person-group>. <article-title>Multiple overlapping processes underlying short-term synaptic enhancement</article-title>. <source>Trends in neurosciences</source>, <volume>20</volume>(<issue>4</issue>):<fpage>170</fpage>–<lpage>177</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alex M</given-names> <surname>Thomson</surname></string-name></person-group>. <article-title>Facilitation, augmentation and potentiation at central synapses</article-title>. <source>Trends in neurosciences</source>, <volume>23</volume>(<issue>7</issue>):<fpage>305</fpage>–<lpage>312</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Diasynou</given-names> <surname>Fioravante</surname></string-name> and <string-name><given-names>Wade G</given-names> <surname>Regehr</surname></string-name></person-group>. <article-title>Short-term forms of presynaptic plasticity</article-title>. <source>Current opinion in neurobiology</source>, <volume>21</volume>(<issue>2</issue>):<fpage>269</fpage>–<lpage>274</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yuanyuan</given-names> <surname>Mi</surname></string-name>, <string-name><given-names>Mikhail</given-names> <surname>Katkov</surname></string-name>, and <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name></person-group>. <article-title>Synaptic correlates of working memory capacity</article-title>. <source>Neuron</source>, <volume>93</volume>(<issue>2</issue>):<fpage>323</fpage>–<lpage>330</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>, <string-name><given-names>Klaus</given-names> <surname>Pawelzik</surname></string-name>, and <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name></person-group>. <article-title>Neural networks with dynamic synapses</article-title>. <source>Neural Computation</source>, <volume>10</volume>(<issue>4</issue>):<fpage>821</fpage>–<lpage>835</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alessandro</given-names> <surname>Barri</surname></string-name>, <string-name><given-names>Yun</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>David</given-names> <surname>Hansel</surname></string-name>, and <string-name><given-names>Gianluigi</given-names> <surname>Mongillo</surname></string-name></person-group>. <article-title>Quantifying repetitive transmission at chemical synapses: a generative-model approach</article-title>. <source>ENeuro</source>, <volume>3</volume>(<issue>2</issue>), <year>2016</year>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ofer</given-names> <surname>Melamed</surname></string-name>, <string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>, <string-name><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name>, <string-name><given-names>Misha</given-names> <surname>Tsodyks</surname></string-name>, and <string-name><given-names>Henry</given-names> <surname>Markram</surname></string-name></person-group>. <article-title>Coding and learning of behavioral sequences</article-title>. <source>Trends in neurosciences</source>, <volume>27</volume>(<issue>1</issue>):<fpage>11</fpage>–<lpage>14</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ole</given-names> <surname>Jensen</surname></string-name> and <string-name><given-names>John E</given-names> <surname>Lisman</surname></string-name></person-group>. <article-title>Hippocampal sequence-encoding driven by a cortical multi-item working memory buffer</article-title>. <source>Trends in neurosciences</source>, <volume>28</volume>(<issue>2</issue>):<fpage>67</fpage>–<lpage>72</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Joshua J</given-names> <surname>LaRocque</surname></string-name>, <string-name><given-names>Jarrod A</given-names> <surname>Lewis-Peacock</surname></string-name>, and <string-name><given-names>Bradley R</given-names> <surname>Postle</surname></string-name></person-group>. <article-title>Multiple neural states of representation in short-term memory? it’sa matter of attention</article-title>. <source>Frontiers in human neuroscience</source>, <volume>8</volume>:<fpage>5</fpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Klaus</given-names> <surname>Oberauer</surname></string-name> and <string-name><given-names>Edward</given-names> <surname>Awh</surname></string-name></person-group>. <article-title>Is There an Activity-silent Working Memory?</article-title> <source>Journal of Cognitive Neuroscience</source>, <volume>34</volume>(<issue>12</issue>):<fpage>2360</fpage>–<lpage>2374</lpage>, <month>11</month> <year>2022</year>. ISSN <issn>0898-929X</issn>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Joao</given-names> <surname>Barbosa</surname></string-name>, <string-name><given-names>Diego</given-names> <surname>Lozano-Soldevilla</surname></string-name>, and <string-name><given-names>Albert</given-names> <surname>Compte</surname></string-name></person-group>. <article-title>Pinging the brain with visual impulses reveals electrically active, not activity-silent, working memories</article-title>. <source>PLoS biology</source>, <volume>19</volume>(<issue>10</issue>):<fpage>e3001436</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Markus</given-names> <surname>Siegel</surname></string-name>, <string-name><given-names>Melissa R</given-names> <surname>Warden</surname></string-name>, and <string-name><given-names>Earl K</given-names> <surname>Miller</surname></string-name></person-group>. <article-title>Phase-dependent neuronal coding of objects in short-term memory</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>106</volume>(<issue>50</issue>):<fpage>21341</fpage>–<lpage>21346</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Lluís</given-names> <surname>Fuentemilla</surname></string-name>, <string-name><given-names>Will D</given-names> <surname>Penny</surname></string-name>, <string-name><given-names>Nathan</given-names> <surname>Cashdollar</surname></string-name>, <string-name><given-names>Nico</given-names> <surname>Bunzeck</surname></string-name>, and <string-name><given-names>Emrah</given-names> <surname>Düzel</surname></string-name></person-group>. <article-title>Theta-coupled periodic replay in working memory</article-title>. <source>Current Biology</source>, <volume>20</volume>(<issue>7</issue>):<fpage>606</fpage>–<lpage>612</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mikael</given-names> <surname>Lundqvist</surname></string-name>, <string-name><given-names>Jonas</given-names> <surname>Rose</surname></string-name>, <string-name><given-names>Pawel</given-names> <surname>Herman</surname></string-name>, <string-name><given-names>Scott L</given-names> <surname>Brincat</surname></string-name>, <string-name><given-names>Timothy J</given-names> <surname>Buschman</surname></string-name>, and <string-name><given-names>Earl K</given-names> <surname>Miller</surname></string-name></person-group>. <article-title>Gamma and beta bursts underlie working memory</article-title>. <source>Neuron</source>, <volume>90</volume>(<issue>1</issue>):<fpage>152</fpage>–<lpage>164</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Stefanie</given-names> <surname>Liebe</surname></string-name>, <string-name><given-names>Johannes</given-names> <surname>Niediek</surname></string-name>, <string-name><given-names>Matthijs</given-names> <surname>Pals</surname></string-name>, <string-name><given-names>Thomas P</given-names> <surname>Reber</surname></string-name>, <string-name><given-names>Jennifer</given-names> <surname>Faber</surname></string-name>, <string-name><given-names>Jan</given-names> <surname>Bostroem</surname></string-name>, <string-name><given-names>Christian E</given-names> <surname>Elger</surname></string-name>, <string-name><given-names>Jakob H</given-names> <surname>Macke</surname></string-name>, and <string-name><given-names>Florian</given-names> <surname>Mormann</surname></string-name></person-group>. <article-title>Phase of firing does not reflect temporal order in sequence memory of humans and recurrent neural networks</article-title>. <source>Nature Neuroscience</source>, <year>2025</year>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Stephen</given-names> <surname>Grossberg</surname></string-name></person-group>. <article-title>Behavioral contrast in short term memory: serial binary memory models or parallel continuous memory models?</article-title> <source>Journal of Mathematical Psychology</source>, <volume>17</volume>(<issue>3</issue>):<fpage>199</fpage>–<lpage>219</lpage>, <year>1978</year>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Simon</given-names> <surname>Farrell</surname></string-name> and <string-name><given-names>Stephan</given-names> <surname>Lewandowsky</surname></string-name></person-group>. <article-title>Modelling transposition latencies: Constraints for theories of serial order memory</article-title>. <source>Journal of Memory and Language</source>, <volume>51</volume>(<issue>1</issue>):<fpage>115</fpage>–<lpage>135</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark J</given-names> <surname>Hurlstone</surname></string-name> and <string-name><given-names>Graham J</given-names> <surname>Hitch</surname></string-name></person-group>. <article-title>How is the serial order of a spatial sequence represented? insights from transposition latencies</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>41</volume>(<issue>2</issue>):<fpage>295</fpage>–<lpage>324</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark J</given-names> <surname>Hurlstone</surname></string-name> and <string-name><given-names>Graham J</given-names> <surname>Hitch</surname></string-name></person-group>. <article-title>How is the serial order of a visual sequence represented? Insights from transposition latencies</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>44</volume>(<issue>2</issue>):<fpage>167</fpage>–<lpage>192</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Adam</given-names> <surname>Reeves</surname></string-name> and <string-name><given-names>George</given-names> <surname>Sperling</surname></string-name></person-group>. <article-title>Attention gating in short-term visual memory</article-title>. <source>Psychological review</source>, <volume>93</volume>(<issue>2</issue>):<fpage>180</fpage>–<lpage>206</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P</given-names> <surname>Barone</surname></string-name> and <string-name><given-names>JP</given-names> <surname>Joseph</surname></string-name></person-group>. <article-title>Prefrontal cortex and spatial sequencing in macaque monkey</article-title>. <source>Experimental brain research</source>, <volume>78</volume>:<fpage>447</fpage>–<lpage>464</lpage>, <year>1989</year>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Shintaro</given-names> <surname>Funahashi</surname></string-name>, <string-name><given-names>Masato</given-names> <surname>Inoue</surname></string-name>, and <string-name><given-names>Kisou</given-names> <surname>Kubota</surname></string-name></person-group>. <article-title>Delay-period activity in the primate prefrontal cortex encoding multiple spatial positions and their order of presentation</article-title>. <source>Behavioural brain research</source>, <volume>84</volume>(<issue>1-2</issue>):<fpage>203</fpage>–<lpage>223</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yang</given-names> <surname>Xie</surname></string-name>, <string-name><given-names>Peiyao</given-names> <surname>Hu</surname></string-name>, <string-name><given-names>Junru</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Jingwen</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Weibin</given-names> <surname>Song</surname></string-name>, <string-name><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Tianming</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Stanislas</given-names> <surname>Dehaene</surname></string-name>, <string-name><given-names>Shiming</given-names> <surname>Tang</surname></string-name>, <string-name><given-names>Bin</given-names> <surname>Min</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Geometry of sequence working memory in macaque prefrontal cortex</article-title>. <source>Science</source>, <volume>375</volume> (<issue>6581</issue>):<fpage>632</fpage>–<lpage>639</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew</given-names> <surname>Botvinick</surname></string-name> and <string-name><given-names>Takamitsu</given-names> <surname>Watanabe</surname></string-name></person-group>. <article-title>From numerosity to ordinal rank: a gain-field model of serial order representation in cortical working memory</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>(<issue>32</issue>):<fpage>8636</fpage>–<lpage>8642</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Maxwell</given-names> <surname>Gillett</surname></string-name>, <string-name><given-names>Ulises</given-names> <surname>Pereira</surname></string-name>, and <string-name><given-names>Nicolas</given-names> <surname>Brunel</surname></string-name></person-group>. <article-title>Characteristics of sequential activity in networks with temporally asymmetric hebbian learning</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>117</volume>(<issue>47</issue>):<fpage>29948</fpage>–<lpage>29958</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kwang Il</given-names> <surname>Ryom</surname></string-name>, <string-name><given-names>Vezha</given-names> <surname>Boboeva</surname></string-name>, <string-name><given-names>Oleksandra</given-names> <surname>Soldatkina</surname></string-name>, and <string-name><given-names>Alessandro</given-names> <surname>Treves</surname></string-name></person-group>. <article-title>Latching dynamics as a basis for short-term recall</article-title>. <source>PLoS computational biology</source>, <volume>17</volume>(<issue>9</issue>):<fpage>e1008809</fpage>, <year>2021</year>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Fundamental</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper develops a <bold>fundamental</bold> theory that explains how the brain can hold in working memory not only the identity but also the order of presented stimuli. Previous theories did not explain the ability of people to immediately recall the correct order of the stimulus presentation. The authors present <bold>compelling</bold> evidence that this can be achieved through synaptic augmentation, an experimentally observed phenomenon with a time scale of tens of seconds.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The issue of how the brain can maintain serial order of presented items in working memory is a major unsolved question in cognitive neuroscience. It has been proposed that this serial order maintenance could be achieved thanks to periodic reactivations of different presented items at different phases of an oscillation, but the mechanisms by which this could be achieved by brain networks, as well as the mechanisms of read-out, are still unclear. In an influential 2008 paper, the authors have proposed a mechanism by which a recurrent network of neurons could maintain multiple items in working memory, thanks to `population spikes' of populations of neurons encoding for the different items, occurring at alternating times. These population spikes occur in a specific regime of the network and are a result of synaptic facilitation, an experimentally observed type of synaptic short-term dynamics with time scales of order hundreds of ms.</p>
<p>In the present manuscript, the authors extend their model to include another type of experimentally observed short-term synaptic plasticity termed synaptic augmentation, that operates on longer time scales on the order of 10s. They show that while a network without augmentation loses information about serial order, augmentation provides a mechanism by which this order can be maintained in memory thanks to a temporal gradient of synaptic efficacies. The order can then be read out using a read-out network whose synapses are also endowed with synaptic augmentation. Interestingly, the read-out speed can be regulated using background inputs.</p>
<p>Strengths:</p>
<p>This is an elegant solution to the problem of serial order maintenance, that only relies on experimentally observed features of synapses. The model is consistent with a number of experimental observations in humans and monkeys. The paper will be of interest to the broad readership of eLife and I believe it will have a strong impact on the field.</p>
<p>Comments on revisions:</p>
<p>I am happy with how the authors have addressed my comments, and believe the paper can be published in its present form.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this manuscript, the authors present a model to explain how working memory (WM) encodes both existence and timing simultaneously using transient synaptic augmentation. A simple yet intriguing idea.</p>
<p>The model presented here has the potential to explain what previous theories like 'active maintenance via attractors' and 'liquid state machine' do not, and describe how novel sequences are immediately stored in WM. Altogether, the topic is of great interest to those studying higher cognitive processes, and the conclusions the authors draw are certainly thought-provoking from an experimental perspective.</p>
<p>Comments on revisions:</p>
<p>The authors have done an excellent job of addressing the questions that I raised, and the manuscript is greatly improved - both in content and clarity. It is an insightful advance and I recommend publication.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107005.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Mongillo</surname>
<given-names>Gianluigi</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6885-9394</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Tsodyks</surname>
<given-names>Misha</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5661-4349</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>(1) The network they propose is extremely simple. This simplicity has pros and cons: on the one hand, it is nice to see the basic phenomenon exposed in the simplest possible setting. On the other hand, it would also be reassuring to check that the mechanism is robust when implemented in a more realistic setting, using, for instance, a network of spiking neurons similar to the one they used in the 2008 paper. The more noisy and heterogeneous the setting, the better.</p>
</disp-quote>
<p>The choice of a minimal model to illustrate our hypothesis is deliberate. Our main goal was to suggest a physiologically-grounded mechanism to rapidly encode temporally-structured information (i.e., sequences of stimuli) in Working Memory, where none was available before. Indeed, as discussed in the manuscript, previous proposals were unsatisfactory in several respects. In view of our main goal, we believe that a spiking implementation is beyond the scope of the present work.</p>
<p>We would like to note that the mechanism originally proposed in Mongillo et al. (2008), has been repeatedly implemented, by many different groups, in various spiking network models with different levels of biological realism (see, e.g., Lundquivst et al. (2016), for an especially ‘detailed’ implementation) and, in all cases, the relevant dynamics has been observed. We take this as an indication of ‘robustness’; the relevant network dynamics doesn’t critically depend on many implementation details and, importantly, this dynamics is qualitatively captured by a simple rate model (see, e.g., Mi et al. (2017)).</p>
<p>In the present work, we make a relatively ‘minor’ (from a dynamical point of view) extension of the original model, i.e., we just add augmentation. Accordingly, we are fairly confident that a set of parameters for the augmentation dynamics can be found such that the spiking network behaves, qualitatively, as the rate model. A meaningful study, in our opinion, then would require extensively testing the (large) parameters’ space (different models of augmentation?) to see how the network behavior compares with the relevant experimental observations (which ones? Behavioral? Physiological?). As said above, we believe that this is beyond the scope of the present work.</p>
<p>This being said, we definitely agree with the reviewer that not presenting a spiking implementation is a limitation of the present work. We have clearly acknowledged this limitation here, by adding the following paragraph to the Discussion.</p>
<p>“To illustrate our theory in a simple setting, we used a minimal model network that neglects many physiological details. This, however, constitutes a limitation of the present study. It would be reassuring to see that the mechanism we propose here is robust enough to reliably operate also in spiking networks, in the presence of heterogeneity in both single-cell and synaptic properties. While we are fairly confident that this is the case, a spiking implementation of our model is beyond the scope of the present study and will be addressed in the future. Also, because of the simplicity of the model network, a comparison between the model behavior and the electrophysiological observations cannot be completely direct. Nevertheless the model qualitatively accounts for a diverse set of experimental data”.</p>
<disp-quote content-type="editor-comment">
<p>(2) One major issue with the population spike scenario is that (to my knowledge) there is no evidence that these highly synchronized events occur in delay periods of working memory experiments. It seems that highly synchronized population spikes would imply (a) a strong regularity of spike trains of neurons, at odds with what is typically observed in vivo (b) high synchronization of neurons encoding for the same item (and also of different items in situations where multiple items have to be held in working memory), also at odds with in vivo recordings that typically indicate weak synchronization at best. It would be nice if the authors at least mention this issue, and speculate on what could possibly bridge the gap between their highly regular and synchronized network, and brain networks that seem to lie at the opposite extreme (highly irregular and weakly synchronized). Of course, if they can demonstrate using a spiking network simulation that they can bridge the gap, even better.</p>
</disp-quote>
<p>Direct experimental evidence (in monkeys) in support of the existence of highly synchronized events -- to be identified with the ‘population spikes’ of our model -- during the delay period of a memory task is available in the literature, i.e., Panichello et al. (2024). we provide a short discussion of the results of Panichello et al. (2024) and how these results directly relate to our model. We also provide a short discussion of the results of Liebe et al. (2025), which, again, are fully consistent with our model.</p>
<p>We note that there is no fundamental contradiction between highly synchronized events in ‘small’ neural populations (e.g., a cell assembly) on one hand, and temporally irregular (i.e., Poisson-like) spiking at the single-neuron level and weakly synchronized activity at the network level, on the other hand. This was already illustrated in our original publication, i.e., Mongillo et al. (2008) (see, in particular, Fig. S2). We further note that the mechanism we propose to encode temporal order -- a temporal gradient in the synaptic efficacies brought about by synaptic augmentation -- would also work if the memory of the items is maintained by ‘tonic’ persistent activity (i.e., without highly synchronized events), provided this activity occurs at suitably low rates such as to prevent the saturation of the synaptic augmentation.</p>
<p>We have added the following two paragraphs to the Discussion.</p>
<p>“More direct support to this interpretation comes from recent electrophysiological studies [Panichello et al., 2024, Liebe et al., 2025]. By recording large neuronal populations (∼ 300) simultaneously in the prefrontal cortex of monkeys performing a WM task, [Panichello et al., 2024] found that, during the maintenance period, the decoding of the actively held item from neural activity was ’intermittent’; that is, decoding was only possible during short epochs (∼ 100ms) interleaved with epochs (also ∼ 100ms) where decoding was at chance level. The inability to decode resulted from a loss of selectivity at the population level, with a return of the single-neuron firing rates to their spontaneous (pre-stimulus) activity levels. The transitions between these two activity states (decodable/not-decodable) were coordinated across large populations of neurons in PFC. By recording single-neuron activity in the medial temporal lobe of humans performing a sequential multi-item WM task, [Liebe et al., 2025] found that during maintenance, neurons coding for a given item tended to fire at a specific phase of the underlying theta rhythm, again suggesting that the corresponding neuronal populations reactivate briefly and sequentially. In summary, these experimental results suggest that active memory maintenance relies on brief reactivations of the neural representations of the items, which we identify with the population spikes in our model, and that these reactivatations occur sequentially in time, as predicted by our theory”.</p>
<p>“We note that the proposed mechanism would still work if the items were maintained by tonically-enhanced firing rates, instead of population spikes, provided that those firing rates were suitably low. However, obtaining low firing rates in model networks of persistent activity is quite difficult”.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>The study relates to the well-known computational theory for working memory, which suggests short-term synaptic facilitation is required to maintain working memory, but doesn't rely on persistent spiking. This previous theory appears similar to the proposed theory, except for the change from facilitation to augmentation. A more detailed explanation of why the authors use augmentation instead of facilitation in this paper is warranted: is the facilitation too short to explain the whole process of WM? Can the theory with synaptic facilitation also explain the immediate storage of novel sequences in WM?</p>
</disp-quote>
<p>In the model, synaptic dynamics displays both short-term facilitation and augmentation (and shortterm depression). Indeed, synaptic facilitation, alone, would be too short-lived to encode novel sequences. This is illustrated in Fig. 1B.</p>
<p>We provide a discussion of this important point, by adding the following paragraph to the Results section.</p>
<p>“If augmentation was the only form of synaptic plasticity present in the network, the encoding of an item in WM would require long presentation times, or alternatively high firing rates upon presentation, precisely because K_A is small. Instead, rapid encoding is made possible by the presence of the short-term facilitation, which builds up significantly faster than augmentation, as U &gt;&gt; K_A . For the same reason, however, the level of facilitation rapidly reaches the steady state; therefore, short-term facilitation alone is unable to encode temporal order (see Fig. 1B). Thus, our model requires the existence of transitory synaptic enhancement on at least two time scales, such that longer decays are accompanied by slower build-ups. Intriguingly, this pattern is experimentally observed [Fisher et al., 1997]”.</p>
<disp-quote content-type="editor-comment">
<p>In Figure 1, the authors mention that synaptic augmentation leads to an increased firing rate even after stimulus presentation. It would be good to determine, perhaps, what the lowest threshold is to see the encoding of a WM task, and whether that is biologically plausible.</p>
</disp-quote>
<p>We believe that this comment is related to the above point. The reviewer is correct; augmentation alone would require fairly long stimulus presentations to encode an item in WM. ‘Fast’ encoding, indeed, is guaranteed by the presence of short-term facilitation. This important point is emphasized; see above.</p>
<disp-quote content-type="editor-comment">
<p>In the middle panel of Figure 4, after 15-16 sec, when the neuronal population prioritizes with the second retro-cue, although the second retro-cue item's synaptic spike dominates, why is the augmentation for the first retro-cue item higher than the second-cue augmentation until the 20 sec?</p>
</disp-quote>
<p>This is because of the slow build-up and decay of the augmentation. When the second item is prioritized, and the corresponding neuronal population re-activates, its augmentation level starts to increase. At the same time, as the first item is now de-prioritized and the corresponding neuronal population is now silent, its augmentation level starts to decrease. Because of the ‘slowness’ of both processes (i.e., augmentation build-up and decay), it takes about 5 seconds for the augmentation level of the second item to overcome the augmentation level of the first item.</p>
<p>We note that the slow time scales of the augmentation dynamics, consistently with experimental observations, are necessary for our mechanism to work; see above.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations for the authors):</bold></p>
<p>(1) Line 46 identify -&gt; identity.</p>
<p>(2) Line 207 scale -&gt; scales.</p>
</disp-quote>
<p>Fixed. Thank you.</p>
<disp-quote content-type="editor-comment">
<p>(3) Lines 222-224 what about behavioral time-scale plasticity? This type of plasticity can apparently be induced very quickly.</p>
</disp-quote>
<p>We have removed the corresponding paragraph.</p>
<disp-quote content-type="editor-comment">
<p>(4) Line 231 identification of `gamma bursts' with population spikes: These two phenomena seem to be very different - one can be weakly synchronized and can be consistent with highly irregular activity, while it is not clear whether the other can (see major issue 2). Also, it seems that population spikes occur at frequencies that are an order of magnitude lower than gamma.</p>
</disp-quote>
<p>We have rewritten the corresponding paragraph and we rely now on more direct electrophysiological evidence (i.e., on the simultaneous recording of large neuronal populations) to identify putative population spikes; see above.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations for the authors):</bold></p>
<p>(1) On page 7, the behavioral study of Rose et al. (2016) is quite important for readers to understand the 'low-activity regime', and to fully appreciate Figure 4, it would be beneficial to explain that study in greater detail.</p>
</disp-quote>
<p>We have added a panel to Fig. 4, and accompanying text in the caption, to better illustrate the main task events in the experiment of Rose et al. (2016).</p>
<disp-quote content-type="editor-comment">
<p>(2) Line 17: &quot;wrong order&quot;, but wrong timing matters too</p>
</disp-quote>
<p>Definitely, depending on the task. Specifically, in our example, timing is immaterial.</p>
<disp-quote content-type="editor-comment">
<p>(3) Line 33-34: &quot;special training&quot;, what is considered special? One could argue that the number of trials needed to learn, depending on the TI timing, is special, depending on the task.</p>
</disp-quote>
<p>We have removed the sentence as apparently it was confusing. We simply meant that ‘naive’ human subjects can perform the task (e.g., serial recall); that is, they didn’t undergo any kind of practice that can be construed as ‘training’.</p>
<disp-quote content-type="editor-comment">
<p>(4) Line 40-41: but timing is also part of working memory processing. Perhaps it can be merged with the next sentence.</p>
</disp-quote>
<p>We have merged the two sentences.</p>
<disp-quote content-type="editor-comment">
<p>(5) Line 53: Is the implication here that what happens in the synapses is what drives WM, and not just that the neurons stay persistently on?</p>
</disp-quote>
<p>Yes. The idea is that information can be maintained in the synaptic facilitation level, without enhanced spiking activity. Reading-out and refreshing the memory contents, however, requires neuronal activity. We explain this in some detail in the next paragraph (i.e., lines 60-65 in the revised submission).</p>
<disp-quote content-type="editor-comment">
<p>(6) Line 102: could a lack of excitatory activity be explained by inhibitory signaling? It appears the inhibitory component is quite understated here.</p>
</disp-quote>
<p>Here we are just defining A-bar; according to Eq. (6), if r_a is 0 (i.e., no synaptic activity, for whatever reason), then A_a will converge to A-bar after a time much longer than \tau_A (i.e., a long period). We have rephrased the sentence to improve clarity.</p>
<disp-quote content-type="editor-comment">
<p>(7) Line 158-172: please consider revising this paragraph for a more general audience.</p>
</disp-quote>
<p>We have rewritten this paragraph to improve clarity. For the same purpose, we have also slightly modified Fig. 3.</p>
<disp-quote content-type="editor-comment">
<p>(8) Line 227: it would seem this is due to a singular inhibitory group making the model highly dependent on the excitatory groups.</p>
</disp-quote>
<p>We are not sure that we understand this comment. Here, we are just saying that if the item-coding populations don’t reactivate during the maintenance period (i.e., activity-silent regime) then the augmentation gradient cannot build up. If, on the other hand, the item-coding populations are constantly active at high rates during the maintenance period (i.e., persistent-activity regime) then then augmentation levels will rapidly saturate and, again, there will be no augmentation gradient. This is independent of how ‘silence’ or ‘activity’ of the item-coding populations is determined by the interplay of excitation and inhibition.</p>
<disp-quote content-type="editor-comment">
<p>(9) Line 284: this would certainly be an interesting take, but it isn't clear that the model proved this type of decoupling of the temporal aspect of the recall.</p>
</disp-quote>
<p>This is an ‘educated’ speculation, based on the model and on a specific interpretation of some experimental results, as discussed in the paper and, in particular, in the last paragraph of the Discussion. We believe that the phrasing of the paragraph makes clear that this is, indeed, a speculation.</p>
</body>
</sub-article>
</article>