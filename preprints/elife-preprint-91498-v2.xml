<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">91498</article-id>
<article-id pub-id-type="doi">10.7554/eLife.91498</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.91498.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Medicine</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Evaluating Study Design Rigor in Preclinical Cardiovascular Research: A Replication Study</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Jimenez</surname>
<given-names>Isaiah C</given-names>
</name>
<xref ref-type="author-notes" rid="n1">*</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Montenegro</surname>
<given-names>Gabrielle C</given-names>
</name>
<xref ref-type="author-notes" rid="n1">*</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7931-9115</contrib-id>
<name>
<surname>Zahiri</surname>
<given-names>Keyana</given-names>
</name>
<xref ref-type="author-notes" rid="n1">*</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Patel</surname>
<given-names>Damini</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9161-5323</contrib-id>
<name>
<surname>Mueller</surname>
<given-names>Adrienne</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>alm04@stanford.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Stanford Cardiovascular Institute</institution></institution-wrap>, <city>Stanford</city>, <country>United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01hgj5t98</institution-id><institution>Saint Mary’s College of California</institution></institution-wrap>, <city>Moraga</city>, <country>United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04fceqm38</institution-id><institution>Macalester College</institution></institution-wrap>, <city>Saint Paul</city>, <country>United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Warren Alpert Medical School of Brown University</institution></institution-wrap>, <city>Providence</city>, <country>United States</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02xawj266</institution-id><institution>Central Michigan University</institution></institution-wrap>, <city>Mt Pleasant</city>, <country>United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Daehn</surname>
<given-names>Ilse S</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Icahn School of Medicine at Mount Sinai</institution>
</institution-wrap>
<city>New York</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Barton</surname>
<given-names>Matthias</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Zurich</institution>
</institution-wrap>
<city>Zurich</city>
<country>Switzerland</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>*</label><p>ICJ, GCM, and KZ contributed equally to this work and are co-first authors.</p></fn>
<fn fn-type="coi-statement"><p>Competing Interest Statement: The authors have declared no competing interest.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-11-16">
<day>16</day>
<month>11</month>
<year>2023</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-01-22">
<day>22</day>
<month>01</month>
<year>2025</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP91498</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-09-21">
<day>21</day>
<month>09</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-06-29">
<day>29</day>
<month>06</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.06.27.546731"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2023-11-16">
<day>16</day>
<month>11</month>
<year>2023</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.91498.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.91498.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.91498.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.91498.1.sa0">Reviewer #2 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Jimenez et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Jimenez et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-91498-v2.pdf"/>
<abstract>
<title>Abstract</title>
<sec>
<title>Background</title>
<p>Methodological rigor remains a priority in preclinical cardiovascular research to ensure experimental reproducibility and high-quality research. Limited reproducibility diminishes the translation of preclinical discoveries into medical practice. In addition, lack of reproducibility fosters uncertainty in the public’s acceptance of reported research results.</p></sec><sec>
<title>Methods</title>
<p>We evaluated the reporting of methodological practices in preclinical cardiovascular research studies published in leading scientific journals by screening articles for the inclusion of the following study design elements (SDEs): considering sex as a biological variable, randomization, blinding, and sample size power estimation. We screened for these SDEs across articles regarding preclinical cardiovascular research studies published between 2011 and 2021. We replicated and extended a study published in 2017 by Ramirez et al. We hypothesized a higher SDE inclusion across preclinical studies over time, that preclinical studies that include human and animal substudies within the same study will exhibit greater SDE inclusion than animal-only preclinical studies, and that a difference exists in SDE usage between large and small animal models.</p></sec><sec>
<title>Results</title>
<p>SDE inclusion was low; with 15.2% of animal-only studies including both sexes as a biological variable, 30.4% including randomization, 32.1% including blinding, and 8.2% including sample size estimation. The incorporation of SDEs did not significantly increase over the ten-year timeframe in the screened articles. Randomization and sample size estimation differed significantly between animal and human substudies (corrected p=1.85e-05 and corrected p=3.81e-07, respectively.)</p></sec><sec>
<title>Conclusions</title>
<p>Evidence of methodological rigor varies depending on the study type and model organisms used. From 2011-2021, SDE reporting within preclinical studies has not increased, suggesting more work is needed to foster the inclusion of rigorous study design elements in cardiovascular research.</p></sec>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Statistical analysis and figures have been updated.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Preclinical studies using animal models play an important role in developing new treatments and evaluating the safety and efficacy of novel therapies. Preclinical cardiovascular research has greatly contributed to our understanding of heart disease (<xref ref-type="bibr" rid="c5">Houser et al., 2012</xref>; <xref ref-type="bibr" rid="c1">Bacmeister et al, 2019</xref>), yet we often find failed translations from “bench-to-bedside” (<xref ref-type="bibr" rid="c7">Justice &amp; Dhillon, 2016</xref>; Seok et al., 2012). Methodological rigor in these studies remains a major priority to establish a level of consistent reproducibility across preclinical research.</p>
<p>One means to enhance reproducibility of preclinical research is to increase the frequency of use of study design elements (SDEs) such as inclusion of sex as a biological variable, randomization of samples or subjects, blinding, and sample size estimation. Including both biological sexes in experimental design removes sex as a potential confounding variable in establishing causal relationships between variables of interest. Implementation of randomization in experimental design is an additional means to control for <italic>all</italic> potential confounders between variables of interest. Moreover, randomization helps reduce bias. The use of blinding in experimental design limits potential bias in the assessment of experimental outcomes from study participants and researchers themselves. Finally, sample size estimation limits impractical significance in experimental results and false-negative results. Sample size estimation also addresses the ethical concern of over-sampling of animal model cohorts by establishing a minimum sample size needed. Ultimately, each of these four SDEs influences the reproducibility of preclinical experimental outcomes.</p>
<p>This study is a replication and extension of a study performed by <xref ref-type="bibr" rid="c13">Ramirez et al. (2017)</xref>, which investigated the prevalence of these four SDEs in preclinical studies published in five leading cardiovascular journals of the American Heart Association (<italic>Circulation</italic>; <italic>Circulation Research</italic>; <italic>Hypertension</italic>; <italic>Stroke</italic>; and <italic>Arteriosclerosis, Thrombosis, and Vascular Biology</italic> (<italic>ATVB</italic>)) between July 2006 and June 2016. Their study found a low prevalence of SDEs across screened studies, reflecting low methodological rigor in preclinical cardiovascular research in that decade (<xref ref-type="bibr" rid="c13">Ramirez et al., 2017</xref>). This study investigates the inclusion of these four SDEs in randomly selected preclinical cardiovascular studies published between 2011 and 2021 in nine different leading biomedical and scientific journals outside of American Heart Association publications: <italic>Science, Nature, European Heart Journal, Journal of the American College of Cardiology, New England Journal of Medicine, Cell, Lancet, Journal of the American Medical Association</italic>, and <italic>Proceedings of the National Academy of Sciences of the United States of America</italic>. This study also examines the use of rigorous SDEs by comparing animal-only studies with studies that have both animal and human substudies (human/animal studies) over ten years. The decade 2011-2021 was selected for analysis to provide a more recent evaluation of methodological rigor in preclinical cardiovascular research, following the work of <xref ref-type="bibr" rid="c13">Ramirez et al., 2017</xref>.</p>
<p>By identifying trends in the sex of study subjects used, randomization, blinding, and sample size estimations, we assessed the methodological rigor of scientific practices carried out in preclinical cardiovascular research.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<p>We reviewed preclinical cardiovascular articles published between 2011 and 2021 in leading biomedical and scientific journals. Studies were included from nine leading journals: <italic>Science, Nature, European Heart Journal, Journal of the American College of Cardiology, New England Journal of Medicine, Cell, Lancet, Journal of the American Medical Association</italic>, and <italic>Proceedings of the National Academy of Sciences of the United States of America</italic>. These journals were selected to complement those used in a previous study: <italic>Circulation</italic>; <italic>Circulation Research</italic>; <italic>Hypertension</italic>; <italic>Stroke</italic>; and <italic>Arteriosclerosis, Thrombosis, and Vascular Biology</italic> (<italic>ATVB</italic>) (<xref ref-type="bibr" rid="c13">Ramirez et al., 2017</xref>). Using a search string in a Pubmed query, we identified primary research articles (excluding editorials or comments) describing cardiovascular experiments using animal models. The complete search string used was:</p>
<p>((cardi*[Title]) OR (heart[Title]) OR (arteri*[Title]) OR (hypertensi*[Title]) OR (atherosclero*[Title]) OR (arrhythm*[Title])) AND ((pig[Title/Abstract]) OR (rat[Title/Abstract]) OR (mouse[Title/Abstract]) OR (guinea pig[Title/Abstract]) OR (gerbil[Title/Abstract]) OR (hamster[Title/Abstract]) OR (monkey[Title/Abstract]) OR (rabbit[Title/Abstract]) OR (dog[Title/Abstract])) NOT ((review[Publication Type]) OR (systematic review[Publication Type]) OR (editorial[Publication Type]) OR (comment[Publication Type])) AND ((“2011/01/01”[Date - Publication] : “2021/12/31”[Date - Publication])) AND ((“Lancet (London, England)”[Journal]) OR (“Nature”[Journal]) OR (“Science (New York, N.Y.)”[Journal]) OR (“JAMA”[Journal]) OR (“The New England journal of medicine”[Journal]) OR (“Proceedings of the National Academy of Sciences of the United States of America”[Journal]) OR (“Cell”[Journal]) OR (“European heart journal”[Journal]) OR (“Journal of the American College of Cardiology”[Journal])).</p>
<p>309 articles were returned by the PubMed Search query. No stopping rule was utilized, as the sample size was predetermined before data collection. Studies were included if they were published manuscripts and used animal subjects. Articles were excluded from data analysis if they did not include animal-model experiments, if they were not related to a cardiovascular research topic, or were published as an abstract, editorial, or any form other than a published full manuscript. Thus, although the search string yielded 309 studies for screening, 11 studies were excluded for not meeting inclusion criteria. A total of 298 studies were ultimately included in our data analyses.</p>
<p>Articles were screened based on four study design elements (SDEs): inclusion of both biological sexes in study subjects, randomization, blinding, and sample size estimation. The screening database included animal-only studies, as well as animal studies that included human substudies (human/animal studies). For human/animal studies, the same SDEs were used to evaluate methodological rigor across human subject populations. We evaluated the four SDEs separately for studies that only performed animal experiments and studies that performed human/animal experiments, if applicable. Screening definitions were predefined (<xref ref-type="table" rid="tbl1">Table I</xref>). Articles were also screened for what cardiovascular research topic they were investigating, as well as which animal species were used in the study (<xref ref-type="table" rid="tbl2">Table II</xref>). We initially used cardiovascular research topics that were defined by <xref ref-type="bibr" rid="c13">Ramirez et al. (2017)</xref> and also expanded the topic list to include 2 additional topics that occurred more frequently in our dataset: congenital heart disease and heart development/repair/regeneration.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table I:</label>
<caption><title>This table depicts the predetermined screening numerical codes and descriptions used for study analysis of methodological rigor across all studies.</title></caption>
<graphic xlink:href="546731v2_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table II:</label>
<caption><title>This table lists the information collected during screening across all studies.</title></caption>
<graphic xlink:href="546731v2_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Articles were distributed equally among members of the research team for screening. Articles were initially screened in the order they were returned from the PubMed search. Investigators did not select which articles from the database of 298 articles to screen based on any specific criteria. To ensure accuracy and consistency in screening, each article was independently screened by two investigators. Screeners were randomly assigned for the second screening of an article. Discrepancies in screening were resolved by consensus.</p>
<sec id="s2a">
<title>Statistical Methods</title>
<p>The collected data was analyzed to evaluate the prevalence of the use of SDEs in preclinical cardiovascular research between 2011 and 2021. Categorical variables are reported as a number (%). RStudio and Microsoft Excel software were used to perform statistical significance comparisons. A median-based linear model analysis was performed to analyze changes in SDE inclusion over time, and nonparametric Kruskal-Wallis tests were performed to analyze differences in SDE reporting across journals. Chi-squared tests were performed for other analyses to assess differences in SDE reporting across experimental models, between animals vs humans within the same study, and across different animal models. A threshold of p &lt; 0.05 was considered statistically significant, however, we used the Holm-Bonferroni correction to correct for multiple comparisons.</p>
</sec>
<sec id="s2b" sec-type="data-availability">
<title>Pre-registration and Data Availability</title>
<p>This study was pre-registered in the Open Science Framework (OSF) registry. The preregistration can be accessed via the following link: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/F4NH9">https://doi.org/10.17605/OSF.IO/F4NH9</ext-link> (<xref ref-type="bibr" rid="c11">Patel et al., 2022</xref>). We adhered to the methodology detailed in the pre registration for this analysis.</p>
<p>The data and analytical methods used for this study are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/52Q6W/">https://osf.io/52Q6W/</ext-link> (<xref ref-type="bibr" rid="c17">Zahiri et al., 2022</xref>.)</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<p>A total of 298 preclinical research studies published between 2011 and 2021 were included in our analyses. 61.7% (N=184) of these studies were animal only and 38.3% (N=114) were human/animal studies (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). Approximately the same number of cardiovascular preclinical research studies were published for each of the ten years in our sample (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). The majority of the studies in our analysis were published in Proceedings of the National Academy of Sciences of the United States of America, 45.3% (N=135) (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). In addition, a wide range of species were used in the preclinical studies we analyzed (<xref rid="fig1" ref-type="fig">Figure 1D</xref>). Mice were the most commonly studied species used in 77.2% (N=230) of studies. This was followed by rats in 20.1% (N=60) of studies. Additionally, a wide range of topics relating to cardiovascular disease were investigated in the studies we assessed (<xref rid="fig1" ref-type="fig">Figure 1E</xref>). We categorized the topics as follows: cardiomyopathy or heart failure (28.2%), atherosclerosis or vascular homeostasis (16.1%), myocardial infarction (14.8%), cardiac arrhythmia (9.1%), heart development/repair/regeneration (8.0%), hypertension (4.4%), metabolic or endocrine disease (4.0%), congenital heart disease (2.7%), valvular disease (2.0%), cardiac transplantation (1.7%), hematological disorder (0.3%), and other (8.7%), based on topics identified in the original <xref ref-type="bibr" rid="c13">Ramirez et al. (2017)</xref> study.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>There is a diverse range of preclinical cardiovascular research studies published over the last decade.</title>
<p><bold>(A)</bold> This figure depicts the proportion of studies included in our analysis were animal only or human/animal studies. <bold>(B)</bold> This figure depicts the proportions of studies included in our analysis from various publication years between 2011-2021. (<bold>C)</bold> This figure depicts the proportions of studies included in our analysis from each of nine high impact scientific journals. (<bold>D)</bold> This figure depicts the range of species used in the sample populations of studies included in our analysis. Mice and rats were the most commonly studied animal models across all studies. (<bold>E)</bold> This figure depicts the main range of topics the articles used in this study primarily investigated.</p></caption>
<graphic xlink:href="546731v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<sec id="s3a">
<title>Overall SDE Inclusion</title>
<p><xref ref-type="table" rid="tbl3">Table III</xref> shows the proportion of studies that included each of the four SDEs, stratified by animal-only studies, as well as animal and human substudies in human/animal studies. In animal-only studies, both sexes were used in 15.2% (N=28) studies, single-sex was used in 48.4% (N=89) studies, and there was no reporting on the sex of study subjects used in 36.4% (N=67) studies. In animal substudies in human/animal studies, both sexes were used in 17.5% (N=20) studies, single-sex was used in 53.5% (N=61) studies, and there was no reporting on the sex of study subjects used in 29.0% (N=33) studies. In human substudies in human/animal studies, both sexes were used in 36% (N=41) of studies, single-sex was used in 8.8% (N=10) of studies, and there was no reporting on the sex of study subjects used in 55.2% (N=63) studies.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table III:</label>
<caption><title>These tables depict the descriptive statistics for SDEs analyzed for animal only studies vs animal or human substudies in human/animal studies.</title></caption>
<graphic xlink:href="546731v2_tbl3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>In terms of randomization, 30.4% (N=56) of animal-only studies, 36% (N=41) of animal substudies in human/animal studies, and 6% (N=7) of human substudies in human/animal studies used randomization to any degree in their experiments. In terms of blinding, 32.1% (N=59) of animal-only studies, 24.5% (N=28) of animal substudies in human/animal studies, and 11.4% (N=13) of human substudies in human/animal studies used blinding to any degree in their experiments.</p>
<p>In terms of sample size estimations for animal-only studies, 8.2% (N=15) used statistical analysis to determine the sample size for experiments, 4.9% (N=9) provided other justification for the sample size they selected, 2.7% (N=5) indicated that no sample size estimation was done, and 84.2% (N=155) did not report sample size justification. Examples of ‘other justification for sample size selection’ include estimating sample size based on pilot studies or determining sample size based on previous standards in the field. In terms of sample size estimations for animal substudies in human/animal studies, 7% (N=8) used statistical analysis to determine the sample size for experiments, 2.6% (N=3) provided other justification for the sample size they selected, 5.3% (N=6) indicated that no sample size estimation was done, and 85.1% (N=97) did not report any sample size justification. Lastly, in terms of sample size estimations for human substudies in human/animal studies, 1.8% (N=2) used statistical analysis to determine the sample size for experiments, 12.3% (N=14) provided other justification for the sample size they selected, 2.6% (N=3) indicated that no sample size estimation was done, and 83.3% (N=95) did not report any sample size justification.</p>
</sec>
<sec id="s3b">
<title>Changes in SDEs Over Time</title>
<p>A median-based linear analysis of SDE inclusion between 2011 and 2021 revealed no statistically significant difference in the proportion of studies including animals of both biological sexes between 2011 and 2021 (corrected p=1.476) (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Of studies screened from 2011, 10% (N=3 of 29) included animals of both biological sexes. Of studies screened from 2017, 27% (N=9 of 33) included animals of both biological sexes. This proportion ultimately decreases to 10% (N=2 of 21) of studies in 2021 (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Although there appears to be an overall general increase in the proportion of studies including animals of both biological sexes across the decade of interest, no statistically significant difference was found (corrected p&gt;0.05).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Percentage of studies with SDE inclusion in preclinical cardiovascular research between 2011-2021 differed across the four SDEs screened.</title>
<p>Percentages are reported for animal models used in all 298 eligible studies, regardless of whether the experimental design included human substudies. The percentage of studies including both biological sexes, randomization, blinding, and sample size estimation showed no statistically significant difference between 2011-2021 (median-based linear analysis).</p></caption>
<graphic xlink:href="546731v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Similarly, a median-based linear analysis of randomization implementation revealed no statistically significant difference in the proportion of studies implementing randomization between 2011 and 2021 (corrected p=1.617). Approximately half of preclinical cardiovascular studies implemented randomization in 2011, as 48% (N=14 of 29) of 2011 studies mentioned randomization in their methods. This proportion declined to 29% (N=6 of 21) of studies in 2021 (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Although there appears to be an overall general decrease in the proportion of studies including randomization across the decade of interest, no statistically significant decrease was found (corrected p&gt;0.05)</p>
<p>Interestingly, a median-based linear analysis of blinding implementation also showed no statistically significant difference in the proportion of studies including blinding as part of the study design between 2011 and 2021 (corrected p=0.335) (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Of studies screened from 2011, 24% (N=7 of 29) included blinding. This proportion decreased to 19% (N=4 of 21) in 2021 (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Likewise, comparable results were found for sample size justification (corrected p=0.390) (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Of studies screened from 2011, 14% (N=4 of 29) justified their sample size using size estimation (justification or statistical estimation). This proportion dropped to 0% (N=0 of 22) studies in 2018 but ultimately increased back up to 14% (N=3 of 21) in 2021 (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Again, although there appears to be an overall general decrease in the proportion of studies including blinding and sample size justification as part of the study design, a median-based linear model ultimately revealed no statistically significant decrease across the decade of interest (corrected p&gt;0.05).</p>
</sec>
<sec id="s3c">
<title>Differences in SDE Reporting Across Journals</title>
<p>Of all 298 journal articles screened in this study, the four journals with the highest numbers of cardiovascular preclinical studies were: <italic>Proceedings of the National Academy of Sciences of the United States of America (Proc Natl Acad Sci)</italic> 45.3% (N=135), <italic>European Heart Journal (Eur Heart J)</italic> 20.5% (N=61), <italic>Journal of the American College of Cardiology (J Am Coll Cardiol)</italic> 14.1% (N=42), and <italic>Nature</italic> 10.4% (N=31). A general difference in the reporting of the four SDEs was observed across all four journals, but differences were not determined to be statistically significant by Kruskal-Wallis tests: both sexes: H(10)=6.625, corrected p=2.281; randomization: H(10)=6.597, corrected p=1.526; blinding: H(10)=3.498, corrected p=0.967, sample size estimation: H(8)=8.344, corrected p=2.804) (<xref rid="fig3" ref-type="fig">Figure 3</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>The percentage of SDE inclusion in preclinical cardiovascular research between 2011-2021 generally varied across the four most prevalent journals.</title>
<p><bold>(A) Both Sexes Analysis:</bold> The percentage of studies including animals of both biological sexes generally increased across all four most journals, but no statistically significant differences were found (corrected p=2.281) (Kruskal-Wallis test analysis). <bold>(B) Randomization Analysis:</bold> The percentage of studies using randomization generally increased in studies from <italic>Eur Heart J</italic> and <italic>J Am Coll Cardiol</italic>, but decreased across studies from <italic>Proc Natl Acad Sci</italic> and <italic>Nature</italic> (Kruskal-Wallis Test). However, no statistically significant differences were found (corrected p=1.526) <bold>(C) Blinding Analysis:</bold> Similar results for randomization inclusion apply to blinding inclusion. Likewise, no statistically significant differences were found (corrected p=0.967) (Kruskal-Wallis test analysis). <bold>(D) Sample Size Analysis:</bold> The percentage of studies implementing statistical sample size estimations increased in studies screened from <italic>Eur Heart J</italic> and <italic>Nature</italic>, and decreased across those screened from <italic>Proc Natl Acad Sci</italic> and <italic>J Am Coll Cardiol</italic> (Kruskal-Wallis Test analysis). Still, no statistically significant differences were found (corrected p=2.804).</p></caption>
<graphic xlink:href="546731v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Articles screened across the four most prevalent journals in this study varied in frequency across the ten years (2011-2021). Among studies screened from <italic>Eur Heart J</italic>, (N=1 of 11) 11% included animals of both biological sexes in 2011 while (N=2 of 8) 25% included both biological sexes in 2019. Across studies screened from the <italic>J Am Coll Cardiol</italic>, (N=1 of 6) 17% included animals from both biological sexes in 2011 while 50% (N=2 of 4) included both biological sexes in 2019 (<xref rid="fig3" ref-type="fig">Figure 3</xref>). A difference of +14% in the <italic>Eur Heart J</italic> and +33% in the <italic>J Am Coll Cardiol</italic> between the journals was not found to be statistically significant (corrected p=2.804).</p>
<p>In studies screened from <italic>Eur Heart J</italic>, 56% (N=5 of 9) reported using randomization in 2011 and 43% (N=3 of 7) reported using randomization in 2021. Meanwhile, in studies screened from the <italic>Proc Natl Acad Sci</italic>, 44% (N=4 of 9) reported using randomization in 2011 and 22% (N=2 of 9) reported using randomization in 2021 (<xref rid="fig3" ref-type="fig">Figure 3</xref>). Similarly, although a difference of -13% over time was observed in <italic>Eur Heart J</italic> versus a difference of -22% in the <italic>Proc Natl Acad Sci</italic>, no statistically significant difference between these decreasing rates was found across the ten years (corrected p=1.526).</p>
<p>With regards to reporting of blinding, in studies screened from the <italic>Proc Natl Acad Sci</italic>, 22% (N=2 of 9) reported implementing blinding in 2011 and 33% (N=3 of 9) reported implementing blinding in 2021. In studies screened from the <italic>J Am Coll Cardiol</italic>, 33% (N=2 of 6) used blinding in 2011 while 100% (N=1 of 1) used blinding in 2021 (<xref rid="fig3" ref-type="fig">Figure 3</xref>). A change of +11% overtime was observed across studies screened from the <italic>Proc Natl Acad Sci</italic> versus a change of +77% across studies screened from the <italic>J Am Coll Cardiol</italic>, but no statistically significant difference was found in comparing these differences as well (corrected p=0.967).</p>
<p>Finally, in assessing differences in reporting statistical estimations for study sample size, a difference of +3% (N=2 of 9 to N=1 of 4) was found across studies screened from the <italic>Eur Heart J</italic> between 2011 and 2020 (<xref rid="fig3" ref-type="fig">Figure 3</xref>). A difference of -10% (N=3 of 18 to N=1 of 15) was observed between studies screened from <italic>Proc Natl Acad Sci</italic> from 2012-2017 (<xref rid="fig3" ref-type="fig">Figure 3</xref>). No studies before 2012 nor beyond 2017 from the <italic>Proc Natl Acad Sci</italic> reported using sample size estimations. Observed differences were not determined to be statistically significant (corrected p=2.804).</p>
</sec>
<sec id="s3d">
<title>Differences in SDE Reporting Across Experimental Models</title>
<p>There were slight differences in SDE reporting for animal substudies in human/animal studies vs animal-only studies (<xref rid="fig4" ref-type="fig">Figure 4</xref>). In human/animal studies, 18% (N=20) used subjects of both sexes, 53% (N=61) used only one sex of study subjects, and 29% (N= 33) did not report the sex of study subjects used, as opposed to 16% (N=28), 47% (N=89), and 37% (N=67), respectively, for animal only studies. Randomization was only used in 36% (N=41) of human/animal studies and 30% (N=56) of animal-only studies. Blinding was only used in 25% (N=28) of human/animal studies and 32% (N=59) of animal-only studies. In terms of sample size estimations for human/animal studies, 7% (N=8) performed sample size estimations, 3% (N=3) justified not using sample size estimations, 5% (N=6) did not perform sample size estimation, and 85% (N=97) did not report any information on sample size estimation. For animal-only studies, these values were 8% (N=15), 5% (N=9), 3% (N=5), and 84% (N=155), respectively.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>SDE inclusion varied in Human/Animal (HA) vs Animal Only (AO) studies.</title>
<p><bold>(A) Both Sexes Analysis:</bold> This figure depicts the inclusion of both sexes vs single sex in human/animal studies vs animal only studies (Chi-Squared analysis). <bold>(B) Randomization Analysis:</bold> This figure depicts the inclusion of randomization in human/animal studies vs animal only studies (Chi-Squared analysis). <bold>(C) Blinding Analysis:</bold> This figure depicts the inclusion of blinding in human/animal studies vs animal only studies (Chi-Squared analysis). <bold>(D) Sample Size Analysis:</bold> This figure depicts the inclusion of sample size estimation in human/animal studies vs animal only studies (Chi-Squared analysis).</p></caption>
<graphic xlink:href="546731v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>However, there were no statistically significant differences in SDE reporting in human/animal or animal-only studies in terms of the sex of study subjects used (X<sup>2</sup>=1.775, df=2, corrected p=2.470), randomization (X<sup>2</sup>=0.7448, df=1, corrected p=3.104), blinding (X<sup>2</sup>=1.5715, df=1, corrected p=1.89), or sample size estimation (X<sup>2</sup>=2.2518, df=3, corrected p=2.609).</p>
</sec>
<sec id="s3e">
<title>Differences in SDE Reporting For Animals vs Humans within the Same Study</title>
<p>Within human/animal studies, there were variations in SDE reporting for human vs animal substudies (<xref rid="fig5" ref-type="fig">Figure 5</xref>). For human substudies in human/animal studies, 36% (N=41) used subjects of both sexes, 8.7% (N=10) used only one sex of study subjects, and 55.3% (N= 63) did not report the sex of study subjects used, as opposed to 17.5% (N=20), 53.5% (N=61), and 29% (N=33), respectively, for animal only studies. Randomization was used in 6% (N=7) of human substudies and 36% (N=41) of animal substudies, and blinding was used in 11% (N=13) of human substudies and 25% (N=28) of animal substudies in human/animal studies. In terms of sample size estimations for human substudies, 2% (N=2) performed sample size estimations, 12% (N=14) justified not using sample size estimations, 3% (N=3) did not perform sample size estimation, and 83% (N=95) did not report any information on sample size estimation. For animal substudies, these values were 7% (N=8), 3% (N=3), 5% (N=6), and 85% (N=97), respectively.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>SDE inclusion for animal vs human substudies also varied within human/animal studies.</title>
<p><bold>(A) Human/Animal Studies: Both Sexes Analysis</bold>. This figure depicts the inclusion of both sexes vs single sex in human vs animal substudies in human/animal studies (Chi-Squared analysis). <bold>(B) Human/Animal Studies: Randomization Analysis</bold>. This figure depicts the inclusion of randomization in human vs animal substudies in human/animal studies(Chi-Squared analysis). <bold>(C) Human/Animal Studies: Blinding Analysis</bold>. This figure depicts the inclusion of blinding in human vs animal substudies in human/animal studies (Chi-Squared analysis). <bold>(D) Human/Animal Studies: Sample Size Analysis</bold> This figure depicts the inclusion of sample size estimation in human vs animal substudies in human/animal studies (Chi-Squared analysis).</p></caption>
<graphic xlink:href="546731v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>There was a statistically significant difference in the use of randomization (X<sup>2</sup>=24.083, df=1, corrected p=1.85e-05) and sample size estimation inclusion (X<sup>2</sup>=38.911, df=3, corrected p=3.81e-07) of animal vs human substudies in human/animal studies. However, there was no statistically significant difference for blinding (X<sup>2</sup>=5.4878, df=1, corrected p=0.326) and sex of study subjects used in animal vs human substudies in human/animal studies (X<sup>2</sup>=3.123, df=2, corrected p=2.098).</p>
</sec>
<sec id="s3f">
<title>Differences in SDE Reporting in Different Animal Models</title>
<p>Reporting of biological sex SDE is greater in large animal studies whether including both sexes or stating only one sex was used when compared to small animal studies (<xref rid="fig6" ref-type="fig">Figure 6</xref>). Note that the number of small animal studies was far greater than the number of large animal studies that were used for this analysis. For small animals, both sexes were used in 16% (N=44) studies, a single-sex was used in 50% (N=135) studies, and sex was not reported for 34% (N=93) studies. Large animal studies exhibited a similar trend in that both sexes were used in 15% (N=4) studies, a single-sex was used in 58% (N=15), and sex was not reported in 26% (N=7) studies. There was no significant difference in the proportions of studies reporting sex between the small and large animals (chi-square test of interdependence, X<sup>2</sup>=0.689, df=2, corrected p=2.836). In small animal studies, randomization was used in 30% (N=82) whereas for large animal studies, 58% (N=15) studies used randomization. There was no significant difference in the proportions of studies using randomization between the large and small animals (chi-square test of interdependence, X<sup>2</sup>=6.995, df=1, corrected p=0.152). Small animal studies had 27% (N=74) of studies that used blinding whereas large animals had 50% (N=13) of studies that used blinding. There was no significant difference in the proportion of studies using blinding between the two variables (chi-square test of interdependence, X<sup>2</sup>=4.913, df=1, corrected p=0.390). Lastly, 86% (N=234) of small animal studies did not report any information regarding sample size estimation. For large animal studies, 69% (N=18) did not report any information regarding sample size estimation. There was no significant difference in the proportion of studies using sample size estimation between the two variables (chi-square test of interdependence, X<sup>2</sup>= 7.7154, df=3, corrected p=0.676). This data is summarized in <xref rid="fig6" ref-type="fig">Figure 6</xref>.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Proportion of SDE inclusion in preclinical cardiovascular studies differs between studies consisting of either small or large animal substudies from 2011-2021.</title>
<p><bold>(A) Sex as a Biological Variable Analysis:</bold> This figure compares the proportion of articles that reported incorporation of both sexes, a single sex, or omission of reporting for small or large animals (Chi-Squared analysis). <bold>(B) Randomization Analysis:</bold> This figure compares the proportion of articles that reported randomization for small or large animals (Chi-Squared analysis). <bold>(C) Blinding Analysis:</bold> This figure compares the proportion of articles that reported randomization for small or large animals (Chi-Squared analysis). <bold>(D) Sample Size Estimation Analysis:</bold> This figure compares the proportion of studies that reported use of sample size estimation for small or large animals (Chi-Squared analysis).</p></caption>
<graphic xlink:href="546731v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The proportion of single-sex studies was found to be greater for other animal models in comparison to rodents (<xref rid="fig7" ref-type="fig">Figure 7</xref>). Of the studies in which rodents were the primary animal model, 48.1% (N=128) were single-sex studies. This is less than other animal model studies where 68.8% (N=22) were single-sex studies. There is a statistically significant difference between single-sex inclusion in rodent studies and other animal studies (X<sup>2</sup>=4.073, df=1, corrected p=0.610).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Sex inclusion in the study population varied in rodent vs other animal studies.</title>
<p>This figure compares the proportion of rodent studies and non-rodent animal studies that were single-sex studies (Chi-Squared analysis).</p></caption>
<graphic xlink:href="546731v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>We replicated and expanded a 2017 study by Ramirez et al. by assessing the reporting of four study design elements - inclusion of both sexes, randomization, blinding, and sample size analysis - in preclinical cardiovascular studies with either animal-only studies or studies with both human and animal substudies, over 10 years from 2011 to 2021. Overall, the inclusion of SDEs was low. 15.2% of animal-only studies included both sexes as a biological variable, 30.4% included randomization, 32.1% included blinding, and 8.2% included sample size estimation. Also, the incorporation of SDE in preclinical studies did not significantly increase over the ten years in the articles we assessed. Among human and animal substudies of human/animal studies, a significantly larger proportion of animal substudies reported usage of randomization and sample size estimation. Our conclusions serve as an informative checkpoint for the impacts of implementing ARRIVE (Animal Research: Reporting in In Vivo Experiments) and other protocols for enforcing methodological rigor (Lapchak et al., 2013; Ramirez et al., 2020; <xref ref-type="bibr" rid="c16">Williams et al., 2022</xref>).</p>
<sec id="s4a">
<title>The Prevalence and Importance of Study Design Elements in Preclinical Research</title>
<p>The low reproducibility of preclinical studies may partially be attributed to the pressure to publish in high-impact journals, which is more easily achieved if a study has positive results (Mlinaric et al., 2017). Researchers are also incentivized to share positive results to secure funding or highly competitive academic jobs. Studies with limited SDE incorporation also make it harder to perform systematic reviews (O’Connor, 2018). Though the reproducibility crisis has been acknowledged by the NIH (<xref ref-type="bibr" rid="c2">Collins &amp; Tabak, 2014</xref>) and mitigative efforts have been employed, the progress and success of these efforts continue to warrant assessment. In addition to <xref ref-type="bibr" rid="c13">Ramirez et al. (2017)</xref> finding that preclinical cardiovascular research studies had low SDE inclusion, <xref ref-type="bibr" rid="c16">Williams et al. (2022)</xref> determined that preclinical research articles do not adequately adhere to many ARRIVE guidelines, including having sufficient power for t-tests, use of randomization, and blinding. Our results support the findings of both of these previous studies.</p>
</sec>
<sec id="s4b">
<title>Study Design Elements</title>
<p>Although some SDEs can be relevant only to specific domains of a study, (Provencher, 2018), several SDEs can broadly be applied across preclinical research. The use of single-sex in a study compromises generalizability, therefore, the omission of sex as a variable may hinder later applications or the reproducibility of results in translational or clinical settings (<xref ref-type="bibr" rid="c13">Ramirez et al., 2017</xref>). Animal studies show a significant lack of incorporation of both sexes. In addition, there is a significant difference between the reporting of both sexes among rodent and non-rodent studies indicating that the type of animal model may be a factor in reporting (<xref rid="fig7" ref-type="fig">Figure 7</xref>).</p>
<p>Failure to apply randomization can exaggerate results, leading to unreliable findings (<xref ref-type="bibr" rid="c4">Hirst et al., 2014</xref>). This SDE is critical to preventing selection bias and is also the assumption upon which many statistical tests are based. In our study, the proportion of studies reporting the usage of randomization was low for both large and small animals.</p>
<p>The use of blinding in research also advantageously limits selection and procedural bias that could influence experimental results. Articles were screened for any reporting of blinding used whether it was single, double, or triple blinding, however, no significant differences were found.</p>
<p>Sample size estimation enables researchers to identify the necessary number of subjects for conclusions to be drawn and applied to the general population. This consists of predetermining a set number of animals needed for random group assignment. Sample size estimation was the lowest reported SDE among the four SDEs observed - only 8% of animal-only studies provided any justification, statistical or otherwise, for their sample size.</p>
</sec>
<sec id="s4c">
<title>Study Design Element Inclusion Over Time in the Past Decade</title>
<p>Although we hypothesized that the level of SDE inclusion would increase over time, the general prevalence of SDEs, whether they be applied to animal or human substudies, was remarkably low across the 298 articles screened (<xref rid="fig2" ref-type="fig">Figure 2</xref>). This contrasts with <xref ref-type="bibr" rid="c13">Ramirez et al. (2017)</xref>, who found a positive trend in reporting for the journals they observed. It is important to note that their study screened studies published between 2006 and 2016, and we evaluated those published between 2011 and 2021. Another positive trend in temporal SDE inclusion in elements such as randomization and blinding has more recently been reported, however, sample size estimation and inclusion of both sexes remained low (<xref ref-type="bibr" rid="c6">Jung et al., 2021</xref>). In contrast, our findings indicate decreasing SDE inclusion rates for blinding and sample size estimation.</p>
</sec>
<sec id="s4d">
<title>The Influence of Animal and Human Subject Models on Study Design Element Inclusion</title>
<p>We evaluated SDE usage in animal-only studies compared to human/animal studies and SDE usage in animal substudies vs. human substudies within the same overall study. SDE incorporation in animal only and animal with human substudies were comparable though overall SDE reporting was low for both study types. Sample size estimation remained the lowest reported SDE for both study types.</p>
<p>Evaluating differences between SDE usage for animal or human subjects within the same study showed differences in the inclusion of randomization and sample size estimation. For these studies, a larger proportion of studies exhibit greater reporting of randomization and sample size estimation in animal substudies compared to human substudies.</p>
</sec>
<sec id="s4e">
<title>Study Limitations</title>
<p>Although all articles were subjected to randomized double screenings, we cannot be completely confident that an article did not use an SDE. In some instances, certain SDEs cannot be incorporated due to the conditions of the study, however, studies where SDE inclusion was not possible were still considered as lacking the SDE. Also, although the SDEs evaluated in this study are critical to conducting rigorous experimentation, other SDEs discipline-specific may ultimately be more relevant to the reproducibility of a paper.</p>
</sec>
<sec id="s4f">
<title>Future Directions</title>
<p>Future studies should expand the scope of SDEs reviewed in preclinical cardiovascular publications to include more domain-specific SDEs such as the use of comparison groups, units of concern, or other forms of subject allocation (O’Connor, 2018). A more detailed investigation of reasons publications do not include sample size estimation would also be extremely valuable, given the complexity of justification for including or not including the SDE. A further extension of this work would be to survey the authors of these studies to determine the underlying reason for either the omission or inclusion of different SDEs. This would allow both verification of this study’s screening, as well as expand upon the reasons why investigators do or do not use SDEs in their studies.</p>
</sec>
<sec id="s4g">
<title>Conclusion</title>
<p>The inclusion of SDEs improves reproducibility, which is important for translating preclinical findings into clinical outcomes. Contrary to our hypothesis, we found that over the past decade, there has been no significant increase in SDE incorporation in the preclinical cardiovascular publications we studied. Sample size estimation remains the least reported study design element. These trends all indicate the need for further efforts to increase the incorporation of rigorous study design elements in research projects to the point that they become routine. Future research efforts should evaluate a wider range of SDEs and investigate the reasons why SDEs have such low incorporation in preclinical cardiovascular research.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The authors acknowledge support from the Stanford Program on Research Rigor &amp; Reproducibility (SPORR). GCM acknowledges support from Kelsey Grinde, PhD from Macalester College for her guidance on the statistical analysis for this project.</p>
</ack>
<sec id="d1e1052" sec-type="additional-information">
<title>Additional information</title>
<sec id="s5">
<title>Funding</title>
<p>This work was supported by an NIH NHLBI R25 training award “Stanford Undergraduate URM Summer Cardiovascular Research Program” (R25HL147666), an AHA institutional training award “AHA - Stanford Cardiovascular Institute Undergraduate Fellowship Program,” (18UFEL33960207,) and an NIH NHLBI T35 training award “Stanford Cardiovascular Summer Research Training Program for Medical Students” (T35HL160496.)</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bacmeister</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Schwarzl</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Warnke</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Stoffers</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Blankenberg</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Westermann</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Lindner</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Inflammation and fibrosis in murine models of heart failure</article-title>. <source>Basic Research in Cardiology</source>, <volume>114</volume>(<issue>3</issue>). <pub-id pub-id-type="doi">10.1007/s00395-019-0722-5</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>F. S.</given-names></string-name>, &amp; <string-name><surname>Tabak</surname>, <given-names>L. A.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Policy: NIH plans to enhance reproducibility</article-title>. <source>Nature</source>, <volume>505</volume>(<issue>7485</issue>), <fpage>612</fpage>–<lpage>613</lpage>. <pub-id pub-id-type="doi">10.1038/505612a</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gosselin</surname>, <given-names>R.-D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Insufficient transparency of statistical reporting in Preclinical Research: A scoping review</article-title>. <source>Scientific Reports</source>, <volume>11</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41598-021-83006-5</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hirst</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Howick</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Aronson</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Roberts</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Perera</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Koshiaris</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Heneghan</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2014</year>). <article-title>The need for randomization in animal trials: An overview of Systematic Reviews</article-title>. <source>PLoS ONE</source>, <volume>9</volume>(<issue>6</issue>). <pub-id pub-id-type="doi">10.1371/journal.pone.0098856</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Houser</surname>, <given-names>S. R.</given-names></string-name>, <string-name><surname>Margulies</surname>, <given-names>K. B.</given-names></string-name>, <string-name><surname>Murphy</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Spinale</surname>, <given-names>F. G.</given-names></string-name>, <string-name><surname>Francis</surname>, <given-names>G. S.</given-names></string-name>, <string-name><surname>Prabhu</surname>, <given-names>S. D.</given-names></string-name>, <string-name><surname>Rockman</surname>, <given-names>H. A.</given-names></string-name>, <string-name><surname>Kass</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Molkentin</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Sussman</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Koch</surname>, <given-names>W. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Animal models of heart failure</article-title>. <source>Circulation Research</source>, <volume>111</volume>(<issue>1</issue>), <fpage>131</fpage>–<lpage>150</lpage>. <pub-id pub-id-type="doi">10.1161/res.0b013e3182582523</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jung</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>Stotts</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Makwana</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Motazedian</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Di Santo</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Goh</surname>, <given-names>C.-Y.</given-names></string-name>, <string-name><surname>Verreault-Julien</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Simard</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ramirez</surname>, <given-names>F. D.</given-names></string-name>, &amp; <string-name><surname>Hibbert</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Methodological rigor in preclinical cardiovascular research: Contemporary Performance of AHA Scientific Publications</article-title>. <source>Circulation Research</source>, <volume>129</volume>(<issue>9</issue>), <fpage>887</fpage>–<lpage>889</lpage>. <pub-id pub-id-type="doi">10.1161/circresaha.121.319921</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Justice</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Dhillon</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Using the Mouse to model human disease: Increasing validity and reproducibility</article-title>. <source>Disease Models &amp; Mechanisms</source>, <volume>9</volume>(<issue>2</issue>), <fpage>101</fpage>–<lpage>103</lpage>. <pub-id pub-id-type="doi">10.1242/dmm.024547</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lapchak</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>J. H.</given-names></string-name>, &amp; <string-name><surname>Noble-Haeusslein</surname>, <given-names>L. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Rigor guidelines: Escalating stair and steps for effective Translational Research</article-title>. <source>Translational Stroke Research</source>, <volume>4</volume>(<issue>3</issue>), <fpage>279</fpage>–<lpage>285</lpage>. <pub-id pub-id-type="doi">10.1007/s12975-012-0209-2</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mlinarić</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Horvat</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Šupak Smolčić</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Dealing with the positive publication bias: Why you should really publish your negative results</article-title>. <source>Biochemia Medica</source>, <volume>27</volume>(<issue>3</issue>). <pub-id pub-id-type="doi">10.11613/bm.2017.030201</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Connor</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Totton</surname>, <given-names>S. C.</given-names></string-name>, <string-name><surname>Cullen</surname>, <given-names>J. N.</given-names></string-name>, <string-name><surname>Ramezani</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kalivarapu</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Yuan</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Gilbert</surname>, <given-names>S. B.</given-names></string-name></person-group> (<year>2018</year>). <article-title>The study design elements employed by researchers in preclinical animal experiments from two research domains and implications for automation of Systematic Reviews</article-title>. <source>PLOS One</source>, <volume>13</volume>(<issue>6</issue>). <pub-id pub-id-type="doi">10.1371/journal.pone.0199441</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Patel</surname>, <given-names>D. N.</given-names></string-name>, <string-name><surname>Zahiri</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Jimenez</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Montenegro</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Mueller</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Evaluating Study Design Rigor in Preclinical Cardiovascular Research: A Replication Study</article-title>. <source>OSF Preregistration</source> <pub-id pub-id-type="doi">10.17605/OSF.IO/F4NH9</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Provencher</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Archer</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Ramirez</surname>, <given-names>F. D.</given-names></string-name>, <string-name><surname>Hibbert</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Paulin</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Boucherat</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Lacasse</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Bonnet</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Standards and methodological rigor in Pulmonary Arterial Hypertension Preclinical and translational research</article-title>. <source>Circulation Research</source>, <volume>122</volume>(<issue>7</issue>), <fpage>1021</fpage>–<lpage>1032</lpage>. <pub-id pub-id-type="doi">10.1161/circresaha.117.312579</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramirez</surname>, <given-names>F. D.</given-names></string-name>, <string-name><surname>Motazedian</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Jung</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>Di Santo</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>MacDonald</surname>, <given-names>Z. D.</given-names></string-name>, <string-name><surname>Moreland</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Simard</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Clancy</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Russo</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Welch</surname>, <given-names>V. A.</given-names></string-name>, <string-name><surname>Wells</surname>, <given-names>G. A.</given-names></string-name>, &amp; <string-name><surname>Hibbert</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Methodological rigor in preclinical cardiovascular studies</article-title>. <source>Circulation Research</source>, <volume>120</volume>(<issue>12</issue>), <fpage>1916</fpage>–<lpage>1926</lpage>. <pub-id pub-id-type="doi">10.1161/circresaha.117.310628</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramirez</surname>, <given-names>F. D.</given-names></string-name>, <string-name><surname>Jung</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>Motazedian</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Perry-Nguyen</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Di Santo</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>MacDonald</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Clancy</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Labinaz</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Promislow</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Simard</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Provencher</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bonnet</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Graham</surname>, <given-names>I. D.</given-names></string-name>, <string-name><surname>Wells</surname>, <given-names>G. A.</given-names></string-name>, &amp; <string-name><surname>Hibbert</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Journal initiatives to enhance preclinical research: Analyses of Stroke, Nature Medicine, Science Translational Medicine</article-title>. <source>Stroke</source>, <volume>51</volume>(<issue>1</issue>), <fpage>291</fpage>–<lpage>299</lpage>. <pub-id pub-id-type="doi">10.1161/strokeaha.119.026564</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seok</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Warren</surname>, <given-names>H. S.</given-names></string-name>, <string-name><surname>Cuenca</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>Mindrinos</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>H. V.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Richards</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>McDonald-Smith</surname>, <given-names>G. P.</given-names></string-name>, <string-name><surname>Gao</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hennessy</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Finnerty</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>López</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Honari</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Moore</surname>, <given-names>E. E.</given-names></string-name>, <string-name><surname>Minei</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Cuschieri</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bankey</surname>, <given-names>P. E.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Sperry</surname>, <given-names>J.</given-names></string-name>, <etal>…</etal> <string-name><surname>Wong</surname>, <given-names>W. H.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Genomic responses in mouse models poorly mimic human inflammatory diseases</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume>(<issue>9</issue>), <fpage>3507</fpage>–<lpage>3512</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1222878110</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Chu</surname>, <given-names>H.</given-names></string-name> (Cindy), <string-name><surname>Lown</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Daniel</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Meckl</surname>, <given-names>R. D.</given-names></string-name>, <string-name><surname>Patel</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Ibrahim</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Weaknesses in experimental design and reporting decrease the likelihood of reproducibility and generalization of recent cardiovascular research</article-title>. <source>Cureus</source>. <pub-id pub-id-type="doi">10.7759/cureus.21086</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="data"><person-group person-group-type="author"><string-name><surname>Zahiri</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Jimenez</surname>, <given-names>I. C.</given-names></string-name>, <string-name><surname>Montenegro</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Patel</surname>, <given-names>D. N.</given-names></string-name> &amp; <string-name><surname>Mueller</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Methodological Rigor in Cardiovascular Publications</article-title>. <source>OSF</source> <pub-id pub-id-type="doi">10.17605/OSF.IO/52Q6W</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91498.2.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Daehn</surname>
<given-names>Ilse S</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Icahn School of Medicine at Mount Sinai</institution>
</institution-wrap>
<city>New York</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>The objective of this <bold>important</bold> study is to assess the study design and rigor, enhance the quality of clinical research studies, and emphasize crucial design elements in basic science research. It specifically tackles the ongoing problem of experimental design deficiencies that obstruct the effective translation of research findings into clinical applications. This paper is particularly <bold>convincing</bold> as it highlights the lack of progress in addressing these issues over the past decade, despite a substantial body of existing research. It serves as a strong call to action for the broader scientific community to improve research practices.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91498.2.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Rigor in the design and application of scientific experiments is an ongoing concern in preclinical (animal) research. Because findings from these studies are often used in the design of clinical (human) studies, it is critical that the results of the preclinical studies are valid and replicable. However, several recent peer-reviewed published papers have shown that some of the research results in cardiovascular research literature may not be valid because their use of key design elements is unacceptably low. The current study is designed to expand on and replicate previous preclinical studies in nine leading scientific research journals. Cardiovascular research articles that were used for examination were obtained from a PubMed Search. These articles were carefully examined for four elements that are important in the design of animal experiments: use of both biological sexes, randomization of subjects for experimental groups, blinding of the experimenters, and estimating the proper size of samples for the experimental groups. The findings of the current study indicate that the use of these four design elements in the reported research in preclinical research is unacceptably low. Therefore, the results replicate previous studies and demonstrate once again that there is an ongoing problem in the experimental design of preclinical cardiovascular research.</p>
<p>Strengths:</p>
<p>This study selected four important design elements for study. The descriptions in the text and figures of this paper clearly demonstrate that the rate of use of all four design elements in the examined research articles was unacceptably low. The current study is important because it replicates previous studies and continues to call attention once again to serious problems in the design of preclinical studies, and the problem does not seem to lessen over time.</p>
<p>Weaknesses:</p>
<p>Weaknesses from the first review were adequately addressed.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91498.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Jimenez</surname>
<given-names>Isaiah C</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Montenegro</surname>
<given-names>Gabrielle C</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zahiri</surname>
<given-names>Keyana</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7931-9115</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Patel</surname>
<given-names>Damini</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mueller</surname>
<given-names>Adrienne</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9161-5323</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>Rigor in the design and application of scientific experiments is an ongoing concern in preclinical (animal) research. Because findings from these studies are often used in the design of clinical (human) studies, it is critical that the results of the preclinical studies are valid and replicable. However, several recent peer-reviewed published papers have shown that some of the research results in cardiovascular research literature may not be valid because their use of key design elements is unacceptably low. The current study is designed to expand on and replicate previous preclinical studies in nine leading scientific research journals. Cardiovascular research articles that were used for examination were obtained from a PubMed Search. These articles were carefully examined for four elements that are important in the design of animal experiments: use of both biological sexes, randomization of subjects for experimental groups, blinding of the experimenters, and estimating the proper size of samples for the experimental groups. The findings of the current study indicate that the use of these four design elements in the reported research in preclinical research is unacceptably low. Therefore, the results replicate previous studies and demonstrate once again that there is an ongoing problem in the experimental design of preclinical cardiovascular research.</p>
<p>Strengths:</p>
<p>This study selected four important design elements for study. The descriptions in the text and figures of this paper clearly demonstrate that the rate of use of all four design elements in the examined research articles was unacceptably low. The current study is important because it replicates previous studies and continues to call attention once again to serious problems in the design of preclinical studies, and the problem does not seem to lessen over time.</p>
<p>Weaknesses:</p>
<p>The current study uses both descriptive and inferential statistics extensively in describing the results. The descriptive statistics are clear and strong, demonstrating the main point of the study, that the use of these design elements is quite low, which may invalidate many of the reported studies. In addition, inferential statistical tests were used to compare the use of the four design elements against each other and to compare some of the journals. The use of inferential statistical tests appears weak because the wrong tests may have been used in some cases. However, the overall descriptive findings are very strong and make the major points of the study.</p>
</disp-quote>
<p>We sincerely appreciate the reviewer’s comments and detailed feedback and their recognition of the importance of this work in replicating previous studies and calling attention to the problems in preclinical study design. In response to the reviewer’s suggestions, we have recalculated our inferential statistics. In place of our previous inferential statistics, we have used an alternative correction calculation for p-values (Holm-Bonferroni corrections) and used median-based linear model analyses and nonparametric Kruskal-Wallis tests that are more appropriate for analyzing this dataset. Our overall trends in results remain the same.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary</p>
<p>This study replicates a 2017 study in which the authors reviewed papers for four key elements of rigor: inclusion of sex as a biological variable, randomization of subjects, blinding outcomes, and pre-specified sample size estimation. Here they screened 298 published papers for the four elements. Over a 10 year period, rigor (defined as including any of the 4 elements) failed to improve. They could not detect any differences across the journals they surveyed, nor across models. They focused primarily on cardiovascular disease, which both helps focus the research but limits the potential generalizability to a broader range of scientific investigation. There is no reason, however, to believe rigor is any better or worse in other fields, and hence this study is a good 'snapshot' of the progress of improving rigor over time.</p>
<p>Strengths</p>
<p>The authors randomly selected papers from leading journals, e.g., PNAS). Each paper was reviewed by 2 investigators. They pulled papers over a 10-year period, 2011 to 2021, and have a good sample of time over which to look for changes. The analysis followed generally accepted guidelines for a structured review.</p>
<p>Weaknesses</p>
<p>The authors did not use the exact same journals as they did in the 2017 study. This makes comparing the results complicated. Also, they pulled papers from 2011 to 2021, and hence cannot assess the impact of their own prior paper.</p>
<p>The authors write &quot;the proportion of studies including animals of both biological sexes generally increased between 2011 and 2021, though not significantly (R2= 0.0762, F(1,9)= 0.742, p= 0.411 (corrected p=8.2&quot;. This statement is not rigorous because the regression result is not statistically significant. Their data supports neither a claim of an increase nor a decrease over time. A similar problem repeats several times in the remainder of their results presentation.</p>
<p>I think the Introduction and the Discussion are somewhat repetitive and the wording could be reduced.</p>
<p>Impact and Context</p>
<p>Lack of reproducibility remains an enormous problem in science, plaguing both basic and translational investigations. With the increased scrutiny on rigor, and requirements at NIH and other funding agencies for more rigor and transparency, one would expect to find increasing rigor, as evidenced by authors including more study design elements (SDEs) that are recommended. This review found no such change, and this is quite disheartening. The data implies that journals-editors and reviewers-will have to increase their scrutiny and standards applied to preclinical and basic studies. This work could also serve as a call to action to investigators outside of cardiovascular science to reflect on their own experiences and when planning future projects.</p>
</disp-quote>
<p>We sincerely appreciate the reviewer’s insights and comments and recognition of our work contributing to the growing body of evidence on the lack of rigor in preclinical cardiovascular research study design. Regarding the weaknesses the reviewer noted; the referenced 2017 publication details a study by Ramirez et al, and was not conducted by our group. Our study aimed to expand upon their findings by using a more recent timeframe and an alternative list of highly respected cardiovascular research journals. We have now better clarified this distinction in the manuscript. We have also addressed our phrasing regarding the lack of statistical significance in the increase of the proportion of studies including animals of both sexes from 2011-2021.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>Many of the methods in this study were strong or adequate. Although the descriptive statistics appear solid, there are significant problems that need to be addressed in the selection and use of inferential statistics.</p>
<p>(1) One of the design elements that was studied was sample size estimation. This is usually done by a power analysis. The authors should consider what group size for the examined journals is adequate for their statistics to be valid. Or they could report the power of their studies to achieve a given meaningful difference.</p>
</disp-quote>
<p>We thank the reviewer for this excellent observation. We unfortunately failed to conduct an <italic>a priori</italic> power analysis. Previous research (Gupta, et al. 2016) suggests that <italic>post-hoc</italic> power calculations should not be carried out after the study has been conducted. We acknowledge the importance of establishing a sufficient sample size to draw sound conclusions based on an adequate effect size, and we regret that we did not carry out the appropriate estimations. We are very appreciative of the reviewer’s suggestions and aim to implement such an appropriate study design element in future studies.</p>
<p>Gupta KK, Attri JP, Singh A, Kaur H, Kaur G. Basic concepts for sample size calculation: Critical step for any clinical trials!. Saudi J Anaesth. 2016;10(3):328-331. doi:10.4103/1658-354X.174918</p>
<disp-quote content-type="editor-comment">
<p>(2) A Bonferroni correction was used extensively. Because of its use, the corrected p values often appear much too high. The Bonferroni test becomes much too conservative for more than 3 or 4 tests. I suggest using a different test for multiple comparisons.</p>
</disp-quote>
<p>We thank the reviewer for their insightful suggestion. We have updated all p-values to reflect a Holm-Bonferroni correction instead. All p-values have been corrected and updated.</p>
<disp-quote content-type="editor-comment">
<p>(3) The use of the chi-square test for categorical data is appropriate. However, the t-test and multiple regression tests are designed for continuous variables. Here, it appears that they were used for the nominal variables (Table 1). For these nominal data, other nonparametric tests should be used.</p>
</disp-quote>
<p>We thank the reviewer for this valuable insight. We have updated our statistical analysis methods and now use nonparametric Kruskal-Wallis tests to analyze differences in SDE reporting across journals, instead of chi-square test. Our reported p-values have been adjusted accordingly.</p>
<disp-quote content-type="editor-comment">
<p>(4) It is not clear exactly when each test is used. The stats section in Methods should better delineate when each test is used. In addition, it would be helpful to include the test used in the figure legends.</p>
</disp-quote>
<p>We thank the reviewer for bringing up this important point. We have now updated the methods section to better delineate which tests were used, and also included the specific tests in the figure legends.</p>
<disp-quote content-type="editor-comment">
<p>(5) You will need to rewrite some sections of the text to reflect the changes due to changing your use of statistics.</p>
</disp-quote>
<p>We have rewritten the sections of the text to reflect the changes in our use of statistics.</p>
<disp-quote content-type="editor-comment">
<p>Here are a few comments on the presentation.</p>
<p>(1) Some of the figure legends are almost impossible to read. They are too congested.</p>
</disp-quote>
<p>We thank the reviewer for pointing this out. We have edited the figure legends to make them more readable. We will also attach a pdf with the graphs to allow for easier formatting.</p>
<disp-quote content-type="editor-comment">
<p>(2) Also, is it possible to drop some of the panels in Figure 1?</p>
</disp-quote>
<p>The panels in figure 1 have been rearranged to make them more readable. We believe that each panel provides valuable visual summaries of our data, that will aid readers in understanding our results.</p>
<disp-quote content-type="editor-comment">
<p>(3) It is not mandatory that values of y-axis on the graphs go up 100% (Figs 2 and 3). Using a maximum value of 100% clumps the lines visually. I suggest a max value on the y-axis of the graph of 50% or 60%. That will spread the lines better visually so differences can better be seen.</p>
</disp-quote>
<p>We thank the reviewer for considering the experience of our paper’s readers. The y-axes of Figures 2 and 3 have been truncated to 50%. The trend lines in each Figure now appear more separated and differences can better be seen.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>The authors did not use the exact same journals as they did in the 2017 study. This makes comparing the results complicated. Also, they pulled papers from 2011 to 2021, and hence cannot assess the impact of their own prior paper.</p>
</disp-quote>
<p>We appreciate the reviewer’s concern in maintaining consistency with the paper published by Ramirez, et al. in 2017. To clarify, our efforts focused on providing a replication study that expanded upon the original Ramirez publication - which we have no affiliation with. For our study, we used different academic journals than those used by Ramirez, et al, and also a different time-frame. We have updated the language in the manuscript to better-clarify the purpose and parameters of our study relative to the previous, unaffiliated, study.</p>
<disp-quote content-type="editor-comment">
<p>The authors write &quot;the proportion of studies including animals of both biological sexes generally increased between 2011 and 2021, though not significantly (R2= 0.0762, F(1,9)= 0.742, p= 0.411 (corrected p=8.2&quot;. This statement is not rigorous because the regression result is not statistically significant. Their data supports neither a claim of an increase nor a decrease over time. A similar problem repeats several times in the remainder of their results presentation.</p>
</disp-quote>
<p>Thank you for bringing this information to our attention. We agree with the concern regarding the statement, “the proportion of studies including animals of both biological sexes generally increased between 2011 and 2021, though not significantly (R2= 0.0762, F(1,9)= 0.742, p= 0.411 (corrected p=8.2.” We have rephrased the statement. Our updated Holm-Bonferroni corrected p-value is now noted in this more appropriately worded description of our results. Lastly, we have addressed the wording and redundancy seen in both the introduction and discussion and have made both more concise.</p>
<disp-quote content-type="editor-comment">
<p>I think the Introduction and the Discussion are somewhat repetitive and the wording could be reduced.</p>
</disp-quote>
<p>We thank the reviewer for bringing this to our attention. We have addressed the redundancy across the Introduction and the Discussion. We have also altered the wording to reflect a more concise explanation of our study.</p>
<disp-quote content-type="editor-comment">
<p>The 'trends' are not statistically significant. A non-significant trend does not exist and no claim of a 'trend' is justified by the data.</p>
</disp-quote>
<p>We thank the reviewer for this observation. We have updated the phrasing of ‘trends’ in all areas of the manuscript.</p>
</body>
</sub-article>
</article>