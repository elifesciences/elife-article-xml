<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106609</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106609</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106609.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Working memory shapes neural geometry in human EEG over learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3254-8519</contrib-id>
<name>
<surname>Wójcik</surname>
<given-names>Michał J</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>michal.wojcik@dpag.ox.ac.uk</email>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Li</surname>
<given-names>Amy</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Wasmuht</surname>
<given-names>Dante</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4263-5755</contrib-id>
<name>
<surname>Stroud</surname>
<given-names>Jake P</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Stokes</surname>
<given-names>Mark G</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5599-3044</contrib-id>
<name>
<surname>Myers</surname>
<given-names>Nicholas E</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="author-notes" rid="n2">#</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8393-8533</contrib-id>
<name>
<surname>Hunt</surname>
<given-names>Laurence T</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="author-notes" rid="n2">#</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Experimental Psychology, University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Physiology, Anatomy and Genetics, University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>Department of Engineering, University of Cambridge</institution></institution-wrap>, <city>Cambridge</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01ee9ar58</institution-id><institution>School of Psychology, University of Nottingham</institution></institution-wrap>, <city>Nottingham</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Department of Psychiatry, University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Cools</surname>
<given-names>Roshan</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country country="NL">Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>*</label><p>Shared authorship</p></fn>
<fn id="n2" fn-type="equal"><label>#</label><p>Shared senior authorship</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-07-28">
<day>28</day>
<month>07</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106609</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-04-22">
<day>22</day>
<month>04</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-21">
<day>21</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.01.21.634110"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Wójcik et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Wójcik et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106609-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Working memory has been traditionally studied as a passive storage for information. However, recent advances have suggested that working memory is prospective rather than retrospective, meaning that its content undergoes transformations that will support future behaviour. One perspective that underscores this notion conceptualises memory processes as a computational resource that can be used to reduce the complexity of computation at decision time. Here, we explore this perspective by examining whether the process of maintenance shapes neural geometry and leads to low-dimensional representations during storage and later decision time. We recorded EEG in 25 human participants who learnt to solve a XOR task. We hypothesised that separating task features by a working memory delay would result in participants temporally decomposing the XOR computation, by prospectively processing one of the task features early in trial time. In line with our predictions, participants transformed the first feature from a sensory to an abstract format and maintained this pre-processed information throughout the delay. This process was related to the low-dimensional representation required at decision time early in learning, a representation that has recently been shown to support later cross-generalisation. These results demonstrate that low-dimensional representations, elsewhere associated with slow learning, might also provide a mechanism for maintenance processes in working memory.</p>
</abstract>
<funding-group>
<award-group id="fund1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/001aqnf71</institution-id>
<institution>UKRI</institution>
</institution-wrap>
</funding-source>
<award-id>BB/W003392/1</award-id>
<principal-award-recipient>
<name>
<surname>Hunt</surname>
<given-names>Laurence T</given-names>
</name>
<name>
<surname>Stokes</surname>
<given-names>Mark G</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="fund2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00cwqg982</institution-id>
<institution>UKRI</institution>
</institution-wrap>
</funding-source>
<award-id>BB/M010732/1</award-id>
<principal-award-recipient>
<name>
<surname>Stokes</surname>
<given-names>Mark G</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="fund3">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id>
<institution>University of Oxford</institution>
</institution-wrap>
</funding-source>
<award-id>Clarendon Fund</award-id>
<principal-award-recipient>
<name>
<surname>Wójcik</surname>
<given-names>Michał J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="fund4">
<funding-source>
<institution-wrap>
<institution>Fundacja Wyręba</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Wójcik</surname>
<given-names>Michał J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="fund5">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id>
<institution>University of Oxford</institution>
</institution-wrap>
</funding-source>
<award-id>Saven European Scholarship</award-id>
<principal-award-recipient>
<name>
<surname>Wójcik</surname>
<given-names>Michał J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="fund6">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03wnrjx87</institution-id>
<institution>Royal Society</institution>
</institution-wrap>
</funding-source>
<award-id>Sir Henry Dale Fellowship</award-id>
<principal-award-recipient>
<name>
<surname>Hunt</surname>
<given-names>Laurence T</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="fund7">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/029chgv08</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id award-id-type="doi">10.35802/208789</award-id>
<principal-award-recipient>
<name>
<surname>Hunt</surname>
<given-names>Laurence T</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Working memory, the capacity to briefly retain and manipulate information, is a foundational element of adaptive and flexible behaviour. A dominant view has emphasised the role of working memory in storing past sensory input (<xref ref-type="bibr" rid="c14">Goldman-Rakic, 1995</xref>). Yet there is also a clear role for working memory being used in anticipation of future task demands, supported by both empirical (<xref ref-type="bibr" rid="c23">Quintana &amp; Fuster, 1992</xref>; <xref ref-type="bibr" rid="c24">Rainer et al., 1999</xref>; <xref ref-type="bibr" rid="c29">Sakai &amp; Miyashita, 1991</xref>; <xref ref-type="bibr" rid="c31">Spaak et al., 2017</xref>; <xref ref-type="bibr" rid="c32">Stokes, 2015</xref>; <xref ref-type="bibr" rid="c33">Stokes et al., 2013</xref>; <xref ref-type="bibr" rid="c41">Wolff et al., 2017</xref>) and theoretical studies (<xref ref-type="bibr" rid="c35">Stroud et al., 2023</xref>, <xref ref-type="bibr" rid="c34">2024</xref>). In particular, electrophysiological research in humans and primates has revealed that information in working memory undergoes transformations, yielding abstract representations that guide future behaviour, rather than merely mimicking sensory codes (<xref ref-type="bibr" rid="c22">Meyers et al., 2008</xref>; <xref ref-type="bibr" rid="c31">Spaak et al., 2017</xref>; <xref ref-type="bibr" rid="c32">Stokes, 2015</xref>; <xref ref-type="bibr" rid="c33">Stokes et al., 2013</xref>). The shift from sensory to abstract coding is now recognised as an inherent computational characteristic of working memory, possibly reflecting optimal loading of information into a working memory store (<xref ref-type="bibr" rid="c35">Stroud et al., 2023</xref>).</p>
<p>Insights from machine learning and computational neuroscience further highlight the idea that memory processes can be viewed as a resource for computations rather than a passive mechanism for storage (<xref ref-type="bibr" rid="c9">Dasgupta &amp; Gershman, 2021</xref>; <xref ref-type="bibr" rid="c11">Ehrlich &amp; Murray, 2022</xref>). In this light, working memory adapts computations to the current task demands (<xref ref-type="bibr" rid="c9">Dasgupta &amp; Gershman, 2021</xref>); pre-computed information can be stored in working memory, and thus reduce the computation time at the moment of the decision (<xref ref-type="bibr" rid="c5">Braver, 2012</xref>; <xref ref-type="bibr" rid="c16">Hunt et al., 2021</xref>). This perspective is further supported by computational modelling of neural circuits that contends that working memory will change neural geometry in a way that supports the temporal decomposition of computations (<xref ref-type="bibr" rid="c11">Ehrlich &amp; Murray, 2022</xref>). This work suggests that the computational load at the moment of action can be thus alleviated by decomposing complex operations into several simple problems solved sequentially in time.</p>
<p>One of the mechanisms of reducing neural dimensionality and thus the complexity of neural computations is filtering out irrelevant information through working memory selection (<xref ref-type="bibr" rid="c17">Jacob &amp; Nieder, 2014</xref>). Extensive empirical and theoretical investigations demonstrate that low-dimensional representations are characterised by enhanced efficiency on various metrics (<xref ref-type="bibr" rid="c2">Barak et al., 2013</xref>; <xref ref-type="bibr" rid="c3">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c7">Cromer et al., 2010</xref>; <xref ref-type="bibr" rid="c8">Cueva et al., 2020</xref>; <xref ref-type="bibr" rid="c12">Flesch et al., 2022</xref>). For example, these representations can reduce the impact of noise on ongoing decision processes and provide robust and stable readouts (<xref ref-type="bibr" rid="c13">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="c39">Wójcik et al., 2023</xref>). The compressed format permits easy generalisation and thus increases adaptability (<xref ref-type="bibr" rid="c6">Chien et al., 2023</xref>; <xref ref-type="bibr" rid="c25">Reinert et al., 2021</xref>; <xref ref-type="bibr" rid="c39">Wójcik et al., 2023</xref>).</p>
<p>Using non-human primates, we recently demonstrated that low-dimensional representations are acquired over learning spanning multiple days (<xref ref-type="bibr" rid="c39">Wójcik et al., 2023</xref>). We found that metabolically constrained optimisation provides a parsimonious description of this process (Stroud et al., n.d.). Yet these observations were made under conditions where all necessary inputs were still available from the environment at the moment of the decision, rather than being sequentially presented to the participant and requiring retention and/or prospective manipulation over a delay. In an alternative setting, involving delay periods, low-dimensional representations could be constructed via working memory selection and prospective re-coding of features that enter working memory.</p>
<p>Here, we explored whether engaging working memory leads to the construction of low-dimensional neural representations. To test these predictions, we asked human participants to learn an exclusive-or (XOR) mapping – a problem that can be solved by a range of representations, from low- to high-dimensional (<xref ref-type="bibr" rid="c11">Ehrlich &amp; Murray, 2022</xref>). Crucially, we presented the elements of the XOR mapping separately, with a temporal delay, to test what information was stored and transformed in working memory. By recording the EEG signal from naïve to expert performance on the task, we also tracked how the dimensionality and geometry of neural representations changed with learning. Based on theoretical work that suggests that working memory can be used to temporally decompose computations (<xref ref-type="bibr" rid="c9">Dasgupta &amp; Gershman, 2021</xref>; Ehrlich &amp; Murray, n.d.), we hypothesised that separating task features with a memory delay would result in the preparation of an abstract, low-dimensional context signal (representing the first task feature) before all necessary information for solving the task was presented. This decomposition should lead to a low-dimensional representation at the moment of the decision and be accompanied by tell-tale reaction time and performance biases (i.e., context switch costs). Specifically, we hypothesised that the task feature presented first would be used to contextualise the processing of subsequent features, and that trial-to-trial changes to this context would impact behavioural performance more than changes to subsequently presented features (<xref ref-type="bibr" rid="c21">Mayr &amp; Kliegl, 2003</xref>; <xref ref-type="bibr" rid="c38">Vandierendonck et al., 2010</xref>).</p>
<p>Consistent with these predictions, participants rapidly learned to construct a contextual signal from sensory information provided by the first feature and maintained it throughout the delay period. Irrelevant dimensions of the contextual cue were suppressed early in the learning process. Notably, participants who exhibited stronger abstract coding of the first feature early in learning generated lower-dimensional representations at decision time. These low-dimensional representations closely resembled the low-dimensional representations observed in non-human primates after extensive training spanning several weeks (<xref ref-type="bibr" rid="c39">Wójcik et al., 2023</xref>). Interestingly, neural dimensionality did not decrease as a function of learning but remained low throughout, with reductions observed during trials associated with XOR coding failures. These findings suggest that neural dimensionality was not adapted as a learning strategy to achieve low-dimensional representations at decision time. Overall, this study highlights that low-dimensional representations, critical for complex decision-making, can be rapidly constructed via working memory selection processes.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>Participants learned a cued stimulus-response mapping task with delay between context cue and stimulus-response mapping (<xref rid="fig1" ref-type="fig">Fig. 1a, b</xref>). First, a coloured circle was presented (colour). After a delay (fixation point), a shape was displayed, and participants were instructed to choose one of two response buttons (left or right). A nonlinear combination of the colour and shape predicted whether the left or the right response button was correct (the XOR rule). Importantly, to test whether irrelevant dimensions were discarded via working memory selection, the task consisted of two instances of the XOR rule (<xref rid="fig1" ref-type="fig">Fig. 1c-d</xref>). For example, in colour pair 1 (blue and green) the combination “blue-square” and combination “green-diamond” predicted the left response button to be correct. “Green-square” and “blue-diamond” predicted the right response button to be the correct one. In colour pair 2, the colours pink and khaki shared the same shape-response mapping as the colours blue and green in colour pair 1, respectively (e.g., “pink-square” and “khaki-diamond” were mapped onto the left response button). This allowed us to distinguish context coding (relevant dimension) from colour coding (irrelevant dimension) in the neural analyses.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental design and behavioural results.</title>
<p><bold>a</bold>, Timeline of task events in a single trial. <bold>b</bold>, Participants learnt by trial-and-error to combine two task features (colour and shape) in a non-linear fashion (XOR) and respond either by pressing the left or the right response button. For example, blue+square and green+diamond combined with left button press (XOR == False (0)) were followed by positive feedback; blue+diamond and green+square combined with right button press (XOR == True (1)) were also followed by positive feedback. Any other combination was followed by negative feedback. <bold>b</bold>, The task consisted of three features: colour (<italic>n</italic> = 4), shape (<italic>n</italic> = 2) and XOR conditions (<italic>n</italic> = 2; aligned fully with left and right button responses). <bold>c</bold>, Participants could generalise the meaning of colour 1 (e.g. blue) to colour 3 (e.g. pink), and vice versa, as both shared the same shape-response mapping. This could result in colours being grouped by the contextual information they provided for the shape-response mapping. <bold>d</bold>, The cue stimulus (first feature) had two dimensions: the task-irrelevant colour dimension and the task-relevant context dimension. <bold>e</bold>, In context switch trials the context of the current trial (trial 3) changed compared to the previous trial (trial 2) whereas in context stay trials the context of the current trial (trial 2) remained the same compared to the previous trial (trial 1). <bold>f</bold>, In shape switch trials the shape of the current trial (trial 3) changed compared to the previous trial (trial 2) whereas in shape stay trials the shape of the current trial (trial 2) remained the same compared to the previous trial (trial 1). <bold>g</bold>, In colour switch trials the colour of the current trial (trial 2) changed compared to the previous trial (trial 1) whereas in colour stay trials the colour of the current trial (trial 3) remained the same compared to the previous trial (trial 2). <bold>h</bold>, Mean performance accuracy plotted as a function of learning stages; shaded area indicates 95% CIs obtained through random resampling with replacement (<italic>n</italic> = 1000); accuracy in stage 1 was compared to accuracy in stage 4. <bold>i</bold>, Accuracy is lower on context switch trials (the context of the current trial changed compared to the previous trial) than context stay trials (the context of the current trial remained the same compared to the previous trial); horizontal lines are individual participants. <bold>j</bold>, Accuracy is also lower on context switch trials than shape switch trials (the shape of the current trial changed compared to the previous trial). Plotting conventions analogous to e. <bold>k</bold>, Comparison of context switch trials with colour switch trials (the colour of the current trial changed compared to the previous trial; as the context remained the same this measure captures changes caused by sensory differences only). <bold>l-o</bold>, Analogous to panels d-g but plotted for reaction time medians (before transformations). All p-values were calculated using t-tests for dependent samples (***, p &lt; 0.01; **, p &lt;0.01; *, p &lt; 0.05; †, p &lt; 0.1; n.s., not significant); reaction times were transformed using the log transformation prior to running parametric tests.</p></caption>
<graphic xlink:href="634110v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Participants needed to infer the correct responses through trial and error. As the task consisted of eight different stimuli-response combinations which formulated two instances of the same XOR rule, participants could have used two different strategies: (1) memorise all combinations (a high-dimensional strategy) or (2) capitalise on the colour feature being presented first and generate a low-dimensional representation at decision time, i.e., transform the colour information into an abstract context signal (context-sensitive strategy, <xref rid="fig1" ref-type="fig">Fig. 1c</xref>) before the shape onset to reduce the computational complexity at the moment of the decision. These strategies can be distinguished by their impact on trial-to-trial variability in reaction times and performance (<xref ref-type="bibr" rid="c21">Mayr &amp; Kliegl, 2003</xref>; <xref ref-type="bibr" rid="c38">Vandierendonck et al., 2010</xref>). More precisely, if a strategy based on context information was used, the first feature would be considered more important and trial-to-trial changes in context (<xref rid="fig1" ref-type="fig">Fig. 1e</xref>) would have a stronger negative impact on behaviour (switch cost) than trial-to-trial changes in the second presented feature (shape; <xref rid="fig1" ref-type="fig">Fig. 1f</xref>). Conversely, with a memory-based strategy, both context and shape are equally important, leading to comparable switch costs for both context and shape switches. Our design further allowed us to distinguish costs associated with a context switch from costs arising from a mere change in the colour of the cue (<xref rid="fig1" ref-type="fig">Fig. 1g</xref>).</p>
<sec id="s2a">
<title>Human behaviour exhibiting evidence of employing a context-sensitive strategy</title>
<p>Participants learned to solve the task rapidly with a performance above chance level (50%) in the first learning stage (i.e., first 25% of trials), <italic>M</italic> = .75, <italic>t</italic>(24) = 9.16, <italic>p</italic> &lt; .001 (<xref rid="fig1" ref-type="fig">Fig. 1h</xref>). Task accuracy also significantly increased with learning from stage 1 (<italic>M</italic> = .75) to stage 4 (<italic>M</italic> = .96), where participants exhibited ceiling-level performance, <italic>t</italic>(24) = 7.22, <italic>p</italic> &lt; .001, <italic>d</italic> = 1.51. The learning-induced increase in performance was not accompanied by a significant decrease in reaction times, <italic>M</italic> = 554 <italic>ms vs M</italic> = 485 <italic>ms</italic>, <italic>t</italic>(24) = 1.15, <italic>p</italic> = 0.13, <italic>d</italic> = 0.19 (<xref rid="fig1" ref-type="fig">Fig. 1l</xref>).</p>
<p>We explored whether participants utilised a context-sensitive representation to solve the task by comparing context switch costs to shape switch costs. Performance in context switch trials (<italic>M</italic> = 89.2% ; where context in the current trial changed in comparison to context in the previous trial) was lower compared to context stay trials (<italic>M</italic> = 91.3%; where the same context was presented in the current and previous trial), <italic>t</italic>(24) = −3.85, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.3 (<xref rid="fig1" ref-type="fig">Fig. 1i</xref>). Context switches led to lower accuracy than shape switches, <italic>M</italic> = 89.2% <italic>vs M</italic> = 90.1%, <italic>t</italic>(24) = −2.96, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.13 (<xref rid="fig1" ref-type="fig">Fig. 1j</xref>). We found no differences in performance when context-switch trials and colour-switch trials were compared (when the previous colour was different from the current colour, but the context stayed the same) <italic>M</italic> = 89.2% <italic>vs M</italic> = 89.8%, <italic>t</italic>(24) = −1.18, <italic>p</italic> = 0.13, <italic>d</italic> = 0.08 (<xref rid="fig1" ref-type="fig">Fig. 1k</xref>), indicating that context switch performance costs may in part arise from cue switches.</p>
<p>Reaction time switch costs mirrored the pattern of results found in performance switch costs. Context switch trials were characterised by slower median reaction times compared to context stay trials, <italic>M</italic> = 478 <italic>ms vs M</italic> = 464 <italic>ms</italic>, <italic>t</italic>(24) = 4.34, <italic>p</italic> &lt; .002, <italic>d</italic> = 0.22 (<xref rid="fig1" ref-type="fig">Fig. 1m</xref>) and shape switch trials, <italic>M</italic> = 479 <italic>ms vs M</italic> = 475 <italic>ms</italic>, <italic>t</italic>(24) = 4.42, <italic>p</italic> = 0.0, <italic>d</italic> = 0.15 (<xref rid="fig1" ref-type="fig">Fig. 1n</xref>). Interestingly, we also found that participants exhibited slightly slower reaction times in context switch trials as compared to colour switch trials, <italic>M</italic> = 480 <italic>ms vs M</italic> = 481 <italic>ms</italic>, <italic>t</italic>(24) = 2.07, <italic>p</italic> = 0.02, <italic>d</italic> = 0.07 (<xref rid="fig1" ref-type="fig">Fig. 1o</xref>).</p>
<p>These results indicate that participants used a highly structured representation of the task, in which the context was used to facilitate the subsequent processing of the shape feature. This led to worse and slower adaptation on trials where a switch in this higher-order feature took place. Next, we explored whether these behavioural effects translated into the hypothesised changes in neural codes.</p>
</sec>
<sec id="s2b">
<title>Humans learn to maintain the context information and construct the XOR feature over learning</title>
<p>To solve the task, participants were required to construct an XOR dimension by mixing nonlinearly the context and shape features. The initial cue stimulus, consisting of a coloured circle, could be classified along two dimensions: the irrelevant <italic>colour</italic> dimension, and the relevant <italic>context</italic> dimension (<xref rid="fig1" ref-type="fig">Fig. 1d</xref>). The former is retrospective in that it represents sensory differences between colours (blue vs pink or green vs khaki; <xref rid="fig1" ref-type="fig">Fig. 1c</xref>), whereas the latter is prospective: it dictates the context within which the next feature (shape) should be processed (‘square-left/diamond-right or square-right/diamond-left’; <xref rid="fig1" ref-type="fig">Fig. 1c</xref>). As the stimulus is displayed only for 500ms at the beginning of the trial, participants needed to maintain a representation in at least one of these formats in working memory until the shape was displayed. We hypothesised that across learning, participants would exhibit an increase in context coding but not colour coding in the delay period and that this would lead to an increase in XOR coding in the shape-locked period.</p>
<p>We first employed linear discriminant analysis (LDA) decoding on each time-point of the EEG signal separately, on trials pooled across learning stages. Context information decoding peaked early, in the colour-locked period, was maintained throughout the delay to then increase slightly after shape presentation, <italic>cluster</italic> 1: 0.082 − 1.188<italic>s</italic>, <italic>p</italic> = 0.001 and <italic>cluster</italic> 2: 1.208 − 3.2<italic>s</italic>, <italic>p</italic> = 0.001 (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>). Next, the EEG signal was averaged in the colour-locked, delay-locked and shape-locked periods to explore learning-induced changes in decoding scores (see <italic>Methods, decoding</italic> for more details). We found that context coding in stage 4 increased as compared to stage 1 in the delay-locked period: <italic>M</italic> = 0.519 <italic>vs M</italic> = 0.507, <italic>t</italic>(24) = −1.8, <italic>p</italic> = 0.04, <italic>d</italic> = 0.35 (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Participants maintain a context signal and construct an XOR representation over learning.</title>
<p><bold>a</bold>, Time-resolved decoding of context; horizontal bars indicate statistical significance; the pale orange area indicates the time windows for which subsequent time-averaged decoding analyses were run (e.g., panel b). Vertical three dashed lines show the onset of the colour, delay, and shape, respectively; <bold>b</bold>, The learning dynamics of the context decoding computed from the time-averaged signal in the delay-locked period. <bold>c-d</bold>, Analogues to a-b but for within-context colour decoding (captures only the physical properties of the colour). <bold>i,j</bold>, <bold>k,l</bold>, and <bold>m,l</bold> Analogues to a-b but for shape, XOR and motor decoding, respectively. The shaded area indicated 95% CIs obtained through random resampling with replacement (<italic>n</italic> = 1000); All p-values for stage 1 vs stage 4 comparisons were calculated using t-tests for dependent samples (***, p &lt; 0.01; **, p &lt;0.01; *, p &lt; 0.05; †, p &lt; 0.1; n.s., not significant).</p></caption>
<graphic xlink:href="634110v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We hypothesised that working memory processes control the dimensionality of neural representations by selecting features for maintenance. We tested this prediction by exploring the learning dynamics of the colour representation. Importantly, to obtain an isolated measure of colour coding (unrelated to context) we focused on decoding colour that provided the same context information (blue vs pink or green vs khaki). Decoding analyses demonstrated that colour information peaked in the early colour-locked period of the trial and then rapidly declined over time to reach chance levels before the delay-locked period, <italic>cluster</italic> 1: 0.082 − 0.484 <italic>ms</italic>, <italic>p</italic> = 0.006 (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>). No learning-induced changes to colour decoding were detected between stage 1 and stage 4 in the delay-locked periods, <italic>M</italic> = 0.498 <italic>vs M</italic> = 0.498, <italic>t</italic>(24) = 0.03, <italic>p</italic> = 0.51, <italic>d</italic> = 0.0 (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>). These results suggest that participants rapidly discarded irrelevant colour information. Only information relevant for performance (context) entered working memory and was maintained.</p>
<p>Time-resolved decoding also revealed that the shape information rapidly peaked, persisted through the presentation period and rapidly fell back to chance after stimulation was over, <italic>cluster</italic> 1: 1.772 − 2.556<italic>s</italic>, <italic>p</italic> = 0.001 (<xref rid="fig2" ref-type="fig">Fig. 2e</xref>). Furthermore, no learning-induced (stage 1 vs stage 4) changes to shape coding were detected, <italic>M</italic> = 0.516 <italic>vs M</italic> = 0.508, <italic>t</italic>(24) = 0.79, <italic>p</italic> = 0.782, <italic>d</italic> = 0.15 (<xref rid="fig2" ref-type="fig">Fig. 2f</xref>). XOR and motor decoding followed the same temporal evolution with a later peak (compared to shape) and a slower decay; XOR: <italic>cluster</italic> 1: 1.892 − 3.2 <italic>ms</italic>, <italic>p</italic> = 0.001; motor: <italic>cluster</italic> 1: 1.45 − 1.772 <italic>ms</italic>, <italic>p</italic> = 0.039, <italic>cluster</italic> 2: 1.792 − 3.2 <italic>ms</italic>, <italic>p</italic> = 0.001 (<xref rid="fig2" ref-type="fig">Fig. 2g</xref> and <xref rid="fig2" ref-type="fig">Fig. 2i</xref>). In line with our predictions, the XOR signal exhibited a learning-induced increase from stage 1 to stage 4, <italic>M</italic> = 0.496 <italic>vs M</italic> = 0.516, <italic>t</italic>(24) = −1.85, <italic>p</italic> = 0.04, <italic>d</italic> = 0.4 (<xref rid="fig2" ref-type="fig">Fig. 2h</xref>). No such effect was found for the motor signal (<xref rid="fig2" ref-type="fig">Fig. 2j</xref>).</p>
</sec>
<sec id="s2c">
<title>The neural format of the context signal evolves over learning</title>
<p>A defining characteristic of low-dimensional task representations is that they can be easily cross-generalised to different sensory instances of the same task. Guided by this consideration, we next tested whether task features like context, shape, XOR and the motor signal were coded in a similar format across different levels of the irrelevant feature (colour). For example, to explore the cross-colour generalisation of context we trained a classifier on differentiating blue from green and tested it on the discrimination of pink vs khaki, and vice versa (see <italic>Methods, cross-colour generalised decoding</italic> for details). Decoding scores above chance obtained from such an analysis would suggest that the same abstract format of context was used in both sets of colours. It is important to note, however, that the lack of colour coding in the delay- and shape-locked periods indicates that the alignment of discriminant boundaries for each of the task variables (context, shape, XOR and motor coding) across different levels of colour would be trivial in these trial periods.</p>
<p>We found that cross-colour generalised context decoding mirrors the temporal dynamics of simple context decoding only in the shape-locked period, <italic>cluster</italic> 1: 1.892 − 2.315 <italic>ms</italic>, <italic>p</italic> = 0.001, <italic>cluster</italic> 2: 2.335 − 2.516 <italic>ms</italic>, <italic>p</italic> = 0.011 (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). There, context transforms into an abstract format only later in the period. Furthermore, the learning-resolved data reveal that contextual information transforms into an abstract cross-generalisable format over learning in the delay-locked period, stage 1 vs stage 4: <italic>M</italic> = 0.502 <italic>vs M</italic> = 0.523, <italic>t</italic>(24) = 1.71, <italic>p</italic> = 0.05, <italic>d</italic> = 0.3 (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>). Time-resolved cross-colour generalised decoding of shape (<italic>cluster</italic> 1: 1.772 − 2.375 <italic>ms</italic>, <italic>p</italic> = 0.002), XOR (<italic>cluster</italic> 1: 1.892 − 3.2 <italic>ms</italic>, <italic>p</italic> = 0.001) and motor coding (<italic>cluster</italic> 1: 1.289 − 3.2 <italic>ms</italic>, <italic>p</italic> = 0.001; <xref rid="fig3" ref-type="fig">Fig. 3c,e,g</xref>) and their learning dynamics (<xref rid="fig3" ref-type="fig">Fig. 3d,f,h</xref>) follow the same pattern of results as observed for simple decoding (<xref rid="fig2" ref-type="fig">Fig. 2i-n</xref>) with only the XOR exhibiting a learning induced effect, <italic>M</italic> = 0.484 <italic>vs M</italic> = 0.513 (stage 1 vs stage 4), <italic>t</italic>(24) = 2.19, <italic>p</italic> = 0.02, <italic>d</italic> = 0.45. As discussed above, cross-colour generalisation of context in the delay period is already implied by the significant context decoding combined with the absence of irrelevant colour coding noted above. Taken together, these findings imply that participants constructed abstract representations of task features but that the mechanism responsible for this transformation relied heavily on discarding colour information early in trial time. That is, the dimensionality of the task representation was primarily reduced as a function of time in the trial and not changed over learning, through the selection of which information enters working memory. It is worth noting the U-shaped learning dynamic observed across each task variable when learning dynamics were examined (<xref rid="fig3" ref-type="fig">Fig. 3f,h</xref>). This might be because task-specific geometrical transformations to the neural ctivity might reflect preparation processes and shift with reaction times. Averaging a temporally shifting neural signal using the same time window might thus result in a U-shaped dynamic. We next examined neural representations locked to the response activity to eliminate potential biases from preparation-related shifts.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Context and XOR are progressively represented in an abstract format over learning.</title>
<p><bold>a</bold>, Time-resolved cross-colour decoding of context; horizontal bars indicate statistical significance; the pale orange areas indicate the time windows for which subsequent decoding analyses were run (panel b). Vertical three dashed lines show the onset of the colour, delay, and shape, respectively; <bold>b</bold>, The learning dynamics of the cross-colour context decoding computed from the time-averaged signal in the delay period. <bold>c,d</bold> and <bold>e,f</bold>, and <bold>g,h,</bold> Analogues to a-b but for shape, XOR and motor cross-colour decoding, respectively. The shaded area indicated 95% CIs obtained through random resampling with replacement (<italic>n</italic> = 1000); All p-values for stage 1 vs stage 4 comparisons were calculated using t-tests for dependent samples (***, p &lt; 0.01; **, p &lt;0.01; *, p &lt; 0.05; †, p &lt; 0.1; n.s., not significant).</p></caption>
<graphic xlink:href="634110v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Analysis of neural geometry reveals evidence of low-dimensional representations at decision time</title>
<p>We hypothesised that the engagement of working memory processes could reflect preparation as part of the necessary computations, and thus lead to a low-dimensional task representation at the decision timepoint. In particular, our previous research showed that non-human primates constructed a low-dimensional and abstract representation of a XOR task over several weeks of training (<xref ref-type="bibr" rid="c40">Wójcik et al., 2022</xref>). In that study we found that at the end of learning the task representation was characterised by strong XOR decoding and weak context and shape coding. Furthermore, using cross-generalised decoding we demonstrated that the XOR feature was represented in an abstract format that supported later transfer to a new instance of the same task.</p>
<p>We therefore tested here whether learning in human participants also led to a low-dimensional and abstract task representation at decision time. To test these predictions, we analysed the geometry and dimensionality of averaged neural responses, shortly before the motor response was triggered ([t<sub>-200<italic>ms</italic></sub>, t<sub>0<italic>ms</italic></sub>]). We observed that decoding of the XOR feature increases with learning (stage 1 vs stage 4), <italic>M</italic> = 0.516 <italic>vs M</italic> = 0.572, <italic>t</italic>(23) = 4.05, <italic>p</italic> &lt; .001, <italic>d</italic> = 0.77 (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). Moreover, the XOR feature became progressively represented in an abstract format over learning as evidenced by the increase in cross-generalised decoding from stage 1 to stage 4, <italic>M</italic> = 0.512 <italic>vs M</italic> = 0.56, <italic>t</italic>(23) = 3.52, <italic>p</italic> = 0.001, <italic>d</italic> = 0.66 (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). Additionally, the cross-generalised decoding of context and shape decreased over learning (stage 1 vs stage 4); context: <italic>M</italic> = 0.514 <italic>vs M</italic> = 0.494, <italic>t</italic>(23) = 1.54, <italic>p</italic> = 0.068, <italic>d</italic> = 0.32; shape: <italic>M</italic> = 0.513 <italic>vs M</italic> = 0.493, <italic>t</italic>(23) = 1.86, <italic>p</italic> = 0.038, <italic>d</italic> = 0.41 (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). We note that the XOR decoding is colinear with the motor decoding at later stages of learning (i.e., XOR True == Left and XOR False == Right; <xref rid="fig1" ref-type="fig">Fig. 1c</xref>). However, in early learning (stage 1), when participants have not yet constructed a prominent XOR representation, motor coding is not related to XOR coding. This is corroborated by the above chance-level decoding of motor response in both stage 1 (<italic>M</italic> = 0.592, <italic>t</italic>(23) = 6.65, <italic>p</italic> &lt; .000) and stage 2 (<italic>M</italic> = 0.582, <italic>t</italic>(23) = 6.69, <italic>p</italic> &lt; .000) and no significant change in motor coding over learning (stage 1 vs stage 4), <italic>M</italic> = 0.592 <italic>vs M</italic> = 0.582, <italic>t</italic>(23) = 1.3, <italic>p</italic> = 0.205, <italic>d</italic> = 0.12 (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Neural geometry but not dimensionality changes over learning before the decision.</title>
<p><bold>a</bold>, Linear decoding of task variables for learning stages 1 (grey) and 4 (black). <bold>b</bold>, Cross-generalised linear decoding of task variables for learning stages 1 (grey) and 4 (black). <bold>c</bold>, Comparison of motor decoding (response) in stage 1 and stage 4; horizontal black lines represent value pairs for each participant. <bold>d</bold>, The learning dynamic of mean decoding of all possible task dichotomies excluding context, shape and XOR (shattering dimensionality) run on all trials (gold) and only correct trials (green); solid lines indicate the mean and shaded areas 95% confidence intervals over participants, respectively. <bold>e</bold>, Linear decoding of task variables in learning stage 1 run on correct trials (green) and incorrect (red). <bold>f</bold>,<bold>g</bold>, Correlation between normalised mean cross-generalised context decoding scores in the delay-locked period (context maintenance) and the shattering dimensionality computed at the moment of the decision on all trials in stage 1 and stage 4, respectively. All p-values were calculated using a t-test for dependent samples (a-h; l-m) and Pearson’s correlation coefficient (***, <italic>p</italic> &lt; 0.01; **, <italic>p</italic> &lt; 0.01; *, <italic>p</italic> &lt; 0.05; †, <italic>p</italic> &lt; 0.1; <italic>n</italic>. <italic>s</italic>., not significant).</p></caption>
<graphic xlink:href="634110v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We next explored whether the process of learning influenced the neural dimensionality of the representations used to solve the task. An analysis run on all trials (correct and incorrect combined) indicated that, although shattering dimensionality (see <italic>Method, neural dimensionality</italic> for details) was low throughout the entire experiment, an increase over learning (stage 1 vs stage 4) was observed, <italic>M</italic> = 0.507 <italic>vs M</italic> = 0.515, <italic>t</italic>(22) = 2.73, <italic>p</italic> = 0.012, <italic>d</italic> = 0.5 (gold line, <xref rid="fig4" ref-type="fig">Fig. 4d</xref>). We hypothesised that low neural dimensionality in learning stage 1 might be related to a high proportion of error trials (<xref ref-type="bibr" rid="c26">Rigotti et al., 2013</xref>). That is, a failure in maintaining one of the task features in error trials might have resulted in a low-dimensional representation at the decision timepoint and thus decreased neural dimensionality when all trials were analysed. As the number of error trials was not large enough for a shattering dimensionality analysis, we compared the learning dynamic of shattering dimensionality computed on all trials to the dimensionality dynamic obtained from only correct trials (gold vs green; <xref rid="fig4" ref-type="fig">Fig. 4d</xref>). This data split revealed that dimensionality in correct trials did not change over learning from stage 1 to stage 4, <italic>M</italic> = 0.518 <italic>vs M</italic> = 0.517, <italic>t</italic>(22) = 0.51, <italic>p</italic> = 0.615, <italic>d</italic> = 0.1. Moreover, a statistically significant difference between shattering dimensionality computed on all trials and computed on correct trials was only detected in learning stage 1, <italic>M</italic> = 0.507 <italic>vs M</italic> = 0.517, <italic>t</italic>(22) = 3.71, <italic>p</italic> = 0.001, <italic>d</italic> = 0.54, i.e., the learning stage containing the most error trials. In summary, these findings suggest that the observed increase in dimensionality reflected the differences between the neural geometry found in correct and incorrect trials rather than being indicative of dimensionality expansion as a learning strategy.</p>
<p>To address this explicitly, we next explored whether incorrect trials in stage 1 are in fact characterised by a weak representation of any of the task features. In line with these predictions, we found that incorrect trials compared to correct trials in stage 1 were characterised by a lower shape decoding score, <italic>M</italic> = 0.46 <italic>vs M</italic> = 0.51, <italic>t</italic>(2182) = 3.02, <italic>p</italic> = 0.004, <italic>d</italic> = 0.73. Interestingly, context decoding was observed to be higher in incorrect trials than in correct trials, <italic>M</italic> = 0.56 <italic>vs M</italic> = 0.51, <italic>t</italic>(18) = 2.64, <italic>p</italic> = .008, <italic>d</italic> = 0.48 (<xref rid="fig4" ref-type="fig">Fig. 4e</xref>). No significant difference in XOR decoding between incorrect and correct trials was observed, <italic>M</italic> = 0.53 <italic>vs M</italic> = 0.55, <italic>t</italic>(18) = 0.98, <italic>p</italic> = 0.171, <italic>d</italic> = 0.19. These results suggest that the representation used in incorrect trials was dominated by a context representation.</p>
<p>Finally, to test whether working memory engagement resulted in the reduction of neural dimensionality at the moment of the decision, we related the strength of mean cross-generalised context decoding in the delay-locked period to the mean shattering dimensionality (all trials) measured at the moment of the decision at a group level. In line with this hypothesis, we found that the strength of abstract context decoding during maintenance was negatively related to neural dimensionality at the decision time in learning stage 1, <italic>r</italic>(23) = −0.37, <italic>p</italic> = 0.04 (<xref rid="fig4" ref-type="fig">Fig. 4f</xref>). However, this effect was not present in learning stage 4, <italic>r</italic>(23) = 0.08, <italic>p</italic> = 0.63 (<xref rid="fig4" ref-type="fig">Fig. 4g</xref>). This suggests that participants that maintained a stronger representation of abstract contextual information during the delay also exhibited lower dimensional representations at decision time.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The recent convergence of neuroscience and machine learning has led to a novel conceptualisation of the role of working memory. It has been proposed that working memory actively participates in improving the efficiency of computation rather than just being a passive data storage system (<xref ref-type="bibr" rid="c9">Dasgupta &amp; Gershman, 2021</xref>). Our research echoes this perspective, suggesting that working memory selection shapes neural dimensionality. Notably, these representations closely mirror the energy-efficient neural codes observed in non-human primates following intensive training (Stroud et al., n.d.; <xref ref-type="bibr" rid="c39">Wójcik et al., 2023</xref>).</p>
<p>The feature selection mechanism discussed here is based on the assumption that irrelevant features are filtered out after they enter working memory. However, feature selection can also take place at the early perceptual stages through the engagement of selective attention. This is supported by empirical reports demonstrating that the PFC, specifically the inferior temporal junction, can exert top-down control over posterior cortical areas involved in visual processing (<xref ref-type="bibr" rid="c42">Zanto et al., 2010</xref>, <xref ref-type="bibr" rid="c43">2011</xref>). Specifically, these frontal areas can enhance or diminish the processing of low-level physical features in visual cortices (from V1 to V5; <xref ref-type="bibr" rid="c28">Ruff et al., 2008</xref>) during the early stages of perceptual processing (∼100ms) and thus control what information enters later stages of information processing such as working memory maintenance. As a consequence of attention selection, the diminished representation of the irrelevant feature was observed early in trial time. The early perceptual selection account seems, however, at odds with the described here data. In particular, the strength of colour (irrelevant) and context (relevant) decoding was similar during the presentation period of the coloured cue. Crucially, the irrelevant feature was only discarded during the delay after it entered working memory. Therefore, we believe that the selection mechanism observed here reflects working memory selection rather than selective attention.</p>
<p>In the present study, we also showed that human participants rapidly acquired an abstract representation of context over learning. It should be noted, however, that learning here might not be an effect of slow updates to neural circuitry that accompany building a task representation from scratch. Specifically, it is possible that human participants were already in the possession of a hierarchical XOR representation that could have been used to solve the task and the observed rapid learning speed reflected the alignment of the task representation stored in long-term memory to the new sensory instance. In line with this, our previous research in non-human primates demonstrated that after learning low-dimensional XOR representations, animals were able to rapidly align the already acquired readout dimension to the representation of previously unseen stimuli combinations very early in training (Wójcik et al., n.d.).</p>
<p>While the data presented here shed light on how working memory processes could be utilised to control neural dimensionality, there are potential limitations that should be considered. Firstly, to establish a causal role of working memory selection in reducing the dimensionality of neural activity at the decision timepoint, a control condition could be introduced, whereby the colour information persisted throughout the entire trial. The neural representations and their learning dynamics observed in the current study could be then compared to representation acquired in the second, continuous colour input setting. Secondly, the low difficulty of the task, and consequently a small number of error trials, prevented us from performing a dimensionality analysis on representations that subsequently led to erroneous responses. To address this issue, the difficulty of the task could be increased by reducing the memory delay period. Finally, the motor response signal and the XOR signal were collinear in the study after learning. These two features could be disentangled by introducing a third-level policy and thus a second interaction term. In the current design, the XOR feature represents an interaction between the shape and the colour features. Displaying two abstract stimuli (e.g., “#” and “&amp;” signs) representing the XOR (True vs False) and randomising the sides on which they would be presented (left vs right) would provide a marker of the XOR that is not confounded by motor code.</p>
<p>Building on the results described here, future studies could explore the relationship between working memory processes and low-dimensional task representations using perturbation approaches. Specifically, techniques such as TMS (Rose et al., n.d.) or pinging (<xref ref-type="bibr" rid="c41">Wolff et al., 2017</xref>) have been successfully used in the past to reactivate information stored in working memory in an activity-silent format (<xref ref-type="bibr" rid="c32">Stokes, 2015</xref>). Using these methods to non-specifically perturb the system right after the stimulus presentation could reveal, for example, whether discarding irrelevant features is related to the decay of neural activity (i.e., in the early delay) (<xref ref-type="bibr" rid="c30">Souza &amp; Oberauer, 2015</xref>).</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Twenty-five participants (14 women and 11 men; mean age 23.3 years) were recruited for the study. Before taking part in the experiment, all participants declared their written consent according to the guidelines approved by the MS IDREC of the University of Oxford (approval no R62730/RE001 and R51332). No previous history of neuropsychiatric or neurological disorders was reported by the participants who had either normal or corrected-to-normal vision. All participants received an appropriate monetary reward for their time and effort.</p>
</sec>
<sec id="s4b">
<title>Procedure and task</title>
<p>Participants were seated in a sound-proof and dimply lit room. Their heads were supported by a chinrest which also ensured a constant viewing distance of 70 <italic>cm</italic>. Visual stimuli were then projected on the screen at a spatial resolution of 1024 <italic>x</italic> 786 pixels with a 60 <italic>Hz</italic> refresh rate. The Psychtoolbox run on MATLAB was used to design and run the task. Each of the conditions (<italic>n</italic> = 8) was repeated 100 times across 20 blocks of 40 trials. The sequence of trials was randomised. Importantly, 5 task variables could have been represented in the task: colour, context, shape, XOR and motor coding (left vs right response).</p>
</sec>
<sec id="s4c">
<title>Stimuli</title>
<p>The colours of the coloured circles stimulus were chosen using the CIELab colour space (Tkalčič &amp; Tasič, n.d.). To ensure that the colours were approximately isoluminant, the same L parameter was used for every colour. Furthermore, to ensure a circular (equidistant) colour representation, parameters <italic>a</italic> and <italic>b</italic> were fixed with respect to value but not valence. Note that colours were randomly mapped to the XOR rule for every participant before the experiment. This was done to ensure that the initial dissimilarity between colours on a physical level did not influence the learning of the XOR rule at the group level. The shapes were custom-made in Adobe Illustrator.</p>
</sec>
<sec id="s4d">
<title>EEG acquisition and pre-processing</title>
<p>EEG signal was collected using 61 Ag/AGcl electrodes (EasyCap, Herrshing, Germany) mounted in the cap in line with the 10-20 system (<xref ref-type="bibr" rid="c1">Acharya et al., 2016</xref>). The data was amplified and collected at a 1000 <italic>Hz</italic> sampling rate using the NeuroScan SynAmps RT amplifier and the Scan 4.5 software (Compumedics NeuroScan, Charlotte, NC). The electrode system was grounded with an electrode placed at the surface of the right elbow. To allow efficient ocular artefact detection and elimination, horizontal and vertical electrooculography (EOG) was collected. Specifically, two vertical channels were attached to the suborbit and supraorbit of the left eye and two horizontal channels were attached at the exterior canthi of both eyes. The impedance of all channels was checked throughout the duration of the experiment and kept below the level of 10 <italic>kΩ</italic>. After collection, the EEG data were pre-processed using the MNE toolbox that was run on Python 3.5 (<xref ref-type="bibr" rid="c15">Gramfort et al., 2013</xref>). Firstly, the data was re-referenced using the right mastoid channel. Then we downsampled the signal to 250<italic>Hz</italic> and used a bandpass filter from 0.01 to 40<italic>Hz</italic>. The signal was subsequently epoched into segments starting −200<italic>ms</italic> and ending 1500<italic>ms</italic>, locked to the onset of colour stimuli and also shape stimuli. For a decision time analysis data was epoched −200 – 0<italic>ms</italic> locked to the button press. Horizontal and vertical eye movement, blinks, ECG and movement artefacts were identified using Independent Component Analysis. Then, we estimated artefact rejection thresholds separately for each participant using the Autoreject algorithm and discarded or repaired corrupt epochs (<xref ref-type="bibr" rid="c18">Jas et al., 2017</xref>). We also employed the RANSAC algorithm to identify and repair contaminated sensors (<xref ref-type="bibr" rid="c4">Bigdely-Shamlo et al., 2015</xref>). Note that automated pre-processing methods have been shown to be less prone to error than methods based on visual inspection and support transparency, reliability, and scalability of EEG analysis (<xref ref-type="bibr" rid="c18">Jas et al., 2017</xref>). Due to technical issues in electrode position digitalisation artifact rejection was based only on automatic threshold estimation in seven participants. Our pre-processing pipeline resulted in a mean value of 728 (<italic>SD</italic> = 85) colour-locked, 728 (<italic>SD</italic> = 83) shape-locked, and 740 (<italic>SD</italic> = 97) response-locked epochs of that were then used in the subsequent analysis phase. For time-averaged analyses these data were divided equally into four learning stages.</p>
</sec>
<sec id="s4e">
<title>Behavioural analysis</title>
<p>Performance was calculated as the proportion of correct responses in each of the four learning stages. Similarly, reaction times were operationalised as median (over trials) time measured from the onset of the shape stimulus and response button press in each of the four learning stages. Next, we computed three types of switch costs (<xref rid="fig1" ref-type="fig">Fig. 1e, f, g</xref>) for both performance and reaction times using all trials (<xref rid="fig1" ref-type="fig">Fig. 1i, j, k</xref> and <xref rid="fig1" ref-type="fig">m, n, o</xref>, respectively). We first contrasted performance scores and reaction times obtained from <italic>context switch trials</italic> (<xref rid="fig1" ref-type="fig">Fig. 1e</xref>), where the context on the current trial changed as compared to the previous trial against trials in which the context remained the same (<xref rid="fig1" ref-type="fig">Fig. 1i, j</xref>). (Note that here, context denotes the predictive value of the colour, shared between two colours: for example, the square should be mapped to the left button in the context of both the blue and the pink colour; <xref rid="fig1" ref-type="fig">Fig. 1c</xref>). To test whether context switches impacted performance and reaction times more than shape switches (<xref rid="fig1" ref-type="fig">Fig. 1f</xref>), we compared context switch trials to <italic>shape switch trials</italic> (<xref rid="fig1" ref-type="fig">Fig. 1f, k</xref>). Finally, context switch trials were compared to <italic>colour switch trials</italic> (<xref rid="fig1" ref-type="fig">Fig. 1g</xref>), where the colour on the current trial changed as compared to the previous trials but the context remained the same (<xref rid="fig1" ref-type="fig">Fig. 1g, l</xref>). This was done to measure a context-independent impact of a sensory switch on performance and reaction times. Importantly, as frequentist statistics were used in the behavioural analysis, reaction times distribution were transformed using a log transform to approximate a normal distribution.</p>
</sec>
<sec id="s4f">
<title>Decoding</title>
<p>To determine the amount of information represented for each task variable by the brain linear discriminant analysis (LDA) decoders were employed. The inherent presence of noise and spatial correlations observed in the EEG signal can make decoding particularly difficult. Specifically, because electrical potentials can propagate freely through brain tissue, the same source signal can be measured by multiple EEG sensors leading to a spatial covariance structure that is prevalent in the observed signal. Additionally, the process of referencing introduces artefacts present at the reference site to every sensor in the dataset. To account for these characteristics a LDA decoder with shrinkage was used (for similar shrinkage applications in decoding see <xref ref-type="bibr" rid="c41">Wolff et al., 2017</xref>). The shrinkage factor was chosen based on the Ledoit-Wolf lemma (<xref ref-type="bibr" rid="c19">Ledoit &amp; Wolf, 2004</xref>). The decoding analysis was run within each participant for each time point separately. First, trials were split randomly into equal test and train sets. Next, an LDA classifier was trained on the train data and subsequently tested on the test data (and vice-versa). The scores obtained from these two procedures were then averaged. This was repeated for 10 random 50%/50% splits and the scores were again averaged. Importantly, to obtain an estimate of colour decoding that was not biased by context information (i.e., an estimate of pure irrelevant information) we run two separate decoders that differentiated colours within the same context: (1) colour 1 vs colour 3 (context 1), and (2) colour 2 from colour 4 (context 1). The scores were then averaged. Decoding analyses were also run on time average data. For this purpose, learning resolved data (4 learning stages) were time-averaged (trial time) in the colour-locked period ([t<sub>100<italic>ms</italic></sub>, t<sub>500<italic>ms</italic></sub>], colour-locked), delay-locked period ([t<sub>500<italic>ms</italic></sub>, t<sub>1500<italic>ms</italic></sub>], colour-locked), and shape-locked period ([t<sub>100<italic>ms</italic></sub>, t<sub>500<italic>ms</italic></sub>], shape-locked). When analysing neural activity at the moment of decision the EEG signal was averaged in the response-locked period ([t-<sub>200<italic>ms</italic></sub>, t<sub>0<italic>ms</italic></sub>]).</p>
</sec>
<sec id="s4g">
<title>Neural dimensionality</title>
<p>Neural dimensionality was operationalised in this study as shattering dimensionality, a metric that has been applied in several previous experiments (<xref ref-type="bibr" rid="c3">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c26">Rigotti et al., 2013</xref>; Wójcik et al., n.d.). We utilised the same decoding method mentioned earlier but averaged the results across all 35 potential dichotomies possible given the task’s structure. This task involves three linear variables: colour, context, and shape. When combined, they create a cube in the input space, which can be divided in 35 unique ways, each representing two sets of 4 vertices. We determined how decodable each dichotomy was and observed the average decoding accuracy over time.</p>
</sec>
<sec id="s4h">
<title>Full cross-generalised decoding</title>
<p>To explore the neural geometry of the task information represented by the participants at decision time we used cross-generalised LDA decoding (<xref ref-type="bibr" rid="c3">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c39">Wójcik et al., 2023</xref>). Similarly as previous studies, trials were split according to the to-be-decoded target variable labels as well as the splitting variable labels. That is, the splitting variable provided the training and test instances of the data for the decoding of the target variable. The task examined here had three linear input variables (colour, context and shape) which resulted in 36 possible cross. gen axes per each of the task variables. That is, the labels for 8 conditions (2 <italic>colours x</italic> 2 <italic>shapes x</italic> 2 <italic>widt</italic>h<italic>s</italic>) are split into two sets of four labels (by colour, shape, or width). To identify training and testing exemplars within each of the sets, every possible binary combination of condition labels was determined (4 <italic>c</italic>h<italic>oose</italic> 2). This yielded 6 combinations for each of the sets. Thirty-six unique train-test splits (cross-generalisation axes) can be achieved by combining these two sets. Decoding accuracy scores estimated by running linear LDA decoders for each of these splits were then averaged to obtain a general cross-generalisation score of the analysed target variable.</p>
</sec>
<sec id="s4i">
<title>Cross-colour generalised decoding</title>
<p>The examine whether the task-irrelevant feature (colour) was discarded by the cortex and therefore influenced neural geometry a simpler format of cross-generalised LDA decoding was employed. Specifically, we tested whether learning the task resulted in representations that were shared across different levels of the irrelevant feature (colour). This resulted in four possible binary decoding problems (e.g., when performing cross-generalised decoding for the context variable we can: (1) train on differentiating colour 1 (context 1) from colour 2 (context 2) and test on differentiating colour 3 (context 1) from colour 4 (context 2), (2) train on differentiating colour 3 (context 1) from colour 4 (context 2) and test on differentiating colour 1 (context 1) from colour 2 (context 2), (3) train on differentiating colour 1 (context 1) from colour 4 (context 2) and test on differentiating colour 2 (context 2) from colour 3 (context 1), and (4) train on differentiating colour 2 (context 2) from colour 3 (context 1) and test on differentiating colour 1 (context 1) from colour 4 (context 2); these four decoding scores were then averaged). Using this procedure, we explored the cross-colour generalisation potential of the context, shape, XOR and motor coding variables.</p>
</sec>
<sec id="s4j">
<title>Significance testing</title>
<p>Time-resolved one-sample t-tests (one-tailed) were used to test for statistical significance of the temporally resolved decoding accuracy scores. To correct for family-wise errors a cluster-based correction was employed (<xref ref-type="bibr" rid="c20">Maris &amp; Oostenveld, 2007</xref>). To test for learning-induced changes in accuracy, reaction times, decoding and selectivity measures we compared data from learning stage 1 to data from learning stage 4 using a t-test for dependent samples. Furthermore, shaded areas in all figures represent 95% confidence intervals obtained through a resampling with replacement procedure (<italic>n</italic> = 1000). In analyses where decoding scores were compared to the chance level, one-sample t tests were used. Test statistics were supplemented with Cohen’s <italic>d</italic> effect size estimation. Two participants were excluded from the response-locked analyses due to trigger failure and an insufficient number of error trials.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This work was funded by the Strategic Longer and Larger grant (awarded to LTH and MGS; BB/W003392/1) and the Biotechnology and Biological Sciences Research Council (award BB/M010732/1 to MGS). MJW was supported by the Clarendon Fund, Fundacja Wyręba and the Saven European Scholarship. LTH was supported by a Sir Henry Dale Fellowship from the Royal Society and the Wellcome Trust (208789/Z/17/Z). We also thank Emilia Piwek for useful feedback and detailed comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Acharya</surname>, <given-names>J. N.</given-names></string-name>, <string-name><surname>Hani</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cheek</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Thirumala</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Tsuchida</surname>, <given-names>T. N</given-names></string-name></person-group>. (<year>2016</year>). <article-title>American Clinical Neurophysiology Society Guideline 2: Guidelines for Standard Electrode Position Nomenclature</article-title>. <source>Journal of Clinical Neurophysiology</source>, <volume>33</volume>(<issue>4</issue>), <fpage>308</fpage>–<lpage>311</lpage>. <pub-id pub-id-type="doi">10.1097/WNP.0000000000000316</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barak</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Rigotti</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Fusi</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2013</year>). <article-title>The sparseness of mixed selectivity neurons controls the generalization-discrimination trade-off</article-title>. <source>Journal of Neuroscience</source>, <volume>33</volume>(<issue>9</issue>), <fpage>3844</fpage>–<lpage>3856</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2753-12.2013</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernardi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Benna</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Rigotti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Munuera</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Salzman</surname>, <given-names>C. D</given-names></string-name></person-group>. (<year>2020</year>). <article-title>The Geometry of Abstraction in the Hippocampus and Prefrontal Cortex</article-title>. <source>Cell</source>, <volume>183</volume>(<issue>4</issue>), <fpage>954</fpage>–<lpage>967.e21</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2020.09.031</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bigdely-Shamlo</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mullen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kothe</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Su</surname>, <given-names>K. M.</given-names></string-name>, &amp; <string-name><surname>Robbins</surname>, <given-names>K. A</given-names></string-name></person-group>. (<year>2015</year>). <article-title>The PREP pipeline: Standardized preprocessing for large-scale EEG analysis</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>9</volume>(<issue>JUNE</issue>), <fpage>1</fpage>–<lpage>19</lpage>. <pub-id pub-id-type="doi">10.3389/fninf.2015.00016</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braver</surname>, <given-names>T. S</given-names></string-name></person-group>. (<year>2012</year>). <article-title>The variable nature of cognitive control: a dual mechanisms framework</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>16</volume>(<issue>2</issue>), <fpage>106</fpage>–<lpage>113</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chien</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Wallis</surname>, <given-names>J. D.</given-names></string-name>, &amp; <string-name><surname>Rich</surname>, <given-names>E. L</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Abstraction of reward context facilitates relative reward coding in neural populations of the macaque anterior cingulate cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>43</volume>(<issue>33</issue>), <fpage>5944</fpage>–<lpage>5962</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cromer</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>J. E.</given-names></string-name>, &amp; <string-name><surname>Miller</surname>, <given-names>E. K</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Representation of Multiple, Independent Categories in the Primate Prefrontal Cortex</article-title>. <source>Neuron</source>, <volume>66</volume>(<issue>5</issue>), <fpage>796</fpage>– <lpage>807</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2010.05.005</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cueva</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Saez</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Marcos</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Genovesio</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jazayeri</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Romo</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Salzman</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name>, &amp; <string-name><surname>Fusi</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Low-dimensional dynamics for working memory and time encoding</article-title>. <source>PNAS</source>, <volume>117</volume>(<issue>37</issue>), <fpage>23021</fpage>–<lpage>23032</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1915984117</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dasgupta</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Gershman</surname>, <given-names>S. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Memory as a Computational Resource</article-title>. In <source>Trends in Cognitive Sciences</source>, <volume>25</volume>(<issue>3</issue>), <fpage>240</fpage>–<lpage>251</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2020.12.008</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Ehrlich</surname>, <given-names>D. B.</given-names></string-name>, &amp; <string-name><surname>Murray</surname>, <given-names>J. D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Geometry of neural computation unifies working memory and planning</article-title>. <source>bioRxiv</source> <pub-id pub-id-type="doi">10.1101/2021.02.01.429156</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ehrlich</surname>, <given-names>D. B.</given-names></string-name>, &amp; <string-name><surname>Murray</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Geometry of neural computation unifies working memory and planning</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>119</volume>(<issue>37</issue>), <fpage>e2115610119</fpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Flesch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Juechems</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dumbalska</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Orthogonal representations for robust context-dependent task performance in brains and neural networks</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>7</issue>), <fpage>1258</fpage>–<lpage>1270.e11</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.005</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, <string-name><surname>Rigotti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Karpova</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Kiani</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Why neurons mix: high dimensionality for higher cognition This review comes from a themed issue on Neurobiology of behavior</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>37</volume>, <fpage>66</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goldman-Rakic</surname>, <given-names>P. S</given-names></string-name></person-group>. (<year>1995</year>). <article-title>Cellular Basis of Working Memory Review</article-title>. In <source>Neuron</source> (Vol. <volume>14</volume>).</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Luessi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Larson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Engemann</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Strohmeier</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Brodbeck</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Goj</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Jas</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brooks</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Parkkonen</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Hämäläinen</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2013</year>). <article-title>MEG and EEG data analysis with MNE-Python</article-title>. <source>Frontiers in Neuroscience</source>, <italic>7 DEC</italic>. <pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hunt</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Kaanders</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>MacIver</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Mugan</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Procyk</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Redish</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Russo</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Scholl</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Stachenfeld</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Formalizing planning and information search in naturalistic decision-making</article-title>. <source>Nature Neuroscience</source>, <volume>24</volume>(<issue>8</issue>), <fpage>1051</fpage>–<lpage>1064</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jacob</surname>, <given-names>S. N.</given-names></string-name>, &amp; <string-name><surname>Nieder</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Complementary roles for primate frontal and parietal cortex in guarding working memory from distractor stimuli</article-title>. <source>Neuron</source>, <volume>83</volume>(<issue>1</issue>), <fpage>226</fpage>–<lpage>237</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2014.05.009</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jas</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Engemann</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Bekhti</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Raimondo</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Gramfort</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Autoreject: Automated artifact rejection for MEG and EEG data</article-title>. <source>NeuroImage</source>, <volume>159</volume>, <fpage>417</fpage>–<lpage>429</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.030</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ledoit</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Wolf</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2004</year>). <article-title>A well-conditioned estimator for large-dimensional covariance matrices</article-title>. <source>Journal of Multivariate Analysis</source>, <volume>88</volume>(<issue>2</issue>), <fpage>365</fpage>–<lpage>411</lpage>. <pub-id pub-id-type="doi">10.1016/S0047-259X(03)00096-4</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maris</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Oostenveld</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>164</volume>(<issue>1</issue>), <fpage>177</fpage>–<lpage>190</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mayr</surname>, <given-names>U.</given-names></string-name>, &amp; <string-name><surname>Kliegl</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Differential Effects of Cue Changes and Task Changes on Task-Set Selection Costs</article-title>. <source>Journal of Experimental Psychology: Learning Memory and Cognition</source>, <volume>29</volume>(<issue>3</issue>), <fpage>362</fpage>–<lpage>372</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.29.3.362</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meyers</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Kreiman</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Dynamic population coding of category information in inferior temporal and prefrontal cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>100</volume>(<issue>3</issue>), <fpage>1407</fpage>–<lpage>1419</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quintana</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Fuster</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>1992</year>). <article-title>Mnemonic and predictive functions of cortical neurons in a memory task</article-title>. <source>Neuroreport</source>, <volume>3</volume>(<issue>8</issue>), <fpage>721</fpage>–<lpage>724</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rainer</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rao</surname>, <given-names>S. C.</given-names></string-name>, &amp; <string-name><surname>Miller</surname>, <given-names>E. K</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Prospective coding for objects in primate prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>19</volume>(<issue>13</issue>), <fpage>5493</fpage>–<lpage>5505</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reinert</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hübener</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bonhoeffer</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Goltstein</surname>, <given-names>P. M</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Mouse prefrontal cortex represents learned rules for categorization</article-title>. <source>Nature</source>, <volume>593</volume>(<issue>7859</issue>), <fpage>411</fpage>–<lpage>417</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-021-03452-z</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rigotti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Barak</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Warden</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Fusi</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2013</year>). <article-title>The importance of mixed selectivity in complex cognitive tasks</article-title>. <source>Nature</source>, <volume>497</volume>(<issue>7451</issue>), <fpage>585</fpage>–<lpage>590</lpage>. <pub-id pub-id-type="doi">10.1038/nature12160</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Rose</surname>, <given-names>N. S.</given-names></string-name>, <string-name><surname>Larocque</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Riggall</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Gosseries</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Starrett</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Meyering</surname>, <given-names>E. E.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R.</given-names></string-name></person-group> (<year>2016</year>). <source>Reactivation of latent working memories with transcranial magnetic stimulation</source>. <ext-link ext-link-type="uri" xlink:href="https://www.science.org/doi/10.1126/science.aah7011">https://www.science.org/doi/10.1126/science.aah7011</ext-link></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ruff</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>Bestmann</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Blankenburg</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Bjoertomt</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Josephs</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Weiskopf</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Deichmann</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Driver</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Distinct causal influences of parietal versus frontal areas on human visual cortex: Evidence from concurrent TMS-fMRI</article-title>. <source>Cerebral Cortex</source>, <volume>18</volume>(<issue>4</issue>), <fpage>817</fpage>–<lpage>827</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhm128</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sakai</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Miyashita</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>1991</year>). <article-title>Neural organization for the long-term memory of paired associates</article-title>. <source>Nature</source>, <volume>354</volume>(<issue>6349</issue>), <fpage>152</fpage>–<lpage>155</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Souza</surname>, <given-names>A. S.</given-names></string-name>, &amp; <string-name><surname>Oberauer</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Time-based forgetting in visual working memory reflects temporal distinctiveness, not decay</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>22</volume>, <fpage>156</fpage>–<lpage>162</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spaak</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Watanabe</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Funahashi</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Stokes</surname>, <given-names>M. G</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Stable and dynamic coding for working memory in primate prefrontal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>37</volume>(<issue>27</issue>), <fpage>6503</fpage>–<lpage>6516</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3364-16.2017</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stokes</surname>, <given-names>M. G</given-names></string-name></person-group>. (<year>2015</year>). <article-title>‘Activity-silent’ working memory in prefrontal cortex: A dynamic coding framework</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>19</volume>(<issue>7</issue>), <fpage>394</fpage>–<lpage>405</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2015.05.004</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stokes</surname>, <given-names>M. G.</given-names></string-name>, <string-name><surname>Kusunoki</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sigala</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Gaffan</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Duncan</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Dynamic coding for cognitive control in prefrontal cortex</article-title>. <source>Neuron</source>, <volume>78</volume>(<issue>2</issue>), <fpage>364</fpage>–<lpage>375</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2013.01.039</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stroud</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Lengyel</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2024</year>). <article-title>The computational foundations of dynamic coding in working memory</article-title>. <source>Trends in Cognitive Sciences</source>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stroud</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Watanabe</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Suzuki</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Stokes</surname>, <given-names>M. G.</given-names></string-name>, &amp; <string-name><surname>Lengyel</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Optimal information loading into working memory explains dynamic coding in the prefrontal cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>120</volume>(<issue>48</issue>), <fpage>e2307991120</fpage>. <pub-id pub-id-type="doi">10.1073/pnas.2307991120</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Stroud</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Wójcik</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jensen</surname>, <given-names>K. T.</given-names></string-name>, <string-name><surname>Kusunoki</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kadohisa</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Stokes</surname>, <given-names>M. G.</given-names></string-name>, &amp; <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Ignorance is bliss: effects of noise and metabolic cost on cortical task representations</article-title>. <source>bioRxiv</source> <pub-id pub-id-type="doi">10.1101/2023.07.11.548492</pub-id>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Tkalčič</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Tasič</surname>, <given-names>J. F.</given-names></string-name></person-group> (<year>n.d.</year>). <source>Colour spaces-perceptual, historical and applicational background</source>. <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com">http://www.mathworks.com</ext-link></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vandierendonck</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Liefooghe</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Verbruggen</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Task Switching: Interplay of Reconfiguration and Interference Control</article-title>. <source>Psychological Bulletin</source>, <volume>136</volume>(<issue>4</issue>), <fpage>601</fpage>–<lpage>626</lpage>. <pub-id pub-id-type="doi">10.1037/a0019791</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Wójcik</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Stroud</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Wasmuht</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kusunoki</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kadohisa</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Myers</surname>, <given-names>N. E.</given-names></string-name>, <string-name><surname>Hunt</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Stokes</surname>, <given-names>M. G</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Learning shapes neural geometry in the prefrontal cortex</article-title>. <source>bioRxiv</source> <pub-id pub-id-type="doi">10.1101/2023.04.24.538054</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wójcik</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Stroud</surname> <given-names>J. P.</given-names></string-name>, <string-name><surname>Wasmuht</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kusunoki</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kadohisa</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Myers</surname>, <given-names>N. E.</given-names></string-name>, <string-name><surname>Hunt</surname>, <given-names>L. T.</given-names></string-name>, <string-name><surname>Duncan</surname> <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Stokes</surname>, <given-names>M. G.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Learning shapes neural dimensionality in the prefrontal cortex</article-title>. . In <source>Preparation</source>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolff</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Jochim</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Akyürek</surname>, <given-names>E. G.</given-names></string-name>, &amp; <string-name><surname>Stokes</surname>, <given-names>M. G</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title>. <source>Nature Neuroscience</source>, <volume>20</volume>(<issue>6</issue>), <fpage>864</fpage>–<lpage>871</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zanto</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Rubens</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Bollinger</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Gazzaley</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Top-down modulation of visual feature processing: The role of the inferior frontal junction</article-title>. <source>NeuroImage</source>, <volume>53</volume>(<issue>2</issue>), <fpage>736</fpage>–<lpage>745</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.06.012</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zanto</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Rubens</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Thangavel</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gazzaley</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Causal role of the prefrontal cortex in top-down modulation of visual processing and working memory</article-title>. <source>Nature Neuroscience</source>, <volume>14</volume>(<issue>5</issue>), <fpage>656</fpage>–<lpage>663</lpage>. <pub-id pub-id-type="doi">10.1038/nn.2773</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106609.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Cools</surname>
<given-names>Roshan</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>The findings are <bold>valuable</bold>, given that they highlight the flexible and future-oriented nature of working memory. However, the evidence for the claims about context/color generalization, behavioural relevance of context decoding, dimensionality reduction, neural geometry, the XOR representation, and the specific contribution of working memory is <bold>incomplete</bold>. The work could be reframed in terms of prospective remapping.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106609.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Wojcik et al. conducted a working memory (WM) experiment in which participants had to press the right or left button after being presented with a square (upright) or diamond stimulus. The response mapping ('context') depended on a colour cue presented at the start of each trial. This results in an XOR task, requiring participants to integrate colour and shape information. Importantly, multiple colours could map onto the same context, allowing the authors to disentangle the (neural) representations of context from those of colour.</p>
<p>The authors report that participants learn the appropriate context mappings quickly over the course of the experiment. Neural context representation is evident in the WM delay and emerges later in the experiment, unlike colour representation, which is present only during colour presentation and does not evolve over experimental time. There are furthermore results on neural geometry (averaged cross-generalized decoding) and neural dimensionality (averaged decoding after shattering all task dimensions), which are somewhat harder to interpret.</p>
<p>Overall, the findings are likely Important, as they highlight the flexible and future-oriented nature of WM. The strength of support at the moment is incomplete: there are some loose ends on the context/colour generalization, and the evidence for the XOR neural representation is not (yet) well-established.</p>
<p>I have one (major) concern and several suggestions for improvement.</p>
<p>(1a) As the authors also acknowledge in several places, the XOR dimension is strongly correlated with motor responses, in any case toward the end of the task (and by definition for all correct trials). This should be dealt with properly. Right now, e.g. Figures 2g/i, 2h/j, 3e/g, 3f/h are highly similar, respectively, because of this strong collinearity. I would remove the semi-duplicate graphs and/or deal with this explicitly through some partial regression, trial selection, or similar (and report these correlations).</p>
<p>(1b) Most worrisome in this respect is that one of the key results presented is that XOR decoding increases with learning. But also task accuracy increases, meaning that the proportion of correct trials increases with learning, meaning that the XOR and motor regressors become more similar over experimental time. This means that any classifier picking up on motor signals will be better able to do so later on in the task than earlier on. (In other words, the XOR regressor may be a noisy version of the motor regressor early on, and a more precise version of the motor regressor later on.) Therefore, the increase in XOR decoding over experimental time may be (entirely) due to an increase in similarity between the XOR and motor dimensions. The authors should either rule out this explanation, and/or remove/tone down the conclusions regarding the XOR coding increase. (Note that the takeaway regarding colour/context generalization does not depend on this analysis, fortunately.) The absence of a change in motor decoding with learning (as reported on page 11) does not affect this potential confound; in fact it is made more likely with it.</p>
<p>(2) Bayes factors would be valuable in several places, especially with null results (p. 5) or cases with borderline-significant p-values.</p>
<p>(3) The authors' interpretation of the key results implies that the abstract coding learned over the task should be relevant for behaviour. The current results do not show a particularly strong behavioural relevance of coding, to put it mildly. It might be worth exploring whether neural coding expresses itself in reaction times, rather than (in)correct responses, and reflecting on the (lack of) behavioural relevance in the Discussion.</p>
<p>(4) All data and experiment/analysis code should be made available, in public repositories (i.e., not &quot;upon request&quot;).</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106609.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This manuscript describes an experiment in which subjects learned to apply an XOR rule in a task in which an initial color cue conditioned the instruction (&quot;press left&quot; or &quot;press right&quot;) conveyed by a subsequent shape.</p>
<p>This manuscript gives the impression of being written to address a sophisticated computational framework, but the experiment was not designed to test this framework. Stated differently, the memory-as-resource-for-computations framework may not be needed to account for the results presented here. Variants of this task have been used for decades, often in the context of prospective processing, and although the authors emphasize a dimensionality reduction operation, the task may actually only require the recoding of retrospectively relevant sensory information into the prospectively relevant rule that is needed to guide the response on that trial. Consequently, many of the claims are only partially supported.</p>
<p>The framework invoked by the authors is summarized in the second paragraph of the manuscript:</p>
<p>&quot;Insights from machine learning and computational neuroscience further highlight the idea that memory processes can be viewed as a resource for computations rather than a passive mechanism for storage (Dasgupta &amp; Gershman, 2021; Ehrlich &amp; Murray, 2022). In this light, working memory adapts computations to the current task demands (Dasgupta &amp; Gershman, 2021); pre-computed information can be stored in working memory, and thus reduce the computation time at the moment of the decision (Braver, 2012; Hunt et al., 2021). This perspective is further supported by computational modelling of neural circuits that contends that working memory will change neural geometry in a way that supports the temporal decomposition of computations (Ehrlich &amp; Murray, 2022). This work suggests that the computational load at the moment of action can be thus alleviated by decomposing complex operations into several simple problems solved sequentially in time.&quot;</p>
<p>However, the relevance, certainly the necessity, of this framework leads to mischaracterizations of some elements of the task (including about a hypothesis), the emphasis of constructs that don't actually exist in the task, some logical inconsistencies, and the repeated invocation of operations like &quot;dimensionality reduction&quot; despite the fact that the authors find no evidence for them.</p>
<p>Beginning with the final point, the task presented here is a variant of a Badre-style hierarchical control task, one requiring solution at the second order of abstraction (i.e., the color conditions the interpretation of the shape [2nd order], which then determines the correct response [1st order]. These operations can be accomplished without dimensionality reduction by simply carrying out the remapping instructed by each element. For example, on a trial beginning with a blue color cue, the subject can use a lookup table to translate this into the rule &quot;square = left; diamond = right&quot;. When the shape is subsequently presented, the subject responds according to this rule. This is really no different from any of the several studies that have shown prospective recoding of information in working memory, including the work from the 1990s in nonhuman primates, and several subsequent studies using fMRI in humans beginning in the 2000s. Importantly, this account does not involve dimensionality reduction in any overt way. If it were the case that the more recent computational work indicates that this operation of &quot;prospective recoding&quot; does, in fact, entail dimensionality reduction on this type of task, that would be interesting. However, I don't see evidence that this is the case. Although the authors carry out several analyses of shattering dimensionality, I do not find any that track this measure across epochs within the trial, an approach that would presumably capture epoch-to-epoch dimensionality reduction, if it occurred.</p>
<p>With regard to mischaracterization of a hypothesis, the authors state: &quot;We hypothesised that working memory processes control the dimensionality of neural representations by selecting features for maintenance. We tested this prediction by exploring the learning dynamics of the colour representation.&quot; However, what is described here is not a test of a prediction about dimensionality reduction. Rather, it's a test of a prediction that color decoding would not persist after color offset. To describe this as &quot;dimensionality reduction&quot; misrepresents/mischaracterizes what's happening, which is the translation of color (on any trial, a low-dimensional variable) into the rule that was cued by that color. It is a translation of what kind of information is being represented, as opposed to a dimensionality reduction applied to a representation.</p>
<p>With regard to constructs that don't actually exist, it is unclear what the reality is in the study of a &quot;color pair&quot;? I.e., because colors are never presented together, nor associated in some way, this would seem to be a device that's helpful to the authors for thinking about how their task might be solved, rather than a fundamental aspect of the task that the reader needs to understand. Furthermore, the example given here wasn't helpful for this reader. (What WAS helpful was the description of the two possible strategies and accompanying references to Mayr &amp; Kleigel and to Vandierendonck.)</p>
<p>With regard to logical inconsistencies, one is the notion that color is irrelevant. This is not true, in a literal sense, because if every color cue were rendered as the same monochromatic patch, one wouldn't be able to solve the task. What the authors could do to make their point is perhaps refer to Strategy 1, which corresponds to a less efficient way to solve the task.</p>
<p>Also inconsistent is the relation of the present work to a previous study carried out by this group in nonhuman primates. That task did not include a working memory delay, and so this is difficult to reconcile the comparison that the authors draw with this task with the many suggestions that they make that it's something about WM, per se, that allows for the efficient performance of this task.</p>
<p>&quot;Crucially, the irrelevant feature was only discarded during the delay after it entered working memory.&quot; This statement is in direct contradiction with the authors' own reporting of the results: &quot;Decoding analyses demonstrated that colour information peaked in the early colour locked period of the trial and then rapidly declined over time to reach chance levels before the delay-locked period, 𝑐𝑙𝑢𝑠𝑡𝑒𝑟 1: 0.082 − 0.484 𝑚𝑠, 𝑝 = 0.006 (Fig. 2c).&quot;</p>
<p>Other areas where I had difficulties include:</p>
<p>(1) &quot;These results suggest that participants rapidly discarded irrelevant colour information. Only information relevant for performance (context) entered working memory and was maintained.&quot;</p>
<p>
Although this may be the case, each of the four colors also instructed a rule, and so what's being documented in this study is the translation of a cue into a rule, not the transformation of a &quot;meaningless color&quot; into a &quot;meaningful context.&quot; It is very possible that if the authors only used two colors, one for each rule (i.e., one for each &quot;context&quot;), they'd get the same decoding results.</p>
<p>(2) &quot;A defining characteristic of low-dimensional task representations is that they can be easily cross-generalised to different sensory instances of the same task.&quot;</p>
<p>
This result is difficult to reconcile with the loss of color decoding with color offset. Must it not mean that the rule is being represented differently when cued, e.g., by blue vs. by pink, or by green vs. by khaki? If this is true, then this would also argue against the idea of dimensionality reduction during the delay period, because subjects will, in effect, have swapped needing to represent one of four colors with needing to represent one of four rules.</p>
<p>(3) The authors assert that &quot;cross-colour generalisation of context in the delay period is already implied by the significant context decoding combined with the absence of irrelevant colour coding.&quot;</p>
<p>
This is contradicted, however, by the failure of the direct test of cross-color decoding!</p>
<p>(4) &quot;Taken together, these findings imply that participants constructed abstract representations of task features but that the mechanism responsible for this transformation relied heavily on discarding colour information early in trial time.&quot;</p>
<p>This statement does not follow from the data because no mechanism is being directly measured. Rather, it's simply the case that after translating the color to a rule, the color is no longer needed and so is no longer kept in an active state. There is certainly no evidence for &quot;heavy reliance&quot;.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106609.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Wójcik and colleagues investigated how the maintenance of task information in working memory influences the dimensionality of task representations. The task required an exclusive-or (XOR) mapping as the output by combining stimulus features separated by a delay period. The authors found that context information invariant to input features (i.e., color) is maintained and enhanced over the course of learning the task.</p>
<p>The significance of this study lies in its demonstration of how learning selectively changes the geometry of task representations. The clear-cut results emphasize that learning promotes the abstraction of task representations for context-dependent computations. It is also important to investigate how working memory mechanisms contribute to the geometry and optimization of task representations, as such studies in humans are scarce.</p>
<p>Strengths:</p>
<p>(1) The task design and analyses are clear.</p>
<p>(2) The theoretical motivation to study low-dimensional representations and temporal decomposition is strong. Understanding how learning changes these qualities is a novel and important question.</p>
<p>Weaknesses:</p>
<p>(1) The specific contribution of working memory maintenance to the dimensionality and abstraction of representations is unclear. While the task likely recruits working memory, there are no direct assessments linking the observed results to particular qualities or mechanisms of working memory. In other words, neural representations observed during the delay period are interpreted as working memory.</p>
<p>(2) The dissociation between XOR and motor representations is ambiguous, as they only become distinguishable during error trials. Additionally, they show similar time courses and learning-related changes.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106609.1.sa0</article-id>
<title-group>
<article-title>Author Response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wójcik</surname>
<given-names>Michał J</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3254-8519</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Amy</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wasmuht</surname>
<given-names>Dante</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Stroud</surname>
<given-names>Jake P</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4263-5755</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Stokes</surname>
<given-names>Mark G</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Myers</surname>
<given-names>Nicholas E</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5599-3044</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Hunt</surname>
<given-names>Laurence T</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8393-8533</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1( Public review):</bold></p>
</disp-quote>
<p>The reviewer raised two main concerns: the potential confound between XOR and motor coding, and the relationship between neural coding and behaviour.</p>
<p>First, we appreciate the consideration of the collinearity between the XOR and motor dimensions. We fully agree that this confound may have contributed to the observed increase in XOR decoding over the course of learning. In response, we will merge the XOR and motor features in the main figures, tone down our interpretation of the XOR learning effect, and clarify how motor signals may obscure or mimic XOR-related changes. As the reviewer noted, this confound does not affect the colour/context cross-generalisation analyses, which remain central to our conclusions regarding flexible and prospective working memory coding.</p>
<p>We also thank the reviewer for the suggestion to examine the behavioural relevance of the neural representations more directly. We agree entirely, and will incorporate new analyses relating coding strength to reaction times, as well as reflect on the implications of these results in the revised Discussion.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
</disp-quote>
<p>The reviewer rightly noted that our manuscript overlooks the established concept of retrospective/prospective coding in working memory, giving the impression that we attempted to reframe it using newer machine learning terminology. We thank the reviewer for catching this important omission. Our intention was not to override this well-established conceptual framework with a newer machine learning term, but rather to build upon it. In fact, prospective coding and the idea of working memory as a resource for computation are closely related—one helps define the functions (prospective and retrospective coding) and the other explains the computational rationale behind applying them. For example, prospective codes specify what is being stored (future-relevant information), while the “memory-as-computation” view addresses why such representation is useful: to enable temporal decomposition of complex tasks and reduce computational load at decision time. We will revise the relevant paragraphs to explicitly reference this cognitive framework and clarify how it relates to — and is complemented by — the newer computational perspective we introduce. Thank you again for highlighting this.</p>
<p>Reviewer 2 also argues that the evidence presented does not support dimensionality reduction, noting that participants likely transition from processing the sensory cue (e.g., blue) to a rule-based representation (e.g., context 1 vs context 2) later in the trial, and that this remapping does not inherently require dimensionality reduction. We agree that our results are consistent with such a transformation into an abstract rule representation during the delay period, as supported by the observed cross- colour context generalisation (Figure 3b) and that this process does not require dimensionality reduction per se. However, we would like to clarify that a shared decision boundary between two colour pairs (e.g., context 1 vs context 2) can manifest in two types of neural geometries. In one case — observed in our data — the irrelevant colour dimension is not maintained after the presentation period, such that blue and pink are maintained as context 1 but variance along the blues vs pink dimension is not represented in neural activity. In the other case, it is possible for the same abstract rule (context 1) to be constructed while maintaining the sensory representation of colour (e.g., “blue” or “pink”), resulting in a change in representational geometry without a reduction in dimensionality. Our data do not support the latter scenario: irrelevant colour information is not maintained in the delay period, suggesting that the abstraction is accompanied by a loss of variance along irrelevant sensory dimensions—i.e., a form of dimensionality reduction. We will clarify this point in the revised manuscript and include a new analysis that explicitly tests whether shattering dimensionality changes as a function of trial time.</p>
<p>The reviewer also raised concerns about inconsistencies in our terminology, particularly the use of “colour pair” and “irrelevant colour.” We agree with the reviewer that the term “colour pair” was a conceptual device rather than a literal aspect of the task, and we will revise the text to make this clear. We recognise that our wording around “irrelevant colour” might have caused confusion. We did not mean “colour” in the broad sense of all colour processing, but rather referred to specific colour dimensions that are not relevant for task performance—for example, when context 1 is cued by both pink and blue, the dimension carrying variance between blue and pink can be considered irrelevant. We will clarify this point in the revised manuscript, using the reviewer’s suggestion to incorporate the description we had already provided in the Methods section.</p>
<p>While we respectfully disagree with the reviewer’s interpretation of our findings—particularly regarding the absence of dimensionality reduction, which they associate with the failure of the direct test of cross-colour context decoding (see Fig. 3b, which shows a significant effect)—we appreciate the opportunity to clarify our position and will revise the manuscript to ensure our reasoning is as transparent and rigorous as possible.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (PublIc review):</bold></p>
</disp-quote>
<p>The reviewer values the study’s demonstration that learning promotes abstraction in task representations, but raises concerns about the lack of direct evidence linking delay-period activity to specific working memory mechanisms and the ambiguous dissociation between XOR and motor representations. We thank the reviewer for their careful reading of the manuscript and will address both concerns in the revised version. As mentioned in our response to Reviewer #1, we will merge the motor and XOR analyses, tone down our interpretations, and clarify why these signals are entangled. Additionally, we will link delay-period neural activity to behavioural performance to establish a more direct connection to working memory processes. Notably, in Figure 4f, we show that early in learning, participants who exhibit stronger cross-generalisation of context during the delay are also more likely to exhibit decreased shattering dimensionality at decision time — providing an early link between the preparation of a contextual signal and the subsequent reduction in computational complexity at decision time. We will include additional analyses to further strengthen this link in the revised manuscript.</p>
</body>
</sub-article>
</article>