<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106050</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106050</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106050.3</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.4</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Cross-modal interaction of Alpha Activity does not reflect inhibition of early sensory processing: A frequency tagging study using EEG and MEG</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3461-038X</contrib-id>
<name>
<surname>Brickwedde</surname>
    <given-names>Marion</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>marion.brickwedde@outlook.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Limachya</surname>
    <given-names>Rupali</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5311-8008</contrib-id>
<name>
<surname>Markiewicz</surname>
    <given-names>Roksana</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sutton</surname>
    <given-names>Emma</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Postzich</surname>
    <given-names>Christopher</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0419-1460</contrib-id>
<name>
<surname>Shapiro</surname>
    <given-names>Kimron</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8193-8348</contrib-id>
<name>
<surname>Jensen</surname>
    <given-names>Ole</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5732-7555</contrib-id>
<name>
<surname>Mazaheri</surname>
    <given-names>Ali</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/001w7jn25</institution-id><institution>Department of Child and Adolescent Psychiatry, Charité - Universitätsmedizin Berlin</institution></institution-wrap>, <city>Berlin</city>, <country country="DE">Germany</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05r3f7h03</institution-id><institution>Physikalisch Technische Bundesanstalt</institution></institution-wrap>, <city>Berlin</city>, <country country="DE">Germany</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03angcq70</institution-id><institution>Centre for Human Brain Health, School of Psychology, University of Birmingham</institution></institution-wrap>, <city>Birmingham</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/042t93s57</institution-id><institution>Istituto Italiano di Tecnologia</institution></institution-wrap>, <city>Genova</city>, <country country="IT">Italy</country></aff>
<aff id="a5"><label>5</label><institution>Max-Planck Research Institute</institution>, <city>Leipzig</city>, <country country="DE">Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Groen</surname>
<given-names>Iris IA</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5536-6128</contrib-id><role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution>
</institution-wrap>
<city>Amsterdam</city>
<country country="NL">Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-03-07">
<day>07</day>
<month>03</month>
<year>2025</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-11-07">
<day>07</day>
<month>11</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106050</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-01-29">
<day>29</day>
<month>01</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-07-26">
<day>26</day>
<month>07</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.04.19.488727"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-03-07">
<day>07</day>
<month>03</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106050.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.106050.1.sa4">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106050.1.sa3">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106050.1.sa2">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106050.1.sa1">Reviewer #3 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.106050.1.sa0">Author response:</self-uri>
</event>
<event>
<event-desc>Reviewed preprint v2</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-05-22">
<day>22</day>
<month>05</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106050.2"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.106050.2.sa4">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106050.2.sa3">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106050.2.sa2">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106050.2.sa1">Reviewer #3 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.106050.2.sa0">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Brickwedde et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Brickwedde et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106050-v3.pdf"/>
<abstract><p>Selective attention involves prioritizing relevant sensory input while suppressing irrelevant stimuli. It has been proposed that oscillatory alpha-band activity (∼10 Hz) aids this process by functionally inhibiting early sensory regions. However, recent studies have challenged this notion. Our EEG and MEG studies aimed to investigate whether alpha oscillations serve as a ‘gatekeeper’ for downstream signal transmission. We first observed these effects in an EEG study and then replicated them using MEG, which allowed us to localize the sources.</p>
<p>We employed a cross-modal paradigm where visual cues indicated whether upcoming targets required visual or auditory discrimination. To assess inhibition, we utilized frequency-tagging, simultaneously flickering the fixation cross at 36 Hz and playing amplitude-modulated white noise at 40 Hz during the cue-to-target interval.</p>
<p>Consistent with prior research, we observed an increase in posterior alpha activity following cues signalling auditory targets. However, remarkably, both visual and auditory frequency tagged responses amplified in anticipation of auditory targets, correlating with alpha activity amplitude. Our findings suggest that when attention shifts to auditory processing, the visual stream remains responsive and is not hindered by occipital alpha activity. This implies that alpha modulation does not solely regulate ‘gain control’ in early visual areas but rather orchestrates signal transmission to later stages of the processing stream.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Updated Figure 1
Added SUPPL Figure 13 and 14
Revised the manuscript text slightly to reflect the goal of this study more clearly</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In our daily life, we are often confronted with sensory information from many different sources, all at once. To operate effectively, we require selective attention, reconciling the tension between environmental inputs relevant for top-down goals and sensory information that may be perceptually salient but task-irrelevant. Previous research gave rise to the prominent alpha inhibition hypothesis, which suggests that oscillatory activity in the alpha range (∼10 Hz) plays a mechanistic role in selective attention through functional inhibition of irrelevant cortical areas (see <xref rid="fig1" ref-type="fig">Fig. 1</xref>; <xref ref-type="bibr" rid="c17">Foxe et al., 1998</xref>; <xref ref-type="bibr" rid="c28">Jensen &amp; Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="c32">Klimesch et al., 2007</xref>). Functional inhibition refers to an area of the cortex being actively hindered to process input, which is distinctly different from idling, where a part of the cortex is not actively involved. Evidence supporting this theory revealed an increase in alpha-power over task-irrelevant sensory cortices after the onset of cues indicating the spatial location (<xref ref-type="bibr" rid="c30">Kelly et al., 2006</xref>; <xref ref-type="bibr" rid="c41">Okazaki et al., 2014</xref>; <xref ref-type="bibr" rid="c56">Thut et al., 2006</xref>; <xref ref-type="bibr" rid="c66">Worden et al., 2000</xref>; <xref ref-type="bibr" rid="c71">Zumer et al., 2014</xref>) or specific modality of an upcoming target (<xref ref-type="bibr" rid="c17">Foxe et al., 1998</xref>; <xref ref-type="bibr" rid="c19">Fu et al., 2001</xref>; <xref ref-type="bibr" rid="c36">Mazaheri et al., 2014</xref>). Moreover, previous investigations have observed ‘spontaneous fluctuations’ of alpha power in sensory regions, particularly in the visual cortex, to be inversely related to discrimination ability (<xref ref-type="bibr" rid="c16">Ergenoglu et al., 2004</xref>; <xref ref-type="bibr" rid="c65">Van Dijk et al., 2008</xref>). Alpha inhibition is believed to be transmitted in a phasic manner, as phosphene perception as well as high-frequency and spiking activity vary in line with the alpha cycle (<xref ref-type="bibr" rid="c15">Dugué et al., 2011</xref>; <xref ref-type="bibr" rid="c23">Haegens et al., 2011</xref>; <xref ref-type="bibr" rid="c52">Spaak et al., 2012</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Illustration of the alpha inhibition hypothesis.</title>
<p>The alpha inhibition hypothesis suggests that occipital alpha inhibits visual information processing in a phasic manner. If alpha activity is high, it suggests that neural processing in the cortical area is inhibited (<xref ref-type="bibr" rid="c17">Foxe et al., 1998</xref>; <xref ref-type="bibr" rid="c28">Jensen &amp; Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="c32">Klimesch et al., 2007</xref>). We propose a revision of this hypothesis, whereby alpha activity exerts its phasic inhibition to regulate information transfer, creating enhanced signal packages of prioritised information (see also <xref ref-type="bibr" rid="c68">Yang et al., 2023</xref>; <xref ref-type="bibr" rid="c70">Zhigalov &amp; Jensen, 2020</xref>; <xref ref-type="bibr" rid="c71">Zumer et al., 2014</xref>). This way, irrelevant or distracting information is inhibited through a block of transfer, rather than through blocking of incoming sensory information.</p></caption>
<graphic xlink:href="488727v4_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Recent evidence challenged a direct connection between alpha activity and visual information processing in early visual cortex. As such, both visual steady-state responses and alpha power were modulated by attention but did not covary when investigating individual trials (<xref ref-type="bibr" rid="c70">Zhigalov &amp; Jensen, 2020</xref>). Unfortunately, very few studies have investigated direct connections between alpha activity, attention and sensory signals, especially over trials. Furthermore, results seem to depend on timing of alpha activity in relation to sensory responses as well as stimulus type and outcome measure (<xref ref-type="bibr" rid="c37">Morrow et al., 2023</xref>).</p>
<p>Accordingly, the objective of the current study is to test the alpha inhibition hypothesis compared to an alternative theory. Based on the alpha inhibition hypothesis, alpha modulation is connected to ‘gain control’ in early visual areas through modulation of excitability (<xref ref-type="bibr" rid="c18">Foxe &amp; Snyder, 2011</xref>; <xref ref-type="bibr" rid="c28">Jensen &amp; Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="c63">Van Diepen et al., 2019</xref>). In contrast, we propose that functional and inhibitory effects of alpha modulation, such as distractor inhibition, are exhibited through blocking or facilitating signal transmission to higher order areas (<xref ref-type="bibr" rid="c43">Peylo et al., 2021</xref>; <xref ref-type="bibr" rid="c68">Yang et al., 2023</xref>; <xref ref-type="bibr" rid="c70">Zhigalov &amp; Jensen, 2020</xref>; <xref ref-type="bibr" rid="c71">Zumer et al., 2014</xref>), gating feedforward or feedback communication between sensory areas (see <xref rid="fig1" ref-type="fig">Fig. 1</xref>; <xref ref-type="bibr" rid="c3">Bauer et al., 2020</xref>; <xref ref-type="bibr" rid="c22">Haegens et al., 2015</xref>; <xref ref-type="bibr" rid="c61">Uemura et al., 2021</xref>).</p>
<p>To this end, we applied frequency-tagging, the rhythmic presentation of sensory stimuli, which elicits steady-state sensory evoked potentials or fields (SSEP/SSEF), consisting of rhythmic neuronal activity in the frequency of stimulation (<xref ref-type="bibr" rid="c5">Brickwedde et al., 2020</xref>; <xref ref-type="bibr" rid="c8">Colon et al., 2012</xref>; <xref ref-type="bibr" rid="c11">Dinse et al., 1998</xref>; <xref ref-type="bibr" rid="c35">Marzoll et al., 2018</xref>; <xref ref-type="bibr" rid="c47">Regan, 1982</xref>; <xref ref-type="bibr" rid="c51">Snyder, 1992</xref>; <xref ref-type="bibr" rid="c55">Stapells et al., 1984</xref>; <xref ref-type="bibr" rid="c57">Tobimatsu et al., 1999</xref>). The magnitude of SSEPs is attention-dependent (<xref ref-type="bibr" rid="c10">de Jong et al., 2010</xref>; <xref ref-type="bibr" rid="c39">Müller et al., 1998</xref>; <xref ref-type="bibr" rid="c38">Müller &amp; Hillyard, 2000</xref>; <xref ref-type="bibr" rid="c46">Porcu et al., 2013</xref>; <xref ref-type="bibr" rid="c48">Saupe et al., 2009</xref>; <xref ref-type="bibr" rid="c58">Toffanin et al., 2009</xref>) even for frequencies too fast to perceive consciously (<xref ref-type="bibr" rid="c4">Brickwedde et al., 2022</xref>; <xref ref-type="bibr" rid="c69">Zhigalov et al., 2019</xref>). Visual SSEP/SSEFs are most strongly observable over occipital areas, whereas auditory SSEP/SSEFs appear most strongly over temporal (MEG) or fronto-to-central (EEG) areas (<xref ref-type="bibr" rid="c10">de Jong et al., 2010</xref>; <xref ref-type="bibr" rid="c24">Hari et al., 1989</xref>; <xref ref-type="bibr" rid="c42">Pantev et al., 1996</xref>; <xref ref-type="bibr" rid="c47">Regan, 1982</xref>). Furthermore, when applying two different frequencies for two different sensory modalities, their intermodulation frequency (f1-f2) has been suggested to reflect cross-modal integration (<xref ref-type="bibr" rid="c12">Drijvers et al., 2021</xref>). Due to distinct responses, localisation and attention-dependence, frequency-tagging provides an optimal tool to study sensory signal processing and integration over time.</p>
<p>The aim of our study was to directly test the alpha inhibition hypothesis by investigating if cue-induced modulation of alpha activity coincides with the suppression of frequency-tagging responses in task-irrelevant modalities. Based on previous studies, we utilized a cross-modal attention paradigm, in which symbolic visual cues signalled the target modality (visual or auditory) of an upcoming discrimination task (e.g., <xref ref-type="bibr" rid="c62">van Diepen et al., 2015</xref>). Here, we included an additional experimental manipulation in the form of frequency-tagging to assess the involvement of the auditory and visual systems in the <italic>cue-to-target interval</italic>.</p>
<p>In line with previous results, we hypothesized that signalling an upcoming auditory target would lead to increased alpha activity over visual occipital regions as well as increased SSEP responses to auditory and decreased SSEP to visual stimuli as indexed by frequency-tagging. In brief, while we observed the expected cue-induced early-visual alpha modulation, the amplitude of auditory and <italic>visual</italic> SSEP/SSEFs as well as their intermodulation frequency increased just prior to the onset of the auditory target, contradicting the alpha inhibition hypothesis. The difference between conditions of visual SSEP/SSEFs originated from sensory integration areas and correlated with early sensory alpha activity on a trial-by-trial basis, speaking to an effect of alpha modulation on signal transmission rather than inhibition of early visual areas.</p>
</sec>
<sec id="s2">
<title>Results Study 1 – cross-modal EEG experiment</title>
<p>To assess audio-visual excitability in anticipation of either visual or auditory targets, we displayed visual cues to signal the modality of the upcoming target (auditory, visual, or non-specific). In a three-second cue-to-target interval, we frequency-tagged the fixation cross at 36 Hz and played 40 Hz amplitude modulating white noise. Immediately afterwards, participants had to either discriminate between three different pitch sounds (auditory target) or three different Gabor patch orientations (visual target). If the target modality was cued (e.g. not non-specific), 50% of the trials were accompanied by a random distractor from the target pool of the opposing sensory modality (see <xref rid="fig2" ref-type="fig">Fig. 2A</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption>
    <p>A, Illustration of the cross-model discrimination task in Study 1. Trials were separated by a 4 s interval, in which a fixation cross was displayed. A brief central presentation of the cue (100 ms) initiated the trial, signalling the target modality (see figure above from left to right: auditory, non-specific, visual). In the cue-to-target interval, the fixation cross was frequency-tagged at 36 Hz. At the same time, a sound was displayed over headphones, which was frequency-tagged at 40 Hz. Both tones and fixation cross contained no task-relevant information. The target, consisting either of a static Gabor patch or a tone, was presented for 25 ms. Participants had to differentiate via button presses between 3 different Gabor rotations or tone pitches, respectively. In 50% of auditory and visually cued trials, a distractor in form of a random pitch or rotation of the un-cued modality was presented alongside the target. <bold>B-C</bold>, Analysis of task accuracy and reaction time indicates increased difficulty of auditory targets. <bold>B</bold>, Task accuracy compared between all 6 experimental conditions reveals a drop in accuracy for responses to auditory targets. <bold>C</bold>, reaction times of correct trials compared between all 6 experimental conditions. The slowest reaction times are observable following auditory targets alongside visual distractors. N = 22; *** sig &lt; .001; ** sig. &lt; .01; * sig. &lt; .05;</p></caption>
<graphic xlink:href="488727v4_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s2a">
<title>Behavioural performance</title>
<p>We found that accuracy differed significantly between conditions (F<sub>(5,105)</sub> = 44.16; <italic>p</italic> &lt; .001). Overall, participants were significantly less accurate in the auditory discrimination task (‘overall auditory’, <italic>M</italic> = 79% correct, <italic>SD</italic> = 11.7) than in the visual discrimination task (‘overall visual’, <italic>M</italic> = 97%, <italic>SD</italic> = 2.3; see <xref rid="fig2" ref-type="fig">Fig. 2B</xref>), with the worst performance occurring when auditory targets were paired with visual distractors (auditory +: <italic>M</italic> = 74% correct, <italic>SD</italic> = 13).</p>
<p>Reaction times yielded a similar pattern, with auditory reactions (overall auditory: <italic>M</italic> = 662 ms, <italic>SD</italic> = 136) being slower than for the visual task (overall visual: <italic>M</italic> = 597 ms, <italic>SD</italic> = 130; main effect over all conditions: F<sub>(5,105)</sub> = 27.47; <italic>p</italic> &lt; .001; see <xref rid="fig2" ref-type="fig">Fig. 2C</xref>). This was mostly driven by slow responses to auditory targets paired with distractors (auditory +: <italic>M</italic> = 723 ms).</p>
<p>To ascertain that cues and distractors were functionally relevant, we calculated attentional benefit (cued - non-specific condition) and distractor cost (cued condition with distractor – cued condition without distractor). As expected, cues improved reaction times over all conditions and distractors impaired the accuracy over all conditions and reaction times for auditory targets. (see <xref rid="figs1" ref-type="fig">suppl Fig. 1</xref>). Interestingly, auditory distractors reduced reaction times to visual targets, which could be explained by a generally faster processing of auditory targets (<xref ref-type="bibr" rid="c27">Jain et al., 2015</xref>). As such, the auditory distractor possibly caused intersensory facilitation (<xref ref-type="bibr" rid="c40">Nickerson, 1973</xref>), whereby reaction times to a target can be facilitated when accompanied by stimuli of other sensory modalities, even if they are irrelevant or distracting.</p>
</sec>
<sec id="s2b">
<title>Cross-modal cues differentially modulated pre-target alpha activity</title>
<p>We conducted a time-frequency analysis of power in the cue-to-target interval and found a stronger amplitude increase from baseline for auditory compared to visual target conditions starting around 2 s before target onset (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). We calculated the time course of alpha power changes using the Hilbert-transformation (8 – 12 Hz, <xref rid="fig3" ref-type="fig">Fig. 3A-B</xref>). We then applied cluster permutation analysis, whereby real condition differences were tested against coincidental findings by randomly permutating the condition labels to the data and testing for condition differences 1000 times (<xref ref-type="bibr" rid="c34">Maris &amp; Oostenveld, 2007</xref>). Consistent with previous work (<xref ref-type="bibr" rid="c36">Mazaheri et al., 2014</xref>; <xref ref-type="bibr" rid="c64">van Diepen &amp; Mazaheri, 2017</xref>), analysing the last two seconds before target onset revealed two significant clusters of difference in alpha power when expecting an auditory compared to a visual target. These effects corresponded to clusters extending from −1.84 to – 0.64 s (<italic>p</italic> = .004) and −0.62 to 0s (<italic>p</italic> = .005). When presenting non-specific cues, alpha power changes were not significant, but descriptively larger compared to visual target conditions and lower compared to auditory target conditions (see <xref rid="figs2" ref-type="fig">suppl Fig. 2</xref>). However as significant alpha modulation was a prerequisite to test our hypotheses, we excluded this condition from further analysis.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Post-cue modality specific modulation of alpha power in anticipation of an auditory versus a visual target</title>
    <p><bold>A</bold>-<bold>B</bold>, the time course of post-cue alpha power. Cluster permutation analysis resulted in two condition effects, both indicating heightened alpha activity when expecting an auditory compared to a visual target (A: <italic>p</italic> &lt; .01; B: <italic>p</italic> &lt; .01). <bold>C-D</bold>, Time-frequency representation of power in the cue-to-target interval. A greater increase in alpha power was observed when expecting an auditory target (average over significant electrodes for the condition difference in A). <italic>note</italic>: Cluster electrodes are marked in white. Shading represents standard error from the mean; Δ / ∑ represents (a-b)/(a+b) normalization.</p></caption>
<graphic xlink:href="488727v4_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Cross-modal cues increased the amplitude of the frequency-tagged responses across both modalities</title>
<p>To assess the temporal development of frequency-tagging responses, steady-state potentials were calculated using data band-pass filtered around the tagging frequency. Neuronal 40 Hz auditory-steady state evoked potential (ASSEP) responses were strongest over central areas (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>), and 36 Hz auditory-steady state evoked potential (VSSEP) responses were strongest over occipital areas (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Increase in amplitude of both visual and auditory frequency tagged responses when anticipating visual or auditory targets.</title>
    <p>Event-related potentials and scalp topographies reveal distinct modality specific responses at the tagged frequencies. <bold>A</bold>, auditory steady-state evoked potential (ASSEP) averaged over 6 central electrodes displaying the highest 40 Hz power (Cz, FC1, FC2, C1, C2, FCz; marked with white squares). <bold>B</bold>, visual steady-state evoked potential (VSSEP) averaged over 4 occipital electrodes displaying the highest 36 Hz power (POz, O1, O2, Oz; marked with white squares) <bold>C</bold>, the Hilbert-envelope of the 40 Hz ASSEP reveals an increase shortly before target onset when anticipating an auditory compared to a visual target (<italic>p</italic> = .041); <bold>D</bold>, the Hilbert-envelope of the 36 Hz VSSEP likewise reveals an increase shortly before target onset when anticipating an auditory compared to a visual target (<italic>p</italic> = .014). <italic>note</italic>: Cluster electrodes are marked in white. Shading represents standard error from the mean. Δ / ∑ represents (a-b)/(a+b) normalization.</p></caption>
<graphic xlink:href="488727v4_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To assess the differences between conditions, the Hilbert envelope of the steady-state potentials was analysed using cluster permutation analyses. When expecting an auditory target compared to a visual target, the 40 Hz ASSEP response was larger shortly before target onset (see <xref rid="fig4" ref-type="fig">Fig. 4C</xref>; −0.15 to −0.08 s; <italic>p</italic> = .041).</p>
<p>Surprisingly, the 36 Hz VSSEP response was likewise increased shortly before expecting an auditory compared to a visual target (see <xref rid="fig4" ref-type="fig">Fig. 4D</xref>; −0.16 to −0.06 s; <italic>p</italic> = .014). As such, the observed frequency tagging responses might reflect effort, which affects the vigilance of the whole sensory system rather than sensory-specific allocations of attention. For both 36 Hz VSSEP and 40 Hz ASSEP responses, condition differences appeared strongest over mid-parietal regions in contrast to primary sensory cortices.</p>
</sec>
<sec id="s2d">
<title>Alpha power was positively correlated with amplitude of frequency tagged responses</title>
<p>Following the observation of condition differences in alpha activity and frequency-tagging responses, we were further interested in exploring whether these responses were connected. Accordingly, we conducted trial-by-trial correlations using alpha condition differences and their electrode positions as seed, which was correlated with frequency-tagging signals over all electrodes. Multiple comparison correction was applied by testing the correlation matrix against a zero-correlation matrix with a cluster permutation approach. A positive correlation was observed over right parietal-to-occipital areas between the late alpha cluster activity and both 40 Hz ASSEP (<italic>p</italic> = .009) and 36 Hz VSSEP (<italic>p</italic> = .004) responses when expecting a visual target (see <xref rid="fig5" ref-type="fig">Fig. 5.A-B</xref>). To estimate the robustness of these results, we additionally conducted median split analyses between trials with high and low alpha power for each participant, as well as averaged the correlation coefficient of each participant and calculated a one-sample t-test against 0. For each analysis we provided the Bayes Factor, which estimates the strength of support for or against the null hypothesis (BF &gt; 3.2 is considered as substantial evidence and BF &gt; 10 is considered as strong evidence; <xref ref-type="bibr" rid="c29">Kass &amp; Raftery, 1995</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Relationship between cue induced alpha modulation and amplitude of frequency tagged responses in study 1.</title>
    <p>Previously obtained alpha clusters (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>) were correlated over trials with auditory 40 Hz and visual 36 Hz clusters (see <xref rid="fig4" ref-type="fig">Fig. 4</xref>), where alpha electrodes/sensors were applied as seeds. The analysis was performed using a cluster-permutation approach, testing a correlation model against a 0-correlation model. Clusters significantly diverging from the 0-correlation model are presented topographically. Additionally, median splits between high and low alpha trials as well as correlation coefficients of these clusters are displayed for all participants <bold>A</bold>-<bold>B</bold>, a positive correlation is visible between alpha activity in the last 400 ms and steady state potentials shortly before target onset when expecting a visual target (visual 36 HZ: <italic>p</italic> = .013; 40 Hz: <italic>p</italic> = .009). <bold>D</bold>, when expecting an auditory target, there is a positive correlation between alpha activity in the last 400 ms and visual 36 Hz activity shortly before target onset (<italic>p</italic> = .010). <bold>E</bold>, the correlation between alpha activity 400 ms and visual 36 Hz activity shortly before target onset changes its direction depending on whether an auditory or a visual target is expected (<italic>p</italic> = .037). <bold>C</bold>, a positive correlation is also visible between alpha activity as early as ∼1200 ms to 400 ms and visual 36 Hz activity shortly before target onset when expecting a visual target (<italic>p</italic> = .016). N = 22; *** sig &lt; .001; ** sig &lt; .01; * sig &lt; .05. + sig. &lt; .1</p></caption>
<graphic xlink:href="488727v4_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The median split was highly significant for the 36 Hz VSSEP response (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>, middle columns, <italic>p</italic> = .033; <italic>t</italic><sub>(19)</sub> = 2.29; BF<sub>(10)</sub> = 1.91) but did not reach significance for the 40 Hz ASSEP response (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>, middle column; <italic>p</italic> = 0.20; <italic>t</italic><sub>(19)</sub> = 1.32; BF<sub>(10)</sub> = 0.49). Correlation coefficients indicated strong correlations with alpha activity for both 40 Hz ASSEP (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>, right column; <italic>p</italic> &lt; .001; <italic>t</italic><sub>(19)</sub> = 4.95; BF<sub>(10)</sub> = 306.93) and 36 Hz VSSEP activity (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>, right column; <italic>p</italic> &lt; .01; <italic>t</italic><sub>(19)</sub> = 3.66; BF<sub>(10)</sub> = 23.57).</p>
<p>The same positive correlation with alpha activity was found when expecting an auditory target for 36 Hz VSSEP activity (<italic>p</italic> = .031), but not for 40 Hz ASSEP activity (see <xref rid="fig5" ref-type="fig">Fig. 5D</xref>). A median split between high and low alpha activity (<italic>p</italic> = .005; <italic>t</italic><sub>(19)</sub> = 3.14; BF<sub>(10)</sub> = 8.53) and correlation coefficients (<italic>p</italic> = .002; <italic>t</italic><sub>(19)</sub> = 3.52; BF<sub>(10)</sub> = 17.76) provided moderate to strong evidence for this effect. The likely origin of alpha modulations from early visual cortices may explain a stronger connection to 36 Hz VSSPE responses compared to 40 Hz ASSEP responses.</p>
<p>Additionally, we compared how correlation coefficients between alpha activity and frequency-tagging differed when anticipating an auditory versus a visual target. Multiple comparison correction was applied with cluster permutation analysis. Interestingly, an interaction between the strength of the correlation associating alpha, 36 Hz VSSEP activity and condition became apparent (<italic>p</italic> = .044; <italic>see</italic> <xref rid="fig5" ref-type="fig">Fig. 5E</xref>) and was observed most strongly over right-central electrodes. Comparing the correlation coefficients of participants over this cluster revealed a strong effect and even a change of direction in the correlation (<italic>p</italic> &lt; .001; <italic>t</italic><sub>(21)</sub> = −4.76; BF<sub>(10)</sub> = 259.97). Particularly, when expecting a visual target, there was a negative correlation between 36 Hz VSSEP and alpha activity, which turned positive when expecting an auditory target. Both correlations also differed significantly from 0 (expecting a visual target: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(21)</sub> = −3.87; BF<sub>(10)</sub> =39.62; expecting an auditory target: <italic>p</italic> = .020; <italic>t</italic><sub>(21)</sub> = 2.53; BF<sub>(10)</sub> =2.83). In contrast to the previously observed positive correlation between alpha activity and 36 Hz VSSEP activity, the significant electrode cluster was located more ventrally. This effect could possibly hint at dynamic adaptability of oscillatory alpha effects on later processing stages.</p>
<p>It is further noteworthy that the correlation between alpha activity and 36 Hz VSSEP response when expecting a visual target, was also present when utilizing the early alpha cluster as seed (∼ 1200 to 400 ms before target onset, see <xref rid="fig5" ref-type="fig">Fig. 5C</xref>), in which case alpha modulation greatly preceded the 36 Hz VSSEP modulation (<italic>p</italic> = .016<italic>)</italic>. For this correlation, the median split between high and low alpha trials did not reach significance (<italic>p</italic> = .11; <italic>t</italic><sub>(20)</sub> = 1.69; BF<sub>(10)</sub> =0.76), however testing the correlation coefficients against 0 again revealed a significant effect (<italic>p</italic> = .003; <italic>t</italic><sub>(20)</sub> = 3.39; BF<sub>(10)</sub> =14.22). This result may support the directionality of alpha modulation affecting visual information processing (and not vice versa).</p>
</sec>
<sec id="s2e">
<title>Intermodulation frequency</title>
<p>Lastly, we analysed the steady-state response of the intermodulation frequency at 4 Hz. Increased intermodulation shortly before target onset could be observed when expecting an auditory compared to a visual target (−0.51 to −0.0620; <italic>p</italic> &lt; .001). This effect was strongest over left fronto-to-central electrodes and right central-to-occipital electrodes (see <xref rid="fig6" ref-type="fig">Fig. 6A</xref>) and may suggest in increase in cross-modal integration.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Steady-state response in the intermodulation frequency and its behavioural relevance.</title>
    <p><bold>A</bold>, the Hilbert-envelope of the 4 Hz steady-state response reveals an increase shortly before target onset when anticipating an auditory compared to a visual target (<italic>p</italic> &lt; .01). <bold>B</bold>, there is a trial-by-trial correlation between 4 Hz activity and reaction time when a visual target without distractor was presented. The correlation is further illustrated by a median split between fast and slow reaction time trials as well as by correlation coefficients for each participant. N = 22; ** sig. &lt; .01;</p></caption>
<graphic xlink:href="488727v4_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>With the goal to examine whether there are any behavioral effects of the condition difference, trial by trial correlations with reaction times of each of the 2 auditory and visual conditions were performed. Only in the easiest condition, when expecting a visual target that was not accompanied by a distractor, a negative correlation with reaction time could be found, strongest over right central electrodes (see <xref rid="fig6" ref-type="fig">Fig. 6B</xref>; <italic>p</italic> = .046). While a median split between slow and fast trials did not reach significance (<italic>p</italic> = .50; <italic>t</italic><sub>(21)</sub> = −0.69; BF<sub>(10)</sub> = .28), testing the correlation coefficients against 0 revealed strong evidence for a correlation (<italic>p</italic> = .004; <italic>t</italic><sub>(21)</sub> = −3.28; BF<sub>(10)</sub> = 11.98). If the intermodulation frequency reflects cross-modal integration (<xref ref-type="bibr" rid="c12">Drijvers et al., 2021</xref>), this effect would indicate faster reaction times for trials with stronger sensory integration.</p>
</sec>
</sec>
<sec id="s3">
<title>Results Study 2 – cross-modal MEG experiment</title>
<p>To test the robustness of our results and to employ additional control analyses, we replicated our experiment using MEG (see <xref rid="fig7" ref-type="fig">Fig. 7A</xref>). While an increase in visual information processing parallel to an increase in alpha modulation already contradicts the notion of alpha inhibition exerting “gain control”, affecting the whole visual cortex, our claim that alpha modulation instead affects visual information at later processing stages still required further validation. As such, our goal was to perform source analyses showing alpha modulation originating from primary visual areas affected visual information at later processing stages (e.g. not in primary visual cortex). Additionally, to exclude that the uncertainty over possible distractors affected our results, we employed a block design, where block 1 consisted only of trials without distractors and in block 2 targets were always accompanied by a distractor. Furthermore, we aligned the visual and auditory task to be more similar, both of them now featuring frequency-discrimination, which related to sound pitch (frequency) in the auditory condition and stripe-frequency of the Gabor patch in the visual condition. Lastly, to make sure our effects were driven by sensory modality-differences rather than task-difficulty differences, we included a short calibration phase. Prior to the experiment, difficulty of pitch sounds, and Gabor patch frequency were calibrated for each individual, ascertaining a success rate between 55% to 75%.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption>
    <p>A, Illustration of the cross-model discrimination task in Study 2. Trials were separated by a 1-1.3 s interval, in which a fixation cross was displayed. A brief central presentation of the cue (100 ms) initiated the trial, signalizing the target modality (from left to right: auditory, visual). In the cue-to-target interval, the fixation cross was frequency-tagged at 36 Hz. At the same time, a sound was displayed over headphones, which was frequency-tagged at 40 Hz. Both tones and fixation cross contained no task-relevant information. The target, consisting either of a static Gabor patch or a tone, was presented for 25 ms. Participants had to differentiate via button presses between 3 different Gabor stripe frequencies or tone pitches, respectively. In block 2, a distractor in form of a random sound or Gabor patch of the un-cued modality was always presented alongside the target. <bold>B-C</bold>, analysis of task accuracy and reaction time indicates comparable difficulties in block 2. <bold>B</bold>, task accuracy differences were only observable in the first block without distractors. <bold>C</bold>, reaction times to visual targets in the first block were strongly increased compared to all other conditions. In the second block, no significant difference in reaction times was observable. N = 27; *** sig &lt; .001; ** sig. &lt; .01; * sig. &lt; .05;</p></caption>
<graphic xlink:href="488727v4_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s3a">
<title>Behavioural performance</title>
<p>Our adjustments in the MEG-study streamlined performances to be more in line between auditory and visual conditions in the second block, however in the first block there were strong condition differences (Main effect condition: (F<sub>(3,75)</sub> = 10.26; <italic>p</italic> &lt; .01). In block 1, participants were significantly more accurate in the auditory (‘block 1 auditory’, <italic>M</italic> = 84% correct, <italic>SD</italic> = 10.03) compared to the visual task (‘block 1 visual’, <italic>M</italic> = 70%, <italic>SD</italic> = 10.61; see <xref rid="fig7" ref-type="fig">Fig. 7B</xref>). However, in block 2, there was no observable difference between visual and auditory task accuracy (‘block 2 auditory’, <italic>M</italic> = 77% correct, <italic>SD</italic> = 10.03; (‘block 2 visual’, <italic>M</italic> = 78%, <italic>SD</italic> = 13.15). Reaction times were comparable between conditions (overall: <italic>M</italic> = 661 ms, <italic>SD</italic> = 76), with the exception of responses to visual targets in block 1 (block 1 visual: <italic>M</italic> = 726 ms, <italic>SD</italic> = 85), which were significantly slower than all other reaction times (main effect condition: F<sub>(3,75)</sub> = 18.13; <italic>p</italic> &lt; .001; see <xref rid="fig7" ref-type="fig">Fig. 7C</xref>).</p>
<p>Due to the block design, distractor cost could not be differentiated from learning effects. For auditory targets, there was a significant decrease in accuracy between block 1 and 2, while for visual targets, there was a significant increase. Similar to study 1, reaction times for auditory targets stayed roughly the same, but became shorter for visual targets (see <xref rid="figs1" ref-type="fig">suppl Fig. 1</xref>).</p>
</sec>
<sec id="s3b">
<title>Cross-modal cues differentially modulated pre-target alpha activity in early visual areas</title>
<p>In line with previous studies (<xref ref-type="bibr" rid="c64">van Diepen &amp; Mazaheri, 2017</xref>), condition differences in alpha activity were only significant in block 2, where distractors were always present. As alpha modulation was a prerequisite to test our hypotheses, we performed the following analyses solely with data from block 2 (see <xref rid="fig8" ref-type="fig">Fig. 8</xref>).</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Post-cue modality specific early visual modulation of alpha power in anticipation of an auditory versus a visual target</title>
    <p><bold>A</bold>, the time course of post-cue alpha power. Cluster permutation analysis resulted in a condition effects, indicating heightened alpha activity when expecting an auditory compared to a visual target (<italic>p</italic> = .034). <bold>B</bold>, source localization of the condition difference between expecting an auditory versus a visual target, revealing a significant cluster in early visual areas with stronger effects on the right hemisphere (<italic>p</italic> &lt; .01). <bold>C-D</bold>, Time-frequency representation of power in the cue-to-target interval (average over electrodes that showed maximal condition difference in A). <italic>note</italic>: Cluster electrodes are marked in white. Shading represents standard error from the mean; Δ / ∑ represents (a-b)/(a+b) normalization.</p></caption>
<graphic xlink:href="488727v4_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Replicating our results from study 1, cluster permutation on the Hilbert-transformed alpha activity revealed a significant cluster between −1.47 to −1.18 s (p = .034), where alpha change from baseline was higher when expecting an auditory compared to a visual target (see <xref rid="fig8" ref-type="fig">Fig. 8A</xref>). Applying roughly the cluster time-window (−1.5 and −1 s), we conducted a source localization, contrasting the two conditions with cluster permutation analysis. We found that condition differences in alpha activity originated from early visual areas, albeit with a stronger effect on the right compared to the left hemisphere (p &lt; .01; peak spm coordinates: 41 −82 −19 mm, in the right lingual gyrus see <xref rid="fig8" ref-type="fig">Fig. 8B</xref>). Additionally, we replicated this effect with a virtual channel analysis in V1 (see SUPPL Fig. 12)</p>
</sec>
<sec id="s3c">
<title>Cross-modal cues increased the amplitude of the frequency-tagged responses across both modalities</title>
<p>In accordance with study 1, neuronal responses to 40 Hz auditory steady-state evoked field (ASSEF) responses were strongest over temporal areas (<xref rid="fig9" ref-type="fig">Fig. 9A</xref>) and 36 Hz visual steady-state evoked field (VSSEF) responses were strongest over occipital areas (<xref rid="fig9" ref-type="fig">Fig. 9C</xref>). As expected, the auditory tagging response originated from the right-hemispheric early auditory cortex (cluster significance: <italic>p</italic> &lt; .01; peak spm coordinates: 69 −22 5 mm, in the right superior temporal gyrus; see <xref rid="fig9" ref-type="fig">Fig. 9B</xref>) and the visual tagging response originated from the early visual cortex (cluster significance: <italic>p</italic> &lt; .001; peak spm coordinates: 19 −105-11 mm, in the right lingual gyrus; see <xref rid="fig9" ref-type="fig">Fig. 9D</xref>). Additionally, we observed significantly reduced 40 Hz activity in the left-hemispheric visual-to-central cortex (cluster significance: <italic>p</italic> &lt; .01).</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><title>Post-cue modality specific early visual modulation of alpha power in anticipation of an auditory versus a visual target.</title>
    <p><bold>A</bold>, auditory steady-state evoked fields (ASSEF) averaged over 24 temporal sensors displaying the highest auditory 40 Hz power (12 right, 12 left; marked in white squares). <bold>B</bold>, ASSEF source localization revealed a significant positive cluster in the right-hemispheric early auditory cortex (<italic>p</italic> &lt; .001). <bold>C</bold>, visual steady-state evoked fields (VSSEF) averaged over 10 occipital sensors, displaying the highest visual 36 Hz power (marked in white squares). <bold>D</bold>, VSSEF source localization revealed a significant positive cluster in the early visual cortex (<italic>p</italic> &lt; .001). <bold>E</bold>, the Hilbert-envelope of the 40 Hz ASSEF reveals an increase shortly before target onset when anticipating an auditory compared to a visual target (<italic>p</italic> = .043); <bold>F</bold>, condition differences in the 40 Hz ASSEF response did not reach significance in sensor space. <bold>G</bold>, the Hilbert-envelope of the 36 Hz VSSEF likewise reveals an increase shortly before target onset when anticipating an auditory compared to a visual target (<italic>p</italic> = .019). <bold>H</bold>, condition differences in the 36 Hz VSSEF response were significant over several areas of the visual stream, including most strongly the medial occipital cortex, the calcarine fissure, and the precuneus (<italic>p</italic> = .047); <italic>note</italic>: Cluster electrodes are marked in white. Shading represents standard error from the mean. Δ / ∑ represents (a-b)/(a+b) normalization.</p></caption>
<graphic xlink:href="488727v4_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Applying cluster permutation on the Hilbert-transformed frequency-tagging data over the last 500 ms before target onset replicated the results of study 1, where both 36 Hz VSSEF as well as 40 Hz ASSEF signals were significantly enhanced when expecting an auditory compared to a visual target (see <xref rid="fig9" ref-type="fig">Fig. 9E-G</xref>; auditory target: <italic>p</italic> = .043; visual target: <italic>p</italic> = .019).</p>
<p>Source localization confirmed the condition difference in 36 Hz VSSEF activity to originate from later stages of the processing stream, encompassing a wide range of areas, most strongly the medial occipital cortex and the precuneus (cluster significance: <italic>p</italic> = .047; peak spm coordinates: 3 −66 44 mm, in the left and right precuneus; see <xref rid="fig9" ref-type="fig">Fig. 9H</xref>). In source space, the effect was not significant for auditory 40 Hz activity (p = .11; peak spm coordinates: −9 −39 0 mm, in the left precuneus; see <xref rid="fig9" ref-type="fig">Fig. 9F</xref>). Furthermore, a virtual channel analysis in V1 and Heschl’s gyrus confirmed that there were no condition differences in primary visual and auditory areas (see SUPPL Fig. 12).</p>
</sec>
<sec id="s3d">
<title>Alpha power was positively correlated with amplitude of frequency tagged responses</title>
<p>The positive correlations between alpha power and frequency-tagging amplitude observed in study 1 could be replicated. Alpha activity 500 ms before target onset correlated both with 36 Hz VSSEF and 40 Hz ASSEF activity when expecting a visual target (see <xref rid="fig10" ref-type="fig">Fig. 10A-B</xref>, 36 Hz response: cluster significance: <italic>p</italic> &lt; .01; median split: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(24)</sub> = 4.33; BF<sub>(10)</sub> = 127; t-test: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(24)</sub> = 5.33; BF<sub>(10)</sub> = 1272; 40 Hz response: cluster significance: <italic>p</italic> &lt; .001; median split: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(24)</sub> = 7.05; BF<sub>(10)</sub> = 59443; t-test: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(24)</sub> = 6.75; BF<sub>(10)</sub> = 30515).</p>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><title>Relationship between cue induced alpha modulation and amplitude of frequency tagged responses in study 2.</title>
<p><bold>A-C</bold>, a positive correlation is visible between alpha activity in the last 500 ms as well as alpha activity in the last 1500ms–1000 ms and steady state potentials shortly before target onset when expecting a visual target (36 HZ late: <italic>p</italic> = .013; 40 Hz late: <italic>p</italic> = .009; 40 Hz early: <italic>p</italic> = 002). <bold>D-F</bold>, when expecting an auditory target, there is a positive correlation between alpha activity in the last 500 ms as well as alpha activity in the last 1500ms–1000 ms and steady state potentials shortly before target onset (36 HZ late: <italic>p</italic> &lt; .001; 40 Hz late: <italic>p</italic> = .005; 36Hz early: <italic>p</italic> = 011). N = 27; *** sig &lt; .001; ** sig. &lt; .01; * sig. &lt; .05. + sig. &lt; .1</p></caption>
<graphic xlink:href="488727v4_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The same correlation was present when expecting an auditory target for both 36 Hz VSSEF activity (see <xref rid="fig10" ref-type="fig">Fig. 10</xref>. D-E; cluster significance: <italic>p</italic> &lt; .001; median split: <italic>p</italic> = .001; <italic>t</italic><sub>(23)</sub> = 3.62; BF<sub>(10)</sub> = 25.51; t-test: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(23)</sub> = 4.60; BF<sub>(10)</sub> = 216) and 40 Hz ASSEF activity (cluster significance: <italic>p</italic> = .005; median split: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(25)</sub> = 3.75; BF<sub>(10)</sub> = 36.40; t-test: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(25)</sub> = 4.06; BF<sub>(10)</sub> = 73.61).</p>
<p>In accordance with the results of study 1, we then tested whether alpha activity preceding frequency-tagging activity showed similar correlations. Our data revealed that during the last 1 to 1.5 s before target onset alpha activity correlated with the 36 Hz VSSEF response during the last 500 ms prior to an auditory target (see <xref rid="fig10" ref-type="fig">Fig. 10F</xref>; cluster significance: <italic>p</italic> = .01; median split: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(24)</sub> = 4.66; BF<sub>(10)</sub> = 271; t-test: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(24)</sub> = 5.66; BF<sub>(10)</sub> = 2688). The same alpha activity correlated with 40 Hz ASSEF activity during the last 500 ms prior to a visual target (see <xref rid="fig10" ref-type="fig">Fig. 10C</xref>; cluster significance: <italic>p</italic> = .002; median split: <italic>p</italic> = .002; <italic>t</italic><sub>(23)</sub> = 3.41; BF<sub>(10)</sub> = 16.38; t-test: <italic>p</italic> &lt; .001; <italic>t</italic><sub>(23)</sub> = 5.57; BF<sub>(10)</sub> = 1901).</p>
<p>Lastly, both alpha activity as well as 36 Hz VSSEF responses 500 ms before target onset correlated negatively with reaction time on a trial-by-trial basis, indicating faster reaction times in trials with higher pre-stimulus activity (alpha: <italic>p</italic> = .037; median split: <italic>p</italic> = .013; <italic>t</italic><sub>(25)</sub> = −2.67; BF<sub>(10)</sub> = 3.78; t-test: <italic>p</italic> &lt; .01; <italic>t</italic><sub>(25)</sub> = −3.34; BF<sub>(10)</sub> = 14.84; 36 Hz: <italic>p</italic> = .002; median split: <italic>p</italic> = .004; <italic>t</italic><sub>(25)</sub> = −3.20; BF<sub>(10)</sub> = 8.98; t-test: <italic>p</italic> &lt; .01; <italic>t</italic><sub>(25)</sub> = −3.46; BF<sub>(10)</sub> = 19.12. See <xref rid="figs3" ref-type="fig">suppl Fig. 3</xref>-<xref rid="figs4" ref-type="fig">4</xref>).</p>
<p>The same increase in the intermodulatory frequency observed in study 1, could be observed in our second study, during the last 500 ms prior to target onset (see <xref rid="fig11" ref-type="fig">Fig. 11A</xref>; <italic>p</italic> = .006). In source space, a descriptive condition difference was visible in auditory and visual sensory cortices, however this effect did not reach significance (p = .49; peak spm coordinates: 45 −83 −19 mm, in the right lingual gyrus; see <xref rid="fig11" ref-type="fig">Fig. 11B</xref>).</p>
<fig id="fig11" position="float" orientation="portrait" fig-type="figure">
<label>Figure 11.</label>
<caption><title>Steady-state response in the intermodulation frequency</title>
<p><bold>A</bold>, similar to study 1, 4 Hz frequency-tagging activity was increased shortly before target onset when expecting an auditory compared to a visual target (<italic>p</italic> = .006). <bold>D</bold>, source localization showed activity over auditory sensory areas, but did not reach significance. N = 27;</p></caption>
<graphic xlink:href="488727v4_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>The neuropsychological account of attention defines it as the selective facilitation (i.e., prioritization) of relevant sensory input and suppression of irrelevant sensory input. Oscillatory activity in the alpha range (∼10 Hz) has been suggested to play a mechanistic role in attention through inhibition of irrelevant cortices, commonly referred to as the ‘alpha inhibition hypothesis’ (<xref ref-type="bibr" rid="c17">Foxe et al., 1998</xref>; <xref ref-type="bibr" rid="c28">Jensen &amp; Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="c32">Klimesch et al., 2007</xref>). In the current cross-modal attention study we directly tested this hypothesis by using frequency-tagging to specifically examine how cues signalling the modality of an upcoming target (either the auditory or visual modality) affected the responsiveness of the relevant and irrelevant sensory cortices prior to target onset. In-line with previous work, we observed a post-cue increase in posterior alpha power in anticipation of processing auditory targets. However, contrary to prevalent theories proposing visual gain suppression when focusing on the auditory modality, we observed that the amplitude of visual frequency-tagging responses increased just prior to the onset of the auditory target. This suggests that responsiveness of the visual stream was not inhibited when attention was directed to auditory processing and was not inhibited by occipital alpha activity, which directly contradicts the proposed mechanism behind the alpha inhibition hypothesis. Our results reconcile previously paradoxical results on audio-visual attention and support the view that alpha activity gates downstream communication pathways.</p>
<sec id="s4a">
<title>Frequency-tagging</title>
<p>In the current experiment, we specifically chose to analyse the cue-to-target interval, where both visual and auditory SSEPs/SSEFs present preparatory states for the upcoming task, independent of task-related processing or performance. The magnitude of auditory SSEPs/SSEFs was increased shortly before target onset when expecting an auditory target compared to a visual target, very much in line with previous reports (e.g., <xref ref-type="bibr" rid="c48">Saupe et al., 2009</xref>). In contrast to the results reported in Saupe et a., (2009), where visual SSEPs decreased when attending the auditory modality, visual SSEPs/SSEFs increased shortly before target onset when expecting an <italic>auditory</italic> target in our data. This is especially surprising as auditory targets were frequently, or in case of our second study, always accompanied by visual distractors, rendering it optimal for task success to completely ignore any visual input. As auditory targets were significantly more difficult than visual targets in our first study and of comparable difficulty in our second study, these results strongly speak to a vigilance increase of sensory processing independent of modality and an inability to selectively disengage one sensory modality in anticipation of a demanding task. This view is consistent with previous work in which visual SSEPs elicited by irrelevant background stimulation increased with task load in an auditory discrimination task (<xref ref-type="bibr" rid="c26">Jacoby et al., 2012</xref>). Furthermore, our results indicate that task demand is a strong candidate to reconcile previously seemingly paradox results, as splitting attention between the auditory and visual system seemed possible in simpler tasks (<xref ref-type="bibr" rid="c14">Driver &amp; Spence, 1998</xref>; <xref ref-type="bibr" rid="c48">Saupe et al., 2009</xref>) and impossible under high demand (<xref ref-type="bibr" rid="c10">de Jong et al., 2010</xref>; <xref ref-type="bibr" rid="c13">Driver, 1996</xref>; <xref ref-type="bibr" rid="c14">Driver &amp; Spence, 1998</xref>; <xref ref-type="bibr" rid="c54">Spence &amp; Driver, 1996</xref>). An alternative account for our findings stems from the evidence, that participants are more likely to only perceive and react to the visual modality, when confronted with audio-visual stimuli (<xref ref-type="bibr" rid="c7">Colavita, 1974</xref>; <xref ref-type="bibr" rid="c53">Spence, 2009</xref>). However, this effect was mostly limited to speeded modality discrimination/target detection tasks (<xref ref-type="bibr" rid="c50">Sinnett et al., 2008</xref>; <xref ref-type="bibr" rid="c53">Spence, 2009</xref>). Furthermore, the increased difficulty of the here-used auditory stimuli was confirmed in a previous block-design study (<xref ref-type="bibr" rid="c64">van Diepen &amp; Mazaheri, 2017</xref>) and in our second study, performances over the visual and auditory tasks were comparable. Nevertheless, visual dominance could play a role for auditory target difficulty as well as predictions over the reciprocity of the audio-visual relationship.</p>
</sec>
<sec id="s4b">
<title>A revision of the alpha inhibition hypothesis</title>
<p>Top-down cued changes in alpha power have now been widely viewed to play a functional role in directing attention: the processing of irrelevant information is attenuated by increasing alpha power in areas involved with processing this information (<xref ref-type="bibr" rid="c17">Foxe, Simpson, &amp; Ahlfors, 1998</xref>; Hanslmayr et al., 2007; <xref ref-type="bibr" rid="c28">Jensen &amp; Mazaheri, 2010</xref>). However, recent evidence suggests that posterior alpha activity does not inhibit gain in early sensory processing stages (<xref ref-type="bibr" rid="c2">Antonov et al., 2020</xref>; <xref ref-type="bibr" rid="c20">Gundlach et al., 2020</xref>; <xref ref-type="bibr" rid="c21">Gutteling et al., 2022</xref>; <xref ref-type="bibr" rid="c70">Zhigalov &amp; Jensen, 2020</xref>). To date there has been no direct investigation into the effect of alpha increases on later stages in the processing stream. In the current study, as expected, we observed a post-cue increase in occipital alpha activity in anticipation of an auditory target. However, we also observed an increase in the amplitude of visual SSEPs during the cue-target interval, which directly contradicts the widespread view of alpha activity exerting ‘gain control’ in early sensory areas by regulating excitability (<xref ref-type="bibr" rid="c18">Foxe &amp; Snyder, 2011</xref>; <xref ref-type="bibr" rid="c28">Jensen &amp; Mazaheri, 2010</xref>; <xref ref-type="bibr" rid="c63">Van Diepen et al., 2019</xref>). Here we propose that alpha activity, rather than modulating early primary sensory processing, exhibits its inhibitory effects at later stages of the processing stream (<xref ref-type="bibr" rid="c2">Antonov et al., 2020</xref>; <xref ref-type="bibr" rid="c20">Gundlach et al., 2020</xref>; <xref ref-type="bibr" rid="c70">Zhigalov &amp; Jensen, 2020</xref>; <xref ref-type="bibr" rid="c71">Zumer et al., 2014</xref>), gating feedforward or feedback communication between sensory areas (<xref ref-type="bibr" rid="c3">Bauer et al., 2020</xref>; <xref ref-type="bibr" rid="c22">Haegens et al., 2015</xref>; <xref ref-type="bibr" rid="c61">Uemura et al., 2021</xref>). Our data provides evidence in favour of this view, as we can show that early sensory alpha activity does not covary over trials with SSEP magnitude in early visual areas, but covaries instead over trials with SSEP magnitude in higher order sensory areas (see also SUPPL. Fig. 14). If alpha activity exerted gain control in early visual regions, increased alpha activity would have to lead to a decrease in SSEP responses. In contrast, we observe that increased alpha activity originating from early visual cortex is related to <italic>enhanced</italic> visual processing. Source localization confirmed that this enhancement was not originating from early visual areas, but from areas associated with later stages of the processing stream such as the precuneus, which has been connected to sensory integration (<xref ref-type="bibr" rid="c1">Al-Ramadhani et al., 2021</xref>; <xref ref-type="bibr" rid="c67">Xie et al., 2019</xref>). While we cannot completely rule out alternative explanations, it seems plausible to assume that inhibition of other task-irrelevant communication pathways leads to prioritised and thereby enhanced processing over relevant pathways. In line with previous literature (<xref ref-type="bibr" rid="c37">Morrow et al., 2023</xref>; <xref ref-type="bibr" rid="c43">Peylo et al., 2021</xref>; <xref ref-type="bibr" rid="c70">Zhigalov &amp; Jensen, 2020</xref>), we therefore suggest that alpha activity limits task-irrelevant feedforward communication, thereby enhancing processing capabilities in relevant downstream areas (see <xref rid="fig1" ref-type="fig">Fig. 1A</xref>). The benefit of alpha-modulation and its effect on visual information processing is underlined by reaction times, which were faster both for trials with high pre-target alpha activity and high pre-target visual SSVEF activity.</p>
<p>It should be noted, the comparison between modulation in alpha activity and in SSEP/SSEFs is difficult, especially concerning timing. This is largely owed to differences in signal-to-noise due to trial averaging in the frequency versus the time domain and temporal and frequency lag in the estimation of alpha activity (<xref ref-type="bibr" rid="c43">Peylo et al., 2021</xref>). It is further noteworthy, that the majority of evidence for the alpha inhibition hypothesis focused on the effect of pre-target alpha modulation on behaviour and target-related potentials (<xref ref-type="bibr" rid="c37">Morrow et al., 2023</xref>). However, in our data alpha modulation occurs clearly ahead of SSVEP/SSVEF modulation on a scale that could not be simply explained by temporal or frequency smearing. Additionally, significant trial-by-trial correlations, which occur in the frequency domain for both signal types, underline the strong relationship between both measurements.</p>
<p>Interestingly, we could show that the magnitude of the correlation between alpha power and visual information processing varied between conditions, suggesting a dynamic and adaptive regime. This notion supports the view that alpha oscillations represent a mechanism rather than a specific function, which can fulfil different roles depending on task demand and network location, which has been confirmed in a recent study revealing functionally distinct alpha networks (<xref ref-type="bibr" rid="c6">Clausner et al., 2024</xref>). As such, it is conceivable that alpha oscillations can in some cases inhibit local transmission, while in other cases, depending on network location, connectivity and demand, alpha oscillation can facilitate signal transmission. This mechanism allows to increase transmission of relevant information and to block transmission of distractors.</p>
<p>In different contexts, utilizing unimodal targets and distractors, spatial cueing, or covert attention, different functional processes could be involved (<xref ref-type="bibr" rid="c37">Morrow et al., 2023</xref>). Future research should intensify efforts to disentangle these effects, investigating localized alpha networks intracranially or through combinations of fMRI, EEG and MEG, to clearly measure their effects on sensory processing and behaviour.</p>
<p>It is known that the localisation of alpha activity reflects the retinotopic organisation of visual spatial attention topographically over the parietooccipital cortex (<xref ref-type="bibr" rid="c30">Kelly et al., 2006</xref>; <xref ref-type="bibr" rid="c44">Popov et al., 2019</xref>). Notably, recent studies provided evidence, that the same organisation can be observed for auditory attention. Specifically, the localisation of visual alpha activity in the parietooccipital cortex reflects the spatial direction of auditory attention (<xref ref-type="bibr" rid="c31">Klatt et al., 2021</xref>; <xref ref-type="bibr" rid="c45">Popov et al., 2021</xref>). This observation can be explained through micro-saccades towards the spatial location of sounds, which are irrevocably connected to alpha oscillations (<xref ref-type="bibr" rid="c45">Popov et al., 2021</xref>). While we did not manipulate spatial attention, our results fit well to the notion of visual alpha activity serving as a sensory orientation system, relaying visual information to task-relevant downstream processing areas, and blocking communication to irrelevant pathways.</p>
</sec>
<sec id="s4c">
<title>The intermodulation frequency</title>
<p>Previous research showed that simultaneous frequency-tagging in multiple frequencies evokes a response in the intermodulation frequency (f1 – f2). In multimodal settings, this frequency is thought to reflect cross-modal integration (<xref ref-type="bibr" rid="c12">Drijvers et al., 2021</xref>). This is very well in line with our findings, where increased vigilance of the sensory system arising from anticipation of a difficult auditory target resulted in an increase in the intermodulation frequency. Likewise, our data shows that visual signal enhancement was localized in precuneus, which has been connected to sensory integration (<xref ref-type="bibr" rid="c1">Al-Ramadhani et al., 2021</xref>; <xref ref-type="bibr" rid="c67">Xie et al., 2019</xref>). Furthermore, we could show that the intermodulation frequency covaries over trials with reaction time in the easiest condition, where visual targets were presented without any distractors. A lack of this connection in other conditions might reflect increasing interferences from higher task difficulty, rather than a lack of the effect itself, but this remains to be tested. We cannot exclude an alternative explanation, as theta oscillations are known to be involved in movement preparation, it is possible that phase-resets could lead to time-locked appearance of these oscillations (<xref ref-type="bibr" rid="c33">Lakatos et al., 2008</xref>; <xref ref-type="bibr" rid="c59">Tomassini et al., 2017</xref>).</p>
</sec>
<sec id="s4d">
<title>Conclusion</title>
<p>Our results taken together suggest that under high attention, audio-visual excitability is enhanced, reflecting an increase in vigilance for both visual as well as auditory information, even if this increases processing of distracting information. We showed that this vigilance shift, as reflected by SSEP/SSEF responses, is regulated by early visual alpha activity, presumably through relaying of visual information over communication pathways, thereby controlling the downstream flow of visual information.</p>
</sec>
</sec>
<sec id="s5">
<title>Materials and Methods</title>
<sec id="s5a">
<title>Participants EEG-Study</title>
<p>In total, 24 healthy volunteers participated in this study (mean age: 19.1 ± 1.8 SD; 17 women). Due to technical difficulties, one participant could not finish the experiment and one participant did not exceed chance level in the behavioural task (∼33 %). Both were therefore removed from any further analysis. All remaining participants reported normal or corrected-to-normal vision, no history of psychiatric or neurological illness and provided written informed consent. After completion of the experiment, participants received either monetary compensation or certification of their participation for their university course program. The study protocol was approved by the Ethics Committee of the School of Psychology at the University of Birmingham and is in accordance with the Declaration of Helsinki.</p>
</sec>
<sec id="s5b">
<title>Participants MEG-Study</title>
<p>In total, 28 healthy volunteers participated in this study (mean age: 23.4 ± 3.6 SD; 20 women). One participant was removed from further analysis, as they only responded to ∼42% of trials correctly in the second block, which related to 27/19 trials per condition respectively. All remaining participants reported normal or corrected-to-normal vision, no history of psychiatric or neurological illness and provided written informed consent. After completion of the experiment, participants received either monetary compensation or certification of their participation for their university course program. The study protocol was approved by the Ethics Committee of the School of Psychology at the University of Birmingham and is in accordance with the Declaration of Helsinki.</p>
</sec>
<sec id="s5c">
<title>Cross-modal attention paradigm EEG-Study</title>
<p>Each trial was initiated by a brief presentation of a cue (100 ms) signalling the modality of the upcoming discrimination task (v-shape: visual modality; inversed v-shape: auditory modality; diamond-shape: non-specific). During the following cue-to-target interval, the fixation cross was frequency-tagged at 36 Hz. At the same time, a 40 Hz frequency-tagged sound (amplitude modulated white noise) was played over headphones (see <xref rid="fig1" ref-type="fig">Fig. 1</xref>). The volume of tones was initially adjusted to a level that was clearly perceivable but not uncomfortable and remained stable over participants. No task was connected to this interval and participants did not need to pay attention to either the sound or the fixation cross. After three seconds, the frequency-tagging stopped, and right after the cessation of stimuli, the target was presented for a very brief moment (25 ms). It consisted either of a Gabor patch (visual modality) or a sound (auditory modality). If the target modality was visual, participants had to use the three arrow buttons on the keyboard to indicate whether the Gabor patch was tilted to the left (−10°; left arrow button), vertical (0°; down arrow button), or tilted to the right (10°; right arrow button). Additionally, in 50% of the trials, a random distractor from the pool of auditory targets was presented simultaneously to the visual target over headphones. Similarly, if the target modality was auditory, participants used the same buttons to indicate whether the pitch of the tone was low (500 Hz), medium (1000 Hz) or high (2000 Hz). Again, in 50% of the trials, a random distractor from the pool of visual targets was also presented. If the cue was non-specific (diamond shape), either a visual (50% of non-specific trials) or an auditory target was presented, never accompanied by any distractors. Experimental trials were separated by an inter-trial interval of 4 seconds, to avoid carry-over effects from previous trials. The resulting 6 conditions were randomly ordered and balanced out over the experiment.</p>
<p>During the experiment, participants were instructed to keep their gaze locked to a fixation cross presented at the centre of the screen. Preceding data collection, participants performed 36 practice trials to get accustomed to the task and the target stimuli. The ensuing experiment was split into 26 trial sequences, separated by self-chosen breaks, which together resulted in 468 trials and lasted between 80 and 90 minutes. The discrimination task was programmed and presented with MATLAB® R2020b and Psychtoolbox-3 on an LCD-monitor featuring a 140 Hz refresh rate. The onset of the visual and auditory tagging frequencies (i.e steady state stimuli) were tracked using the Cedrus Stimtracker (<ext-link ext-link-type="uri" xlink:href="https://cedrus.com/stimtracker/index.htm">https://cedrus.com/stimtracker/index.htm</ext-link>).</p>
</sec>
<sec id="s5d">
<title>Adjustments to the attention paradigm in the MEG-Study</title>
<p>In our second study, we removed all ambiguity concerning targets and distractors and therefore developed a blocked design, incorporating two blocks. The first block did not display distractors and only cues which correctly predicted the target were presented. Cues in the second block were likewise always correctly indicating the target modality, but this time, each target was accompanied by a random distractor from the non-target modality.</p>
<p>Furthermore, the visual task was adjusted to be more in line with the auditory task. As such, the Gabor patches now featured stripes in different frequencies (e.g. a low number of stripes, a medium number of stripes and a high number of stripes. The participant’s task was to discriminate between these three Gabor patches. As auditory targets had been markedly more difficult in our first study, we now included a brief difficulty calibration prior to the experiment. First, we presented 21 Gabor patches with 3 different amounts of stripes following a standard difficulty. If participants could discriminate them correctly 55 – 75% of the time, this difficulty setting was chosen. Otherwise, depending on the performance, the stripe-frequency of the Gabor patches was adjusted. There were maximally 3 sessions of 21 Gabor patches, after which we had enough data to calibrate the individual difficulty setting.</p>
<p>The same procedure was then performed with the difficulty of the tones, calibrating the pitch frequency for each individual participant.</p>
<p>Lastly, visual frequency-tagging stimulation now followed a sinusoidal contrast-change rather than an on-off stimulation, which was possible due to a high-resolution projector featuring a refresh rate of 1440 Hz (PROPixx DLP LED projector ;VPixx Technologies Inc., Canada).</p>
</sec>
<sec id="s5e">
<title>Eye-tracking</title>
<p>To confirm that participants had focused on the fixation cross during the cue-to-target interval, we incorporated eye-tracking into our MEG-experiment (EyeLink 1000 Plus). Correct trials of the second block were analysed for vertical and horizontal eye-movements. To exclude blinks from this analysis, trials with very large eye-movements (&gt; 10 degrees of visual angle) were removed from the eye-tracking data (See <xref rid="figs5" ref-type="fig">suppl Fig. 5</xref>).</p>
</sec>
<sec id="s5f">
<title>Behavioral analysis</title>
<p>We were interested in accuracy in the discrimination of visual targets and auditory targets, as well as reaction times. Furthermore, we examined the distraction cost of having a target presented with a distractor of a different modality as well as the reaction time to make the target discrimination. The distraction cost was calculated as the reaction time difference between cued targets with distractors (i.e. visual and auditory stimuli presented together) and cued targets without distractors (either a visual or auditory stimulus presented alone). All incorrect trials as well as trials with reaction times faster than 100 ms or exceeding 1500 ms were removed from analysis (0.5 % too fast, 9.2% too slow).</p>
</sec>
<sec id="s5g">
<title>EEG data acquisition</title>
<p>All EEG recordings were conducted using a WaveGuard Cap (ANTneuro), featuring 64 Ag/AgCL electrodes (10-10 system; ground: Fz; reference: Cpz; EOG: left canthus). Electrodes positions were prepared with OneStep cleargel conductive paste and impedances were kept below 100 kΩ. The measured signal was transmitted using an ANTneuro EEGosports amplifier (low-pass filter: 150 Hz; high-pass filter: 0.5 Hz; sampling rate: 500 Hz).</p>
</sec>
<sec id="s5h">
<title>MEG data acquisition</title>
<p>Prior to the experiment, feducial positions and head-shape were recorded using a FASTRAK system (Polhemus, USA). The experiment took place in a dimly lit room, where participants were seated in a comfortable chair in the gantry of a 306-sensor TRIUX Elekta system with 204 orthogonal planar gradiometers and 102 magnetometers (Elekta, Finland). The 71*40 cm screen was positioned at ∼1.40 m distance from the participant.</p>
</sec>
<sec id="s5i">
<title>EEG Preprocessing</title>
<p>Offline analyses were performed in MATLAB ® R2020b. The data was pruned from artifacts by visual inspection using the EEGLAB toolbox (Delorme &amp; Makeig, 2004). Additionally, blinks and ocular artefacts were removed from the data using independent component analysis (ICA). EEG channels were re-referenced to an average of all channels (excluding EOG).</p>
</sec>
<sec id="s5j">
<title>MEG Preprocessing</title>
<p>Offline analyses were performed in MATLAB ® R2020b and Python. Spatiotemporal Signal-Source-Separation (SSS) was applied to the raw data via MNE’s inbuilt maxfilter function with a duration window of 10 s and a correlation value of .9. The data was pruned from artifacts by visual inspection using the Fieldtrip toolbox (Delorme &amp; Makeig, 2004). Additionally, blinks and ocular artefacts were removed from the data using independent component analysis (ICA). In sensor space, planar gradiometers were combined for further analyses. In source space, all individual planar gradiometers were analysed.</p>
</sec>
<sec id="s5k">
<title>Amplitude of the evoked frequency-tagging response</title>
<p>To investigate the temporal dynamics of amplitude of the frequency tagged responses after the onset of the attentional cues (also the precise onset of the frequency tagged stimuli) the data was epoched into 6-second segments starting 1.5 seconds prior to cue onset. Next the data were narrow-band filtered around the 36 Hz activity to capture the visual frequency-tagging, 40 Hz activity in to capture the auditory frequency-tagging, and the intermodulation frequency at 4 Hz, which can be derived by subtracting both frequency-tagging responses (f<sub>i</sub> = f<sub>auditory</sub> – f<sub>visual;</sub> see Drijvers, Spaak &amp; Jensen, 2020). Here we used a Blackmann-windowed sync filters adapted to a suitable ratio of temporal and frequency resolution for the specific frequency of each of the tagged signals: filter order 116 for 35.5 to 36.5 Hz and 39.5 to 40.5, filter order 344 for 3.5 to 4.5 Hz. The filtered data at each of the tagged frequencies as well the intermodulated frequency were baseline corrected (interval between 700 and 200 ms preceding cue onset) before calculating the average over trials to obtain steady-state evoked potentials). The power envelope of the SSEPs of tagged frequencies was estimated using Hilbert transformation. To confirm that 4 Hz is a sufficient distance between tagging frequencies, we repeated to analysis for 43.5 to 44.5. We found no indication of frequency-bleeding over, as the effects observed at 40 Hz, were not present at 44 Hz (see SUPPL Fig. 11).</p>
</sec>
<sec id="s5l">
<title>Temporal dynamics of the induced EEG changes</title>
<p>In addition to looking at the cue evoked changes in the amplitude of the frequency tagged signals, we investigated the induced changes in the EEG signal at the frequencies of the tagged auditory and visual stimuli, alpha activity (9-11 Hz, filter order 276 for 7.5 to 12.5 Hz), as well as the intermodulation frequency (4 Hz; filter order 344 for 3.5 to 4.5 Hz). Here rather than averaging the epoched data filtered at the specific frequency ranges, we performed the Hilbert transform, and averaged the power-envelope of the specific frequencies across trials. This approach is very much analogous to the standard time-frequency analysis using convolutions (<xref ref-type="bibr" rid="c64">van Diepen &amp; Mazaheri, 2017</xref>; <xref ref-type="bibr" rid="c69">Zhigalov et al., 2019</xref>), but affords more control concerning temporal versus frequency resolution to examine the temporal dynamics of the specific frequencies of interest. In our second study, the individual peak alpha frequency was used for bandpass-filtering in contrast to a standardised band applied in the first study.</p>
</sec>
<sec id="s5m">
<title>Time-frequency representations of power</title>
<p>In addition to the estimating frequency power envelopes, Time–frequency representations (TFRs) of power of the EEG signal were estimated using the Fieldtrip toolbox (Oostenveld et al., 2011). The power or frequencies between 5 and 20 Hz were calculated for each trial, using a sliding time window (frequency steps: 0.5; time steps: 10 ms). The length of the window was adjusted to a length of 3 cycles per frequency and tapered with a Hanning window. For each trial, both datasets were normalised to display relative percent change from baseline using the following formula: [(activity – baseline) / baseline], where baseline refers to the interval between 700 and 200 ms before cue onset. To estimate the topographical distribution of voltage differences between conditions, uncorrected power values were normalised applying the following formula: [Δ/∑ = (a – b) / (a + b)], where a and b reflect the different conditions.</p>
</sec>
<sec id="s5n">
<title>Source localization</title>
<p>Source localization was performed with a beamformer approach using the Fieldtrip toolbox. Headmodels were created based on individual T1-scans fitted to fiducial points and head shapes. These data were fit to a 5mm 3d sourcemodel and warped into MNI-space. Two participants were missing individual T1-scans. In these cases, we applied a standardized T1-scan using the Colin 27 Average Brain Model (<xref ref-type="bibr" rid="c25">Holmes et al., 1998</xref>). Frequency-domain data was localized using the Dynamic Imaging of Coherent Sources (DICS beamformer) method with a dpss taper of 2 Hz assuming fixed orientation. As condition differences between frequency-tagging responses were better estimated in the time-domain, we assessed them applying the Synthetic Aperture Magnetometry (SAM-beamformer) method with optimal fixed rotation (<xref ref-type="bibr" rid="c49">Sekihara et al., 2004</xref>). Significant brain areas and peak coordinates were related to brain areas using the Anatomical Automatic Labeling (AAL) atlas for SPM8 (<xref ref-type="bibr" rid="c60">Tzourio-Mazoyer et al., 2002</xref>) . After statistical analysis, source localized data was interpolated onto the Colin 27 Average Brain Model MRI. Cerebellar and brainstem interpolations were excluded from the coordinate system.</p>
</sec>
<sec id="s5o">
<title>Statistical analysis</title>
<p>Condition differences in the behavioural task were estimated with paired t-tests and repeated measures ANOVAS, utilizing Tukey-Kramer Post-Hoc test. Power differences between conditions, as well as source-space contrasts were analysed using cluster permutation analysis (<xref ref-type="bibr" rid="c34">Maris &amp; Oostenveld, 2007</xref>). In this procedure, condition labels were randomly shuffled 1000 times, creating pairs of surrogate conditions. To test for significance, paired t-tests were conducted for each data point and each channel, resulting in one t-matrix for real conditions and 1000 t-matrices for surrogate conditions. Significant t-values (<italic>p</italic> &lt; .05) were defined as clusters if there was at least one significant data point present at the same time and frequency in at least two neighbouring channels. To correct for multiple comparisons, a condition difference was only assumed, if the maximum sum of t-values in a real cluster exceeded the same sum of 95% of the clusters found in the surrogate data. To replicate our results in the second study, we applied the same statistics and averaged the previously found time-intervals into windows of 500ms (e.g.: if we found an effect −0.51 to −0.0620 s prior to target onset we tested this effect for a time window of −0.5 to 0 s prior to target onset).</p>
<p>The relationship between induced changes in alpha activity and frequency tagged responses was assessed using trial by trial Spearman correlations. For each participant and each electrode, a correlation coefficient was calculated between the average activity in a previously identified cluster, which was used as seed (e.g., condition differences in alpha activity), and the average activity of the electrophysiological correlate of interest (e.g., 36 Hz activity over the previously identified time window). The correlation coefficients were z-transformed, and the resulting channel by participant matrix was tested against null-correlation model using the cluster permutation approach described above. Derived clusters were additionally tested and visualised by comparing median split trials of high vs low activity. For this analysis, outliers (values deviating more than 2 standard deviations from the mean) were excluded. Furthermore, the average correlation coefficient of the cluster was tested against a 0-correlation model for each participant using t-statistics. Lastly, an interaction between electrophysiological correlations and conditions was performed using correlation coefficients for each participant and electrode, testing them between conditions using the cluster permutation approach. Perceptually uniform and universally readable colormaps were applied to all visualisations (<xref ref-type="bibr" rid="c9">Crameri et al., 2020</xref>). All data are presented as mean ± standard error of the mean (SEM).</p>
</sec>
</sec>
</body>
<back>
<sec id="s8">
<title>Supplementary Materials</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 1</label>
<caption><title>Distractor cost and attentional benefit.</title>
<p><bold>A-B</bold>, illustration of distractor cost: mean performance over trials with distractors was subtracted from mean performance over trials without distractors. Distractor effects were observable for accuracy as well as reaction time; <bold>A</bold>, accuracy: auditory-– auditory +: <italic>M</italic> = 10.0 %; <italic>SD</italic> = 7.3; <italic>p</italic> &lt; .001; <italic>t</italic><sub>(21)</sub> = 7.32; visual-– visual+: <italic>M</italic> = 1.5%; <italic>SD</italic> = 3.06; <italic>p</italic> = .02). The effect was stronger for auditory than for visual target trials (<italic>p</italic> &lt; .001; <italic>t</italic><sub>(21)</sub> = 7.67). Reaction time: (auditory- - auditory+: <italic>M</italic> = −108.1 ms; <italic>SD</italic> = 84.8; <italic>p</italic> &lt; .001; <italic>t</italic><sub>(21)</sub> = −5.98; visual- - visual+: <italic>M</italic> = 123.6 ms; <italic>SD</italic> = 76.3; <italic>p</italic> &lt; .001; <italic>t</italic><sub>(21)</sub> = 7.60). auditory distracters decreased response time to visual targets (<italic>p</italic> &lt; .001; <italic>t</italic><sub>(21)</sub> = −11.99). <bold>B</bold>, (accuracy: auditory-– auditory +: M = 7.2 %; SD = 7.5; p = .001; t(25) = 4.9; visual-– visual+: M = −7.6%; SD = 10.80; p &lt; .01; t(25) = −3.59; Reaction time: auditory-– auditory +: M = −20.64 ms; SD = 57.6; n.s.: p = .08; t(25) = −1.83; visual-– visual+: M = 60.1 ms ; SD = 58.52; p &lt; .001; t(25) = 5.23). <bold>C</bold>, Illustration of attentional benefit: mean performance over non-specific trials was subtracted from mean performance over modality-cued trials without distractor. attentional benefit auditory: non-specifically cued auditory targets - informatively cued auditory targets = M = 81.2 ms; SD = 54.9; p &lt; .001; t(21) = 6.94; attentional benefit visual: non-specifically cued visual targets - informatively cued visual targets -; M = 54.4 ms; SD = 41.1 ; p &lt; .001; t(21) = 5.19). The magnitude of the effect on reaction time also differed between conditions (p = .043; t(21) = 2.16), with stronger attentional benefit for auditory target cues. Attentional cues did not affect response accuracy, neither in auditory nor visual target conditions (auditory: p = 0.49; visual: p = 0.32). EEG Study: N = 22; MEG-Study: N = 27; *** sig &lt; .001; ** sig. &lt; .01; * sig. &lt; .05;</p></caption>
<graphic xlink:href="488727v4_figs1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 2</label>
<caption><title>Time course of alpha activity and frequency-tagging responses for the non-specific compared to the visually-cued condition.</title>
    <p><bold>A</bold>, alpha activity compared between expecting a visual target and having received a non-specific cue. <bold>B</bold>, 36 Hz frequency-tagging response between expecting a visual target and having received a non-specific cue. <bold>C</bold>, 40 Hz frequency-tagging response between expecting a visual target and having received a non-specific cue. <bold>D</bold>, alpha activity compared between expecting an auditory target and having received a non-specific cue. <bold>E</bold>, 36 Hz frequency-tagging response between expecting an auditory target and having received a non-specific cue. <bold>F</bold>, 40 Hz frequency-tagging response between expecting an auditory target and having received a non-specific cue.</p></caption>
<graphic xlink:href="488727v4_figs2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 3</label>
<caption><title>Correlation of prestimulus alpha change from baseline with reaction time in the MEG study.</title>
    <p><bold>A</bold>, the analysis was performed using a cluster-permutation approach, testing a correlation model against a 0-correlation model. Clusters significantly diverging from the 0-correlation model are presented topographically (<italic>p</italic> = .037). Additionally, median splits between fast and slow reaction time trials (<italic>p</italic> = .013; <italic>t</italic><sub>(25)</sub> = −2.67) as well as correlation coefficients (<italic>p</italic> = .003; <italic>t</italic><sub>(25)</sub> = −3.34) of these clusters are displayed for all participants. A negative correlation is visible between alpha modulation and reaction times in the last 500 ms before target onset when expecting a visual target. B, Correlation between alpha modulation and reaction time for each participant. Black diamonds represent trials from the first block (without distractor) and blue dots represent trials from the second block (with auditory distractor).</p></caption>
<graphic xlink:href="488727v4_figs3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 4</label>
<caption><title>Correlation of 36 Hz change from baseline with reaction time in the MEG study.</title>
    <p><bold>A</bold>, the analysis was performed using a cluster-permutation approach, testing a correlation model against a 0-correlation model. Clusters significantly diverging from the 0-correlation model are presented topographically (<italic>p</italic> = .040). Additionally, median splits between fast and slow reaction time trials (<italic>p</italic> = .005; <italic>t</italic><sub>(25)</sub> = −3.10) as well as correlation coefficients (<italic>p</italic> = .002; <italic>t</italic><sub>(25)</sub> = −3.46) of these clusters are displayed for all participants. A negative correlation is visible between 36 Hz modulation and reaction times in the last 500 ms before target onset when expecting a visual target. B, Correlation between 36 Hz modulation and reaction time for each participant. Black diamonds represent trials from the first block (without distractor) and blue dots represent trials from the second block (with auditory distractor).</p></caption>
<graphic xlink:href="488727v4_figs4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 5</label>
<caption><title>Illustration of eye-tracking during the cue-to-target interval (2.5 – 0 s before target onset).</title>
<p>All datapoints of eye-positions during the cue-to-trial interval for all trials and all participants were plotted with 5% visibility on top of each other. Only 3% of datapoints showed eye-movement larger than 3 degrees of visual angle away from the fixation cross.</p></caption>
<graphic xlink:href="488727v4_figs5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 6</label>
<caption><title>Individual ERP power spectra of the cue-to-target interval when anticipating an auditory target in the MEG-study.</title>
<p>Fast-fourier transformation was applied to the averaged trials using a dynamic hanning-tapered sliding time-window of 7 cycles per frequency. The Dotted line represents 40 Hz (auditory frequency-tagging).</p></caption>
<graphic xlink:href="488727v4_figs6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 7</label>
<caption><title>Individual ERP power spectra of the cue-to-target interval when anticipating a visual target in the MEG-study.</title>
<p>Fast-fourier transformation was applied to the averaged trials using a dynamic hanning-tapered sliding time-window of 7 cycles per frequency. The Dotted line represents 36 Hz (auditory frequency-tagging).</p></caption>
<graphic xlink:href="488727v4_figs7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs8" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 8</label>
<caption><title>Individual ERP power spectra of the cue-to-target interval when anticipating an auditory target in the EEG-study.</title>
<p>Fast-fourier transformation was applied to the averaged trials using a dynamic hanning-tapered sliding time-window of 7 cycles per frequency. The Dotted line represents 40 Hz (auditory frequency-tagging).</p></caption>
<graphic xlink:href="488727v4_figs8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs9" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 9</label>
<caption><title>Individual ERP power spectra of the cue-to-target interval when anticipating a visual target in the EEG-study.</title>
<p>Fast-fourier transformation was applied to the averaged trials using a dynamic hanning-tapered sliding time-window of 7 cycles per frequency. The Dotted line represents 36 Hz (auditory frequency-tagging).</p></caption>
<graphic xlink:href="488727v4_figs9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs10" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 10</label>
<caption><title>Exemplary illustration of the correlation between alpha power (0.5 – 0 s before target onset) and 36 Hz steady-state response (0.5 – 0 s before target onset) for each participant in block 2 (distractors present).</title>
<p>Alpha activity was averaged over the significant group difference cluster for alpha condition differences (seed cluster). Frequency-tagging activity was averaged over the significant cluster in the correlation with the alpha seed activity.</p></caption>
<graphic xlink:href="488727v4_figs10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs11" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Fig. 11</label>
<caption><title>Illustration of bleeding over effects over a span of 4 Hz.</title>
<p><bold>A</bold>, 40 Hz frequency-tagging data over the significant cluster differing between when expecting an auditory versus a visual target (identical to <xref rid="fig9" ref-type="fig">Fig. 9</xref> in the manuscript). <bold>B</bold>, 44 Hz signal over the same cluster chosen for A. The analysis was identical with the analysis performed in A, apart from the frequency for the band-pass filter.</p></caption>
<graphic xlink:href="488727v4_figs11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs12" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Figure 12</label>
<caption><title>Virtual channels for V1 and Helschl’s gyrus.</title>
<p><bold>A</bold>, alpha power for the virtual channel created in V1 (Calcerine_L and Calcerine_R from AAL atlas; <xref ref-type="bibr" rid="c60">Tzourio-Mazoyer et al., 2002</xref>, NeuroImage). A cluster permutation analysis over time (between −2 and 0) revealed a significant condition difference between ∼ −2 and −1.7 s (<italic>p</italic> = 0.0449). <bold>B</bold>, 36 Hz frequency-tagging signal for the virtual channel created in V1 (equivalent to the procedure in A). The same cluster permutation as performed in A revealed no significant condition differences. <bold>C</bold>, 40 Hz frequency-tagging signal for the virtual channel created in Heschl’s gryrus (Heschl_L and Heschl_R from AAL atlas; <xref ref-type="bibr" rid="c60">Tzourio-Mazoyer et al., 2002</xref>, NeuroImage). The same cluster permutation as performed in A revealed no significant condition differences.</p></caption>
<graphic xlink:href="488727v4_figs12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs13" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Figure 13.</label>
<caption><title>Power spectrum over MEG sensor clusters with significant condition differences.</title>
<p>A, the sensor cluster which was localized to early visual areas showed a significant difference in power at 10 Hz when expecting an auditory (M = 9.90e-27; SD = 1.06e-26) versus a visual (M = 6.85e-27; SD = 7.11e-27) target (<italic>t</italic>(26) = 2.13; <italic>p</italic> = .043; <italic>d</italic> = 0.41; time-range: −1.5 to 0 sec before target onset). B, the sensor cluster which was localized to sensory integration areas showed a significant difference in power at 36 Hz when expecting an auditory (M = 1.55e-27; SD = 1.61e-27) compared to a visual (M = 1.27e-27; SD = 1.53e-27) target (<italic>t</italic>(26) = 3.58; <italic>p</italic> = .001; <italic>d</italic> = 0.69; time-range: −0.5 to 0 sec before target onset). In the same cluster, a significant difference in power was also found at 40 Hz when expecting an auditory (M = 1.15e-27; SD = 9.51e-28) versus a visual (M = 9.09e-28; SD = 6.74e-28) target (<italic>t</italic>(26) = 2.60; <italic>p</italic> = .015; <italic>d</italic> = 0.50; time-range: −0.5 to 0 sec before target onset).</p></caption>
<graphic xlink:href="488727v4_figs13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs14" position="float" orientation="portrait" fig-type="figure">
<label>SUPPL Figure 14.</label>
<caption><title>Relationship between cue induced alpha modulation and amplitude of frequency tagged responses in the MEG study, both inter- and intra-cortically.</title>
<p>Power was estimated over the last second before target onset, using fast Fourier transformation with a sliding Hanning window of 7 cycles per frequency and a step size of 0.1. A, there is a significant correlation between alpha activity in early visual areas and 36 Hz activity when expecting an auditory target (p = .006). The significant sensor cluster was found vial cluster permutation approach and is positions over fronto-central areas. A median split between trials with high and low alpha activity, as well as a test of the correlation coefficients against 0 confirm this result. There were no significant results for the expectation of a visual target or for 40 Hz activity. B-E, there was no significant correlation between alpha activity in early visual areas and 36 Hz as well as 40 Hz activity within the same sensor cluster. C, there is a significant correlation between early visual alpha activity and 40 Hz activity within the same sensor cluster. The Bayes factor of ∼3 speaks for anecdotal evidence, and the median split could not confirm the effect.</p></caption>
<graphic xlink:href="488727v4_figs14.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7" sec-type="data-availability">
<title>Data availability</title>
<p>Codes for analyses and figures as well as data will be made accessible upon reasonable request to the authors.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This work was made possible by funding support from Facebook Oculus and BBSRC (BB/R018723/1).</p>
</ack>
    
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Al-Ramadhani</surname>, <given-names>R. R.</given-names></string-name>, <string-name><surname>Shivamurthy</surname>, <given-names>V. K. N.</given-names></string-name>, <string-name><surname>Elkins</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Gedela</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Pedersen</surname>, <given-names>N. P.</given-names></string-name>, &amp; <string-name><surname>Kheder</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The Precuneal Cortex: Anatomy and Seizure Semiology</article-title>. <source>Epileptic Disorders : International Epilepsy Journal with Videotape</source>, <volume>23</volume>(<issue>2</issue>), <fpage>218</fpage>. <pub-id pub-id-type="doi">10.1684/EPD.2021.1257</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Antonov</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Chakravarthi</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Andersen</surname>, <given-names>S. K</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Too little, too late, and in the wrong place: Alpha band activity does not reflect an active mechanism of selective attention</article-title>. <source>NeuroImage</source>, <volume>219</volume>, <fpage>117006</fpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2020.117006</pub-id></mixed-citation></ref>
    <ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bauer</surname>, <given-names>A. K. R.</given-names></string-name>, <string-name><surname>Debener</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Nobre</surname>, <given-names>A. C</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Synchronisation of Neural Oscillations and Cross-modal Influences</article-title>. In <source>Trends in Cognitive Sciences</source> (Vol. <volume>24</volume>, <issue>6</issue>, pp. <fpage>481</fpage>–<lpage>495</lpage>). <publisher-name>Elsevier Ltd</publisher-name>. <pub-id pub-id-type="doi">10.1016/j.tics.2020.03.003</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brickwedde</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bezsudnova</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kowalczyk</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Zhigalov</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Application of rapid invisible frequency tagging for brain computer interfaces</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>382</volume>, <fpage>109726</fpage>. <pub-id pub-id-type="doi">10.1016/J.JNEUMETH.2022.109726</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brickwedde</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Krüger</surname>, <given-names>M. C.</given-names></string-name>, &amp; <string-name><surname>Dinse</surname>, <given-names>H. R</given-names></string-name></person-group>. (<year>2020</year>). <article-title>20 Hz Steady-State Response in Somatosensory Cortex During Induction of Tactile Perceptual Learning Through LTP-Like Sensory Stimulation</article-title>. <source>Frontiers in Human Neuroscience</source>. <pub-id pub-id-type="doi">10.3389/fnhum.2020.00257</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Clausner</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Marques</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Scheeringa</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Bonnefond</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Feature specific neuronal oscillations in cortical layers</article-title>. <source>BioRxiv</source>, 2024.07.31.605816. <pub-id pub-id-type="doi">10.1101/2024.07.31.605816</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Colavita</surname>, <given-names>F. B.</given-names></string-name></person-group> (<year>1974</year>). <article-title>Human sensory dominance</article-title>*. In <source>Perception &amp; Psychophysics</source> (Vol. <issue>16</issue>, <issue>2</issue>).</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Colon</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Legrain</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Mouraux</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Steady-state evoked potentials to study the processing of tactile and nociceptive somatosensory input in the human brain</article-title>. <source>Neurophysiologie Clinique/Clinical Neurophysiology</source>, <volume>42</volume>(<issue>5</issue>), <fpage>315</fpage>–<lpage>323</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEUCLI.2012.05.005</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crameri</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Shephard</surname>, <given-names>G. E.</given-names></string-name>, &amp; <string-name><surname>Heron</surname>, <given-names>P. J</given-names></string-name></person-group>. (<year>2020</year>). <article-title>The misuse of colour in science communication</article-title>. <source>Nature Communications</source>, <volume>11</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41467-020-19160-7</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Jong</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Toffanin</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Harbers</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Dynamic crossmodal links revealed by steady-state responses in auditory–visual divided attention</article-title>. <source>International Journal of Psychophysiology</source>, <volume>75</volume>(<issue>1</issue>), <fpage>3</fpage>–<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1016/J.IJPSYCHO.2009.09.013</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dinse</surname>, <given-names>H. R.</given-names></string-name>, <string-name><surname>Ragert</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Pleger</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Schwenkreis</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Tegenthoff</surname>, <given-names>M</given-names></string-name></person-group>. (<year>1998</year>). <article-title>Pharmacological Modulation of Perceptual Learning and Associated Cortical Reorganization</article-title>. <source>Science</source>, <volume>282</volume>, <fpage>865</fpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Drijvers</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Spaak</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Rapid invisible frequency tagging reveals nonlinear integration of auditory and visual information</article-title>. <source>Human Brain Mapping</source>, <volume>42</volume>(<issue>4</issue>), <fpage>1138</fpage>–<lpage>1152</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.25282</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Driver</surname>, <given-names>J</given-names></string-name></person-group>. (<year>1996</year>). <article-title>Enhancement of selective listening by illusory mislocation of speech sounds due to lip-reading</article-title>. <source>Nature</source>, <volume>381</volume>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Driver</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Spence</surname>, <given-names>C</given-names></string-name></person-group>. (<year>1998</year>). <article-title>Cross-modal links in spatial attention</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>, <volume>353</volume>, <fpage>1319</fpage>–<lpage>1331</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dugué</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Marque</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>VanRullen</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2011</year>). <article-title>The phase of ongoing oscillations mediates the causal relation between brain excitation and visual perception</article-title>. <source>Journal of Neuroscience</source>, <volume>31</volume>(<issue>33</issue>), <fpage>11889</fpage>–<lpage>11893</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1161-11.2011</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ergenoglu</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Demiralp</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Bayraktaroglu</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Ergen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Beydagi</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Uresin</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Alpha rhythm of the EEG modulates visual detection performance in humans</article-title>. <source>Cognitive Brain Research</source>, <volume>20</volume>(<issue>3</issue>), <fpage>376</fpage>–<lpage>383</lpage>. <pub-id pub-id-type="doi">10.1016/J.COGBRAINRES.2004.03.009</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foxe</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Simpson</surname>, <given-names>G. V</given-names></string-name>, &amp; <string-name><surname>Ahlfors</surname>, <given-names>S. P.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Parieto-occipital ∼10Hz activity reflects anticipatory state of visual attention mechanisms</article-title>. <source>NeuroReport</source>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foxe</surname>, <given-names>J. J.</given-names></string-name>, &amp; <string-name><surname>Snyder</surname>, <given-names>A. C</given-names></string-name></person-group>. (<year>2011</year>). <article-title>The role of alpha-band brain oscillations as a sensory suppression mechanism during selective attention</article-title>. <source>Frontiers in Psychology</source>, <volume>2</volume>(<issue>JUL</issue>). <pub-id pub-id-type="doi">10.3389/fpsyg.2011.00154</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fu</surname>, <given-names>K. M. G.</given-names></string-name>, <string-name><surname>Foxe</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Higgins</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Javitt</surname>, <given-names>D. C.</given-names></string-name>, &amp; <string-name><surname>Schroeder</surname>, <given-names>C. E</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Attention-dependent suppression of distracter visual input can be cross-modally cued as indexed by anticipatory parieto–occipital alpha-band oscillations</article-title>. <source>Cognitive Brain Research</source>, <volume>12</volume>(<issue>1</issue>), <fpage>145</fpage>–<lpage>152</lpage>. <pub-id pub-id-type="doi">10.1016/S0926-6410(01)00034-9</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gundlach</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Moratti</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Forschack</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Müller</surname>, <given-names>M. M</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Spatial Attentional Selection Modulates Early Visual Stimulus Processing Independently of Visual Alpha Modulations</article-title>. <source>Cerebral Cortex</source>, <volume>30</volume>(<issue>6</issue>), <fpage>3686</fpage>–<lpage>3703</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhz335</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gutteling</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Sillekens</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Lavie</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Alpha oscillations reflect suppression of distractors with increased perceptual load</article-title>. <source>Progress in Neurobiology</source>, <volume>214</volume>. <pub-id pub-id-type="doi">10.1016/J.PNEUROBIO.2022.102285</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haegens</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Barczak</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Musacchia</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lipton</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Mehta</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Lakatos</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Schroeder</surname>, <given-names>C. E</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Laminar profile and physiology of the α rhythm in primary visual, auditory, and somatosensory regions of neocortex</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>(<issue>42</issue>), <fpage>14341</fpage>–<lpage>14352</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0600-15.2015</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haegens</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Nácher</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Luna</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Romo</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2011</year>). <article-title>α-Oscillations in the monkey sensorimotor network influence discrimination performance by rhythmical inhibition of neuronal spiking</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>108</volume>(<issue>48</issue>), <fpage>19377</fpage>–<lpage>19382</lpage>. <pub-id pub-id-type="doi">10.1073/PNAS.1117190108</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hari</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Hämäläinen</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Joutsiniemi</surname>, <given-names>S. L</given-names></string-name></person-group>. (<year>1989</year>). <article-title>Neuromagnetic steady-state responses to auditory stimuli</article-title>. <source>Journal of the Acoustical Society of America</source>, <volume>86</volume>(<issue>3</issue>), <fpage>1033</fpage>–<lpage>1039</lpage>. <pub-id pub-id-type="doi">10.1121/1.398093</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holmes</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Hoge</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Collins</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Woods</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Toga</surname>, <given-names>A. W.</given-names></string-name>, &amp; <string-name><surname>Evans</surname>, <given-names>A. C</given-names></string-name></person-group>. (<year>1998</year>). <article-title>Enhancement of MR images using registration for signal averaging</article-title>. <source>Journal of Computer Assisted Tomography</source>, <volume>22</volume>(<issue>2</issue>), <fpage>324</fpage>–<lpage>333</lpage>. <pub-id pub-id-type="doi">10.1097/00004728-199803000-00032</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jacoby</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Hall</surname>, <given-names>S. E.</given-names></string-name>, &amp; <string-name><surname>Mattingley</surname>, <given-names>J. B</given-names></string-name></person-group>. (<year>2012</year>). <article-title>A crossmodal crossover: Opposite effects of visual and auditory perceptual load on steady-state evoked potentials to irrelevant visual stimuli</article-title>. <source>NeuroImage</source>, <volume>61</volume>(<issue>4</issue>), <fpage>1050</fpage>–<lpage>1058</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2012.03.040</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jain</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bansal</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kumar</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Singh</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2015</year>). <article-title>A comparative study of visual and auditory reaction times on the basis of gender and physical activity levels of medical first year students</article-title>. <source>International Journal of Applied &amp; Basic Medical Research</source>, <volume>5</volume>(<issue>2</issue>), <fpage>124</fpage>. <pub-id pub-id-type="doi">10.4103/2229-516X.157168</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Mazaheri</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Shaping functional architecture by oscillatory alpha activity: Gating by inhibition</article-title>. <source>Frontiers in Human Neuroscience</source>, <volume>4</volume>. <pub-id pub-id-type="doi">10.3389/fnhum.2010.00186</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kass</surname>, <given-names>R. E.</given-names></string-name>, &amp; <string-name><surname>Raftery</surname>, <given-names>A. E</given-names></string-name></person-group>. (<year>1995</year>). <article-title>Bayes factors</article-title>. <source>Journal of the American Statistical Association</source>, <volume>90</volume>(<issue>430</issue>), <fpage>773</fpage>–<lpage>795</lpage>. <pub-id pub-id-type="doi">10.1080/01621459.1995.10476572</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kelly</surname>, <given-names>S. P.</given-names></string-name>, <string-name><surname>Lalor</surname>, <given-names>E. C.</given-names></string-name>, <string-name><surname>Reilly</surname>, <given-names>R. B.</given-names></string-name>, &amp; <string-name><surname>Foxe</surname>, <given-names>J. J</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Increases in alpha oscillatory power reflect an active retinotopic mechanism for distracter suppression during sustained visuospatial attention</article-title>. <source>Journal of Neurophysiology</source>, <volume>95</volume>(<issue>6</issue>), <fpage>3844</fpage>–<lpage>3851</lpage>. <pub-id pub-id-type="doi">10.1152/jn.01234.2005</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Klatt</surname>, <given-names>L.-I.</given-names></string-name>, <string-name><surname>Getzmann</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Schneider</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Attentional Modulations of Alpha Power Are Sensitive to the Task-relevance of Auditory Spatial Information</article-title>. <source>BioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2021.02.12.430942</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klimesch</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Sauseng</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Hanslmayr</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2007</year>). <article-title>EEG alpha oscillations: The inhibition– timing hypothesis</article-title>. <source>Brain Research Reviews</source>, <volume>53</volume>(<issue>1</issue>), <fpage>63</fpage>–<lpage>88</lpage>. <pub-id pub-id-type="doi">10.1016/J.BRAINRESREV.2006.06.003</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lakatos</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Karmos</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Mehta</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Ulbert</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Schroeder</surname>, <given-names>C. E</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Entrainment of neuronal oscillations as a mechanism of attentional selection</article-title>. <source>Science</source>, <volume>320</volume>(<issue>5872</issue>), <fpage>110</fpage>–<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1126/SCIENCE.1154735</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maris</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Oostenveld</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>164</volume>(<issue>1</issue>), <fpage>177</fpage>–<lpage>190</lpage>. <pub-id pub-id-type="doi">10.1016/J.JNEUMETH.2007.03.024</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marzoll</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Saygi</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Dinse</surname>, <given-names>H. R</given-names></string-name></person-group>. (<year>2018</year>). <article-title>The effect of LTP- and LTD-like visual stimulation on modulation of human orientation discrimination</article-title>. <source>Scientific Reports</source>, <volume>8</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41598-018-34276-z</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mazaheri</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>van Schouwenburg</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Dimitrijevic</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Denys</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Region-specific modulations in oscillatory alpha activity serve to facilitate processing in the visual and auditory modalities</article-title>. <source>NeuroImage</source>, <volume>87</volume>, <fpage>356</fpage>–<lpage>362</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2013.10.052</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morrow</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Elias</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Samaha</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Evaluating the Evidence for the Functional Inhibition Account of Alpha-band Oscillations during Preparatory Attention</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>35</volume>(<issue>8</issue>), <fpage>1195</fpage>–<lpage>1211</lpage>. <pub-id pub-id-type="doi">10.1162/JOCN_A_02009</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Müller</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Hillyard</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Concurrent recording of steady-state and transient event-related potentials as indices of visual-spatial selective attention</article-title>. <source>Clinical Neurophysiology</source>, <volume>111</volume>(<issue>9</issue>), <fpage>1544</fpage>–<lpage>1552</lpage>. <pub-id pub-id-type="doi">10.1016/S1388-2457(00)00371-0</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Müller</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Picton</surname>, <given-names>T. W.</given-names></string-name>, <string-name><surname>Valdes-Sosa</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Riera</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Teder-Sälejärvi</surname>, <given-names>W. A.</given-names></string-name>, &amp; <string-name><surname>Hillyard</surname>, <given-names>S. A</given-names></string-name></person-group>. (<year>1998</year>). <article-title>Effects of spatial selective attention on the steady-state visual evoked potential in the 20–28 Hz range</article-title>. <source>Cognitive Brain Research</source>, <volume>6</volume>(<issue>4</issue>), <fpage>249</fpage>–<lpage>261</lpage>. <pub-id pub-id-type="doi">10.1016/S0926-6410(97)00036-0</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nickerson</surname>, <given-names>R. S</given-names></string-name></person-group>. (<year>1973</year>). <article-title>Intersensory facilitation of reaction time: energy summation or preparation enhancement?</article-title> <source>Psychological Review</source>, <volume>80</volume>(<issue>6</issue>), <fpage>489</fpage>–<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1037/H0035437</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Okazaki</surname>, <given-names>Y. O.</given-names></string-name>, <string-name><surname>De Weerd</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Haegens</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Hemispheric lateralization of posterior alpha reduces distracter interference during face matching</article-title>. <source>Brain Research</source>, <volume>1590</volume>(<issue>1</issue>), <fpage>56</fpage>–<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1016/J.BRAINRES.2014.09.058</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pantev</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Roberts</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Elbert</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Roß</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Wienbruch</surname>, <given-names>C</given-names></string-name></person-group>. (<year>1996</year>). <article-title>Tonotopic organization of the sources of human auditory steady-state responses</article-title>. <source>Hearing Research</source>, <volume>101</volume>(<issue>1–2</issue>), <fpage>62</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1016/S0378-5955(96)00133-5</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peylo</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hilla</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Sauseng</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Cause or consequence? Alpha oscillations in visuospatial attention</article-title>. <source>Trends in Neurosciences</source>, <volume>44</volume>(<issue>9</issue>), <fpage>705</fpage>–<lpage>713</lpage>. <pub-id pub-id-type="doi">10.1016/J.TINS.2021.05.004</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Popov</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Gips</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Kastner</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Spatial specificity of alpha oscillations in the human visual system</article-title>. <source>Human Brain Mapping</source>, <volume>40</volume>(<issue>15</issue>), <fpage>4432</fpage>–<lpage>4440</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.24712</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Popov</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Gips</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Weisz</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Brain areas associated with visual spatial attention display topographic organization during auditory spatial attention</article-title>. <source>BioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2021.03.15.435371</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Porcu</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Keitel</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Müller</surname>, <given-names>M. M</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Concurrent visual and tactile steady-state evoked potentials index allocation of inter-modal attention: A frequency-tagging study</article-title>. <source>Neuroscience Letters</source>, <volume>556</volume>, <fpage>113</fpage>–<lpage>117</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEULET.2013.09.068</pub-id></mixed-citation></ref>
    <ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Regan</surname>, <given-names>D</given-names></string-name></person-group>. (<year>1982</year>). <article-title>Comparison of transient and steady-state methods</article-title>. <source>Annals of the New York Academy of Sciences</source>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saupe</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Schröger</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Andersen</surname>, <given-names>S. K.</given-names></string-name>, &amp; <string-name><surname>Müller</surname>, <given-names>M. M</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Neural mechanisms of intermodal sustained selective attention with concurrently presented auditory and visual stimuli</article-title>. <source>Frontiers in Human Neuroscience</source>, <volume>3</volume>(<issue>NOV</issue>). <pub-id pub-id-type="doi">10.3389/neuro.09.058.2009</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sekihara</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nagarajan</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Poeppel</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Marantz</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Asymptotic SNR of scalar and vector minimum-variance beanformers for neuromagnetic source reconstruction</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>, <volume>51</volume>(<issue>10</issue>), <fpage>1726</fpage>–<lpage>1734</lpage>. <pub-id pub-id-type="doi">10.1109/TBME.2004.827926</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sinnett</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Soto-Faraco</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Spence</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2008</year>). <article-title>The co-occurrence of multisensory competition and facilitation</article-title>. <source>Acta Psychologica</source>, <volume>128</volume>(<issue>1</issue>), <fpage>153</fpage>–<lpage>161</lpage>. <pub-id pub-id-type="doi">10.1016/J.ACTPSY.2007.12.002</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Snyder</surname>, <given-names>A</given-names></string-name></person-group>. (<year>1992</year>). <article-title>Steady-state vibration evoked potentials: description of technique and characterization of responses</article-title>. <source>Electroencephalography and Clinical Neurophysiology/Evoked Potentials Section</source>, <volume>84</volume>(<issue>3</issue>), <fpage>257</fpage>–<lpage>268</lpage>. <pub-id pub-id-type="doi">10.1016/0168-5597(92)90007-X</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spaak</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Bonnefond</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Maier</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Leopold</surname>, <given-names>D. A.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Layer-Specific Entrainment of Gamma-Band Neural Activity by the Alpha Rhythm in Monkey Visual Cortex</article-title>. <source>Current Biology</source>, <volume>22</volume>(<issue>24</issue>), <fpage>2313</fpage>–<lpage>2318</lpage>. <pub-id pub-id-type="doi">10.1016/J.CUB.2012.10.020</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spence</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Explaining the Colavita visual dominance effect</article-title>. In <source>Progress in Brain Research</source> (Vol. <volume>176</volume>, pp. <fpage>245</fpage>–<lpage>258</lpage>). <pub-id pub-id-type="doi">10.1016/S0079-6123(09)17615-X</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spence</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Driver</surname>, <given-names>J</given-names></string-name></person-group>. (<year>1996</year>). <article-title>Audiovisual Links in Endogenous Covert Spatial Attention</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>22</volume>(<issue>4</issue>), <fpage>1005</fpage>–<lpage>1030</lpage>.</mixed-citation></ref>
    <ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stapells</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>Linden</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Suffield</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Hamel</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Picton</surname>, <given-names>T. W.</given-names></string-name></person-group> (<year>1984</year>). <article-title>Human Auditory Steady State Potentials</article-title> <source>Ear Hear</source> (Vol. <volume>5</volume>, <issue>2</issue>).</mixed-citation></ref>
    <ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thut</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Nietzel</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brandt</surname>, <given-names>S. A.</given-names></string-name>, &amp; <string-name><surname>Pascual-Leone</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Alpha-Band Electroencephalographic Activity over Occipital Cortex Indexes Visuospatial Attention Bias and Predicts Visual Target Detection</article-title>. <source>J Neurosci</source> <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0875-06.2006</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tobimatsu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Y. M.</given-names></string-name>, &amp; <string-name><surname>Kato</surname>, <given-names>M</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Steady-state vibration somatosensory evoked potentials: physiological characteristics and tuning function</article-title>. <source>Clinical Neurophysiology</source>, <volume>110</volume>(<issue>11</issue>), <fpage>1953</fpage>–<lpage>1958</lpage>. <pub-id pub-id-type="doi">10.1016/S1388-2457(99)00146-7</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toffanin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>de Jong</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Martens</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Using frequency tagging to quantify attentional deployment in a visual divided attention task</article-title>. <source>International Journal of Psychophysiology</source>, <volume>72</volume>(<issue>3</issue>), <fpage>289</fpage>–<lpage>298</lpage>. <pub-id pub-id-type="doi">10.1016/J.IJPSYCHO.2009.01.006</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tomassini</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ambrogioni</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Medendorp</surname>, <given-names>W. P.</given-names></string-name>, &amp; <string-name><surname>Maris</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Theta oscillations locked to intended actions rhythmically modulate perception</article-title>. <source>eLife</source>, <volume>6</volume>. <pub-id pub-id-type="doi">10.7554/eLife.25618.001</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tzourio-Mazoyer</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Landeau</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Papathanassiou</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Crivello</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Etard</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Delcroix</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mazoyer</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Joliot</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>NeuroImage</source>, <volume>15</volume>(<issue>1</issue>), <fpage>273</fpage>–<lpage>289</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uemura</surname>, <given-names>J.-I.</given-names></string-name>, <string-name><surname>Hoshino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Go Igarashi</surname></string-name>, |, <string-name><surname>Matsui</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Chishima</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hoshiyama</surname></string-name>, | <string-name><surname>Minoru</surname></string-name>, &amp; <string-name><surname>Mazaheri</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Pre-stimulus alpha oscillation and post-stimulus cortical activity differ in localization between consciously perceived and missed near-threshold somatosensory stimuli</article-title>. <source>Eur J Neurosci</source>. <pub-id pub-id-type="doi">10.1111/ejn.15388</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Diepen</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>M. X.</given-names></string-name>, <string-name><surname>Denys</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Mazaheri</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Attention and temporal expectations modulate power, not phase, of ongoing alpha oscillations</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>27</volume>(<issue>8</issue>), <fpage>1573</fpage>–<lpage>1586</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00803</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Diepen</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Foxe</surname>, <given-names>J. J.</given-names></string-name>, &amp; <string-name><surname>Mazaheri</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2019</year>). <article-title>The functional role of alpha-band activity in attentional processing: the current zeitgeist and future outlook</article-title>. <source>Current Opinion in Psychology</source>, <volume>29</volume>, <fpage>229</fpage>–<lpage>238</lpage>. <pub-id pub-id-type="doi">10.1016/J.COPSYC.2019.03.015</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Diepen</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Mazaheri</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Cross-sensory modulation of alpha oscillatory activity: suppression, idling, and default resource allocation</article-title>. <source>European Journal of Neuroscience</source>, <volume>45</volume>(<issue>11</issue>), <fpage>1431</fpage>–<lpage>1438</lpage>. <pub-id pub-id-type="doi">10.1111/ejn.13570</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Dijk</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Schoffelen</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Oostenveld</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Prestimulus oscillatory activity in the alpha band predicts visual discrimination ability</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>(<issue>8</issue>), <fpage>1816</fpage>–<lpage>1823</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1853-07.2008</pub-id></mixed-citation></ref>
    <ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Worden</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Foxe</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Simpson</surname>, <given-names>G. V.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Anticipatory biasing of visuospatial attention indexed by retinotopically specific alpha-band electroencephalography increases over occipital cortex</article-title>. <source>J Neurosci</source> <pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-06-j0002.2000</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xie</surname>, <given-names>Y. J.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Y. Y.</given-names></string-name>, <string-name><surname>Xie</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>Y. Y.</given-names></string-name>, &amp; <string-name><surname>Peng</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2019</year>). <article-title>The neural basis of complex audiovisual objects maintenances in working memory</article-title>. <source>Neuropsychologia</source>, <volume>133</volume>, <fpage>107189</fpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROPSYCHOLOGIA.2019.107189</pub-id></mixed-citation></ref>
    <ref id="c68"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Fiebelkorn</surname>, <given-names>I. C.</given-names></string-name>, <string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Knight</surname>, <given-names>R. T.</given-names></string-name>, &amp; <string-name><surname>Kastner</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Differential neural mechanisms underlie cortical gating of visual spatial attention mediated by alpha-band oscillations</article-title>. <source>BioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2023.08.21.553303</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhigalov</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Herring</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Herpers</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bergmann</surname>, <given-names>T. O.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Probing cortical excitability using rapid frequency tagging</article-title>. <source>NeuroImage</source>, <volume>195</volume>, <fpage>59</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2019.03.056</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhigalov</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Alpha oscillations do not implement gain control in early visual cortex but rather gating in parieto-occipital regions</article-title>. <source>Human Brain Mapping</source>, <volume>41</volume>(<issue>18</issue>), <fpage>5176</fpage>–<lpage>5186</lpage>. <pub-id pub-id-type="doi">10.1002/HBM.25183</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zumer</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Scheeringa</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Schoffelen</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Norris</surname>, <given-names>D. G.</given-names></string-name>, &amp; <string-name><surname>Jensen</surname>, <given-names>O</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Occipital Alpha Activity during Stimulus Processing Gates the Information Flow to Object-Selective Cortex</article-title>. <source>PLoS Biology</source>, <volume>12</volume>(<issue>10</issue>). <pub-id pub-id-type="doi">10.1371/journal.pbio.1001965</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106050.3.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Groen</surname>
<given-names>Iris IA</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5536-6128</contrib-id>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution>
</institution-wrap>
<city>Amsterdam</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> manuscript provides <bold>solid</bold> evidence regarding the role of alpha oscillations in sensory gain control. The authors use an attention-cuing task in an initial EEG study followed by a separate MEG replication study to demonstrate that whilst (occipital) alpha oscillations are increased when anticipating an auditory target, so is visual responsiveness as assessed with frequency tagging. The authors propose that their results demonstrate a general vigilance effect on sensory processing and offer a re-interpretation of the inhibitory role of the alpha rhythm.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106050.3.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this study, Brickwedde et al. leveraged a cross-modal task where visual cues indicated whether upcoming targets required visual or auditory discrimination. Visual and auditory targets were paired with auditory and visual distractors, respectively. The authors found that during the cue-to-target interval, posterior alpha activity increased along with auditory and visual frequency-tagged activity when subjects were anticipating auditory targets. The authors conclude that their results imply that alpha modulation does not solely regulate 'gain control' in early visual areas (also referred to as alpha inhibition hypothesis), but rather orchestrates signal transmission to later stages of the processing stream.</p>
<p>Comments on revisions:</p>
<p>I thank the authors for their clarifications. The manuscript is much improved now, in my opinion. The new power spectral density plots and revised Figure 1 are much appreciated. However, there is one remaining point that I am unclear about. In the rebuttal, the authors state the following: &quot;To directly address the question of whether the auditory signal was distracting, we conducted a follow-up MEG experiment. In this study, we observed a significant reduction in visual accuracy during the second block when the distractor was present (see Fig. 7B and Suppl. Fig. 1B), providing clear evidence of a distractor cost under conditions where performance was not saturated.&quot;</p>
<p>I am very confused by this statement, because both Fig. 7B and Suppl. Fig. 1B show that the visual- (i.e., visual target presented alone) has a lower accuracy and longer reaction time than visual+ (i.e., visual target presented with distractor). In fact, Suppl. Fig. 1B legend states the following: &quot;accuracy: auditory- - auditory+: M = 7.2 %; SD = 7.5; p = .001; t(25) = 4.9; visual- - visual+: M = -7.6%; SD = 10.80; p &lt; .01; t(25) = -3.59; Reaction time: auditory- - auditory +: M = -20.64 ms; SD = 57.6; n.s.: p = .08; t(25) = -1.83; visual- - visual+: M = 60.1 ms ; SD = 58.52; p &lt; .001; t(25) = 5.23).&quot;</p>
<p>These statements appear to directly contradict each other. I appreciate that the difficulty of auditory and visual trials in block 2 of MEG experiments are matched, but this does not address the question of whether the distractor was actually distracting (and thus needed to be inhibited by occipital alpha). Please clarify.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106050.3.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Brickwedde</surname>
    <given-names>Marion</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3461-038X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Limachya</surname>
    <given-names>Rupali</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Markiewicz</surname>
    <given-names>Roksana</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5311-8008</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Sutton</surname>
    <given-names>Emma</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Postzich</surname>
    <given-names>Christopher</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shapiro</surname>
    <given-names>Kimron</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0419-1460</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Jensen</surname>
    <given-names>Ole</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8193-8348</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Mazaheri</surname>
    <given-names>Ali</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5732-7555</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the previous reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>In this study, Brickwedde et al. leveraged a cross-modal task where visual cues indicated whether upcoming targets required visual or auditory discrimination. Visual and auditory targets were paired with auditory and visual distractors, respectively. The authors found that during the cue-to-target interval, posterior alpha activity increased along with auditory and visual frequency-tagged activity when subjects were anticipating auditory targets. The authors conclude that their results disprove the alpha inhibition hypothesis, and instead implies that alpha &quot;regulates downstream information transfer.&quot; However, as I detail below, I do not think the presented data irrefutably disproves the alpha inhibition hypothesis. Moreover, the evidence for the alternative hypothesis of alpha as an orchestrator for downstream signal transmission is weak. Their data serves to refute only the most extreme and physiologically implausible version of the alpha inhibition hypothesis, which assumes that alpha completely disengages the entire brain area, inhibiting all neuronal activity.</p>
</disp-quote>
<p>We thank the reviewer for taking the time to provide additional feedback and suggestions and we improved our manuscript accordingly.</p>
<disp-quote content-type="editor-comment">
<p>(1) Authors assign specific meanings to specific frequencies (8-12 Hz alpha, 4 Hz intermodulation frequency, 36 Hz visual tagging activity, 40 Hz auditory tagging activity), but the results show that spectral power increases in all of these frequencies towards the end of the cue-to-target interval. This result is consistent with a broadband increase, which could simply be due to additional attention required when anticipating auditory target (since behavioral performance was lower with auditory targets, we can say auditory discrimination was more difficult). To rule this out, authors will need to show a power spectral density curve with specific increases around each frequency band of interest. In addition, it would be more convincing if there was a bump in the alpha band, and distinct bumps for 4 vs 36 vs 40 Hz band.</p>
</disp-quote>
<p>This is an interesting point with several aspects, which we will address separately</p>
<p>Broadband Increase vs. Frequency-Specific Effects:</p>
<p>The suggestion that the observed spectral power increases may reflect a broadband effect rather than frequency-specific tagging is important. However, Supplementary Figure 11 shows no difference between expecting an auditory or visual target at 44 Hz. This demonstrates that (1) there is no uniform increase across all frequencies, and (2) the separation between our stimulation frequencies was sufficient to allow differentiation using our method.</p>
<p>Task Difficulty and Performance Differences:</p>
<p>The reviewer suggests that the observed effects may be due to differences in task difficulty, citing lower performance when anticipating auditory targets in the EEG study. This issue was explicitly addressed in our follow-up MEG study, where stimulus difficulty was calibrated. In the second block—used for analysis—accuracy between auditory and visual targets was matched (see Fig. 7B). The replication of our findings under these controlled conditions directly rules out task difficulty as the sole explanation. This point is clearly presented in the manuscript.</p>
<p>Power Spectrum Analysis:</p>
<p>The reviewer’s suggestion that our analysis lacks evidence of frequency-specific effects is addressed directly in the manuscript. While we initially used the Hilbert method to track the time course of power fluctuations, we also included spectral analyses to confirm distinct peaks at the stimulation frequencies. Specifically, when averaging over the alpha cluster, we observed a significant difference at 10 Hz between auditory and visual target expectation, with no significant differences at 36 or 40 Hz in that cluster. Conversely, in the sensor cluster showing significant 36 Hz activity, alpha power did not differ, but both 36 Hz and 40 Hz tagging frequencies showed significant effects These findings clearly demonstrate frequency-specific modulation and are already presented in the manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(2) For visual target discrimination, behavioral performance with and without the distractor is not statistically different. Moreover, the reaction time is faster with distractor. Is there any evidence that the added auditory signal was actually distracting?</p>
</disp-quote>
<p>We appreciate the reviewer’s observation regarding the lack of a statistically significant difference in behavioral performance for visual target discrimination with and without the auditory distractor. While this was indeed the case in our EEG experiment, we believe the absence of an accuracy effect may be attributable to a ceiling effect, as overall visual performance approached 100%. This high baseline likely masked any subtle influence of the distractor.</p>
<p>To directly address the question of whether the auditory signal was distracting, we conducted a follow-up MEG experiment. In this study, we observed a significant reduction in visual accuracy during the second block when the distractor was present (see Fig. 7B and Suppl. Fig. 1B), providing clear evidence of a distractor cost under conditions where performance was not saturated.</p>
<p>Regarding the faster reaction times observed in the presence of the auditory distractor, this phenomenon is consistent with prior findings on intersensory facilitation. Auditory stimuli, which are processed more rapidly than visual stimuli, can enhance response speed to visual targets—even when the auditory input is non-informative or nominally distracting (Nickerson, 1973; Diederich &amp; Colonius, 2008; Salagovic &amp; Leonard, 2021). Thus, while the auditory signal may facilitate motor responses, it can simultaneously impair perceptual accuracy, depending on task demands and baseline performance levels.</p>
<p>Taken together, our data suggest that the auditory signal does exert a distracting influence, particularly under conditions where visual performance is not at ceiling. The dual effect—facilitated reaction time but reduced accuracy—highlights the complexity of multisensory interactions and underscores the importance of considering both behavioral and neurophysiological measures.</p>
<disp-quote content-type="editor-comment">
<p>(3) It is possible that alpha does suppress task-irrelevant stimuli, but only when it is distracting. In other words, perhaps alpha only suppresses distractors that are presented simultaneously with the target. Since the authors did not test this, they cannot irrefutably reject the alpha inhibition hypothesis.</p>
</disp-quote>
<p>The reviewer’s claim that we did not test whether alpha suppresses distractors presented simultaneously with the target is incorrect. As stated in the manuscript and supported by our data (see point 2), auditory distractors were indeed presented concurrently with visual targets, and they were demonstrably distracting. Therefore, the scenario the reviewer suggests was not only tested—it forms a core part of our design.</p>
<p>Furthermore, it was never our intention to irrefutably reject the alpha inhibition hypothesis. Rather, our aim was to revise and expand it. If our phrasing implied otherwise, we have now clarified this in the manuscript. Specifically, we propose that alpha oscillations:</p>
<p>(a) Exhibit cyclic inhibitory and excitatory dynamics;</p>
<p>(b) Regulate processing by modulating transfer pathways, which can result in either inhibition or facilitation depending on the network context.</p>
<p>In our study, we did not observe suppression of distractor transfer, likely due to the engagement of a supramodal system that enhances both auditory and visual excitability. This interpretation is supported by prior findings (e.g., Jacoby et al., 2012), which show increased visual SSEPs under auditory task load, and by Zhigalov et al. (2020), who found no trial-by-trial correlation between alpha power and visual tagging in early visual areas, despite a general association with attention.</p>
<p>Recent evidence (Clausner et al., 2024; Yang et al., 2024) further supports the notion that alpha oscillations serve multiple functional roles depending on the network involved. These roles include intra- and inter-cortical signal transmission, distractor inhibition, and enhancement of downstream processing (Scheeringa et al., 2012; Bastos et al., 2015; Zumer et al., 2014). We believe the most plausible account is that alpha oscillations support both functions, depending on context.</p>
<p>To reflect this more clearly, we have updated Figure 1 to present a broader signal-transfer framework for alpha oscillations, beyond the specific scenario tested in this study.</p>
<p>We have now revised Figure 1 and several sentences in the introduction and discussion, to clarify this argument.</p>
<p>L35-37: Previous research gave rise to the prominent alpha inhibition hypothesis, which suggests that oscillatory activity in the alpha range (~10 Hz) plays a mechanistic role in selective attention through functional inhibition of irrelevant cortical areas (see Fig. 1; Foxe et al., 1998; Jensen &amp; Mazaheri, 2010; Klimesch et al., 2007).</p>
<p>L60-65: In contrast, we propose that functional and inhibitory effects of alpha modulation, such as distractor inhibition, are exhibited through blocking or facilitating signal transmission to higher order areas (Peylo et al., 2021; Yang et al., 2023; Zhigalov &amp; Jensen, 2020; Zumer et al., 2014), gating feedforward or feedback communication between sensory areas (see Fig. 1; Bauer et al., 2020; Haegens et al., 2015; Uemura et al., 2021).</p>
<p>L482-485: This suggests that responsiveness of the visual stream was not inhibited when attention was directed to auditory processing and was not inhibited by occipital alpha activity, which directly contradicts the proposed mechanism behind the alpha inhibition hypothesis.</p>
<p>L517-519: Top-down cued changes in alpha power have now been widely viewed to play a functional role in directing attention: the processing of irrelevant information is attenuated by increasing alpha power in areas involved with processing this information (Foxe, Simpson, &amp; Ahlfors, 1998; Hanslmayr et al., 2007; Jensen &amp; Mazaheri, 2010).</p>
<p>L566-569: As such, it is conceivable that alpha oscillations can in some cases inhibit local transmission, while in other cases, depending on network location, connectivity and demand, alpha oscillation can facilitate signal transmission. This mechanism allows to increase transmission of relevant information and to block transmission of distractors.</p>
<disp-quote content-type="editor-comment">
<p>(4) In the abstract and Figure 1, the authors claim an alternative function for alpha oscillations; that alpha &quot;orchestrates signal transmission to later stages of the processing stream.&quot; In support, the authors cite their result showing that increased alpha activity originating from early visual cortex is related to enhanced visual processing in higher visual areas and association areas. This does not constitute a strong support for the alternative hypothesis. The correlation between posterior alpha power and frequency-tagged activity was not specific in any way; Fig. 10 shows that the correlation appeared on both 1) anticipating-auditory and anticipating-visual trials, 2) the visual tagged frequency and the auditory tagged activity, and 3) was not specific to the visual processing stream. Thus, the data is more parsimonious with a correlation than a causal relationship between posterior alpha and visual processing.</p>
</disp-quote>
<p>Again, the reviewer raises important points, which we want to address</p>
<p>The correlation between posterior alpha power and frequency-tagged activity was not specific, as it is present both when auditory and visual targets are expected:</p>
<p>If there is a connection between posterior alpha activity and higher-order visual information transfer, then it can be expected that this relationship remains across conditions and that a higher alpha activity is accompanied by higher frequency-tagged activity, both over trials and over conditions. However, it is possible that when alpha activity is lower, such as when expecting a visual target, the signal-to-noise ratio is affected, which may lead to higher difficulty to find a correlation effect in the data when using non-invasive measurements.</p>
<p>The connection between alpha activity and frequency-tagged activity appears both for auditory as well as visual stimuli and The correlation is not specific to the visual processing stream:</p>
<p>While we do see differences between conditions (e.g. in the EEG-analysis, mostly 36 Hz correlated with alpha activity and only in one condition 40 Hz showed a correlation as well), it is true that in our MEG analysis, we found correlations both between alpha activity and 36 Hz as well as alpha activity and 40 Hz.</p>
<p>We acknowledge that when analysing frequency-tagged activity on a trial-by-trial basis, where removal of non-timelocked activity through averaging (which we did when we tested for condition differences in Fig. 4 and 9) is not possible, there is uncertainty in the data. Baseline-correction can alleviate this issue, but it cannot offset the possibility of non-specific effects. We therefore decided to repeat the analysis with a fast-fourier calculated power instead of the Hilbert power, in favour of a higher and stricter frequency-resolution, as we averaged over a time-period and thus, the time-domain was not relevant for this analysis. In this more conservative analysis, we can see that only 36 Hz tagged activity when expecting an auditory target correlated with early visual alpha activity.</p>
<p>Additionally, we added correlation analyses between alpha activity and frequency-tagged activity within early visual areas, using the sensor cluster which showed significant condition differences in alpha activity. Here, no correlations between frequency-tagged activity and alpha activity could be found (apart from a small correlation with 40 Hz which could not be confirmed by a median split; see SUPPL Fig. 14 C). The absence of a significant correlation between early visual alpha and frequency-tagged activity has previously been described by others (Zhigalov &amp; Jensen, 2020) and a Bayes factor of below 1 also indicated that the alternative hypotheses is unlikely.</p>
<p>Nonetheless, a correlation with auditory signal is possible and could be explained in different ways. For example, it could be that very early auditory feedback in early visual cortex (see for example Brang et al., 2022) is transmitted alongside visual information to higher-order areas. Several studies have shown that alpha activity and visual as well as auditory processing are closely linked together (Bauer et al., 2020; Popov et al., 2023). Inference on whether or how this link could play out in the case of this manuscript expands beyond the scope of this study.</p>
<p>To summarize, we believe the fact that 36 Hz activity within early visual areas does not correlate with alpha activity on a trial-by-trial basis, but that 36 Hz activity in other areas does, provides strong evidence that alpha activity affects down-stream signal processing.</p>
<p>We mention this analysis now in our discussion:</p>
<p>L533-536: Our data provides evidence in favour of this view, as we can show that early sensory alpha activity does not covary over trials with SSEP magnitude in early visual areas, but covaries instead over trials with SSEP magnitude in higher order sensory areas (see also SUPPL. Fig. 14).</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations for the authors):</bold></p>
<p>The evidence for the alternative hypothesis, that alpha in early sensory areas orchestrates downstream signal transmission, is not strong enough to be described up front in the abstract and Figure 1. I would leave it in the Discussion section, but advise against mentioning it in the abstract and Figure 1.</p>
</disp-quote>
<p>We appreciate the reviewer’s concern regarding the inclusion of the alternative hypothesis—that alpha activity in early sensory areas orchestrates downstream signal transmission—in the abstract and Figure 1. While we agree that this interpretation is still developing, recent studies (Keitel et al., 2025; Clausner et al., 2024; Yang et al., 2024) provide growing support for this framework.</p>
<p>In response, we have revised the introduction, discussion, and Figure 1 to clarify that our intention is not to outright dismiss the alpha inhibition hypothesis, but to refine and expand it in light of new data. This revision does not invalidate the prior literature on alpha timing and inhibition; rather, it proposes an updated mechanism that may better account for observed effects.</p>
<p>We have though retained Figure 1, as it visually contextualizes the broader theoretical landscape. while at the same time added further analyses to strengthen our empirical support for this emerging view.</p>
<p>References:</p>
<p>Bastos, A. M., Litvak, V., Moran, R., Bosman, C. A., Fries, P., &amp; Friston, K. J. (2015). A DCM study of spectral asymmetries in feedforward and feedback connections between visual areas V1 and V4 in the monkey. NeuroImage, 108, 460–475. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2014.12.081">https://doi.org/10.1016/j.neuroimage.2014.12.081</ext-link></p>
<p>Bauer, A. R., Debener, S., &amp; Nobre, A. C. (2020). Synchronisation of Neural Oscillations and Cross-modal Influences. Trends in cognitive sciences, 24(6), 481–495. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2020.03.003">https://doi.org/10.1016/j.tics.2020.03.003</ext-link></p>
<p>Brang, D., Plass, J., Sherman, A., Stacey, W. C., Wasade, V. S., Grabowecky, M., Ahn, E., Towle, V. L., Tao, J. X., Wu, S., Issa, N. P., &amp; Suzuki, S. (2022). Visual cortex responds to sound onset and offset during passive listening. Journal of neurophysiology, 127(6), 1547–1563. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00164.2021">https://doi.org/10.1152/jn.00164.2021</ext-link></p>
<p>Clausner T., Marques J., Scheeringa R. &amp; Bonnefond M (2024). Feature specific neuronal oscillations in cortical layers BioRxiv :2024.07.31.605816. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2024.07.31.605816">https://doi.org/10.1101/2024.07.31.605816</ext-link></p>
<p>Diederich, A., &amp; Colonius, H. (2008). When a high-intensity &quot;distractor&quot; is better then a low-intensity one: modeling the effect of an auditory or tactile nontarget stimulus on visual saccadic reaction time. Brain research, 1242, 219–230. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.brainres.2008.05.081">https://doi.org/10.1016/j.brainres.2008.05.081</ext-link></p>
<p>Haegens, S., Nácher, V., Luna, R., Romo, R., &amp; Jensen, O. (2011). α-Oscillations in the monkey sensorimotor network influence discrimination performance by rhythmical inhibition of neuronal spiking. Proceedings of the National Academy of Sciences of the United States of America, 108(48), 19377–19382. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1117190108">https://doi.org/10.1073/pnas.1117190108</ext-link></p>
<p>Jacoby, O., Hall, S. E., &amp; Mattingley, J. B. (2012). A crossmodal crossover: opposite effects of visual and auditory perceptual load on steady-state evoked potentials to irrelevant visual stimuli. NeuroImage, 61(4), 1050–1058. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.03.040">https://doi.org/10.1016/j.neuroimage.2012.03.040</ext-link></p>
<p>Keitel, A., Keitel, C., Alavash, M., Bakardjian, K., Benwell, C. S. Y., Bouton, S., Busch, N. A., Criscuolo, A., Doelling, K. B., Dugue, L., Grabot, L., Gross, J., Hanslmayr, S., Klatt, L.-I., Kluger, D. S., Learmonth, G., London, R. E., Lubinus, C., Martin, A. E., … Kotz, S. A. (2025). Brain rhythms in cognition – controversies and future directions. ArXiv. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.48550/arXiv.2507.15639">https://doi.org/10.48550/arXiv.2507.15639</ext-link></p>
<p>Nickerson R. S. (1973). Intersensory facilitation of reaction time: energy summation or preparation enhancement?. Psychological review, 80(6), 489–509. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0035437">https://doi.org/10.1037/h0035437</ext-link></p>
<p>Popov, T., Gips, B., Weisz, N., &amp; Jensen, O. (2023). Brain areas associated with visual spatial attention display topographic organization during auditory spatial attention. Cerebral cortex (New York, N.Y. : 1991), 33(7), 3478–3489. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhac285">https://doi.org/10.1093/cercor/bhac285</ext-link></p>
<p>Salagovic, C. A., &amp; Leonard, C. J. (2021). A nonspatial sound modulates processing of visual distractors in a flanker task. Attention, perception &amp; psychophysics, 83(2), 800–809. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-020-02161-5">https://doi.org/10.3758/s13414-020-02161-5</ext-link></p>
<p>Scheeringa, R., Petersson, K. M., Kleinschmidt, A., Jensen, O., &amp; Bastiaansen, M. C. (2012). EEG α power modulation of fMRI resting-state connectivity. Brain connectivity, 2(5), 254–264. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1089/brain.2012.0088">https://doi.org/10.1089/brain.2012.0088</ext-link></p>
<p>Spaak, E., Bonnefond, M., Maier, A., Leopold, D. A., &amp; Jensen, O. (2012). Layer-specific entrainment of γ-band neural activity by the α rhythm in monkey visual cortex. Current biology : CB, 22(24), 2313–2318. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2012.10.020">https://doi.org/10.1016/j.cub.2012.10.020</ext-link></p>
<p>Yang, X., Fiebelkorn, I. C., Jensen, O., Knight, R. T., &amp; Kastner, S. (2024). Differential neural mechanisms underlie cortical gating of visual spatial attention mediated by alpha-band oscillations. Proceedings of the National Academy of Sciences of the United States of America, 121(45), e2313304121. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.2313304121">https://doi.org/10.1073/pnas.2313304121</ext-link></p>
<p>Zhigalov, A., &amp; Jensen, O. (2020). Alpha oscillations do not implement gain control in early visual cortex but rather gating in parieto-occipital regions. Human brain mapping, 41(18), 5176–5186. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.25183">https://doi.org/10.1002/hbm.25183</ext-link></p>
<p>Zumer, J. M., Scheeringa, R., Schoffelen, J. M., Norris, D. G., &amp; Jensen, O. (2014). Occipital alpha activity during stimulus processing gates the information flow to object-selective cortex. PLoS biology, 12(10), e1001965. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1001965">https://doi.org/10.1371/journal.pbio.1001965</ext-link></p>
</body>
</sub-article>
</article>