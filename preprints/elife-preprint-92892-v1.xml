<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">92892</article-id>
<article-id pub-id-type="doi">10.7554/eLife.92892</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.92892.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>The Neural Correlates of Ambiguity and Risk In Human Decision-Making Under an Active Inference Framework</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Shuo</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Tian</surname>
<given-names>Yan</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Liu</surname>
<given-names>Quanying</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Wu</surname>
<given-names>Haiyan</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Biomedical Engineering, Southern University of Science and Technology</institution>, Shenzhen, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>Centre for Cognitive and Brain Sciences and Department of Psychology, University of Macau</institution>, Macau, <country>China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Chait</surname>
<given-names>Maria</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding to <email>liuqy@sustech.edu.cn</email> &amp; <email>haiyanwu@um.edu.mo</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-02-22">
<day>22</day>
<month>02</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP92892</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-10-17">
<day>17</day>
<month>10</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-09-18">
<day>18</day>
<month>09</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.09.18.558250"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Zhang et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Zhang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-92892-v1.pdf"/>
<abstract>
<title>A<sc>bstract</sc></title>
<p>Active inference integrates perception, decision-making, and learning into a united theoretical frame-work, providing an efflcient way to trade off exploration and utilization by minimizing (expected) free energy. In this study, we asked how the brain represents values, uncertainty, and resolves the uncertainty under the active inference framework in the exploration-exploitation trade-off. 25 participants performed a contextual two-step two-armed bandit task, with electroencephalogram (EEG) recordings. By comparing the fltting results from the active inference and reinforcement learning model, we show that active inference can better capture the exploration instinct of humans, which helps resolve the uncertainty of the environment. The EEG sensor-level results show that the activity in the frontal, central, and parietal regions is associated with uncertainty, while activity in the frontal and central brain regions is associated with risk. The EEG source-level results indicate that the expected free energy is encoded in the lateral occipital cortex and the uncertainty in the middle temporal pole. Our study dissociates the expected free energy and the uncertainty in active inference theory and their neural correlates, suggesting the reliability of active inference in characterizing cognitive processes of human decisions. It provides behavioral and neural evidence of active inference in decision processes and insights into the neural mechanism of human decision under different kinds of uncertainty.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Active inference from the free energy principle provides a powerful explanatory tool for understanding the dynamic relationship between an agent and its environment [<xref ref-type="bibr" rid="c1">1</xref>]. Free energy is a measure of uncertainty used to describe a system, which can be understood as the difference between the real system state and the estimated system state [<xref ref-type="bibr" rid="c2">2</xref>]. In addition, expected free energy can also be used to guide the optimization process of decision-making. Under the active inference framework, perception, action, and learning are all driven by the minimization of variational free energy (<xref rid="fig1" ref-type="fig">Flgure 1</xref>). By minimizing free energy, people can optimize decisions which encompasses both the reduction of uncertainty about the environment (through <italic>exploration</italic>) and the maximization of rewards (through <italic>exploitation</italic>). Active inference [<xref ref-type="bibr" rid="c3">3</xref>] is a pragmatic implementation of the free energy principle to action, proposing that agents not only minimize free energy through perception, but also through actions that enable them to reach preferable states. Briefly, in active inference, the agent has an internal belief model to approximate the hidden states of the environment (perception), and actively acts to enable oneself to reach preferable states (action)(see <italic><xref ref-type="sec" rid="s2a">Section 2.1</xref></italic>).</p>
<fig id="fig1" position="float" fig-type="Figure">
<label>Flgure 1:</label>
<caption><p>Active inference. (a) Qualitatively, agents receive observations from the environment and use these observations to optimize the internal cognitive model of the environment. Then agents actively sample the environment states by action (choose actions that would make them in more favorable states). The environment changes its state according to agents’ actions and again agents receive new observations from the environment. (b) Quantiflcationally, agents optimize the internal cognitive model by minimizing the variational free energy. Then agents select policies (actions) by minimizing the expected free energy to minimize the surprise in the future.</p></caption>
<graphic xlink:href="558250v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In recent years, the active inference framework has been applied to understanding cognitive processes and behavioral policies in human decisions. Many works provide support for the potential of active inference framework to describe complex cognitive processes, which provide theoretical insights into behavioral dynamics [<xref ref-type="bibr" rid="c4">4</xref>–<xref ref-type="bibr" rid="c7">7</xref>]. For instance, it is theoretically deduced in the active inference framework on exploration and exploitation trade-off [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c8">8</xref>] which trade-off is essential to the functioning of cognitive agents in many decision contexts [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c10">10</xref>]. Speciflcally, <italic>exploration</italic> is to take the action that offers extra information about the current environment, while <italic>exploitation</italic> is to take action to maximize the potential reward given the current belief. The exploration-exploitation trade-off captures an inherent tension and uncertainty, particularly when the agent is confronted with incomplete information about the environment [<xref ref-type="bibr" rid="c11">11</xref>]. However, these theoretical studies have rarely been conflrmed experimentally with lab empirical evidence from both behavioral and neural levels.</p>
<p>The decision-making process frequently involves grappling with varying forms of uncertainty, such as ambiguity -the element of uncertainty that can be mitigated through sampling, risk -the inherent uncertainty presented by a stable environment, and unexpected uncertainty -the uncertainty pertaining to environmental changes. Studies have investigated these different forms of uncertainty in decision-making, focusing especially on their neural correlates [<xref ref-type="bibr" rid="c12">12</xref>–<xref ref-type="bibr" rid="c15">15</xref>]. However, it remains an open question whether the brain represents these different types of uncertainty distinctly [<xref ref-type="bibr" rid="c16">16</xref>](<bold>Aim 1</bold>). In addition to the representation of uncertainties, the brain may also encode the value of resolving these uncertainties [<xref ref-type="bibr" rid="c16">16</xref>](<bold>Aim 2</bold>). The active inference framework presents a theoretical approach to resolving these research gaps. Within this framework, ambiguity is represented by the information gain about model parameters associated with choosing a particular action, while risk is signifled by the variance of hidden environmental states. In active inference, the representations of uncertainty naturally translate into representations of the value of reducing ambiguity or avoiding risk(see <italic><xref ref-type="sec" rid="s2a">Section 2.1</xref></italic>), which means that those representations may show common associated neural signatures [<xref ref-type="bibr" rid="c1">1</xref>].</p>
<p>Our study, therefore, aimed to determine how the human brain represents different uncertainties (<bold>Q1</bold>), and how humans encode the policies or value of resolving these uncertainties (<bold>Q2</bold>). To achieve these aims, we utilized the active inference framework to examine the exploration-exploitation trade-off, with behavioral data and electroencephalogram (EEG) neural recordings (see <italic>Methods</italic>). We designed a contextual two-armed bandit task (see <italic><xref ref-type="sec" rid="s2b">Section 2.2</xref></italic> and <xref rid="fig4" ref-type="fig">Flgure 4 (a)</xref>), wherein participants were instructed to maximize cumulative rewards. They were offered various policies to either avoid risk, reduce ambiguity, or maximize immediate rewards (see <italic>Methods</italic>). With aims to address the two questions, our study provides results of 1) how participants trade off the exploration and exploitation in the contextual two-armed bandit task (behavioral evidence)(see <italic><xref ref-type="sec" rid="s3a">Section 3.1</xref></italic>); 2) how brain signals differ under different levels of ambiguities and risks (sensor-level EEG evidence)(see <italic><xref ref-type="sec" rid="s3b">Section 3.2</xref></italic>) ; 3) how our brain encodes the trade-off of exploration and exploitation, evaluates the values of reducing ambiguity and avoiding risk during action selection, and 4) updates the information about the environment during belief update (source-level EEG evidence)(see <italic><xref ref-type="sec" rid="s3c">Section 3.3</xref></italic>).</p>
</sec>
<sec id="s2">
<label>2.</label>
<title>Methods</title>
<sec id="s2a">
<label>2.1</label>
<title>The free energy principle and active inference</title>
<p>The free energy principle can sample different states of the environment by choosing different actions to obtain the sensory input we like that this process is termed as <italic>active inference</italic>. Under the active inference framework, the free energy can be viewed as the objective function of the system, i.e. the free energy to minimize. By minimizing free energy, we can optimize decisions and reduce uncertainty. In active inference, variational inference is used to estimate model parameters (minimize variational free energy), guide the agent’s actions (minimize expected free energy), and compute an objective function by maximizing the expected log-likelihood (see <xref rid="fig1" ref-type="fig">Flgure 1 (b)</xref>). This process can be viewed as an optimization problem that seeks to flnd the best model parameters and action strategy to maximize the log-likelihood. By minimizing the objective function, optimal model parameters can be estimated and better decisions can be made [<xref ref-type="bibr" rid="c17">17</xref>]. This principle bridges the sensory input, cognitive processes, and action output, enabling us to quantitatively describe the neural processes of learning about the environment. For example, the brain receives sensory input <italic>s</italic> from the environment, and the cognitive model encoded by the human brain <italic>q</italic>(<italic>s</italic>) makes an inference on the cause of sensory input <italic>p</italic>(<italic>s</italic> |<italic>o</italic>). In the free energy principle, minimizing free energy refers to minimizing the difference (<italic>e</italic>.<italic>g</italic>., KL divergence) between the cognitive model (<italic>p</italic>(<italic>s</italic> |<italic>o</italic>)) encoded by our brain and the causes of the sensory input (<italic>q</italic>(<italic>s</italic>)). Thus, free energy is an information-theoretic quantity that constrains the evidence for the data model. Free energy can be minimized by the following two means [<xref ref-type="bibr" rid="c18">18</xref>]:</p>
<list list-type="bullet">
<list-item><p>Minimize free energy through <italic>perception</italic>. Based on existing observations, by maximizing model evidence, the brain improves its internal cognitive model, reducing the gap between the true cause of the sensory input and the internal cognitive model.</p></list-item>
<list-item><p>Minimize free energy through <italic>action</italic>. The agent actively samples the environment, making the sensory input more in line with the cognitive model by sampling the states which are preferred. Minimizing free energy through action is one of the advantages of the free energy principle over Bayesian inference, which can only passively optimize cognition.</p></list-item>
</list>
<sec id="s2a1">
<label>2.1.1</label>
<title>The generative model</title>
<p>Active inference builds on partially observable Markov decision processes: (O, S, U, T, R, P, Q)(see <xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Ingredients for computational modeling of active inference</title></caption>
<graphic xlink:href="558250v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>In this model, the generative model <italic>P</italic> is parameterized as follows and the model parameters are <italic>η</italic> = <italic>a, c, d, β</italic> [<xref ref-type="bibr" rid="c3">3</xref>]:
<disp-formula id="eqn1">
<graphic xlink:href="558250v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>o</italic> is the sensory inputs, <italic>s</italic> is the hidden states of the environment, <italic>π</italic> is the policy of the agent, <italic>A</italic> is the likelihood matrix mapping from hidden states to outcomes, <italic>B</italic> is the transition probability for hidden states under the action of a policy in time <italic>t, d</italic> is the prior expectation of each state at the beginning of each trial, <italic>γ</italic> is the inverse temperature pf beliefs about policies, <italic>β</italic> is the prior expectation of temperature of beliefs about policies, <italic>a</italic> is the concentration parameters of likelihood, <italic>Cat</italic>() is the categorical distribution, <italic>Dir</italic>() is the Dirichlet distribution, and Γ() is the Gamma distribution.</p>
<p>The posterior probability of the corresponding hidden state and parameters (<inline-formula><inline-graphic xlink:href="558250v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, π, A, B, <italic>β</italic>) is as <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref>
<disp-formula id="eqn2">
<graphic xlink:href="558250v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The generative model is a conceptual representation of how agents construe their environmental circumstances. This model fundamentally posits that agents’ observations are contingent upon states, and the transitions of these states inherently depend on both the state itself and the chosen policy or action sequence. It is crucial to note that within this model, the policy is considered a stochastic variable requiring inference, thus considering planning as a form of inference. This inference process involves deducing the optimal policy from the agents’ observations. All the conditional probabilities incorporated within this model are parameterized using a Dirichlet distribution [<xref ref-type="bibr" rid="c19">19</xref>]. The Dirichlet distribution’s sufflcient statistic is its concentration parameter, which is equivalently interpreted as the cumulative frequency of previous occurrences. In essence, this means that the agents incorporate the frequency of past combinations of states and outcomes into the generative model. Therefore, the generative model plays a pivotal role in stipulating the probabilities and uncertainties related to the potential states and outcomes.</p>
</sec>
<sec id="s2a2">
<label>2.1.2</label>
<title>Variational free energy and expected free energy</title>
<p>Perception, decision-making, and learning in active inference are all achieved by minimizing the variational and expected free energy with respect to the model parameters and hidden states. The variational free energy can be expressed in various forms with respect to the reduced posterior as <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref>:
<disp-formula id="eqn3">
<graphic xlink:href="558250v1_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
These forms of free energy are consistent with the variational inference in statistics. Minimizing free energy is equal to maximizing model evidence, that is, minimizing surprise. In addition, free energy can also be written in other forms as <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref>:
<disp-formula id="eqn4">
<graphic xlink:href="558250v1_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The initial term, denoted as <italic>D</italic><sub><italic>KL</italic></sub>(<italic>q</italic>(<italic>s</italic>) || <italic>p</italic>(<italic>s</italic>)), is conventionally referred to as “complexity”. This term, reflecting the divergence between <italic>q</italic>(<italic>s</italic>) and <italic>p</italic>(<italic>s</italic>), quantifles the volume of information intended to be encoded within <italic>q</italic>(<italic>s</italic>) that is not inherent in <italic>p</italic>(<italic>s</italic>). The subsequent term, <italic>E</italic><sub><italic>q</italic></sub>[<italic>logp</italic>(<italic>o</italic>| <italic>s</italic>)], designated as “accuracy”, represents the conditional probability of receiving an observation given each state.</p>
<p>The minimization of variational free energy facilitates a progressive alignment between the approximate posterior distribution of hidden states, as encoded within the brain’s representation of the environment, and the actual posterior distribution of the environment, conditioned on observed data. However, it is noteworthy that our policy beliefs are predominantly future-oriented. Our aspiration entails designing policies that possess the potential to effectively guide us toward achieving the future state that we desire. Thus, it follows that these policies should aim to minimize future free energy, or in other words, the expected free energy. The relationship between policy selection and expected free energy is inversely proportional: a lower expected free energy under a given policy heightens the probability of that policy’s selection. Hence, expected free energy emerges as a crucial factor influencing policy choice.
<disp-formula id="eqn5">
<graphic xlink:href="558250v1_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Next, we can derive the expected free energy in the same way as the variational free energy:
<disp-formula id="eqn6">
<graphic xlink:href="558250v1_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn7">
<graphic xlink:href="558250v1_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In <xref ref-type="disp-formula" rid="eqn7">Eq. (7)</xref>, it is important to note that we anticipate observations that have not yet transpired. Consequently, we designate <inline-formula><inline-graphic xlink:href="558250v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Within the context of expected free energy, if we establish a relationship between <italic>lnP</italic> (<italic>o</italic><sub><italic>τ</italic></sub>) and preference, it enables us to express expected free energy in terms of cognitive value and extrinsic value. The implications of such a relationship offer a new lens to understand the interplay between cognitive processes and their environmental consequences, thereby enriching our understanding of decision-making under the active inference framework.
<disp-formula id="eqn8">
<graphic xlink:href="558250v1_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In this context, extrinsic value aligns with the concept of expected utility. On the other hand, epistemic value corresponds to the anticipated information gain, encapsulating the exploration of both model parameters (active learning) and the hidden states (active inference), which are to be illuminated by future observations.</p>
<p>Belief updates play a dual role by facilitating both inference and learning processes. The inference is here understood as the optimization of expectations concerning hidden states. Learning, on the other hand, involves the optimization of model parameters. This optimization necessitates the flnding of sufflcient statistics of the approximate posterior that minimize the variational free energy. Active inference employs the technique of gradient descent to identify the optimal update method [<xref ref-type="bibr" rid="c3">3</xref>]. In the present work, our focus is primarily centered on the updated methodology related to the mapping function <italic>A</italic> and the concentration parameter <italic>a</italic>:
<disp-formula id="eqn9">
<graphic xlink:href="558250v1_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>α</italic> is the learning rate.</p>
</sec>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Contextual two-armed bandit task</title>
<p>In this study, we developed a “contextual two-armed bandit task”, which is based on the conventional multi-armed bandit task [<xref ref-type="bibr" rid="c20">20</xref>]. In this task, participants are instructed to explore two paths that offer rewards with the aim of maximizing them. One path provides constant rewards in each trial, labeled the “safe path,” while the other, referred to as the “risky path,” probabilistically offers varying amounts of rewards. The risky path has two distinct contexts, “Context 1” (high-reward context) and “Context 2” (low-reward context), each corresponding to different reward distributions.</p>
<p>The context associated with the risky path undergoes random alternations in each trial, and participants can determine the speciflc context of the current trial’s risky path by accessing a cue, although this comes with a cost. Additionally, participants must discern and comprehend the reward distributions of both contexts. For a comprehensive overview of the speciflc parameter settings, please refer to <xref rid="fig2" ref-type="fig">Flgure 2</xref>.</p>
<fig id="fig2" position="float" fig-type="Figure">
<label>Flgure 2:</label>
<caption><p>Generative model of the contextual two-armed bandit task. (a) There are 2 stages in this task. The flrst choice is: “Stay” and “Cue”. The “Stay” option gives you nothing while the “Cue” option gives you a −1 reward and the context information about the “Risky” option in the current trial. The second choice is: “Safe” and “Risky”. The “Safe” option gives you a +6 reward and the “Risky” option gives you a reward probabilistically ranging from 0 to +12 depending on the current context (context 1 or context 2); (b) The four policies in this task are: “Cue” and “Safe”, “Stay” and “Safe”, “Cue” and “Risky”, and “Stay” and “Risky”; (c) The A-matrix maps from 8 hidden states (columns) to 7 observable outcomes (rows).</p></caption>
<graphic xlink:href="558250v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In the task, active inference agents with different parameter conflgurations can exhibit different decision-making policies, as demonstrated in a simulation experiment (see <xref rid="fig3" ref-type="fig">Flgure 3</xref>). By adjusting parameters such as prior, learning rate, and precision, agents can operate under different policies. Agents with a low learning rate (and a relatively high proportion of epistemic value) will initially incur a cost to access the cue, enabling them to thoroughly explore and understand the reward distributions of different contexts. Once sufflcient environmental information is obtained, the agent will evaluate the actual values of various policies and select the optimal policy for exploitation. In the experimental setup, the optimal policy requires selecting the risky path in a high-reward context and the safe path in a low-reward context after accessing the cue. However, in particularly difflcult circumstances, an agent with a high learning rate (and a smaller proportion of epistemic value) may become trapped in a local optimum and consistently opt for the safe path, especially if the initial high-reward scenarios encountered yield minimal rewards.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Flgure 3:</label>
<caption><p>The simulation experiment results. This Flgure demonstrates how an agent selects actions and updates beliefs over 60 trials in the active inference framework. The flrst two panels (a-b) display the agent’s policy and depict how the policy probabilities are updated (choosing between the stay or cue option in the flrst choice, and selecting between the safe or risky option in the second choice). The scatter plot indicates the agent’s actions, with green representing the cue option when the context of the risky path is “Context 1” (high-reward context), orange representing the cue option when the context of the risky path is “Context 2” (low-reward context), purple representing the stay option when the agent is uncertain about the context of the risky path, and blue indicating the safe-risky choice. The shadow represents the agent’s confldence, with darker shadows indicating greater confldence. The third panel(c) displays the rewards obtained by the agent in each trial. The fourth panel(d) shows the prediction error of the agent in each trial, which decreases over time. Flnally, the flfth panel(e) illustrates the expected rewards of the “Risky Path” in the two contexts of the agent.</p></caption>
<graphic xlink:href="558250v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>EEG collection and analysis</title>
<sec id="s2c1">
<label>2.3.1</label>
<title>Participants</title>
<p>Participants were recruited via an online recruitment advertisement. We recruited 25 participants (male: 14, female: 11, mean age: 20.82 <italic>±</italic> 2.12 years old) concurrently collecting electroencephalogram (EEG) and behavioral data. All participants signed an informed consent form before the experiments. This study was approved by the local ethics committee of the University of Macau (BSERE22-APP006-ICI).</p>
</sec>
<sec id="s2c2">
<label>2.3.2</label>
<title>Data collection</title>
<p>In our experiment, to diversify the data, we incorporated an additional “you can ask” stage prior to the stay-cue option. This measure was implemented to ensure that each participant encountered trials under conditions of heightened uncertainty. Participants were presented with the following experimental scenario and instructions: <italic>“You are on a quest for apples in a forest, beginning with 5 apples. You encounter two paths: 1) The left path offers a flxed yield of 6 apples per excursion. 2) The right path offers a probabilistic reward of 0/3/6/9/12 apples per exploration, but it includes two distinct contexts, labeled “Context 1” and “Context 2,” each with a different reward distribution. Note that the context associated with the right path will randomly change in each trial. Before selecting a path, a ranger will provide information about the context of the right path (“Context 1” or “Context 2”) in exchange for an apple. The more apples you collect, the greater your monetary reward will be</italic>.<italic>”</italic></p>
<p>The participants were informed of the introduction which included basic information about the experiment and press the spacebar to proceed(e.g., the total number of apples collected being linked to the monetary reward they would receive). For each trial, the experimental procedure is illustrated in <xref rid="fig4" ref-type="fig">Flgure 4</xref> (a), and comprises flve stages:</p>
<list list-type="order">
<list-item><p>“You can ask” stage: Participants are given the option to ask the ranger for information, which lasts for 2 seconds.</p></list-item>
<list-item><p>“Flrst choice” stage: Participants must decide whether to press the right or left button to ask the ranger for information, at the cost of an apple. This stage also lasts 2 seconds and corresponds to the action selection in active inference.</p></list-item>
<list-item><p>“Flrst result” stage: Participants either receive information about the context of the right path for the current trial or gain no additional information. This stage lasts for 2 seconds and corresponds to the belief update in active inference.</p></list-item>
<list-item><p>“Second choice” stage: Participants decide whether to select the RIGHT or LEFT key to choose the respective path. This stage again lasts for 2 seconds and corresponds to the action selection in active inference.</p></list-item>
<list-item><p>“Second result” stage: Participants are informed about the number of apples rewarded in the current trial and their total apple count, which lasts for 2 seconds. And this stage corresponds to the belief update in active inference.</p></list-item>
</list>
<fig id="fig4" position="float" fig-type="figure">
<label>Flgure 4:</label>
<caption><p>The experiment task and behavioral result. Panel (a) outlines the flve stages of the experiment, which include the “You can ask” stage to determine if participants can request information from the ranger, the “Flrst choice” stage to decide whether to ask the ranger for information, the “Flrst result” stage to display the result of the “Flrst choice” stage, the “Second choice” stage to choose between left and right paths under different uncertainties, and the “Second result” stage to show the result of the “Second choice” stage. Panel (b) displays the number of times each option was selected. Flnally, panel (c) compares model-free RL and active inference models.</p></caption>
<graphic xlink:href="558250v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Each stage is separated by a jitter ranging from 0.6 to 1.0 seconds. The entire experiment consists of a single block with a total of 120 trials.</p>
</sec>
</sec>
<sec id="s2d">
<label>2.3.</label>
<title>EEG processing</title>
<p>The processing of EEG signals was conducted using the EEGLAB toolbox [<xref ref-type="bibr" rid="c21">21</xref>] in the Matlab and the MNE package [<xref ref-type="bibr" rid="c22">22</xref>]. The preprocessing of EEG data involved multiple steps, including data selection, downsampling, high- and low-pass flltering, and independent component analysis (ICA) decomposition. Data segments encompassing a 2-second interval before and after the experiment were chosen. Subsequently, the data was downsampled to a frequency of 250Hz and subjected to high- and low flltering within the 1-30 Hz frequency range. In instances where channels exhibited abnormal data, these were resolved using interpolation and average values. Following this, ICA was applied to identify and discard components flagged as noise.</p>
<p>After obtaining the preprocessed data, our objective was to gain a more comprehensive understanding of the speciflc functions associated with each brain region. To accomplish this, we employed the head model and source space available in the “fsaverage” of the MNE package. To localize the sources, we utilized eLORETA [<xref ref-type="bibr" rid="c23">23</xref>] and mapped the EEG data to the source space.</p>
<p>We segmented the data into flve time intervals that corresponded to the flve stages of the experiment. The flrst stage, known as the “You can ask” stage, involved identifying participants’ willingness to access cues. In the second stage, referred to as the “Flrst choice” stage, participants decided whether to seek cues. The third stage, called the “Flrst result” stage, focused on obtaining the results of cue access. The fourth stage, known as the “Second choice” stage, involved choosing between visiting the safe or risky path. Flnally, the flfth stage, named the “Second result” stage, encompassed receiving rewards. Each interval lasted two, and this categorization allowed us to investigate brain activity responses to two distinct choices at different stages of the task. Speciflcally, we examined the processes of prediction (action selection) and outcome (belief update) within the framework of active inference.</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label>
<title>Results</title>
<sec id="s3a">
<label>3.1.</label>
<title>Behavioral results</title>
<p>The active inference framework was employed to flt the participants’ behavioral policies. To account for differing preferences regarding resolving uncertainty and rewards, we incorporated fltting coefflcients into the three terms constituting the expected free energy (active learning, active inference, and extrinsic value). Subsequently, these fltting parameters were integrated into the active inference model, enabling the extraction of expected free energy, prediction error, and other variables for each trial. We then could perform linear regression to analyze the associated EEG signals for each brain region.</p>
<p>The model comparison results demonstrated that active inference provided a performance to flt participants’ behavioral data compared to the basic model-free reinforcement learning (<xref rid="fig4" ref-type="fig">Flgure 4 (c)</xref>). Notably, the active inference captured the participants’ exploratory inclinations better compared to model-free RL [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>]. This was evident in our experimental observations (<xref rid="fig4" ref-type="fig">Flgure 4 (b)</xref>) where participants signiflcantly favored consulting the ranger over opting to stay. Consulting the ranger, which provided environmental information, emerged as a more beneflcial policy within the context of this task.</p>
<p>Moreover, participants’ preferences for uncertainty were found to vary depending on the context. When participants lacked information about the context and the risky path had the same average rewards as the safe path but with greater variability, they showed an equal preference for both options(<xref rid="fig4" ref-type="fig">Flgure 4 (b)</xref>, “Not ask”). However, in context 1 (<xref rid="fig4" ref-type="fig">Flgure 4 (b)</xref>, “Context 1”, high-reward context), where the risky path offered greater rewards than the safe path, participants strongly favored the riskier option, which not only provided higher rewards but also had added epistemic value. In contrast, in context 2 (<xref rid="fig4" ref-type="fig">Flgure 4 (b)</xref>, “Context 2”, low-reward context), where the risky path had lower rewards than the safe path, participants mostly chose the safe path but occasionally opted for the risky path, recognizing that despite its lower rewards, it offers epistemic value.</p>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>EEG results at sensor level</title>
<p>As depicted in <xref rid="fig5" ref-type="fig">Flgure 5 (a)</xref>, we divided electrodes into flve clusters: left frontal, right frontal, central, left parietal, and right parietal. Within the “Second choice” stage, participants were required to make decisions amidst varying degrees of uncertainty (the uncertainty about the hidden states and the uncertainty about the model parameters). Thus, we investigated whether distinct brain regions exhibited differential responses under such uncertainty.</p>
<fig id="fig5" position="float" fig-type="Figure">
<label>Flgure 5:</label>
<caption><p>EEG results in at the sensor level. (a) The electrode distribution. (b) The signal amplitude of different brain regions in the flrst and second half of the experiment in the “Second choice” stage. The right panel shows the visualization of the evoked data and spectrum data. (c) The signal amplitude of different brain areas in the “Second choice” stage where participants know the context or do not know the context of the right path. The right panel shows the visualization of the evoked data and spectrum data</p></caption>
<graphic xlink:href="558250v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Usually, in the flrst half of the experimental trials, participants would display greater uncertainty about model parameters compared to the latter half of the trials [<xref ref-type="bibr" rid="c8">8</xref>]. We thus analyzed data from the flrst half and latter half trials, and identifled statistically signiflcant differences in the signal amplitude of the left frontal region (<italic>p &lt;</italic> 0.01), the right frontal region (<italic>p &lt;</italic> 0.05), the central region (<italic>p &lt;</italic> 0.01), and the left parietal region (<italic>p &lt;</italic> 0.05) suggesting a role for these areas in encoding the statistical structure of the environment(<xref rid="fig5" ref-type="fig">Flgure 5</xref> (b)). We postulate that when participants have constructed the statistical model of the environment during the second half of the trials, brains could effectively utilize the statistical model to make superior decisions and exhibit more positive activities.</p>
<p>To investigate whether distinct brain regions exhibited differential responses under the uncertainty about the hidden states, we divided all trials into two groups: the <italic>asked</italic> trials and the <italic>not-asked</italic> trials based on whether participants chose to ask in the “Flrst choice” stage. In the <italic>not-asked</italic> (<xref rid="fig5" ref-type="fig">Flgure 5 (c)</xref>), participants displayed greater uncertainty about the hidden states of the environment compared to the <italic>asked trials</italic>. We identifled statistically signiflcant differences in the signal amplitude of the left frontal region (<italic>p &lt;</italic> 0.01), the right frontal region (<italic>p &lt;</italic> 0.05), and the central region (<italic>p &lt;</italic> 0.001), suggesting a role for these areas in encoding the hidden states of the environment. It may suggest that when participants knew the hidden states, they could effectively integrate the information with the environmental statistical structure to make superior decisions and exhibit more positive brain activities. The right panel of <xref rid="fig5" ref-type="fig">Flgure 5</xref> (c) reveals a higher signal in the delta band during not-asked trials, suggesting a correlation between theta band signal and uncertainty about the hidden states [<xref ref-type="bibr" rid="c26">26</xref>]. To investigate whether distinct brain regions exhibited differential responses under the uncertainty about the hidden states, we divided all trials into two groups: the <italic>asked</italic> trials and the <italic>not-asked</italic> trials based on whether participants chose to ask the range in the “Flrst choice” stage. In our settings, participants would display greater uncertainty about the hidden states of the environment for the <italic>not-asked</italic> trials, compared to the <italic>asked</italic> trials. We identifled statistically signiflcant differences between the two conditions in the signal amplitude over the left frontal region (<italic>p &lt;</italic> 0.01), the right frontal region (<italic>p &lt;</italic> 0.05), and the central region (<italic>p &lt;</italic> 0.001)(<xref rid="fig5" ref-type="fig">Flgure 5</xref> (c)), suggesting a role for these areas in encoding the hidden states of the environment. The right panel of <xref rid="fig5" ref-type="fig">Flgure 5 (c)</xref> also reveals a higher signal in the delta band during <italic>not-asked</italic> trials, suggesting a correlation between theta band signal and uncertainty about the hidden states [<xref ref-type="bibr" rid="c26">26</xref>].</p>
</sec>
<sec id="s3c">
<label>3.3.</label>
<title>EEG results at source level</title>
<p>In order to uncover the functional roles of various brain regions in the decision, we employed a generalized linear model (GLM) to flt the EEG source signal. The GLM included several regressors to capture different aspects of the decision-making process, namely expected free energy, active learning, active inference, extrinsic value (reward), and reward prediction error. Incorporating these regressors, enables us to know how each of these factors influenced EEG activity and contributed to the decision-making process.</p>
<sec id="s3c1">
<label>3.3.1</label>
<title>“Flrst choice” stage – action selection</title>
<p>During the “Flrst choice” stage, participants were presented with the choice of either choosing to stay or approaching the ranger to gather information regarding the present situation of the risky path, the latter choice coming at a cost.</p>
<p>We found a robust correlation (<italic>p &lt;</italic> 0.05) between the “expected free energy” regressor and activities of the lateral occipital cortex (<xref rid="fig6" ref-type="fig">Flgure 6</xref> (a)). In addition, the rostral middle frontal cortex and the middle temporal gyrus, also displayed correlations with expected free energy. With respect to the “extrinsic value” regressor, we identifled a strong correlation (<italic>p &lt;</italic> 0.05) with the activities over the inferior temporal gyrus. Furthermore, the superior temporal gyrus, insula, and precentral area. For the “active inference” regressor (<xref rid="fig6" ref-type="fig">Flgure 6 (b)</xref>), we observed a strong negative correlation (<italic>p &lt;</italic> 0.05) with activities of the middle temporal gyrus, the inferior temporal gyrus, superior temporal gyrus, and precentral area. Interestingly, we observed that during the “Flrst choice” stage, expected free energy and extrinsic value regressors were strongly correlated both at the beginning and the end. However, expected free energy correlations appeared earlier than those of extrinsic value at the beginning, suggesting that the brain initially encodes reward values before integrating these values with information values (active inference and active learning) for decision-making. In the case of the “active learning” regressor, we found strong correlations in the middle temporal gyrus, lateral occipital cortex, inferior temporal gyrus, and inferior parietal lobule.</p>
<fig id="fig6" position="float" fig-type="Figure">
<label>Flgure 6:</label>
<caption><p>The source estimation results of the “Flrst choice” stage of expected free energy and active inference. (A) The regression coefflcients (<italic>β</italic>) of the expected free energy regressor. The blue point indicates the most correlated brain region (the lateral occipital cortex, left hemisphere, MNI: [−9.9, −96.8, 9.8]). The right panel shows the neural activity of the blue point and the shadow indicates that the neural activity of the blue point in these time intervals (0.380s to 0.581s and 1.172s to 1.724s) is signiflcantly correlated with expected free energy (<italic>p &lt;</italic> 0.05 and the time intervals are longer than 0.2s). (B) The regression coefflcients (<italic>β</italic>) of the active inference regressor. The blue point indicates the most correlated brain region (the middle temporal gyrus, left hemisphere, MNI: [-63.5, −23.5, −13.8]). The right panel shows the neural activity of the blue point and the green shadow indicates that the neural activities of the blue point in these time intervals (0.08s to 0.636s, 0.657s to 0.906s, and 1.32s to 2.00s) are signiflcantly correlated with active inference (<italic>p &lt;</italic> 0.05 and the time intervals are longer than 0.2s).</p></caption>
<graphic xlink:href="558250v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3c2">
<label>3.3.2</label>
<title>“Flrst result” stage – belief update</title>
<p>During the “Flrst result” stage, participants were presented with the outcome of their initial choice, which informed them of the current context: either “Context 1” or “Context 2” for the risky path, or no additional information if they opted not to ask. This process correlates with the “active inference” regressor (<xref rid="fig7" ref-type="fig">Flgure 7</xref> (a) (b)), as it corresponds to resolving uncertainties about hidden states. We observed a robust correlation (<italic>p &lt;</italic> 0.05) within certain regions of the middle temporal gyrus and superior frontal cortex. Additionally, other brain regions such as the temporal pole, lateral orbitofrontal cortex, and rostral middle frontal cortex also displayed time-dependent correlations. Towards the conclusion of the “Flrst result” stage, we noted subtle correlations with active inference in parietal and occipital regions. This observation suggests that following the assimilation of environmental state information, the brain starts utilizing a reward model to assist in decision-making.</p>
<fig id="fig7" position="float" fig-type="Figure">
<label>Flgure 7:</label>
<caption><p>The source estimation results of the two result stages of active inference and active learning. (A) The regression coefflcients (<italic>β</italic>) of the active inference regressor in the “Flrst result” stage. The blue point indicates the most correlated brain region (the middle temporal gyrus, right hemisphere, MNI: [52.6, −32.3, −19.7]). The right panel shows the neural activity of the blue point and the shadow indicates that the neural activity of the blue point in these time intervals (0.076s to 0.436s, 0.47s to 0.67s, and 0.80s to 1.24s) is signiflcantly correlated with expected free energy (<italic>p &lt;</italic> 0.05 and the time intervals are longer than 0.2s). (B) The regression coefflcients (<italic>β</italic>) of the active learning regressor in the “Second result” stage. The blue point indicates the most correlated brain region (the intersection of the middle temporal gyrus and the bankssts, left hemisphere, MNI: [-52.5, −56.6, 5.5]). The right panel shows the neural activity of the blue point and the shadow indicates that the neural activity of the blue point in these time intervals (0.355s to 0.745 and 1.441 to 1.651) is signiflcantly correlated with active inference (<italic>p &lt;</italic> 0.05 and the time intervals are longer than 0.2s).</p></caption>
<graphic xlink:href="558250v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3c3">
<label>3.3.3</label>
<title>“Second choice” stage – action selection</title>
<p>During the “Second choice” stage, participants choose between the risky and safe paths based on the available information, with the aim of maximizing rewards. This requires a balance between exploration and exploitation, similar to the “Flrst choice” stage. Flrst, for the “expected free energy” regressor (<xref rid="fig8" ref-type="fig">Flgure 8</xref>(a) (b)), we identifled strong correlations (<italic>p &lt;</italic> 0.01) in particular regions of the lateral occipital cortex. Additionally, correlations were observed in various periods within other brain regions such as the superior parietal gyrus, inferior parietal gyrus, and rostral middle frontal cortex. Generally, the correlations between regressors and brain signals were more pronounced in the “Second choice” stage compared to the “Flrst choice” stage. Regarding the “extrinsic value” regressor, we found that certain regions of the middle temporal gyrus showed strong correlations during the time interval from 0.104 to 0.168. Furthermore, other brain regions such as the inferior temporal gyrus, and insula, exhibited some degree of correlation at different time periods. For the “active learning” regressor (<xref rid="fig8" ref-type="fig">Flgure 8</xref>(c) (d)), strong correlations (<italic>p &lt;</italic> 0.05) were evident in the lateral occipital cortex, the parietal lobule, and temporal pole.</p>
<fig id="fig8" position="float" fig-type="Figure">
<label>Flgure 8:</label>
<caption><p>The source estimation results of the “Second choice” stage of expected free energy and active learning. (a) The regression coefflcients (<italic>β</italic>) of the expected free energy regressor. The blue point indicates the most correlated brain region (the lateral occipital cortex, left hemisphere, MNI: [−5.5, −92.8, 15.4]). The right panel shows the neural activity of the blue point and the shadow indicates that the neural activity of the blue point in these time intervals (0.188s to 0.516s, 0.532s to 1.312s, and 1.336s to 2.00s) is signiflcantly correlated with expected free energy (<italic>p &lt;</italic> 0.05 and the time intervals are longer than 0.2s). (b) The regression coefflcients (<italic>β</italic>) of the active learning regressor. The blue point indicates the most correlated brain region (the lateral occipital cortex, left hemisphere, MNI: [−9.9, −96.8, 9.8]). The right panel shows the neural activity of the blue point and the shadow indicates that the neural activity of the blue point in the time intervals (0.108s to 2.00s) is signiflcantly correlated with expected free energy (<italic>p &lt;</italic> 0.05).</p></caption>
<graphic xlink:href="558250v1_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3c4">
<label>3.3.4</label>
<title>“Second result” stage – belief update</title>
<p>During the “Second result” stage, participants obtain specific rewards based on their second choice: selecting the safe path yields a flxed reward, whereas choosing the risky path results in variable rewards, contingent upon the context. For the “extrinsic value” regressor, we observed strong correlations (<italic>p &lt;</italic> 0.05) in speciflc regions of the rostral middle frontal gyrus and the lateral orbitofrontal cortex. Additionally, other brain regions such as the pars orbitalis, inferior temporal gyrus, lateral occipital sulcus, caudal middle frontal gyrus, and frontal pole demonstrated varying degrees of correlation with “extrinsic value” across different time periods. With regards to the “active learning” regressor (<xref rid="fig7" ref-type="fig">Flgure 7</xref> (c) (d))), strong correlations (<italic>p &lt;</italic> 0.05) were identifled at the middle temporal gyrus, and the superior parietal lobule.</p>
</sec>
</sec>
</sec>
<sec id="s4">
<label>4</label>
<title>Discussion</title>
<p>In this study, we utilized active inference to explore the different cognitive types and associated neural components involved in human exploration strategies during the decision-making process. By employing a contextual two-bandit task, we demonstrated that the active inference model framework effectively describes real-world decision-making. Our flndings indicate that active inference not only provides explanations and distinctions for uncertainties during decision-making, but also reveals the common and unique neural correlates associated with different types of uncertainties and decision-making policies. This was supported by evidence from both sensor-level and source-level EEG.</p>
<sec id="s4a">
<label>4.1</label>
<title>The varieties of human exploration strategies in active inference</title>
<p>In the diverse realm of human behavior, it has been observed that exploration strategies vary signiflcantly depending on the situation at hand. Such strategies can be viewed as a blend of <italic>directed exploration</italic>, where options with higher levels of uncertainty or ambiguity are favored, and <italic>random exploration</italic>, where actions are chosen with absolute randomness [<xref ref-type="bibr" rid="c27">27</xref>]. In the framework of active inference, the randomness in exploration is derived from the precision parameter employed during policy selection. As the precision parameter increases, the randomness in agents’ actions also escalates. On the other hand, the directed exploration aspect stems from the computation of expected free energy. Policies that lead to the exploration of more ambiguous options, hence yielding higher information gain, are assigned increased expected free energy by the model [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c11">11</xref>].</p>
<p>Our model-fltting results of decision behavior indicate that people show high variance in the exploration strategies4 (b). Exploration strategies, from a model-based perspective, incorporate a fusion of model-free learning and model-based learning. Intriguingly, these two learning ways exhibit both competition and cooperation within the human brain [<xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c29">29</xref>]. The simplicity and effectiveness of model-free learning contrast with its inflexibility and data inefflciency. Conversely, model-based learning, although flexible and capable of forward planning, demands substantial cognitive resources. The active inference model tends to lean more toward model-based learning, as this model incorporates a cognitive representation of the environment to guide the agent’s actions. Our simulation results showed these model-based behaviors that the agent constructs an environment model and uses the model to maximize rewards3. To integrate model-free learning, a habitual term was added in [<xref ref-type="bibr" rid="c3">3</xref>]. This allows the active inference agent to exploit the cognitive model (model-based) for planning in the initial task stages and utilize habits for increased accuracy and efflciency in later stages.</p>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>The strength of the active inference framework in decision</title>
<p>Active inference is a comprehensive framework elucidating neurocognitive processes (<xref rid="fig1" ref-type="fig">Flgure 1</xref>). It unifles perception, decision-making, and learning within a single framework centered around the minimization of free energy. One of the primary strengths of the active inference model lies in its robust statistical [<xref ref-type="bibr" rid="c30">30</xref>] and neuroscientiflc underpinnings [<xref ref-type="bibr" rid="c31">31</xref>], allowing for a lucid understanding of an agent’s interaction within its environment. This model effectively harmonizes cognitive and practical values by emphasizing both within the context of free energy, thereby facilitating the modeling of each participant’s cognitive and practical value.</p>
<p>Active inference offers a superior exploration mechanism compared with basic model-free reinforcement learning (<xref rid="fig4" ref-type="fig">Flgure 4</xref> (c)). Since traditional reinforcement learning models predicate their policies solely on the state, this setting leads to difflculty in extracting temporal information [<xref ref-type="bibr" rid="c32">32</xref>] and increases the likelihood of entrapment within local minima. In contrast, the policies in active inference are determined by both time and state. This dependence on time [<xref ref-type="bibr" rid="c33">33</xref>] enables policies to adapt efflciently, such as emphasizing exploration in the initial stages and exploitation later on. Moreover, this mechanism prompts more exploratory behavior in instances of state ambiguity. A further advantage of active inference lies in its adaptability of different task environments [<xref ref-type="bibr" rid="c4">4</xref>]. It can conFlgure different generative models to address distinct tasks, and compute varied forms of free energy and expected free energy.</p>
<p>Despite these strengths, the active inference framework also has its limitations [<xref ref-type="bibr" rid="c34">34</xref>]. One notable limitation pertains to its computational complexity (<xref rid="fig2" ref-type="fig">Flgure 2</xref> (c)), resulting from its model-based architecture, restricting the traditional active inference model’s application within continuous state-action spaces. Additionally, the model heavily relies on the selection of priors, meaning that poorly chosen priors could adversely affect decision-making, learning, and other processes [<xref ref-type="bibr" rid="c8">8</xref>].</p>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Representing uncertainties at the sensor level</title>
<p>In the previous work, the employment of EEG signals in decision-making processes under uncertainty has largely concentrated on event-related potential (ERP) and spectral features at the sensor level [<xref ref-type="bibr" rid="c35">35</xref>–<xref ref-type="bibr" rid="c38">38</xref>]. In our study, the sensor level results reveal more positive activities in multiple brain regions during the second half trials compared to the flrst half, and similarly, during not-asked trials as opposed to asked trials5.</p>
<p>In our setting, after the flrst half of the trials, participants had learned some information about the environmental statistical structure, thus experiencing less ambiguity in the latter half of the trials. This increased understanding enabled them to better utilize the statistical structure for decision-making as compared to the flrst half of the trials. In contrast, during the not-asked trials, the lack of knowledge of the environment’s hidden states led to higher-risk actions. This elevated risk was reflected in increased positive brain activities.</p>
<p>The aspects of ambiguity and risk, two pivotal factors in decision-making, are often misinterpreted and can vary in meaning depending on the context. Regarding the sensor level results, we flnd an overall more positive amplitude for the second half of the trials than the flrst half of the trials5 (b). It may indicate a generally more positive amplitude of EEG for the lower ambiguity trials, which may contract with previous studies showing more positive amplitude for higher ambiguity trials in previous studies [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c39">39</xref>]. For example, a late positive potential (LPP) was identifled in their work, which differentiated levels of ambiguity, with the amplitude of the LPP serving as an index for perceptual ambiguity levels. However, the ambiguity in their task was deflned as the perceptual difflculty of distinguishing, while our deflnition of ambiguity corresponds to the information gained from certain policies. Furthermore, Zheng et al. [<xref ref-type="bibr" rid="c40">40</xref>] used a wheel-of-fortune task to examine the ERP and oscillatory correlations of neural feedback processing under conditions of risk and ambiguity. Their flndings suggest that risky gambling enhanced cognitive control signals, as evidenced by theta oscillation. In contrast, ambiguous gambling heightened affective and motivational salience during feedback processing, as indicated by positive activity and delta oscillation. Future work may focus on this oscillation level analysis and reveal more evidence on it.</p>
</sec>
<sec id="s4d">
<label>4.4</label>
<title>Representation of decision-making process in human brain</title>
<p>In our experiment, each stage corresponded to distinct phases of the decision-making process. Participants made decisions to optimize cumulative rewards based on current information about the environment during the two choice stages while acquiring information about the environment during the two result stages.</p>
<p>During the “Flrst choice” stage, participants had to decide whether to bear an additional cost in exchange for information regarding the environment’s state (epistemic value). Here, the primary source of epistemic value stemmed from resolving the uncertainty of the hidden staterisk. The occipital cortex appears to play a critical role in this process by combining extrinsic value with epistemic value (expected free energy) to guide decision-making (<xref rid="fig6" ref-type="fig">Flgure 6</xref>). Previous study [<xref ref-type="bibr" rid="c41">41</xref>] has demonstrated signiflcant activations in the lateral occipital complex during perceptual decision-making, indicating that the human brain may use perceptual persistence to facilitate reward-related decisions.</p>
<p>As for the “Flrst result” stage, participants learned about the environment’s hidden states. Our results indicated that the regions within the temporal lobe played a crucial role in both valuing the uncertainty of hidden states and learning information about these hidden states (<xref rid="fig7" ref-type="fig">Flgure 7</xref> (a)). Other studies have similarly demonstrated the importance of the temporal pole and the inferior temporal areas in processing the ambiguity regarding lexical semantics [<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>]. Studies on macaques also identifled the role of the inferior temporal lobe in representing blurred visual objects [<xref ref-type="bibr" rid="c44">44</xref>]. Throughout the “Flrst result” stage, participants are processing the state information relevant to the current trial. The middle temporal gyrus is postulated to play a key role in processing this state information and employing it to construct an environmental model. This aligns with previous flndings [<xref ref-type="bibr" rid="c45">45</xref>], which suggest that the middle temporal gyrus collaborates with other brain regions to facilitate conscious learning. Moreover, studies have also identifled deflcits in episodic future thinking in patients with damage to the middle temporal gyrus (MTG) [<xref ref-type="bibr" rid="c46">46</xref>], thereby indicating the critical role of MTG in future-oriented decision-making tasks, particularly those involving future thinking [<xref ref-type="bibr" rid="c47">47</xref>–<xref ref-type="bibr" rid="c49">49</xref>].</p>
<p>In the “Second choice stage”, participants chose between a safe path and a risky path, contingent on perceived value. When knowing the environment’s hidden states, participants tended to resolve the uncertainty of model parameters by opting for the risky path. Conversely, without knowledge of the hidden states, participants gravitated towards risk avoidance by selecting the safe path. Our results highlighted the signiflcance of the occipital lobe regions, in conjunction with the temporal and parietal lobes, in both valuing the uncertainty of model parameters and learning about these parameters (<xref rid="fig8" ref-type="fig">Flgure 8</xref>). These results are consistent with another study that demonstrates activation in the superior parietal, right precentral gyrus, postcentral gyrus, and superior frontal regions during decision-making involving ambiguity and risk [<xref ref-type="bibr" rid="c50">50</xref>]. Since the superior parietal region was involved in the integration of visual motion information and extraction of episodic memory [<xref ref-type="bibr" rid="c51">51</xref>–<xref ref-type="bibr" rid="c53">53</xref>], it may play a crucial role in our decision task as well, where participants need to extract statistical relationship from different visual input at different times.</p>
<p>For the “Second result stage”, participants got rewards according to their actions, constructing the model-free action value function and the model-based state transition function. Our results highlighted the role of the frontal cortex in learning the action value function and the role of the middle temporal gyrus in learning the state transition function (<xref rid="fig7" ref-type="fig">Flgure 7</xref> (b)). Notably, the correlations’ signiflcance between “active inference” and the middle temporal gyrus reached its peak later than the correlations’ signiflcance between “extrinsic value” and the orbitofrontal cortex. This temporal disparity may suggest that the brain processes reward information earlier than environmental information. However, this is contrary to previous flndings that the temporospatial factors derived from PCA on the effect model-based prediction error peaked earlier than those on the effect model-free prediction error [<xref ref-type="bibr" rid="c54">54</xref>]. Future work should look deeper into where and when the human brain processes different information in decision tasks.</p>
<p>In the two choice stages, we observed stronger correlations for the expected free energy compared to the extrinsic value, suggesting that the expected free energy could serve as a better representation of the brain’s actual value employed to guide actions [<xref ref-type="bibr" rid="c55">55</xref>]. Our results pointed to a strong correlation between the expected free energy and activations in the occipital lobe. Such a result may be explained by that the lateral occipital sulcus plays a key role in the persistence of perceptual information and represents delayed rewards [<xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c56">56</xref>].</p>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Conclusion</title>
<p>In the current study, we introduced the active inference framework as a means to investigate the neural mechanisms underlying an exploration and exploitation decision-making task. Compared to model-free reinforcement learning, active inference provides a superior exploration bonus during the initial trials and offers a better flt to the participants’ behavioral data. Given that the behavioral task in our study only involved variables from a limited number of states and rewards, future research should strive to apply the active inference framework to more complex tasks. Speciflc brain regions may play key roles in balancing exploration and exploitation. The lateral occipital gyrus was primarily involved in action selection (expected free energy), while the temporal lobe regions were mainly engaged in valuing the information related to the hidden states of the environment. Furthermore, the middle temporal gyrus and lateral occipital gyrus were prominently involved in valuing the information related to the environmental model parameters. The temporal pole regions primarily participated in learning the hidden states of the environment (active inference), while the middle temporal gyrus was more engaged in learning the model parameters of the environment (active learning). In essence, our flndings suggest that active inference is capable of investigating human behaviors in decision-making under uncertainty, reducing ambiguity, avoiding risk, and maximizing rewards. Overall, this research presents evidence from both behavioral and neural perspectives that support the concept of active inference in decision-making processes. We also offer insights into the neural mechanisms involved in human decision-making under various forms of uncertainty.</p>
</sec>
</body>
<back>
<sec id="s6">
<title>Data and Code availability</title>
<p>All experiment codes and analysis codes are available at GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/andlab-um/FreeEnergyEEG">https://github.com/andlab-um/FreeEnergyEEG</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This work was mainly supported by the Science and Technology Development Fund (FDCT) of Macau[0127/2020/A3, 0041/2022/A], the Natural Science Foundation of Guangdong Province (2021A1515012509), Shenzhen-Hong Kong-Macao Science and Technology Innovation Project (Category C) (SGDX2020110309280100), MYRG of University of Macau (MYRG2022-00188-ICI), NSFC-FDCT Joint Program 0095/2022/AFJ, the SRG of University of Macau (SRG202000027-ICI), the National Key R&amp;D Program of China (2021YFF1200804), National Natural Science Foundation of China (62001205), Shenzhen Science and Technology Innovation Committee (2022410129, KCXFZ2020122117340001), Shenzhen-Hong Kong-Macao Science and Technology Innovation Project (SGDX2020110309280100), Guangdong Provincial Key Laboratory of Advanced Biomaterials (2022B1212010003).</p>
</ack>
<sec id="s7">
<title>Author contributions</title>
<p>S.Z, Q.L., and H.W. developed the study concept and designed the study; S.Z. and H.W. prepared experimental materials; Q.L. and H.W. supervised the experiments and analyses; S.Z. and Y. T. performed the data collection; S.Z. performed the data analyses; all authors drafted, revised and reviewed the manuscript and approved the flnal manuscript for submission.</p>
</sec>
<sec id="s8">
<title>Competing interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, “<article-title>The free-energy principle: a unifled brain theory?</article-title>” <source>Nature reviews neuroscience</source>, vol. <volume>11</volume>, no. <issue>2</issue>, pp. <fpage>127</fpage>–<lpage>138</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name> and <string-name><given-names>K. E.</given-names> <surname>Stephan</surname></string-name>, “<article-title>Free-energy and the brain</article-title>,” <source>Synthese</source>, vol. <volume>159</volume>, pp. <fpage>417</fpage>–<lpage>458</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>T.</given-names> <surname>FltzGerald</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Rigoli</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Schwartenbeck</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Pezzulo</surname></string-name> <etal>et al.</etal>, “<article-title>Active inference and learning</article-title>,” <source>Neuroscience &amp; Biobehavioral Reviews</source>, vol. <volume>68</volume>, pp. <fpage>862</fpage>–<lpage>879</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>T.</given-names> <surname>FltzGerald</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Rigoli</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Schwartenbeck</surname></string-name>, and <string-name><given-names>G.</given-names> <surname>Pezzulo</surname></string-name>, “<article-title>Active inference: a process theory</article-title>,” <source>Neural computation</source>, vol. <volume>29</volume>, no. <issue>1</issue>, pp. <fpage>1</fpage>–<lpage>49</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Kirchhoff</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Parr</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Palacios</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Kiverstein</surname></string-name>, “<article-title>The markov blankets of life: autonomy, active inference and the free energy principle</article-title>,” <source>Journal of The royal society interface</source>, vol. <volume>15</volume>, no. <issue>138, p. 20170792</issue>, <year>2018</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="other"><string-name><given-names>T.</given-names> <surname>Parr</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Pezzulo</surname></string-name>, and <string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name>, <source>Active inference: the free energy principle in mind, brain, and behavior. MIT Press</source>, <year>2022</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Daunizeau</surname></string-name>, and <string-name><given-names>S. J.</given-names> <surname>Kiebel</surname></string-name>, “<article-title>Reinforcement learning or active inference?</article-title>” <source>PloS one</source>, vol. <volume>4</volume>, no. <issue>7, p. e6421</issue>, <year>2009</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Schwartenbeck</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Passecker</surname></string-name>, <string-name><given-names>T. U.</given-names> <surname>Hauser</surname></string-name>, <string-name><given-names>T. H.</given-names> <surname>FltzGerald</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Kronbichler</surname></string-name>, and <string-name><given-names>K. J.</given-names> <surname>Friston</surname></string-name>, “<article-title>Computational mechanisms of curiosity and goal-directed exploration</article-title>,” <source>Elife</source>, vol. <volume>8</volume>, <year>2019</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>C. A.</given-names> <surname>O’Reilly</surname> <suffix>III</suffix></string-name> and <string-name><given-names>M. L.</given-names> <surname>Tushman</surname></string-name>, “<article-title>Organizational ambidexterity in action: How managers explore and exploit</article-title>,” <source>California management review</source>, vol. <volume>53</volume>, no. <issue>4</issue>, pp. <fpage>5</fpage>–<lpage>22</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>R. C.</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Geana</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>White</surname></string-name>, <string-name><given-names>E. A.</given-names> <surname>Ludvig</surname></string-name>, and <string-name><given-names>J. D.</given-names> <surname>Cohen</surname></string-name>, “<article-title>Humans use directed and random exploration to solve the explore–exploit dilemma</article-title>.” <source>Journal of Experimental Psychology: General</source>, vol. <volume>143</volume>, no. <issue>6, p. 2074</issue>, <year>2014</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>S. J.</given-names> <surname>Gershman</surname></string-name>, “<article-title>Uncertainty and exploration</article-title>.” <source>Decision</source>, vol. <volume>6</volume>, no. <issue>3</issue>, p. <fpage>277</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>N. D.</given-names> <surname>Daw</surname></string-name>, <string-name><given-names>J. P.</given-names> <surname>O’doherty</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Seymour</surname></string-name>, and <string-name><given-names>R. J.</given-names> <surname>Dolan</surname></string-name>, “<article-title>Cortical substrates for exploratory decisions in humans</article-title>,” <source>Nature</source>, vol. <volume>441</volume>, no. <issue>7095</issue>, pp. <fpage>876</fpage>–<lpage>879</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Badre</surname></string-name>, <string-name><given-names>B. B.</given-names> <surname>Doll</surname></string-name>, <string-name><given-names>N. M.</given-names> <surname>Long</surname></string-name>, and <string-name><given-names>M. J.</given-names> <surname>Frank</surname></string-name>, “<article-title>Rostrolateral prefrontal cortex and individual differences in uncertainty-driven exploration</article-title>,” <source>Neuron</source>, vol. <volume>73</volume>, no. <issue>3</issue>, pp. <fpage>595</fpage>–<lpage>607</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>J. F.</given-names> <surname>Cavanagh</surname></string-name>, <string-name><given-names>C. M.</given-names> <surname>Flgueroa</surname></string-name>, <string-name><given-names>M. X.</given-names> <surname>Cohen</surname></string-name>, and <string-name><given-names>M. J.</given-names> <surname>Frank</surname></string-name>, “<article-title>Frontal theta reflects uncertainty and unexpectedness during exploration and exploitation</article-title>,” <source>Cerebral cortex</source>, vol. <volume>22</volume>, no. <issue>11</issue>, pp. <fpage>2575</fpage>–<lpage>2586</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Payzan-LeNestour</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Dunne</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Bossaerts</surname></string-name>, and <string-name><given-names>J. P.</given-names> <surname>Odoherty</surname></string-name>, “<article-title>The neural representation of unexpected uncertainty during value-based decision making</article-title>,” <source>Neuron</source>, vol. <volume>79</volume>, no. <issue>1</issue>, pp. <fpage>191</fpage>–<lpage>201</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>I.</given-names> <surname>Levy</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Snell</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Nelson</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Rustichini</surname></string-name>, and <string-name><given-names>P. W.</given-names> <surname>Glimcher</surname></string-name>, “<article-title>Neural representation of subjective value under risk and ambiguity</article-title>,” <source>Journal of neurophysiology</source>, vol. <volume>103</volume>, no. <issue>2</issue>, pp. <fpage>1036</fpage>–<lpage>1047</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, “<article-title>Active inference and free energy</article-title>,” <source>Behavioral and brain sciences</source>, vol. <volume>36</volume>, no. <issue>3, p. 212</issue>, <year>2013</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>C. L.</given-names> <surname>Buckley</surname></string-name>, <string-name><given-names>C. S.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>S.</given-names> <surname>McGregor</surname></string-name>, and <string-name><given-names>A. K.</given-names> <surname>Seth</surname></string-name>, “<article-title>The free energy principle for action and perception: A mathematical review</article-title>,” <source>Journal of Mathematical Psychology</source>, vol. <volume>81</volume>, pp. <fpage>55</fpage>–<lpage>79</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>T. H.</given-names> <surname>FltzGerald</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Schwartenbeck</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Moutoussis</surname></string-name>, <string-name><given-names>R. J.</given-names> <surname>Dolan</surname></string-name>, and <string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, “<article-title>Active inference, evidence accumulation, and the urn task</article-title>,” <source>Neural computation</source>, vol. <volume>27</volume>, no. <issue>2</issue>, pp. <fpage>306</fpage>–<lpage>328</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="other"><string-name><given-names>T.</given-names> <surname>Lu</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Pál</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Pál</surname></string-name>, <article-title>“Contextual multi-armed bandits,” in Proceedings of the Thirteenth international conference on Artiflcial Intelligence and Statistics</article-title>. <source>JMLR Workshop and Conference Proceedings</source>, <year>2010</year>, pp. <fpage>485</fpage>–<lpage>492</lpage>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal">R. Martínez-Cancino, <string-name><given-names>A.</given-names> <surname>Delorme</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Truong</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Artoni</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Kreutz-Delgado</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Sivagnanam</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Yoshimoto</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Majumdar</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Makeig</surname></string-name>, “<article-title>The open eeglab portal interface: High-performance computing with eeglab</article-title>,” <source>NeuroImage</source>, vol. <volume>224</volume>, p. <fpage>116778</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="other"><string-name><given-names>L.</given-names> <surname>Esch</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Dinh</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Larson</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Engemann</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Jas</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Khan</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Gramfort</surname></string-name>, and <string-name><given-names>M. S.</given-names> <surname>Hämäläinen</surname></string-name>, “<article-title>Mne: software for acquiring, processing, and visualizing meg/eeg data</article-title>,” <source>Magnetoencephalography: From Signals to Dynamic Cortical Networks</source>, pp. <fpage>355</fpage>–<lpage>371</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>R. D.</given-names> <surname>Pascual-Marqui</surname></string-name>, <article-title>“Discrete, 3d distributed, linear imaging methods of electric neuronal activity. part 1: exact, zero error localization,”</article-title> <source>arXiv preprint</source> <pub-id pub-id-type="arxiv">0710.3341</pub-id>, <year>2007</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="other"><string-name><given-names>R. S.</given-names> <surname>Sutton</surname></string-name> and <string-name><given-names>A. G.</given-names> <surname>Barto</surname></string-name>, <source>Reinforcement learning: An introduction. MIT press</source>, <year>2018</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Rigoli</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Ognibene</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Mathys</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Fltzgerald</surname></string-name>, and <string-name><given-names>G.</given-names> <surname>Pezzulo</surname></string-name>, “<article-title>Active inference and epistemic value</article-title>,” <source>Cognitive neuroscience</source>, vol. <volume>6</volume>, no. <issue>4</issue>, pp. <fpage>187</fpage>–<lpage>214</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Harper</surname></string-name>, <string-name><given-names>S. M.</given-names> <surname>Malone</surname></string-name>, and <string-name><given-names>W. G.</given-names> <surname>Iacono</surname></string-name>, “<article-title>Theta-and delta-band eeg network dynamics during a novelty oddball task</article-title>,” <source>Psychophysiology</source>, vol. <volume>54</volume>, no. <issue>11</issue>, pp. <fpage>1590</fpage>–<lpage>1605</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>S. J.</given-names> <surname>Gershman</surname></string-name>, “<article-title>Deconstructing the human algorithms for exploration</article-title>,” <source>Cognition</source>, vol. <volume>173</volume>, pp. <fpage>34</fpage>–<lpage>42</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Gläscher</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Daw</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, and <string-name><given-names>J. P.</given-names> <surname>O’Doherty</surname></string-name>, “<article-title>States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>,” <source>Neuron</source>, vol. <volume>66</volume>, no. <issue>4</issue>, pp. <fpage>585</fpage>–<lpage>595</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>N. D.</given-names> <surname>Daw</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Niv</surname></string-name>, and <string-name><given-names>P.</given-names> <surname>Dayan</surname></string-name>, “<article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>,” <source>Nature neuroscience</source>, vol. <volume>8</volume>, no. <issue>12</issue>, pp. <fpage>1704</fpage>–<lpage>1711</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>G. E.</given-names> <surname>Crooks</surname></string-name>, “<article-title>Nonequilibrium measurements of free energy differences for microscopically reversible markovian systems</article-title>,” <source>Journal of Statistical Physics</source>, vol. <volume>90</volume>, pp. <fpage>1481</fpage>–<lpage>1487</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="other"><string-name><given-names>K.</given-names> <surname>Lehmann</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Bolis</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Ramstead</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Friston</surname></string-name>, and <string-name><given-names>P.</given-names> <surname>Kanske</surname></string-name>, <source>“An active inference approach to secondperson neuroscience,”</source> <year>2022</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Laskin</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Stooke</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Pinto</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Abbeel</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Srinivas</surname></string-name>, “<article-title>Reinforcement learning with augmented data</article-title>,” <source>Advances in neural information processing systems</source>, vol. <volume>33</volume>, pp. <fpage>19 884</fpage>–<lpage>19 895</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="other"><string-name><given-names>J. X.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Kurth-Nelson</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Tirumala</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Soyer</surname></string-name>, <string-name><given-names>J. Z.</given-names> <surname>Leibo</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Munos</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Blundell</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kumaran</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Botvinick</surname></string-name>, “<article-title>Learning to reinforcement learn</article-title>,” <source>arXiv preprint</source> <pub-id pub-id-type="arxiv">1611.05763</pub-id>, <year>2016</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>V.</given-names> <surname>Raja</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Valluri</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Baggs</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Chemero</surname></string-name>, and <string-name><given-names>M. L.</given-names> <surname>Anderson</surname></string-name>, “<article-title>The markov blanket trick: On the scope of the free energy principle and active inference</article-title>,” <source>Physics of Life Reviews</source>, vol. <volume>39</volume>, pp. <fpage>49</fpage>–<lpage>72</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>L.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Huang</surname></string-name>, and <string-name><given-names>H.</given-names> <surname>Sun</surname></string-name>, “<article-title>P300 and decision making under risk and ambiguity</article-title>,” <source>Computational intelligence and neuroscience</source>, vol. <volume>2015</volume>, pp. <fpage>1</fpage>–<lpage>1</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>Y.</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Duan</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Gu</surname></string-name>, and <string-name><given-names>Y.</given-names> <surname>Luo</surname></string-name>, “<article-title>Electrophysiological indexes of option characteristic processing</article-title>,” <source>Psychophysiology</source>, vol. <volume>56</volume>, no. <issue>10, p. e13403</issue>, <year>2019</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>A. R.</given-names> <surname>Bland</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Schaefer</surname></string-name>, “<article-title>Electrophysiological correlates of decision making under varying levels of uncertainty</article-title>,” <source>Brain research</source>, vol. <volume>1417</volume>, pp. <fpage>55</fpage>–<lpage>66</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="other"><string-name><given-names>C.</given-names> <surname>Botelho</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Fernandes</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Campos</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Seixas</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Pasion</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Garcez</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Ferreira-Santos</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Barbosa</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Maques-Teixeira</surname></string-name>, and <string-name><given-names>T. O.</given-names> <surname>Paiva</surname></string-name>, “<article-title>Uncertainty deconstructed: conceptual analysis and state-of-the-art review of the erp correlates of risk and ambiguity in decision-making</article-title>,” <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source>, pp. <fpage>1</fpage>–<lpage>21</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Sun</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Zhen</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Fu</surname></string-name>, <string-name><given-names>D.-A.</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Shimojo</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Adolphs</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Yu</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Wang</surname></string-name>, “<article-title>Decision ambiguity is mediated by a late positive potential originating from cingulate cortex</article-title>,” <source>NeuroImage</source>, vol. <volume>157</volume>, pp. <fpage>400</fpage>–<lpage>414</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><given-names>Y.</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Yi</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Cheng</surname></string-name>, and <string-name><given-names>Q.</given-names> <surname>Li</surname></string-name>, “<article-title>Common and distinct electrophysiological correlates of feedback processing during risky and ambiguous decision making</article-title>,” <source>Neuropsychologia</source>, vol. <volume>146, p. 107526</volume>, <year>2020</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>M. G.</given-names> <surname>Philiastides</surname></string-name> and <string-name><given-names>P.</given-names> <surname>Sajda</surname></string-name>, “<article-title>Eeg-informed fmri reveals spatiotemporal characteristics of perceptual decision making</article-title>,” <source>Journal of Neuroscience</source>, vol. <volume>27</volume>, no. <issue>48</issue>, pp. <fpage>13 082</fpage>–<lpage>13 091</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Hoenig</surname></string-name> and <string-name><given-names>L.</given-names> <surname>Scheef</surname></string-name>, “<article-title>Mediotemporal contributions to semantic processing: fmri evidence from ambiguity processing during semantic context veriflcation</article-title>,” <source>Hippocampus</source>, vol. <volume>15</volume>, no. <issue>5</issue>, pp. <fpage>597</fpage>–<lpage>609</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Vitello</surname></string-name>, <string-name><given-names>J. E.</given-names> <surname>Warren</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>Devlin</surname></string-name>, and <string-name><given-names>J. M.</given-names> <surname>Rodd</surname></string-name>, “<article-title>Roles of frontal and temporal regions in reinterpreting semantically ambiguous sentences</article-title>,” <source>Frontiers in human neuroscience</source>, vol. <volume>8, p. 530</volume>, <year>2014</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Emadi</surname></string-name> and <string-name><given-names>H.</given-names> <surname>Esteky</surname></string-name>, “<article-title>Neural representation of ambiguous visual objects in the inferior temporal cortex</article-title>,” <source>PloS one</source>, vol. <volume>8</volume>, no. <issue>10, p. e76856</issue>, <year>2013</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><given-names>A. R.</given-names> <surname>McIntosh</surname></string-name>, <string-name><given-names>M. N.</given-names> <surname>Rajah</surname></string-name>, and <string-name><given-names>N. J.</given-names> <surname>Lobaugh</surname></string-name>, “<article-title>Functional connectivity of the medial temporal lobe relates to learning and awareness</article-title>,” <source>Journal of Neuroscience</source>, vol. <volume>23</volume>, no. <issue>16</issue>, pp. <fpage>6520</fpage>–<lpage>6528</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><given-names>D. J.</given-names> <surname>Palombo</surname></string-name>, <string-name><given-names>M. M.</given-names> <surname>Keane</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Verfaellie</surname></string-name>, “<article-title>The medial temporal lobes are critical for reward-based decision making under conditions that promote episodic future thinking</article-title>,” <source>Hippocampus</source>, vol. <volume>25</volume>, no. <issue>3</issue>, pp. <fpage>345</fpage>–<lpage>353</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Okuda</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Fujii</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Ohtake</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Tsukiura</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Tanji</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Suzuki</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Kawashima</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Fukuda</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Itoh</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Yamadori</surname></string-name>, “<article-title>Thinking of the future and past: The roles of the frontal pole and the medial temporal lobes</article-title>,” <source>Neuroimage</source>, vol. <volume>19</volume>, no. <issue>4</issue>, pp. <fpage>1369</fpage>–<lpage>1380</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Palombo</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Keane</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Verfaellie</surname></string-name>, “<article-title>Using future thinking to reduce temporal discounting: Under what circumstances are the medial temporal lobes critical?</article-title>” <source>Neuropsychologia</source>, vol. <volume>89</volume>, pp. <fpage>437</fpage>–<lpage>444</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><string-name><given-names>D. L.</given-names> <surname>Schacter</surname></string-name> and <string-name><given-names>D. R.</given-names> <surname>Addis</surname></string-name>, “<article-title>On the nature of medial temporal lobe contributions to the constructive simulation of future events</article-title>,” <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, vol. <volume>364</volume>, no. <issue>1521</issue>, pp. <fpage>1245</fpage>–<lpage>1253</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><string-name><given-names>A. L.</given-names> <surname>Krain</surname></string-name>, <string-name><given-names>A. M.</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Arbuckle</surname></string-name>, <string-name><given-names>F. X.</given-names> <surname>Castellanos</surname></string-name>, and <string-name><given-names>M. P.</given-names> <surname>Milham</surname></string-name>, “<article-title>Distinct neural mechanisms of risk and ambiguity: a meta-analysis of decision-making</article-title>,” <source>Neuroimage</source>, vol. <volume>32</volume>, no. <issue>1</issue>, pp. <fpage>477</fpage>–<lpage>484</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Iacoboni</surname></string-name> and <string-name><given-names>E.</given-names> <surname>Zaidel</surname></string-name>, “<article-title>Interhemispheric visuo-motor integration in humans: the role of the superior parietal cortex</article-title>,” <source>Neuropsychologia</source>, vol. <volume>42</volume>, no. <issue>4</issue>, pp. <fpage>419</fpage>–<lpage>425</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><string-name><given-names>A. D.</given-names> <surname>Wagner</surname></string-name>, <string-name><given-names>B. J.</given-names> <surname>Shannon</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Kahn</surname></string-name>, and <string-name><given-names>R. L.</given-names> <surname>Buckner</surname></string-name>, “<article-title>Parietal lobe contributions to episodic memory retrieval</article-title>,” <source>Trends in cognitive sciences</source>, vol. <volume>9</volume>, no. <issue>9</issue>, pp. <fpage>445</fpage>–<lpage>453</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><string-name><given-names>D. M.</given-names> <surname>Wolpert</surname></string-name>, <string-name><given-names>S. J.</given-names> <surname>Goodbody</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Husain</surname></string-name>, “<article-title>Maintaining internal representations: the role of the human superior parietal lobe</article-title>,” <source>Nature neuroscience</source>, vol. <volume>1</volume>, no. <issue>6</issue>, pp. <fpage>529</fpage>–<lpage>533</lpage>, <year>1998</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><given-names>T. D.</given-names> <surname>Sambrook</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Hardwick</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Wills</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Goslin</surname></string-name>, “<article-title>Model-free and model-based reward prediction errors in eeg</article-title>,” <source>NeuroImage</source>, vol. <volume>178</volume>, pp. <fpage>162</fpage>–<lpage>171</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><string-name><given-names>T. B.</given-names> <surname>Williams</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Burke</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Nebe</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Preuschoff</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Fehr</surname></string-name>, and <string-name><given-names>P. N.</given-names> <surname>Tobler</surname></string-name>, “<article-title>Testing models at the neural level reveals how the brain computes subjective value</article-title>,” <source>Proceedings of the National Academy of Sciences</source>, vol. <volume>118</volume>, no. <issue>43, p. e2106237118</issue>, <year>2021</year>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><string-name><given-names>M. M.</given-names> <surname>Owens</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Gray</surname></string-name>, <string-name><given-names>M. T.</given-names> <surname>Amlung</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Oshri</surname></string-name>, <string-name><given-names>L. H.</given-names> <surname>Sweet</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>MacKillop</surname></string-name>, “<article-title>Neuroanatomical foundations of delayed reward discounting decision making</article-title>,” <source>NeuroImage</source>, vol. <volume>161</volume>, pp. <fpage>261</fpage>–<lpage>270</lpage>, <year>2017</year>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92892.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Chait</surname>
<given-names>Maria</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>The study addresses a central question in systems neuroscience (validation of active inference models of exploration) using a combination of behavior, neuroimaging, and modelling. The data provided are <bold>useful</bold> but <bold>incomplete</bold>, missing critical detail. Additionally, some of the conclusions require a comparison model, and proper consideration of alternative explanations.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92892.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This paper presents a compelling and comprehensive study of decision-making under uncertainty. It addresses a fundamental distinction between belief-based (cognitive neuroscience) formulations of choice behaviour with reward-based (behavioural psychology) accounts. Specifically, it asks whether active inference provides a better account of planning and decision-making, relative to reinforcement learning. To do this, the authors use a simple but elegant paradigm that includes choices about whether to seek both information and rewards. They then assess the evidence for active inference and reinforcement learning models of choice behaviour, respectively. After demonstrating that active inference provides a better explanation of behavioural responses, the neuronal correlates of epistemic and instrumental value (under an optimised active inference model) are characterised using EEG. Significant neuronal correlates of both kinds of value were found in sensor and source space. The source space correlates are then discussed sensibly, in relation to the existing literature on the functional anatomy of perceptual and instrumental decision-making under uncertainty.</p>
<p>Strengths:</p>
<p>
The strengths of this work rest upon the theoretical underpinnings and careful deconstruction of the various determinants of choice behaviour using active inference. A particular strength here is that the experimental paradigm is designed carefully to elicit both information-seeking and reward-seeking behaviour; where the information-seeking is itself separated into resolving uncertainty about the context (i.e., latent states) and the contingencies (i.e., latent parameters), under which choices are made. In other words, the paradigm - and its subsequent modelling - addresses both inference and learning as necessary belief and knowledge-updating processes that underwrite decisions.</p>
<p>The authors were then able to model belief updating using active inference and then look for the neuronal correlates of the implicit planning or policy selection. This speaks to a further strength of this study; it provides some construct validity for the modelling of belief updating and decision-making; in terms of the functional anatomy as revealed by EEG. Empirically, the source space analysis of the neuronal correlates licences some discussion of functional specialisation and integration at various stages in the choices and decision-making.</p>
<p>In short, the strengths of this work rest upon a (first) principles account of decision-making under uncertainty in terms of belief updating that allows them to model or fit choice behaviour in terms of Bayesian belief updating - and then use relatively state-of-the-art source reconstruction to examine the neuronal correlates of the implicit cognitive processing.</p>
<p>Weaknesses:</p>
<p>
The main weaknesses of this report lies in the communication of the ideas and procedures. Although the language is generally excellent, there are some grammatical lapses that make the text difficult to read. More importantly, the authors are not consistent in their use of some terms; for example, uncertainty and information gain are sometimes conflated in a way that might confuse readers. Furthermore, the descriptions of the modelling and data analysis are incomplete. These shortcomings could be addressed in the following way.</p>
<p>First, it would be useful to unpack the various interpretations of information and goal-seeking offered in the (active inference) framework examined in this study. For example, it will be good to include the following paragraph:</p>
<p>&quot;In contrast to behaviourist approaches to planning and decision-making, active inference formulates the requisite cognitive processing in terms of belief updating in which choices are made based upon their expected free energy. Expected free energy can be regarded as a universal objective function, specifying the relative likelihood of alternative choices. In brief, expected free energy can be regarded as the surprise expected following some action, where the expected surprise comes in two flavours. First, the expected surprise is uncertainty, which means that policies with a low expected free energy resolve uncertainty and promote information seeking. However, one can also minimise expected surprise by avoiding surprising, aversive outcomes. This leads to goal-seeking behaviour, where the goals can be regarded as prior preferences or rewarding outcomes.</p>
<p>Technically, expected free energy can be expressed in terms of risk plus ambiguity - or rearranged to be expressed in terms of expected information gain plus expected value, where value corresponds to (log) prior preferences. We will refer to both decompositions in what follows; noting that both decompositions accommodate information and goal-seeking imperatives. That is, resolving ambiguity and maximising information gain have epistemic value, while minimising risk or maximising expected value have pragmatic or instrumental value. These two kinds of values are sometimes referred to in terms of intrinsic and extrinsic value, respectively [1-4].&quot;</p>
<p>The description of the modelling of choice behaviour needs to be unpacked and motivated more carefully. Perhaps along the following lines:</p>
<p>&quot;To assess the evidence for active inference over reinforcement learning, we fit active inference and reinforcement learning models to the choice behaviour of each subject. Effectively, this involved optimising the free parameters of active inference and reinforcement learning models to maximise the likelihood of empirical choices. The resulting (marginal) likelihood was then used as the evidence for each model. The free parameters for the active inference model scaled the contribution of the three terms that constitute the expected free energy (in Equation 6). These coefficients can be regarded as precisions that characterise each subjects' prior beliefs about contingencies and rewards. For example, increasing the precision or the epistemic value associated with model parameters means the subject would update her beliefs about reward contingencies more quickly than a subject who has precise prior beliefs about reward distributions. Similarly, subjects with a high precision over prior preferences or extrinsic value can be read as having more precise beliefs that she will be rewarded. The free parameters for the reinforcement learning model included...&quot;</p>
<p>In terms of the time-dependent correlations with expected free energy - and its constituent terms - I think the report would benefit from overviewing these analyses with something like the following:</p>
<p>&quot;In the final analysis of the neuronal correlates of belief updating - as quantified by the epistemic and intrinsic values of expected free energy - we present a series of analyses in source space. These analyses tested for correlations between constituent terms in expected free energy and neuronal responses in source space. These correlations were over trials (and subjects). Because we were dealing with two-second timeseries, we were able to identify the periods of time during decision-making when the correlates were expressed.</p>
<p>In these analyses, we focused on the induced power of neuronal activity at each point in time, at each brain source. To illustrate the functional specialisation of these neuronal correlates, we present whole-brain maps of correlation coefficients and pick out the most significant correlation for reporting fluctuations in selected correlations over two-second periods. These analyses are presented in a descriptive fashion to highlight the nature and variety of the neuronal correlates, which we unpack in relation to the existing EEG literature in the discussion. Note that we did not attempt to correct for multiple comparisons; largely, because the correlations observed were sustained over considerable time periods, which would be almost impossible under the null hypothesis of no correlations.&quot;</p>
<p>There was a slight misdirection in the discussion of priors in the active inference framework. The notion that active inference requires a pre-specification of priors is a common misconception. Furthermore, it misses the point that the utility of Bayesian modelling is to identify the priors that each subject brings to the table. This could be easily addressed with something like the following in the discussion:</p>
<p>&quot;It is a common misconception that Bayesian approaches to choice behaviour (including active inference) are limited by a particular choice of priors. As illustrated in our fitting of choice behaviour above, priors are a strength of Bayesian approaches in the following sense: under the complete class theorem [5, 6], any pair of choice behaviours and reward functions can be described in terms of ideal Bayesian decision-making with particular priors. In other words, there always exists a description of choice behaviour in terms of some priors. This means that one can, in principle, characterise any given behaviour in terms of the priors that explain that behaviour. In our example, these were effectively priors over the precision of various preferences or beliefs about contingencies that underwrite expected free energy.&quot;</p>
<p>(1) Oudeyer, P.-Y. and F. Kaplan, What is intrinsic motivation? a typology of computational approaches. Frontiers in Neurorobotics, 2007. 1: p. 6.</p>
<p>
(2) Schmidhuber, J., Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-2010). Ieee Transactions on Autonomous Mental Development, 2010. 2(3): p. 230-247.</p>
<p>
(3) Barto, A., M. Mirolli, and G. Baldassarre, Novelty or surprise? Front Psychol, 2013. 4: p. 907.</p>
<p>
(4) Schwartenbeck, P., et al., Computational mechanisms of curiosity and goal-directed exploration. Elife, 2019. 8: p. e41703.</p>
<p>
(5) Wald, A., An Essentially Complete Class of Admissible Decision Functions. Annals of Mathematical Statistics, 1947. 18(4): p. 549-555.</p>
<p>
(6) Brown, L.D., A Complete Class Theorem for Statistical Problems with Finite-Sample Spaces. Annals of Statistics, 1981. 9(6): p. 1289-1300.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92892.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
Zhang and colleagues use a combination of behavioral, neural, and computational analyses to test an active inference model of exploration in a novel reinforcement learning task.</p>
<p>Strengths:</p>
<p>
The paper addresses an important question (validation of active inference models of exploration). The combination of behavior, neuroimaging, and modeling is potentially powerful for answering this question.</p>
<p>Weaknesses:</p>
<p>
The paper does not discuss relevant work on contextual bandits by Schulz, Collins, and others. It also does not mention the neuroimaging study of Tomov et al. (2020) using a risky/safe bandit task.</p>
<p>The statistical reporting is inadequate. In most cases, only p-values are reported, not the relevant statistics, degrees of freedom, etc. It was also not clear if any corrections for multiple comparisons were applied. Many of the EEG results are described as &quot;strong&quot; or &quot;robust&quot; with significance levels of p&lt;0.05; I am skeptical in the absence of more details, particularly given the fact that the corresponding plots do not seem particularly strong to me.</p>
<p>The authors compare their active inference model to a &quot;model-free RL&quot; model. This model is not described anywhere, as far as I can tell. Thus, I have no idea how it was fit, how many parameters it has, etc. The active inference model fitting is also not described anywhere. Moreover, you cannot compare models based on log-likelihood, unless you are talking about held-out data. You need to penalize for model complexity. Finally, even if active inference outperforms a model-free RL model (doubtful given the error bars in Fig. 4c), I don't see how this is strong evidence for active inference per se. I would want to see a much more extensive model comparison, including model-based RL algorithms which are not based on active inference, as well as model recovery analyses confirming that the models can actually be distinguished on the basis of the experimental data.</p>
<p>Another aspect of the behavioral modeling that's missing is a direct descriptive comparison between model and human behavior, beyond just plotting log-likelihoods (which are a very impoverished measure of what's going on).</p>
<p>The EEG results are intriguing, but it wasn't clear that these provide strong evidence specifically for the active inference model. No alternative models of the EEG data are evaluated.</p>
<p>Overall, the central claim in the Discussion (&quot;we demonstrated that the active inference model framework effectively describes real-world decision-making&quot;) remains unvalidated in my opinion.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92892.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This paper aims to investigate how the human brain represents different forms of value and uncertainty that participate in active inference within a free-energy framework, in a two-stage decision task involving contextual information sampling, and choices between safe and risky rewards, which promotes a shift from exploration to exploitation. They examine neural correlates by recording EEG and comparing activity in the first vs second half of trials and between trials in which subjects did and did not sample contextual information, and perform a regression with free-energy-related regressors against data &quot;mapped to source space.&quot; Their results show effects in various regions, which they take to indicate that the brain does perform this task through the theorised active inference scheme.</p>
<p>Strengths:</p>
<p>
This is an interesting two-stage paradigm that incorporates several interesting processes of learning, exploration/exploitation, and information sampling. Although scalp/brain regions showing sensitivity to the active-inference-related quantities do not necessarily suggest what role they play, it can be illuminating and useful to search for such effects as candidates for further investigation. The aims are ambitious, and methodologically it is impressive to include extensive free-energy theory, behavioural modelling, and EEG source-level analysis in one paper.</p>
<p>Weaknesses:</p>
<p>
Though I could surmise the above general aims, I could not follow the important details of what quantities were being distinguished and sought in the EEG and why. Some of this is down to theoretical complexity - the dizzying array of constructs and terms with complex interrelationships, which may simply be part and parcel of free-energy-based theories of active inference - but much of it is down to missing or ambiguous details.</p>
<p>In general, an insufficient effort has been made to make the paper accessible to readers not steeped in the free energy principle and active inference. There are critical inconsistencies in key terminology; for example, the introduction states that aim 1 is to distinguish the EEG correlates of three different types of uncertainty: ambiguity, risk, and unexpected uncertainty. But the abstract instead highlights distinctions in EEG correlates between &quot;uncertainty... and... risk&quot; and between &quot;expected free energy .. and ... uncertainty.&quot; There are also inconsistencies in mathematical labelling (e.g. in one place 'p(s|o)' and 'q(s)' swap their meanings from one sentence to the very next).</p>
<p>Some basic but important task information is missing, and makes a huge difference to how decision quantities can be decoded from EEG. For example:</p>
<p>
- How do the subjects press the left/right buttons - with different hands or different fingers on the same hand?</p>
<p>
- Was the presentation of the Stay/cue and safe/risky options on the left/right sides counterbalanced? If not, decisions can be formed well in advance especially once a policy is in place.</p>
<p>
- What were the actual reward distributions (&quot;magnitude X with probability p, magnitude y with probability 1-p&quot;) in the risky option?</p>
<p>The EEG analysis is not sufficiently detailed and motivated. For example,</p>
<p>
- why the high lower-filter cutoff of 1 Hz, and shouldn't it be acknowledged that this removes from the EEG any sustained, iteratively updated representation that evolves with learning across trials?</p>
<p>
- Since the EEG analysis was done using an array of free-energy-related variables in a regression, was multicollinearity checked between these variables?</p>
<p>
- In the initial comparison of the first/second half, why just 5 clusters of electrodes, and why these particular clusters? How many different variables are systematically different in the first vs second half, and how do you rule out less interesting time-on-task effects such as engagement or alertness? In what time windows are these amplitudes being measured? In the comparison of asked and not-asked trials, what trial stage and time window is being measured? Again, how many different variables, of the many estimated per trial in the active inference model, are different in the asked and not-asked trials, and how can you know which of these differences is the one reflected in the EEG effects? The authors choose to interpret that on not-asked trials the subjects are more uncertain because the cue doesn't give them the context, but you could equally argue that they don't ask because they are more certain of the possible hidden states.</p>
<p>
- The EEG regressors are not fully explained. For example, an &quot;active learning&quot; regressor is listed as one of the 4 at the beginning of section 3.3, but it is the first mention of this term in the paper and the term does not arise once in the methods.</p>
<p>
- In general, it is not clear how one can know that the EEG results reflect that the brain is purposefully encoding these very parameters while implementing this very mechanism, and not other, possibly simpler, factors that correlate with them since there is no engagement with such potential confounds or alternative models. For example, a model-free reinforcement learning model is fit to behaviour for comparison. Why not the EEG?</p>
</body>
</sub-article>
</article>