<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">97274</article-id>
<article-id pub-id-type="doi">10.7554/eLife.97274</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.97274.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Local, calcium- and reward-based synaptic learning rule that enhances dendritic nonlinearities can solve the nonlinear feature binding problem</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6124-949X</contrib-id>
<name>
<surname>Khodadadi</surname>
<given-names>Zahra</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9068-6744</contrib-id>
<name>
<surname>Trpevski</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9134-3601</contrib-id>
<name>
<surname>Lindroos</surname>
<given-names>Robert</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0550-0739</contrib-id>
<name>
<surname>Kotaleski</surname>
<given-names>Jeanette Hellgren</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Computer Science, KTH Royal Institute of Technology</institution>, Stockholm, <country>Sweden</country></aff>
<aff id="a2"><label>2</label><institution>Department of Neuroscience, Karolinska Institutet</institution>, Stockholm, <country>Sweden</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ding</surname>
<given-names>Jun</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Stanford University</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><bold>For correspondence:</bold> <email>zahra.khodadadi@scilifelab.se</email> (ZK)</corresp>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-06-17">
<day>17</day>
<month>06</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP97274</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-03-14">
<day>14</day>
<month>03</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-03-14">
<day>14</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.03.12.584462"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Khodadadi et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Khodadadi et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-97274-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>This study explores the computational potential of single striatal projection neurons (SPN), emphasizing dendritic nonlinearities and their crucial role in solving complex integration problems. Utilizing a biophysically detailed multicompartmental model of an SPN, we introduce a calcium-based, local synaptic learning rule that leverages dendritic plateau potentials. According to what is known about excitatory corticostriatal synapses, the learning rule is governed by local calcium dynamics from NMDA and L-type calcium channels and dopaminergic reward signals. In addition, we incorporated metaplasticity in order to devise a self-adjusting learning rule which ensures stability for individual synaptic weights. We demonstrate that this rule allows single neurons to solve the nonlinear feature binding problem (NFBP), a task traditionally attributed to neuronal networks. We also detail an inhibitory plasticity mechanism, critical for dendritic compartmentalization, further enhancing computational efficiency in dendrites. This <italic>in silico</italic> study underscores the computational capacity of individual neurons, extending our understanding of neuronal processing and the brain’s ability to perform complex computations.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Classically, single neurons in the nervous system have been thought to operate as simple linear integrators where the nonlinearity of dendrites can be neglected (<xref ref-type="bibr" rid="c42">McCulloch and Pitts, 1943</xref>). Based on this simplification, powerful artificial neural systems have been created, outperforming humans on multiple tasks (<xref ref-type="bibr" rid="c64">Silver <italic>et al</italic>., 2018</xref>). However, in recent decades it has been shown that active dendritic properties participate in shaping neuronal output. Not only the axon spikes, but also the dendrites can display nonlinear integration of input signals (<xref ref-type="bibr" rid="c1">Antic <italic>et al</italic>., 2010</xref>). Dendritic nonlinearities endow a neuron with the ability to perform sophisticated dendritic computations, expanding its computational power beyond what is available with the somatic voltage threshold and making it similar to a multilayer artificial neural network (<xref ref-type="bibr" rid="c48">Poirazi, Brannon and Mel, 2003</xref>).</p>
<p>A dendritic nonlinearity common among projection neurons in several brain areas is the NMDA-dependent plateau potential (<xref ref-type="bibr" rid="c45">Oikonomou <italic>et al</italic>., 2014</xref>). Plateau potentials are regenerative, all-or-none, supralinear voltage elevations triggered by spatio-temporally clustered glutamatergic input (<xref ref-type="bibr" rid="c57">Schiller <italic>et al</italic>., 2000</xref>; <xref ref-type="bibr" rid="c49">Polsky, Mel and Schiller, 2004</xref>; <xref ref-type="bibr" rid="c38">Losonczy and Magee, 2006</xref>; <xref ref-type="bibr" rid="c39">Major <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c33">Larkum <italic>et al</italic>., 2009</xref>; <xref ref-type="bibr" rid="c34">Lavzin <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c75">Xu <italic>et al</italic>., 2012</xref>). Such plateaus require that nearby spines are coactivated, but the requirement is perhaps somewhat loose as even single branches have been proposed to act as computational units (<xref ref-type="bibr" rid="c38">Losonczy and Magee, 2006</xref>; <xref ref-type="bibr" rid="c5">Branco and Häusser, 2010</xref>). With that said, multiple dendritic regions, preferentially responsive to different input values or features, are known to form with close dendritic proximity (<xref ref-type="bibr" rid="c26">Jia <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c9">Chen <italic>et al</italic>., 2011</xref>; <xref ref-type="bibr" rid="c70">Varga <italic>et al</italic>., 2011</xref>). Such functional synaptic clusters are present in multiple species, developmental stages and brain regions (<xref ref-type="bibr" rid="c32">Kleindienst <italic>et al</italic>., 2011</xref>; <xref ref-type="bibr" rid="c67">Takahashi <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c73">Winnubst <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c72">Wilson <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c25">Iacaruso, Gasler and Hofer, 2017</xref>; <xref ref-type="bibr" rid="c58">Scholl, Wilson and Fitzpatrick, 2017</xref>; <xref ref-type="bibr" rid="c44">Niculescu <italic>et al</italic>., 2018</xref>; <xref ref-type="bibr" rid="c31">Kerlin <italic>et al</italic>., 2019</xref>; <xref ref-type="bibr" rid="c28">Ju <italic>et al</italic>., 2020</xref>). Hence, multiple features are commonly clustered in a single dendritic branch, indicating that this could be the neural substrate where combinations of simple features into more complex items occur.</p>
<p>Combinations of features in dendritic branches further provide single neurons with the possibility to solve linearly non-separable tasks, such as the nonlinear feature binding problem (NFBP) (<xref ref-type="bibr" rid="c68">Tran-Van-Minh <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c20">Gidon <italic>et al</italic>., 2020</xref>). In the most elementary form, the NFBP consists of discriminating between two groups of feature combinations. The problem is nonlinear since the neuron should learn to respond only to specific feature combinations, even though all features are represented by the same amount of synaptic input. Common example features used are two different shapes combined with two different colors, giving in total four combinations of which the neuron should respond to only two feature combinations (exemplified in <xref rid="fig1" ref-type="fig">Fig. 1A</xref> and <xref rid="fig1" ref-type="fig">1B</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Learning Mechanisms in direct pathway Striatal Projection Neurons (dSPNs) for the Nonlinear Feature Binding Problem (NFBP)</title>
<p>A: Inputs and assumed supralinearity that could solve the NFBP: The NFBP is represented with an example from visual feature binding. In the simplest form of the NFBP, a stimulus has two features, here shape and form, each with two possible values, strawberry and banana, and red and yellow, respectively. The NFBP consists of responding with neuronal spiking to two of the feature combinations, corresponding to the relevant stimuli (red strawberry and yellow banana), and remaining silent for the other two feature combinations which represent the irrelevant stimuli (yellow strawberry and red banana). Assuming that each feature is represented with locally clustered synapses, a solution of the NFBP can be achieved when the co-active clusters on a single dendrite, representing the features of a relevant stimulus, evoke a plateau potential, thus supralinearly exciting the soma. Conversely, co-activation of synaptic clusters for the irrelevant combinations should not evoke plateau potentials.</p><p>B: Dendritic Learning: Illustration of how synaptic plasticity in SPNs may contribute to solving the NFBP for a pre-existing arrangement of synaptic clusters on two dendrites. A plasticity rule which strengthens only synaptic clusters representing relevant feature combinations, so that they produce robust supralinear responses, while weakening synapses activated by irrelevant feature combinations, could solve the NFBP.</p><p>C: Dopamine (Da) Feedback in Learning: dopaminergic feedback from the midbrain to the striatum (Str) guides the learning process, differentiating between positive feedback for relevant stimuli and negative feedback for irrelevant stimuli. Positive feedback represented by dopamine peaks is necessary for LTP, and negative feedback represented by a dopaminergic pause is necessary for LTD.</p><p>D: Signaling pathways underlying synaptic plasticity in dSPNs: Illustrations of molecular components at the corticostriatal synapse that modify synaptic strength (redrawn from Shen et al., 2009). NMDA calcium influx, followed by stimulation of D<sub>1</sub> dopamine receptors (D<sub>1</sub>Rs), triggers LTP (while inhibiting the LTD cascade). L-type calcium influx and activation of metabotropic glutamate receptors (mGluRs) when D<sub>1</sub>Rs are free of Da triggers LTD (while counteracting the LTP cascade).</p></caption>
<graphic xlink:href="584462v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As a task, the NFBP is relevant to brain regions which perform integration of multimodal input signals, or signals representing different features of the same modality (<xref ref-type="bibr" rid="c53">Roskies, 1999</xref>). It is usually illustrated with examples from the visual system, as in <xref rid="fig1" ref-type="fig">Fig. 1A</xref> (<xref ref-type="bibr" rid="c53">Roskies, 1999</xref>; <xref ref-type="bibr" rid="c40">von der Malsburg, 1999</xref>; <xref ref-type="bibr" rid="c68">Tran-Van-Minh <italic>et al</italic>., 2015</xref>). A region that integrates multimodal inputs, such as sensory information and motor-related signals, is the input nucleus of the basal ganglia, the striatum (<xref ref-type="bibr" rid="c51">Reig and Silberberg, 2014</xref>; <xref ref-type="bibr" rid="c27">Johansson and Silberberg, 2020</xref>), and this system will be used in the present modeling study. We will here, however, continue to illustrate the NFBP with the more intuitive features borrowed from the visual field, although for dorsal striatum these features would rather map onto different sensory- and motor-related features. Plateau potentials and some clustering of input have been demonstrated in SPNs (<xref ref-type="bibr" rid="c47">Plotkin, Day and Surmeier, 2011</xref>; <xref ref-type="bibr" rid="c45">Oikonomou <italic>et al</italic>., 2014</xref>; <xref ref-type="bibr" rid="c15">Du <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c24">Hwang <italic>et al</italic>., 2022</xref>; <xref ref-type="bibr" rid="c11">Day <italic>et al</italic>., 2024</xref>; <xref ref-type="bibr" rid="c54">Sanabria <italic>et al</italic>., 2024</xref>).</p>
<p>In addition to integrating convergent input from the cortex and the thalamus, the striatum is densely innervated by midbrain dopaminergic neurons which carry information about rewarding stimuli (<xref ref-type="bibr" rid="c59">Schultz, 2007</xref>; <xref ref-type="bibr" rid="c41">Matsuda <italic>et al</italic>., 2009</xref>; <xref ref-type="bibr" rid="c66">Surmeier <italic>et al</italic>., 2010</xref>). As such, the striatum is thought to be an important site of reward learning, associating actions with outcomes based on neuromodulatory cues. In this classical framework, peaks in dopamine (Da) signify rewarding outcomes and pauses in dopamine represent omission of expected rewards (<xref ref-type="bibr" rid="c60">Schultz, Dayan and Montague, 1997</xref>). Dopamine signals further control the synaptic plasticity of corticostriatal synapses on the SPNs (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>). In direct pathway SPNs (dSPN) expressing the D<sub>1</sub> receptor, a dopamine peak stimulates the D<sub>1</sub> receptor, which together with significant calcium influx through NMDA receptors triggers synaptic strengthening (long-term potentiation - LTP). Conversely, when little/no dopamine is bound to the D<sub>1</sub> receptors, as during a dopamine pause, and there is significant calcium influx through L-type calcium channels, synaptic weakening occurs (long-term depression - LTD) (<xref ref-type="bibr" rid="c61">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c16">Fino <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c46">Plotkin <italic>et al</italic>., 2013</xref>) (see <xref rid="fig1" ref-type="fig">Fig. 1D</xref>).</p>
<p>If dopamine peaks are associated with the relevant feature combinations in the NFBP and dopamine pauses with the irrelevant ones, it can trigger LTP in synapses representing the relevant feature combinations and LTD in those representing irrelevant combinations. If, after learning, the relevant feature combinations have strong enough synapses so they can evoke plateau potentials while the irrelevant feature combinations have weak enough synapses so they don’t evoke plateaus, the outcome of this learning process should be a synaptic arrangement that could solve the NFBP (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>) (<xref ref-type="bibr" rid="c68">Tran-Van-Minh <italic>et al</italic>., 2015</xref>). In line with this, it has been demonstrated that the NFBP can be solved in abstract neuron models where the soma and dendrites are represented by single electrical compartments and where neuronal firing and plateau potentials are phenomenologically represented by instantaneous firing rate functions (<xref ref-type="bibr" rid="c35">Legenstein and Maass, 2011</xref>; <xref ref-type="bibr" rid="c56">Schiess, Urbanczik and Senn, 2016</xref>). Good performance on the NFBP has also been demonstrated with biologically detailed models (<xref ref-type="bibr" rid="c2">Bicknell and Häusser, 2021</xref>). This solution used a multicompartmental model of a single pyramidal neuron, including both excitatory and inhibitory synapses and supralinear NMDA depolarizations. Synapses representing different features were randomly dispersed throughout the dendrites and a phenomenological learning rule - dependent on somatic spike timing and high local dendritic voltage - were used to optimize the strength of the synapses. The solution did, however, depend on a form of supervised learning as somatic current injections were used to raise the spiking probability of the relevant feature combinations.</p>
<p>In this article we develop a local, calcium-dependent synaptic learning rule based on the known synaptic machinery of the corticostriatal synapse onto dSPNs (<xref ref-type="bibr" rid="c61">Shen <italic>et al</italic>., 2008</xref>), which, guided by the reward signals from dopaminergic neurons, can solve the NFBP in a multicompartment model of a dSPN. The learning rule is initially tested assuming pre-existing clustered synapses for each individual feature, potentiating synaptic clusters to the point where they can evoke robust plateau potentials for the relevant feature combinations of the NFBP, and weakening synapses representing irrelevant features. We also apply the learning rule on more randomly distributed synapses, and results suggest that branch-specific plasticity might be important for the single neuron to solve nonlinear problems. Although brain systems integrating multimodal inputs, such as the striatum, somehow solve nonlinear problems at the network/systems level, it is not known whether any individual neuron in the brain actually solves the NFBP on a regular basis. Our investigation suggests, however, that single SPNs have the computational capacity to solve linearly non-separable tasks by utilizing information of the organism’s success (here represented by a dopamine peak) and failures (here a dopamine pause). This might also generalize to other projection neurons that can display dendritic plateaus, such as pyramidal neurons. Depending on neuron and synapse type, however, the specific feedback mechanisms (which in this case is dopamine) will have to be mapped to another neuromodulatory signal.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Characterization of the dendritic NMDA-dependent nonlinearities in the model</title>
<p>The nonlinear, sigmoidal voltage sensitivity of the NMDA receptors is a crucial element for formation of dendritic plateau potentials. We use a model for generating plateau potentials first presented in <xref ref-type="bibr" rid="c19">Gao <italic>et al</italic>., (2021)</xref> and adjusted to SPNs (<xref ref-type="bibr" rid="c69">Trpevski <italic>et al</italic>., 2023</xref>). To produce robust, all-or-none plateau potentials, glutamate spillover from the synaptic cleft that activates extrasynaptic NMDA receptors is included in the model. Glutamate spillover occurs when the total synaptic weight (normalized value) of the activated synapses reaches a threshold value (see Methods). The threshold value here is set to be equivalent to the total weight of 10 clustered synapses with weights of 0.2 each (weight 0.2 corresponds to 0.5 nS). <xref rid="fig2" ref-type="fig">Figure 2A</xref> shows the somatic membrane potential following synaptic activation of a cluster of synapses of increasing size and the corresponding local spine membrane potential (averaged over all spines in the cluster) as well as the NMDA and L-type calcium accumulated in a single spine (also averaged over all spines in the cluster). A plateau potential is generated when a critical level of total NMDA conductance in a dendritic segment is reached (accomplished here by the addition of more synapses in a cluster and by glutamate spillover). Reaching the spillover threshold produces a sudden and robust increase in NMDA conductance, caused by the activation of extrasynaptic NMDA receptors (where the clearance of glutamate is assumed to be slower), thus triggering an all-or-none plateau potential as investigated in <xref ref-type="bibr" rid="c69">Trpevski <italic>et al</italic>., (2023)</xref>.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Characterization of dendritic plateau behavior in the model.</title>
<p>A: Somatic voltage, spine voltage, NMDA calcium ([Ca]<sub>NMDA</sub>), and L-type calcium ([Ca]<sub>L-type</sub>) evoked by a cluster varying in size from 1 to 20 synapses. A plateau potential is evoked after a threshold level of NMDA conductance is exceeded, here set at 10 synapses with a weight of 0.2 each (corresponding to the “baseline” weights in C). The traces for spine voltage, [Ca]<sub>NMDA</sub>, and [Ca]<sub>L-type</sub> are averages over all activated spines in the cluster.</p><p>B: Schematic of the neuron morphology with an arrow indicating the stimulated dendritic branch in A.</p><p>C: Maximal amplitude of the measures shown in A averaged over 10 dendritic locations. The curves represent clusters with different synaptic weights: baseline (0.2), strengthened (0.28) and weakened weights (0.15). Somatic voltages higher than the action potential threshold were set to −50 mV. A synaptic background noise is used in all simulations to elevate the membrane potential to ranges seen in vivo (<xref ref-type="bibr" rid="c51">Reig and Silberberg, 2014</xref>).</p></caption>
<graphic xlink:href="584462v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The synaptic input to the neuron is provided through the activation of a cluster of synapses at the indicated location in <xref rid="fig2" ref-type="fig">Fig. 2B</xref>, and gives the voltage and calcium responses in <xref rid="fig2" ref-type="fig">Fig. 2A</xref>. <xref rid="fig2" ref-type="fig">Figure 2C</xref> shows the maximal amplitudes of the somatic voltage and of the NMDA and L-type calcium signals in the dendritic spines, averaged over 10 trials and over 10 dendrites, and shown for three different synaptic weights in the clusters. The “baseline” results in <xref rid="fig2" ref-type="fig">Fig. 2C</xref> are within the range of the initial synaptic weights of excitatory synapses in all remaining figures in the article, and thus illustrate a possible initial situation before learning. Stronger and weaker synapses require a smaller and a larger cluster to trigger a plateau potential, respectively. In the simulation using “strengthened” synapses the synaptic weights in the cluster are 40% greater than in the “baseline” case, and hence need fewer synapses to trigger plateau potentials. Conversely, with weaker synapses where weights are 25% smaller than the “baseline” case, more synapses are needed to evoke a plateau.</p>
<p>To summarize, the dSPN model exhibits the dendritic nonlinearities required for solving the NFBP. If a cluster of strengthened synapses can reliably generate robust plateau potentials, this increases the likelihood for somatic spiking compared to when a more gradual NMDA dependent nonlinearity occurs in the dendrite. This also means that the neuron can reliably spike following the activation of a set of synapses strengthened (see illustration in <xref rid="fig1" ref-type="fig">Fig. 1</xref>).</p>
<p>Conversely, a cluster of weakened synapses will most likely not generate plateau potentials, and thus the neuron will spike with much lower probability following activation of such a cluster.</p>
</sec>
<sec id="s2b">
<title>Characterization of the plasticity rule</title>
<p>To characterize the learning rule we start with a simple setup where three features (each illustrating either a color or a shape) are distributed onto two dendritic branches, so that one relevant and one irrelevant feature combination can be represented per dendrite (see <xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Each feature is represented with 5 synapses, and we start with assuming that those synapses are already organized in pre-existing clusters. In addition to background synaptic noise inputs (compare <xref rid="fig1" ref-type="fig">Fig. 1</xref>), we also added 108 distributed glutamatergic synapses that were activated together with all four stimuli, i.e. they were feature-unspecific. SPNs have a very hyperpolarized resting potential, and the additional feature-unspecific synapses allow the neurons to spike often enough in the beginning of the learning process so that a dopamine feedback signal would be elicited and trigger learning in the activated synapses. The neuron model was then activated with a sequence of feature combinations (960 here) including equal amounts of relevant (i.e. ‘red strawberry’ and ‘yellow banana’) and irrelevant feature combinations (i.e. ‘yellow strawberry’ and ‘red banana’). Thus, since the neuron always spikes initially due to the feature unspecific synapses, dopamine peaks and dopamine pauses arrive equally much. <xref rid="fig3" ref-type="fig">Fig. 3A</xref> shows an illustration of the setup. When the neuron spikes for the relevant feature combinations, dopamine rewards are delivered, triggering LTP in those active synapses with NMDA Ca levels within the LTP kernel, while spiking for the irrelevant feature combinations elicits a dopamine pause as feedback, instead triggering LTD as a function of L-type Ca. As learning progresses, the cell learns to respond only to the relevant feature combinations (see example in <xref rid="fig3" ref-type="fig">Fig. 3B</xref>). Initially all four stimuli, ‘yellow banana’ and ‘red banana’ in dendrite 1, and ‘red strawberry’ and ‘yellow strawberry’ in dendrite 2, elicited robust supralinear responses (as they together reached the threshold for glutamate spillover in our model). After learning the neuron could differentiate between the two sets of stimuli. The relevant feature combinations associated with a reward continued to provoke a plateau potential, eliciting somatic spiking. In contrast, the neuron’s response to irrelevant feature combinations was notably decreased following LTD in the synapses on the dendrite where this feature is irrelevant.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Example of setup and learning-induced synaptic plasticity</title>
<p>A: Illustration of input configuration. Upper panel shows the arrangement of the features in two dendrites. Each dendrite has synaptic clusters for three features allowing the representation of each of the four feature combinations if seen from the whole neuron’s perspective. Also, the feature combinations allow for only one relevant feature combination per dendrite. The middle panel illustrates the stimulation protocol used in the simulation where stimuli presentation is followed by a dopaminergic feedback signal only if the neuron spikes. The two features representing a stimulus are active within 20 ms, and dopamine feedback, lasting for 50 ms, is delivered 300 ms after the beginning of the stimulus. Two stimuli are spaced 800 ms apart, to allow for the calcium dynamics to reach baseline levels. The bottom panel illustrates the stimulus sequence over the full learning task: all stimuli are equally present in a sequence of 12 stimuli.</p><p>B: Example voltage in the soma and the two dendrites before and after learning. Each dendrite stops responding to the irrelevant feature represented by its synaptic clusters.</p><p>C: Evolution of synaptic conductances throughout learning. The left panel shows the conductances of the clustered synapses in one of the dendrites (dendrite 1, d<sub>1</sub>). B, Y and R stand for ‘banana’, ‘yellow’ and ‘red’, respectively. The right panel shows the distributed feature-unspecific synapses. The initial synaptic conductances are set to 0.25 ± 0.05 (around 0.625 nS). The purple trace exemplifies a synapse that is weakened, while the green and blue traces exemplify synapses that are close to the clusters (blue) or by chance (green) have a sufficiently high local NMDA calcium level for LTP to dominate.</p><p>D: Peak calcium (dots) and plasticity kernel dynamics (solid lines) during learning. The left panel shows the NMDA calcium of a single ‘banana’ and a single ‘yellow’ synapse that undergo LTP as well as for a single red feature synapse undergoing LTD in dendrite 1 (marked with arrows in the left panel in C). The right panel shows the NMDA calcium for the feature-unspecific synapses identified in the right panel of C.</p></caption>
<graphic xlink:href="584462v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig3" ref-type="fig">Figure 3C</xref> shows the evolution of synaptic conductances during the learning process for dendrite 1 (dendrite 2 is not shown, but has the same behavior). The synapses representing the relevant feature combination in this dendrite (‘yellow’ and ‘banana’) are typically strengthened, eventually encoding this stimulus robustly. Conversely, the synapses for the feature ‘red’, activated during the irrelevant feature combination (‘red banana’) are all weakened, making the dendrite only weakly responsive to this stimulus following learning. Note that LTD also occurs in some of the synapses representing the features yellow as well as ‘banana’ as these features are also parts of the irrelevant stimuli (yellow strawberry and ‘red banana’, respectively). Nevertheless, the reward process still causes the remaining yellow synapses to strengthen, albeit to a lower level than the synapses for the feature ‘banana’ due to the LTD that has occurred (when combined with strawberry). This is because of the learning rule that successively slides the LTP NMDA Ca dependent plasticity kernel over training (see Methods). This means that our learning rule tends to stabilize the number of synapses that are needed to perform the task, but not necessarily all the synapses carrying the relevant features. Depending on the initial local Ca response in the synapse to relevant and irrelevant stimuli, individual synapses might either be preferentially recruited into the LTP or LTD process.</p>
<p>The NMDA calcium levels shown in <xref rid="fig3" ref-type="fig">Fig. 3D</xref>, left panel, shows examples on how the different synapses stabilize at their particular conductances/weights (for three example synapses marked with arrows in 3C). With repeated dopamine rewards, the metaplasticity kernel moves towards lower calcium levels, while a dopamine pause moves the kernel to higher calcium levels (i.e. it becomes easier for a synapse to strengthen for a slightly lower local calcium level if a reward has been seen often and also if the synapse is not being activated too often during reward omissions). Because the rate of metaplasticity kernel adaptation towards higher calcium levels is faster when the neuron makes errors (omitted rewards) on the NFBP, the kernels for all features move higher. This results in LTD in the ‘red’ synapses on the dendrite, while LTP develops in most of the ‘yellow’ and ‘banana’ synapses in dendrite 1. The upward shift in the kernel serves to prevent excessive strengthening in the weakened ‘red’ synapses on dendrite 1 when rewards for ‘red strawberry’ arrive (due to learning in dendrite 2), as they no longer fall within the optimal calcium range for LTP. In contrast to this, most synapses for ‘yellow’ and ‘banana’ are strengthened initially, but as their LTP kernels move downwards due to rewards and a sufficiently high NMDA calcium locally, no further LTP occurs. This means that in our learning rule, synapses tend to stop changing their weights when the neuron can perform the NFBP.</p>
<p>The feature-unspecific synapses exhibit different types of behaviors, which are primarily determined by the initial positioning of their calcium levels with respect to the optimal learning zone of the LTP plasticity kernel (<xref rid="fig3" ref-type="fig">Fig. 3C</xref> and <xref rid="fig3" ref-type="fig">3D</xref>, right panels). The common trend of gradual weakening of these synapses, triggered by co-activation with irrelevant stimuli and subsequent dopaminergic pauses, is due to the metaplasticity kernel shifting away from the calcium level necessary for LTP. This shift increases the likelihood of LTD (initially during the training this occurs half of the time) This general weakening is exemplified by the purple trace in the right panel of <xref rid="fig3" ref-type="fig">Fig. 3D</xref>.</p>
<p>However, not all feature-unspecific synapses follow this trend. Some synapses, like the one depicted in blue, are situated close enough to the input clusters to experience increased NMDA Ca levels, enabling them to strengthen their synaptic connections. Finally, there are also a few feature-unspecific synapses that randomly happen to trigger calcium levels within the optimal learning region of the LTP plasticity kernel, causing enhanced LTP at the beginning (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>, right panel, green trace). However, as the LTD amplitude is proportional to the L-type calcium level, the LTD-drive eventually becomes too high, pushing the calcium level below the LTP-kernel from which a period of LTD-only follows until synapses stabilize. To summarize, initially all synapses, clustered and feature-unspecific, may experience some LTP as dopamine rewards are delivered initially half of the time. However, as omitted rewards occuring for irrelevant stimuli cause the LTP metaplasticity kernel to slide higher, only clustered synapses signaling relevant feature combinations (and synapses close to them), where supralinear voltage effects cause high NMDA calcium, remain in the optimal learning region of the LTP kernel and a few undergo LTP before stabilizing. Note that learning is always “on”, i.e. weight updates happen for each training example, meaning that there are no separate training and testing phases. The reason why synapse weights stop changing and stabilize is because the neuron performance improves so fewer and fewer omitted rewards occur (and this halts the LTD process) while at the same time the LTP kernel slides downwards when the neuron responds correctly most of the time and thus receives a reward (and this halts the LTP process).</p>
</sec>
<sec id="s2c">
<title>Characterization of input combinations that can be learned</title>
<p>After showing that the SPN can learn to separate relevant from irrelevant stimuli in the single example in <xref rid="fig3" ref-type="fig">Fig. 3</xref>, we next generalized the setup by giving different innervations of the four features to the two dendrites and recorded the performance of the SPN on the NFBP as learning progressed. Out of all possible feature innervations to two dendrites, we used only the innervations containing both relevant feature combinations arranged at least one per dendrite, as these are the cases with enough feature innervation to possibly solve the NFBP (for an illustration see <xref rid="fig4" ref-type="fig">Fig. 4A</xref>). We then estimated how the performance developed over training, i.e. whether the SPN spiked for the right feature combinations and was silent for the irrelevant ones. Performance of 100% indicates that the neuron spikes only for the relevant stimuli and is silent for the irrelevant stimuli. Performance of 50% can indicate two situations: i) either the neuron spikes for all four stimuli, or ii) is silent for all four stimuli. Performance of 75% indicates spiking behavior between the following two cases: i) the SPN spikes for only one of the relevant feature combinations, remaining silent for the other three, or ii) it is silent for one of the irrelevant feature combinations while spiking for the other three. In this study we consider the NFBP solved when the performance is greater than 87.5%, exemplified by the situation where the SPN always spikes for one relevant stimulus, and at least half of the time for the other relevant stimulus, while remaining silent for the irrelevant stimuli. In the cases with two or three features innervating one dendrite (where one relevant feature combination is present per dendrite) the mean performance is above 90%, indicating that both stimuli are learned (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>, purple traces). In the cases when all four features can innervate at least one of the dendrites, typically only one relevant feature combination (i.e. ‘red strawberry’ or ‘yellow banana’) could be correctly learned (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>, light blue traces). In this case the same feature combination is usually encoded in both dendrites. In <xref rid="fig4" ref-type="fig">Fig. 4C</xref> the performance over the last 160 training examples of the simulation is shown, for each of the four stimuli separately. <xref rid="fig4" ref-type="fig">Fig. 4C<sub>1</sub></xref> shows the performance for the purple traces in <xref rid="fig4" ref-type="fig">Fig. 4B</xref>, while <xref rid="fig4" ref-type="fig">Fig. 4C<sub>2</sub></xref> shows the same for the light blue traces in <xref rid="fig4" ref-type="fig">Fig. 4B</xref>. This illustrates that for the purple traces in <xref rid="fig4" ref-type="fig">Fig. 4B</xref>, the NFBP is solved by the neuron, and the mistakes are usually made by firing for some of the irrelevant feature combinations. For the light blue traces in <xref rid="fig4" ref-type="fig">Fig. 4B</xref>, the NFBP is usually not solved, with somatic spiking for the relevant stimuli occurring only around 75% of the time. Additionally, spiking for the irrelevant stimuli is increased.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Impact of feature combinations and synaptic cluster locations on NFBP learning performance</title>
<p>A-C: NFBP configurational analysis. Configurations are categorized based on the number of features per dendrite, those with two or three features (purple traces) and those with all four features on at least one dendrite (light blue traces).</p>
<p>A: Illustration of the setup of the task where two, three or four features are given in two dendritic locations.</p><p>B: Performance trajectories for the combinatorial task illustrated in A. Traces of the performance of the model over time for 31 unique feature configurations. Light blue lines show combinations with four features in at least one dendrite, while purple lines show input with maximally 3 input in the local dendritic branches. Right-side histograms display the distribution of the end performance.</p><p>C: Outcome results split on stimuli for configurations where maximally three features in one dendritic location (C<sub>1</sub>) or at least one dendrite has all four features present in a single dendrite (C<sub>2</sub>).</p><p>D and E: End performance in a three-feature configuration as a function of cluster location. D illustrates the location of the inputs, and E shows end performance in the three-pattern configuration as a function of somatic distance of the synapse clusters. Initial synaptic weight is 0.25 ± 0.05 in all the simulation experiments.</p></caption>
<graphic xlink:href="584462v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Optimal learning is achieved at intermediate distances from soma through excitatory plasticity</title>
<p>We also investigated the impact of synaptic positioning on learning (<xref rid="fig4" ref-type="fig">Fig. 4 D</xref>) when using the same settings as in <xref rid="fig3" ref-type="fig">Fig. 3</xref>, but varying dendritic locations. Our results predict that the best performance on the NFBP is obtained with synaptic clusters positioned at intermediate somatic distances from the soma (<xref rid="fig4" ref-type="fig">Fig. 4E</xref>). From <xref rid="fig4" ref-type="fig">Fig. 4E</xref> one can infer that after learning the proximal synapses have actually decreased when trained on the NFBP as the performance is around 50%. The neuron stays silent for the irrelevant feature combinations (blue dots), which is the correct response, but also the neuron can’t respond to the relevant feature combinations (red dots). For successively more distal synapses the performance increases and then slightly decreases for the most distal clusters that sometimes fail to evoke somatic spiking for the correct feature combinations (red dots). This result can be conceptually explained in the following way. The electrotonic properties of dendrites dictate that synapses near the soma, in the most proximal regions, are less capable of inducing supralinear potentiation underlying plateau potentials (<xref ref-type="bibr" rid="c15">Du <italic>et al</italic>., 2017</xref>). This is due to the soma acting as a current sink, resulting in smaller localized voltage changes (and hence a lower input resistance in accordance with Ohm’s law). Consequently, these synapses cannot easily evoke dendritic nonlinearities necessary for solving the NFBP, and hence the performance with proximal clusters is low for NFBP. Note that in our simulations we allow glutamatergic synapses on spines quite close to the soma, although SPN dendritic spines are relatively rare at more proximal distances than 40-50 <italic>μ</italic>m from the soma (<xref ref-type="bibr" rid="c71">Wilson <italic>et al</italic>., 1983</xref>).</p>
<p>In contrast, the most distal dendritic regions are electrically more isolated and have a higher local input resistance, enabling larger voltage changes locally and thus also higher local calcium concentrations when synapses are activated in our model. This allows even a small number of active synapses to generate local supralinear NMDA-dependent responses. Such ease of elevating the local calcium, seems advantageous, but in fact results in decreased performance on the NFBP for the following reasons. In the distal synaptic clusters related to irrelevant stimuli, local calcium levels might stay in the optimal learning region of the LTP kernel despite omitted rewards occurring regularly and thus the weakening of the synapses takes longer. This causes increased somatic stimulation for irrelevant stimuli, sometimes leading to spiking over a longer period during the training. In addition, distally evoked dendritic signals, including plateau potentials from strengthened synaptic clusters, naturally attenuate more before they reach the soma, and sometimes fail to elicit somatic spiking. As a consequence, compared to more optimally placed clusters, the proportion of negative feedback signals is increased and that of positive feedback is decreased. The altered feedback results in a decreased capacity to selectively reinforce the active synapses to only relevant stimuli and weaken synapses activated with irrelevant stimuli.</p>
<p>The ideal learning zone for NFBP in our simulations thus lies at an intermediate somatic distance, roughly 100-150 µm from the soma, where synapses can effectively contribute to learning the NFBP (<xref rid="fig4" ref-type="fig">Fig. 4 E</xref>). In this zone synaptic changes are more likely to impact the neuron’s firing probability as the dendritic plateau potential at this location causes a larger elevation of the somatic potential, and thus synapses at this distance benefit more from the dopamine feedback loop. Note that the prediction that proximal and very distal synapses are less likely to contribute to the solving of the NFBP doesn’t imply they are not important for more ‘linear’ learning contexts. For instance, if we had trained the neuron to only respond to one single stimulus, such as ‘red strawberry’, both proximal and very distal synapses representing that stimulus would of course be able to both strengthen or weaken as well as contribute to spiking of the neuron following learning.</p>
</sec>
<sec id="s2e">
<title>The possible role of inhibitory plasticity in learning</title>
<p>In our initial simulations we assumed that only the excitatory synapses could undergo plasticity during learning, and we identified two critical observations that highlight possible areas for improvement. The first is a vulnerability to noise, which resulted in a performance around 90 percent, as illustrated in <xref rid="fig4" ref-type="fig">Fig. 4B</xref>. The second is decrease in performance observed across very distal synapses, as detailed in <xref rid="fig4" ref-type="fig">Fig. 4E</xref>. These findings prompted us to explore the potential role of inhibitory synapses in addressing these challenges.</p>
<p>We therefore developed a phenomenological inhibitory plasticity rule to enhance dendritic nonlinearities (detailed in the Methods section). The rule is designed to compartmentalize a dendrite so that it mostly responds to excitatory inputs that cause the strongest dendritic activation. It achieves this by weakening inhibitory connections at highly active excitatory synapses based on the local increase in voltage-dependent calcium, reinforcing their dominance, and strengthening them where excitatory activity is lower (and thus as well local calcium concentration, see Methods for details).</p>
<p>To demonstrate our inhibitory plasticity rule, we use the same excitatory synapse setup as in <xref rid="fig4" ref-type="fig">Fig. 4</xref> to which we add four inhibitory synapses near each cluster in the middle of the dendritic branch, representing each of the four features (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). Thus, a single feature activates both the excitatory and inhibitory synapses. To achieve a level of depolarization and spike probability comparable to that in our excitatory-only setup, we increased the distributed synaptic input from 108 to 144. Alongside this, we began with low inhibitory synaptic weights. This was key to maintaining higher baseline activity in our model as starting with strong inhibitory weights could excessively suppress excitatory activity as e.g. inhibitory inputs close to clustered synapses effectively can counteract the NMDA-dependent nonlinearities (<xref ref-type="bibr" rid="c14">Doron <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c15">Du <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c13">Dorman, Jędrzejewska-Szmek and Blackwell, 2018</xref>). This setup ensured that we could clearly observe how learning modified synaptic connections without initial excessive inhibition preventing the dendritic nonlinearities initially.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Effects of inhibitory inputs on performance</title>
<p>A: Dendritic input configuration with inhibitory synapses added. Illustrations depict two dendritic branches, each with synaptic connections from three excitatory and four inhibitory features, but the general setup is the same as in <xref rid="fig4" ref-type="fig">Fig. 4</xref>.</p><p>B: Displays average performance for configurations with varying pattern configurations as a comparison between the setup with (orange) and without inhibitory plasticity (blue).</p><p>C: Shows task-specific performances for dendritic locations of the clustered synapses, with individual dots and curves representing fitted performance curves with (solid) and without plastic inhibition (dashed).</p><p>D: Synaptic conductance changes during learning. Left panel shows excitatory synaptic conductances in dendrite 1 during learning. The right panel shows the inhibitory synaptic conductances. B, Y, R and S stands for ‘banana’, ‘yellow’, ‘red’ and ‘strawberry’.</p><p>E: Peak calcium (dots) and plasticity thresholds dynamics (lines) over the learning. The left panel shows examples of the postsynaptic calcium amplitude of the clustered spines in dendrite 1 (marked with arrows on the left panel in D). The right panel tracks calcium levels at inhibitory synapses. The Upper threshold (T<sub>max</sub>) captures peak calcium levels while the lower threshold (T<sub>min</sub>) identifies the next highest. Stability achieved at both thresholds enhances contrast between the activity levels and makes the dendrites respond preferentially to one relevant feature combination at that dendritic site.</p></caption>
<graphic xlink:href="584462v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As in the example in <xref rid="fig3" ref-type="fig">Fig. 3</xref>, the conductances of the excitatory inputs representing ‘yellow’ and ‘banana’ increase to cluster the ‘yellow banana’ pairing, while the weights of synapses representing the feature ‘red’ decrease (<xref rid="fig5" ref-type="fig">Fig. 5D</xref>, left panel). Conversely, the inhibitory synapses associated with the ‘yellow’ and ‘banana’ features, linked to excitatory synapses, are instead further weakened, while those linked to ‘red’ and ‘strawberry’ features in the same compartment are strengthened (<xref rid="fig5" ref-type="fig">Fig. 5D</xref>, right panel). This outcome of the inhibitory plasticity rule effectively prevents the ‘red banana’ and ‘yellow strawberry’ stimuli from triggering spikes due to the excitatory inputs to this particular dendrite, thereby compartmentalizing dendrite 1 to be responsive to mainly ‘yellow banana’.</p>
<p>We also show the dynamics of peak calcium levels associated with both excitatory and inhibitory synapses for each task (<xref rid="fig5" ref-type="fig">Fig. 5E</xref>). For excitatory synapses, for which strengthening NMDA calcium influx is a key factor, the patterns in peak calcium levels behave as in the example in <xref rid="fig3" ref-type="fig">Fig. 3D</xref> (<xref rid="fig5" ref-type="fig">Fig. 5E</xref>, right panel). On the inhibitory side, the peak calcium levels, influenced by voltage-gated calcium channels as shown in the right panel of <xref rid="fig5" ref-type="fig">Fig. 5E</xref>, displayed different behavior, resulting from the inhibitory plasticity rule. The threshold levels of calcium for inhibitory synapses followed the highest excitatory synaptic activity, which in our task corresponded to the ‘yellow banana’ input. Conversely, the minimum threshold level was able to surpass all other synaptic activities, effectively designating it for ‘yellow banana’ only.</p>
<p>We also compared the performance for different feature configurations with added inhibitory synapses to the results for the excitatory-only setup from <xref rid="fig4" ref-type="fig">Fig. 4B</xref>. The results show not only that learning with inhibitory plasticity is faster, i.e. requires less training examples, but also achieves high performance, nearing 100%. This demonstrates the potential impact of inhibitory synapses in enhancing learning capabilities, as well as in performing the NFBP computation (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>).</p>
<p>Inhibitory plasticity additionally produced a marked improvement in performance when the location of the synaptic clusters was varied, especially prominent at very distal locations (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>). Incorporating inhibitory plasticity allows for more rapid, robust, and accurate learning. Unlike excitatory plasticity, which relies on dopaminergic feedback signals, our inhibitory plasticity model follows a passive rule that just aligns with the local excitatory activity. It reinforces the most active excitatory synapses within a dendritic branch by decreasing the inhibitory synapses corresponding to the same features there, and conversely, it strengthens inhibitory synapses for features for which excitatory activity is less prominent. This ‘winner-takes-all’ strategy not only accelerated the learning process by requiring fewer training examples but also enhanced performance consistency across different dendritic locations, including the distal regions where excitatory-only models faltered to some extent when challenged with the NFBP. The inhibitory rule’s ability to function without dopaminergic feedback streamlines the learning process, leading to higher accuracy and a more stable and robust set of synaptic modifications, regardless of the synaptic cluster’s position along the dendrite. This demonstrates the influence inhibitory synapses could potentially exert in fine-tuning dendritic responsiveness and refining the neuronal circuitry critical for learning.</p>
</sec>
<sec id="s2f">
<title>Dendritic Branch Plasticity and Synaptic Learning – Investigating the Role of Randomly Distributing Excitatory and Inhibitory Synapses on the Dendrites</title>
<p>We finally challenged our plasticity rule by relaxing the assumption that single features are represented by pre-clustered synapses on specific dendritic branches. The synaptic plasticity rule was therefore investigated by randomly distributing 200 excitatory synapses signaling the different features across 30 dendrites. Each feature was represented by 40 excitatory synapses and an additional 40 feature-unspecific excitatory synapses were used. <xref rid="fig6" ref-type="fig">Figure 6A</xref> illustrates the setup and exemplifies the pre- and post-learning synaptic weights for both excitatory and inhibitory synapses. Our objective was to examine the learning dynamics in the absence of assumed synaptic clustering and to determine the capability of the single neuron to learn the NFBP. We initiated the experiment with synaptic conductance set to 0.3 ± 0.1 (around 0.75 nS), focusing first on purely excitatory synapses. This higher initial weight and increased variance, compared to the initial weights of 0.25 ± 0.05 (around 0.75 nS) with clustered synapses, were chosen to compensate for the reduced efficacy of non-clustered synaptic inputs in producing sufficient depolarization and calcium influx, essential for effective learning and synaptic plasticity.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Performance analysis of learning using distributed synaptic inputs</title>
<p>A: Example illustration of synaptic distribution before (top) and after learning (bottom) of the 200 excitatory and 60 inhibitory inputs.</p><p>B: Learning performance with two spillover models, branch-specific thresholded and accumulative, without (left) and with plasticity of inhibitory synapses (right).</p><p>C: Performance trends of 31 distributions with branch-specific thresholded spillover and inhibitory plasticity.</p><p>D: Example of summed synaptic conductances (left) and voltage (right) in the soma, and four example dendrites (d1-d4) of one model following successful learning of the NFBP. The sums of both excitatory (Ex) and inhibitory (Inh) inputs are shown.</p></caption>
<graphic xlink:href="584462v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig6" ref-type="fig">Figure 6B</xref> (right panel) shows limited learning capacity on the NFBP, which corresponded with our hypothesis: that without clustering-induced supralinearities due to spillover in the dendrites, distributed synapses would be too weak to trigger high enough differences in local calcium levels for separating the correct and incorrect feature combinations. To confirm that the lack of dendritic nonlinearities is the cause for not learning the NFBP, we extended this concept by introducing a hypothetical branch-specific spillover mechanism assuming that spillover occurs if synapses are on the same dendritic branch. This hypothetical construct assumes that concurrent activation of a critical mass of co-activated synapses in a single dendritic branch would trigger both plateau potentials and a significant rise in calcium levels despite that the synapses are not spatially pre-clustered, endowing the dendrites with supralinear responses even without closely clustered synapses. We also tested a more gradual spillover model proposing that each synapse could contribute incrementally to a cumulative spillover effect, instead of using a sharp glutamate threshold (see <xref ref-type="bibr" rid="c69">Trpevski et al, 2023</xref>). This modification provided a reduced level of nonlinearity compared to the branch-specific spillover model but still led to an increase in learning effectiveness. As shown in <xref rid="fig6" ref-type="fig">Fig. 6B</xref>, adding the hypothetical nonlinearities to the model increases the performance towards solving part of the NFBP, i.e. learning to respond to one relevant feature combination only. The performance increases with the amount of nonlinearity.</p>
<p>We next extended our investigation by including 60 inhibitory synapses, 15 for each feature, dispersed randomly over the 30 dendrites. Performance improved with the introduction of these additional nonlinearities, especially in combination with the branch-specific spillover mechanisms. This finding emphasizes the importance of dendritic branch plasticity and calcium nonlinearity in coordinating synaptic modifications for both excitatory and inhibitory inputs. In <xref rid="fig6" ref-type="fig">Fig. 6C</xref>, we report that a subset of neurons (5 out of 31) successfully solved the NFBP (reaching a performance of at least 87.5%).</p>
<p>For a more granular analysis of the successful cases, we selected an example that learned the NFBP. In <xref rid="fig6" ref-type="fig">Fig. 6D</xref>, we show the somatic and dendritic voltages for four dendritic branches where we found successful encodings of the relevant stimuli. The voltage traces show the somatic and dendritic responses to all four stimuli after learning. For each dendrite we also estimated the cumulative synaptic conductances for both excitatory and inhibitory synapses at the dendritic branch midpoint. Notably, in dendrites numbered 1 and 4, we observed an enhancement of excitatory inputs for the ‘yellow banana’ pattern and inhibitory inputs for the ‘red strawberry’ pattern. Conversely, dendrites 2 and 3 displayed the opposite arrangement.</p>
<p>These results show that for an adequate random innervation of distributed synapses, where the necessary features for a relevant stimulus innervate the same dendritic branch with enough synapses, that stimulus can be stored on that dendrite. In this way, the NFBP can also be learned if the two relevant stimuli are encoded on different dendrites and each of them can trigger a supralinear dendritic response. Since on average the two features representing a relevant stimulus do not innervate a single dendrite with enough synapses, the stimulus is not stored in a single dendrite, but is distributed across the dendritic tree. And since distributed synapses summate more linearly at the soma, only one of the relevant stimuli can be typically encoded by the dendritic tree.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this article we studied whether single neurons can solve linearly non-separable computational tasks, represented by the NFBP, by using a biophysically detailed multicompartment dSPN model. Based on the synaptic machinery of corticostriatal synapses onto dSPNs, we propose a learning rule that uses local synaptic calcium concentration and dopamine feedback signals: rewards for relevant stimuli and omitted rewards for irrelevant stimuli. Assuming first that single features in the NFBP are represented by clustered synapses, we show that the learning rule can solve the NFBP by strengthening (or stabilizing) synaptic clusters for relevant stimuli and weakening clusters for the irrelevant stimuli. The feature combinations for the relevant stimuli, stored in strengthened synaptic clusters, trigger supralinear dendritic responses in the form of plateau potentials, which is an important ingredient for the solution of the NFBP, as plateaus significantly increase the likelihood of neuronal spiking in SPNs in a robust way (<xref ref-type="bibr" rid="c15">Du <italic>et al</italic>., 2017</xref>).</p>
<p>The location of the synaptic clusters along the dendrites influenced the performance on the NFBP. In our model the region for optimal performance was 100-150 <italic>μ</italic>m away from the soma, at about the same distance as where the somatic depolarization and induced spike probability, following activation of clustered input, is largest in an older version of the model (<xref ref-type="bibr" rid="c37">Lindroos and Hellgren Kotaleski, 2021</xref>). Clusters placed further away produce smaller somatic depolarizations, due to dendritic filtering (<xref ref-type="bibr" rid="c39">Major <italic>et al</italic>., 2008</xref>), and as a consequence does not control the likelihood of somatic spiking as decisively. As the supralinear response is necessary for discriminating the relevant from the irrelevant stimuli, the performance with distally placed clusters decreases somewhat.</p>
<p>We further verified that supralinear dendritic responses were necessary to solve the NFBP by using randomly distributed synapses instead of clustered for each feature. In this scenario, only one relevant stimulus is sometimes learned in a dendritic branch by the randomly distributed synapses. The random setup was tested with two glutamate spillover models: The first model assumed that thresholded glutamate spillover is branch-specific, building on the notion that the single branch act as a single computational unit (<xref ref-type="bibr" rid="c38">Losonczy and Magee, 2006</xref>; <xref ref-type="bibr" rid="c5">Branco and Häusser, 2010</xref>). The second assumed that spillover is accumulative (<xref ref-type="bibr" rid="c69">Trpevski <italic>et al</italic>., 2023</xref>). Both spillover versions increase the performance of our neuron model, further certifying the necessity of supralinear responses for solving the NFBP. In the real dendritic branches, however, also diffusion of signaling molecules within the branch likely contributes significantly both to the plasticity in already existing synapses as well as to local structural plasticity, both of which could increase branch specific supralinearities.</p>
<p>By using a phenomenological inhibitory plasticity rule based on the BCM formalism (<xref ref-type="bibr" rid="c3">Bienenstock, Cooper and Munro, 1982</xref>), we also show that inhibitory synapses can significantly improve performance on the NFBP. This is in line with earlier theoretical studies where negative synaptic weights were required to solve the NFBP (<xref ref-type="bibr" rid="c56">Schiess, Urbanczik and Senn, 2016</xref>). In our setup with pre-existing synaptic clusters, inhibitory synapses made learning faster and increased performance by inhibiting supralinear NMDA responses for the irrelevant stimuli. This was specifically true in distal dendrites where the input impedance is higher (<xref ref-type="bibr" rid="c4">Branco, Clark and Häusser, 2010</xref>). The threshold for plateau initiation is also lower in distal dendrites compared to proximal (<xref ref-type="bibr" rid="c38">Losonczy and Magee, 2006</xref>) which likely will further extend the influence of inhibition in this region (<xref ref-type="bibr" rid="c14">Doron <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c15">Du <italic>et al</italic>., 2017</xref>). Similarly, in the scenario with distributed synapses, inhibition enables one of the relevant stimuli to be reliably encoded in the dendritic branch by strengthening the inhibitory synapses for features different from those of the encoded stimulus. Together, it therefore seems like inhibition not only has a role in learning (<xref ref-type="bibr" rid="c8">Chen <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c10">Cichon and Gan, 2015</xref>), but also improves the ability of the neuron to discriminate between stimuli with shared features.</p>
<p>Although our learning rule only occasionally solves the NFBP when used with randomly distributed synapses, it can always learn to perform a linearly separable task, such as learning to respond to only one relevant stimulus (such as red strawberry). Moreover, the learning rule is general enough so that in addition to the feature-specific inputs related to the task, it can handle feature-unspecific inputs that might or might not be related to the NFBP. Finally, the learning rule is always “on”, continuously updating synapses with each stimulus presentation, which is a more realistic mechanism compared to using separate training and testing phases as in the field of machine learning. The synaptic weights automatically stabilize in the model when the performance improves. That is, rewards are then seen very regularly as the neuron has learned to spike for the relevant stimuli, while omitted rewards seldomly occur as the neuron stays silent when the irrelevant stimuli are provided.</p>
<p>When formulating the learning rule in this article, our goal was to base it on what is known regarding the synaptic machinery in corticostriatal synapses. This implied that the learning rule is based on the local calcium activity and on dopamine signals. Feedback from the dopamine system can also be viewed as an innate, evolutionarily encoded “supervisor”, which instructs neurons which feature combinations are beneficial and which ones should be avoided. However, in our case we do not use additional excitation to promote somatic spiking for only the relevant feature combinations, and in that sense the learning rule does not require a supervised learning paradigm. Since the SPNs rest at very hyperpolarized membrane potential, our setup includes distributed excitatory inputs which are feature-unspecific in order to make sure that the neuron spikes for all stimuli, especially at the beginning of training. These additional inputs are on average weakened as learning progresses (as they are activated for all stimuli and thus often receive negative feedback). That general or noisy inputs are reduced during learning is in line with the observed reduction of execution-variability during motor-learning as a novice becomes an expert (<xref ref-type="bibr" rid="c30">Kawai <italic>et al</italic>., 2015</xref>). Also, the underlying neuronal representation of corticostriatal synapses undergo a similar change during learning (<xref ref-type="bibr" rid="c55">Santos <italic>et al</italic>., 2015</xref>).</p>
<p>Since each synapse has its own calcium response, it is important for the learning rule to be able to follow individual synaptic activities. The LTP plasticity kernel in our model is for this reason itself plastic, meaning that it changes its calcium dependence as a function of the history of reward and punishment. This setup helps the model separate clustered synaptic input from the feature-unspecific input at the beginning of training, as only clustered synapses will see enough calcium to fall within the plastic range. We further use an asymmetric metaplasticity rule, where negative feedback causes a larger shift of the LTP kernel than a positive. This was necessary in order to stop LTP in synapses participating in LTD. Similarly to the classical loss-aversion tendency described in economic decision theory (<xref ref-type="bibr" rid="c29">Kahneman and Tversky, 1979</xref>), the model hence predicts that negative feedback will have a bigger impact in changing a well learned behavior on the single cell level than a positive feedback. Dopamine signaling has also been linked as a neural substrate to the decision making theory mentioned above (<xref ref-type="bibr" rid="c65">Stauffer <italic>et al</italic>., 2016</xref>).</p>
<p>It is not known whether single neurons solve the NFBP or other linearly non-separable tasks. However, many brain nuclei receive convergent inputs from numerous other brain nuclei, acting as integratory hubs (<xref ref-type="bibr" rid="c22">van den Heuvel and Sporns, 2013</xref>). Since feature binding evidently occurs in the brain, and functional clusters for single features such as visual stimulus orientation, receptive fields, color, or sound intensity exist on single neurons (<xref ref-type="bibr" rid="c9">Chen <italic>et al</italic>., 2011</xref>; <xref ref-type="bibr" rid="c72">Wilson <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c25">Iacaruso, Gasler and Hofer, 2017</xref>; <xref ref-type="bibr" rid="c58">Scholl, Wilson and Fitzpatrick, 2017</xref>; <xref ref-type="bibr" rid="c28">Ju <italic>et al</italic>., 2020</xref>), it is possible that the NFBP is a relevant task for neurons to solve. How brain regions with different synaptic machinery than the striatal dSPN might solve the NFBP remains a question, and reliance on other neuromodulatory signals may be part of the answer. For example, in the striatum, the indirect pathway SPNs (iSPN) have analogous synaptic machinery to the one in dSPNs, requiring calcium influx from the same sources for LTP and LTD, but are differently responsive to dopamine (<xref ref-type="bibr" rid="c61">Shen <italic>et al</italic>., 2008</xref>). In iSPNs a dopaminergic pause, together with a peak in adenosine, is required to trigger LTP, whereas a dopamine peak without peaks in adenosine rather promotes LTD (<xref ref-type="bibr" rid="c61">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c43">Nair <italic>et al</italic>., 2015</xref>). Therefore, we expect that an analogously formulated learning rule will also solve the NFBP in iSPNs, activating them for irrelevant feature combinations to e.g. suppress movement, and suppressing their activity for relevant feature combinations to facilitate movement. In addition, LTP in dSPNs might require co-activation of other neuromodulatory systems, such as a coincident acetylcholine pause with the dopamine peak, which we have not explicitly included in the model (<xref ref-type="bibr" rid="c43">Nair <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c6">Bruce <italic>et al</italic>., 2019</xref>; <xref ref-type="bibr" rid="c52">Reynolds <italic>et al</italic>., 2022</xref>).</p>
</sec>
<sec id="s4">
<title>Method</title>
<p>In this paper we introduce a local, calcium- and reward-based synaptic learning rule, constrained by experimental findings, to investigate learning in SPNs. The learning rule operates based on the local calcium concentration in conjunction with plateau potentials and other dendritic nonlinearities and shows that such events enable learning of the nonlinear feature binding problem (NFBP). The learning rule is embedded in a biophysically detailed model of a dSPN built and simulated in the NEURON software, v8.2 (Carnevale et al., 2006). Here we will focus on the setup of the learning rule and only give a short summary of the neuron and synapse models, focusing on changes compared to previously published versions. For a detailed description of the neuron model setup, see <xref ref-type="bibr" rid="c36">Lindroos et al., (2018)</xref>, <xref ref-type="bibr" rid="c37">Lindroos &amp; Hellgren Kotaleski, (2021)</xref>, and Trpevski et al., (2023).</p>
<sec id="s4a">
<title>Neuron model</title>
<p>In short, the dSPN model used here was sourced from a collection of biophysically detailed models, including a reconstructed morphology and all of the most influential ion channels, including six calcium channels, each with its own voltage dependence and dendritic distribution (<xref ref-type="bibr" rid="c37">Lindroos and Hellgren Kotaleski, 2021</xref>). In accordance with <xref ref-type="bibr" rid="c69">Trpevski et al., (2023)</xref>, the model was further extended with synaptic spines on selected dendrites. Each spine was modeled as two additional compartments consisting of a neck and a head region, and contains voltage-gated calcium channels of types R (Ca<sub>v</sub>2.3), T (Ca<sub>v</sub>3.2 and Ca<sub>v</sub>3.3), and L (Ca<sub>v</sub>1.2 and Ca<sub>v</sub>1.3); the addition of explicit spines did not change the basic behavior of the model, such as the response to current injections, etc.</p>
</sec>
<sec id="s4b">
<title>Calcium sources used in learning</title>
<p>The intracellular calcium concentration is separated into distinct pools that are used during the learning process. For learning in glutamatergic synapses, one pool for NMDA-evoked calcium concentration ([Ca]<sub>NMDA</sub>) is used, and another for L-type calcium concentration ([Ca]<sub>L-type</sub>), to reflect the different synaptic plasticity responses of the SPN’s biochemical machinery to these two calcium sources in the corticostriatal synapse (<xref ref-type="bibr" rid="c61">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c16">Fino <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c46">Plotkin <italic>et al</italic>., 2013</xref>). Both pools are based on the calcium influx from the corresponding source (NMDA and the L-type channels Ca<sub>v</sub>1.2 and Ca<sub>v</sub>1.3, respectively). Similarly a third pool, used for inhibitory plasticity, collects the current from all voltage dependent Ca channels (T-, R-, L- and N-type, [Ca]<sub>V</sub>). All pools include extrusion mechanisms in the form of a calcium pump as well as a one-dimensional time-decay. The calcium pump follows the implementation in <xref ref-type="bibr" rid="c74">Wolf et al., (2005)</xref>. The parameters for the [Ca]<sub>NMDA</sub> model were manually tuned to match the quantities reported in <xref ref-type="bibr" rid="c13">Dorman et al., (2018)</xref>. The voltage gated calcium channel conductances in the spines were also manually tuned to match the relative calcium proportions in <xref ref-type="bibr" rid="c7">Carter and Sabatini, (2004)</xref> and <xref ref-type="bibr" rid="c23">Higley and Sabatini, (2010)</xref>, as well as the calcium amplitudes due to stimulation with backpropagating action potentials (<xref ref-type="bibr" rid="c63">Shindou, Ochi-Shindou and Wickens, 2011</xref>). Spatial diffusion was not included in the present model.</p>
</sec>
<sec id="s4c">
<title>Glutamatergic synaptic input</title>
<p>In our study, we used a synaptic model that includes both AMPA and NMDA conductances activated on spines. Additionally, we considered extrasynaptic NMDA conductances on dendritic shafts directly under the spines to account for glutamate spillover if the synapses were sufficiently stimulated and spatially clustered. Spillover has been shown to be important for generating robust all-or-none dendritic plateaus (<xref ref-type="bibr" rid="c69">Trpevski <italic>et al</italic>., 2023</xref>). The conductance of extrasynaptic NMDARs during spillover matches their synaptic counterparts. Glutamate spillover in a set of clustered synapses occurs in the model if a glutamate threshold is met, and in that case a presynaptic spike also activates the corresponding extrasynaptic NMDA conductance (<xref ref-type="bibr" rid="c69">Trpevski <italic>et al</italic>., 2023</xref>). The threshold mechanism involves summing the synaptic weights for each NMDA synapse activated in the cluster, and checking whether their sum is greater than a threshold level. The synaptic weight is represented by a weight parameter (w) which scales the maximal conductance of the synapse (the change of the weights are described by <xref rid="eqn1" ref-type="disp-formula">Eq. 1</xref>-<xref rid="eqn3" ref-type="disp-formula">3</xref>). We exemplify this with the equation for calculating the NMDA current I<sub>NMDA</sub>:
<disp-formula>
<graphic xlink:href="584462v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where V(t) is the membrane voltage, ENMDA is the reversal potential of the NMDA synapse, gsyn is the NMDA conductance which has a time varying part, ranging from 0 to 1, scaled by a fixed part comprised of the maximal NMDA conductance and the synaptic weight. In our simulations a cluster needs to reach a summed weight of 2 to reach the glutamate threshold for spillover, at which point the extrasynaptic NMDARs are activated. This is modeled in NEURON by summing the NMDA synaptic weights upon each spike arrival, with the sum normalized so that e.g. ten synapses of 0.2 weight reach the threshold. An integrate-and-fire cell in NEURON generates a spike to extrasynaptic NMDARs when this threshold is met. This model allows for fewer synapses to reach the threshold as synaptic weight increases, a phenomenon linked to LTP and enhanced glutamate spillover due to astroglial process withdrawal (<xref ref-type="bibr" rid="c21">Henneberger <italic>et al</italic>., 2020</xref>).</p>
<p>Extrasynaptic NMDA synapses were not included for feature-unspecific (non-clustered) synapses although we explored the role of a potential branch-specific spillover mechanism, where non-clustered synapses localized on the same branch still could interact through spillover mechanisms, either assuming thresholded or accumulative spillover as detailed in <xref ref-type="bibr" rid="c69">Trpevski <italic>et al</italic>., (2023)</xref>. The AMPA and NMDA synapse models were taken from <xref ref-type="bibr" rid="c19">Gao <italic>et al</italic>., (2021)</xref> and are a variation of the saturating synapse models in <xref ref-type="bibr" rid="c12">Destexhe <italic>et al.</italic>, (1994)</xref>. See <xref ref-type="bibr" rid="c69">Trpevski <italic>et al</italic>., (2023)</xref> for a detailed description of how the synaptic input was set for the SPN model.</p>
</sec>
<sec id="s4d">
<title>Learning rule</title>
<sec id="s4d1">
<title>Excitatory synaptic plasticity</title>
<p>The learning rule is based on experimental findings showing that striatal LTP depends on NMDA-channel activation and the presence of dopamine, while LTD is dependent on activation of the L-type Ca channel Ca<sub>v</sub>1.3 and the mGluR5 receptor in the absence of dopamine (low dopaminergic tone) (<xref ref-type="bibr" rid="c61">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c16">Fino <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c46">Plotkin <italic>et al</italic>., 2013</xref>; <xref ref-type="bibr" rid="c76">Yagishita <italic>et al</italic>., 2014</xref>; <xref ref-type="bibr" rid="c17">Fisher <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c62">Shindou <italic>et al</italic>., 2019</xref>). Under basal dopamine levels, no significant synaptic plasticity is assumed to occur. The rule describes a reward-based learning scheme in which a dopamine peak increases the synaptic weight based on one function (plasticity kernel) while a dopamine pause decreases the weights based on another function. Hence, dopamine acts as a switch selecting which of the LTP or LTD pathways should be activated (as illustrated in <xref rid="fig1" ref-type="fig">Fig. 1D</xref>). The plasticity kernels for LTP and LTD depend on NMDA calcium and L-type calcium, respectively, and are described below.</p>
</sec>
<sec id="s4d2">
<title>LTP<italic/></title>
<p>The LTP process is triggered by increased dopamine levels and is based on calcium influx through the NMDA channel. Here the synaptic strength is updated based on a sliding bell-shaped kernel in such a way that the maximal increase is obtained for peak calcium levels close to the kernel midpoint, while higher or lower peak calcium levels result in a smaller increase. This sets an upper limit on the synaptic strength and guarantees that the weights will not grow beyond a certain limit (<xref ref-type="bibr" rid="c77">Zenke and Gerstner, 2017</xref>; <xref ref-type="bibr" rid="c78">Zenke, Gerstner and Ganguli, 2017</xref>). Since each synapse has its own calcium level, the sliding of the bell-shaped kernel enables the precise tuning of each synaptic weight separately (see <xref rid="fig7" ref-type="fig">Fig. 7A</xref> for an illustration).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Synaptic Plasticity Rules: Calcium and Dopamine Interactions in Synaptic Weight Modification</title>
<p>A: Synaptic weight updates during a dopamine peak. (Left) LTP kernel is a bell-shaped curve which determines an optimal [Ca]<sub>NMDA</sub> region in which synaptic weight is increased. (Right) A wider bell-shaped kernel, i.e. the metaplasticity kernel, determines how the LTP kernel (the optimal region for plasticity) slides along the calcium level ([Ca]<sub>NMDA</sub>) axis following a Da peak.</p><p>B: Synaptic weight updates during LTD. (Left) The LTD plasticity kernel. This kernel is constant. The LTD threshold is constant and set at 70 nM (Right). Metaplasticity describes how the LTP kernel slides along the calcium axis following a Da pause.</p><p>C: A schematic of how the LTP kernel window is updated following a dopamine peak. As NMDA calcium levels increase following activation of the strengthened synapse due to a dopamine peak (illustrated with the red circle jumping to the blue circle), the LTP kernel slides down and in this example the strengthened synapse (blue circle) stabilizes, and doesn’t increase in strength even though additional rewards arrive.</p><p>D: A schematic showing the update of the LTP window following a dopamine pause leading to that synaptic weight and calcium response decrease as a function of L-type Ca (illustrated with the red circle jumping to the blue one). Here, the LTP kernel slides up towards higher NMDA calcium levels, and thus the weakened synapse (blue circle) is more unlikely to be recruited into the LTP window (unless it in the future is activated with Da peaks more regularly than with Da dips).</p><p>E: Depicts the inhibitory plasticity rule. (Left) Changes in synaptic weight for active (orange) and inactive (blue) synapses based on voltage dependent calcium levels in the dendritic shaft at the location of the inhibitory synapse, and minimum (T<sub>min</sub>) and maximum (T<sub>max</sub>) threshold. (Right) Functions for sliding the minimum and maximum thresholds with voltage dependent calcium level. The asterisk denotes the semi-stable zero level where the curves for active and inactive synapses meet.</p></caption>
<graphic xlink:href="584462v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Mathematically, the bell-shaped kernel for the LTP process is represented by the derivative of the sigmoid function σ (<xref rid="eqn1" ref-type="disp-formula">Eqs. 1</xref> and <xref rid="eqn2" ref-type="disp-formula">2</xref>) with a slope that can be adjusted through the β parameter. The LTP learning rule (<xref rid="eqn3" ref-type="disp-formula">Eq. 3</xref>) describes the increase in synaptic weight (w) of the inputs, as a function of peak calcium level ([Ca]<sub>NMDA</sub>), the learning rate (η<sub>1</sub>), and the midpoint (θ<sub>ltp</sub>) and slope of the sigmoid curve (β<sub>1</sub>).
<disp-formula id="eqn1">
<graphic xlink:href="584462v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<disp-formula id="eqn2">
<graphic xlink:href="584462v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn3">
<graphic xlink:href="584462v1_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</sec>
<sec id="s4d3">
<title>LTD<italic/></title>
<p>The LTD process is triggered by a dopamine pause and is dependent on L-type calcium. The LTD plasticity rule (<xref rid="eqn4" ref-type="disp-formula">Eq. 4</xref>), describes a threshold level of the calcium level necessary for LTD to occur (<xref ref-type="bibr" rid="c63">Shindou, Ochi-Shindou and Wickens, 2011</xref>), after which the decrease in synaptic weight is linearly proportional to the amplitude of the peak calcium level, and is scaled by the learning rate (η<sub>2</sub>, see left panel of <xref rid="fig7" ref-type="fig">Fig. 7B</xref> for an illustration). The peak calcium threshold is implemented with a sigmoid function, whose slope parameter, β<sub>2</sub>, was set to a high-value to make the curve resemble a step function. The midpoint, θ<sub>ltp</sub>, of the LTP kernel was also increased during LTD, as described in the next section (<xref rid="fig7" ref-type="fig">Fig. 7B</xref> right panel).
<disp-formula id="eqn4">
<graphic xlink:href="584462v1_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4d4">
<title>Metaplasticity</title>
<p>Metaplasticity is a form of regulatory mechanism changing the state of the synapses in such a way as to influence subsequent learning. In our model we implemented this as a reward-history-dependent change of the location of the calcium range over which the LTP kernel was operating - a pause in dopamine triggered a shift towards higher calcium concentrations while a peak in dopamine pushed the LTP kernel in the opposite direction. The metaplasticity was also implemented using a kernel with the same midpoint as the LTP kernel, but with a wider calcium dependence. Together the setup with the two dynamically moving kernels allowed for a wide range of calcium levels to induce plasticity. This setup typically gave rise to a few characteristic situations:
<list list-type="order">
<list-item><p>For peaks in dopamine (see <xref rid="fig7" ref-type="fig">Fig. 7C</xref> for an illustration),
<list list-type="alpha-lower">
<list-item><p>In synapses with low calcium levels, the kernel will be shifted closer to the observed level and thereby eventually enable LTP in synapses that are regularly activated during rewards, despite that they initially don’t generate big changes in calcium.</p></list-item>
<list-item><p>In synapses with already high calcium levels, the kernel will be shifted away from the observed level, and thereby protect the neuron from excessive LTP and instead stabilize the weight (as illustrated with the red circle moving to the blue one in <xref rid="fig7" ref-type="fig">Fig. 7C</xref>).</p></list-item>
</list>
</p></list-item>
<list-item><p>For dopaminergic pauses, the kernel will be shifted away from the observed level and thereby reducing the likelihood of LTP in synapses that are undergoing LTD (see <xref rid="fig7" ref-type="fig">Fig. 7D</xref> for an illustration).</p></list-item>
</list>
The LTP kernel update was further asymmetric with regards to dopamine peaks and pauses in such a way that a pause caused a larger shift of the kernel than a peak. This further reduced the likelihood of inducing LTP in synapses often participating in LTD or in synapses randomly activated with regard to the dopamine feedback signal. The metaplasticity kernel thus adjusts the LTP kernel for these processes based on ongoing neural activity. These changes are described by <xref rid="eqn5" ref-type="disp-formula">Eq. 5</xref>, where the LTP kernel midpoint is updated based on the learning rate (η<sub>s</sub>), the peak NMDA calcium level ([Ca]<sub>NMDA</sub>), and the slope of the sigmoid curve (β<sub>3</sub>). The learning rate, η<sub>s</sub>, captures the described asymmetry in response to dopamine feedback (see <xref rid="tbl1" ref-type="table">Table 1</xref>). This setup can give rise to the following situations:
<list list-type="order">
<list-item><p>For randomly alternating dopamine peaks and pauses,
<list list-type="alpha-lower">
<list-item><p>In a few synapses that initially happen to generate very high calcium levels the synapses can become even stronger as their postsynaptic calcium response is still within the shifted LTP kernel. This explains e.g. the increase in strengths of the synapses illustrated with the blue and green traces in the right panel of <xref rid="fig3" ref-type="fig">Fig. 3C</xref>. (However, as the computational performance of the neuron successively improves these synapses stabilize when the neuron starts to receive less dopamine pauses).</p></list-item>
<list-item><p>In synapses that generate somewhat less postsynaptic calcium responses the general trend is that they decrease as their calcium level becomes lower than the LTP kernel. This is illustrated in <xref rid="fig7" ref-type="fig">Fig. 7D</xref> with the red circle shifting to the blue one; also e.g. compare the purple trace in the right panel of <xref rid="fig3" ref-type="fig">Fig. 3C</xref>.</p></list-item>
</list>
</p></list-item>
</list>
</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Excitatory Plasticity Parameters</title></caption>
<graphic xlink:href="584462v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="584462v1_tbl1a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Inhibitory Plasticity Parameters</title></caption>
<graphic xlink:href="584462v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="584462v1_tbl2a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>In summary, the slower shifting metaplasticity kernel, compared to the weight update, allows the individual synapses to stabilize when the neuron has learned a specific task and thus doesn’t receive negative reward feedback that often. Also, the rule allows initially weaker synapses to be recruited to undergo LTP if they are more consistently co-active with a reward than with an omitted reward (an illustration of this can be seen in <xref rid="fig5" ref-type="fig">Fig. 5D</xref>, where one of the yellow synapse traces jumps upwards during the middle of the training session).
<disp-formula id="eqn5">
<graphic xlink:href="584462v1_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4d5">
<title>Inhibitory synaptic plasticity</title>
<p>In contrast to the well studied mechanistic underpinnings of glutamatergic plasticity in e.g. SPNs, much less is known about how inhibitory synapses might be updated during learning. The inhibitory plasticity rule developed here is therefore more phenomenological and exploratory in nature and was developed to enhance nonlinearities in the local dendrite. The rule is based on the Bienenstock-Cooper-Munro (BCM) formalism (<xref ref-type="bibr" rid="c3">Bienenstock, Cooper and Munro, 1982</xref>). In the BCM rule there is a threshold level of synaptic activity below which LTD is triggered and above which LTP is triggered (<xref rid="fig7" ref-type="fig">Fig. 7E</xref>). Inspired by (<xref ref-type="bibr" rid="c18">Gandolfi <italic>et al</italic>., 2020</xref>; <xref ref-type="bibr" rid="c50">Ravasenga <italic>et al</italic>., 2022</xref>) and, we use calcium from all voltage-gated calcium channels ([Ca]<sub>V</sub>) as the indicator of excitatory synaptic activity near the dendritic shaft where an inhibitory synapse is located. The inhibitory rule is designed to passively observe and respond to the surrounding excitatory synaptic activity, governed by local calcium influx, but without reliance on dopamine or explicit feedback. It operates at a slower pace to ensure alignment with the excitatory activity levels, thus enhancing the contrast in activity by amplifying local differences in excitatory synaptic efficacy. The weight change is further dynamic and dependent on the weight itself, in such a way that large and small weights get small updates. This stabilizes the weight at the end of learning in the inhibitory synapses, together with the dynamical threshold level meeting the local calcium level, and prevents the weight from taking on large or negative values. Large weights are then close to <inline-formula><inline-graphic xlink:href="584462v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and small weights close to 0 (see <xref rid="fig5" ref-type="fig">Fig. 5D</xref>).</p>
<p>The rule is described by <xref rid="eqn6" ref-type="disp-formula">Eq. 6</xref>-<xref rid="eqn9" ref-type="disp-formula">9</xref> where <xref rid="eqn6" ref-type="disp-formula">Eq. 6</xref> describes the basic plasticity curve used in <xref rid="eqn7" ref-type="disp-formula">Eq. 7</xref> to control the change in inhibitory weights (dw<sub>inh</sub>). In these equations, the parameters a and b set the activity values for the two terms in <xref rid="eqn6" ref-type="disp-formula">Eq. 6</xref> while β and T control the steepness and intersection with the x-axis.</p>
<p>The parameter c recalibrates the baseline for T<sub>min</sub>, ensuring T<sub>min</sub> and T<sub>max</sub> intersect at zero, as depicted in <xref rid="fig7" ref-type="fig">Fig. 7E</xref> (right panel, indicated by an green asterisk *).</p>
<p>The upper threshold T<sub>max</sub> gradually shifts toward the highest calcium level observed in each synapse while the lower threshold T<sub>min</sub> shifts towards a level below the maximum calcium level (<xref rid="eqn8" ref-type="disp-formula">Eqs. 8</xref> and <xref rid="eqn9" ref-type="disp-formula">9</xref>; see <xref rid="fig7" ref-type="fig">Fig. 7E</xref> right panel for an illustration). Once the thresholds stabilize, the synapse will also reach stability. The goal of this is to enhance the difference in depolarization/calcium between the most active level, and the next one.</p>
<p>Further, depending on whether the synapse was active or inactive during the period of the calcium influx, the learning rate of <xref rid="eqn7" ref-type="disp-formula">Eq. 7</xref> (η<sub>act</sub>) takes on negative or positive values. Because of this, the active synapses are depressed when the calcium concentration is higher than the upper threshold T<sub>max</sub> and potentiated if the concentration is between the two thresholds, while inactive synapses follow the inverse relationship. No change happens below the lower threshold (see <xref rid="fig7" ref-type="fig">Fig. 7E</xref> left panel for an illustration). This framework emphasizes the inhibitory synapse capacity to follow and dynamically amplify the contrast between local excitatory synaptic activity levels.
<disp-formula id="eqn6">
<graphic xlink:href="584462v1_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<disp-formula id="eqn7">
<graphic xlink:href="584462v1_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn8">
<graphic xlink:href="584462v1_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn9">
<graphic xlink:href="584462v1_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</sec>
</sec>
<sec id="s4e">
<title>Training Procedure</title>
<p>We present the neuron with a sequence of 960 stimuli, which, as described in <xref rid="fig1" ref-type="fig">Fig. 1</xref>, can come in four varieties (four possible feature combinations). The learning rule is always “on”, i.e. synapses can always be updated, meaning that there are no separate training and testing phases in which synapses are plastic and frozen, respectively. We used two distinct synaptic arrangements for when representing the features: the clustered setup and the distributed setup.</p>
<sec id="s4e1">
<title>Clustered setup</title>
<p>This setup is based on the assumption of pre-existing clustered synapses for each feature. The features of a stimulus are represented here by the shape and color of bananas and strawberries (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Features were allocated to two dendritic branches. Each branch had each feature represented with five synapses clustered closely on a single dendrite. Depending on the feature combination, two, three, or four features were represented in clusters on one or both dendritic branches (see <xref rid="fig3" ref-type="fig">Fig. 3A</xref>, <xref rid="fig4" ref-type="fig">4A</xref> and <xref rid="fig4" ref-type="fig">4D</xref> for example). Additionally, 108 feature-unspecific synapses were distributed throughout the dendrites, activated concurrently with all stimuli to enhance the probability of spiking (as plateau potentials together with the general background synaptic noise used do not often lead to spikes in SPNs, cf <xref rid="fig2" ref-type="fig">Fig 2A</xref>). To demonstrate the inhibitory plasticity rule, four inhibitory synapses near each cluster (in the middle of the dendritic branch), representing each of the four features, were added (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). With this setup a single feature activates both excitatory and inhibitory synapses. To match the level of depolarization seen in our excitatory-only setup, the number of distributed feature-unspecific synaptic inputs was increased to 144. The initial conductance of inhibitory synapses is set at 0.1 ± 0.01 nS.</p>
</sec>
<sec id="s4e2">
<title>Distributed setup</title>
<p>In contrast, this setup examines learning dynamics in neurons without pre-existing synaptic clustering for individual features. A total of 200 excitatory synapses were randomly distributed over 30 dendrites. Each feature was represented by 40 excitatory synapses, and an additional 40 feature unspecific excitatory synapses were used (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>). We initiated this experiment with excitatory synaptic weights at 0.3 ± 0.1 (around 0.75 nS). This higher initial weight was chosen to compensate for the reduced efficacy of non-clustered synaptic inputs in producing sufficient depolarization and calcium influx. Extending our investigation, we added 60 inhibitory synapses, 15 for each feature, dispersed randomly over the 30 dendrites. We initiated this extended experiment with excitatory synaptic weights at 0.45 ± 0.1 (around 1.125 nS), aiming to maintain the same baseline voltage activity as in the excitatory-only case. <xref rid="fig6" ref-type="fig">Figure 6A</xref> illustrates this setup, highlighting the pre- and post-learning synaptic weights for both excitatory and inhibitory synapses. The four stimuli were presented in random order three times each within a block of 12 stimuli, followed by another reshuffled block of 12, and so on, for 960 trials. Each trial consisted of a stimulus presentation, lasting 20 ms, followed by a reward cue arriving 300 ms after stimulus onset, and lasting for 50 ms (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). During the stimulus presentation, the stimuli-related synapses receive one randomly-timed spike per synapse. We opted not to quantitatively model the dopamine receptor response to dopamine concentrations. Instead, dopamine levels from the reward-based learning system are represented with +1 (dopamine peak) for relevant stimuli if the neuron spikes, and −1 (dopamine pause) for irrelevant stimuli if the neuron spikes, and 0 for baseline levels when the neuron was silent, at which time the calcium amplitudes were measured, and the synaptic weights were updated during the presence of the reward cue.</p>
<p>The time between two stimuli is 800 ms, long enough to allow for the voltage, calcium (and all other state variables in the model) to return to their baseline values.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgement</title>
<p>We would like to thank members of the Hellgren Kotaleski laboratory for helpful discussion of various aspects of the manuscript. DT would like to thank Ana Kalajdjieva for illustrating the mouse brain. We acknowledge the use of Fenix Infrastructure resources, which are partially funded from the European Union’s Horizon 2020 research and innovation programme through the ICEI project under the grant agreement No. 800858.</p>
<p>Simulations were also performed on resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS) at PDC KTH partially funded by the Swedish Research Council through grant agreement no. 2022-06725.</p>
<p>The study was supported by the Swedish Research Council (VR-M-2020-01652), Swedish e-Science Research Centre (SeRC), Science for Life Lab, EU/Horizon 2020 no. 945539 (HBP SGA3) and No. 101147319 (EBRAINS 2.0 Project), European Union’s Research and Innovation Program Horizon Europe under grant agreement No 101137289 (the Virtual Brain Twin Project), and KTH Digital Futures.</p>
</ack>
<sec id="s5">
<title>Author contributions</title>
<p>ZK and DT implemented the model, ran the simulations and analyzed the data with support from RL.</p>
<p>JHK and RL supervised all aspects of the study.</p>
<p>All authors contributed to the writing of the manuscript.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Antic</surname>, <given-names>S.D.</given-names></string-name> <etal>et al.</etal> (<year>2010</year>) ‘<article-title>The decade of the dendritic NMDA spike</article-title>’, <source>Journal of neuroscience research</source>, <volume>88</volume>(<issue>14</issue>), pp. <fpage>2991</fpage>–<lpage>3001</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Bicknell</surname>, <given-names>B.A.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> (<year>2021</year>) ‘<article-title>A synaptic learning rule for exploiting nonlinear dendritic computation</article-title>’, <source>Neuron</source>, <volume>109</volume>(<issue>24</issue>), pp. <fpage>4001</fpage>–<lpage>4017</lpage>.e10.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Bienenstock</surname>, <given-names>E.L.</given-names></string-name>, <string-name><surname>Cooper</surname>, <given-names>L.N.</given-names></string-name> and <string-name><surname>Munro</surname>, <given-names>P.W.</given-names></string-name> (<year>1982</year>) ‘<article-title>Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>2</volume>(<issue>1</issue>), pp. <fpage>32</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>B.A.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> (<year>2010</year>) ‘<article-title>Dendritic discrimination of temporal input sequences in cortical neurons</article-title>’, <source>Science</source>, <volume>329</volume>(<issue>5999</issue>), pp. <fpage>1671</fpage>–<lpage>1675</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> (<year>2010</year>) ‘<article-title>The single dendritic branch as a fundamental functional unit in the nervous system</article-title>’, <source>Current opinion in neurobiology</source>, <volume>20</volume>(<issue>4</issue>), pp. <fpage>494</fpage>–<lpage>502</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Bruce</surname>, <given-names>N.J.</given-names></string-name> <etal>et al.</etal> (<year>2019</year>) ‘<article-title>Regulation of adenylyl cyclase 5 in striatal neurons confers the ability to detect coincident neuromodulatory signals</article-title>’, <source>PLoS computational biology</source>, <volume>15</volume>(<issue>10</issue>), p. <fpage>e1007382</fpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Carter</surname>, <given-names>A.G.</given-names></string-name> and <string-name><surname>Sabatini</surname>, <given-names>B.L.</given-names></string-name> (<year>2004</year>) ‘<article-title>State-dependent calcium signaling in dendritic spines of striatal medium spiny neurons</article-title>’, <source>Neuron</source>, <volume>44</volume>(<issue>3</issue>), pp. <fpage>483</fpage>–<lpage>493</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>S.X.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>) ‘<article-title>Subtype-specific plasticity of inhibitory circuits in motor cortex during motor learning</article-title>’, <source>Nature neuroscience</source>, <volume>18</volume>(<issue>8</issue>), pp. <fpage>1109</fpage>–<lpage>1115</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal> (<year>2011</year>) ‘<article-title>Functional mapping of single spines in cortical neurons in vivo</article-title>’, <source>Nature</source>, <volume>475</volume>(<issue>7357</issue>), pp. <fpage>501</fpage>–<lpage>505</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Cichon</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Gan</surname>, <given-names>W.-B.</given-names></string-name> (<year>2015</year>) ‘<article-title>Branch-specific dendritic Ca(2+) spikes cause persistent synaptic plasticity</article-title>’, <source>Nature</source>, <volume>520</volume>(<issue>7546</issue>), pp. <fpage>180</fpage>–<lpage>185</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Day</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> (<year>2024</year>) ‘<article-title>GABAergic regulation of striatal spiny projection neurons depends upon their activity state</article-title>’, <source>PLoS biology</source>, <volume>22</volume>(<issue>1</issue>), p. <fpage>e3002483</fpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Destexhe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mainen</surname>, <given-names>Z.F.</given-names></string-name> and <string-name><surname>Sejnowski</surname>, <given-names>T.J.</given-names></string-name> (<year>1994</year>) ‘<article-title>An efficient method for computing synaptic conductances based on a kinetic model of receptor binding</article-title>’, <source>Neural computation</source>, <volume>6</volume>(<issue>1</issue>), pp. <fpage>14</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Dorman</surname>, <given-names>D.B.</given-names></string-name>, <string-name><surname>Jędrzejewska-Szmek</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Blackwell</surname>, <given-names>K.T.</given-names></string-name> (<year>2018</year>) ‘<article-title>Inhibition enhances spatially-specific calcium encoding of synaptic input patterns in a biologically constrained model</article-title>’, <source>eLife</source>, <volume>7</volume>. Available at: <pub-id pub-id-type="doi">10.7554/eLife.38588</pub-id>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Doron</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> (<year>2017</year>) ‘<article-title>Timed Synaptic Inhibition Shapes NMDA Spikes, Influencing Local Dendritic Processing and Global I/O Properties of Cortical Neurons</article-title>’, <source>Cell reports</source>, <volume>21</volume>(<issue>6</issue>), pp. <fpage>1550</fpage>–<lpage>1561</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Du</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal> (<year>2017</year>) ‘<article-title>Cell-type-specific inhibition of the dendritic plateau potential in striatal spiny projection neurons</article-title>’, <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>114</volume>(<issue>36</issue>), pp. <fpage>E7612</fpage>–<lpage>E7621</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Fino</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal> (<year>2010</year>) ‘<article-title>Distinct coincidence detectors govern the corticostriatal spike timing-dependent plasticity</article-title>’, <source>The Journal of physiology</source>, <volume>588</volume>(<issue>Pt 16</issue>), pp. <fpage>3045</fpage>–<lpage>3062</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Fisher</surname>, <given-names>S.D.</given-names></string-name> <etal>et al.</etal> (<year>2017</year>) ‘<article-title>Reinforcement determines the timing dependence of corticostriatal synaptic plasticity in vivo</article-title>’, <source>Nature communications</source>, <volume>8</volume>(<issue>1</issue>), p. <fpage>334</fpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Gandolfi</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> (<year>2020</year>) ‘<article-title>Inhibitory Plasticity: From Molecules to Computation and Beyond</article-title>’, <source>International journal of molecular sciences</source>, <volume>21</volume>(<fpage>5</fpage>). Available at: <pub-id pub-id-type="doi">10.3390/ijms21051805</pub-id>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Gao</surname>, <given-names>P.P.</given-names></string-name> <etal>et al.</etal> (<year>2021</year>) ‘<article-title>Local glutamate-mediated dendritic plateau potentials change the state of the cortical pyramidal neuron</article-title>’, <source>Journal of neurophysiology</source>, <volume>125</volume>(<issue>1</issue>), pp. <fpage>23</fpage>–<lpage>42</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Gidon</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> (<year>2020</year>) ‘<article-title>Dendritic action potentials and computation in human layer 2/3 cortical neurons</article-title>’, <source>Science</source>, <volume>367</volume>(<issue>6473</issue>), pp. <fpage>83</fpage>–<lpage>87</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Henneberger</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal> (<year>2020</year>) ‘<article-title>LTP Induction Boosts Glutamate Spillover by Driving Withdrawal of Perisynaptic Astroglia</article-title>’, <source>Neuron</source>, <volume>108</volume>(<issue>5</issue>), pp. <fpage>919</fpage>–<lpage>936</lpage>.e11.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>van den Heuvel</surname>, <given-names>M.P.</given-names></string-name> and <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name> (<year>2013</year>) ‘<article-title>Network hubs in the human brain</article-title>’, <source>Trends in cognitive sciences</source>, <volume>17</volume>(<issue>12</issue>), pp. <fpage>683</fpage>–<lpage>696</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Higley</surname>, <given-names>M.J.</given-names></string-name> and <string-name><surname>Sabatini</surname>, <given-names>B.L.</given-names></string-name> (<year>2010</year>) ‘<article-title>Competitive regulation of synaptic Ca2+ influx by D2 dopamine and A2A adenosine receptors</article-title>’, <source>Nature neuroscience</source>, <volume>13</volume>(<issue>8</issue>), pp. <fpage>958</fpage>–<lpage>966</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Hwang</surname>, <given-names>F.-J.</given-names></string-name> <etal>et al.</etal> (<year>2022</year>) ‘<article-title>Motor learning selectively strengthens cortical and striatal synapses of motor engram neurons</article-title>’, <source>Neuron</source>, <volume>110</volume>(<issue>17</issue>), pp. <fpage>2790</fpage>–<lpage>2801</lpage>.e5.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Iacaruso</surname>, <given-names>M.F.</given-names></string-name>, <string-name><surname>Gasler</surname>, <given-names>I.T.</given-names></string-name> and <string-name><surname>Hofer</surname>, <given-names>S.B.</given-names></string-name> (<year>2017</year>) ‘<article-title>Synaptic organization of visual space in primary visual cortex</article-title>’, <source>Nature</source>, <volume>547</volume>(<issue>7664</issue>), pp. <fpage>449</fpage>–<lpage>452</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Jia</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal> (<year>2010</year>) ‘<article-title>Dendritic organization of sensory input to cortical neurons in vivo</article-title>’, <source>Nature</source>, <volume>464</volume>(<issue>7293</issue>), pp. <fpage>1307</fpage>–<lpage>1312</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Johansson</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Silberberg</surname>, <given-names>G.</given-names></string-name> (<year>2020</year>) ‘<article-title>The Functional Organization of Cortical and Thalamic Inputs onto Five Types of Striatal Neurons Is Determined by Source and Target Cell Identities</article-title>’, <source>Cell reports</source>, <volume>30</volume>(<issue>4</issue>), pp. <fpage>1178</fpage>–<lpage>1194</lpage>.e3.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Ju</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal> (<year>2020</year>) ‘<article-title>Spatiotemporal functional organization of excitatory synaptic inputs onto macaque V1 neurons</article-title>’, <source>Nature communications</source>, <volume>11</volume>(<issue>1</issue>), p. <fpage>697</fpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Kahneman</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Tversky</surname>, <given-names>A.</given-names></string-name> (<year>1979</year>) ‘<article-title>Prospect theory: An analysis of decision under risk</article-title>’, <source>Econometrica: journal of the Econometric Society</source>, <volume>47</volume>(<issue>2</issue>), p. <fpage>263</fpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Kawai</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>) ‘<article-title>Motor cortex is required for learning but not for executing a motor skill</article-title>’, <source>Neuron</source>, <volume>86</volume>(<issue>3</issue>), pp. <fpage>800</fpage>–<lpage>812</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kerlin</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> (<year>2019</year>) ‘<article-title>Functional clustering of dendritic activity during decision-making</article-title>’, <source>eLife</source>, <volume>8</volume>. Available at: <pub-id pub-id-type="doi">10.7554/eLife.46966</pub-id>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Kleindienst</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> (<year>2011</year>) ‘<article-title>Activity-dependent clustering of functional synaptic inputs on developing hippocampal dendrites</article-title>’, <source>Neuron</source>, <volume>72</volume>(<issue>6</issue>), pp. <fpage>1012</fpage>–<lpage>1024</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Larkum</surname>, <given-names>M.E.</given-names></string-name> <etal>et al.</etal> (<year>2009</year>) ‘<article-title>Synaptic integration in tuft dendrites of layer 5 pyramidal neurons: a new unifying principle</article-title>’, <source>Science</source>, <volume>325</volume>(<issue>5941</issue>), pp. <fpage>756</fpage>–<lpage>760</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Lavzin</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> (<year>2012</year>) ‘<article-title>Nonlinear dendritic processing determines angular tuning of barrel cortex neurons in vivo</article-title>’, <source>Nature</source>, <volume>490</volume>(<issue>7420</issue>), pp. <fpage>397</fpage>–<lpage>401</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Legenstein</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name> (<year>2011</year>) ‘<article-title>Branch-specific plasticity enables self-organization of nonlinear computation in single neurons</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>31</volume>(<issue>30</issue>), pp. <fpage>10787</fpage>–<lpage>10802</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Lindroos</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> (<year>2018</year>) ‘<article-title>Basal Ganglia Neuromodulation Over Multiple Temporal and Structural Scales-Simulations of Direct Pathway MSNs Investigate the Fast Onset of Dopaminergic Effects and Predict the Role of Kv4.2</article-title>’, <source>Frontiers in neural circuits</source>, <volume>12</volume>, p. <fpage>3</fpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Lindroos</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Hellgren Kotaleski</surname>, <given-names>J.</given-names></string-name> (<year>2021</year>) ‘<article-title>Predicting complex spikes in striatal projection neurons of the direct pathway following neuromodulation by acetylcholine and dopamine</article-title>’, <source>The European journal of neuroscience</source>, <volume>53</volume>(<issue>7</issue>), pp. <fpage>2117</fpage>–<lpage>2134</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Losonczy</surname>, <given-names>A.</given-names></string-name> and <string-name><surname>Magee</surname>, <given-names>J.C.</given-names></string-name> (<year>2006</year>) ‘<article-title>Integrative properties of radial oblique dendrites in hippocampal CA1 pyramidal neurons</article-title>’, <source>Neuron</source>, <volume>50</volume>(<issue>2</issue>), pp. <fpage>291</fpage>–<lpage>307</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Major</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal> (<year>2008</year>) ‘<article-title>Spatiotemporally graded NMDA spike/plateau potentials in basal dendrites of neocortical pyramidal neurons</article-title>’, <source>Journal of neurophysiology</source>, <volume>99</volume>(<issue>5</issue>), pp. <fpage>2584</fpage>–<lpage>2601</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>von der Malsburg</surname>, <given-names>C.</given-names></string-name> (<year>1999</year>) <article-title>‘The what and why of binding: the modeler’s perspective’</article-title>, <source>Neuron</source>, <volume>24</volume>(<issue>1</issue>), pp. <fpage>95</fpage>–<lpage>104</lpage>, 111–25.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Matsuda</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal> (<year>2009</year>) ‘<article-title>Single nigrostriatal dopaminergic neurons form widely spread and highly dense axonal arborizations in the neostriatum</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>29</volume>(<issue>2</issue>), pp. <fpage>444</fpage>–<lpage>453</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>McCulloch</surname>, <given-names>W.S.</given-names></string-name> and <string-name><surname>Pitts</surname>, <given-names>W.</given-names></string-name> (<year>1943</year>) ‘<article-title>A logical calculus of the ideas immanent in nervous activity</article-title>’, <source>The Bulletin of mathematical biophysics</source>, <volume>5</volume>(<issue>4</issue>), pp. <fpage>115</fpage>–<lpage>133</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Nair</surname>, <given-names>A.G.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>) ‘<article-title>Sensing Positive versus Negative Reward Signals through Adenylyl Cyclase-Coupled GPCRs in Direct and Indirect Pathway Striatal Medium Spiny Neurons</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>35</volume>(<issue>41</issue>), pp. <fpage>14017</fpage>–<lpage>14030</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Niculescu</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> (<year>2018</year>) ‘<article-title>A BDNF-Mediated Push-Pull Plasticity Mechanism for Synaptic Clustering</article-title>’, <source>Cell reports</source>, <volume>24</volume>(<issue>8</issue>), pp. <fpage>2063</fpage>–<lpage>2074</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Oikonomou</surname>, <given-names>K.D.</given-names></string-name> <etal>et al.</etal> (<year>2014</year>) ‘<article-title>Spiny neurons of amygdala, striatum, and cortex use dendritic plateau potentials to detect network UP states</article-title>’, <source>Frontiers in cellular neuroscience</source>, <volume>8</volume>, p. <fpage>292</fpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Plotkin</surname>, <given-names>J.L.</given-names></string-name> <etal>et al.</etal> (<year>2013</year>) ‘<article-title>Regulation of dendritic calcium release in striatal spiny projection neurons</article-title>’, <source>Journal of neurophysiology</source>, <volume>110</volume>(<issue>10</issue>), pp. <fpage>2325</fpage>–<lpage>2336</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Plotkin</surname>, <given-names>J.L.</given-names></string-name>, <string-name><surname>Day</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Surmeier</surname>, <given-names>D.J.</given-names></string-name> (<year>2011</year>) ‘<article-title>Synaptically driven state transitions in distal dendrites of striatal spiny neurons</article-title>’, <source>Nature neuroscience</source>, <volume>14</volume>(<issue>7</issue>), pp. <fpage>881</fpage>–<lpage>888</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Poirazi</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brannon</surname>, <given-names>T.</given-names></string-name> and <string-name><surname>Mel</surname>, <given-names>B.W.</given-names></string-name> (<year>2003</year>) ‘<article-title>Pyramidal neuron as two-layer neural network</article-title>’, <source>Neuron</source>, <volume>37</volume>(<issue>6</issue>), pp. <fpage>989</fpage>–<lpage>999</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Polsky</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mel</surname>, <given-names>B.W.</given-names></string-name> and <string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name> (<year>2004</year>) ‘<article-title>Computational subunits in thin dendrites of pyramidal cells</article-title>’, <source>Nature neuroscience</source>, <volume>7</volume>(<issue>6</issue>), pp. <fpage>621</fpage>–<lpage>627</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Ravasenga</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> (<year>2022</year>) ‘<article-title>Spatial regulation of coordinated excitatory and inhibitory synaptic plasticity at dendritic synapses</article-title>’, <source>Cell reports</source>, <volume>38</volume>(<issue>6</issue>), p. <fpage>110347</fpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Reig</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Silberberg</surname>, <given-names>G.</given-names></string-name> (<year>2014</year>) ‘<article-title>Multisensory integration in the mouse striatum</article-title>’, <source>Neuron</source>, <volume>83</volume>(<issue>5</issue>), pp. <fpage>1200</fpage>–<lpage>1212</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Reynolds</surname>, <given-names>J.N.J.</given-names></string-name> <etal>et al.</etal> (<year>2022</year>) ‘<article-title>Coincidence of cholinergic pauses, dopaminergic activation and depolarisation of spiny projection neurons drives synaptic plasticity in the striatum</article-title>’, <source>Nature communications</source>, <volume>13</volume>(<issue>1</issue>), p. <fpage>1296</fpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Roskies</surname>, <given-names>A.L.</given-names></string-name> (<year>1999</year>) ‘<article-title>The binding problem</article-title>’, <source>Neuron</source>, <volume>24</volume>(<issue>1</issue>), pp. <fpage>7</fpage>–<lpage>9</lpage>, 111–25.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Sanabria</surname>, <given-names>B.D.</given-names></string-name> <etal>et al.</etal> (<year>2024</year>) ‘<article-title>Cell-Type Specific Connectivity of Whisker-Related Sensory and Motor Cortical Input to Dorsal Striatum</article-title>’, <source>eNeuro</source>, <volume>11</volume>(<issue>1</issue>). Available at: <pub-id pub-id-type="doi">10.1523/ENEURO.0503-23.2023</pub-id>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Santos</surname>, <given-names>F.J.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>) ‘<article-title>Corticostriatal dynamics encode the refinement of specific behavioral variability during skill learning</article-title>’, <source>eLife</source>, <volume>4</volume>, p. <fpage>e09423</fpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Schiess</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Urbanczik</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Senn</surname>, <given-names>W.</given-names></string-name> (<year>2016</year>) ‘<article-title>Somato-dendritic Synaptic Plasticity and Error-backpropagation in Active Dendrites</article-title>’, <source>PLoS computational biology</source>, <volume>12</volume>(<issue>2</issue>), p. <fpage>e1004638</fpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> (<year>2000</year>) ‘<article-title>NMDA spikes in basal dendrites of cortical pyramidal neurons</article-title>’, <source>Nature</source>, <volume>404</volume>(<issue>6775</issue>), pp. <fpage>285</fpage>–<lpage>289</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Scholl</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>D.E.</given-names></string-name> and <string-name><surname>Fitzpatrick</surname>, <given-names>D.</given-names></string-name> (<year>2017</year>) ‘<article-title>Local Order within Global Disorder: Synaptic Architecture of Visual Space</article-title>’, <source>Neuron</source>, <volume>96</volume>(<issue>5</issue>), pp. <fpage>1127</fpage>–<lpage>1138</lpage>.e4.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name> (<year>2007</year>) ‘<article-title>Multiple dopamine functions at different time courses</article-title>’, <source>Annual review of neuroscience</source>, <volume>30</volume>, pp. <fpage>259</fpage>–<lpage>288</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> and <string-name><surname>Montague</surname>, <given-names>P.R.</given-names></string-name> (<year>1997</year>) ‘<article-title>A neural substrate of prediction and reward</article-title>’, <source>Science</source>, <volume>275</volume>(<issue>5306</issue>), pp. <fpage>1593</fpage>–<lpage>1599</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Shen</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal> (<year>2008</year>) ‘<article-title>Dichotomous dopaminergic control of striatal synaptic plasticity</article-title>’, <source>Science</source>, <volume>321</volume>(<issue>5890</issue>), pp. <fpage>848</fpage>–<lpage>851</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Shindou</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> (<year>2019</year>) ‘<article-title>A silent eligibility trace enables dopamine-dependent synaptic plasticity for reinforcement learning in the mouse striatum</article-title>’, <source>The European journal of neuroscience</source>, <volume>49</volume>(<issue>5</issue>), pp. <fpage>726</fpage>–<lpage>736</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Shindou</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ochi-Shindou</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Wickens</surname>, <given-names>J.R.</given-names></string-name> (<year>2011</year>) ‘<article-title>A Ca(2+) threshold for induction of spike-timing-dependent depression in the mouse striatum</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>31</volume>(<issue>36</issue>), pp. <fpage>13015</fpage>–<lpage>13022</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Silver</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> (<year>2018</year>) ‘<article-title>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play</article-title>’, <source>Science</source>, <volume>362</volume>(<issue>6419</issue>), pp. <fpage>1140</fpage>–<lpage>1144</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Stauffer</surname>, <given-names>W.R.</given-names></string-name> <etal>et al.</etal> (<year>2016</year>) ‘<article-title>Components and characteristics of the dopamine reward utility signal</article-title>’, <source>The Journal of comparative neurology</source>, <volume>524</volume>(<issue>8</issue>), pp. <fpage>1699</fpage>–<lpage>1711</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Surmeier</surname>, <given-names>D.J.</given-names></string-name> <etal>et al.</etal> (<year>2010</year>) ‘<article-title>The role of dopamine in modulating the structure and function of striatal circuits</article-title>’, <source>Progress in brain research</source>, <volume>183</volume>, pp. <fpage>149</fpage>–<lpage>167</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Takahashi</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal> (<year>2012</year>) ‘<article-title>Locally synchronized synaptic inputs</article-title>’, <source>Science</source>, <volume>335</volume>(<issue>6066</issue>), pp. <fpage>353</fpage>–<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Tran-Van-Minh</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>) ‘<article-title>Contribution of sublinear and supralinear dendritic integration to neuronal computations</article-title>’, <source>Frontiers in cellular neuroscience</source>, <volume>9</volume>, p. <fpage>67</fpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Trpevski</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> (<year>2023</year>) ‘<article-title>Glutamate spillover drives robust all-or-none dendritic plateau potentials-an investigation using models of striatal projection neurons</article-title>’, <source>Frontiers in cellular neuroscience</source>, <volume>17</volume>, p. <fpage>1196182</fpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Varga</surname>, <given-names>Z.</given-names></string-name> <etal>et al.</etal> (<year>2011</year>) ‘<article-title>Dendritic coding of multiple sensory inputs in single cortical neurons in vivo</article-title>’, <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>108</volume>(<issue>37</issue>), pp. <fpage>15420</fpage>–<lpage>15425</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname>, <given-names>C.J.</given-names></string-name> <etal>et al.</etal> (<year>1983</year>) ‘<article-title>Three-dimensional structure of dendritic spines in the rat neostriatum</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>3</volume>(<issue>2</issue>), pp. <fpage>383</fpage>–<lpage>388</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname>, <given-names>D.E.</given-names></string-name> <etal>et al.</etal> (<year>2016</year>) ‘<article-title>Orientation selectivity and the functional clustering of synaptic inputs in primary visual cortex</article-title>’, <source>Nature neuroscience</source>, <volume>19</volume>(<issue>8</issue>), pp. <fpage>1003</fpage>–<lpage>1009</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Winnubst</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> (<year>2015</year>) ‘<article-title>Spontaneous Activity Drives Local Synaptic Plasticity In Vivo</article-title>’, <source>Neuron</source>, <volume>87</volume>(<issue>2</issue>), pp. <fpage>399</fpage>–<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Wolf</surname>, <given-names>J.A.</given-names></string-name> <etal>et al.</etal> (<year>2005</year>) ‘<article-title>NMDA/AMPA ratio impacts state transitions and entrainment to oscillations in a computational model of the nucleus accumbens medium spiny projection neuron</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>25</volume>(<issue>40</issue>), pp. <fpage>9080</fpage>–<lpage>9095</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>Xu</surname>, <given-names>N.-L.</given-names></string-name> <etal>et al.</etal> (<year>2012</year>) ‘<article-title>Nonlinear dendritic integration of sensory and motor input during an active sensing task</article-title>’, <source>Nature</source>, <volume>492</volume>(<issue>7428</issue>), pp. <fpage>247</fpage>–<lpage>251</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Yagishita</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> (<year>2014</year>) ‘<article-title>A critical time window for dopamine actions on the structural plasticity of dendritic spines</article-title>’, <source>Science</source>, <volume>345</volume>(<issue>6204</issue>), pp. <fpage>1616</fpage>–<lpage>1620</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name> and <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name> (<year>2017</year>) ‘<article-title>Hebbian plasticity requires compensatory processes on multiple timescales</article-title>’, <source>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</source>, <volume>372</volume>(<issue>1715</issue>). Available at: <pub-id pub-id-type="doi">10.1098/rstb.2016.0259</pub-id>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name> and <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name> (<year>2017</year>) ‘<article-title>The temporal paradox of Hebbian learning and homeostatic plasticity</article-title>’, <source>Current opinion in neurobiology</source>, <volume>43</volume>, pp. <fpage>166</fpage>–<lpage>176</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Jun</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Stanford University</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This computational modeling study builds on multiple previous lines of experimental and theoretical research to investigate how a single neuron can solve a nonlinear pattern classification task. The study presents <bold>valuable</bold> insights that the location of synapses on dendritic branches, as well as synaptic plasticity of excitatory and inhibitory synapses, influences the ability of a neuron to discriminate combinations of sensory stimuli. However, the evidence presented is <bold>incomplete</bold> - the major conclusions are only partially supported by the data presented, and there are identified gaps between the supporting evidence and the major conclusions.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This computational modeling study builds on multiple previous lines of experimental and theoretical research to investigate how a single neuron can solve a nonlinear pattern classification task. The authors construct a detailed biophysical and morphological model of a single striatal medium spiny neuron, and endow excitatory and inhibitory synapses with dynamic synaptic plasticity mechanisms that are sensitive to (1) the presence or absence of a dopamine reward signal, and (2) spatiotemporal coincidence of synaptic activity in single dendritic branches. The latter coincidence is detected by voltage-dependent NMDA-type glutamate receptors, which can generate a type of dendritic spike referred to as a &quot;plateau potential.&quot; The proposed mechanisms result in moderate performance on a nonlinear classification task when specific input features are segregated and clustered onto individual branches, but reduced performance when input features are randomly distributed across branches. Given the high level of complexity of all components of the model, it is not clear which features of which components are most important for its performance. There is also room for improvement in the narrative structure of the manuscript and the organization of concepts and data.</p>
<p>Strengths:</p>
<p>The integrative aspect of this study is its major strength. It is challenging to relate low-level details such as electrical spine compartmentalization, extrasynaptic neurotransmitter concentrations, dendritic nonlinearities, spatial clustering of correlated inputs, and plasticity of excitatory and inhibitory synapses to high-level computations such as nonlinear feature classification. Due to high simulation costs, it is rare to see highly biophysical and morphological models used for learning studies that require repeated stimulus presentations over the course of a training procedure. The study aspires to prove the principle that experimentally-supported biological mechanisms can explain complex learning.</p>
<p>Weaknesses:</p>
<p>The high level of complexity of each component of the model makes it difficult to gain an intuition for which aspects of the model are essential for its performance, or responsible for its poor performance under certain conditions. Stripping down some of the biophysical detail and comparing it to a simpler model may help better understand each component in isolation. That said, the fundamental concepts behind nonlinear feature binding in neurons with compartmentalized dendrites have been explored in previous work, so it is not clear how this study represents a significant conceptual advance. Finally, the presentation of the model, the motivation and justification of each design choice, and the interpretation of each result could be restructured for clarity to be better received by a wider audience.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The study explores how single striatal projection neurons (SPNs) utilize dendritic nonlinearities to solve complex integration tasks. It introduces a calcium-based synaptic learning rule that incorporates local calcium dynamics and dopaminergic signals, along with metaplasticity to ensure stability for synaptic weights. Results show SPNs can solve the nonlinear feature binding problem and enhance computational efficiency through inhibitory plasticity in dendrites, emphasizing the significant computational potential of individual neurons. In summary, the study provides a more biologically plausible solution to single-neuron learning and gives further mechanical insights into complex computations at the single-neuron level.</p>
<p>Strengths:</p>
<p>The paper introduces a novel learning rule for training a single multicompartmental neuron model to perform nonlinear feature binding tasks (NFBP), highlighting two main strengths: the learning rule is local, calcium-based, and requires only sparse reward signals, making it highly biologically plausible, and it applies to detailed neuron models that effectively preserve dendritic nonlinearities, contrasting with many previous studies that use simplified models.</p>
<p>Weaknesses:</p>
<p>I am concerned that the manuscript was submitted too hastily, as evidenced by the quality and logic of the writing and the presentation of the figures. These issues may compromise the integrity of the work. I would recommend a substantial revision of the manuscript to improve the clarity of the writing, incorporate more experiments, and better define the goals of the study.</p>
<p>Major Points:</p>
<p>(1) Quality of Scientific Writing: The current draft does not meet the expected standards. Key issues include:</p>
<p>i. Mathematical and Implementation Details: The manuscript lacks comprehensive mathematical descriptions and implementation details for the plasticity models (LTP/LTD/Meta) and the SPN model. Given the complexity of the biophysically detailed multicompartment model and the associated learning rules, the inclusion of only nine abstract equations (Eq. 1-9) in the Methods section is insufficient. I was surprised to find no supplementary material providing these crucial details. What parameters were used for the SPN model? What are the mathematical specifics for the extra-synaptic NMDA receptors utilized in this study? For instance, Eq. 3 references [Ca2+]-does this refer to calcium ions influenced by extra-synaptic NMDARs, or does it apply to other standard NMDARs? I also suggest the authors provide pseudocodes for the entire learning process to further clarify the learning rules.</p>
<p>ii. Figure quality. The authors seem not to carefully typeset the images, resulting in overcrowding and varying font sizes in the figures. Some of the fonts are too small and hard to read. The text in many of the diagrams is confusing. For example, in Panel A of Figure 3, two flattened images are combined, leading to small, distorted font sizes. In Panels C and D of Figure 7, the inconsistent use of terminology such as &quot;kernels&quot; further complicates the clarity of the presentation. I recommend that the authors thoroughly review all figures and accompanying text to ensure they meet the expected standards of clarity and quality.</p>
<p>iii. Writing clarity. The manuscript often includes excessive and irrelevant details, particularly in the mathematical discussions. On page 24, within the &quot;Metaplasticity&quot; section, the authors introduce the biological background to support the proposed metaplasticity equation (Eq. 5). However, much of this biological detail is hypothesized rather than experimentally verified. For instance, the claim that &quot;a pause in dopamine triggers a shift towards higher calcium concentrations while a peak in dopamine pushes the LTP kernel in the opposite direction&quot; lacks cited experimental evidence. If evidence exists, it should be clearly referenced; otherwise, these assertions should be presented as theoretical hypotheses. Generally, Eq. 5 and related discussions should be described more concisely, with only a loose connection to dopamine effects until more experimental findings are available.</p>
<p>(2) Goals of the Study: The authors need to clearly define the primary objective of their research. Is it to showcase the computational advantages of the local learning rule, or to elucidate biological functions?</p>
<p>i. Computational Advantage: If the intent is to demonstrate computational advantages, the current experimental results appear inadequate. The learning rule introduced in this work can only solve for four features, whereas previous research (e.g., Bicknell and Hausser, 2021) has shown capability with over 100 features. It is crucial for the authors to extend their demonstrations to prove that their learning rule can handle more than just three features. Furthermore, the requirement to fine-tune the midpoint of the synapse function indicates that the rule modifies the &quot;activation function&quot; of the synapses, as opposed to merely adjusting synaptic weights. In machine learning, modifying weights directly is typically more efficient than altering activation functions during learning tasks. This might account for why the current learning rule is restricted to a limited number of tasks. The authors should critically evaluate whether the proposed local learning rule, including meta-plasticity, actually offers any computational advantage. This evaluation is essential to understand the practical implications and effectiveness of the proposed learning rule.</p>
<p>ii. Biological Significance: If the goal is to interpret biological functions, the authors should dig deeper into the model behaviors to uncover their biological significance. This exploration should aim to link the observed computational features of the model more directly with biological mechanisms and outcomes.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.1.sa3</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Khodadadi</surname>
<given-names>Zahra</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6124-949X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Trpevski</surname>
<given-names>Daniel</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9068-6744</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Lindroos</surname>
<given-names>Robert</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9134-3601</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Kotaleski</surname>
<given-names>Jeanette Hellgren</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0550-0739</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<disp-quote content-type="editor-comment">
<p>Summary:</p>
<p>This computational modeling study builds on multiple previous lines of experimental and theoretical research to investigate how a single neuron can solve a nonlinear pattern classification task. The authors construct a detailed biophysical and morphological model of a single striatal medium spiny neuron, and endow excitatory and inhibitory synapses with dynamic synaptic plasticity mechanisms that are sensitive to (1) the presence or absence of a dopamine reward signal, and (2) spatiotemporal coincidence of synaptic activity in single dendritic branches. The latter coincidence is detected by voltage-dependent NMDA-type glutamate receptors, which can generate a type of dendritic spike referred to as a &quot;plateau potential.&quot; The proposed mechanisms result in moderate performance on a nonlinear classification task when specific input features are segregated and clustered onto individual branches, but reduced performance when input features are randomly distributed across branches. Given the high level of complexity of all components of the model, it is not clear which features of which components are most important for its performance. There is also room for improvement in the narrative structure of the manuscript and the organization of concepts and data.</p>
</disp-quote>
<p>To begin with, we will better explain the goal of the study in the introduction and explain that it relies on earlier theoretical work. The goal of the study was to investigate whether and how detailed neuron models with biologically-based morphologies, membrane properties, ion channels, dendritic nonlinearities, and biologically plausible learning rules can quantitatively account for the theoretical results obtained with more abstract models.</p>
<p>We will further evaluate and clarify the roles of several components in our model regarding their impact on the results. These include a) the role of sufficiently robust and supralinear plateau potentials in computing the NFBP; and b) the importance of metaplasticity for individual synapses, allowing them to start or stop responding to relevant or irrelevant stimuli, respectively, over the training period.</p>
<disp-quote content-type="editor-comment">
<p>Strengths:</p>
<p>The integrative aspect of this study is its major strength. It is challenging to relate low-level details such as electrical spine compartmentalization, extrasynaptic neurotransmitter concentrations, dendritic nonlinearities, spatial clustering of correlated inputs, and plasticity of excitatory and inhibitory synapses to high-level computations such as nonlinear feature classification. Due to high simulation costs, it is rare to see highly biophysical and morphological models used for learning studies that require repeated stimulus presentations over the course of a training procedure. The study aspires to prove the principle that experimentally-supported biological mechanisms can explain complex learning.</p>
<p>Weaknesses:</p>
<p>The high level of complexity of each component of the model makes it difficult to gain an intuition for which aspects of the model are essential for its performance, or responsible for its poor performance under certain conditions. Stripping down some of the biophysical detail and comparing it to a simpler model may help better understand each component in isolation. That said, the fundamental concepts behind nonlinear feature binding in neurons with compartmentalized dendrites have been explored in previous work, so it is not clear how this study represents a significant conceptual advance. Finally, the presentation of the model, the motivation and justification of each design choice, and the interpretation of each result could be restructured for clarity to be better received by a wider audience.</p>
</disp-quote>
<p>To achieve the goal of the study as described above, we chose to use a biophysically and morphologically detailed neuron model to see if it could quantitatively account for the theoretically-based nonlinear computations, for instance, those discussed in <ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/4u5mj9/0yhz">Tran-Van-Minh, A.</ext-link> <italic><ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/4u5mj9/0yhz">et al.</ext-link></italic> <ext-link ext-link-type="uri" xlink:href="http://paperpile.com/b/4u5mj9/0yhz">(2015)</ext-link>.</p>
<p>We will explain the role of each component of the learning rule, as well as the dendritic nonlinearities, for the performance on the NFBP.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>The study explores how single striatal projection neurons (SPNs) utilize dendritic nonlinearities to solve complex integration tasks. It introduces a calcium-based synaptic learning rule that incorporates local calcium dynamics and dopaminergic signals, along with metaplasticity to ensure stability for synaptic weights. Results show SPNs can solve the nonlinear feature binding problem and enhance computational efficiency through inhibitory plasticity in dendrites, emphasizing the significant computational potential of individual neurons. In summary, the study provides a more biologically plausible solution to single-neuron learning and gives further mechanical insights into complex computations at the single-neuron level.</p>
<p>Strengths:</p>
<p>The paper introduces a novel learning rule for training a single multicompartmental neuron model to perform nonlinear feature binding tasks (NFBP), highlighting two main strengths: the learning rule is local, calcium-based, and requires only sparse reward signals, making it highly biologically plausible, and it applies to detailed neuron models that effectively preserve dendritic nonlinearities, contrasting with many previous studies that use simplified models.</p>
</disp-quote>
<p>Indeed, the learning rule is local and reward-based, and we will highlight better in the paper that it is “always on”, i.e. there are no separate training and testing phases.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>I am concerned that the manuscript was submitted too hastily, as evidenced by the quality and logic of the writing and the presentation of the figures. These issues may compromise the integrity of the work. I would recommend a substantial revision of the manuscript to improve the clarity of the writing, incorporate more experiments, and better define the goals of the study.</p>
</disp-quote>
<p>We will revise the manuscript thoroughly to better present the figures and writing (more detailed below). We will also show supplementary figures showcasing the role of the different components of the learning rule.</p>
<disp-quote content-type="editor-comment">
<p>Major Points:</p>
<p>(1) Quality of Scientific Writing: The current draft does not meet the expected standards. Key issues include:</p>
<p>i. Mathematical and Implementation Details: The manuscript lacks comprehensive mathematical descriptions and implementation details for the plasticity models (LTP/LTD/Meta) and the SPN model. Given the complexity of the biophysically detailed multicompartment model and the associated learning rules, the inclusion of only nine abstract equations (Eq. 1-9) in the Methods section is insufficient. I was surprised to find no supplementary material providing these crucial details. What parameters were used for the SPN model? What are the mathematical specifics for the extra-synaptic NMDA receptors utilized in this study? For instance, Eq. 3 references [Ca2+]-does this refer to calcium ions influenced by extra-synaptic NMDARs, or does it apply to other standard NMDARs? I also suggest the authors provide pseudocodes for the entire learning process to further clarify the learning rules.</p>
</disp-quote>
<p>The detailed setup of the model is described in the referenced papers, including equations and parameter values. The model is downloadable on github. For this reason we did not repeat the information here. That said, we will go through the manuscript and clarify all details, and provide supplemental figures and a GitHub link where necessary for reproducing the results.</p>
<disp-quote content-type="editor-comment">
<p>ii. Figure quality. The authors seem not to carefully typeset the images, resulting in overcrowding and varying font sizes in the figures. Some of the fonts are too small and hard to read. The text in many of the diagrams is confusing. For example, in Panel A of Figure 3, two flattened images are combined, leading to small, distorted font sizes. In Panels C and D of Figure 7, the inconsistent use of terminology such as &quot;kernels&quot; further complicates the clarity of the presentation. I recommend that the authors thoroughly review all figures and accompanying text to ensure they meet the expected standards of clarity and quality.</p>
</disp-quote>
<p>We will revise the figures for consistency and clarity.</p>
<disp-quote content-type="editor-comment">
<p>iii. Writing clarity. The manuscript often includes excessive and irrelevant details, particularly in the mathematical discussions. On page 24, within the &quot;Metaplasticity&quot; section, the authors introduce the biological background to support the proposed metaplasticity equation (Eq. 5). However, much of this biological detail is hypothesized rather than experimentally verified. For instance, the claim that &quot;a pause in dopamine triggers a shift towards higher calcium concentrations while a peak in dopamine pushes the LTP kernel in the opposite direction&quot; lacks cited experimental evidence. If evidence exists, it should be clearly referenced; otherwise, these assertions should be presented as theoretical hypotheses. Generally, Eq. 5 and related discussions should be described more concisely, with only a loose connection to dopamine effects until more experimental findings are available.</p>
</disp-quote>
<p>The reviewer is correct; the cited text does not present experimental facts but rather illustrates how the learning rule operates. We will revise the section on the construction of learning rules to clarify which aspects are explicit assumptions and which are experimentally verified. In particular, we will provide a more detailed description and motivation for metaplasticity</p>
<disp-quote content-type="editor-comment">
<p>(2) Goals of the Study: The authors need to clearly define the primary objective of their research. Is it to showcase the computational advantages of the local learning rule, or to elucidate biological functions?</p>
</disp-quote>
<p>Briefly, the goal of the study was to investigate whether earlier theoretical results with more abstract models can be quantitatively recapitulated in morphologically and biophysically detailed neuron models with dendritic nonlinearities and with biologically based learning rules. (similar response to Summary and Weaknesses to Reviewer #1). We will update the introduction with this information.</p>
<disp-quote content-type="editor-comment">
<p>i. Computational Advantage: If the intent is to demonstrate computational advantages, the current experimental results appear inadequate. The learning rule introduced in this work can only solve for four features, whereas previous research (e.g., Bicknell and Hausser, 2021) has shown capability with over 100 features. It is crucial for the authors to extend their demonstrations to prove that their learning rule can handle more than just three features. Furthermore, the requirement to fine-tune the midpoint of the synapse function indicates that the rule modifies the &quot;activation function&quot; of the synapses, as opposed to merely adjusting synaptic weights. In machine learning, modifying weights directly is typically more efficient than altering activation functions during learning tasks. This might account for why the current learning rule is restricted to a limited number of tasks. The authors should critically evaluate whether the proposed local learning rule, including meta-plasticity, actually offers any computational advantage. This evaluation is essential to understand the practical implications and effectiveness of the proposed learning rule.</p>
</disp-quote>
<p>As mentioned above, our intent is not to demonstrate the computational advantages of the proposed learning rule but to investigate and illustrate how biophysically detailed neuron models that also display dendritic plateau potential mechanisms, together with biologically-based learning rules, can support the theoretically predicted computational requirements for complex neuronal processing (e.g., Tran-Van-Minh, A. et al., 2015), as well as the results obtained with more abstract neuron models and plateau potential mechanisms (e.g., Schiess et al., 2016; Legenstein and Maass, 2011).</p>
<p>In the revised manuscript, we will also discuss the differences between the supervised learning rule in Bicknell and Hausser (2021) and our local and reward-based learning rule. We will also show a critical evaluation of how our local learning rule and metaplasticity affect the synaptic weights and why the different components of the rule are needed.</p>
<disp-quote content-type="editor-comment">
<p>ii. Biological Significance: If the goal is to interpret biological functions, the authors should dig deeper into the model behaviors to uncover their biological significance. This exploration should aim to link the observed computational features of the model more directly with biological mechanisms and outcomes.</p>
</disp-quote>
<p>We will make an attempt to better link the learning rule and dendritic supra-linearities and interpret their biological function.</p>
</body>
</sub-article>
</article>