<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">108943</article-id>
<article-id pub-id-type="doi">10.7554/eLife.108943</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108943.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Comprehensive characterization of human color discrimination thresholds</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1890-1977</contrib-id>
<name>
<surname>Hong</surname>
<given-names>Fangfang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>fh862@sas.upenn.edu</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bouhassira</surname>
<given-names>Ruby</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chow</surname>
<given-names>Jason</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sanders</surname>
<given-names>Craig</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shvartsman</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Guan</surname>
<given-names>Phillip</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Williams</surname>
<given-names>Alex H</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9827-543X</contrib-id>
<name>
<surname>Brainard</surname>
<given-names>David H</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
    <aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>Department of Psychology, University of Pennsylvania</institution></institution-wrap>, <city>Philadelphia</city>, <country country="US">United States</country></aff>
    <aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zbnvs85</institution-id><institution>Reality Lab Research, Meta</institution></institution-wrap>, <city>Menlo Park</city>, <country country="US">United States</country></aff>
    <aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zbnvs85</institution-id><institution>FAIR, Meta</institution></institution-wrap>, <city>Menlo Park</city>, <country country="US">United States</country></aff>
    <aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Center for Neural Science, New York University</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country></aff>
    <aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00sekdz59</institution-id><institution>Center for Computational Neuroscience, Flatiron Institute</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Huxlin</surname>
<given-names>Krystel R</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>University of Rochester</institution>
</institution-wrap>
<city>Rochester</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-11-25">
<day>25</day>
<month>11</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP108943</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-09-05">
<day>05</day>
<month>09</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-08-18">
<day>18</day>
<month>08</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.07.16.665219"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Hong et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Hong et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-108943-v1.pdf"/>
<abstract>
<p>Color discrimination thresholds—the smallest detectable color differences—provide a benchmark for models of color vision, enable quantitative evaluation of eye diseases, and inform the design of display technologies. Despite their importance, a comprehensive characterization of these thresholds has long been considered intractable due to the psychophysical curse of dimensionality. Here, we address this challenge using a novel semi-parametric Wishart Process Psychophysical Model (WPPM), which leverages the feature that the internal noise limiting color discrimination varies smoothly across stimulus space. The model was fit to data collected with a non-parametric adaptive trial-placement procedure, enabling efficient stimulus selection. Together, through the combination of adaptive trial placement and <italic>post hoc</italic> WPPM fitting, we achieved comprehensive characterization of color discrimination in the isoluminant plane with only ~6,000 trials per participant (N = 8). Once fit, the WPPM allows readouts of discrimination performance for any stimulus pair. We validated these readouts against 25 probe psychometric functions, measured with an additional 6,000 trials per participant held out from model fitting. In conclusion, our study provides a foundational dataset for color vision, and our approach generalizes beyond color to any domain in which the internal noise limiting performance varies smoothly across stimulus space, offering a powerful and efficient method for comprehensively characterizing various perceptual discrimination thresholds.</p>
</abstract>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01zbnvs85</institution-id>
<institution>Meta</institution>
</institution-wrap>
</funding-source>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>In this revised version, we combined the abstract and significance statement into a single abstract, reformatted the manuscript using a different LaTeX template, and merged the supplement with the main text into a single PDF so that cross-references work seamlessly. No other substantive changes were made.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Measurements of discrimination threshold—the smallest detectable stimulus change—are foundational for understanding biological vision. Threshold measurements support inferences about the neural mechanisms mediating performance (<xref ref-type="bibr" rid="c45">Hecht et al., 1942</xref>; <xref ref-type="bibr" rid="c16">Campbell and Robson, 1968</xref>), guide the design of displays and specification of perceptual tolerances (<xref ref-type="bibr" rid="c62">MacAdam, 1942</xref>; <xref ref-type="bibr" rid="c58">de Lange Dzn, 1958</xref>), allow quantitative evaluation of eye diseases (<xref ref-type="bibr" rid="c3">Aspinall et al., 1983</xref>; <xref ref-type="bibr" rid="c52">Johnson et al., 2011</xref>; <xref ref-type="bibr" rid="c70">Niwa et al., 2014</xref>; <xref ref-type="bibr" rid="c91">Vemala et al., 2017</xref>), inform models of suprathreshold perceptual representations (<xref ref-type="bibr" rid="c36">Fechner, 1860</xref>; <xref ref-type="bibr" rid="c47">Hillis and Brainard, 2007</xref>; <xref ref-type="bibr" rid="c104">Zhou et al., 2024</xref>), and allow perceptual effects to be incorporated into the study of cognitive processes (<xref ref-type="bibr" rid="c75">Palmer et al., 1993</xref>; <xref ref-type="bibr" rid="c67">Najemnik and Geisler, 2005</xref>; <xref ref-type="bibr" rid="c73">Olkkonen et al., 2014</xref>). Modern psychophysical methods (<xref ref-type="bibr" rid="c54">Knoblauch and Maloney, 2012</xref>; <xref ref-type="bibr" rid="c78">Prins et al., 2016</xref>) provide rigorous quantification of thresholds, and the theory of signal detection (<xref ref-type="bibr" rid="c42">Green et al., 1966</xref>; <xref ref-type="bibr" rid="c2">Ashby and Soto, 2015</xref>; <xref ref-type="bibr" rid="c44">Hautus et al., 2021</xref>) provides a mature framework for relating thresholds to the precision of the underlying representation.</p>
<p>Despite the central role of perceptual thresholds, characterization of thresholds has largely been limited to individual stimulus dimensions. For example, pedestal functions characterize contrast discrimination threshold across varying baseline contrasts (<xref ref-type="bibr" rid="c37">Foley and Legge, 1981</xref>). To generalize threshold characterization beyond a single dimension, we introduce the concept of the <italic>psychometric field</italic>: a multidimensional function that specifies the probability of a particular perceptual response as a joint function of both a reference and a comparison stimulus. In contrast to the psychometric function, which describes response probability as a function of variation around a fixed reference, the psychometric field captures how discrimination performance varies across all combinations of reference and comparison stimuli in a stimulus space. As the dimensionality of the psychometric field increases, the number of trials needed to tile the field grows exponentially—a psychophysical curse of dimensionality.</p>
<p>In this study, we focus on human color discrimination thresholds. Despite their significances and applications described above, fully characterizing human color discrimination—even on a single planar slice—has long been considered impractical (<xref ref-type="bibr" rid="c83">Schrödinger, 1920</xref>). This is because, although the stimulus space itself is two-dimensional, the underlying psychometric field is fourdimensional, as both the reference and comparison stimuli vary along two color dimensions. Mapping this field requires estimating discrimination performance across a densely sampled set of reference stimuli, with multiple comparison stimuli tested at each. The number of required trials quickly becomes intractable using conventional methods such as the method of constant stimuli (MOCS). While adaptive trial-placement procedures can greatly improve sampling efficiency (<xref ref-type="bibr" rid="c59">Lesmes et al., 2010</xref>; <xref ref-type="bibr" rid="c96">Watson, 2017</xref>), they typically rely on certain parametric forms. In many cases—including ours—such form is not known in advance.</p>
<p>Here, we show that it is possible to obtain a comprehensive characterization of the color discrimination psychometric field in the isoluminant plane. We achieved this by efficiently sampling reference-comparison stimulus pairs obtained using a non-parametric adaptive trial-placement procedure (<xref ref-type="bibr" rid="c74">Owen et al., 2021</xref>; <xref ref-type="bibr" rid="c60">Letham et al., 2022</xref>), and then fitting the data <italic>post hoc</italic> with a semiparametric model that leverages the feature that the internal noise limiting color discrimination varies smoothly across stimulus space. We collected full datasets from 8 individual participants, and for each participant, we validated the accuracy of the model readouts against independent threshold measurements from held-out validation trials. Importantly, from the model fit, we can read out the psychometric function along any chromatic direction around any reference stimulus in the plane and thus determine the discrimination threshold in that direction. Our study provides a foundational dataset that can be used to test computational and neural models of color discrimination, benchmark color metrics, and develop models that can predict supra-threshold color discrimination performance.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Overview</title>
<p>The Results section is organized as follows. We begin with a brief overview of the experimental stimuli and task (Task and stimuli), followed by a summary of how our model characterizes the full psychometric field (The Wishart Process Psychophysical Model (WPPM)) and a description of the non-parametric adaptive trial-placement procedure used to collect the data (Adaptively sampled trials). Having described these essential methods, we then present our core results (WPPM threshold estimates) and evaluate the validity of our model (Validation of the WPPM). Finally, we compare our findings with previous measurements from the color discrimination literature (Comparison with previous measurements). Additional technical details are provided in Methods and Materials and Appendix 1 Appendix 11.</p>
</sec>
<sec id="s2b">
<title>Task and stimuli</title>
    <p>Participants (N = 8) performed a 3AFC oddity task. On each trial, three blobby stimuli were shown in a triangular spatial arrangement—two identical reference stimuli and one comparison stimulus with a different surface color (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). The comparison stimulus was pseudo-randomly assigned to one of the three positions within the triangular arrangement. Participants were asked to identify the odd one out. Stimuli were rendered using the Unity graphics engine, and color was controlled by varying the specified surface reflectance using RGB (red, green, blue) coordinates, with other scene aspects held constant. We used naturalistic stimuli to increase the relevance of our results for understanding color vision in the real world. Hedjar and colleagues (<xref ref-type="bibr" rid="c46">Hedjar et al., 2025</xref>) provide a comparison of color discrimination using stimuli similar to ours versus traditional flat spatially uniform patches.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
    <caption><title>Task, stimuli and the WPPM.</title>
        <p>(A) 3AFC oddity task. On each trial, participants viewed a triplet of stimuli—two identical references and one different comparison—and identified the odd one out. (B) Stimuli were constrained to lie in the isoluminant plane the display’s gray point. Data were represented and fit in a transformation of this plane which we refer to as <italic>model space</italic>. The grid of dots illustrates the transformation between the plane in the RGB and model space. (C) Example of a smoothly varying covariance matrix field produced by the WPPM. The field was generated by sampling from a finite-basis Wishart random process with a smooth prior (<italic>ϵ</italic> = 0.5; see Prior over the weight matrix). Although the field is illustrated on a 7 × 7 grid, it specifies a covariance matrix <inline-formula id="inline-eqn-1"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="665219v2_inline9.gif"/></inline-formula> for every stimulus in the plane, as shown in the heat maps. (D) Example of a less smoothly varying covariance matrix field. This field was obtained by drawing from a finite-basis Wishart random process with a less smooth prior (<italic>ϵ</italic> = 0.8). (E) Observer model. For each stimulus triplet <inline-formula id="inline-eqn-2"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="665219v2_inline10.gif"/></inline-formula>, internal representations <inline-formula id="inline-eqn-3"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="665219v2_inline11.gif"/></inline-formula> are drawn from multivariate Gaussian distributions centered at the reference stimulus with noise characterized by the corresponding covariance matrices. The model determines whether the observer correctly identifies the odd stimulus by comparing the squared Mahalanobis distances <inline-formula id="inline-eqn-4"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="665219v2_inline12.gif"/></inline-formula> between the representation pairs. (F) Derivation of elliptical threshold contour. One-dimensional psychometric functions are approximated using Monte Carlo simulations (10,000 samples per stimulus pair shown for illustration; 2,000 used during model fitting). For each selected chromatic direction, we derive the threshold distance corresponding to 66.7% correct. An ellipse is then fit to the threshold distances to describe the discrimination threshold contour. Notably, while the threshold contour and the noise ellipse shown at one standard deviation have well-matched shapes, the threshold contour is larger because it corresponds to 66.7% correct.</p></caption>
<graphic xlink:href="665219v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We made spectral calibration measurements (<xref ref-type="bibr" rid="c9">Brainard et al., 2002</xref>) to establish the relationship between RGB and the light emitted from the display. These measurements allowed us to represent the stimuli in terms of the excitations of the human L, M, and S cones elicited by the stimuli, and more generally in any standard color space (<xref ref-type="bibr" rid="c12">Brainard, 1996</xref>, <xref ref-type="bibr" rid="c8">2003</xref>; <xref ref-type="bibr" rid="c11">Brainard and Stockman, 2010</xref>). For this study, stimuli were constrained to lie in the isoluminant plane passing through the monitor’s gray point and bounded by its gamut. This plane was then affine-transformed into a square ranging between −1 and 1 along each axis (<xref rid="fig1" ref-type="fig">Figure 1B</xref>; Appendix 1). We refer the space in which the transformed plane is as the <italic>model space</italic> because it is directly related to the way we formulated our semi-parametric model, and also served as a convenient representation for the non-parametric adaptive trial-placement procedure we used (see details in Covariance matrix field).</p>
</sec>
<sec id="s2c">
<title>The Wishart Process Psychophysical Model (WPPM)</title>
<p>As an overview of our modeling approach, we fit the color discrimination responses (coded as ‘correct’ or ‘incorrect’) with a novel model, the WPPM—a Bayesian probabilistic model that combines an observer model (specified through a likelihood function) with an expectation of smoothness in the internal noise limiting color discrimination (specified through a prior distribution). Once fit to the data, the WPPM yields a continuously varying field of covariance matrices that characterize the internal noise in the perceptual representation of color stimuli (<xref rid="fig1" ref-type="fig">Figure 1 C-D</xref>). These covariance matrices, in turn, determine the entire psychometric field.</p>
<p>More specifically, we designed the observer model within the WPPM to formalize the intuition that the stimulus perceived as most distant from the other two is identified as the “odd one out”. The internal representation of each stimulus is assumed to be noisy and modeled as a multivariate Gaussian with the same dimensionality as the stimulus space. We assume the mean of each distribution is given by the corresponding stimulus’ location in the model space. In contrast, we allow the covariance matrices to vary across the model space to account for differences in the encoding precision of the color stimuli. On each trial, the observer model has access to one sample from the distribution of each of the three stimuli—two identical reference stimuli and one comparison. The observer model computes the pairwise squared Mahalanobis distance between each pair of noisy samples, using the weighted average of the covariance matrices of the reference and comparison (<xref rid="fig1" ref-type="fig">Figure 1E</xref>). By using Mahalanobis distance to make decisions (instead of, for example, Euclidean distance), the observer accounts for the expected noise structure. The two stimuli whose pairwise distance is smallest are identified as the references, and the remaining stimulus as the comparison (the “odd one out”). Because there is no simple closed-form solution for this decision rule (<xref ref-type="bibr" rid="c66">Mullen and Ennis, 1991</xref>), we used Monte Carlo simulation to approximate the percent-correct performance (Observer model).</p>
<p>We expect the internal noise that limits color discrimination to vary smoothly across the model space—that is, small changes in the reference stimulus should produce only small changes in the corresponding internal noise. The WPPM reflects this expectation by placing a finite-basis Wishart process prior over the continuous field of covariance matrices (<xref ref-type="bibr" rid="c99">Wilson and Ghahramani, 2011</xref>). Intuitively, the Wishart process prior introduces a regularization term to the model—it penalizes overly complex or erratic patterns of the covariance matrix field by giving preference to simple, smoothly varying covariance matrix fields. A single hyperparameter, <italic>ϵ</italic>, controls the strength of this regularization (<xref rid="fig1" ref-type="fig">Figure 1C-D</xref>; Prior over the weight matrix).</p>
<p>To fit the model to each participant’s data, we found the <italic>maximum a posteriori</italic> (MAP) estimates of the WPPM’s parameters, using gradient-based numerical optimization of the log posterior density (i.e., the sum of the log prior density and log likelihood function; Model fitting).</p>
<p>The best-fit model parameters, together with the observer model, allow us to read out percentcorrect performance for any pair of reference and comparison stimuli. In particular, to read out a one-dimensional psychometric function, we select a reference stimulus and use the observer model to approximate performance as the comparison stimulus varies along a line (<xref rid="fig1" ref-type="fig">Figure 1F</xref>, left panels). The threshold distance along the line is defined as the distance that yields 66.7% correct. By repeating this process across many directions, we derive a set of threshold distances around the reference (<xref rid="fig1" ref-type="fig">Figure 1F</xref>, right panel). Given our assumption that internal noise follows a multivariate Gaussian distribution, these threshold distances form approximately elliptical contours, and we fit ellipses to them for data representation. This approach is consistent with prior work showing that ellipses provide a good approximation of color discrimination thresholds (<xref ref-type="bibr" rid="c62">MacAdam, 1942</xref>; <xref ref-type="bibr" rid="c13">Brown and MacAdam, 1949</xref>; <xref ref-type="bibr" rid="c71">Noorlander et al., 1981</xref>, <xref ref-type="bibr" rid="c72">1983</xref>; <xref ref-type="bibr" rid="c77">Poirson and Wandell, 1990</xref>; <xref ref-type="bibr" rid="c56">Krauskopf and Karl, 1992</xref>; <xref ref-type="bibr" rid="c53">Knoblauch and Maloney, 1996</xref>; <xref ref-type="bibr" rid="c29">Danilova and Mollon, 2025</xref>), despite some reported deviations (<xref ref-type="bibr" rid="c69">Newton and Eskew, 2003</xref>; <xref ref-type="bibr" rid="c86">Shepard et al., 2016</xref>, <xref ref-type="bibr" rid="c85">2017</xref>). Notably, while we show threshold contours corresponding to 66.7% correct for visualization, once fit, the WPPM allows us to read out the full psychometric function for any reference and chromatic direction—effectively mapping the entire psychometric field. Given that the psychometric field is derived from the underlying field of covariance matrices that characterize internal noise, the smoothness constraint imposed on the covariance matrices naturally propagates to the threshold contours and the field itself.</p>
</sec>
<sec id="s2d">
<title>Adaptively sampled trials</title>
<p>Reference and comparison stimuli for each trial were selected using AEPsych (<xref ref-type="bibr" rid="c74">Owen et al., 2021</xref>), an open-source package for adaptive psychophysics. For the adaptive sampling model, we used a probit-Bernoulli Gaussian Process (GP) model (<xref ref-type="bibr" rid="c98">Williams and Rasmussen, 2006</xref>) with a radial basis function (RBF) kernel. As with the WPPM, the GP assumes smooth variation in performance across the model space due to the RBF kernel, but unlike the WPPM, it does not impose any specific parametric form on the internal noise (or thresholds). The semi-parametric constraint— multivariate Gaussian-shaped internal noise—was introduced only when fitting the WPPM. For this reason, we describe the adaptive trial-placement procedure as non-parametric (relative to the WPPM)—acknowledging that while it incorporates some parametric assumptions, they are less restrictive than those of the WPPM. This non-parametric approach ensures that our data collection was not biased by assuming the correctness of the WPPM prior to validation.</p>
<p>Each participant completed 6,000 AEPsych-driven trials: the first 900 were generated using quasi-random Sobol’ sampling (<xref ref-type="bibr" rid="c88">Sobol, 1967</xref>) to provide an adequate initialization for the GP (Appendix 2); for the remaining 5,100 trials, the GP was updated continuously based on participants’ responses, and each trial was adaptively selected to be most informative for estimating the thresholds targeted at 66.7% correct (<xref ref-type="bibr" rid="c60">Letham et al., 2022</xref>). See <xref rid="fig2" ref-type="fig">Figure 2A</xref> for an illustration of the procedure, and Design for more details.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
    <caption><title>Threshold results and validation.</title>
        <p>(A) Adaptively sampled trials. AEPsych-driven stimulus pairs that were most informative for estimating thresholds across the entire psychometric field. Of the 6,000 trials, the first 900 were Sobol’-sampled; the remaining 5,100 (shown) were adaptively selected based on a non-parametric GP model that was updated every 20 trials and the EAVC acquisition function. (B) Discrimination threshold contours read out from the WPPM fit (66.7% correct) for a representative participant (CH), based on fits to the 6000 AEPsych trials and the fallback trials (Appendix 2). (C) Group summary of WPPM readouts (N = 8). Summary of regression slopes and correlation coefficients for all participants. Error bars: 95% confidence intervals. As a benchmark, the same analysis was performed on simulated data using CIELab Δ<italic>E</italic> 94 as ground truth. (D) Validation trials for the same participant. reference stimuli and chromatic directions were Sobol’-sampled uniquely for each participant. (E) Comparison of thresholds. Ellipses represent discrimination threshold contour read out from the WPPM fit (same fit as in (B)), evaluated at the 25 reference stimuli used in the validation trials. The black bars at the end of each gray line show the 95% bootstrapped confidence interval for the corresponding threshold. (F) Comparison of psychometric functions. Black lines represent the Weibull functions fit to the validation trials (black points), with 95% bootstrapped confidence intervals (gray regions). Colored lines represent the psychometric functions from the WPPM fit, with the full range of 10 bootstraps shown as colored shaded regions. (G) Linear regression of thresholds read out from the WPPM fit against validation thresholds. Horizontal and vertical error bars represent 95% confidence intervals for the validation thresholds from 120 bootstraps and the full range from 10 bootstraps of the WPPM fits, respectively. (H) Summary of regression slopes and correlation coefficients for all participants. Error bars: 95% confidence intervals. As a benchmark, the same analysis was performed on simulated data using CIELab Δ<italic>E</italic> 94 as ground truth.</p></caption>
<graphic xlink:href="665219v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Adaptive sampling with AEPsych requires solving two optimization problems: one for updating the GP model (<xref ref-type="bibr" rid="c98">Williams and Rasmussen, 2006</xref>) and another for selecting the next trial using the Expected Absolute Volume Change (EAVC) acquisition function (<xref ref-type="bibr" rid="c60">Letham et al., 2022</xref>). To reduce computational time, we updated the GP model only every 20 trials. Sometimes, however, either the fitting or the trial selection process did not complete in time for the upcoming stimulus presentation. To avoid perturbing the participants’ rhythm, in these cases we slotted in pre-generated fallback trials (Appendix 3). The number of fallback trials varied across participants, ranging from 0 to 466. These trials were included along with the 6000 AEPsych-driven trials when fitting the WPPM.</p>
</sec>
<sec id="s2e">
<title>WPPM threshold estimates</title>
<p>For each participant, we fit the WPPM to the 6,000 AEPsych-driven trials, along with any additional fallback trials. To visualize the fits, we read out the elliptical threshold contours around a grid of reference stimuli (<xref rid="fig2" ref-type="fig">Figure 2B</xref> for a representative participant). The threshold contours revealed three key regularities: (1) thresholds were lowest for references near the achromatic point defined by the background behind the blobby stimuli, (2) thresholds increased with the distance of the reference from the achromatic point, and (3) the major axes of the elliptical threshold contours were consistently radially oriented with respect to the achromatic point. These regularities were consistent with previous results in the color discrimination literature, as explained further in Comparison with previous measurements.</p>
<p>The data were notably consistent across participants, with all three regularities observed in every individual (<xref rid="fig2" ref-type="fig">Figure 2C</xref>; Appendix 2 for individual plots for the remaining participants). When the variability across participants was assessed as Euclidean distance in the model space representation, it was lowest near the achromatic point where sensitivity was highest and it increased with threshold magnitude. This trend has been observed in other perceptual discrimination tasks (<xref ref-type="bibr" rid="c41">Girshick et al., 2011</xref>; <xref ref-type="bibr" rid="c1">Aguilar et al., 2017</xref>; <xref ref-type="bibr" rid="c49">Hong et al., 2021</xref>).</p>
</sec>
<sec id="s2f">
<title>Validation of the WPPM</title>
<p>To validate the WPPM estimates, we interleaved 6,000 validation trials throughout the experiment. These trials were held out from WPPM model fitting. For each participant, we used Sobol’ sampling to select 25 reference stimuli and associated chromatic directions, with a unique draw per participant. Along each sampled chromatic direction, we used MOCS to sample 12 comparison levels (<xref rid="fig2" ref-type="fig">Figure 2D</xref>): 11 were evenly spaced, and one was selected to provide easily discriminable catch trials (Appendix 4.3). The comparison levels were selected based on a pilot dataset to account for variability in thresholds across different reference stimuli and chromatic directions (see Design for details). Notably, we intentionally avoided densely sampling around a small number of references to minimize differential perceptual learning between the trials used for fitting the WPPM and those reserved for validation (<xref ref-type="bibr" rid="c50">Horiuchi and Nagai, 2024</xref>).</p>
<p>For each of the 25 validation references, we fit a Weibull psychometric function to the 240 MOCS trials collected along the sampled chromatic direction and identified the comparison stimulus corresponding to 66.7% correct (see two examples in <xref rid="fig2" ref-type="fig">Figure 2F</xref>). We then used the WPPM fit (constrained using the non-overlapping set of adaptively-sampled trials) to extract elliptical contours corresponding to the 66.7% threshold level for each validation reference (<xref rid="fig2" ref-type="fig">Figure 2E</xref>). Finally, to directly compare these two methods, we read out the WPPM threshold along the MOCS chromatic direction for each reference. The confidence intervals of the WPPM estimates overlapped with those from the Weibull fits in 24 out of 25 conditions for participant CH (<xref rid="fig2" ref-type="fig">Figure 2E</xref>) and in 21 to 25 conditions across other participants (Appendix 4.1). These results demonstrate strong agreement between thresholds derived from the WPPM psychometric field and the 25 discrete MOCS validation thresholds. This strong agreement indicates that the weak Wishart process prior we imposed to favor smoothly varying threshold contours did not lead to substantial over-smoothing, as the validation thresholds were estimated independently without any such constraint.</p>
<p>To quantify the agreement, we performed a linear (slope only) regression between the thresholds read out from the WPPM fit and those obtained using the validation trials (<xref rid="fig2" ref-type="fig">Figure 2G</xref>). The results further support agreement between the two sets of estimates (mean correlation coefficient = 0.82, range = 0.73 0.97). For 7 out of 8 participants, the regression slope was not significantly different from 1 (mean slope = 1.04, range = 0.97 - 1.13), indicating no systematic bias in the WPPM fits with respect to scale (<xref rid="fig2" ref-type="fig">Figure 2H</xref>; see Appendix 4.1 for individual participant fits). To assess whether there were more subtle sources of bias not captured by the regression slope, we analyzed the residuals—the discrepancies between the WPPM and validation thresholds. While we found no evidence that residuals depended on the orientation or shape of threshold contours read out from the WPPM fit, we did observe one small but statistically significant relation: the model slightly overestimated thresholds when validation thresholds were low and underestimated them when validation thresholds were high (slope = −0.151, <italic>t</italic>(198) = −4.632, <italic>p &lt;</italic> 0.001, <italic>R</italic><sup>2</sup> = 0.098). However, the magnitude of this bias in residuals was small (Appendix 4.2).</p>
<p>As an additional benchmark, we simulated trials and responses based on a ground-truth WPPM instance chosen to approximate the predictions from the CIELab Δ<italic>E</italic> 94 metric (Appendix 5.1 - Appendix 5.5). Using this simulated dataset, we repeated the same validation analyses described above. The thresholds read out from the WPPM fit agreed with 23 out of 25 validation thresholds, based on overlapping confidence intervals. A linear regression revealed a slope of 0.94 and a correlation coefficient of 0.83—well within the range observed in human data (<xref rid="fig2" ref-type="fig">Figure 2H</xref>, left bar). Residual analysis showed a negative correlation between the residuals and the magnitude of the ground-truth validation thresholds (Appendix 5.6), consistent with trends observed in human participants. Finally, we assessed the accuracy of the WPPM against simulation ground truth, across a dense grid of reference stimuli in the model space. Although there were some deviations (Appendix 5.7), they were small relative to the inter-participant variation in thresholds (compare <xref rid="fig2" ref-type="fig">Figure 2C</xref> and <xref rid="figS15" ref-type="fig">Figure S15</xref>).</p>
<p>Taken together, these results validate the accuracy of the WPPM and highlight the remarkable efficiency of our approach. With 6000 trials, conventional psychophysical methods only allowed us to estimate percent-correct performance along one chromatic direction across 25 references. In contrast, our new approach—combining non-parametric, adaptive trial placement with <italic>post hoc</italic> fitting of the semi-parametric WPPM—allowed us to map the entire psychometric field, providing the percent-correct performance for any reference-comparison stimulus pair in the isoluminant plane, using the same number of trials.</p>
</sec>
<sec id="s2g">
<title>Comparison with previous measurements</title>
<p>The WPPM is equivariant under affine transformations of color space (Appendix 1.4), allowing threshold contours derived in our model space to be transformed into other colorimetric representations. This flexibility enables direct comparisons with color discrimination thresholds reported in the literature. At the outset, we emphasize that the size and shape of threshold contours depend on ancillary experimental factors, including task design, stimulus spatial and temporal properties, and participants’ state of adaptation. Given these differences, we do not expect quantitative agreement across studies. Nonetheless, such comparisons help set our findings in the context of the literature. To illustrate, we present several such comparisons below, with the first three shown in the colorimetric representations used in the original studies.</p>
<p>We first compared the overall pattern of threshold variation in the isoluminant plane with measurements made by MacAdam using the method of adjustment (<xref ref-type="bibr" rid="c62">MacAdam, 1942</xref>) (see Appendix 6 for details). In his seminal work, the ellipses do not represent discrimination thresholds <italic>per se</italic>, but rather the standard deviation of color matches for each reference stimulus. Nevertheless, we consider his measurements to be comparable to ours, based on the linking assumption that discrimination thresholds are proportional to the internal noise that governs the variability of the appearance-based matches (<xref ref-type="bibr" rid="c28">Crozier and Holway, 1937</xref>). We observed a similar global structure in how the orientation and scale of the ellipses vary with reference stimulus. As expected, the absolute sizes of the threshold contours differ between studies (<xref rid="fig3" ref-type="fig">Figure 3A</xref>; MacAdam ellipses magnified by 10× while ours magnified by 2×). In addition to differences in task and stimulus spatial and temporal structure, it is worth noting that in MacAdam’s experiment, participants controlled the stimulus duration themselves (<xref ref-type="bibr" rid="c92">Wandell, 1985</xref>) and their state of adaptation differed considerably across reference stimuli (<xref ref-type="bibr" rid="c56">Krauskopf and Karl, 1992</xref>). Despite these differences, the general correspondence between the datasets is apparent. It is also noteworthy that MacAdam’s results are based on 25,000 adjustments at a limited number of reference locations, whereas our ~6,000 forced-choice trials enabled us to characterize discrimination performance across all in-gamut reference–comparison pairs.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
    <caption><title>Comparison of color discrimination thresholds with previous measurements.</title>
        <p>(A) <xref ref-type="bibr" rid="c62">MacAdam 1942</xref>. Top: MacAdam’s original threshold contours, magnified by 10× for visualization. Bottom: Threshold contours from one participant in our study, transformed from the model space into CIE 1931 chromaticity space. reference stimuli were sampled from a 5 × 5 grid evenly spaced from –0.75 to 0.75 along each dimension of the model space. To reduce visual clutter, MacAdam ellipses that fall within the gamut of our isoluminant plane (parallelogram) are shown as red arrows indicating only their major axes. For visual comparability, our ellipses are magnified 2× to approximate the size of those in MacAdam’s data. Triangle: gamut of our monitor. (B) <xref ref-type="bibr" rid="c29">Danilova and Mollon 2025</xref>. Left: Original threshold contours (79.4% correct) from their study, magnified by 4×. Right: Threshold contours from one participant in our study (colored ellipses), transformed from the model space into a scaled MacLeod–Boynton space. Reference points were sampled on a 5 × 5 grid ranging from –0.7 to 0.7. As in (A), to reduce visual clutter, their ellipses that fall within the gamut of our isoluminant plane (parallelogram) are shown as red arrows indicating only their major axes. For visual comparability, our ellipses are magnified by 1.5×. (C) <xref ref-type="bibr" rid="c56">Krauskopf and Karl 1992</xref>. Left: Original threshold contours (79.4% correct converged by a three-down-one-up staircase) from their study (Fig. 14 from this study, reproduced under Creative Commons CC BY-NC-ND 4.0). Right: Threshold contours from one participant in our study, transformed into a stretched DKL space. All contours are shown at their original sizes. (D) CIELab Δ<italic>E</italic> 76, Δ<italic>E</italic> 94, and Δ<italic>E</italic> 2000. Δ<italic>E</italic> values were converted into percent correct using a Weibull psychometric function, and threshold is defined as the Δ<italic>E</italic> = 2.5. Colored lines represent the measured thresholds from one participant, shown at their original sizes. For visual comparability, the predicted threshold contours from each CIELab metric (black lines) were magnified by factors of 5, 2.5, and 2.5, for Δ<italic>E</italic> 76, Δ<italic>E</italic> 94, Δ<italic>E</italic> 2000 metrics, respectively, to approximately match the scale of the measured thresholds in our study. See Appendix 6 - Appendix 9 for additional details.</p></caption>
<graphic xlink:href="665219v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In a more recent study, <xref ref-type="bibr" rid="c29">Danilova and Mollon 2025</xref> measured threshold contours across a relatively broad region of the isoluminant plane, with sparse sampling of reference stimuli. The experimental paradigm in their study closely resembled ours: both used a fixed adapting point—D65 in their case and the monitor gray point in ours—and employed an oddity task to estimate discrimination thresholds. They used a 4AFC design combined with an adaptive staircase procedure, whereas we used a 3AFC version. To compare our data with theirs, we transformed our discrimination threshold contours read out from the WPPM fit into the same scaled MacLeod–Boynton space (<xref ref-type="bibr" rid="c64">MacLeod and Boynton, 1979</xref>) used in their study (Appendix 7). Despite minor methodological differences, our results replicated the overall pattern of variation in ellipse orientation and size across the color space. In particular, thresholds were smallest near the adapting point, increased with distance from it, and the ellipses generally pointed towards the adapting point. Given the similarity in experimental design, it is not surprising that we observe closer agreement in the absolute sizes of the threshold contours than in comparison to MacAdam’s data (<xref rid="fig3" ref-type="fig">Figure 3B</xref>; their ellipses were magnified by 4×, ours by 1.5×).</p>
<p>In the next comparison, we turned to the study by <xref ref-type="bibr" rid="c56">Krauskopf and Karl 1992</xref>, whose measurements were concentrated within a small region near the achromatic point. Their experiment used a fixed adapting point and a 4AFC oddity task, with individual thresholds estimated using a threedown-one-up staircase procedure. To enable direct comparison, we read out threshold contours from our model at the same set of reference stimuli they used. Their results revealed two key features: (1) the threshold contour was smallest at the adapting point, and (2) as the reference moved away from it, the contours became increasingly elongated along the axis pointing toward the adapting point. Both features were observed in our data albeit with some inter-participant variability (<xref rid="fig3" ref-type="fig">Figure 3C</xref>; Appendix 8). However, because their measurements were limited to reference stimuli near the adapting point, their data did not reveal how thresholds vary with increasing distance from it. In contrast, our results demonstrate that these patterns extend across a much broader region of the isoluminant plane.</p>
<p>Lastly, we compared our results with iso-distance contours obtained with different versions of the CIELab Δ<italic>E</italic> color difference metrics (<xref ref-type="bibr" rid="c26">Colorimetry, 2004</xref>). For these comparisons, we plotted the CIELab contours in our model space. Although Δ<italic>E</italic> metrics were developed to describe suprathreshold perceptual color differences and are based on data integrated from multiple sources, comparisons with threshold-level measurements remain of interest—particularly because of the widespread use of Δ<italic>E</italic> to equate perceptual differences in studies of cognitive processes (<xref ref-type="bibr" rid="c100">Winawer and Witthoft, 2023</xref>; <xref ref-type="bibr" rid="c39">Garside et al., 2025</xref>). To derive a threshold contour for any given reference stimulus, we identified the comparison stimuli corresponding to Δ<italic>E</italic> = 2.5 across multiple chromatic directions and fit an ellipse. While the choice of Δ<italic>E</italic> = 2.5 is arbitrary, it primarily affects the overall size of the contour rather than its shape. The comparison reveals that the iso-distance contours of the original CIELab Δ<italic>E</italic> 76, which remains widely used, bear little resemblance to our threshold contours (<xref rid="fig3" ref-type="fig">Figure 3D</xref>, left panel; Appendix 9). The large deviations we observed between Δ<italic>E</italic> 76 and our data provide further caution against the practice of using Δ<italic>E</italic> 76 to predict perceptual color difference. In contrast, the more recent Δ<italic>E</italic> 94 and Δ<italic>E</italic> 2000 metrics provided a much closer match (<xref rid="fig3" ref-type="fig">Figure 3D</xref>, center and right), with only modest deviations from our measurements. These deviations may arise from differences between threshold and supra-threshold perceptual judgments, as well as from discrepancies in experimental conditions between our study and those used to constrain the parameters of the CIELab metrics. An important feature of our data is that it enables such comparison with any perceptual metric across the isoluminant plane.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>A data-efficient approach for characterizing color discrimination thresholds</title>
<p>In this study, we demonstrated a data-efficient approach for achieving a comprehensive characterization of human color discrimination thresholds. Participants performed a 3AFC oddity task and completed 6,000 trials that were specifically targeted near threshold via a non-parametric adaptive trial-placement procedure (<xref ref-type="bibr" rid="c74">Owen et al., 2021</xref>; <xref ref-type="bibr" rid="c60">Letham et al., 2022</xref>). We then developed and fit a novel WPPM to these adaptively sampled trials (along with a small number of fallback trials). The WPPM defines a continuous mapping from each reference stimulus to its associated internal noise, characterized by a covariance matrix. This mapping, in turn, enables predictions of discrimination performance for any pair of reference and comparison stimuli—effectively mapping out the full four-dimensional psychometric field. To evaluate model validity, we interleaved 6,000 additional validation trials to estimate 25 probe psychometric functions. The results revealed that thresholds read out from the WPPM closely matched those derived from the validation trials, supporting the model’s accuracy. Thus, by combining the non-parametric adaptive trial-placement procedure with <italic>post hoc</italic> fitting of the semi-parametric WPPM, we achieved an unprecedentedly comprehensive characterization of color discrimination in the isoluminant plane.</p>
<p>Our measurements align qualitatively with previous studies that used either sparse sampling or targeted at a small region of a color space (<xref ref-type="bibr" rid="c62">MacAdam, 1942</xref>; <xref ref-type="bibr" rid="c56">Krauskopf and Karl, 1992</xref>; <xref ref-type="bibr" rid="c29">Danilova and Mollon, 2025</xref>). Moreover, our measurements provide a more comprehensive characterization, in that the WPPM allows direct readout of threshold contour at any reference stimulus without the need for additional measurement. Additionally, for studies examining how thresholds vary with factors such as stimulus size, presentation duration, or adaptation state, our approach offers a scalable and data-efficient approach for measuring how these factors affect the psychometric field. Finally, we have performed simulations that indicate it will be feasible to fully characterize the color psychometric discrimination field across the three-dimensional gamut of our display, a goal that was has been previously described as “hopelessly difficult” (<xref ref-type="bibr" rid="c83">Schrödinger, 1920</xref>).</p>
</sec>
<sec id="s3b">
<title>Implications for the mechanisms of color perception</title>
<p>Consistent with a well-established body of evidence, we found that thresholds were smallest near the achromatic reference, reflecting heightened sensitivity at the adapting point (<xref ref-type="bibr" rid="c27">Craik, 1938</xref>; <xref ref-type="bibr" rid="c14">Brown, 1952</xref>; <xref ref-type="bibr" rid="c51">Hurvich and Hurvich-Jameson, 1961</xref>; <xref ref-type="bibr" rid="c76">Pointer, 1974</xref>; <xref ref-type="bibr" rid="c61">Loomis and Berger, 1979</xref>; <xref ref-type="bibr" rid="c56">Krauskopf and Karl, 1992</xref>). In addition, threshold contours were oriented toward the achromatic center, in agreement with previous findings (<xref ref-type="bibr" rid="c56">Krauskopf and Karl, 1992</xref>; <xref ref-type="bibr" rid="c40">Gegenfurtner, 2025</xref>; <xref ref-type="bibr" rid="c29">Danilova and Mollon, 2025</xref>). The observation that the size and orientation of the elliptical threshold contours vary with the reference stimulus rules out mechanistic models that posit a linear transformation of cone excitations into three post-receptoral channels followed by fixed additive noise. Such models predict identical ellipses across the space. Moreover, the observation that the orientation of the elliptical threshold contours changes across reference stimuli also rules out mechanistic models in which a linear transformation of cone excitations is followed by limiting noise applied independently to each of the three channels. These models allow variation in size and shape but still predict identical principal axes for all threshold contours.</p>
<p>Cone-opponent models that posit noise and nonlinearities at multiple stages of processing, possibly with an overcomplete cone-opponent representation, may be able to account for the observed data, as may models that invoke higher-order mechanisms (e.g. mechanisms narrowly tuned for hue). For more on relevant ideas see <xref ref-type="bibr" rid="c102">Wyszecki 1982</xref>; <xref ref-type="bibr" rid="c93">Wandell 1995</xref>; <xref ref-type="bibr" rid="c21">Chen et al. 2000</xref>; <xref ref-type="bibr" rid="c35">Eskew Jr 2009</xref>; <xref ref-type="bibr" rid="c90">Stockman et al. 2010</xref>; <xref ref-type="bibr" rid="c43">Hansen and Gegenfurtner 2013</xref>; <xref ref-type="bibr" rid="c87">Shevell and Martin 2017</xref>. Although mechanistic models are often tested using additional manipulations such as adaptation and noise-masking, our dataset provides a new and comprehensive benchmark for evaluating and distinguishing competing accounts. In future work, our approach could be extended by incorporating such manipulations to further differentiating those models.</p>
</sec>
<sec id="s3c">
<title>Toward a metric of supra-threshold color difference</title>
    <p>A longstanding and fundamental question in vision science is whether it is possible to develop a perceptual metric that accurately predicts both threshold-level and supra-threshold judgments of color difference. For example, considerable effort has gone into attempts to find color representations where the perceptual color difference between two color stimuli is predicted by the Euclidean distance of their coordinates in the representation (e.g., the original 1976 CIELab and CIELuv Δ<italic>E</italic> metrics; see <xref ref-type="bibr" rid="c8">Brainard 2003</xref>; <xref ref-type="bibr" rid="c82">Robertson et al. 1977</xref>). Our measurements directly establish a locally Euclidean metric for threshold-level differences. While threshold behavior is well-described as locally Euclidean, however, supra-threshold judgments have been shown to violate the assumptions of a globally Euclidean geometry (<xref ref-type="bibr" rid="c101">Wuerger et al., 1995</xref>; <xref ref-type="bibr" rid="c34">Ennis and Zaidi, 2019</xref>). In particular, perceptual similarity judgments at larger distances often fail to satisfy key Euclidean properties such as the expectation that variability in judgments should increase with Euclidean distance (<xref ref-type="bibr" rid="c101">Wuerger et al., 1995</xref>), and that a stimulus equidistant from two endpoints should be perceived as equally similar to both (<xref ref-type="bibr" rid="c34">Ennis and Zaidi, 2019</xref>).</p>
<p>An alternative framework, originally proposed by Fechner (<xref ref-type="bibr" rid="c36">Fechner, 1860</xref>) and explored subsequently (<xref ref-type="bibr" rid="c83">Schrödinger, 1920</xref>; <xref ref-type="bibr" rid="c63">Macadam, 1979</xref>; <xref ref-type="bibr" rid="c102">Wyszecki, 1982</xref>; <xref ref-type="bibr" rid="c103">Zaidi, 2001</xref>; <xref ref-type="bibr" rid="c55">Koenderink, 2010</xref>; <xref ref-type="bibr" rid="c15">Bujack et al., 2022</xref>; <xref ref-type="bibr" rid="c81">Roberti, 2024</xref>; <xref ref-type="bibr" rid="c89">Stark et al., 2025</xref>), suggests that supra-threshold differences may be understood as the accumulation of small threshold-level differences along a path between stimuli. In this framework, color space is taken to be a Riemannian manifold—a space that is locally Euclidean but may be globally curved. The perceptual distance between two colors is hypothesized to correspond to the geodesic—the shortest path between them in terms of accumulated thresholds. This distance is computed by integrating local thresholds along all possible paths between the two points and selecting the path with the smallest total. In our observer model, this integration is effectively equivalent (up to a constant) to summing internal noise along the path.</p>
<p>Testing this <italic>Riemannian hypothesis</italic> requires knowledge of how internal noise (or threshold) varies across color space, as this determines the geodesics. Our measurements provide the necessary knowledge for the isoluminant plane, enabling direct empirical tests of the Riemannian hypothesis within this slice of color space, as well as elaborations of this hypothesis (<xref ref-type="bibr" rid="c15">Bujack et al., 2022</xref>; <xref ref-type="bibr" rid="c89">Stark et al., 2025</xref>). The results of such tests may depend on the particular experimental paradigms used to assess supra-threshold perceptual differences.</p>
<p>Because there is no guarantee that the geodesics between two stimuli in the isoluminant plane are themselves confined to this plane within the full three-dimensional color space, testing the Riemannian hypothesis in this plane based on our current data would be considered provisional. Nonetheless, such tests would provide valuable exploration of the perceptual geometry revealed by our measurements. As noted above, our approach makes it feasible to extend the measurements to the full three-dimensional color space, which, when completed, will allow subsequent investigations to overcome this limitation.</p>
<p>It is possible that the Riemannian hypothesis—and more generally the idea that threshold-level judgments can predict supra-threshold judgments—will fail. Nonetheless, we view understanding whether, when and how such failures occur as central to guiding development of a successful account of color difference perception.</p>
</sec>
<sec id="s3d">
<title>Individual differences and implications</title>
<p>We studied a relatively young cohort of eight participants and found good consistency across individuals, with only modest individual differences. Such differences have, in general, provided useful insights into the neural mechanisms of color vision and are also of interest for understanding how much any given person may differ from an average characterization. To enable studies involving larger and more diverse populations, further improvements in the efficiency of our approach are likely feasible. In the present study, we deliberately used a non-parametric adaptive trial-placement procedure to avoid biasing data collection by assuming the accuracy of the WPPM. Now that the WPPM has been validated, future studies could incorporate adaptive trial-placement strategies tailored to this model or develop priors informed by the current dataset to further improve efficiency. Thus, our results have the potential to support investigations into how variation in the psychometric field of color discrimination relates to underlying biological factors such as pre-retinal absorption, photopigment spectral sensitivity, the ratio of L to M cones in the mosaic, and other color vision measures such as unique hues. Individual differences in these factors have been extensively studied (<xref ref-type="bibr" rid="c68">Neitz and Jacobs, 1986</xref>; <xref ref-type="bibr" rid="c97">Webster and MacLeod, 1988</xref>; <xref ref-type="bibr" rid="c10">Brainard et al., 2000</xref>; <xref ref-type="bibr" rid="c57">Kremers et al., 2000</xref>; <xref ref-type="bibr" rid="c18">Carroll et al., 2002</xref>; <xref ref-type="bibr" rid="c48">Hofer et al., 2005</xref>; <xref ref-type="bibr" rid="c6">Bosten, 2022</xref>; <xref ref-type="bibr" rid="c32">Emery et al., 2023</xref>; <xref ref-type="bibr" rid="c80">Rezeanu et al., 2023</xref>).</p>
</sec>
<sec id="s3e">
<title>Beyond color discrimination</title>
<p>Our approach is generalizable to a wide range of perceptual tasks. A key insight that makes comprehensive characterization of human color discrimination thresholds feasible is the assumption— shared by both our model and the models implemented in AEPsych—that internal noise, and thus thresholds, vary smoothly across stimulus space. This smoothness assumption is not unique to color perception; it applies broadly to other domains. Indeed, smoothly varying elliptical or ellipsoidal thresholds have been reported in studies of motion perception (<xref ref-type="bibr" rid="c79">Reisbeck and Gegenfurtner, 1999</xref>; <xref ref-type="bibr" rid="c19">Champion and Freeman, 2010</xref>), auditory speed discrimination (<xref ref-type="bibr" rid="c38">Freeman et al., 2014</xref>; <xref ref-type="bibr" rid="c17">Carlile and Leung, 2016</xref>; <xref ref-type="bibr" rid="c4">Bertonati et al., 2021</xref>), motion-in-depth (<xref ref-type="bibr" rid="c94">Wardle and Alais, 2013</xref>), and numerosity perception (<xref ref-type="bibr" rid="c23">Cicchini et al., 2016</xref>, <xref ref-type="bibr" rid="c24">2019</xref>, <xref ref-type="bibr" rid="c25">2023</xref>). These parallels highlight the broader relevance of our framework and suggest that combining the non-parametric adaptive trial-placement prodcedure with the WPPM could be a powerful strategy for characterizing perceptual limits across diverse domains.</p>
</sec>
</sec>
<sec id="s4">
<title>Methods and Materials</title>
<sec id="s4a">
<title>Preregistration</title>
<p>This study was preregistered at a public repository. As described in the preregistration document, exploratory analyses were conducted on data from one participant (CH) prior to finalizing the analysis plans for other participants.</p>
</sec>
<sec id="s4b">
<title>Participants</title>
<p>Eight participants (six female, aged 22–30 years; seven right-handed), were recruited for the study. Six were paid volunteers who were naive to the purpose of the study and were compensated for their participation. The remaining two were experimenters and participated without additional compensation. All participants had normal or corrected-to-normal vision (20/40 or better in each eye, assessed using a Snellen eye chart) and normal color vision (assessed using Ishihara plates). The study was approved by the Institutional Review Board at University of Pennsylvania, and written informed consent was obtained from all participants prior to the experiment.</p>
</sec>
<sec id="s4c">
<title>Apparatus</title>
<p>Stimuli were presented using an <ext-link ext-link-type="uri" xlink:href="https://www.amazon.com/Dell-Alienware-Aurora-R11-AWR11-7630DRK-P/dp/B08VCZGY1F">Alienware computer (Aurora R11)</ext-link> running Windows 10 Enterprise, equipped with Intel Core™ i7-10700K processor and NVIDIA GeForce RTX 3080 GPU. The display was a <ext-link ext-link-type="uri" xlink:href="https://www.dell.com/en-us/shop/dell-ultrasharp-27-4k-usb-c-hub-monitor-u2723qe/apd/210-bdpf/monitors-monitor-accessories">DELL U2723QE monitor</ext-link> (59.8cm width, 33.6 cm height, 3840 × 2160 resolution, 60 Hz refresh rate). The monitor was positioned 189 cm from the chinrest, subtending a visual angle of 18.0 × 10.2 degrees of visual angle (dva). Monitor color and luminance measurements were obtained with a <ext-link ext-link-type="uri" xlink:href="https://www.kleininstruments.com/k10-a">Klein K-10A colorimeter</ext-link> and a <ext-link ext-link-type="uri" xlink:href="https://www.jadaktech.com/product/spectrascan-pr-670/">SpectraScan PR-670 radiometer</ext-link>. The display resolution was approximately 200 pixels/dva, above the typical human foveal resolution limit.</p>
<p>The Alienware computer was used solely for stimulus presentation, whereas adaptive sampling of the stimuli was performed on a separate custom-built PC with a <ext-link ext-link-type="uri" xlink:href="https://www.gigabyte.com/Motherboard/X299X-AORUS-MASTER-rev-1x">high-performance Gigabyte motherboard (X299X aorus master)</ext-link>, an NVIDIA GeForce RTX3070 GPU and a 12-core Intel i9-10920X processor. This computer also ran Windows Enterprise 10. The two computers communicated via a shared network disk, using a custom protocol based on text files that both computers could read and write.</p>
<p>A USB speaker (3 Watts output power, 20k Hz frequency response) was used for playing auditory feedback, and a gamepad controller (Logitech Gamepad F310) was used for registering trial-by-trial responses.</p>
</sec>
<sec id="s4d">
<title>Stimulus</title>
    <p>The visual scene (<xref ref-type="fig" rid="figS25">Fig. S25A</xref>) was constructed in <ext-link ext-link-type="uri" xlink:href="https://unity.com/releases/editor/whats-new/2022.3.24">Unity (v2022.3.24f1)</ext-link> and rendered using its standard shader. The scene consisted of three identical blobby 3D objects, each created in <ext-link ext-link-type="uri" xlink:href="https://unity.com/releases/editor/whats-new/2022.3.24">Blender (v4.0)</ext-link> with a matte, non-reflective surface. On each trial, the surface color of the blobby objects was varied by adjusting their RGB values in Unity. The three blobby objects (2.5 × 2.5 dva; 203,900 pixels each) were arranged in a triangular configuration (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). Each blobby object was centered and floating inside its own cubic room (3.3 × 3.3 dva; <italic>x</italic> = 0.302, <italic>y</italic> = 0.322, <italic>Y</italic> = 66.1 <italic>cd</italic>/<italic>m</italic><sup>2</sup>). Each room, along with the blobby stimulus inside it, was illuminated exclusively by an achromatic spotlight positioned in front of the object and set to maximum intensity (<italic>R</italic> = <italic>G</italic> = <italic>B</italic> = 1). The three rooms were presented against a spatially uniform gray background (18.0 × 10.2 dva; <italic>x</italic> = 0.306, <italic>y</italic> = 0.326, <italic>Y</italic> = 116.8 <italic>cd</italic>/<italic>m</italic><sup>2</sup>). The centers of the blobby objects were 3.7 dva apart.</p>
</sec>
<sec id="s4e">
<title>Calibration and color depth</title>
<p>We used a SpectraScan PR-670 to measure the monitor’s primaries and gamma function as rendered through Unity (Appendix 10.1). These measurements directly characterized the relationship between the specified RGB values for the blobby stimuli and the light emitted from the display. The same calibration was repeated for all three blobby stimuli, confirming consistent color behavior across screen locations. Based on these results, a single gamma correction—derived from the bottom-right stimulus—was applied to all three objects during the experiment. This correction was validated by remeasuring the output with gamma correction applied, showing good alignment with the predicted identity line. To confirm stability over time, we repeated the calibration one month into data collection and observed negligible changes.</p>
<p>Additionally, we used a Klein K-10A colorimeter to verify that the system achieved sufficient color depth. For this check, a single blobby stimulus was presented at the center of the screen, rather than in the full triangular arrangement. Measurements confirmed that Unity and our video chain were able to produce at least 10-bit color precision via its native 8-bit output and implicit spatial dithering that occurred across the surface of the blobby object through the rendering process (Appendix 10.2).</p>
</sec>
<sec id="s4f">
<title>Design</title>
<p>We restricted our stimuli to lie within the isoluminant plane that passes through the monitor’s gray point (i.e., the point where each RGB primary was set to half of its maximum value). To define the boundaries of this plane, we identified the limits of RGB values that remained within the monitor’s color gamut. These boundary points formed a parallelogram in RGB space. We then computed an affine transformation that maps this parallelogram onto a square bounded between −1 and 1 (Appendix 1). The forward and inverse transformations enabled conversion between RGB and model space: stimuli were rendered in RGB space, while trial placement and model fitting were performed in the model space.</p>
<p>We used <ext-link ext-link-type="uri" xlink:href="https://aepsych.org/">AEPsych (v0.7)</ext-link> to sample a total of 6,000 reference–comparison stimulus pairs. The first 900 trials were generated using Sobol’ sampling (<xref ref-type="bibr" rid="c88">Sobol, 1967</xref>), a “space-filling” design based on a low-discrepancy quasi-random sequence. The remaining 5,100 trials were adaptively selected to efficiently estimate thresholds across the entire psychometric field. Each stimulus pair was defined in the 2D model space. As a result, the psychometric field comprised four variables: two specifying the reference stimulus, <italic>x</italic><sub>0</sub> ∈ ℝ<sup>2</sup>, and the other two specifying a difference vector, Δ ∈ ℝ<sup>2</sup>, which was added to the reference to define the comparison stimulus <italic>x</italic><sub>1</sub> = <italic>x</italic><sub>0</sub> + Δ. Reference values were constrained between –0.75 and 0.75 along each model dimension. Each element of Δ was constrained between –0.25 and 0.25 to ensure that all comparison stimuli remained within the [−1, 1]<sup>2</sup> bounds of the model space. During the initial 900 Sobol’-sampled trials, the difference vector Δ was scaled by one of three factors (1/4, 2/4, or 3/4) before being added to the reference stimulus. This controlled the distance between the reference and comparison stimuli, effectively modulating task difficulty. These scaling factors were evenly distributed and pseudo-randomized across trials. For the remaining 5,100 trials, all four variables were adaptively selected using AEPsych’s optimization procedure. Specifically, the underlying GP model was updated every 20 trials, and new trials were selected using the Expected Absolute Volume Change (EAVC) acquisition function (<xref ref-type="bibr" rid="c60">Letham et al., 2022</xref>), targeting the 66.7% threshold level across the entire psychometric field.</p>
<p>In addition to the 6,000 AEPsych-driven trials, we interleaved an additional 6,000 validation trials sampled using MOCS. Each participant was tested on 25 reference stimuli: one was fixed at the achromatic point and the remaining 24 were Sobol’-sampled within the isoluminant plane bounded between –0.6 and 0.6 along each model dimension. For each reference, a chromatic direction was Sobol’-sampled between 0<sup>°</sup> and 360<sup>°</sup>. Each validation condition consisted of 12 stimulus levels: 11 equally spaced along the sampled direction and one easily discriminable level, with each level repeated 20 times. These levels were determined based on a pilot dataset described in the preregistration documents.</p>
<p>The validation trials were pre-generated for each participant, pseudo-randomized so that every 300 validation trials contained all the unique trials (25 conditions x 12 levels). To minimize differential learning effects between AEPsych-driven and validation trials, we pre-generated a randomized sequence in which the two trial types were arranged in alternating pairs, with the order within each pair shuffled. However, because AEPsych occasionally required longer time to determine the next trial placement, this sequence could not always be followed in real time. For this reason, we implemented a fallback trial strategy (Appendix 3): if for any trial AEPsych did not have trial-placement computed in time, the next validation trial was inserted to keep the experiment moving. If necessary, subsequent validation trials were queued, but this was capped to a lead of four validation trials ahead of AEPsych trials. Once the cap was reached and AEPsych was still not ready, pregenerated fallback trials were presented instead. These fallback trials were Sobol’-sampled with the difference vector Δ scaled by one of three factors (2/8, 3/8, or 4/8) to manipulate task difficulty. Validation trials resumed once AEPsych caught up. Notably, the fallback trials (range: 0-466) were included alongside the 6,000 AEPsych trials when fitting the WPPM.</p>
</sec>
<sec id="s4g">
<title>Procedure</title>
<p>Participants performed a 3AFC oddity task. Each trial began with a fixation cross presented at the center of the screen for 0.5 s, followed by a blank screen for 0.2 s. Then, three blobby stimuli appeared inside the cubic rooms for 1 s. After participants responded, a blank screen was shown for 0.2 s, followed by auditory and visual feedback indicating accuracy (“correct” with a beep or “incorrect” with a buzz). Each trial was separated by a 1.5 s inter-trial interval. Participants were instructed that they could move their eyes freely during the stimulus presentation, but should maintain fixation while the fixation cross was on the screen.</p>
<p>The majority of the participants (7 out of 8) completed a total of 12 sessions. Each session began with 40 practice trials to familiarize participants with the task. This was followed by 1,000 experimental trials, consisting of 500 trials determined by AEPsych, 500 predetermined validation trials and a small amount of fallback trials. The validation trials were randomized and the two trial types were fully intermixed. Participants took a break every 200 trials. Each session took approximately 1.5 hours to complete. In total, those seven participants completed between 12,256 and 12,466 trials, depending on the number of fallback trials inserted. Participant CH completed 12,000 trials across 10 sessions, without fallback trials implemented. As a result, the inter-trial interval was slightly longer for this participant, but we expected this to have a negligible effect on performance.</p>
</sec>
<sec id="s4h">
<title>The Wishart Process Psychometric Model</title>
<p>Our implementation of the WPPM relies on two core assumptions about color perception: (1) internal noise that limits color discrimination follows a multivariate Gaussian distribution centered at the reference stimulus, with a covariance matrix that captures both the magnitude and directional structure (i.e., size and orientation) of the noise, and (2) the covariance matrix varies smoothly across the model space, without abrupt local discontinuities. In the following subsections, we describe the WPPM in five parts. First, we define the observer model, which predicts discrimination performance—quantified as the percent-correct responses—for a given pair of reference and comparison stimuli by modeling both the internal representation of the stimuli and the decision rule. Second, we describe how we use a finite-basis Wishart process to parameterize the entire field of covariance matrices across the model space, and what governs its smoothness. Third, we describe the weak prior imposed on the covariance matrix field to favor smooth variation. Fourth, we explain how, given any specification of the covariance matrix field, we compute the likelihood and thereby the posterior probability of the model and its free parameters given binary (correct or incorrect) color-discrimination responses. Finally, we show how, once the model is fit, the covariance matrix for any reference-comparison stimulus pair can be read out and combined with the observer model to predict percent-correct performance, including threshold contours around any reference stimulus.</p>
<sec id="s4h1">
<title>Observer model</title>
<p>On each trial, the observer is presented with two identical reference stimuli, denoted <italic>x</italic><sub>0</sub>, and one comparison stimulus, denoted <italic>x</italic><sub>1</sub> = <italic>x</italic><sub>0</sub> + Δ where Δ represents a small offset from the reference. Our model assumes that these three stimuli are independently encoded into an internal representational space by a noisy process, which we assume to follow a multivariate Gaussian distribution. Formally,
<disp-formula id="eqn1">
<graphic xlink:href="665219v2_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="665219v2_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn3">
<graphic xlink:href="665219v2_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula id="inline-eqn-5"><inline-graphic xlink:href="665219v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> denote the internal representations derived from the two reference and the comparison stimuli, respectively. Our model posits that the observer correctly identifies <italic>z</italic><sub>1</sub> as representing the comparison stimulus (i.e. the “odd-one-out”) if
<disp-formula id="eqn4">
<graphic xlink:href="665219v2_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula id="inline-eqn-6"><inline-graphic xlink:href="665219v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> denotes the squared Mahalanobis distance for a selected pair of internal representations, formulated as
<disp-formula id="eqn5">
<graphic xlink:href="665219v2_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn6">
<graphic xlink:href="665219v2_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn7">
<graphic xlink:href="665219v2_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>S</bold> is the weighted average of the covariance across the reference and the comparison stimuli, that is,
<disp-formula id="eqn8">
<graphic xlink:href="665219v2_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This decision rule is consistent with an observer that uses distances between internal representations to judge stimulus similarity (<xref ref-type="bibr" rid="c22">Churchland, 1986</xref>). We approximated the percent-correct performance using (N=2,000) Monte Carlo simulations (<xref rid="fig1" ref-type="fig">Figure 1E</xref>) as the closed-form analytical solution is complicated to derive (<xref ref-type="bibr" rid="c33">Ennis and Mullen, 2014</xref>). In each Monte Carlo simulation, we draw samples according to <xref ref-type="disp-formula" rid="eqn1">Equation 1</xref> - <xref ref-type="disp-formula" rid="eqn3">Equation 3</xref> and the outcome is marked as correct if the condition in <xref ref-type="disp-formula" rid="eqn4">Equation 4</xref> is fulfilled. The proportion of correct outcomes in the Monte Carlo simulation defines the model’s predicted percent-correct performance, which is then used to evaluate the likelihood function as explained in Model fitting.</p>
</sec>
<sec id="s4h2">
<title>Covariance matrix field</title>
<p>The WPPM specifies a covariance matrix at any selected reference stimulus across the entire isoluminant plane. Each matrix specifies the perceptual noise in terms of the variance along the two model dimensions <inline-formula id="inline-eqn-7"><inline-graphic xlink:href="665219v2_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and their covariance (<italic>σ</italic><sub>dim1,dim2</sub>) (<xref rid="fig1" ref-type="fig">Figure 1C-D</xref>).</p>
<p>The covariance matrix field is constructed using one-dimensional Chebyshev polynomial basis functions (<xref ref-type="bibr" rid="c20">Chebyshev, 1853</xref>). We chose Chebyshev polynomials because they allow for the expression of smoothness over a bounded interval without imposing periodic boundary conditions. Let <italic>x</italic> = [<italic>x</italic><sub>dim1</sub>, <italic>x</italic><sub>dim2</sub>] denote a location in the 2D model space. The basis functions are defined recursively for each model space dimension as given here for <italic>x</italic><sub>dim1</sub>:
<disp-formula id="eqn9">
<graphic xlink:href="665219v2_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn10">
<graphic xlink:href="665219v2_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn11">
<graphic xlink:href="665219v2_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>x</italic><sub>dim1</sub>, <italic>T</italic><sub><italic>i</italic></sub>(<italic>x</italic><sub>dim1</sub>) ∈ ℝ<sup><italic>n</italic></sup>, and <italic>n</italic> is the number of discretized points along that stimulus dimension, which can be chosen flexibly to achieve any desired resolution. We construct two-dimensional basis functions by taking the outer product:
<disp-formula id="eqn12">
<graphic xlink:href="665219v2_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>ϕ</italic><sub><italic>i,j</italic></sub> ∈ ℝ<sup><italic>n</italic>×<italic>m</italic></sup>, with <italic>n</italic> = <italic>m</italic> representing the number of discretized points along each dimension of the model space. We limited the number of basis functions to five per dimension, i.e., <italic>i, j</italic> ∈ {0, 1, …, 4}, resulting in a total of 5 × 5 = 25 2D basis functions (<xref rid="fig4" ref-type="fig">Figure 4</xref>, first panel). The polynomial order of each 2D basis function is given by <italic>i</italic> + <italic>j</italic>, with higher-order basis functions describing more rapidly varying patterns.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
    <caption><title>The finite-basis Wishart Process Psychophysical Model (WPPM).</title>
        <p>In our implementation, we used a set of 5 × 5 two-dimensional Chebyshev polynomial basis functions, denoted <italic>ϕ</italic><sub><italic>i,j</italic></sub> (<italic>x</italic>), where <italic>i, j</italic> ∈ {0, 1, …, 4}. These basis functions were linearly combined using a learnable weight matrix <bold>W</bold> to produce an overcomplete representation <bold>U</bold><sub><italic>k,l</italic></sub>(<italic>x</italic>), where <italic>k</italic> ∈ 1, 2 and <italic>l</italic> ∈ 1, 2, 3. The resulting representation <bold>U</bold><sub><italic>k,l</italic></sub> was then combined with its own transpose to produce a field of symmetric, positive semi-definite covariance matrices. Each matrix specifies the internal noise in terms of the variance along the two model dimensions <inline-formula id="inline-eqn-8"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="665219v2_inline13.gif"/></inline-formula> and their covariance (<italic>σ</italic><sub>dim1,dim2</sub>). For this example covariance matrix field, the weights used to generate the field were samples from the Wishart process prior with <italic>ϵ</italic> = 0.5.</p></caption>
<graphic xlink:href="665219v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The basis functions were weighted by a learnable parameter matrix, <bold>W</bold> ∈ ℝ<sup>5×5×2×3</sup>, where the first two dimensions index the Chebyshev basis functions along each model space dimension (<italic>i, j</italic> ∈ {0, 1, …, 4}), and the last two dimensions index the output components (<italic>k</italic> ∈ {1, 2} and <italic>l</italic> = {1, 2, 3}). The weighted basis functions are expanded into an overcomplete representation <bold>U</bold><sub><italic>k,l</italic></sub> ∈ ℝ<sup><italic>n</italic>×<italic>m</italic></sup> (<xref rid="fig4" ref-type="fig">Figure 4</xref>, second panel) as the following,
<disp-formula id="eqn13">
<graphic xlink:href="665219v2_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This weighted sum overcomplete representation was then combined with its own transpose to yield a positive semi-definite covariance matrix, Σ(<italic>x</italic>) ∈ ℝ<sup>2×2</sup> for <italic>x</italic> at any discretized point in the model space, that is,
<disp-formula id="eqn14">
<graphic xlink:href="665219v2_eqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
    This process ensures that the resulting covariance matrices are symmetric and positive semi-definite (<xref rid="fig4" ref-type="fig">Figure 4</xref>, third panel). The weight matrix serves as the free parameters of the model, controlling the smoothness of the covariance matrix field. The model is highly flexible, capable of generating a wide range of covariance matrix fields, from smooth to rapidly varying fields (<xref rid="fig1" ref-type="fig">Figure 1C-D</xref>).</p>
</sec>
<sec id="s4h3">
<title>Prior over the weight matrix</title>
<p>We imposed a weak prior over the weight matrix <bold>W</bold>. Specifically, we assumed that each weight was distributed <italic>a priori</italic> as a zero-mean one-dimensional Gaussian,
<disp-formula id="eqn15">
<graphic xlink:href="665219v2_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>η</italic> represents the variance of each weight and it decays exponentially with <italic>i</italic>+<italic>j</italic>, which denotes the polynomial order of the corresponding 2D basis function, that is,
<disp-formula id="eqn16">
<graphic xlink:href="665219v2_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The scalar <italic>γ</italic> controls the overall amplitude of the variance and was fixed at 3 × 10<sup>−4</sup>. The scalar <italic>ϵ</italic> controls the rate at which the prior variance decays with increasing polynomial order, and was fixed at 0.5. A higher value of <italic>ϵ</italic> results in a prior that favors more sharply varying covariance matrix fields, while a lower value favors smoother fields. By setting <italic>ϵ</italic> = 0.5, we adopted a prior that favors relatively smooth variation across the space (<xref rid="fig4" ref-type="fig">Figure 4</xref>, fourth panel). This value was chosen by hand based on examination of a pilot dataset and analysis of the data reported here for participant CH, available at a <ext-link ext-link-type="uri" xlink:href="https://github.com/BrainardLab/preregistrations/blob/main/ColorEllipsoids/2025-04-21-ELPS_3_PreRegistration.pdf">public repository</ext-link>. As preregistered, this decision was made before analyzing the validation trials from the remaining seven participants.</p>
</sec>
<sec id="s4h4">
<title>Model fitting</title>
<p>We computed the negative log-likelihood of any hypothesized weight matrix given the participant’s binary responses <italic>y</italic><sub><italic>r</italic></sub> as follows:
<disp-formula id="eqn17">
<graphic xlink:href="665219v2_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>y</italic><sub><italic>r</italic></sub> ∈ {0, 1} indicates whether the response on trial <italic>r</italic> was correct (1) or incorrect (0), <italic>R</italic> is the total number of trials used to fit the WPPM. The model-predicted accuracy <italic>p</italic><sub><italic>r</italic></sub> for each trial is given by:
<disp-formula id="eqn18">
<graphic xlink:href="665219v2_eqn18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Note that on the <italic>r</italic><sup>th</sup> trial, <inline-formula id="inline-eqn-9"><inline-graphic xlink:href="665219v2_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <italic>z</italic><sub>1</sub> are internal representations that depend on the reference and comparison stimuli (<italic>x</italic><sub>0</sub> and <italic>x</italic><sub>1</sub>) for that trial. For notational simplicity, the subscript <italic>r</italic> is omitted here.</p>
<p>Since we imposed a prior on the covariance matrix field to reflect the expectation of smooth variation, we combined the likelihood (<xref ref-type="disp-formula" rid="eqn17">Equation 17</xref>) and the prior (<xref ref-type="disp-formula" rid="eqn16">Equation 16</xref>) to calculate the posterior probability of <bold>W</bold>. As there is no simple closed form expression for <italic>p</italic><sub><italic>r</italic></sub>, we resorted to a numerical approximation based on Monte Carlo simulations. The numerical approximation we built was differentiable with respect to the covariance matrix field, which enabled us to use gradient descent to maximize the posterior probability of <bold>W</bold> (see details in Appendix 11).</p>
</sec>
<sec id="s4h5">
<title>Psychometric field</title>
<p>For any given reference stimulus, the WPPM allows readouts of percent-correct performance along any chromatic direction, which in turn allows us to construct a threshold contour. We sampled comparison stimuli along 16 chromatic directions and simulated internal representations to estimate percent-correct performance, yielding a psychometric function for each direction (<xref rid="fig1" ref-type="fig">Figure 1F</xref>). The threshold distance in each direction was defined as the comparison stimulus corresponding to 66.7% correct. Collectively, these threshold distances form a contour that closely resembles an ellipse, with only minor deviations due to inhomogeneous internal noise between the reference and comparison stimuli. However, because the stimuli are locally proximal in the model space, such discrepancies are negligible. We therefore fit an ellipse to these points as a practical approximation. As a way of visualizing the psychometric field, we plot these ellipses—each corresponding to 66.7% threshold level—at a grid of reference locations. We emphasize, however, that the WPPM provides the full four-dimensional psychometric field, enabling readouts of the psychometric function along any chromatic direction for any reference stimulus within the model space.</p>
</sec>
</sec>
    <sec id="s5">
        <title>Data analysis</title>
        <p>Color calibration analyses were performed using MATLAB 2023b. We computed inverse gamma lookup tables from the measured gamma functions and derived transformation matrices to convert values from the model space to RGB space (Appendix 10). Stimulus presentation, including gamma correction, was implemented in Unity using C#.</p>
        <p>The experiment and model fitting were conducted in Python 3.11 and JAX (<xref ref-type="bibr" rid="c7">Bradbury et al., 2018</xref>). Behavioral data were separated into AEPsych-driven plus fallback trials on the one hand and validation trials on the other. The WPPM was fit exclusively to the AEPsych and fallback trials. To assess variability in model estimates, we performed 10 bootstrap resamplings of the AEPsych-driven trials, preserving the original ratio between Sobol’, adaptively sampled, and fallback trials in each resampled dataset. The WPPM was then re-fit to each of the 10 bootstrapped datasets.</p>
        <p>For the held-out validation trials, we computed the Euclidean distance between each reference and its paired comparison stimulus. For each of the 25 conditions, a Weibull psychometric function was fit to the binary color discrimination responses, with the guess rate fixed at 33.3% correct. Thresholds were defined as the comparison stimulus corresponding to 66.7% correct. To estimate variability, we bootstrapped each condition 120 times and computed 95% confidence intervals for the threshold estimates.</p>
        <p>To assess the validity of the WPPM estimates, we performed linear regression (constrained to pass through the origin) between the thresholds estimated from the WPPM fits and those from the validation trials. This comparison was repeated across all 120 bootstrapped validation datasets. Notably, since only 10 Wishart bootstrapped fits were available, we replicated each one 12 times and shuffled to align with the number of validation bootstraps, rather than generating 120 separate WPPM fits, which would have been computationally expensive. This allowed us to approximate the confidence intervals for the regression slope and correlation coefficient.</p>
    </sec>
</sec>

</body>
<back>
    <sec id="s5a" sec-type="data-availability">
        <title>Data and code availability</title>
        <p>Data and code will be made publicly available upon acceptance for publication. All experiments, data collection, processing activities, and open sourcing were conducted at the University of Pennsylvania.</p>
    </sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Nicolas P. Cottaris for his assistance with the calibration, our colleagues at the UPenn Vision Labs, and Larry Maloney from NYU for their valuable feedback.</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6">
<title>Author contribution</title>
<p>F.H.: Conceptualization; Formal analysis; Investigation; Methodology; Software; Validation; Visualization; Writing – original draft; Writing – review &amp; editing.</p>
<p>R.B.: Investigation; Project administration.</p>
<p>J.C.: Methodology; Software; Writing – review &amp; editing. C.S.: Methodology; Software.</p>
<p>M.S.: Methodology; Software; Writing – review &amp; editing.</p>
<p>P.G.: Conceptualization; Methodology; Resources; Software; Supervision; Validation; Writing – review &amp; editing.</p>
<p>A.H.W.: Conceptualization; Methodology; Resources; Software; Supervision; Validation; Writing – original draft; Writing – review &amp; editing.</p>
<p>D.H.B.: Conceptualization; Funding acquisition; Methodology; Project administration; Resources; Software; Supervision; Validation; Writing – original draft; Writing – review &amp; editing.</p>
</sec>
</sec>
<sec id="additional-files" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="supp1">
<label>Separate supplement</label>
<media xlink:href="supplements/665219_file02.pdf"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aguilar</surname> <given-names>G</given-names></string-name>, <string-name><surname>Wichmann</surname> <given-names>FA</given-names></string-name>, <string-name><surname>Maertens</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Comparing sensitivity estimates from MLDS and forced-choice methods in a slant-from-texture experiment</article-title>. <source>Journal of Vision</source>. <year>2017</year>; <volume>17</volume>(<issue>1</issue>):<fpage>37</fpage>–<lpage>37</lpage>.</mixed-citation></ref>
    <ref id="c2"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ashby</surname> <given-names>FG</given-names></string-name>, <string-name><surname>Soto</surname> <given-names>FA</given-names></string-name></person-group>. <chapter-title>Multidimensional signal detection theory</chapter-title>. <source>Oxford handbook of computational and mathematical psychology</source>. <person-group person-group-type="editor"><string-name><surname>Busemeyer</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Townsend</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Eidels</surname> <given-names>A</given-names></string-name></person-group> <year>2015</year>; p. <fpage>13</fpage>–<lpage>34</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aspinall</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Kinnear</surname> <given-names>PR</given-names></string-name>, <string-name><surname>Duncan</surname> <given-names>LJ</given-names></string-name>, <string-name><surname>Clarke</surname> <given-names>BF</given-names></string-name></person-group>. <article-title>Prediction of diabetic retinopathy from clinical variables and color vision data</article-title>. <source>Diabetes Care</source>. <year>1983</year>; <volume>6</volume>(<issue>2</issue>):<fpage>144</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="pmid">6851807</pub-id>, doi: <pub-id pub-id-type="doi">10.2337/diacare.6.2.144</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bertonati</surname> <given-names>G</given-names></string-name>, <string-name><surname>Amadeo</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Campus</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gori</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Auditory speed processing in sighted and blind individuals</article-title>. <source>Plos one</source>. <year>2021</year>; <volume>16</volume>(<issue>9</issue>):<fpage>e0257676</fpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bhatia</surname> <given-names>R</given-names></string-name>, <string-name><surname>Jain</surname> <given-names>T</given-names></string-name>, <string-name><surname>Lim</surname> <given-names>Y.</given-names></string-name></person-group> <article-title>On the Bures–Wasserstein distance between positive definite matrices</article-title>. <source>Expositiones Mathematicae</source>. <year>2019</year>; <volume>37</volume>(<issue>2</issue>):<fpage>165</fpage>–<lpage>191</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bosten</surname> <given-names>JM</given-names></string-name></person-group>. <article-title>Do you see what I see? Diversity in human color perception</article-title>. <source>Annual review of vision science</source>. <year>2022</year>; <volume>8</volume>(<issue>1</issue>):<fpage>101</fpage>–<lpage>133</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Bradbury</surname> <given-names>J</given-names></string-name>, <string-name><surname>Frostig</surname> <given-names>R</given-names></string-name>, <string-name><surname>Hawkins</surname> <given-names>P</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Leary</surname> <given-names>C</given-names></string-name>, <string-name><surname>Maclaurin</surname> <given-names>D</given-names></string-name>, <string-name><surname>Necula</surname> <given-names>G</given-names></string-name>, <string-name><surname>Paszke</surname> <given-names>A</given-names></string-name>, <string-name><surname>VanderPlas</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wanderman-Milne</surname> <given-names>S</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Q</given-names></string-name></person-group>, <article-title>JAX: composable transformations of Python+NumPy programs</article-title> <source>Github</source>; <year>2018</year>. <ext-link ext-link-type="uri" xlink:href="http://github.com/jax-ml/jax">http://github.com/jax-ml/jax</ext-link>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Brainard</surname> <given-names>DH</given-names></string-name></person-group>. <chapter-title>Color Appearance and Color Difference Specification</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Shevell</surname> <given-names>SK</given-names></string-name></person-group>, editor. <source>The Science of Color</source>, 2nd ed. <publisher-name>Elsevier</publisher-name>; <year>2003</year>.p. <fpage>191</fpage>–<lpage>216</lpage>. doi: <pub-id pub-id-type="doi">10.1016/B978-044451251-2/50006-4</pub-id>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brainard</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Pelli</surname> <given-names>DG</given-names></string-name>, <string-name><surname>Robson</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Display characterization</article-title>. <source>Signal Process</source>. <year>2002</year>; <volume>80</volume>:<fpage>2</fpage>–<lpage>067</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brainard</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Roorda</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yamauchi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Calderone</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Metha</surname> <given-names>A</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Jacobs</surname> <given-names>GH</given-names></string-name></person-group>. <article-title>Functional consequences of the relative numbers of L and M cones</article-title>. <source>Journal of the Optical Society of America A</source>. <year>2000</year>; <volume>17</volume>(<issue>3</issue>):<fpage>607</fpage>–<lpage>614</lpage>.</mixed-citation></ref>
    <ref id="c11"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Brainard</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Stockman</surname> <given-names>A.</given-names></string-name></person-group> <chapter-title>Colorimetry</chapter-title> <source>Handbook of Optics: Volume III - Vision and Vision Optics</source>. <publisher-name>McGraw Hill</publisher-name>; <year>2010</year>.</mixed-citation></ref>
    <ref id="c12"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Brainard</surname> <given-names>D.</given-names></string-name></person-group> <chapter-title>Cone contrast and opponent modulation color spaces</chapter-title>. <source>Human color vision</source> <person-group person-group-type="editor"><string-name><surname>Kaiser</surname> <given-names>PK</given-names></string-name>, <string-name><surname>Boynton</surname> <given-names>RM</given-names></string-name></person-group>. <year>1996</year>;.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brown</surname> <given-names>WRJ</given-names></string-name>, <string-name><surname>MacAdam</surname> <given-names>DL</given-names></string-name></person-group>. <article-title>Visual sensitivities to combined chromaticity and luminance differences</article-title>. <source>Journal of the Optical Society of America</source>. <year>1949</year>; <volume>39</volume>(<issue>10</issue>):<fpage>808</fpage>–<lpage>834</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brown</surname> <given-names>W.</given-names></string-name></person-group> <article-title>The effect of field size and chromatic surroundings on color discrimination</article-title>. <source>Journal of the Optical Society of America</source>. <year>1952</year>; <volume>42</volume>(<issue>11</issue>):<fpage>837</fpage>–<lpage>844</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bujack</surname> <given-names>R</given-names></string-name>, <string-name><surname>Teti</surname> <given-names>E</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>J</given-names></string-name>, <string-name><surname>Caffrey</surname> <given-names>E</given-names></string-name>, <string-name><surname>Turton</surname> <given-names>TL</given-names></string-name></person-group>. <article-title>The non-Riemannian nature of perceptual color space</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2022</year>; <volume>119</volume>(<issue>18</issue>):<fpage>e2119753119</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Campbell</surname> <given-names>FW</given-names></string-name>, <string-name><surname>Robson</surname> <given-names>JG</given-names></string-name></person-group>. <article-title>Application of Fourier analysis to the visibility of gratings</article-title>. <source>The Journal of physiology</source>. <year>1968</year>; <volume>197</volume>(<issue>3</issue>):<fpage>551</fpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carlile</surname> <given-names>S</given-names></string-name>, <string-name><surname>Leung</surname> <given-names>J.</given-names></string-name></person-group> <article-title>The perception of auditory motion</article-title>. <source>Trends in hearing</source>. <year>2016</year>; <volume>20</volume>:<fpage>2331216516644254</fpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carroll</surname> <given-names>J</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Estimates of L: M cone ratio from ERG flicker photometry and genetics</article-title>. <source>Journal of vision</source>. <year>2002</year>; <volume>2</volume>(<issue>8</issue>):<fpage>1</fpage>–<lpage>1</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Champion</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Freeman</surname> <given-names>TC</given-names></string-name></person-group>. <article-title>Discrimination contours for the perception of head-centered velocity</article-title>. <source>Journal of Vision</source>. <year>2010</year>; <volume>10</volume>(<issue>6</issue>):<fpage>14</fpage>–<lpage>14</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chebyshev</surname> <given-names>PL</given-names></string-name></person-group>. <article-title>Théorie des mécanismes connus sous le nom de parallélogrammes</article-title>. <source>Imprimerie de l’Académie impériale des sciences</source>; <year>1853</year>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Foley</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>DH</given-names></string-name></person-group>. <article-title>Detection of chromoluminance patterns on chromoluminance pedestals II: model</article-title>. <source>Vision Research</source>. <year>2000</year>; <volume>40</volume>(<issue>7</issue>):<fpage>789</fpage>–<lpage>803</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Churchland</surname> <given-names>PM</given-names></string-name></person-group>. <article-title>Some reductive strategies in cognitive neurobiology</article-title>. <source>Mind</source>. <year>1986</year>; <volume>95</volume>(<issue>379</issue>):<fpage>279</fpage>–<lpage>309</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cicchini</surname> <given-names>GM</given-names></string-name>, <string-name><surname>Anobile</surname> <given-names>G</given-names></string-name>, <string-name><surname>Burr</surname> <given-names>DC</given-names></string-name></person-group>. <article-title>Spontaneous perception of numerosity in humans</article-title>. <source>Nature communications</source>. <year>2016</year>; <volume>7</volume>(<issue>1</issue>):<fpage>12536</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cicchini</surname> <given-names>GM</given-names></string-name>, <string-name><surname>Anobile</surname> <given-names>G</given-names></string-name>, <string-name><surname>Burr</surname> <given-names>DC</given-names></string-name></person-group>. <article-title>Spontaneous representation of numerosity in typical and dyscalculic development</article-title>. <source>Cortex</source>. <year>2019</year>; <volume>114</volume>:<fpage>151</fpage>–<lpage>163</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cicchini</surname> <given-names>GM</given-names></string-name>, <string-name><surname>Anobile</surname> <given-names>G</given-names></string-name>, <string-name><surname>Burr</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Marchesini</surname> <given-names>P</given-names></string-name>, <string-name><surname>Arrighi</surname> <given-names>R.</given-names></string-name></person-group> <article-title>The role of non-numerical information in the perception of temporal numerosity</article-title>. <source>Frontiers in Psychology</source>. <year>2023</year>; <volume>14</volume>:<fpage>1197064</fpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="book"><person-group person-group-type="author"><collab>Colorimetry C</collab></person-group>, <source>Commission Internationale de l’Èclairage</source>: <publisher-loc>Vienna. Austria</publisher-loc>; <year>2004</year>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Craik</surname> <given-names>K.</given-names></string-name></person-group> <article-title>The effect of adaptation on differential brightness discrimination</article-title>. <source>The Journal of Physiology</source>. <year>1938</year>; <volume>92</volume>(<issue>4</issue>):<fpage>406</fpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crozier</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Holway</surname> <given-names>AH</given-names></string-name></person-group>. <article-title>On the law for minimal discrimination of intensities: I</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1937</year>; <volume>23</volume>(<issue>1</issue>):<fpage>23</fpage>–<lpage>28</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Danilova</surname> <given-names>M</given-names></string-name>, <string-name><surname>Mollon</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Effect of stimulus size on chromatic discrimination</article-title>. <source>Journal of the Optical Society of America A</source>. <year>2025</year>; <volume>42</volume>(<issue>5</issue>):<fpage>B167</fpage>–<lpage>B177</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Derrington</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Krauskopf</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lennie</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Chromatic mechanisms in lateral geniculate nucleus of macaque</article-title>. <source>The Journal of physiology</source>. <year>1984</year>; <volume>357</volume>(<issue>1</issue>):<fpage>241</fpage>–<lpage>265</lpage>.</mixed-citation></ref>
    <ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dvoretzky</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kiefer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wolfowitz</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator</article-title>. <source>The Annals of Mathematical Statistics</source>. <year>1956</year>; p. <fpage>642</fpage>–<lpage>669</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emery</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Volbrecht</surname> <given-names>VJ</given-names></string-name>, <string-name><surname>Peterzell</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Webster</surname> <given-names>MA</given-names></string-name></person-group>. <article-title>Fundamentally different representations of color and motion revealed by individual differences in perceptual scaling</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2023</year>; <volume>120</volume>(<issue>4</issue>):<fpage>e2202262120</fpage>.</mixed-citation></ref>
    <ref id="c33"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ennis</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Mullen</surname> <given-names>K.</given-names></string-name></person-group> <chapter-title>A general probabilistic model for triad discrimination, preferential choice, and two-alternative identification</chapter-title>. <source>Multidimensional models of perception and cognition</source> <person-group person-group-type="editor"><string-name><surname>Ashby</surname><given-names>FG</given-names></string-name></person-group> <publisher-name>Psychology Press</publisher-name>; <year>2014</year>.p. <fpage>115</fpage>–<lpage>122</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ennis</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Zaidi</surname> <given-names>Q.</given-names></string-name></person-group> <article-title>Geometrical structure of perceptual color space: Mental representations and adaptation invariance</article-title>. <source>Journal of vision</source>. <year>2019</year>; <volume>19</volume>(<issue>12</issue>):<fpage>1</fpage>–<lpage>1</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eskew Jr</surname> <given-names>RT</given-names></string-name></person-group>. <article-title>Higher order color mechanisms: A critical review</article-title>. <source>Vision research</source>. <year>2009</year>; <volume>49</volume>(<issue>22</issue>):<fpage>2686</fpage>–<lpage>2704</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Fechner</surname> <given-names>GT</given-names></string-name></person-group>. <source>Elemente der psychophysik</source>, vol. <volume>2</volume>. <publisher-name>Breitkopf u. Härtel</publisher-name>; <year>1860</year>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foley</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Legge</surname> <given-names>GE</given-names></string-name></person-group>. <article-title>Contrast detection and near-threshold discrimination in human vision</article-title>. <source>Vision research</source>. <year>1981</year>; <volume>21</volume>(<issue>7</issue>):<fpage>1041</fpage>–<lpage>1053</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freeman</surname> <given-names>TC</given-names></string-name>, <string-name><surname>Leung</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wufong</surname> <given-names>E</given-names></string-name>, <string-name><surname>Orchard-Mills</surname> <given-names>E</given-names></string-name>, <string-name><surname>Carlile</surname> <given-names>S</given-names></string-name>, <string-name><surname>Alais</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Discrimination contours for moving sounds reveal duration and distance cues dominate auditory speed perception</article-title>. <source>PloS one</source>. <year>2014</year>; <volume>9</volume>(<issue>7</issue>):<fpage>e102864</fpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garside</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Selwyn</surname> <given-names>HM</given-names></string-name>, <string-name><surname>Conway</surname> <given-names>BR</given-names></string-name></person-group>. <article-title>The origin of color categories</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2025</year>; <volume>122</volume>(<issue>1</issue>):<fpage>e2400273121</fpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gegenfurtner</surname> <given-names>KR</given-names></string-name></person-group>. <article-title>The Verriest Lecture: Color vision from pixels to objects</article-title>. <source>Journal of the Optical Society of America A</source>. <year>2025</year>; <volume>42</volume>(<issue>5</issue>):<fpage>B313</fpage>–<lpage>B328</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Girshick</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Landy</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Simoncelli</surname> <given-names>EP</given-names></string-name></person-group>. <article-title>Cardinal rules: visual orientation perception reflects knowledge of environmental statistics</article-title>. <source>Nature neuroscience</source>. <year>2011</year>; <volume>14</volume>(<issue>7</issue>):<fpage>926</fpage>–<lpage>932</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Green</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Swets</surname> <given-names>JA</given-names></string-name>, <etal>et al.</etal></person-group> <source>Signal detection theory and psychophysics</source>, vol. <volume>1</volume>. <publisher-name>Wiley</publisher-name> <publisher-loc>New York</publisher-loc>; <year>1966</year>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hansen</surname> <given-names>T</given-names></string-name>, <string-name><surname>Gegenfurtner</surname> <given-names>KR</given-names></string-name></person-group>. <article-title>Higher order color mechanisms: Evidence from noise-masking experiments in cone contrast space</article-title>. <source>Journal of vision</source>. <year>2013</year>; <volume>13</volume>(<issue>1</issue>):<fpage>26</fpage>–<lpage>26</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hautus</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Macmillan</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Creelman</surname> <given-names>CD</given-names></string-name></person-group>. <source>Detection theory: A user’s guide</source>. <publisher-loc>Routledge</publisher-loc>; <year>2021</year>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hecht</surname> <given-names>S</given-names></string-name>, <string-name><surname>Shlaer</surname> <given-names>S</given-names></string-name>, <string-name><surname>Pirenne</surname> <given-names>MH</given-names></string-name></person-group>. <article-title>Energy, quanta, and vision</article-title>. <source>Journal of General Physiology</source>. <year>1942</year>; <volume>25</volume>(<issue>6</issue>):<fpage>819</fpage>–<lpage>840</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hedjar</surname> <given-names>L</given-names></string-name>, <string-name><surname>Toscani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gegenfurtner</surname> <given-names>KR</given-names></string-name></person-group>. <article-title>Importance of hue: color discrimination of three-dimensional objects and two-dimensional discs</article-title>. <source>Journal of the Optical Society of America A</source>. <year>2025</year>; <volume>42</volume>(<issue>5</issue>):<fpage>B296</fpage>–<lpage>B304</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hillis</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>DH</given-names></string-name></person-group>. <article-title>Distinct mechanisms mediate visual detection and identification</article-title>. <source>Current Biology</source>. <year>2007</year>; <volume>17</volume>(<issue>19</issue>):<fpage>1714</fpage>–<lpage>1719</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hofer</surname> <given-names>H</given-names></string-name>, <string-name><surname>Carroll</surname> <given-names>J</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>DR</given-names></string-name></person-group>. <article-title>Organization of the human trichromatic cone mosaic</article-title>. <source>Journal of Neuroscience</source>. <year>2005</year>; <volume>25</volume>(<issue>42</issue>):<fpage>9669</fpage>–<lpage>9679</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname> <given-names>F</given-names></string-name>, <string-name><surname>Badde</surname> <given-names>S</given-names></string-name>, <string-name><surname>Landy</surname> <given-names>MS</given-names></string-name></person-group>. <article-title>Causal inference regulates audiovisual spatial recalibration via its influence on audiovisual perception</article-title>. <source>PLOS Computational Biology</source>. <year>2021</year> 11; <volume>17</volume>(<issue>11</issue>):<fpage>1</fpage>–<lpage>37</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008877</pub-id>, doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008877</pub-id>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Horiuchi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nagai</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Color discrimination repetition distorts color representations</article-title>. <source>Scientific Reports</source>. <year>2024</year>; <volume>14</volume>(<issue>1</issue>):<fpage>9615</fpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hurvich</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Hurvich-Jameson</surname> <given-names>D.</given-names></string-name></person-group> <source>Opponent chromatic induction and wavelength discrimination</source>. <publisher-name>Springer</publisher-name>; <year>1961</year>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Wall</surname> <given-names>M</given-names></string-name>, <string-name><surname>Thompson</surname> <given-names>HS</given-names></string-name></person-group>. <article-title>A history of perimetry and visual field testing</article-title>. <source>Optometry and Vision Science</source>. <year>2011</year>; <volume>88</volume>(<issue>1</issue>):<fpage>E8</fpage>–<lpage>E15</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knoblauch</surname> <given-names>K</given-names></string-name>, <string-name><surname>Maloney</surname> <given-names>LT</given-names></string-name></person-group>. <article-title>Testing the indeterminacy of linear color mechanisms from color discrimination data</article-title>. <source>Vision research</source>. <year>1996</year>; <volume>36</volume>(<issue>2</issue>):<fpage>295</fpage>–<lpage>306</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Knoblauch</surname> <given-names>K</given-names></string-name>, <string-name><surname>Maloney</surname> <given-names>LT</given-names></string-name></person-group>. <source>Modeling psychophysical data in R</source>, vol. <volume>32</volume>. <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2012</year>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Koenderink</surname> <given-names>JJ</given-names></string-name></person-group>. <source>Color for the Sciences</source>. <publisher-name>MIT press</publisher-name>; <year>2010</year>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krauskopf</surname> <given-names>J</given-names></string-name>, <string-name><surname>Karl</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Color discrimination and adaptation</article-title>. <source>Vision research</source>. <year>1992</year>; <volume>32</volume>(<issue>11</issue>):<fpage>2165</fpage>–<lpage>2175</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kremers</surname> <given-names>J</given-names></string-name>, <string-name><surname>Scholl</surname> <given-names>HP</given-names></string-name>, <string-name><surname>Knau</surname> <given-names>H</given-names></string-name>, <string-name><surname>Berendschot</surname> <given-names>TT</given-names></string-name>, <string-name><surname>Usui</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sharpe</surname> <given-names>LT</given-names></string-name></person-group>. <article-title>L/M cone ratios in human trichromats assessed by psychophysics, electroretinography, and retinal densitometry</article-title>. <source>Journal of the Optical Society of America A</source>. <year>2000</year>; <volume>17</volume>(<issue>3</issue>):<fpage>517</fpage>–<lpage>526</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Lange Dzn</surname> <given-names>H.</given-names></string-name></person-group> <article-title>Research into the dynamic nature of the human fovea cortex systems with intermittent and modulated light. I. Attenuation characteristics with white and colored light</article-title>. <source>Journal of the Optical Society of America</source>. <year>1958</year>; <volume>48</volume>(<issue>11</issue>):<fpage>777</fpage>–<lpage>784</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lesmes</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>ZL</given-names></string-name>, <string-name><surname>Baek</surname> <given-names>J</given-names></string-name>, <string-name><surname>Albright</surname> <given-names>TD</given-names></string-name></person-group>. <article-title>Bayesian adaptive estimation of the contrast sensitivity function: the quick CSF method</article-title>. <source>Journal of vision</source>. <year>2010</year>; <volume>10</volume>(<issue>3</issue>):<fpage>17</fpage>–<lpage>17</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Letham</surname> <given-names>B</given-names></string-name>, <string-name><surname>Guan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Tymms</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bakshy</surname> <given-names>E</given-names></string-name>, <string-name><surname>Shvartsman</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Look-ahead acquisition functions for Bernoulli level set estimation</article-title>. <conf-name>International Conference on Artificial Intelligence and Statistics PMLR</conf-name>; <year>2022</year>. p. <fpage>8493</fpage>–<lpage>8513</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Loomis</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Berger</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Effects of chromatic adaptation on color discrimination and color appearance</article-title>. <source>Vision Research</source>. <year>1979</year>; <volume>19</volume>(<issue>8</issue>):<fpage>891</fpage>–<lpage>901</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MacAdam</surname> <given-names>DL</given-names></string-name></person-group>. <article-title>Visual sensitivities to color differences in daylight</article-title>. <source>Journal of the Optical Society of America</source>. <year>1942</year>; <volume>32</volume>(<issue>5</issue>):<fpage>247</fpage>–<lpage>274</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Macadam</surname> <given-names>DL</given-names></string-name></person-group>. <article-title>Judd’s contributions to color metrics and evaluation of color differences</article-title>. <source>Color Research &amp; Application</source>. <year>1979</year>; <volume>4</volume>(<issue>4</issue>):<fpage>177</fpage>–<lpage>193</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MacLeod</surname> <given-names>DI</given-names></string-name>, <string-name><surname>Boynton</surname> <given-names>RM</given-names></string-name></person-group>. <article-title>Chromaticity diagram showing cone excitation by stimuli of equal luminance</article-title>. <source>Journal of the Optical Society of America</source>. <year>1979</year>; <volume>69</volume>(<issue>8</issue>):<fpage>1183</fpage>–<lpage>1186</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McDonald</surname> <given-names>R</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>KJ</given-names></string-name></person-group>. <article-title>CIE94-a new colour-difference formula</article-title>. <source>Journal of the Society of Dyers and Colourists</source>. <year>1995</year>; <volume>111</volume>(<issue>12</issue>):<fpage>376</fpage>–<lpage>379</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mullen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Ennis</surname> <given-names>DM</given-names></string-name></person-group>. <article-title>A simple multivariate probabilistic model for preferential and triadic choices</article-title>. <source>Psychometrika</source>. <year>1991</year>; <volume>56</volume>(<issue>1</issue>):<fpage>69</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Najemnik</surname> <given-names>J</given-names></string-name>, <string-name><surname>Geisler</surname> <given-names>WS</given-names></string-name></person-group>. <article-title>Optimal eye movement strategies in visual search</article-title>. <source>Nature</source>. <year>2005</year>; <volume>434</volume>(<issue>7031</issue>):<fpage>387</fpage>–<lpage>391</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Neitz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Jacobs</surname> <given-names>GH</given-names></string-name></person-group>. <article-title>Polymorphism of the long-wavelength cone in normal human colour vision</article-title>. <source>Nature</source>. <year>1986</year>; <volume>323</volume>(<issue>6089</issue>):<fpage>623</fpage>–<lpage>625</lpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Newton</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Eskew</surname> <given-names>RT</given-names></string-name></person-group>. <article-title>Chromatic detection and discrimination in the periphery: a postreceptoral loss of color sensitivity</article-title>. <source>Visual neuroscience</source>. <year>2003</year>; <volume>20</volume>(<issue>5</issue>):<fpage>511</fpage>–<lpage>521</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niwa</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Muraki</surname> <given-names>S</given-names></string-name>, <string-name><surname>Naito</surname> <given-names>F</given-names></string-name>, <string-name><surname>Minamikawa</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ohji</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Evaluation of acquired color vision deficiency in glaucoma using the Rabin cone contrast test</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2014</year>; <volume>55</volume>(<issue>10</issue>):<fpage>6686</fpage>–<lpage>90</lpage>. <pub-id pub-id-type="pmid">25168899</pub-id>, doi: <pub-id pub-id-type="doi">10.1167/iovs.14-14079</pub-id>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Noorlander</surname> <given-names>C</given-names></string-name>, <string-name><surname>Heuts</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Koenderink</surname> <given-names>JJ</given-names></string-name></person-group>. <article-title>Sensitivity to spatiotemporal combined luminance and chromaticity contrast</article-title>. <source>Journal of the Optical Society of America</source>. <year>1981</year>; <volume>71</volume>(<issue>4</issue>):<fpage>453</fpage>–<lpage>459</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Noorlander</surname> <given-names>C</given-names></string-name>, <string-name><surname>Koenderink</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Den Olden</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Edens</surname> <given-names>BW</given-names></string-name></person-group>. <article-title>Sensitivity to spatiotemporal colour contrast in the peripheral visual field</article-title>. <source>Vision Research</source>. <year>1983</year>; <volume>23</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Olkkonen</surname> <given-names>M</given-names></string-name>, <string-name><surname>McCarthy</surname> <given-names>PF</given-names></string-name>, <string-name><surname>Allred</surname> <given-names>SR</given-names></string-name></person-group>. <article-title>The central tendency bias in color perception: Effects of internal and external noise</article-title>. <source>Journal of vision</source>. <year>2014</year>; <volume>14</volume>(<issue>11</issue>):<fpage>5</fpage>–<lpage>5</lpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Owen</surname> <given-names>L</given-names></string-name>, <string-name><surname>Browder</surname> <given-names>J</given-names></string-name>, <string-name><surname>Letham</surname> <given-names>B</given-names></string-name>, <string-name><surname>Stocek</surname> <given-names>G</given-names></string-name>, <string-name><surname>Tymms</surname> <given-names>C</given-names></string-name>, <string-name><surname>Shvartsman</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Adaptive nonparametric psychophysics</article-title>. <source>arXiv</source>. <year>2021</year>;.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palmer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ames</surname> <given-names>CT</given-names></string-name>, <string-name><surname>Lindsey</surname> <given-names>DT</given-names></string-name></person-group>. <article-title>Measuring the effect of attention on simple visual search</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>. <year>1993</year>; <volume>19</volume>(<issue>1</issue>):<fpage>108</fpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pointer</surname> <given-names>MR</given-names></string-name></person-group>. <article-title>Color discrimination as a function of observer adaptation</article-title>. <source>Journal of the Optical Society of America</source>. <year>1974</year>; <volume>64</volume>(<issue>6</issue>):<fpage>750</fpage>–<lpage>759</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poirson</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Wandell</surname> <given-names>BA</given-names></string-name></person-group>. <article-title>The ellipsoidal representation of spectral sensitivity</article-title>. <source>Vision research</source>. <year>1990</year>; <volume>30</volume>(<issue>4</issue>):<fpage>647</fpage>– <lpage>652</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Prins</surname> <given-names>N</given-names></string-name>, <etal>et al.</etal></person-group> <source>Psychophysics: a practical introduction</source>. <publisher-name>Academic Press</publisher-name>; <year>2016</year>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reisbeck</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Gegenfurtner</surname> <given-names>KR</given-names></string-name></person-group>. <article-title>Velocity tuned mechanisms in human motion processing</article-title>. <source>Vision research</source>. <year>1999</year>; <volume>39</volume>(<issue>19</issue>):<fpage>3267</fpage>–<lpage>3286</lpage>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rezeanu</surname> <given-names>D</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Neitz</surname> <given-names>J.</given-names></string-name></person-group> <article-title>From cones to color vision: a neurobiological model that explains the unique hues</article-title>. <source>Journal of the Optical Society of America A</source>. <year>2023</year>; <volume>40</volume>(<issue>3</issue>):<fpage>A1</fpage>–<lpage>A8</lpage>.</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roberti</surname> <given-names>V.</given-names></string-name></person-group> <article-title>Helmholtz, Schrödinger, and the First Non-Euclidean Model of Perceptual Color Space</article-title>. <source>Annalen der Physik</source>. <year>2024</year>; <volume>536</volume>(<issue>5</issue>):<fpage>2300536</fpage>.</mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robertson</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Lozano</surname> <given-names>RD</given-names></string-name>, <string-name><surname>Alman</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Orchard</surname> <given-names>S</given-names></string-name>, <string-name><surname>Keitch</surname> <given-names>J</given-names></string-name>, <string-name><surname>Connely</surname> <given-names>R</given-names></string-name>, <string-name><surname>Graham</surname> <given-names>L</given-names></string-name>, <string-name><surname>Acree</surname> <given-names>W</given-names></string-name>, <string-name><surname>John</surname> <given-names>R</given-names></string-name>, <string-name><surname>Hoban</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>CIE recommendations on uniform color spaces, color-difference equations, and metric color terms</article-title>. <source>Color Res Appl</source>. <year>1977</year>; <volume>2</volume>(<issue>5-6</issue>):<fpage>3</fpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schrödinger</surname> <given-names>Ev.</given-names></string-name></person-group> <article-title>Outline of a theory of color measurement for daylight vision</article-title>. <source>Physics Annual</source>. <year>1920</year>; <volume>63</volume>(<issue>4</issue>):<fpage>397</fpage>– <lpage>520</lpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharma</surname> <given-names>G</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>W</given-names></string-name>, <string-name><surname>Dalal</surname> <given-names>EN</given-names></string-name></person-group>. <article-title>The CIEDE2000 color-difference formula: Implementation notes, supplementary test data, and mathematical observations</article-title>. <source>Color Research &amp; Application</source>. <year>2005</year>; <volume>30</volume>(<issue>1</issue>):<fpage>21</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shepard</surname> <given-names>TG</given-names></string-name>, <string-name><surname>Lahlaf</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Eskew</surname> <given-names>RT</given-names></string-name></person-group>. <article-title>Labeling the lines: A test of a six-mechanism model of chromatic detection</article-title>. <source>Journal of Vision</source>. <year>2017</year>; <volume>17</volume>(<issue>13</issue>):<fpage>9</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shepard</surname> <given-names>TG</given-names></string-name>, <string-name><surname>Swanson</surname> <given-names>EA</given-names></string-name>, <string-name><surname>McCarthy</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Eskew</surname> <given-names>RT</given-names></string-name></person-group>. <article-title>A model of selective masking in chromatic detection</article-title>. <source>Journal of vision</source>. <year>2016</year>; <volume>16</volume>(<issue>9</issue>):<fpage>3</fpage>–<lpage>3</lpage>.</mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shevell</surname> <given-names>SK</given-names></string-name>, <string-name><surname>Martin</surname> <given-names>PR</given-names></string-name></person-group>. <article-title>Color opponency: tutorial</article-title>. <source>Journal of the Optical Society of America A</source>. <year>2017</year>; <volume>34</volume>(<issue>7</issue>):<fpage>1099</fpage>– <lpage>1108</lpage>.</mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sobol</surname> <given-names>IM</given-names></string-name></person-group>. <article-title>The distribution of points in a cube and the approximate evaluation of integrals</article-title>. <source>USSR Computational mathematics and mathematical physics</source>. <year>1967</year>; <volume>7</volume>:<fpage>86</fpage>–<lpage>112</lpage>.</mixed-citation></ref>
    <ref id="c89"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Stark</surname> <given-names>E</given-names></string-name>, <string-name><surname>Turton</surname> <given-names>TL</given-names></string-name>, <string-name><surname>Bujack</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Diminishing Returns in Perceptual Color Space-Now in Color</article-title> <conf-name>EuroVisShort2025</conf-name>. <year>2025</year>;.</mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stockman</surname> <given-names>A</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>DH</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Color vision mechanisms</article-title>. <source>OSA handbook of optics</source>. <year>2010</year>; <volume>3</volume>:<fpage>11</fpage>–<lpage>1</lpage>.</mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vemala</surname> <given-names>R</given-names></string-name>, <string-name><surname>Sivaprasad</surname> <given-names>S</given-names></string-name>, <string-name><surname>Barbur</surname> <given-names>JL</given-names></string-name></person-group>. <article-title>Detection of Early Loss of Color Vision in Age-Related Macular Degeneration - With Emphasis on Drusen and Reticular Pseudodrusen</article-title>. <source>Invest Ophthalmol Vis Sci</source>. <year>2017</year>; <volume>58</volume>(<issue>6</issue>):<fpage>BIO247</fpage>– <lpage>BIO254</lpage>. <pub-id pub-id-type="pmid">28846119</pub-id>, doi: <pub-id pub-id-type="doi">10.1167/iovs.17-21771</pub-id>.</mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wandell</surname> <given-names>BA</given-names></string-name></person-group>. <article-title>Color measurement and discrimination</article-title>. <source>Journal of the Optical Society of America A</source>. <year>1985</year>; <volume>2</volume>(<issue>1</issue>):<fpage>62</fpage>– <lpage>71</lpage>.</mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wandell</surname> <given-names>BA</given-names></string-name></person-group>. <source>Foundations of vision</source>. <publisher-name>Sinauer Associates</publisher-name>; <year>1995</year>.</mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wardle</surname> <given-names>SG</given-names></string-name>, <string-name><surname>Alais</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Evidence for speed sensitivity to motion in depth from binocular cues</article-title>. <source>Journal of Vision</source>. <year>2013</year>; <volume>13</volume>(<issue>1</issue>):<fpage>17</fpage>–<lpage>17</lpage>.</mixed-citation></ref>
<ref id="c95"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wasserman</surname> <given-names>L.</given-names></string-name></person-group> <source>All of nonparametric statistics</source>. <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2006</year>.</mixed-citation></ref>
<ref id="c96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watson</surname> <given-names>AB</given-names></string-name></person-group>. <article-title>QUEST+: A general multidimensional Bayesian adaptive psychometric method</article-title>. <source>Journal of Vision</source>. <year>2017</year>; <volume>17</volume>(<issue>3</issue>):<fpage>10</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Webster</surname> <given-names>MA</given-names></string-name>, <string-name><surname>MacLeod</surname> <given-names>DI</given-names></string-name></person-group>. <article-title>Factors underlying individual differences in the color matches of normal observers</article-title>. <source>Journal of the Optical Society of America A</source>. <year>1988</year>; <volume>5</volume>(<issue>10</issue>):<fpage>1722</fpage>–<lpage>1735</lpage>.</mixed-citation></ref>
<ref id="c98"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Williams</surname> <given-names>CK</given-names></string-name>, <string-name><surname>Rasmussen</surname> <given-names>CE</given-names></string-name></person-group>. <source>Gaussian processes for machine learning</source>, vol. <volume>2</volume>. <publisher-name>MIT press Cambridge, MA</publisher-name>; <year>2006</year>.</mixed-citation></ref>
    <ref id="c99"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Ghahramani</surname> <given-names>Z.</given-names></string-name></person-group> <article-title>Generalised Wishart processes</article-title>. <conf-name>Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence UAI’11</conf-name> <conf-loc>Arlington, United States</conf-loc>; <year>2011</year>. p. <fpage>736</fpage>–<lpage>744</lpage>.</mixed-citation></ref>
    <ref id="c100"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Winawer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Witthoft</surname> <given-names>N.</given-names></string-name></person-group> <chapter-title>Effects of color terms on color perception and cognition</chapter-title>. <source>Encyclopedia of color science and technology</source> <person-group person-group-type="editor"><string-name><surname>Shamey</surname><given-names>R</given-names></string-name></person-group> <publisher-name>Springer</publisher-name>; <year>2023</year>.p. <fpage>777</fpage>–<lpage>785</lpage>.</mixed-citation></ref>
<ref id="c101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wuerger</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Maloney</surname> <given-names>LT</given-names></string-name>, <string-name><surname>Krauskopf</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Proximity judgments in color space: tests of a Euclidean color geometry</article-title>. <source>Vision research</source>. <year>1995</year>; <volume>35</volume>(<issue>6</issue>):<fpage>827</fpage>–<lpage>835</lpage>.</mixed-citation></ref>
    <ref id="c102"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wyszecki</surname> <given-names>G.</given-names></string-name></person-group> <source>Color Science: Concepts and methods, quantitative data and formulae</source>. <year>1982</year>; p. <fpage>130</fpage>–<lpage>175</lpage>.</mixed-citation></ref>
<ref id="c103"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Zaidi</surname> <given-names>Q</given-names></string-name></person-group>, <source>Is there a perceptual color space?</source> <publisher-name>Wiley Online Library</publisher-name>; <year>2001</year>.</mixed-citation></ref>
<ref id="c104"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname> <given-names>J</given-names></string-name>, <string-name><surname>Duong</surname> <given-names>LR</given-names></string-name>, <string-name><surname>Simoncelli</surname> <given-names>EP</given-names></string-name></person-group>. <article-title>A unified framework for perceived magnitude and discriminability of sensory stimuli</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2024</year>; <volume>121</volume>(<issue>25</issue>):<fpage>e2312293121</fpage>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app1">
<title>Appendix 1</title>
<sec id="s7">
<title>Transformation between the DKL, RGB, and model spaces</title>
<p>This section summarizes the colorimetric transformations between the RGB space of our monitor, the 2D model space, and standard color spaces.</p>
<p>The DKL color provides a representation of the isoluminant plane with the adapting point at the origin (<xref ref-type="bibr" rid="c30">Derrington et al., 1984</xref>; <xref ref-type="bibr" rid="c12">Brainard, 1996</xref>). We defined our DKL space with respect to the CIE physiologically-relevant 2-deg cone fundamentals and corresponding photopic luminosity function. We began in DKL space, with adapting point defined by the cone excitations elicited by the displayed background so that the space’s isoluminant plane included the background. In this plane, we then densely sampled chromatic directions spanning 360° around the origin. For each direction we marched outward from the origin to find the edge of the monitor’s gamut in that direction (details explained in Appendix 1.1). Repeating across directions, we obtained a set of gamut boundary points that defined a quadrilateral in the isoluminant plane. We then identified the four vertices and recorded their coordinates in both DKL and RGB spaces (<xref ref-type="table" rid="tblS1">Table S1</xref>). Using these vertices, we derived a projective transformation matrix (homography) that maps coordinates from the DKL space to the model space (see Appendix 1.2 and <xref ref-type="table" rid="tblS2">Table S2</xref>). While the homography provides a general solution applicable to any quadrilateral, our derived matrix revealed that an affine transformation provided an accurate approximation. We used this affine transformation and its inverse to convert back and forth linear RGB values and the model space (see Appendix 1.3 and <xref ref-type="table" rid="tblS2">Table S2</xref>).</p>
<table-wrap id="tblS1" orientation="portrait" position="float">
<label>Table S1.</label>
<caption><title>Corner vertices in the DKL, LMS, RGB, and model spaces.</title></caption>
<graphic xlink:href="665219v2_tblS1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS2" orientation="portrait" position="float">
<label>Table S2.</label>
<caption><title>Transformation matrices between DKL, RGB and model spaces.</title></caption>
<graphic xlink:href="665219v2_tblS2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<sec id="s7a">
<title>Appendix 1.1: Search for the boundary points within the monitor’s gamut</title>
<p>We selected 1,000 angles <italic>θ</italic> that span the isoluminant plane uniformly in the DKL representation. For each angle, we defined a chromatic direction vector in DKL space as <bold>d</bold><sub>DKL</sub> = [cos(<italic>θ</italic>), sin(<italic>θ</italic>), 0]<sup><italic>⊤</italic></sup>, where the first two elements correspond to the L–M and S axes of the DKL space, and the third element is set to zero to constrain the direction to the isoluminant plane (i.e., no change in luminance). For each direction, we then determined the farthest point along that vector that remained within the monitor’s gamut in linear RGB space. Specifically, we first converted <bold>d</bold><sub>DKL</sub> to LMS cone excitations, denoted <bold>e</bold><sub>LMS</sub>, as follows:
<disp-formula id="eqnS1">
<graphic xlink:href="665219v2_eqnS1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Notably, because the actual LMS cone excitations include contributions from ambient light, denoted as <bold>e</bold><sub>LMS, ambient</sub>, we subtracted it to isolate the portion due to the RGB stimulus, denoted as <bold>e</bold><sub>LMS, stimulus</sub>, that is,
<disp-formula id="eqnS2">
<graphic xlink:href="665219v2_eqnS2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Next, we converted this isolated stimulus response into RGB space:
<disp-formula id="eqnS3">
<graphic xlink:href="665219v2_eqnS3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqnS4">
<graphic xlink:href="665219v2_eqnS4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Finally, we marched outward along the direction <bold>d</bold><sub>RGB</sub> until the RGB values reached the edge of the RGB cube. The values at this boundary were recorded as a limiting point along that chromatic direction. Repeating this procedure across all sampled directions yielded the full boundary of the isoluminant plane constrained by the monitor’s gamut. From this boundary set, we then identified the four corner vertices (<xref ref-type="table" rid="tblS1">Table S1</xref>).</p>
</sec>
<sec id="s7b">
<title>Appendix 1.2: An affine transformation matrix that maps DKL to model space</title>
<p>These vertices, denoted as <bold>v</bold>, were then used to derive a projective transformation matrix <italic>M</italic><sub>DKL→W</sub> such that for each vertex pair, we have:
<disp-formula id="eqnS5">
<graphic xlink:href="665219v2_eqnS5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>v</bold><sub>W</sub> = [<italic>v</italic><sub>W, dim1</sub>, <italic>v</italic><sub>W, dim2</sub>, 1]<sup><italic>⊤</italic></sup> is the homogeneous coordinate of a vertex in model space, and <bold>v</bold><sub>DKL</sub> = [<italic>v</italic><sub>DKL, <italic>L</italic>-<italic>M</italic></sub>, <italic>v</italic><sub>DKL, <italic>S</italic></sub>, 0]<sup><italic>⊤</italic></sup> is the corresponding homogeneous coordinate in DKL space. By plugging in the vertices, we solved the matrix <italic>M</italic><sub>DKL→W</sub> as the following,
<disp-formula id="eqnS6">
<graphic xlink:href="665219v2_eqnS6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where † denotes the pseudoinverse. Note that the last row of <italic>M</italic><sub>DKL→W</sub> is [0, 0, 1], indicating that the transformation is affine (<xref ref-type="table" rid="tblS2">Table S2</xref>). Although this affine formulation would be sufficient, we initially computed the full projective transformation matrix for generality, since it was uncertain that the DKL vertices would form a parallelogram. In this particular case, both methods yielded equivalent results.</p>
</sec>
<sec id="s7c">
<title>Appendix 1.3: An affine transformation matrix that maps RGB to model space</title>
<p>Given that the transformations from DKL to LMS, LMS to RGB, and DKL to model space are all affine, by the composition property of affine transformations, it follows that the transformation from RGB to model space must also be affine.</p>
<p>To compute the affine transformation matrix, we used corresponding corner vertices in RGB and model spaces. Specifically, we solved for the matrix <italic>M</italic><sub>RGB→W</sub> as:
<disp-formula id="eqnS7">
<graphic xlink:href="665219v2_eqnS7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where † denotes the pseudoinverse and we appended a row of ones to the Wishart coordinates to express them in homogeneous form.</p>
</sec>
<sec id="s7d">
<title>Appendix 1.4: Affine invariance of Mahalanobis distance</title>
<p>We performed trial placement, model fitting, and data presentation using the model space (bounded between –1 and 1). An important feature of the WPPM is that it is equivariant with respect to affine transformations of the color space used to represent the stimuli. That is, if we transform reference and comparison stimuli to a new color space using an affine transformation, and transform the covariance field by the same affine transformation, then the observer model yields a prediction of performance that is unchanged by the transformation. This is because the Mahalanobis distance is itself unchanged by the transformation, as we show below. This is an attractive property because it avoids assigning special status to the particular color space used to represent the stimuli and covariance field.</p>
<p>Let Σ be the covariance matrix. The squared Mahalanobis distance between two points <bold>x</bold><sub>0</sub> and <bold>x</bold><sub>1</sub> is defined as:
<disp-formula id="eqnS8">
<graphic xlink:href="665219v2_eqnS8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Now consider a linear transformation <bold>x</bold> = <italic>A</italic><bold>x</bold><sub>0</sub>, <bold>x</bold> = <italic>A</italic><bold>x</bold><sub>1</sub>. The corresponding transformation of the covariance matrix is Σ<sup>′</sup> = <italic>A</italic>Σ<italic>A</italic><sup><italic>⊤</italic></sup>. Then the squared Mahalanobis distance in the transformed space becomes:
<disp-formula id="eqnS9">
<graphic xlink:href="665219v2_eqnS9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Thus, the Mahalanobis distance is invariant under linear transformations of the data when the covariance matrix is transformed accordingly. Since distance is also invariant to translations (i.e., independent of the choice of origin), this further implies that the Mahalanobis distance is invariant under general affine transformations.</p>
</sec>
</sec>
</app>
<app id="app2">
<label>Appendix 2</label>
<sec id="s8">
<title>AEPsych-driven trials and WPPM readouts for all participants</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1.</label>
    <caption><title>AEPsych-driven trials (900 Sobol’-sampled and 5,100 adaptively sampled), fallback trials, and WPPM predictions for all participants.</title>
        <p>Each row represents data from one participant. AEPsych-driven trials (900 Sobol’-sampled and 5,100 adaptively sampled), fallback trials, and WPPM predictions for all participants. Each row represents data from one participant. Note that for participant CH, no pre-generated Sobol’ trials were used, as the fallback strategy was implemented later in the study to maintain experimental continuity and reduce delays between trials.</p></caption>
<graphic xlink:href="665219v2_figS1.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="665219v2_figS1a.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</app>
<app id="app3">
<label>Appendix 3</label>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2.</label>
    <caption><title>Task timing and real-time trial scheduling.</title>
        <p>(A) Trial sequence: a 0.5 s fixation cross was followed by a 0.2 s blank interval, then a 1 s presentation of three blobby stimuli. Participants responded at their own pace to identify the odd-one-out, after which a 0.2 s blank screen and a 0.5 s feedback were shown. The inter-trial interval (ITI) was 1.5 s. (B) A schematic representation of the trial timing and computational responsibilities of the two computers.</p></caption>
<graphic xlink:href="665219v2_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s9">
<title>Real-time trial scheduling via dual-computer coordination</title>
<p>For each participant, we ran 6,000 AEPsych-driven trials interleaved with an additional 6,000 validation trials. Although our initial plan was to present these 12,000 trials in a pre-determined randomized sequence, we quickly realized this approach was impractical. Under such a design, AEPsych would have only the inter-trial interval (ITI) to compute the next trial placement—a window that is difficult to optimize. A long ITI risks participant fatigue or loss of attention, while a short ITI does not provide AEPsych enough time to complete its computations. To achieve both a smooth experimental flow and adequate computation time for AEPsych, we implemented a fallback trial strategy using a dual-computer setup.</p>
<p>In this setup, stimulus presentation was handled by an Alienware computer, while adaptive trial placement using AEPsych ran on a separate high-performance PC. The two systems communicated via a shared network disk using a custom protocol based on text files that both computers could read and write. This decoupled design provided modular separation between code specialized for stimulus presentation and the sequence of events on each trial and code specialized to handle trial placement, and should allow our trial placement code to be more easily ported to different stimulus display systems.</p>
<p>With the dual-computer design, AEPsych had at least 2.9 s to compute the next trial after the participant’s response (<xref rid="figS2" ref-type="fig">Figure S2</xref>). This window spanned both the post-stimulus period of the current trial (0.2 s blank, 0.5 s feedback, 1.5 s ITI) and the pre-stimulus period of the upcoming trial (0.5 s fixation and 0.2 s blank). Importantly, this computation window began only after the participant responded—since AEPsych requires the participant’s response to update its model—and ended just before the stimulus presentation of the next trial, when AEPsych must deliver the RGB values for the upcoming stimuli.</p>
<p>The fallback trial strategy ensured continuous stimulus presentation. If AEPsych failed to return a new trial within the 2.9 s window, we defaulted to presenting the next available MOCS trial from the pre-determined randomized sequence. In such cases, AEPsych’s computation continued in a different thread and attempted to meet the following decision deadline, which is approximately 7 s after the previous one, included an additional 1 s stimulus presentation and an estimated 0.2 s response time. If AEPsych again missed this deadline, the next opportunity came at around 11.1 s. This staggered scheduling ensured that trials continued smoothly while allowing AEPsych sufficient time to compute adaptive placements when possible.</p>
<p>A potential drawback of the fallback trial strategy is that it could disrupt the intended interleaving of adaptive and validation trials, potentially introducing differential learning effects. To mitigate this, we capped how far MOCS trials could advance relative to AEPsych trials. This cap was set at four trials. If this limit was reached and no AEPsych trial was ready, we inserted pre-generated Sobol’ trials instead. These Sobol’ trials were created in advance using participant- and session-specific random seeds and were separate from those selected by AEPsych.</p>
</sec>
</app>
<app id="app4">
<label>Appendix 4</label>
<sec id="s10">
<title>Comparison between WPPM and validation thresholds</title>
<sec id="s10a">
<title>Appendix 4.1: Validation data for all participants</title>
    <fig id="figS3" position="float" fig-type="figure">
        <label>Figure S3.</label>
        <caption><title>Validation for participant ME.</title>
            <p>Same format as <xref ref-type="fig" rid="fig2">Figure 2D-G</xref> in the main text.</p></caption>
        <graphic xlink:href="665219v2_figS3.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
    <fig id="figS4" position="float" fig-type="figure">
        <label>Figure S4.</label>
        <caption><title>Validation for participant SG.</title>
        </caption>
        <graphic xlink:href="665219v2_figS4.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
    <fig id="figS5" position="float" fig-type="figure">
        <label>Figure S5.</label>
        <caption><title>Validation for participant DK.</title>
        </caption>
        <graphic xlink:href="665219v2_figS5.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
    <fig id="figS6" position="float" fig-type="figure">
        <label>Figure S6.</label>
        <caption><title>Validation for participant BH.</title></caption>
        <graphic xlink:href="665219v2_figS6.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
    <fig id="figS7" position="float" fig-type="figure">
        <label>Figure S7.</label>
        <caption><title>Validation for participant FM.</title></caption>
        <graphic xlink:href="665219v2_figS7.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
    <fig id="figS8" position="float" fig-type="figure">
        <label>Figure S8.</label>
        <caption><title>Validation for participant HG.</title></caption>
        <graphic xlink:href="665219v2_figS8.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
    <fig id="figS9" position="float" fig-type="figure">
        <label>Figure S9.</label>
        <caption><title>Validation for participant FW.</title></caption>
        <graphic xlink:href="665219v2_figS9.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
    <fig id="figS10" position="float" fig-type="figure">
        <label>Figure S10.</label>
        <caption><title>Validation for participant CH.</title></caption>
        <graphic xlink:href="665219v2_figS10.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
</sec>
<sec id="s10b">
<title>Appendix 4.2: Analysis of discrepancies between WPPM and validation thresholds</title>
    <fig id="figS11" position="float" fig-type="figure">
        <label>Figure S11.</label>
        <caption><title>Threshold residuals.</title>
            <p>Data are pooled across all validation conditions and all participants (<italic>N</italic> = 8). For all panels, color codes for the surface color of the reference stimulus, and the y-axis limits are set to ± the mean of the validation thresholds. (A) Residuals as a function of the absolute angular difference between the major axis of the elliptical threshold contours read out from the WPPM fits and the chromatic direction of the validation condition. (B) Residuals as a function of the aspect ratio (major/minor axis) of the WPPM threshold contours. (C) Residuals as a function of thresholds estimated from validation trials.</p></caption>
        <graphic xlink:href="665219v2_figS11.tif" mimetype="image" mime-subtype="tiff"/>
    </fig>
<p>We assessed whether the residuals (the discrepancies between the WPPM and validation thresholds) exhibited systematic patterns. We found no significant correlation between the residuals and the absolute angular difference between the chromatic direction of the validation condition and the major axis of the elliptical threshold contours read out from the WPPM fits (<xref rid="figS11" ref-type="fig">Figure S11A</xref>), nor with the aspect ratio of the contours (<xref rid="figS11" ref-type="fig">Figure S11B</xref>). Thus, there is no evidence that the residuals vary systematically with the orientation or shape of the contours read out from the WPPM fits (see statistical summary in <xref ref-type="table" rid="tblS3">Table S3</xref>).</p>
<p>In contrast, we found a significant negative correlation between the residuals and the magnitude of the validation thresholds (<xref rid="figS11" ref-type="fig">Figure S11C</xref>; slope = −0.151, <italic>t</italic>(198) = −4.632, <italic>p &lt;</italic> 0.001, <italic>R</italic><sup>2</sup> = 0.098), indicating that the WPPM tends to slightly overestimate thresholds when they are small and underestimate them when they are large. However, the magnitude of this bias is small relative to the range of observed validation thresholds.</p>
    <table-wrap id="tblS3" orientation="portrait" position="float">
        <label>Table S3.</label>
        <caption><title>Linear regression results assessing the relationship between WPPM–validation threshold discrepancies and three predictors: (1) the absolute angular difference between the chromatic direction of the validation condition and the major axis of the contours read out from the WPPM fits, (2) the aspect ratio of the contours, and (3) the magnitude of the validation threshold.</title>
            <p>This analysis was done on human data.</p></caption>
        <graphic xlink:href="665219v2_tblS3.tif" mimetype="image" mime-subtype="tiff"/>
    </table-wrap>
</sec>
<sec id="s10c">
<title>Appendix 4.3: Analysis of percent-correct performance for catch trials</title>
<p>For each validation condition, we used the method of constant stimuli to sample 12 comparison levels: 11 were evenly spaced, and one was selected to serve as an easily discriminable catch trial. Participants completed 500 catch trials (1/12 of 6,000 validation trials). These catch trials were included to assess participants’ attentiveness and establish a criterion for potential data exclusion. As shown in <xref ref-type="table" rid="tblS4">Table S4</xref>, participants except for DK performed near ceiling on these trials, indicating high task engagement throughout the experiment. Although DK’s performance was somewhat lower, this likely reflects lower overall sensitivity rather than frequent lapses (<xref rid="figS5" ref-type="fig">Figure S5</xref>), as the “easy” trials may not have been as easily discriminable for this participant.</p>
<table-wrap id="tblS4" orientation="portrait" position="float">
<label>Table S4.</label>
<caption><title>Catch trial performance summary across all sessions.</title>
<p>The proportion correct reflects the total number of correct responses divided by the total number of catch trials. Lower and upper bounds indicate the participant’s lowest and highest session-level performance, respectively.</p></caption>
<graphic xlink:href="665219v2_tblS4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</sec>
</app>
<app id="app5">
<label>Appendix 5</label>
<sec id="s11">
<title>Simulated participant</title>
<p>To evaluate how well thresholds read out from the WPPM fits aligned with those estimated via Weibull fits, we simulated a dataset with a known ground truth. The following subsections outline the key steps in this process.</p>
<sec id="s11a">
<title>Appendix 5.1: Derivation of the comparison stimuli at threshold on the isoluminant plane</title>
<p>We used CIELab Δ<italic>E</italic> 94 as the ground truth metric for deriving color discrimination performance. For any given reference color and any given chromatic direction, both were affine-transformed from the model space to the RGB space. The RGB values were then converted to CIE 1931 XYZ and then to CIELab space, where Δ<italic>E</italic> computations were performed. In the XYZ-to-Lab transformation, we used the monitor gray point (<italic>R</italic> = <italic>G</italic> = <italic>B</italic> = 0.5) as the reference white. We then searched along each chromatic direction in the RGB space to find a comparison stimulus <bold>x</bold><sub>1</sub> = (<italic>x</italic><sub>1,dim1</sub>, <italic>x</italic><sub>1,dim2</sub>) such that Δ<italic>E</italic> in CIELab was equal to 2.5 (<xref rid="figS12" ref-type="fig">Figure S12A</xref>). This procedure was repeated across multiple directions. The resulting comparison stimuli were then mapped back into the model space, where we fit an ellipse to define the iso-distance contour (<xref rid="figS12" ref-type="fig">Figure S12B</xref>).</p>
<fig id="figS12" position="float" fig-type="figure">
<label>Figure S12.</label>
    <caption><title>Derivation of the ground-truth Wishart fits based on CIELab Δ<italic>E</italic> 94.</title>
    <p>(A–B) Comparison stimuli at the iso-distance contours in the isoluminant plane, shown in both RGB and model spaces. Note that the reference grid and fixed set of directions shown here are for illustration only; the actual sampling did not use a fixed grid or evenly spaced chromatic directions. (C) The Weibull psychometric function used to simulate binary (correct or incorrect) responses given Δ<italic>E</italic> values. (D) Sampled reference-comparison stimulus pairs. Reference colors and chromatic directions were sampled using Sobol’ sequences, and comparison stimuli were jittered around the iso-distance contour. A total of 18,000 trials were simulated; only the first 200 are shown here for clarity. (E) Comparison between readouts from the WPPM fit and from CIELab Δ<italic>E</italic> 94. The WPPM fit was subsequently treated as the ground truth for simulating AEPsych and validation trials.</p></caption>
<graphic xlink:href="665219v2_figS12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s11b">
<title>Appendix 5.2: Simulation of trials near threshold contours</title>
<p>To introduce some variability, we added bivariate Gaussian noise to each comparison stimulus at the iso-distance contour in the model space. The noise standard deviation was proportional to the Euclidean distance between the reference stimulus <bold>x</bold><sub>0</sub> and the comparison stimulus <bold>x</bold><sub>1</sub>. The jittered comparison stimulus <inline-formula id="inline-eqn-10"><inline-graphic xlink:href="665219v2_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> was computed as:
<disp-formula id="eqnS10">
<graphic xlink:href="665219v2_eqnS10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We modeled performance using a Weibull psychometric function, which took the Δ<italic>E</italic> between the reference and jittered comparison stimuli as input and returned the predicted percent correct:
<disp-formula id="eqnS11">
<graphic xlink:href="665219v2_eqnS11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The values of <italic>α</italic> and <italic>β</italic> were selected such that the psychometric curve returns 66.7% correct when Δ<italic>E</italic> = 2.5 (<xref rid="figS12" ref-type="fig">Figure S12C</xref>). A binary (correct or incorrect) response was sampled from a Bernoulli distribution using this predicted probability:
<disp-formula id="eqnS12">
<graphic xlink:href="665219v2_eqnS12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The comparison stimuli were selected to be near threshold, while the reference stimuli and chromatic directions were Sobol’ sampled to ensure uniform coverage of the model space without repeated trials (<xref rid="figS12" ref-type="fig">Figure S12D</xref>). In total, we simulated 18,000 trials.</p>
</sec>
<sec id="s11c">
<title>Appendix 5.3: Fit the WPPM and treating the model fits as the ground truth</title>
<p>We fitted the WPPM to the full set of 18,000 trials in the model space, and treated the resulting fit as the ground truth for simulating both AEPsych and validation trials (<xref rid="figS12" ref-type="fig">Figure S12E</xref>, color lines). We chose to use the WPPM fit as the ground truth—rather than percent-correct performance derived from CIELab Δ<italic>E</italic> 94 with a Weibull psychometric function—because our goal was to evaluate how well the WPPM can recover the simulated data. Using a ground truth that is itself an instance of the WPPM fit provides a more direct and interpretable comparison, avoiding local irregularities or discontinuities that might be present in CIELab Δ<italic>E</italic> 94 predictions and thus inherently difficult for the WPPM to characterize.</p>
</sec>
<sec id="s11d">
<title>Appendix 5.4: Fit the WPPM to simulated AEPsych trials</title>
<p>Based on the ground-truth WPPM fit, we simulated 900 Sobol’ trials (<xref rid="figS13" ref-type="fig">Figure S13A</xref>), followed by 5,100 adaptively sampled trials using AEPsych (<xref rid="figS13" ref-type="fig">Figure S13B</xref>), just like the design for the actual experiment. For each pair of reference and comparison stimuli, we approximated percent-correct performance using Monte Carlo simulation (N = 2,000), and generated binary responses by drawing from a Bernoulli distribution. We then fit the WPPM to this simulated dataset. To approximate the variability of the WPPM readouts, we bootstrapped the data 10 times, maintaining the same Sobol’-to-adaptive trial ratio within each bootstrapped dataset. As shown in <xref rid="figS13" ref-type="fig">Figure S13C</xref>, the WPPM was able to reliably recover the ground-truth model, with some minor local deviations.</p>
<fig id="figS13" position="float" fig-type="figure">
<label>Figure S13.</label>
    <caption><title>AEPsych-driven trials and WPPM readouts for a simulated participant.</title>
        <p>Note that the ground-truth thresholds shown in (C) is the same WPPM readouts from <xref ref-type="fig" rid="figS12">Figure S12E</xref>.</p></caption>
<graphic xlink:href="665219v2_figS13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s11e">
<title>Appendix 5.5: Validation trials and Weibull predictions</title>
<p>In addition to the 6,000 AEPsych trials, we also simulated 6,000 validation trials, mirroring the design of the actual experiment. Unlike the experimental design, these validation trials were simulated separately rather than interleaved, since sequential effects or perceptual learning are not factors in simulation. The WPPM thresholds confidence intervals agreed with 23 of 25 validation threshold confidence intervals (<xref rid="figS14" ref-type="fig">Figure S14</xref>). A linear regression fit to the validation thresholds (x-axis) and WPPM thresholds (y-axis) yielded a slope of 0.94 and a correlation coefficient of 0.83. These values fall within the range observed for human data (Appendix 4.1).</p>
<fig id="figS14" position="float" fig-type="figure">
<label>Figure S14.</label>
    <caption><title>Validation trials and WPPM readouts for a simulated participant.</title></caption>
<graphic xlink:href="665219v2_figS14.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s11f">
<title>Appendix 5.6: Statistical analysis of discrepancies between WPPM readouts and validation thresholds</title>
<p>We applied the same statistical analysis to the simulated data as we did for the human data (<bold><italic>subsection</italic></bold>). Consistent with the human results (<xref rid="figS11" ref-type="fig">Figure S11</xref>), we found no strong evidence that residuals systematically varied with the orientation or shape of the elliptical threshold contours read out from the WPPM fits. However, we did observe a significant negative correlation between the residuals and the magnitude of the validation thresholds (slope = −0.347, <italic>t</italic>(23) = −3.810, <italic>p &lt;</italic> 0.001, <italic>R</italic><sup>2</sup> = 0.387; <xref rid="figS15" ref-type="fig">Figure S15</xref>; <xref ref-type="table" rid="tblS5">Table S5</xref>). As noted earlier, the size of this bias is small compared to the overall range of validation thresholds.</p>
<fig id="figS15" position="float" fig-type="figure">
<label>Figure S15.</label>
    <caption><title>Threshold residuals for a simulated dataset.</title>
        <p>For all panels, color codes for the surface color of the reference stimulus, and the y-axis limits are set to ± the mean of the validation thresholds. (A) Residuals as a function of the absolute angular difference between the major axis of the elliptical threshold contours read out from the WPPM fits and the chromatic direction of the validation condition. (B) Residuals as a function of the aspect ratio (major/minor axis) of the WPPM threshold contours. (C) Residuals as a function of thresholds estimated from validation trials.</p></caption>
<graphic xlink:href="665219v2_figS15.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tblS5" orientation="portrait" position="float">
<label>Table S5.</label>
<caption><title>Linear regression results for the simulated dataset.</title></caption>
<graphic xlink:href="665219v2_tblS5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s11g">
<title>Appendix 5.7: Comparison between the WPPM estimates and the ground truths</title>
<p>To evaluate whether the WPPM readouts systematically deviated from the ground truth, we sampled thresholds over a fine grid of reference locations (15 × 15 points evenly spaced between –0.7 and 0.7 in model space) and compared them with the corresponding ground-truth thresholds. As a comparison metric, we used the Bures-Wasserstein (BW) distance (<xref ref-type="bibr" rid="c5">Bhatia et al., 2019</xref>), which quantifies the dissimilarity between two positive semi-definite covariance matrices, Σ<sub>1</sub> and Σ<sub>2</sub>. Intuitively, it captures the “effort” required to morph one ellipse into another. Mathematically, the BW distance is defined as
<disp-formula id="eqnS13">
<graphic xlink:href="665219v2_eqnS13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The BW distance is non-negative and equals zero only when the two matrices being compared are identical. Smaller distances indicate greater similarity between the threshold ellipses.</p>
<p>The results showed that BW distance generally increased as the reference color moved farther from the achromatic point (<xref rid="figS16" ref-type="fig">Figure S16A</xref>), suggesting that the WPPM has more difficulty accurately capturing large threshold contours in regions with higher internal noise. To provide a benchmark for what constitutes a substantial mismatch, we computed the BW distance between each ground-truth ellipse and a circle with radius being the largest major axis length among all ground-truth ellipses. The maximum of these values served as a reference point (shown as the upper limit of the color bar in <xref rid="figS16" ref-type="fig">Figure S16A</xref>). Overall, the mismatches observed in our simulations were modest— well below the level expected if the model were fundamentally mischaracterizing the threshold shapes.</p>
<fig id="figS16" position="float" fig-type="figure">
<label>Figure S16.</label>
    <caption><title>Deviation of WPPM estimates from the ground truth.</title>
        <p>(A) BW distance between WPPM-estimated thresholds and the ground-truth ellipses. The upper limit of the color map (0.17) corresponds to the maximum BW distance between each ground-truth ellipse and a reference circle whose radius equals the largest major axis length among all ground-truth ellipses. The maximum BW distance between WPPM estimates and the ground truth (0.03) is substantially lower than this reference value. (B) Difference in major axis length between WPPM-readouts and ground-truth ellipses. The colormap limits (±0.17) reflect the ± maximum ground-truth major axis length. Again, the maximum deviation observed (0.03) is small relative to this range.</p></caption>
<graphic xlink:href="665219v2_figS16.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We also examined discrepancies in the estimated major axis lengths. The WPPM showed slight underestimation in the upper region and overestimation in the lower region of the space (<xref rid="figS16" ref-type="fig">Figure S16B</xref>; also obvious in <xref rid="figS13" ref-type="fig">Figure S13C</xref>). Similar to the BW analysis, these deviations were relatively small compared to the overall range of ground-truth values. Together, these results indicate that the WPPM provides a close and robust approximation of the true threshold contours, with only minor local deviations.</p>
</sec>
</sec>
</app>
<app id="app6">
<label>Appendix 6</label>
<sec id="s12">
<title>Comparison with MacAdam ellipses (1942)</title>
<fig id="figS17" position="float" fig-type="figure">
<label>Figure S17.</label>
    <caption><title>Comparison with <xref ref-type="bibr" rid="c62">MacAdam 1942</xref>.</title>
    <p>Left: MacAdam’s original ellipses, enlarged 10× for visualization. Red arrows indicate inferred major axis directions at unsampled reference locations, guessed from nearby ellipses. Right: Threshold ellipses from our measurements, also magnified by 2× for visualization. Triangle: gamut of our monitor; parallelogram: gamut of our isoluminant plane.</p></caption>
<graphic xlink:href="665219v2_figS17.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</app>
<app id="app7">
<label>Appendix 7</label>
<sec id="s13">
<title>Comparison with <xref ref-type="bibr" rid="c29">Danilova &amp; Mollon (2025)</xref></title>
<p>In this section, we compare our measurements with those from <xref ref-type="bibr" rid="c29">Danilova and Mollon 2025</xref> by transforming our results into the chromaticity space used in their study—a scaled version of the MacLeod–Boynton space (<xref ref-type="bibr" rid="c64">MacLeod and Boynton, 1979</xref>). While a direct transformation path exists from our model space to theirs (model space → RGB → LMS → MacLeod–Boynton → scaled MacLeod–Boynton), it assumes that the adaptation point and isoluminant plane are identical between the two studies, which is not the case. To account for these differences, we instead took a detour through the DKL space (<xref ref-type="bibr" rid="c30">Derrington et al., 1984</xref>), where cone-opponent mechanisms are explicitly defined and adaptation is more easily controlled. Specifically, we followed the transformation chain: model space → RGB<sub><italic>us</italic></sub> → LMS<sub><italic>us</italic></sub> → ΔLMS<sub><italic>us</italic></sub> → DKL → ΔLMS<sub><italic>dm</italic></sub> → LMS<sub><italic>dm</italic></sub> →</p>
<p>MacLeod–Boynton → scaled MacLeod–Boynton. Here, the subscript “<italic>us</italic>” refers to values computed using our study’s cone fundamentals, luminosity function and adaptation point, while “<italic>dm</italic>” denotes those based on <xref ref-type="bibr" rid="c29">Danilova and Mollon 2025</xref>. This approach allowed us to approximate how our stimuli would be represented in their perceptual framework, enabling a fair visual comparison of the threshold contours. The comparison reveals a general qualitative agreement between their measurements and ours (<xref rid="figS18" ref-type="fig">Figure S18</xref>).</p>
<fig id="figS18" position="float" fig-type="figure">
<label>Figure S18.</label>
    <caption><title>Comparison with <xref ref-type="bibr" rid="c29">Danilova and Mollon 2025</xref> in the scaled MacLeod–Boynton space.</title>
    <p>Top left: threshold contours from their study (black ellipses), enlarged by 4×. Remaining panels: threshold contours from all participants in our study (colored ellipses; <italic>N</italic> = 8). We sampled a grid of reference points evenly spaced from –0.7 to 0.7 (5 steps) in our model space, read out the corresponding threshold contours, and transformed them into the same scaled MacLeod–Boynton space. The parallelogram indicates the gamut of the isoluminant plane. To reduce visual clutter, ellipses from Danilova &amp; Mollon that fall within our gamut are represented by red arrows indicating only their major axes. For visual comparability, our ellipses are enlarged by 1.5× to roughly match the size of those in their study.</p></caption>
<graphic xlink:href="665219v2_figS18.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</app>
<app id="app8">
<label>Appendix 8</label>
<sec id="s14">
<title>Comparison with Krauskopf &amp; Gegenfurtner (1992)</title>
<p>We compared our threshold estimates with those reported by <xref ref-type="bibr" rid="c56">Krauskopf and Karl 1992</xref>. To do so, we transformed our estimates into the color space used in their measurements through a series of steps. We first read out, for each participant, the threshold contour at the achromatic reference color in the model space, which was then transformed to the DKL space (<xref ref-type="bibr" rid="c30">Derrington et al., 1984</xref>). We then normalized the DKL cardinal axes so that the threshold contour at the achromatic reference had unit length along both axes. This normalized space—referred to here as the stretched DKL space—is the coordinate system in which <xref ref-type="bibr" rid="c56">Krauskopf and Karl 1992</xref> conducted their measurements. Finally, we transformed a set of elliptical threshold contours at other reference locations from our original model space into this stretched DKL space to enable direct comparison (<xref rid="figS19" ref-type="fig">Figure S19</xref> shows the transformation and comparison for a representative participant; <xref rid="figS20" ref-type="fig">Figure S20</xref> shows results for the remaining participants).</p>
<fig id="figS19" position="float" fig-type="figure">
<label>Figure S19.</label>
    <caption><title>Transformation from the model space to a stretched DKL space used in <xref ref-type="bibr" rid="c56">Krauskopf and Karl 1992</xref> for participant CH.</title>
    <p>(A) Model space. Threshold contours were read out in this space based on each participant’s WPPM fit. Notably, our data were collected on a much larger region of the isoluminant plane than they characterized. (B) The intermediate, unstretched DKL space. Transformations between this space and both the model space and the stretched DKL space are affine. (C) Stretched DKL space, in which the cardinal axes of the original DKL space are rescaled such that the threshold at the achromatic reference point is normalized to one.</p></caption>
<graphic xlink:href="665219v2_figS19.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS20" position="float" fig-type="figure">
<label>Figure S20.</label>
    <caption><title>Comparison with <xref ref-type="bibr" rid="c56">Krauskopf and Karl 1992</xref> across participants.</title>
    <p>Top left: original threshold contours reported by <xref ref-type="bibr" rid="c56">Krauskopf and Karl 1992</xref>, reproduced under Creative Commons CC BY-NC-ND 4.0). Remaining panels: threshold contours for the remaining participants, transformed into the stretched DKL space using participant-specific scaling of the cardinal axes. All contours are plotted at their original sizes.</p></caption>
<graphic xlink:href="665219v2_figS20.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</app>
<app id="app9">
<label>Appendix 9</label>
<sec id="s15">
<title>Comparison with CIELab Δ<italic>E</italic> 76, 94, 2000</title>
<p>As briefly described in Appendix 5, we derived threshold contours using CIELab Δ metrics as the ground truth (<xref ref-type="bibr" rid="c82">Robertson et al., 1977</xref>; <xref ref-type="bibr" rid="c65">McDonald and Smith, 1995</xref>; <xref ref-type="bibr" rid="c84">Sharma et al., 2005</xref>). For each reference color and chromatic direction, we applied an affine transformation from model space to RGB space using the transformation matrix described in Appendix 1.3. The resulting RGB values were then converted to CIELab coordinates, using the monitor gray point (<italic>R</italic> = <italic>G</italic> = <italic>B</italic> = 0.5) as the reference white in the XYZ-to-Lab transformation. Threshold points were defined in RGB space as those corresponding to a fixed perceptual distance of Δ<italic>E</italic> = 2.5. These points were then transformed back from RGB to model space, where ellipses were fit to the resulting threshold contours. Comparisons revealed that the iso-distance contours from Δ<italic>E</italic> 94 and Δ<italic>E</italic> 2000 provided reasonable approximations to our model-predicted thresholds (<xref rid="figS21" ref-type="fig">Figure S21</xref> – <xref rid="figS22" ref-type="fig">Figure S22</xref>), with only modest deviations. In contrast, the Δ<italic>E</italic> 76 contours—despite their continued widespread use—diverged substantially from our measured thresholds (<xref rid="figS23" ref-type="fig">Figure S23</xref>).</p>
<fig id="figS21" position="float" fig-type="figure">
<label>Figure S21.</label>
    <caption><title>Comparison with CIELab Δ<italic>E</italic> 94 (<xref ref-type="bibr" rid="c65">McDonald and Smith, 1995</xref>) predictions.</title>
    <p>These are scaled by a factor of 2.5× to approximately match the scale of the measured thresholds in our study, which are shown at their original scale.</p></caption>
<graphic xlink:href="665219v2_figS21.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS22" position="float" fig-type="figure">
<label>Figure S22.</label>
    <caption><title>Comparison with CIELab Δ<italic>E</italic> 2000 (<xref ref-type="bibr" rid="c84">Sharma et al., 2005</xref>) predictions.</title>
    <p>These are scaled by a factor of 2.5× to approximately match the scale of the measured thresholds in our study, which are shown at their original scale.</p></caption>
<graphic xlink:href="665219v2_figS22.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS23" position="float" fig-type="figure">
<label>Figure S23.</label>
    <caption><title>Comparison with CIELab Δ<italic>E</italic> 76 (<xref ref-type="bibr" rid="c82">Robertson et al., 1977</xref>) predictions.</title>
    <p>These are scaled by a factor of 5× to approximately match the scale of the measured thresholds in our study, which are shown at their original scale.</p></caption>
<graphic xlink:href="665219v2_figS23.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</app>
<app id="app10">
<label>Appendix 10</label>
<fig id="figS24" position="float" fig-type="figure">
<label>Figure S24.</label>
    <caption><title>Stimuli and equipment used for calibration.</title>
        <p>(A) The stimulus setup during calibration was identical to that used in the main experiment. The surface color of both the cubic room and the blobby stimulus (shown here as the top-position stimulus) was varied during the calibration procedure. The shaded gray circular region on the stimulus indicates the area measured by the spectroradiometer’s lens. (B) A SpectraScan PR-670 used for all calibration measurements.</p></caption>
<graphic xlink:href="665219v2_figS24.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s16">
<title>Display characterization</title>
<fig id="figS25" position="float" fig-type="figure">
<label>Figure S25.</label>
    <caption><title>Calibration results.</title>
        <p>(A) Gamma functions for red, green and blue primaries. Note that Unity’s internal correction places them above the identity line. (B) Spectral power distributions (SPDs) of the three primaries across a range of intensity levels. (C) The chromaticity of each primaries in the CIE chromaticity diagram at different intensity levels. (D) Normalized SPDs for each primary, showing spectral shape stability across intensity levels. (E) Linearity tests comparing predicted and measured chromaticity and luminance across two independent measurement runs. (F) Deviations from linearity. (G) Effect of the cubic room’s background color on the SPD of the blobby stimulus, showing no detectable influence.</p></caption>
<graphic xlink:href="665219v2_figS25.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS26" position="float" fig-type="figure">
<label>Figure S26.</label>
    <caption><title>Comparison of calibration results across the three blobby stimuli.</title>
        <p>(A) Spectral power distributions (SPDs) for each stimulus location: Ref Cal (bottom right), Cal 2 (bottom left), and Cal 3 (top). (B) Ambient light SPDs measured during calibration. (C) Gamma functions for each primary (red, green, blue) across all three stimulus locations. (D) Differences in normalized output for each pairwise comparison of stimulus locations, plotted separately for each primary. (E) Chromaticity coordinates of each primary in the CIE diagram, shown for all three stimulus locations.</p></caption>
<graphic xlink:href="665219v2_figS26.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS27" position="float" fig-type="figure">
<label>Figure S27.</label>
    <caption><title>Gamma correction.</title>
        <p>(A) Measured gamma functions and their corresponding inverse functions for the red, green, and blue primaries, used to construct the gamma correction lookup table. (B) Gamma functions re-measured after applying the correction in Unity, showing close alignment with the identity line for all three primaries.</p></caption>
<graphic xlink:href="665219v2_figS27.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS28" position="float" fig-type="figure">
<label>Figure S28.</label>
    <caption><title>Comparison between the initial and repeated calibration one month into data collection.</title>
        <p>(A) Spectral power distributions (SPDs) from two calibration sessions at the bottom-right blobby stimulus location: Ref Cal (initial calibration prior to the experiment) and Cal 2 (follow-up calibration). (B) Ambient light SPDs measured during each calibration. (C) Gamma functions for the red, green, and blue primaries across both sessions, with gamma correction applied. (D) Chromaticity coordinates of each primary plotted in the CIE diagram for both calibration runs.</p></caption>
<graphic xlink:href="665219v2_figS28.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s16a">
<title>Appendix 10.1: Calibration of monitor output</title>
<p>Calibration was carried out with three blobby objects arranged in a triangular configuration inside the cubic room (<xref rid="figS24" ref-type="fig">Figure S24A</xref>). A SpectraScan PR-670 radiometer (<xref rid="figS24" ref-type="fig">Figure S24B</xref>), positioned at the same viewing distance as the chin-rest, recorded all measurements (<xref ref-type="bibr" rid="c9">Brainard et al., 2002</xref>).</p>
<p>We first obtained each primary’s gamma function by measuring the screen output at 61 evenly spaced input levels (from 0 to 1) rendered through Unity (v2022.3.24f1) (<xref rid="figS25" ref-type="fig">Figure S25A</xref>). The resulting curves lie above the identity line because Unity internally applies its own assumed gamma exponent when texture values are altered. We also measured the spectral power distributions (SPDs) of the red, green, and blue primaries given different intensity levels (<xref rid="figS25" ref-type="fig">Figure S25B</xref>), and examined the stability of the primaries’ chromaticity in the CIE diagram (<xref rid="figS25" ref-type="fig">Figure S25C</xref>). There was almost no drift in the chromaticities, indicating the monitor’s color output remained stable across intensity levels (<xref rid="figS25" ref-type="fig">Figure S25D</xref>). To evaluate linearity and repeatability, we compared nominal (predicted) versus measured luminance and chromaticity for two independent measurement runs (<xref rid="figS25" ref-type="fig">Figure S25E</xref>). Deviations from linearity were minimal and nearly identical across repeats, confirming reliable reproduction (<xref rid="figS25" ref-type="fig">Figure S25F</xref>). Finally, we tested whether the cubic room’s background color affected the stimulus SPD; no measurable influence was detected (<xref rid="figS25" ref-type="fig">Figure S25G</xref>).</p>
<p>To assess consistency across different locations on the screen, we conducted the same calibration procedure on all three blobby stimuli, one at a time, and compared the primaries and chromaticities. The results showed consistent color behavior of the monitor (<xref rid="figS26" ref-type="fig">Figure S26</xref>), and thus we applied a single gamma correction curve to all three stimuli. This correction was derived from measurements of the bottom-right blobby stimulus. Specifically, we interpolated a gamma table for 4,096 RGB input values using a combination of linear and polynomial fits, from which we derived an inverse gamma function (<xref rid="figS27" ref-type="fig">Figure S27A</xref>). To validate this correction, we repeated the calibration with the gamma correction applied in Unity. The measured output closely aligned with the identity line across all three primaries, indicating accurate correction (<xref rid="figS27" ref-type="fig">Figure S27B</xref>).</p>
<p>Finally, to ensure the gamma correction remained stable over time, we repeated the calibration on the bottom-right stimulus with gamma correction applied approximately one month after data collection. The results confirmed that the correction remained accurate and consistent (<xref rid="figS28" ref-type="fig">Figure S28</xref>).</p>
</sec>
<sec id="s16b">
<title>Appendix 10.2: Assessment of color depth</title>
<p>Color depth measurements were conducted using a single blobby stimulus positioned at the center of the screen (<xref rid="figS29" ref-type="fig">Figure S29A</xref>). This stimulus was originally the top stimulus in the triangular configuration, and the camera view was adjusted to center it on the screen. Additionally, compared to the scene used in the main experiment, the other two blobby stimuli and all cubic room elements were excluded from rendering and thus were not visible. A Klein K-10A colorimeter (<xref rid="figS29" ref-type="fig">Figure S29B</xref>), placed directly in front of the monitor display without any distance, was used to make the measurements. Specifically, we tested RGB values ranging from 511/1023 to 541/1023, in increments of 1/1023.</p>
<fig id="figS29" position="float" fig-type="figure">
<label>Figure S29.</label>
    <caption><title>Stimuli and equipment used for calibration.</title>
        <p>(A) The stimulus setup during calibration was identical to that used in the main experiment. The surface color of both the cubic room and the blobby stimulus (shown here as the top-position stimulus) was varied across trials during the calibration procedure. The shaded gray circular region on the stimulus indicates the area measured by the spectroradiometer’s lens. (B) A SpectraScan PR-670 used for all calibration measurements.</p></caption>
<graphic xlink:href="665219v2_figS29.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS30" position="float" fig-type="figure">
<label>Figure S30.</label>
    <caption><title>Evidence of spatial dithering by Unity’s standard shader when the surface texture of the stimulus is being modified.</title>
        <p>(A) Spatial dithering by Unity’s standard shader is suggested by comparing the luminance measurements from the Klein K-10A (averaged across a circular region on the blobby object) with the RGB values stored in the frame buffer. The measured luminance shows small incremental changes as the RGB settings increase in steps of 1/1023. These measurements are consistent with what we obtain by averaging over pixels in a saved image of the frame buffer (saved from Unity in .exr format). The averaged pixel values exhibit 10-bit quantization even though individual pixel values exhibit 8-bit quantization. (B) Top row: mean R channel values averaged vertically within a horizontal slice of the blobby object. Bottom row: differences in the R channel values between the minimum target R channel setting and each of the rest settings. Different shades of gray represent different target R settings. For illustration, only a portion of the horizontal slice is shown, and solid lines in the bottom row are scaled by a factor of 0.1. Dashed lines: the mean difference averaged across all pixels within each slice.</p></caption>
<graphic xlink:href="665219v2_figS30.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Each stimulus was displayed for 5 seconds, and the RGB values from the first frame of the frame buffer were saved in EXR format. We then compared the average RGB values across the surface of the blobby object (extracted from the EXR files) to the luminance measured throughout the full stimulus presentation. Although individual pixels exhibited quantization below 10-bit precision, the mean luminance increased with each 1/1023 increment, rather than in a staircase pattern. A similarly smooth progression was observed in the average R, G, and B channel values, with the R channel shown as an example in <xref rid="figS30" ref-type="fig">Figure S30A</xref>.</p>
<p>To better understand how Unity and our video chain achieved this behavior, we analyzed horizontal slices of pixel values from the EXR files. When extracting a very thin slice—just one pixel in height—the individual pixel values exhibited staircase-like changes, consistent with 8-bit quantization. However, as we increased the height of the horizontal slice, the averaged channel values became progressively smoother. These results suggest that Unity achieves effective 10-bit color depth through internal spatial dithering (<xref rid="figS30" ref-type="fig">Figure S30B</xref>).</p>
</sec>
</sec>
</app>
<app id="app11">
<label>Appendix 11</label>
<sec id="s17">
<title>Differentiable Monte Carlo Scheme</title>
<p>Recall from the main text that the log likelihood function implied by the WPPM observer model can be written in terms of
<disp-formula id="eqnS14">
<graphic xlink:href="665219v2_eqnS14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
which has no simple closed form solution and must be estimated by Monte Carlo simulation. This quantity of interest takes the form of a cumulative distribution function <italic>g</italic>(<italic>u</italic>) = Pr[<italic>v</italic> ≤ <italic>u</italic>] for some random variable <italic>v</italic> and scalar constant <italic>u</italic>. In this section, we describe how to approximate the log likelihood in a manner that is compatible with automatic differentiation libraries, which enables gradient-based optimization of the log posterior density.</p>
<p>Let <italic>P</italic><sub><italic>θ</italic></sub> denote some probability distribution parameterized by <italic>θ</italic>. Given <italic>n</italic> independent and identically distributed random variables, <italic>v</italic><sub>1</sub>, …, <italic>v</italic><sub><italic>n</italic></sub> ~ <italic>P</italic><sub><italic>θ</italic></sub>, we would like to form an estimate of the cumulative distribution function, <italic>g</italic>(<italic>u</italic>) = Pr[<italic>v</italic> ≤ <italic>u</italic>] where <italic>v</italic> ~ <italic>P</italic><sub><italic>θ</italic></sub>. A simple and well-known estimate is empirical cumulative distribution function:
<disp-formula id="eqnS15">
<graphic xlink:href="665219v2_eqnS15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>1</bold>[⋅] is the indicator function—i.e. <bold>1</bold>[<italic>A</italic>] evaluates to one if the event <italic>A</italic> occurs and evaluates to zero otherwise. In many respects, this is a perfectly fine estimator. For example, the celebrated Dvoretzky–Kiefer–Wolfowitz inequality (<xref ref-type="bibr" rid="c31">Dvoretzky et al., 1956</xref>) states that this estimate converges exponentially fast to the true cumulative distribution function as <italic>n</italic> → ∞.</p>
<p>In our setting, we would like to not only evaluate <italic>g</italic>(<italic>u</italic>) for any given <italic>u</italic>, but to also evaluate <italic>∂g</italic>(<italic>u</italic>)/<italic>∂θ</italic><sub><italic>j</italic></sub> for all parameters <italic>θ</italic><sub>1</sub>, …, <italic>θ</italic><sub><italic>J</italic></sub> that define the underlying distribution <italic>P</italic><sub><italic>θ</italic></sub>. <bold><italic>Equation S15</italic></bold> provides an estimate of <italic>g</italic>(<italic>u</italic>) but it is unfortunately not differentiable with respect to <italic>v</italic><sub>1</sub>, …, <italic>v</italic><sub><italic>n</italic></sub> because <bold>1</bold>[<italic>v</italic><sub><italic>i</italic></sub> ≤ <italic>u</italic>] is a discontinuous step as a function of <italic>u</italic>. A straightforward and intuitive solution is to replace this step function with a smooth sigmoid function. We formalize this approach below, showing that it can be motivated by forming a smoothed estimate of the underlying density function.</p>
<p>Specifically, let <italic>K</italic>(<italic>v</italic>) denote a smooth, nonnegative function that integrates to one and satisfies <italic>K</italic>(<italic>v</italic>) = <italic>K</italic>(−<italic>v</italic>). Suppose that <italic>P</italic><sub><italic>θ</italic></sub> has a density function <italic>f</italic> (<italic>v</italic>). Then, given <italic>v</italic><sub>1</sub>, …, <italic>v</italic><sub><italic>n</italic></sub> ~ <italic>P</italic><sub><italic>θ</italic></sub> we can estimate the density function as:
<disp-formula id="eqnS16">
<graphic xlink:href="665219v2_eqnS16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>h &gt;</italic> 0 is a user-specified hyperparameter called the bandwidth. <bold><italic>Equation S16</italic></bold> is known as a <italic>kernel density estimate</italic> (<xref ref-type="bibr" rid="c95">Wasserman, 2006</xref>). Asymptotically, <inline-formula id="inline-eqn-11"><inline-graphic xlink:href="665219v2_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula> approaches the true density function <italic>f</italic> as <italic>n</italic> → ∞ and <italic>h</italic> → 0. Intuitively, larger values of <italic>h</italic> lead to smoother density estimates, which is preferable in sample-limited (i.e. small <italic>n</italic>) regimes.</p>
<p>Now define:
<disp-formula id="eqnS17">
<graphic xlink:href="665219v2_eqnS17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
which is a smooth sigmoid function centered at <italic>v</italic><sub><italic>i</italic></sub>, and consider the following estimate of the cumulative distribution function:
<disp-formula id="eqnS18">
<graphic xlink:href="665219v2_eqnS18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Notice that in the limit of <italic>h</italic> → 0, we recover the empirical cumulative distribution estimator <italic>ĝ</italic> = <italic>ĝ</italic> <sub>emp</sub> because, in this limit, we have that <inline-formula id="inline-eqn-12"><inline-graphic xlink:href="665219v2_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. We can further justify <bold><italic>Equation S18</italic></bold> as a reasonable estimator of <italic>g</italic> by recognizing it as the integral of the density estimate in <bold><italic>Equation S16</italic></bold>. That is,
<disp-formula id="eqnS19">
<graphic xlink:href="665219v2_eqnS19.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqnS20">
<graphic xlink:href="665219v2_eqnS20.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Our refined estimator <inline-formula id="inline-eqn-13"><inline-graphic xlink:href="665219v2_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is clearly differentiable whenever we choose <italic>K</italic>(<italic>v</italic>) to be a smoothly differentiable function. In our model fitting routine, we chose <italic>K</italic>(<italic>v</italic>) to be the density of a standard logistic distribution:
<disp-formula id="eqnS21">
<graphic xlink:href="665219v2_eqnS21.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This smoothing kernel has heavy tails, which we reasoned would enable numerically stable autodifferentiation routines even when <italic>h</italic> is chosen to be small. Another feature is that the integrated density is the well-known <italic>logistic function</italic>:
<disp-formula id="eqnS22">
<graphic xlink:href="665219v2_eqnS22.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
which is familiar and easy to compute.</p>
</sec>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108943.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Huxlin</surname>
<given-names>Krystel R</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>University of Rochester</institution>
</institution-wrap>
<city>Rochester</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study describes a novel Bayesian psychophysical approach that efficiently measures how well humans can discriminate between colors across the entire isoluminant plane. The evidence was considered <bold>compelling</bold>, as it included successful model validation against hold-out data and published datasets. This approach could prove to be of use to color vision scientists, as well as to those who use computational psychophysics and attempt to model perceptual stimulus fields with smooth variations over coordinate spaces.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108943.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper presents an ambitious and technically impressive attempt to map how well humans can discriminate between colours across the entire isoluminant plane. The authors introduce a novel Wishart Process Psychophysical Model (WPPM) - a Bayesian method that estimates how visual noise varies across colour space. Using an adaptive sampling procedure, they then obtain a dense set of discrimination thresholds from relatively few trials, producing a smooth, continuous map of perceptual sensitivity. They validate their procedure by comparing actual and predicted thresholds at an independent set of sample points. The work is a valuable contribution to computational psychophysics and offers a promising framework for modelling other perceptual stimulus fields more generally.</p>
<p>Strengths:</p>
<p>The approach is elegant and well-described (I learned a lot!), and the data are of high quality. The writing throughout is clear, and the figures are clean (elegant in fact) and do a good job of explaining how the analysis was performed. The whole paper is tremendously thorough, and the technical appendices and attention to detail are impressive (for example, a huge amount of data about calibration, variability of the stim system over time, etc). This should be a touchstone for other papers that use calibrated colour stimuli.</p>
<p>Weaknesses:</p>
<p>Overall, the paper works as a general validation of the WPPM approach. Importantly, the authors validate the model for the particular stimuli that they use by testing model predictions against novel sample locations that were not part of the fitting procedure (Figure 2). The agreement is pretty good, and there is no overall bias (perhaps local bias?), but they do note a statistically-significant deviation in the shape of the threshold ellipses. The data also deviate significantly from historical measurements, and I think the paper would be considerably stronger with additional analyses to test the generality of its conclusions and to make clearer how they connect with classical colour vision research. In particular, three points could use some extra work:</p>
<p>(1) Smoothness prior.</p>
<p>
The WPPM assumes that perceptual noise changes smoothly across colour space, but the degree of smoothness (the eta parameter) must affect the results. I did not see an analysis of its effects - it seems to be fixed at 0.5 (line 650). The authors claim that because the confidence intervals of the MOCS and the model thresholds overlap (line 223), the smoothing is not a problem, but this might just be because the thresholds are noisy. A systematic analysis varying this parameter (or at least testing a few other values), and reporting both predictive accuracy and anisotropy magnitude, would clarify whether the model's smoothness assumption is permitting or suppressing genuine structure in the data. Is the gamma parameter also similarly important? In particular, does changing the underlying smoothness constraint alter the systematic deviation between the model and the MOCS thresholds? The authors have thought about this (of course! - line 224), but also note a discrepancy (line 238). I also wonder if it would be possible to do some analysis on the posterior, which might also show if there are some regions of color space where this matters more than others? The reason for doing this is, in part, motivated by the third point below - it's not clear how well the fits here agree with historical data.</p>
<p>(2) Comparison with simpler models. It would help to see whether the full WPPM is genuinely required. Clearly, the data (both here and from historical papers) require some sort of anisotropy in the fitting - the sensitivities decrease as the stimuli move away from the adaptation point. But it's &gt;not&lt; clear how much the fits benefit from the full parameterisation used here. Perhaps fits for a small hierarchy of simpler models - starting with isotropic Gaussian noise (as a sort of 'null baseline') and progressing to a few low-dimensional variants - would reveal how much predictive power is gained by adding spatially varying anisotropy. This would demonstrate that the model's complexity is justified by the data.</p>
<p>(3) Quantitative comparison to historical data. The paper currently compares its results to MacAdam, Krauskopf &amp; Karl, and Danilova &amp; Mollon only by visual inspection. It is hard to extract and scale actual data from historical papers, but from the quality of the plotting here, it looks like the authors have achieved this, and so quantitative comparisons are possible. The MacAdam data comparisons are pretty interesting - in particular, the orientations of the long axes of the threshold ellipses do not really seem to line up between the two datasets - and I thought that the orientation of those ellipses was a critical feature of the MacAdam data. Quantitative comparisons (perhaps overall correlations, which should be immune to scaling issues, axis-ratio, orientation, or RMS differences) would give concrete measures of the quality of the model. I know the authors spend a lot of time comparing to the CIE data, and this is great.... But re-expressing the fitted thresholds in CIE or DKL coordinates, and comparing them directly with classical datasets, would make the paper's claims of &quot;agreement&quot; much more convincing.</p>
<p>Overall, this is a creative and technically sophisticated paper that will be of broad interest to vision scientists. It is probably already a definitive methods paper showing how we can sample sensitivity accurately across colour space (and other visual stimulus spaces). But I think that until the comparison with historical datasets is made clear (and, for example, how the optimal smoothness parameters are estimated), it has slightly less to tell us about human colour vision. This might actually be fine - perhaps we just need the methods?</p>
<p>Related to this, I'd also note that the authors chose a very non-standard stimulus to perform these measurements with (a rendered 3D 'Greebley' blob). This does have the advantage of some sort of ecological validity. But it has the significant &gt;disadvantage&lt; that it is unlike all the other (much simpler) stimuli that have been used in the past - and this is likely to be one of the reasons why the current (fitted) data do not seem to sit in very good agreement with historical measurements.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108943.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Hong et al. present a new method that uses a Wishart process to dramatically increase the efficiency of measuring visual sensitivity as a function of stimulus parameters for stimuli that vary in a multidimensional space. Importantly, they have validated their model against their own hold-out data and against 3 published datasets, as well as against colour spaces aimed at 'perceptual uniformity' by equating JNDs. Their model achieves high predictive success and could be usefully applied in colour vision science and psychophysics more generally, and to tackle analogous problems in neuroscience featuring smooth variation over coordinate spaces.</p>
<p>Strengths:</p>
<p>(1) This research makes a substantial contribution by providing a new method to very significantly increase the efficiency with which inferences about visual sensitivity can be drawn, so much so that it will open up new research avenues that were previously not feasible. Secondly, the methods are well thought out and unusually robust. The authors made a lot of effort to validate their model, but also to put their results in the context of existing results on colour discrimination, transforming their results to present them in the same colour spaces as used by previous authors to allow direct comparisons. Hold-out validation is a great way to test the model, and this has been done for an unusually large number of observers (by the standards of colour discrimination research). Thirdly, they make their code and materials freely available with the intention of supporting progress and innovation. These tools are likely to be widely used in vision science, and could of course be used to address analogous problems for other sensory modalities and beyond.</p>
<p>Weaknesses:</p>
<p>It would be nice to better understand what constraints the choice of basis functions puts on the space of possible solutions. More generally, could there be particular features of colour discrimination (e.g., rapid changes near the white point) that the model captures less well? The substantial individual differences evident in Figure S20 (comparison with Krauskopf and Gegenfurtner, 1992) are interesting in this context. Some observers show radial biases for the discrimination ellipses away from the white point, some show biases along the negative diagonal (with major axes oriented parallel to the blue-yellow axis), and others show a mixture of the two biases. Are these genuine individual differences, or could the model be performing less accurately in this desaturated region of colour space?</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108943.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study presents a powerful and rigorous approach for characterizing stimulus discriminability throughout a sensory manifold, and is applied to the specific context of predicting color discrimination thresholds across the chromatic plane.</p>
<p>Strengths:</p>
<p>Color discrimination has played a fundamental role in studies of human color vision and for color applications, but as the authors note, it remains poorly characterized. The study leverages the assumption that thresholds should vary smoothly and systematically within the space, and validates this with their own tests and comparisons with previous studies.</p>
<p>Weaknesses:</p>
<p>The paper assumes that threshold variations are due to changes in the level of intrinsic noise at different stimulus levels. However, it's not clear to me why they could not also be explained by nonlinearities in the responses, with fixed noise. Indeed, most accounts of contrast coding (which the study is at least in part measuring because the presentation kept the adapt point close to the gray background chromaticity, and thus measured increment thresholds), assume a nonlinear contrast response function, which can at least as easily explain why the thresholds were higher for colors farther from the gray point. It would be very helpful if a section could be added that explains why noise differences rather than signal differences are assumed and how these could be distinguished. If they cannot, then it would be better to allow for both and refer to the variation in terms of S/N rather than N alone.</p>
<p>Related to this point, the authors note that the thresholds should depend on a number of additional factors, including the spatial and temporal properties and the state of adaptation. However, many of these again seem to be more likely to affect the signal than the noise.</p>
<p>An advantage of the approach is that it makes no assumptions about the underlying mechanisms. However, the choice to sample only within the equiluminant plane is itself a mechanistic assumption, and these could potentially be leveraged for deciding how to sample to improve the characterization and efficiency. For example, given what we know about early color coding, would it be more (or less) efficient to select samples based on a DKL space, etc?</p>
</body>
</sub-article>
</article>