<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">102840</article-id>
<article-id pub-id-type="doi">10.7554/eLife.102840</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102840.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>PointTree: Automatic and accurate reconstruction of long-range axonal projections of single-neuron</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Cai</surname>
<given-names>Lin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fan</surname>
<given-names>Taiyu</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Qu</surname>
<given-names>Xuzhong</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Ying</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gou</surname>
<given-names>Xianyu</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Quanwei</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Feng</surname>
<given-names>Weihua</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cao</surname>
<given-names>Tingting</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lv</surname>
<given-names>Xiaohua</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Xiuli</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Huang</surname>
<given-names>Qing</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8393-4292</contrib-id>
<name>
<surname>Quan</surname>
<given-names>Tingwei</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>quantingwei@hust.edu.cn</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zeng</surname>
<given-names>Shaoqun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03c9ncn37</institution-id><institution>Britton Chance Center for Biomedical Photonics, Wuhan National Laboratory for Optoelectronics-Huazhong University of Science and Technology</institution></institution-wrap>, <city>Wuhan</city>, <country>China</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00p991c53</institution-id><institution>MoE Key Laboratory for Biomedical Photonics, Collaborative Innovation Center for Biomedical Engineering, School of Engineering Sciences, Huazhong University of Science and Technology</institution></institution-wrap>, <city>Wuhan</city>, <country>China</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01jxjav08</institution-id>
<institution>School of Computer Science &amp; Engineering, Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology</institution></institution-wrap>, <city>Wuhan</city>, <country>China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Naud</surname>
<given-names>Richard</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Ottawa</institution>
</institution-wrap>
<city>Ottawa</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-11-11">
<day>11</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP102840</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-09-20">
<day>20</day>
<month>09</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-09-23">
<day>23</day>
<month>09</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.09.23.614432"/>
</event>
</pub-history>
<permissions>
<copyright-statement>Â© 2024, Cai et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Cai et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-102840-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Single-neuron axonal projections reveal the route map of neuron output and provide a key cue for understanding how information flows across the brain. Reconstruction of single-neuron axonal projections requires intensive manual operations in tens of terabytes of brain imaging data, and is highly time-consuming and labor-intensive. The main issue lies in the need for precise reconstruction algorithms to avoid reconstruction errors, yet current methods struggle with densely distributed axons, focusing mainly on skeleton extraction. To overcome this, we introduce a point assignment-based method that uses cylindrical point sets to accurately represent axons and a minimal information flow tree model to suppress the snowball effect of reconstruction errors. Our method successfully reconstructs single-neuron axonal projections across hundreds of GBs images with an average of 80% F1-score, while current methods only provide less than 40% F1-score reconstructions from a few hundred MBs images. This huge improvement is helpful for high-throughput mapping of neuron projections.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Neuronal axons in general project to different brain regions, and their projection distribution is an essential cue for neuron type identification, neuronal circuit construction, and deeper insight into how information flows in the brain<sup><xref ref-type="bibr" rid="c1">1</xref>-<xref ref-type="bibr" rid="c4">4</xref></sup>. Advances in optical imaging and molecular labeling techniques<sup><xref ref-type="bibr" rid="c5">5</xref>-<xref ref-type="bibr" rid="c10">10</xref></sup> have allowed us to observe the entire mouse brain at single-axon resolution, and provided the database for the study of neuronal projection patterns<sup><xref ref-type="bibr" rid="c11">11</xref>-<xref ref-type="bibr" rid="c18">18</xref></sup>. However, the reconstruction of these long-range projected axons still requires frequent manual manipulation in tens of TBs volumetric images<sup><xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c19">19</xref>-<xref ref-type="bibr" rid="c22">22</xref></sup>, which severely hinders high-throughput acquisition of neuronal projection patterns<sup><xref ref-type="bibr" rid="c23">23</xref></sup>.</p>
<p>The difficulties in reconstructing the long-range projections of neurons are as follows. On the one hand, while molecular labeling techniques can shed light on a very small fraction of neurons, a significant fraction of neuronal axons are still densely distributed due to the morphological complexity of neurons. The identification of densely distributed axons is considered an open problem in the field<sup><xref ref-type="bibr" rid="c23">23</xref>-<xref ref-type="bibr" rid="c25">25</xref></sup>, which still has no good solution. On the other hand, during neuron reconstruction, reconstruction errors accumulate and a single reconstruction error can result in an entire branch being connected to other neurons or missing<sup><xref ref-type="bibr" rid="c26">26</xref></sup>. Therefore, effective large-scale reconstruction of neurons requires extremely high identification accuracy of dense axons. The contradictions between these two aspects seem hard to reconcile.</p>
<p>The current neuron reconstruction framework focuses on how to accurately extract skeletons and establish the connections between skeletons<sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c27">27</xref></sup>. The BigNeuron project<sup><xref ref-type="bibr" rid="c28">28</xref></sup> conducts a systematic evaluation of 35 automatic neuron reconstruction algorithms, all of which are based on tracing neurite skeletons and can be divided into two categories: local and global approaches. In the local approach<sup><xref ref-type="bibr" rid="c29">29</xref>-<xref ref-type="bibr" rid="c32">32</xref></sup>, the localization of the next skeleton point position requires one to compute the signal anisotropy of the image region near the current skeleton point. Localization errors typically occur when this image region includes other neurite signals. The global approach<sup><xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup> first generates multiple seed points that are commonly located at the neurite centerline, and then establishes connections between these seed points for generating the neurite skeleton. This connection relies mainly on spatial location information, resulting in densely distributed neurites being connected to each other. We also note that deep learning is widely used in neuron reconstruction<sup><xref ref-type="bibr" rid="c35">35</xref>-<xref ref-type="bibr" rid="c38">38</xref></sup>, mostly to segment image regions of neurons and enhance the signal intensity in the segmented regions, which helps in reducing the reconstruction error. However, in the ideal case where all neurite centers are identified and their signals are enhanced, these reconstruction methods based on skeleton extraction still suffer from many errors (Fig.S1).</p>
<p>To address the problem of error accumulation during neuron reconstruction, it is common practice to utilize statistical information of neuron morphology, such as the angle between two neurites, to identify and remove spurious connections between the reconstructed neurites. This strategy<sup><xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup> achieves 80% reconstruction accuracy from GB-scale images under certain constrains. First, for most neurites, their terminals and junctions require to be accurately identified, which is used to calculate the angle between two neurites and to make neuronal morphological statistics available. Second, cell bodies are required as critical information to remove some links between the reconstructed neurites to ensure that each cell body can be mapped to the root node of a single tree structure. However, for long-range axonal reconstruction across hundreds of GB-scale images, the strategy is not effective to eliminate the accumulation of errors due to factors such as the position of the axon at a distance from the soma, and slight morphological differences between axon junction and termination. Current long-range projection reconstruction methods are semi-automatic and require substantial human intervention<sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c40">40</xref></sup>.</p>
<p>Here, we propose a new neuron reconstruction method called PointTree, which aims at how to assign foreground points in neuronal images to their own neurons. In the workflow, we design a constrained Gaussian clustering method to partition the foreground region of a neuronal image into a series of columnar regions whose centerline belongs to only a single neurite. This operation essentially eliminates the interference of different neurites in the dense reconstruction. In addition, a single columnar region is characterized by a minimal envelope ellipsoid for constructing connections between columnar regions, which forms the neurite shape. Based on this reconstruction, we design a minimal information flow tree model to suppress the cumulative reconstruction error. Using the proposed method, we successfully achieve accurate reconstruction of long-range projections of neurons across hundreds of gigabytes of volumetric image.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The architecture and principles of PointTree</title>
<p>In the design of PointTree, we have developed a series of optimization problems to assign foreground points in data blocks to their respective neurites. Firstly, the segment network is utilized for each data block to obtain foreground points. Subsequently, we apply a constrained Gaussian clustering method<sup><xref ref-type="bibr" rid="c41">41</xref></sup> to partition the foreground points into columnar regions and determine their geometrical parameters by solving the minimum-volume covering ellipsoids problem<sup><xref ref-type="bibr" rid="c42">42</xref></sup>. Using these geometrical parameters, we construct a 0-1 assignment problem<sup><xref ref-type="bibr" rid="c43">43</xref></sup> to establish links between these columnar regions. Finally, skeletons are extracted from these linked columnar regions to reduce data redundancy by using region growing<sup><xref ref-type="bibr" rid="c44">44</xref></sup>. The key procedures for neuron reconstruction are presented in <xref rid="fig1" ref-type="fig">Figure 1A</xref>.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Summary and principle of PointTree.</title>
<p>(<bold>A</bold>) The reconstruction procedure of PointTree involves the generation, clustering, and connection of foreground points (the first row). Within this procedure, three optimization problems are designed to allocate the foreground points into their respective neurites (the second row). (<bold>B</bold>) Schematic diagram of information flow score calculation. In a neurite branch with a fixed root node (green circle), the information flow score is calculated based on the assumption that a neurite has few directional changes. The assumption determines the neurite directly connecting to the root node (red), resulting in two branch angles used to calculate the information flow score. (<bold>C</bold>) Statistical analysis of the consistency between the minimum information flow and the real situation. For 208 neurite branches, the information flow scores are calculated as ground truth according to their manually determined skeletons and root nodes. These scores are then displayed in ascending order. The root nodes of neurite branches are changed to generate both maximum and minimum information flow scores. (<bold>D</bold>) One neurite branch is decomposed into two by minimizing the total information flow scores. (<bold>E</bold>) Performance of different methods on separating closely paralleled neurites. In PointTree, a single neurite is represented by a series of ellipsoids whose centerlines are not simultaneously located within different neurites. They are connected using ellipsoid shape which results in perfect reconstruction (Left). However, skeleton-based methods fail to separate two closely paralleled neurites due to interference from other signals (Red circle in middle) or connections being interfered with by another neighboring skeleton point (Red circle in right).</p></caption>
<graphic xlink:href="614432v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In addition, PointTree employed the statistical prior information to reduce the reconstruction errors. At the branching point (node) of the neurites, it can be divided into three segments of neurite skeletons. The segment entering the node forms two angles with the other two segments exiting the node respectively. The smaller angle, called the node angle, corresponds to the segment that serves as part of a single neurite (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). In this way, we can identify the single complete neurite and its corresponding node angles. The skeleton of the neurite is generally smooth, with very few sudden directional changes and even fewer at the nodes. So, the node angles should be as small as possible. For neuronal branches, the node angles are uniquely determined when the root node is given, and the sum of the negative cosine of these node angles expressed by information flow value is small when the root node is correctly identified. This rule is defined as minimal information flow tree (MIFT).</p>
<p>In image blocks of densely distributed neurites, we used semi-automatic software<sup><xref ref-type="bibr" rid="c21">21</xref></sup> extracting 208 neuronal branches and identifying their root nodes, and calculated their information flow values, i.e., the ground-truth values. We looped through all possible structure of these branches by changing the root node in order to compute the maximum and minimum information flow scores (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). It is evident that, for most neuronal branches, the ground-truth values of the information flow achieve the minimum value, suggesting that MIFT rule is reasonable. We utilized MIFT to modify skeleton structure and remove spurious connections between reconstructed neurites (<xref rid="fig1" ref-type="fig">Figure 1D</xref> and Fig.S2), both for reconstructions within individual blocks and for the fused reconstruction in adjacent blocks.</p>
<p>PointTree has the capability to separate densely distributed neurites. When dealing with two parallel neurites in close proximity to each other, their shapes can be represented by a series of columnar regions (The left panels of <xref rid="fig1" ref-type="fig">Figure 1E</xref>). We have modified the Gaussian clustering algorithm by constraining the estimated mean and covariance parameters so that the cluster shape approaches a columnar shape. Additionally, foreground points within the same cluster are connected to each other. These two features ensure that the central line in the columnar region belongs to only a single neurite, which is crucial for separating densely packed neurites. Furthermore, we utilize the minimum volume covering ellipsoid to extract shape information of the columnar regions for constructing their connections. These designs enable PointTree to successfully reconstruct packed neurites. In contrast, skeleton-based local methods rely on determining the position of the next skeleton point based on the shape anisotropy of the region. This often leads to localization errors when there are two neurite image signals within a region (The middle panels of <xref rid="fig1" ref-type="fig">Figure 1E</xref>). When it comes to skeleton-based global methods, although seed points can be located at individual neurite centers, accurately constructing connections between these seed points proves challenging due to the reliance on distance between points and susceptibility to interference from densely distributed neurites. (The right panels of <xref rid="fig1" ref-type="fig">Figure 1E</xref>).</p>
</sec>
<sec id="s2b">
<title>The merits of PointTree in dense reconstruction</title>
<p>In dense reconstruction, one of the main concerns is how well to separate densely distributed neurites which behaves as crossover and closely paralleled neurites. These neurites can be manually identified by visualization with different view angles (Fig.S3). We compared PointTree with several skeleton-based methods such as neuTube<sup><xref ref-type="bibr" rid="c45">45</xref></sup>, PHDF<sup><xref ref-type="bibr" rid="c46">46</xref></sup>, NGPST<sup><xref ref-type="bibr" rid="c39">39</xref></sup> and MOST<sup><xref ref-type="bibr" rid="c47">47</xref></sup> in performing this task. We manually labeled the locations where neurites are crossover or closely parallel from five 256Ã256Ã256 image blocks. For fair comparison, all methods are performed on segmented images derived from the segmentation network. <xref rid="fig2" ref-type="fig">Figure 2A</xref> illustrates the process of separation of crossover and closely paralleled neurites. PointTree can successfully separate the densely distributed neurites in a range of 71.4 % and 91.7%, while these skeleton-based methods only separate 25.0% densely distributed neurites (<xref rid="fig2" ref-type="fig">Figure 2B</xref>) at most. We also present the comparison of PointTree and other methods on some reconstruction examples in which multi crossover neurites (<xref rid="fig2" ref-type="fig">Figure 2C</xref>) and closely paralleled neurites are involved. PointTree provides the perfect reconstruction while other methods fail to reconstruct these neurites.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Performance of PointTree on crossover and closely paralleled neurites.</title>
<p>(<bold>A</bold>) The reconstruction process of crossover and closely paralleled neurites. (<bold>B</bold>) Quantitative evaluation of PointTree and several skeleton-based methods on identifying closely distributed neurites. The box plots present the statistical information in which the horizontal line in the box, the lower and upper borders of the box represent the median value, the first quartile (Q1) and the third quartile (Q3) respectively. The vertical black lines indicate 1.5 Ã IQR. (<bold>C</bold>) Three reconstruction examples derived from PointTree and several skeleton-based methods.</p></caption>
<graphic xlink:href="614432v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Furthermore, we present the quantitative results derived from PointTree and five widely used skeleton-based reconstruction methods. including APP2, neuTube, NGPST, PHDF, MOST. Eight 256Ã256Ã256 image blocks that include many densely distributed neurites are of the testing dataset. All reconstruction algorithms are performed on the segmentation images of these testing dataset. We give the intuitive reconstruction comparisons (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). PointTree provides the reconstruction close to the ground truth. The skeleton-based methods generate lots of reconstruction errors and incorrectly combine multi neurites into a single branch. The quantitative reconstructions suggest that PointTree is far superior to skeleton-based methods (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). For PointTree, the average precision is above 90%, both recall and F1-score are above 85%. The skeleton-based methods cannot provide the good solution to separate the densely neurites. The F1-score of these reconstructions ranges from 30% to 40%, which indicates the ineffective reconstructions.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Comparison of reconstruction methods on image blocks containing densely distributed neurites.</title>
<p>(<bold>A</bold>) Comparison of reconstruction performance among six methods, including PointTree, NGPST, neuTube, APP2, PHDF, and MOST. Individual neurite branches are delineated in different colors. (<bold>B</bold>) Quantitative evaluation of reconstruction performance using precision, recall, and F1-score. The box plots display these three evaluation indexes (n=8). In the box, the horizontal line represents the median value. The box shows the interquartile range (IQR) from the first quartile (Q1) to the third quartile (Q3). The vertical lines indicate 1.5Ã IQR.</p></caption>
<graphic xlink:href="614432v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Restrain error accumulation in the reconstruction</title>
<p>In order to achieve accurate axon reconstruction, it is essential to effectively suppress the snowballing accumulation of reconstruction errors. The performance of the minimal information flow tree (MIFT) in retraining the reconstruction errors is evaluated in this study. <xref rid="fig4" ref-type="fig">Figure 4A</xref> presents six 512Ã512Ã512 image blocks and their reconstructions using PointTree in the first column. The reconstruction fusing procedure is then performed on these axonal reconstructions (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). By employing MIFT to revise the reconstructions and remove false connections between axons, reasonable reconstructions are achieved. In contrast, when the same fusion procedure is conducted without MIFT to revise the reconstruction, almost all axons are incorrectly connected together (Bottom-right panel in <xref rid="fig4" ref-type="fig">Figure 4A</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Minimal information flow tree effectively restrains the accumulation of reconstruction errors.</title>
<p>(<bold>A</bold>) Reconstruction comparisons in the fusion process with MIFT and without MIFT are shown. Both image blocks and neurites reconstructions are displayed using maximum projection along the z-direction. Two fusion procedures are performed, and the final fusion reconstructions are presented in the third column. (<bold>B</bold>) The variation in reconstruction accuracy during the fusion process with MIFT and without MIFT is illustrated. Blue points represent the initial reconstruction accuracy from six image blocks, while green points and red points denote the merged reconstruction accuracy with MIFT and without MIFT, respectively. The squares represent the mean values of the evaluation indexes. (<bold>C</bold>) The skeletons of three neurite branches from the final merged reconstructions with MIFT are shown. Additionally, corresponding ground-truth reconstructions and reconstruction evaluations are also presented.</p></caption>
<graphic xlink:href="614432v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We furthermore measure the enhancement in the reconstruction accuracy achieved by MIFT (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). For the initial reconstructions from six image blocks, the average of F1-score is about 0.86. By using MIFT, the average of F1-score is above 0.8 for the reconstructions from two image blocks which are generated with the first fusion. In the second fusion (Top-right panel in <xref rid="fig4" ref-type="fig">Figure 4A</xref>), F1-score still keeps 0.79. In contrast, without MIFT, the first fusion leads to a drop of about F1-score of 0.3. After the second fusion, F1 score is less than 0.2. We also present some reconstruction examples after two fusions in <xref rid="fig4" ref-type="fig">Figure 4C</xref>, which are close to the ground truth. These results suggest that MIFT model take consideration of the proper structure of axons and thus can restrain the error communications in the reconstruction fusion process.</p>
</sec>
<sec id="s2d">
<title>Long-range axonal projections reconstruction</title>
<p>We applied PointTree for long-range axon reconstruction. The testing image block has the size of 11226Ã8791Ã1486 voxels and includes axons from eight neurons (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). We also used GTree to manually reconstruct these neurons as the ground-truth reconstruction (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). Except for the labeling of training data for segmentation network and of the axon starting points of a single neuron, the whole reconstruction process is totally automatic. The results show PointTree successfully recovered the axonal morphology of these eight neurons without manual interference (<xref rid="fig5" ref-type="fig">Figure 5C</xref> and Movies S1 &amp; S2), and we compared these reconstructions with ground truth (Fig.S4). The average precision is above 85% and the average recall and F1-score are above 80% (<xref rid="fig5" ref-type="fig">Figure 5E</xref>). In addition, we presented the axons reconstructions from two image blocks (<xref rid="fig5" ref-type="fig">Figures 5C<sub>1</sub>&amp;C<sub>2</sub></xref>) which include a large number of densely distributed axons; This reconstruction performance suggests that the point assignment and the minimal information flow tree mode, as the two key strategies in PointTree, perform well in long-range axonal reconstruction.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Long-range axonal reconstruction using PointTree.</title>
<p>(<bold>A</bold>) The image block contains eight neurons in the ventral posteromedial thalamic region. The projection of these neurons includes a large number of densely distributed axons, which are enlarged in A<sub>1</sub> and A<sub>2</sub>. (<bold>B</bold>) The reconstruction of the eight neurons is achieved by annotators with semi-automatic software GTree, serving as ground-truth reconstruction to evaluate automatic algorithms. The reconstructions B<sub>1</sub> and B<sub>2</sub> correspond to the image blocks A<sub>1</sub> and A<sub>2</sub>. (<bold>C</bold>) Automatic reconstruction with PointTree results in reconstructions of the densely distributed axons, which are enlarged in C<sub>1</sub> and C<sub>2</sub>. (<bold>D</bold>) A comparison between automatic reconstruction and ground-truth reconstruction of axonal projection for one neuron is shown. Green indicates consistent reconstruction, blue indicates missed branches, and red denotes branches from other neurons. (<bold>E</bold>) Quantitative analysis of long-range projections for these neurons is presented. Statistical information is displayed in boxes, while black points represent the accuracy of the reconstructions for these neurons.</p></caption>
<graphic xlink:href="614432v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We also applied PointTree to process another 10739Ã11226Ã3921 image blocks collected with HD-fMOST system<sup><xref ref-type="bibr" rid="c48">48</xref></sup>. The high signal-to-noise ratio in this optical system results in a significantly extended dynamic range of the signal. PointTree can effectively deal with this case, and all 14 long-range projections are successfully reconstructed (Fig.S5). The quantitative results suggest that the average F1-score is above 90% (Table S1).</p>
<p>Despite the need to solve multiple large-scale optimization problems, the reconstruction speed using PointTree is generally faster than the imaging speed. For instance, in a typical scenario involving 254 image blocks with 512Ã512Ã512 voxels, the total time required for reconstruction is approximately 44 minutes. Even for a larger dataset comprising 821 image blocks with 512Ã512Ã512 voxels and including a significant number of sparsely distributed neurites, the total time cost amounts to about 60 minutes (Table S2). It should be noted that the time cost does not increase linearly as data volume increases due to the influence of neurite density on overall reconstruction time. In summary, PointTree demonstrates remarkable speed in reconstructing long-range axons (Movie S3).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have presented an automated method for reconstructing the long-range projections of neurons. In this study, we address the problem of mutual interference among densely distributed neurites and the cumulative error during reconstruction by designing reconstruction method based on point set assignment and the minimal information flow tree, respectively. As a result, our approach enables accurate reconstruction of long-range neuron projections from hundreds of gigabytes of data. This advance significantly enhances the efficiency of whole-brain-scale neuron reconstruction, bridging the substantial gap between factory-level generation of whole-brain-scale neuronal imaging data and tens of hours required to reconstruct one neuron.</p>
<p>Our approach is performed on image foregrounds where the segmented neurites have a fixed radius approximately equal to the total size of the three voxels. In this case, we can estimate the total number of foreground points (voxels) and set a suitable number of columnar regions for ensuring the anisotropy of each columnar region, which is based on the fact that the union of columnar regions equals to the foreground region. The anisotropy of the columnar regions will reduce the difficulty in establishing their connection. The requirement that all segmented neurites have a relatively fixed radius can be fulfilled. For all neurites, the value of their voxels decreases as these voxels deviate from the nearest centerline. The deep learning network is able to grasp this feature and segment only the neurite centerline and its neighborhood. Typically, in reconstructions of neurons whose projections are distributed over hundreds to thousands of GBs of data, less than GB-sized images with labels are needed as training data. The labeling process takes a few hours, which is negligible for semi-automatic reconstruction of all neurons in the whole volume images.</p>
<p>We propose a new reconstruction mode centered on point set assignment instead of the current reconstruction mode focused on skeleton extraction. In the current reconstruction paradigm, most deep networks are used to enhance the signal-to-noise ratio of neuronal images and do not address well the issue of signal interference during skeleton extraction. In contrast, our reconstruction approach is based on directly processing the foreground points generated by the deep learning network. With continued advances in deep learning techniques, the generality and accuracy of image segmentation will be continuously enhanced, thereby significantly boosting the application scope of our method in various scenarios. Essentially, our method can be applied to any skeleton tracking-based application scenario and effectively eliminate dense signal interference.</p>
<p>Our method still generates a few reconstruction errors. This is due to the following three aspects. First, our method directly handles image foregrounds, which leads to reconstruction errors when some neurites with weak image intensities are not identified. Second, relying solely on foreground point information and rule-based judgment methods may generate some connection errors when establishing connections between neurites. Finally, the minimal information flow tree derived from the branching morphological statistics may cause inconsistencies in rare cases when correcting for reconstruction errors. Therefore, for the automatic reconstruction of neurons on a brain-wide scale, further work is needed to enhance the imaging intensity and incorporate soma shapes and raw image signals for neurites connection recognition.</p>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title>Data collections</title>
<p>The test datasets are collected through the preparation of two kinds of samples. For one C57BL/6 male mouse, 100 nl AAV-Cre virus and 100 nl of AAV-EF1<italic>Î±</italic> -DIO-EYFP virus were injected into the VPM nucleus at the same time. 21 days later, the chemical sectioning fluorescence tomography(CSFT) system<sup><xref ref-type="bibr" rid="c49">49</xref></sup> was used to acquire imaging data (<xref rid="fig1" ref-type="fig">Figures 1</xref>-<xref rid="fig5" ref-type="fig">5</xref>), more details can be seen in the reference <sup><xref ref-type="bibr" rid="c50">50</xref></sup>. For one C57BL/6J male mouse, 100 nl of AAV-YFP was injected into the motor area. 21 days later, high-definition fluorescent micro-optical sectioning tomography (HD-fMOST) was used to acquire imaging data (Fig.S5), more details can be seen in the reference<sup><xref ref-type="bibr" rid="c48">48</xref></sup>.</p>
</sec>
<sec id="s4b">
<title>Generation of foreground points</title>
<p>Our reconstruction method performs on the image foregrounds. Here, we used UNet3D<sup><xref ref-type="bibr" rid="c51">51</xref></sup> for image stacks segmentation without network structure modification. The detailed information about UNet3D can be found in the reference<sup><xref ref-type="bibr" rid="c51">51</xref></sup>. Considering the requirement that the network output, the segmented neurites, have the relatively fixed radius, we calculate the distance field of the neuriteâs skeleton as the ground-truth for supervise the network. Initially, the semi-automatic software GTree was utilized to extract the neurites skeleton and subsequently interpolate the skeleton points. The interpolation operation ensured that the distance between any skeleton point and its nearest point was less than 1 um. Subsequently, the interpolated skeleton points were used as centers to mark spherical regions with a radius of 5 voxels. These spherical regions served as candidate areas for foreground. Within these candidate areas, the distance from each point to its nearest interpolated skeleton point was calculated. Finally, the distances are mapped into Gaussian kernel distances which forms the Gaussian density map. This map normalized by maximum value leads to the distance field map to supervise UNet3D output.</p>
<p>In the training stage, Adam optimizer is used with an initial learning rate at 3e-4. The input image size is 128Ã128Ã128. Batch size is set to 1, the L1 norm loss function is used to supervise the network outputs to the input labels. We presented the reconstructions from two kinds of fMOST datasets. One is from the reference <sup><xref ref-type="bibr" rid="c50">50</xref></sup> and the other is from the reference <sup><xref ref-type="bibr" rid="c48">48</xref></sup>. Therefore, we created two sets of training data, each consisting of 20 512Ã512Ã512 image blocks. In each set, 10 image blocks contain densely distributed neurites, while the other 10 blocks contain sparsely distributed neurites. In the predicting stage, we applied the threshold operation to the distance field image. The voxels whose values are more than 0.5 are regarded as the foreground points.</p>
</sec>
<sec id="s4c">
<title>Neuron Reconstruction based on Points assignment</title>
<p>For the image stack, we allocated the foreground points to their respective neurites and established connections between neurites by constructing three optimization models. The constrained Gaussian mixture model divides the foreground points into a set of points, each of which has a column shape. The minimum-volume covering ellipsoids model extracts the features of the column-shaped point set. The 0-1 assignment optimization model establishes connections between the column-shaped point sets, resulting in the shapes of individual neurites, and then builds connections between the reconstructed neurites.</p>
</sec>
<sec id="s4d">
<title>Constrained Gaussian mixture model</title>
<p>The three-dimensional Gaussian function exhibits an ellipsoidal shape in space, which we have utilized to approximate the columnar shape of local neurites. In this study, Gaussian distribution mixture functions with <italic>K</italic> components are employed to approximate the shape of all neurites in an image block and obtain the probability density function <italic>P</italic>(<italic>x</italic>) with respect to the foreground point <italic>x</italic>. For each foreground point <italic>x</italic>, its probabilities in <italic>K</italic> Gaussian distributions are calculated. The foreground points are assigned to the <italic>k</italic>-th clusters according to their maximum probability and form <italic>k</italic>-th columnar regions. Considering that both the number of foreground points and <italic>K</italic> are large, we have added some constrained conditions for Gaussian mixture model as follows.
<disp-formula id="eqn1">
<graphic xlink:href="614432v1_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="614432v1_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<italic>N</italic> (<italic>x</italic>|<italic>Î¼</italic><sub><italic>k</italic></sub>, Î£<sub><italic>k</italic></sub>) is the Gaussian density function with mean value <italic>Î¼</italic><sub><italic>k</italic></sub> and covariance matrix Î£<sub><italic>k</italic></sub>. <inline-formula><inline-graphic xlink:href="614432v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> refers to the fact that the total probability distribution normalizes to 1. <italic>I</italic> (Â·) represents the signal intensity from segment image, <italic>Ïµ</italic><sub>0</sub> is the minimum signal intensity of foreground points. <italic>I</italic> (<italic>Î¼</italic><sub><italic>i</italic></sub>) â¥ <italic>Îµ</italic><sub>0</sub> restrain the center of the gaussian distribution to be a foreground point. | Î£<sub><italic>i</italic></sub> |â¤ <italic>Îµ</italic><sub>1</sub> restrain the determinant of the covariance matrix which control the suitable number of foreground points for each columnar region. <italic>Ïµ</italic><sub>1</sub> is set to cube of three times the average diameter of neurite.</p>
<p>Given the foreground points <italic>x</italic><sub><italic>1</italic></sub>, <italic>x</italic><sub><italic>2</italic></sub>, â¦, <italic>x</italic><sub><italic>N</italic></sub>, we employ maximum likelihood to estate the parameters of Gaussian mixture model.
<disp-formula id="eqn3">
<graphic xlink:href="614432v1_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn4">
<graphic xlink:href="614432v1_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In the solving this optimization problem, we employ peak density algorithm to compute density for each foreground points and sort them in descending order. We select signal points from the median to both sides as seed points which can decrease the situations that seed points lies in the center of a crossover or the edge of neurites, this strategy can make the generated columnar regions be more reasonable. The positions of the <italic>K</italic> seed points are set to the initial (<italic>Î¼</italic><sub>1</sub>, <italic>Î¼</italic><sub>2</sub>, â¦, <italic>Î¼</italic><sub><italic>K</italic></sub>). The initial setting of covariance matrix is the identity matrix. The constrained Gaussian mixture model was solved by EM algorithm<sup><xref ref-type="bibr" rid="c52">52</xref></sup> (Supplementary Text).</p>
</sec>
<sec id="s4e">
<title>Shape characterization of columnar regions</title>
<p>After deriving the columnar regions through solving the constrained Gaussian mixture model, it is imperative to characterize their geometric shape (terminals and centerlines). For this purpose, we use the ellipsoid that can fully encompasses a single columnar region and meantime has the minimum volume. For<inline-formula><inline-graphic xlink:href="614432v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, a three-dimensional ellipsoid can be defined as follow:
<disp-formula id="eqn5">
<graphic xlink:href="614432v1_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here, <italic>c</italic> is the center of ellipsoid, <italic>Q</italic> represents the geometric shape, <inline-formula><inline-graphic xlink:href="614432v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> denotes the convex cone of 3Ã3 symmetric positive definite matrices. The volume of <italic>E</italic><sub><italic>c,Q</italic></sub> is given by the formula:
<disp-formula id="eqn6">
<graphic xlink:href="614432v1_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here, Ð(Â·) is the standard gamma function of calculus.</p>
<p>For a columnar region with foreground points <italic>P</italic>{<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, â¦ <italic>x</italic><sub>m</sub> }, we define the target function as follow:
<disp-formula id="eqn7">
<graphic xlink:href="614432v1_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn8">
<graphic xlink:href="614432v1_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn9">
<graphic xlink:href="614432v1_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here <italic>c</italic> â <italic>CHull</italic>(<italic>P</italic><sub><italic>i</italic></sub>) restrain the solved center of ellipsoid to locate within the smallest convex hull formed by the clustering points. Through solving the above minimum-volume covering ellipsoids problem (Supplementary Text), we can characterize the columnar regions more accurate.</p>
<p>Note that from constrained GMM, each cluster has the corresponding mean and covariance matrix of points in the cluster. These two values essentially describe the shape of the cluster. However, if these two values directly replace <italic>c</italic><sup>*</sup> and <italic>Q</italic><sup>*</sup>, the exported ellipsoid may only encompass a part of points in the cluster. For covering all points in the cluster, all elements in the covariance matrix are needed to proportionally enlarged, but the volume of the corresponding ellipsoid is not minimum. These two cases will reduce the accuracy of the connections between clusters, i.e., columnar regions. So, we introduce the minimum-volume covering ellipsoid model to extract the shape of columnar region.</p>
</sec>
<sec id="s4f">
<title>Skeleton generation using 0-1 assignment model</title>
<p>The 0-1 assignment model<sup><xref ref-type="bibr" rid="c43">43</xref></sup> can robustly and accurately establish connections between particles in live-cell imaging<sup><xref ref-type="bibr" rid="c53">53</xref></sup>. It is particularly effective in handling cases where particles are densely distributed, merged, or split. We analogize column regions to particles, and apply the 0-1 assignment model to build the connections between column regions. For the <italic>i-</italic>th columnar region, the center and the two endpoints of the longest axis of its minimum-volume covering ellipsoid are denoted by <italic>c</italic><sub><italic>i</italic></sub>, <italic>t</italic><sub><italic>i</italic>,0</sub>, <italic>t</italic><sub><italic>i</italic>,1</sub>. The direction refers to the pointing of the center point towards <italic>t</italic><sub><italic>i,k</italic></sub>. <italic>k</italic> equals to 0 or 1. According to the direction and the endpoints, we design the cost matrix for building the 0-1 assignment model.
<disp-formula id="eqn10">
<graphic xlink:href="614432v1_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn11">
<graphic xlink:href="614432v1_eqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn12">
<graphic xlink:href="614432v1_eqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here <italic>D</italic> is 2<italic>n</italic>Ã2<italic>n</italic> auxiliary matrix all element of which are all set 100. Both <italic>i</italic>0 and <italic>j</italic>0 in EQ (11) are equal to 0 or 1, labeling the two endpoints of the longest axis of the ellipsoid. <italic>norm</italic>(<italic>t</italic><sub><italic>i,i</italic> 0</sub>, <italic>t</italic> <sub><italic>j, j</italic> 0</sub>) represents the Euclidean distance between <italic>t</italic><sub><italic>i,i</italic> 0</sub> and <italic>t</italic> <sub><italic>j, j</italic> 0</sub>. <italic>Î¸</italic>(<italic>t</italic><sub><italic>i,i</italic>0</sub>, <italic>t</italic> <sub><italic>j, j</italic>0</sub>) describes the angle between two ellipsoids, i.e., two columnar regions. <italic>dir</italic>(<italic>c</italic><sub><italic>i</italic></sub>, <italic>t</italic><sub><italic>i,i</italic> 0</sub>) represents the line from point <italic>c</italic><sub><italic>i</italic></sub> to <italic>t</italic><sub><italic>i,i</italic> 0</sub>. â¨<italic>dir</italic>(<italic>c</italic><sub><italic>i</italic></sub>, <italic>t</italic><sub><italic>i,i</italic> 0</sub>), <italic>dir</italic>(<italic>c</italic><sub><italic>i</italic></sub>, <italic>t</italic> <sub><italic>j, j</italic> 0</sub>)â© represents cosine angle between the two lines. The threshold of 100 in D in EQ (10) and EQ (11) is an experimental value designed to ensure that the terminal points of neurites do not connect to more than one other terminal points.</p>
<p>After set the cost matrix, the 0-1 assignment problem is defined as follow:
<disp-formula id="eqn13">
<graphic xlink:href="614432v1_eqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn14">
<graphic xlink:href="614432v1_eqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn15">
<graphic xlink:href="614432v1_eqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here <italic>A</italic> represents the connectivity matrix between different terminals of columnar regions: if <italic>A</italic><sub><italic>i, j</italic></sub> = 1, then establish connection between terminal <italic>i</italic> and terminal <italic>j</italic>, if <italic>A</italic><sub><italic>i, j</italic></sub> = 0, then establish no connection between terminal <italic>i</italic> and terminal <italic>j</italic>. <inline-formula><inline-graphic xlink:href="614432v1_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="614432v1_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> restrain each terminal establish connection with at most one other terminal. The Lapjv algorithm<sup><xref ref-type="bibr" rid="c43">43</xref></sup> is utilized to solve this optimization problem and the shapes of individual neurites in block images are formed. Furthermore, we employ the region growing method to generate skeletons from the reconstructed shape, achieving the neurites reconstruction from individual image blocks.</p>
</sec>
<sec id="s4g">
<title>Minimal information flow tree for revising the reconstruction</title>
<p>The minimal information flow tree model is designed to modify the topology of skeletons, eliminate incorrect connections, and decompose them into multiple branches. When given an input skeleton file such as the swc file<sup><xref ref-type="bibr" rid="c54">54</xref></sup>, we convert it into a binary tree structure with following steps.</p>
<p><bold>Step1</bold>: select the neurite skeleton <italic>S</italic><sub>1.</sub> <italic>S</italic><sub>1</sub> has the largest length in the neurite skeletons that connect with each other. One of its terminal nodes are recorded as the head node <italic>n</italic><sub>1</sub>.</p>
<p><bold>Step2</bold>: generate the initial tree structure. Starting at head node <italic>n</italic><sub>1</sub>, search the linking nodes along the skeleton <italic>S</italic><sub>1</sub>, denoted by <inline-formula><inline-graphic xlink:href="614432v1_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The topology structure is <inline-formula><inline-graphic xlink:href="614432v1_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p><bold>Step3</bold>: generate new structure induced by the linking node <inline-formula><inline-graphic xlink:href="614432v1_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is regarded as the head node and its corresponding neurite skeleton is denoted by <italic>S</italic><sub>2</sub>. Let <inline-formula><inline-graphic xlink:href="614432v1_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula> represent the linking nodes in skeleton <italic>S</italic><sub><italic>2</italic></sub>The corresponding topology structure is <inline-formula><inline-graphic xlink:href="614432v1_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p><bold>Step4</bold>: repeat the operation in Step3 for dealing with the linking nodes <inline-formula><inline-graphic xlink:href="614432v1_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The corresponding topology structures are added into the total tree structure. After obtaining the tree structures induced by linking nodes in <italic>S</italic><sub><italic>1</italic></sub>, use the operation in Step 3 to generate the tree structures induced by linking nodes in <italic>S</italic><sub><italic>2</italic></sub>. Continue in this manner until all linking nodes have been processed. To gain a better understanding of the above process, we have provided a demonstration of how to generate the corresponding binary tree from the skeletons of neurites (Fig.S6).</p>
<p>For the skeletons of neurites in an image block, the corresponding number of binary tree structures will be generated. We use the MIFT model to merge or split these binary structures. Suppose that an image stack contains <italic>m</italic> skeletons all of which have <italic>K</italic> nodes, denoted by <italic>n</italic><sub>1</sub>, â¦, <italic>n</italic><sub><italic>K</italic> -1</sub>, <italic>n</italic><sub><italic>K</italic></sub>. The connections among these nodes are stored in a matrix <italic>W</italic> with <italic>K</italic> â
s <italic>K</italic> elements. <italic>W</italic><sub><italic>i, j</italic></sub> = 0 indicates that there is no connection between node <italic>i</italic> and node <italic>j. W</italic><sub><italic>i, j</italic></sub> = -1 indicates that <italic>j</italic> â <italic>headnode</italic> = <italic>i, W</italic><sub><italic>i, j</italic></sub> = -2 indicates that <italic>j</italic> â <italic>leftnode</italic> = <italic>i, W</italic><sub><italic>i, j</italic></sub> = -3 indicates that <italic>j</italic> â <italic>rightnode</italic> = <italic>i</italic>.</p>
<p>The information flow can be computed as follow:
<disp-formula id="eqn16">
<graphic xlink:href="614432v1_eqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn17">
<graphic xlink:href="614432v1_eqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here the optimization objective function in EQ (17) is called information flow. <italic>Î¸</italic>(Â·) is the angle between flow from <italic>n</italic><sub><italic>i</italic></sub> â <italic>headnode</italic> to <italic>n</italic><sub><italic>i</italic></sub> and flow from <italic>n</italic><sub><italic>i</italic></sub> to <italic>n</italic><sub><italic>i</italic></sub> â <italic>leftnode</italic>. To minimize optimization problem while ensuring that the topology matrix <italic>W</italic> does not exhibit abnormal values, we adopt the strategy of dynamic programming to update topology matrix <italic>W</italic>. Briefly, we calculate the other two possible angles <italic>Î¸</italic>(<italic>n</italic><sub><italic>i</italic></sub> â <italic>headnode, n</italic><sub><italic>i</italic></sub>, <italic>n</italic><sub><italic>i</italic></sub> â <italic>rightnode</italic>) and <italic>Î¸</italic>(<italic>n</italic><sub><italic>i</italic></sub> â <italic>leftnode, n</italic><sub><italic>i</italic></sub>, <italic>n</italic><sub><italic>i</italic></sub> â <italic>rightnode</italic>) at the first linking node <italic>n</italic><sub><italic>i</italic></sub>. The minimum information flow is selected and <italic>W</italic> is updated. Following the updated <italic>W</italic>, the next branching node is found and information flow and <italic>W</italic> is updated. The updating process iterates until all nodes are updated. The final root nodes {<italic>r</italic><sub>1</sub>, <italic>r</italic><sub>2</sub>, â¦<italic>r</italic><sub><italic>m</italic></sub> } are obtained (node satisfies <italic>W</italic> (<italic>r</italic><sub><italic>t</italic></sub>, <italic>i</italic>) = 0 <italic>or</italic> -1(<italic>i</italic> = 1,â¦<italic>n</italic>) is set root node). The pseudo-code for solving the optimization problem can be found in Supplementary Text.</p>
<p>Please note that the model has the capability to merge binary trees. When two branches of neurites have identifiable root nodes, and one root node is in close proximity to the skeleton points on the other branch of neurites, the root node does not contribute to the calculation of information flow without fusion. However, after fusion, the root node becomes a linking node in the other branch of neurites, resulting in an additional negative information flow value. In this merging process, a threshold is required to be set. When the minimum distance between the root node of a branch of neurites and the skeleton point of the other branch of neurites is less than 8 for individual image blocks or less than 8,12,16 for fused image blocks respectively, these two branches are merged. When splitting a branch of neurites, the minimal information flow tree model is also applied to both individual and fused image blocks.</p>
</sec>
<sec id="s4h">
<title>The fusion of neurites reconstruction</title>
<p>By using MIFT model to revise the neurites reconstruction in individual image blocks, the root nodes and leaf nodes of a branch of neurites can be extracted directly. Here, we use 0-1 assignment model to merge the reconstructions between two adjacent image blocks. For two adjacent image blocks <italic>P</italic> and <italic>Q</italic>, the neurite skeleton nodes which locate near the common boundary are extracted {<italic>p, p</italic>, â¦ <italic>p</italic> },{<italic>q</italic><sub>1</sub>, <italic>q</italic><sub>2</sub>, â¦<italic>q</italic> } and the cost matrix is constructed as follow:
<disp-formula id="eqn18">
<graphic xlink:href="614432v1_eqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn19">
<graphic xlink:href="614432v1_eqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here <italic>D</italic><sub><italic>m</italic>Ã<italic>m</italic></sub>, <italic>D</italic><sub><italic>n</italic>Ã<italic>n</italic></sub>, <italic>D</italic><sub><italic>n</italic>Ã<italic>m</italic></sub> are auxiliary matrix which the values are all set 20. <italic>d</italic> (<italic>p</italic><sub><italic>i</italic></sub>, <italic>q</italic> <sub><italic>j</italic></sub>) represents the Euclidean distance between terminal <italic>p</italic><sub><italic>i</italic></sub> and <italic>q</italic> <sub><italic>j</italic></sub>. <italic>L</italic> (<italic>p</italic><sub><italic>i</italic></sub>) and <italic>L</italic> (<italic>q</italic><sub><italic>j</italic></sub>) are fitted lines from the skeleton points near <italic>p</italic><sub><italic>i</italic></sub> and <italic>q</italic> <sub><italic>j</italic></sub>. <italic>Î¸</italic> (<italic>L</italic> (<italic>p</italic><sub><italic>i</italic></sub>), <italic>L</italic> (<italic>q</italic><sub><italic>j</italic></sub>))?represents the cosine value of their angle. Thus, the 0-1 assignment problem is formed as follow:
<disp-formula id="eqn20">
<graphic xlink:href="614432v1_eqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn21">
<graphic xlink:href="614432v1_eqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn22">
<graphic xlink:href="614432v1_eqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here <italic>A</italic> represents the connectivity relationship between nodes, if <italic>A</italic><sub><italic>i, j</italic></sub> = 1, there is connection between block <italic>P</italic> âs node <italic>i</italic> and block <italic>Q</italic> âs node <italic>j</italic>, if <italic>A</italic><sub><italic>i, j</italic></sub> = 0, there is no connection between block <italic>P</italic> âs node <italic>i</italic> and block <italic>Q</italic> âs node <italic>j</italic>. <inline-formula><inline-graphic xlink:href="614432v1_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="614432v1_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula> restrict each node connect to one other node at most. With solved matrix <italic>A</italic>, the neurite skeletons of adjacent blocks can be merged and fused skeleton structures can be obtained.</p>
</sec>
<sec id="s4i">
<title>Statistical Analysis</title>
<p>In this study, three commonly used metrics defined in <sup><xref ref-type="bibr" rid="c39">39</xref></sup> were used, including precision, recall and F1-score are computed to measure the fidelity between the reconstruction results and the ground truth. They are defined as follow:
<disp-formula id="eqn23">
<graphic xlink:href="614432v1_eqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn24">
<graphic xlink:href="614432v1_eqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn25">
<graphic xlink:href="614432v1_eqn25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
R represents the point set of reconstructed neurons, G represents the point set of the ground truth, | Â· | represents the number of points of a set. The three metrics are first computed on each individual neuron, and then averaged by weighting each neuron with its point number of its ground truth neuritis.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank the members of the Britton Chance Center for Biomedical Photonics for advice and help in experiments.</p>
</ack>
<sec id="s5">
<title>Additional information</title>
<sec id="s5a">
<title>Funding</title>
<p>Advanced Biomedical Imaging facilities (2105-420118-89-01-121873).</p>
</sec>
<sec id="s6">
<title>Author contributions</title>
<p>Methodology: T.Q., L.C.</p>
<p>Investigation: T.Q., L.C., T.F., X.Q., X.G., W.F.</p>
<p>Validation: L.C., T.F., Q.D, T.C, Y.Z.</p>
<p>Supervision: S.Z., T.Q., X.L., X.L., Q.H.</p>
<p>Writing: T.Q., L.C., T.F.</p>
</sec>
<sec id="s7">
<title>Competing interests</title>
<p>Authors declare that they have no competing interests.</p>
</sec>
</sec>
<sec id="s8" sec-type="data-availability">
<title>Data and materials availability</title>
<p>The data for <xref rid="fig1" ref-type="fig">Figure 1C</xref>, <xref rid="fig2" ref-type="fig">Figure 2</xref>, <xref rid="fig3" ref-type="fig">Figure 3</xref>, <xref rid="fig4" ref-type="fig">Figure 4</xref>, <xref rid="fig5" ref-type="fig">Figure 5</xref> and Fig.S5 is available in <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/11239828">https://zenodo.org/records/11239828</ext-link>. The raw image blocks are extremely large and can be available on request from the corresponding author. The training code of the segmentation network is available on Github: <ext-link ext-link-type="uri" xlink:href="https://github.com/FateUBW0227/Seg_Net">https://github.com/FateUBW0227/Seg_Net</ext-link>. The software of PointTree and its user guideline are available on <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/11239828">https://zenodo.org/records/11239828</ext-link>.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Parekh</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Ascoli</surname>, <given-names>G. A.</given-names></string-name></person-group> <article-title>Neuronal morphology goes digital: a research hub for cellular and system neuroscience</article-title>. <source>Neuron</source> <volume>77</volume>, <fpage>1017</fpage>â<lpage>1038</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meijering</surname>, <given-names>E.</given-names></string-name></person-group> <article-title>Neuron tracing in perspective</article-title>. <source>Cytometry Part A</source> <volume>77</volume>, <fpage>693</fpage>â<lpage>704</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zingg</surname>, <given-names>B.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Neural networks of the mouse neocortex</article-title>. <source>Cell</source> <volume>156</volume>, <fpage>1096</fpage>â<lpage>1111</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>Z. J.</given-names></string-name> &amp; <string-name><surname>Luo</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>It takes the world to understand the brain</article-title>. <source>Science</source> <volume>350</volume>, <fpage>42</fpage>â<lpage>44</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cai</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Panoptic imaging of transparent mice reveals whole-body neuronal projections and skullâmeninges connections</article-title>. <source>Nature neuroscience</source> <volume>22</volume>, <fpage>317</fpage>â<lpage>327</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chung</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Deisseroth</surname>, <given-names>K.</given-names></string-name></person-group> <article-title>CLARITY for mapping the nervous system</article-title>. <source>Nature methods</source> <volume>10</volume>, <fpage>508</fpage>â<lpage>513</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Economo</surname>, <given-names>M. N.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A platform for brain-wide imaging and reconstruction of individual neurons</article-title>. <source>elife</source> <volume>5</volume>, <fpage>e10566</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>T. H.</given-names></string-name> &amp; <string-name><surname>Schnitzer</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Fluorescence imaging of large-scale neural ensemble dynamics</article-title>. <source>Cell</source> <volume>185</volume>, <fpage>9</fpage>â<lpage>41</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Micro-optical sectioning tomography to obtain a high-resolution atlas of the mouse brain</article-title>. <source>Science</source> <volume>330</volume>, <fpage>1404</fpage>â<lpage>1408</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Osten</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Margrie</surname>, <given-names>T. W.</given-names></string-name></person-group> <article-title>Mapping brain circuitry with a light microscope</article-title>. <source>Nature methods</source> <volume>10</volume>, <fpage>515</fpage>â<lpage>523</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname>, <given-names>H.</given-names></string-name></person-group> <article-title>What is a cell type and how to define it?</article-title> <source>Cell</source> <volume>185</volume>, <fpage>2739</fpage>â<lpage>2755</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>High-throughput mapping of a whole rhesus monkey brain at micrometer resolution</article-title>. <source>Nature biotechnology</source> <volume>39</volume>, <fpage>1521</fpage>â<lpage>1528</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiu</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Whole-brain spatial organization of hippocampal single-neuron projectomes</article-title>. <source>Science</source> <volume>383</volume>, <fpage>eadj9198</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Morphological diversity of single neurons in molecularly defined cell types</article-title>. <source>Nature</source> <volume>598</volume>, <fpage>174</fpage>â<lpage>181</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Single-neuron projectome of mouse prefrontal cortex</article-title>. <source>Nature Neuroscience</source> <volume>25</volume>, <fpage>515</fpage>â<lpage>529</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foster</surname>, <given-names>N. N.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The mouse corticoâbasal gangliaâthalamic network</article-title>. <source>Nature</source> <volume>598</volume>, <fpage>188</fpage>â<lpage>194</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MuÃ±oz-CastaÃ±eda</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Cellular anatomy of the mouse primary motor cortex</article-title>. <source>Nature</source> <volume>598</volume>, <fpage>159</fpage>â<lpage>166</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname>, <given-names>Q.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A whole-brain map of long-range inputs to GABAergic interneurons in the mouse medial prefrontal cortex</article-title>. <source>Nature neuroscience</source> <volume>22</volume>, <fpage>1357</fpage>â<lpage>1370</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Winnubst</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Reconstruction of 1,000 projection neurons reveals new cell types and organization of long-range connectivity in the mouse brain</article-title>. <source>Cell</source> <volume>179</volume>, <fpage>268</fpage>-<lpage>281.</lpage> e213 (<year>2019</year>).</mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedmann</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Mapping mesoscale axonal projections in the mouse brain using a 3D convolutional network</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>117</volume>, <fpage>11068</fpage>â<lpage>11075</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>GTree: an open-source tool for dense reconstruction of brain-wide neuronal population</article-title>. <source>Neuroinformatics</source> <volume>19</volume>, <fpage>305</fpage>â<lpage>317</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>TeraVR empowers precise reconstruction of complete 3-D neuronal morphology in the whole brain</article-title>. <source>Nature communications</source> <volume>10</volume>, <fpage>3474</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Sanes</surname>, <given-names>J. R.</given-names></string-name></person-group> <article-title>Neuronal cell-type classification: challenges, opportunities and the path forward</article-title>. <source>Nature Reviews Neuroscience</source> <volume>18</volume>, <fpage>530</fpage>â<lpage>546</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Precise segmentation of densely interweaving neuron clusters using G-Cut</article-title>. <source>Nature communications</source> <volume>10</volume>, <fpage>1549</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lichtman</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Denk</surname>, <given-names>W.</given-names></string-name></person-group> <article-title>The big and the small: challenges of imaging the brainâs circuits</article-title>. <source>Science</source> <volume>334</volume>, <fpage>618</fpage>â<lpage>623</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Helmstaedter</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Cellular-resolution connectomics: challenges of dense neural circuit reconstruction</article-title>. <source>Nature methods</source> <volume>10</volume>, <fpage>501</fpage>â<lpage>507</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c27"><label>27</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>BigNeuron: large-scale 3D neuron reconstruction from optical microscopy images</article-title>. <source>Neuron</source> <volume>87</volume>, <fpage>252</fpage>â<lpage>256</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c28"><label>28</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manubens-Gil</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>BigNeuron: a resource to benchmark and predict performance of algorithms for automated tracing of neurons in light microscopy datasets</article-title>. <source>Nature Methods</source> <volume>20</volume>, <fpage>824</fpage>â<lpage>835</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c29"><label>29</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Choromanska</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>S.-F.</given-names></string-name> &amp; <string-name><surname>Yuste</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Automatic reconstruction of neural morphologies with multi-scale tracking</article-title>. <source>Frontiers in neural circuits</source> <volume>6</volume>, <fpage>25</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c30"><label>30</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Brain-wide shape reconstruction of a traced neuron using the convex image segmentation method</article-title>. <source>Neuroinformatics</source> <volume>18</volume>, <fpage>199</fpage>â<lpage>218</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c31"><label>31</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gonzalez-Bellido</surname>, <given-names>P. T.</given-names></string-name> &amp; <string-name><surname>Peng</surname>, <given-names>H.</given-names></string-name></person-group> <article-title>A distance-field based automatic neuron tracing method</article-title>. <source>BMC bioinformatics</source> <volume>14</volume>, <fpage>1</fpage>â<lpage>11</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c32"><label>32</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Long</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Myers</surname>, <given-names>G.</given-names></string-name></person-group> <article-title>Automatic 3D neuron tracing using all-path pruning</article-title>. <source>Bioinformatics</source> <volume>27</volume>, <fpage>i239</fpage>â<lpage>i247</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c33"><label>33</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiao</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Peng</surname>, <given-names>H.</given-names></string-name></person-group> <article-title>APP2: automatic tracing of 3D neuron morphology based on hierarchical pruning of a gray-weighted image distance-tree</article-title>. <source>Bioinformatics</source> <volume>29</volume>, <fpage>1448</fpage>â<lpage>1454</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c34"><label>34</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>TÃ¼retken</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>GonzÃ¡lez</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Blum</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Fua</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>Automated reconstruction of dendritic and axonal trees by global optimization with geometric priors</article-title>. <source>Neuroinformatics</source> <volume>9</volume>, <fpage>279</fpage>â<lpage>302</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c35"><label>35</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Kuo</surname>, <given-names>H.-C.</given-names></string-name>, <string-name><surname>Peng</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Long</surname>, <given-names>F.</given-names></string-name></person-group> <article-title>DeepNeuron: an open deep learning toolbox for neuron tracing</article-title>. <source>Brain informatics</source> <volume>5</volume>, <fpage>1</fpage>â<lpage>9</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c36"><label>36</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name> &amp; <string-name><surname>Shen</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>3D neuron reconstruction in tangled neuronal image with deep networks</article-title>. <source>IEEE transactions on medical imaging</source> <volume>39</volume>, <fpage>425</fpage>â<lpage>435</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c37"><label>37</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>Q.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Weakly supervised learning of 3D deep network for neuron reconstruction</article-title>. <source>Frontiers in Neuroanatomy</source> <volume>14</volume>, <fpage>38</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c38"><label>38</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Ascoli</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Liu</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>Neuron tracing from light microscopy images: automation, deep learning and bench testing</article-title>. <source>Bioinformatics</source> <volume>38</volume>, <fpage>5329</fpage>â<lpage>5339</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c39"><label>39</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quan</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>NeuroGPS-Tree: automatic reconstruction of large-scale neuronal populations with dense neurites</article-title>. <source>Nature methods</source> <volume>13</volume>, <fpage>51</fpage>â<lpage>54</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c40"><label>40</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Single-neuron analysis of dendrites and axons reveals the network organization in mouse prefrontal cortex</article-title>. <source>Nature Neuroscience</source> <volume>26</volume>, <fpage>1111</fpage>â<lpage>1126</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c41"><label>41</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reynolds</surname>, <given-names>D. A.</given-names></string-name></person-group> <article-title>Gaussian mixture models</article-title>. <source>Encyclopedia of biometrics</source> <volume>741</volume> (<year>2009</year>).</mixed-citation></ref>
<ref id="c42"><label>42</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Freund</surname>, <given-names>R. M.</given-names></string-name></person-group> <article-title>Computation of minimum-volume covering ellipsoids</article-title>. <source>Operations Research</source> <volume>52</volume>, <fpage>690</fpage>â<lpage>706</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c43"><label>43</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Volgenant</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Linear and semi-assignment problems: a core oriented approach</article-title>. <source>Computers &amp; Operations Research</source> <volume>23</volume>, <fpage>917</fpage>â<lpage>932</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c44"><label>44</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Models of regional growth: past, present and future</article-title>. <source>Journal of economic surveys</source> <volume>25</volume>, <fpage>913</fpage>â<lpage>951</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c45"><label>45</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feng</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>neuTube 1.0: a new design for efficient neuron reconstruction software based on the SWC format</article-title>. <source>eneuro</source> <volume>2</volume> (<year>2015</year>).</mixed-citation></ref>
<ref id="c46"><label>46</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>RadojeviÄ</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Meijering</surname>, <given-names>E.</given-names></string-name></person-group> <article-title>Automated neuron tracing using probability hypothesis density filtering</article-title>. <source>Bioinformatics</source> <volume>33</volume>, <fpage>1073</fpage>â<lpage>1080</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c47"><label>47</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>3D BrainCV: simultaneous visualization and analysis of cells and capillaries in a whole mouse brain with one-micron voxel resolution</article-title>. <source>Neuroimage</source> <volume>87</volume>, <fpage>199</fpage>â<lpage>208</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c48"><label>48</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhong</surname>, <given-names>Q.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>High-definition imaging using line-illumination modulation microscopy</article-title>. <source>Nature methods</source> <volume>18</volume>, <fpage>309</fpage>â<lpage>315</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c49"><label>49</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Chemical sectioning fluorescence tomography: high-throughput, high-contrast, multicolor, whole-brain imaging at subcellular resolution</article-title>. <source>Cell Reports</source> <volume>34</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c50"><label>50</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Cross-streams through the ventral posteromedial thalamic nucleus to convey vibrissal information</article-title>. <source>Frontiers in Neuroanatomy</source> <volume>15</volume>, <fpage>724861</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c51"><label>51</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>ÃiÃ§ek</surname>, <given-names>Ã.</given-names></string-name>, <string-name><surname>Abdulkadir</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lienkamp</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Brox</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Ronneberger</surname>, <given-names>O.</given-names></string-name></person-group> <source>in Medical Image Computing and Computer-Assisted InterventionâMICCAI 2016: 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings, Part II</source> <volume>19</volume>. <fpage>424</fpage>â<lpage>432</lpage> (<publisher-name>Springer</publisher-name>). <year>no date</year></mixed-citation></ref>
<ref id="c52"><label>52</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>McLachlan</surname>, <given-names>G. J.</given-names></string-name> &amp; <string-name><surname>Krishnan</surname>, <given-names>T.</given-names></string-name></person-group> <source>The EM algorithm and extensions</source>. (<publisher-name>John Wiley &amp; Sons</publisher-name>, <year>2007</year>).</mixed-citation></ref>
<ref id="c53"><label>53</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jaqaman</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Robust single-particle tracking in live-cell time-lapse sequences</article-title>. <source>Nature methods</source> <volume>5</volume>, <fpage>695</fpage>â<lpage>702</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c54"><label>54</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cannon</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Turner</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Pyapali</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Wheal</surname>, <given-names>H.</given-names></string-name></person-group> <article-title>An on-line archive of reconstructed hippocampal neurons</article-title>. <source>Journal of neuroscience methods</source> <volume>84</volume>, <fpage>49</fpage>â<lpage>54</lpage> (<year>1998</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102840.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Naud</surname>
<given-names>Richard</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Ottawa</institution>
</institution-wrap>
<city>Ottawa</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> paper takes a novel approach to the problem of automatically reconstructing long-range axonal projections from stacks of images. The key innovation is to separate the identification of sections of an axon from the statistical rules used to constrain global structure. The authors provide <bold>convincing</bold> evidence that their method is a significant improvement over existing measures in circumstances where the labelling of axons and dendrites is relatively dense, but the robustness to image noise remains to be tested.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102840.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors introduce a novel algorithm for the automatic identification of long-range axonal projections. This is an important problem as modern high-throughput imaging techniques can produce large amounts of raw data, but identifying neuronal morphologies and connectivities requires large amounts of manual work. The algorithm works by first identifying points in three-dimensional space corresponding to parts of labelled neural projections, these are then used to identify short sections of axons using an optimisation algorithm and the prior knowledge that axonal diameters are relatively constant. Finally, a statistical model that assumes axons tend to be smooth is used to connect the sections together into complete and distinct neural trees. The authors demonstrate that their algorithm is far superior to existing techniques, especially when dense labelling of the tissue means that neighbouring neurites interfere with the reconstruction. Despite this improvement, however, the accuracy of reconstruction remains below 90%, so manual proofreading is still necessary to produce accurate reconstructions of axons.</p>
<p>Strengths:</p>
<p>The new algorithm combines local and global information to make a significant improvement on the state-of-the-art for automatic axonal reconstruction. The method could be applied more broadly and might have applications to reconstructions of electron microscopy data, where similar issues of high-throughput imaging and relatively slow or inaccurate reconstruction remain.</p>
<p>Weaknesses:</p>
<p>There are three weaknesses in the algorithm and manuscript.</p>
<p>(1) The best reconstruction accuracy is below 90%, which does not fully solve the problem of needing manual proofreading.</p>
<p>(2) The 'minimum information flow tree' model the authors use to construct connected axonal trees has the potential to bias data collection. In particular, the assumption that axons should always be as smooth as possible is not always correct. This is a good rule-of-thumb for reconstructions, but real axons in many systems can take quite sharp turns and this is also seen in the data presented in the paper (Figure 1C). I would like to see explicit acknowledgement of this bias in the current manuscript and ideally a relaxation of this rule in any later versions of the algorithm.</p>
<p>(3) The writing of the manuscript is not always as clear as it could be. The manuscript would benefit from careful copy editing for language, and the Methods section in particular should be expanded to more clearly explain what each algorithm is doing. The pseudo-code of the Supplemental Information could be brought into the Methods if possible as these algorithms are so fundamental to the manuscript.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102840.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this manuscript, Cai et al. introduce PointTree, a new automated method for the reconstruction of complex neuronal projections. This method has the potential to drastically speed up the process of reconstructing complex neurites. The authors use semi-automated manual reconstruction of neurons and neurites to provide a 'ground-truth' for comparison between PointTree and other automated reconstruction methods. The reconstruction performance is evaluated for precision, recall, and F1-score and positions. The performance of PointTree compared to other automated reconstruction methods is impressive based on these 3 criteria.</p>
<p>As an experimentalist, I will not comment on the computational aspects of the manuscript. Rather, I am interested in how PointTree's performance decreases in noisy samples. This is because many imaging datasets contain some level of background noise for which the human eye appears essential for the accurate reconstruction of neurites. Although the samples presented in Figure 5 represent an inherent challenge for any reconstruction method, the signal-to-noise ratio is extremely high (also the case in all raw data images in the paper). It would be interesting to see how PointTree's performance changes in increasingly noisy samples, and for the author to provide general guidance to the scientific community as to what samples might not be accurately reconstructed with PointTree.</p>
</body>
</sub-article>
</article>