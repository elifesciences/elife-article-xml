<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">89629</article-id>
<article-id pub-id-type="doi">10.7554/eLife.89629</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89629.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Active Dendrites Enable Robust Spiking Computations Despite Timing Jitter</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2238-6111</contrib-id>
<name>
<surname>Burger</surname>
<given-names>Thomas SJ</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4196-774X</contrib-id>
<name>
<surname>Rule</surname>
<given-names>Michael E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1029-0158</contrib-id>
<name>
<surname>O’Leary</surname>
<given-names>Timothy</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Engineering, University of Cambridge</institution>, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution>Theoretical Sciences Visiting Program, Okinawa Institute of Science and Technology Graduate University</institution>, Onna, 904-0495, <country>Japan</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Berman</surname>
<given-names>Gordon J</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Emory University</institution>
</institution-wrap>
<city>Atlanta</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence: <email>tsjb2@cam.ac.uk</email>, <email>timothy.oleary@eng.cam.ac.uk</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-09-29">
<day>29</day>
<month>09</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP89629</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-06-21">
<day>21</day>
<month>06</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-03-24">
<day>24</day>
<month>03</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.22.533815"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Burger et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Burger et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-89629-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Dendritic action potentials exhibit long plateaus of many tens of milliseconds, outliving axonal spikes by an order of magnitude. The computational role of these slow events seems at odds with any need to rapidly integrate and relay information throughout large nervous systems. We propose that the timescale of dendritic potentials allows reliable integration of asynchronous inputs. We develop a physiologically grounded model in which the extended duration of dendritic spikes equips each dendrite with a resettable memory of incoming signals. This provides a tractable model for capturing dendritic nonlinearities observed in experiments and in more complex, detailed models. Using this model, we show that long-lived, nonlinear dendritic plateau potentials allow reliable integration of asynchronous spikes. We demonstrate this model supports non-trivial computations in a network solving an arbitrary association/discrimination task using sparse spiking that is subject to timing jitter. This demonstrates a computational role for the specific timecourse of dendritic potentials in situations where decisions occur quickly, reliably, and with a low number of spikes. Our results provide empirically testable hypotheses for the role of dendritic action potentials in cortical function as well as a potential bio-inspired means of realising neuromorphic spiking computations in analog hardware.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>neurophysiology</kwd>
<kwd>spiking neural networks</kwd>
<kwd>dendrites</kwd>
<kwd>neuromorphic computing</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Across species, many types of neurons possess active dendrites that produce strongly nonlinear responses to synaptic input [<xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c8">8</xref>]. The computational role of these nonlinearities is diverse and will depend on function of the wider neural circuit they inhabit. Some of the most intensely studied examples of dendritic excitability are found in cortical excitatory neurons, which produce regenerative action currents in response to excitatory synaptic drive [<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c55">55</xref>, <xref ref-type="bibr" rid="c38">38</xref>].</p>
<p>Cortical excitatory dendritic action currents last for many tens of milliseconds [<xref ref-type="bibr" rid="c55">55</xref>, <xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c38">38</xref>]. This feature is conspicuous because it is an order of magnitude longer than unitary synaptic inputs and axonal spikes. Reconciling the slow timecourse of dendritic potentials with rapid signalling and computation therefore poses a challenge, particularly when such computations may involve relaying information over multiple brain areas in a short time interval [<xref ref-type="bibr" rid="c62">62</xref>]. Furthermore, the duration of dendritic events incurs heavy energetic costs, because dendritic currents contribute significantly to the ATP budget of the brain [<xref ref-type="bibr" rid="c4">4</xref>]. What computational benefit might couterbalance these signalling and metabolic costs?</p>
<p>We propose that the duration and threshold-like properties of dendritic currents support robust computation in the face of spike timing jitter. This is especially relevant to integration of inputs during high conductance states that are prevalent in-vivo. In these states the effective time constant of the neuronal membrane is extremely short and varies substantially depending on synaptic drive [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c49">49</xref>]. As a consequence, computations that rely on passive summation of multiple inputs place punishing constraints on spike timing precision. Dendritic action potentials, by contrast, have a consistently long duration that is ensured by the kinetic properties of voltage gated ion channels and NMDA receptors [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c3">3</xref>]. These properties are largely determined by the amino acid sequence of receptor and channel proteins that are specifically expressed in dendrites [<xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c40">40</xref>]. This suggests dendritic properties are specifically tuned to produce localised, suprathreshold events that outlive rapid membrane fluctuations.</p>
<p>We extract these core features of the biophysics of dendritic integration to construct and analyse a simplified model, showing that rapid computation remains possible and is in fact facilitated by dendritic transients that exceed the integration timeconstant of single neurons. We focus on computations that take place on the most rapid timescale, because short integration windows are necessarily more sensitive to timing jitter. An interesting side product of this analysis is the interpretation of rapid cortical computations as operating in a binary regime, with each neuron possessing an integration window that can accommodate at most one spike from each input. A number of studies find empirical evidence for such an operating regime in different parts of the nervous system [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c61">61</xref>, <xref ref-type="bibr" rid="c62">62</xref>]. We show how dendritic potentials in this regime allow non-trivial, robust and rapid spiking computations at the network level.</p>
<p>Numerous studies point out that nonlinear summation in dendrites can make neurons computationally equivalent to entire networks of simplified point models, or ‘units’ in a traditional neural network [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c48">48</xref>, <xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c51">51</xref>]. Other work has shown that the dynamic properties of dendritic action potentials enrich computational and signal processing capacity by providing additional long timescales over which input-driven membrane potential dynamics evolve [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c23">23</xref>]. These ideas and the specific examples that support them are complimentary to what we are proposing here. With the dendritic potential as a backbone, our work adds to the computational repertoire by allowing neurons to tune sensitivity to spike timing so as to achieve robust computation on rapid timescales. Our work therefore suggests that long-lived dendritic potentials can paradoxically assist in the most rapid computations possible in a spiking network.</p>
</sec>
<sec id="s2">
<label>1</label>
<title>Results</title>
<sec id="s2a">
<label>1.1</label>
<title>Abstract model</title>
<p>Key features of NMDA action currents are their long duration and their super-linear integration of inputs [<xref ref-type="bibr" rid="c43">43</xref>]. <xref ref-type="fig" rid="fig2">Figure 2A</xref> and <xref ref-type="fig" rid="fig2">B</xref> show a recording of an NMDA spike from a cortical neuron in a rat, from [<xref ref-type="bibr" rid="c18">18</xref>]. [<xref ref-type="bibr" rid="c18">18</xref>] triggered two NMDA spikes by glutamate uncaging at the indicated (red, blue) sites. The voltage response (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) reveals the orders-of-magnitude difference in timescale of an NMDA spike (left) compared to a sodium spike in the soma (right). We took their extensive biophysical computational model (85 compartments, 439 segments—for details see [<xref ref-type="bibr" rid="c18">18</xref>] and subsection 3.1) and simulated glutamate releases 50 ms apart in the three dendritic sites indicated in <xref ref-type="fig" rid="fig2">Figure 2C</xref>, thereby triggering three NMDA spikes at those sites. Despite these dendritic spikes being initiated at different times, they still sum in the soma, leading to a sodium spike there (<xref ref-type="fig" rid="fig2">Figure 2E</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Dendritic NMDA-dependent action currents. <bold>(a)</bold> Long lived calcium and voltage transients initiated within distal dendritic branches. <bold>(b)</bold> If the input to a dendritic branch with NMDA receptors is sufficiently strong, it can cross a threshold to produce an NMDA spike (bold trace). The NMDA response to inputs is super-linear, until it saturates in a plateau potential (top trace). <bold>(c)</bold> A somatic spike mediated by voltage-gated sodium channels. Note the order of magnitude difference in timescales with (b). Reproduced from [<xref ref-type="bibr" rid="c3">3</xref>].</p></caption>
<graphic xlink:href="533815v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><p><bold>A</bold> Fluorescent dye fill image of a layer V pyramidal neuron recorded intracellularly in a rat cortical slice [<xref ref-type="bibr" rid="c18">18</xref>]. Two dendrites are marked where an NMDA spike is triggered through release of glutamate. <bold>B</bold> Voltage traces of the NMDA spikes of the dendritic patches marked in A. Note the long duration of the NMDA spike compared to the somatic sodium spikes evident in the top-left panel. <bold>C</bold> The morphology of the biophysical model used for simulating detailed NMDA plateau potentials. The arrows mark the positions where glutamate release was simulated. <bold>D</bold> The three traces of the NMDA spikes triggered at the sites marked in C, and the resulting somatic spike. <bold>E</bold> The morphology of the abstract model, with and without active NMDA dendrites. <bold>F</bold> The voltage traces of the abstract model, with and without plateaus. Because of the extended time duration of the plateau potentials, they sum accurately to produce a somatic spike. In the case where the plateau potentials are absent, they do not sum due to the short membrane time-constant of the soma. <bold>G</bold> Voltage traces of a basal dendrite with an NMDA spike, in the biophysical model, with an increasingly strong inhibitory current added (left). The plateau duration decreases linearly for a linear increase in the inhibitory conductance (right).</p></caption>
<graphic xlink:href="533815v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We developed an abstract model of these NMDA spikes to capture the essence of their role in circuit computations and for computational expediency. The model consists of a somatic compartment coupled passively to multiple dendritic compartments, each of which corresponds to a single branch on the dendritic tree (<xref ref-type="fig" rid="fig2">Figure 2E</xref>; for details see subsection 3.2). We model NMDA spikes by thresholding the voltage of a leaky dendritic compartment. When the dendritic voltage exceeds threshold it remains depolarized for some time before returning to rest (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). The voltage dynamics are thus parametrised by the threshold and duration of the NMDA spike. We refer to this behavior as “Leaky Integrate-and-Hold” (LIH). It captures the salient features of the NMDA spikes, namely the threshold plus saturation of the super-linear integration, and the long-lived plateau of the dendritic voltage.</p>
<p>Due to passive coupling between compartments in the model, excitation in the dendrites depolarises the soma membrane potential, potentially leading to “axonal” output spikes. We do not model an axonal compartment, we instead implement standard leaky integrate-and-fire (LIF) dynamics to the somatic compartment. A detailed description of the model, along with links to code, is provided in methods.</p>
<p>We compared the behaviour of our simplified model with that of the full, detailed biophysical model. The plateau potentials in the abstract model have a qualitatively similar effect on somatic membrane potential as the NMDA spikes in the biophysical model: <xref ref-type="fig" rid="fig2">Figure 2F</xref> shows that spikes arriving at different times are summed in an integrate and hold-like manner.</p>
<p>We compared this to a situation where all inputs arrive at a soma with standard LIF dynamics and a 10 ms membrane time constant. This time constant is consistent with the high-conductance state of pyramidal neurons in the cortex [<xref ref-type="bibr" rid="c6">6</xref>]: Inputs decay after 2–3 ms, and fail to sum to spike threshold (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, lower).</p>
<p>To partially account for effects of inhibition, we assessed the robustness of dendritic plateaus to tonic inhibitory conductance. As can be seen in <xref ref-type="fig" rid="fig2">Figure 2G</xref>, dendritic plateaus survive inhibitory conductance up to values where the total conductance is roughly equal. Thus, to a crude approximation, dendritic potentials provide an integrate-and-hold mechanism that could function e.g. in the balanced regimen observed in cortical circuits. In the present study we did not attempt to account for temporal variation in inhibition, which will likely play a role in providing further spike synchrony, among other things. This is an important issue we intend to return to in future work. In the scope of what remains here we want to ask if integrate-and-hold is minimally feasible, and if so, whether it can easily and plausibly facilitate network computations with spikes.</p>
</sec>
<sec id="s2b">
<label>1.2</label>
<title>Single Neurons Struggle to Integrate Asynchronous Spikes</title>
<p>The simplified model captures a key feature of the detailed biophysics of pyramidal neuron dendrites: the ability to integrate and hold inputs for a duration exceeding the membrane timeconstant. We hypothesized that this feature would be useful in situations where neurons need to integrate asynchronous input and reliably threshold it despite fluctuations in arrival times of the input.</p>
<p>In effect, each dendrite is performing a binary classification on its inputs. If input spikes arrive in a narrow time window, reliably integrating them is trivial (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref> left). However, millisecond-scale synchrony is unlikely in a large network that is subject to uncertainty and noise. Empirically, spike timing jitter is commonly observed at the population level.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p><bold>(A)</bold> Neurons integrate inputs and compare the result to a firing threshold, which is comparable to performing a binary classification. When inputs are synchronous this can be done with a low number of spikes (left). But when spike timing is unpredictable (middle), this falls apart. Extended depolarizing potentials within dendritic compartments acts as a hold mechanism, allowing asynchronous events from different compartments to summate (right). <bold>(B)</bold> simulation of summed voltage for 10 dendritic compartments, for small amounts of input-event timing jitter (on the order of one EPSP duration <italic>τ</italic> ~ 1 ms; left), and larger amounts jitter (10τ, middle). Increased jitter increases the variability of the net depolarization. Extended depolarizing potentials on the duration of ~ 20 ms reduce the variability in net depolarization. <bold>(C)</bold> Increased jitter in the timing of input events reduces the net summed depolarization. <bold>(D)</bold> Increased jitter in the timing of input events increases the variability in membrane voltage depolarization. <bold>(E)</bold> Variability can be restored by increasing the number of inputs, but this is not cost-effective.</p></caption>
<graphic xlink:href="533815v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To illustrate the severity of this problem, we modelled a single neuron using our abstract model, and fed it input spikes. We drew the times of these input spikes from a normal distribution, and varied the degree of input synchrony by changing the standard deviation of this normal distribution. We took the standard deviation to be a function of the membrane time constant τ, which defines the timescale of the neuron dynamics.</p>
<p>Spikes arriving even slightly out of sync with each other introduces noise in the membrane potential of the receiving neuron (<xref ref-type="fig" rid="fig3">Figure 3B,D</xref>), which can lead to the neuron failing to spike when it should have, or vice-versa. Asynchrony reduces the effective drive of the inputs (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), which means that a failure to spike will occur more often than an errant spike. This loss of drive could be compensated by lowering the postsynaptic cell’s threshold, but variability due to jitter remains. This is shown in (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), where we used the coefficient of variation of the peak membrane potential (standard deviation divided by the mean) to summarize the membrane-voltage uncertainty. This grows with increasing input-timing jitter.</p>
<p>Having extended NMDA spikes remedies these issues (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Because of the extension of the time-constant of the spikes, the uncertainty is filtered out, and the spikes are integrated as if they had arrived synchronously.</p>
<p>It is worth noting that these problems can also be addressed by increasing the number of inputs, thereby reducing the uncertainty through averaging. However, many inputs are required to keep the uncertainty in the membrane potential low; <xref ref-type="fig" rid="fig3">Figure 3E</xref> shows that there is a linear relationship between the spike timing jitter in the inputs, and the number of input spikes necessary to have low uncertainty. Even for a relatively low amount of jitter in the input spike timings of 10 ms, the number of inputs required is in the hundreds. Furthermore, it is only possible to average-away timing jitter if timing variations are uncorrelated. This need not be the case, especially if timing jitter arises from variable conduction delays from common sources.</p>
</sec>
<sec id="s2c">
<label>1.3</label>
<title>Active Dendrites confer Robustness in Spiking Computations</title>
<p>So far we have shown how a biophysical mechanism extracted from detailed biophysics naturally extends the integration window for excitatory inputs. While this might be useful in principle, it remains for us to show how such dynamics can permit non-trivial computations in a network.</p>
<p>In our model, the crucial difference between summation at the soma and summation at the dendrite is that each dendrite can sum subthreshold inputs passively and independently, while the soma is summing sustained plateau potentials from all dendrites that happen to be active. We have made fairly simple assumptions that the dendrite has linear properties beneath the threshold for a dendritic spike, and a relatively short timeconstant. If neither of these assumptions hold, then dendrites might have even more robust integration properties than our model assumes. In this sense our claims and results in this section are rather conservative.</p>
<p>We assumed that inputs to a network arrive at the dendrites within some time window, and their combined depolarisations are either sufficient to either elicit a dendritic spike or not, as shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>. We consider <italic>fast computations,</italic>that is, a regime where the window in which spikes arrive is small, but not so small as to be equivalent to assuming perfect synchrony.</p>
<p>In this regime, each dendrite integrates over a time window and either reaches threshold or does not. Because we assume spike timing jitter in all inputs, each dendrite might reach threshold at different times for different presentations of the same nominal input. However, because dendritic spikes are sustained, jitter in the onset of these events across and entire cell has relatively little effect on whether the soma reaches threshold or not. This effect should confer spike timing robustness at the network level, which is the main claim we will test.</p>
<p>Before describing the implementation of the model and the results, we introduce an interpretation of the operating regime of the network that will be very useful. Computations occurring on short timescales can be interpreted as a binary computation, where incoming connections can be represented with a 1 (a spike arrives) or a 0 (absence of a spike), and the dendrite in turn produces a 1 (it fires) or a 0 (it does not). Connections between dendrites and soma are interpreted analogously: the dendrites produce 1s or 0s, and the soma sums these and compares the result to a firing threshold, thereby computing a 1 or 0. Interestingly, neurons and dendrites operating in this regime have been observed empirically, see e.g. [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c63">63</xref>].</p>
<p>We used this binary interpretation in both a philosophical and practical sense in our spiking model. Philosophically, the binary analogy provides a clean intuition for how fast computations operate, with each unit only having sufficient time to spike once during a single “pass” or “cycle” of a computation. Such situations do appear in biology; see e.g. [<xref ref-type="bibr" rid="c61">61</xref>] for an example where neurons at each synaptic stage have about 10ms to process presynaptic spikes and fire during an animal’s reaction time, leaving room for the receiving and firing of about one action potential per unit.</p>
<p>On a practical level the binary interpretation gives us a means for finding synaptic weights that allow us to train a network to perform a non-trivial computation, then test its robustness to timing jitter. We remind the reader that the focus of our investigation is not on the training or learning procedure, so the fact that we can train binary networks and use the weights in a dynamic, spiking network is not strictly relevant to the biology. However, it may give a powerful practical means for optimising hardware implementations of dynamic spiking networks. It may also hint that biological learning rules can operate in a somewhat equivalent manner.</p>
<p>We now outline the implementation. We built a Spiking Neural Network (SNN) where the individual neurons consist of our abstract neuron model. We constructed a separate Binary Neural Network (BNN) with the same number of equivalent units, and trained it using standard optimisation methods to perform a classification task (see: subsection 3.4 for details). The BNN is a static network where each unit’s state is either 0 or 1. BNNs can thus be regarded as the saturated limit of regular sigmoidal networks, i.e. with weights of large absolute value [<xref ref-type="bibr" rid="c42">42</xref>]. As an aside we point out that BNNs are not restrictive computationally: any computable function can be approximated and implemented with a BNN [<xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c58">58</xref>].</p>
<p>The task we train the BNN for is shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. The <xref ref-type="fig" rid="fig2">2D</xref> input points were first projected onto a binary feature space, to obtain 13D binary vectors. The dimensionality of 13 was chosen because this was the lowest dimensionality in which the binary network could still cope with the loss of information due to the binarization of the continuous coordinates. If the <italic>i</italic><sup>th</sup> input of the binary vector was a 1, a randomly generated timepoint <italic>t<sub>i</sub></italic> was added to produce an input spike (<italic>i, t<sub>i</sub></italic>), meaning that input neuron <italic>i</italic> was fed an impulse so that it would spike at time <italic>t<sub>i</sub></italic>. If the ith element of the binary vector was 0, it meant that neuron i would not fire for that input vector.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>A simple conductance based model displays the same qualitative behavior as a detailed biophysical model. <bold>(A)</bold> The classification task performed by the spiking network of figures D, E, F. Each point is a 2D input vector <italic>x,</italic> the colors represent the different classes. <bold>(B)</bold> Procedure of transforming continuous 2D inputs x into input spikes for the network. First, x is projected onto a binary feature space to obtain a binary vector in a higher dimensional space. Then, spiketimes are added to this binary vector to produce the series of input spikes. For details, see subsection 3.4. <bold>(C)</bold> Schematic of the network architecture. The input somas spike according to the spiketimes obtained from the binary input vector. Each soma in the next layer has one dendrite per upstream soma, and each dendrite is connected to both one downstream and one upstream soma only. The dendrite-soma coupling is a bidirectional passive resistive coupling, whereas the upstream somas have a one-directional synaptic coupling onto the dendrites. <bold>(D)</bold> Example of the spiking network equipped with plateaus in the dendrites receiving asynchronous input spikes. it classifies the three inputs correctly in spite of the asynchrony. <bold>(E)</bold> Example of the spiking network equipped with dendrites without plateaus receiving asynchronous input spikes. The first two points are classified incorrectly, the network gets the third answer correct. <bold>(F)</bold> Summary of how well the network with plateaus and the network without plateaus deal with asynchrony <italic>τ</italic>, with the performance measured as the percentage of points of the classification task classified correctly. Without plateaus the performance drops off quickly, whereas the network with plateaus does not suffer from performance degradation for this range of <italic>τ</italic>.</p></caption>
<graphic xlink:href="533815v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The network architecture is set up so that each dendrite is connected to both a unique upstream neuron and a unique downstream soma (see <xref ref-type="fig" rid="fig4">Figure 4C</xref> for a sketch). The assumption that each neuron connects to one dendrite of an upstream neuron is actually grounded in physiology, although it may appear like a strong assumption at a first glance: related inputs arrive at local clusters of spines synchronously [<xref ref-type="bibr" rid="c60">60</xref>]. We have modelled these dendritic patches that synchronously get excited by correlated inputs as one dendritic compartment. When a sufficiently large number of dendritic compartments have been excited, the soma will spike. We have not explicitly accounted for inhibition in this model. Because our focus is to account for how transient signals can be summed and thresholded robustly, we are assuming that inhibition is implicitly accounted for in the lumped abstraction.</p>
<p>We transplanted the weight matrices of the BNN onto the spiking network, thereby obtaining a spiking network that can do the classification. When the input neurons all spike exactly simultaneously, the spiking network mimics the BNN exactly, i.e. the same units are active in both. But when asychrony is introduced, a discrepancy can arise. We introduce asynchrony in the network by moving the timing of the input spikes. Two examples of the spiking network receiving jittered input spikes are shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref> and <xref ref-type="fig" rid="fig4">E</xref>. In <xref ref-type="fig" rid="fig4">Figure 4D</xref> the dendrites are furnished with plateau potentials, (as in <xref ref-type="fig" rid="fig2">Figure 2F</xref>, top). For these three input vectors, the network gives the correct answer despite the input spike jitter. In fact, the identity of the neurons spiking are still the same units that emit a 1 in its BNN counterpart.</p>
<p>This stands in contrast with the network performance without dendritic plateaus (<xref ref-type="fig" rid="fig4">Figure 4E</xref>), where the dendrites had no plateau potentials, (as in <xref ref-type="fig" rid="fig2">Figure 2F</xref>, bottom). In <xref ref-type="fig" rid="fig4">Figure 4E</xref> it can be seen that the network now fails to process two of the three input vectors correctly. The duration of the dendritic spikes is too short so that the dendritic spikes are separated in time, and the soma fails to sum them all. To test how quickly this leads to a degradation of performance, we tested the accuracy (as percentage of inputs classified correctly) of the network as the asynchrony increased. The network with active dendrites coped well, but the performance of the network without dendrites with plateau potentials degraded rapidly. This is quantified in <xref ref-type="fig" rid="fig4">Figure 4F</xref>, where we see that classification accuracy drops precipitously if spike timing jitter exceeds the membrane timeconstant significantly. In contrast, dendritic plateaus maintain performance even when spike jitter exceeds membrane timeconstant by an order of magnitude.</p>
<p>Together, these results show in principle how a cellular mechanism that captures the essential abstract features of dendritic spikes can serve to enhance robustness of non-trivial spiking computations in a network. Furthermore, they provide an abstract interpretation of rapid spiking computations as binary neural network computations.</p>
</sec>
</sec>
<sec id="s3">
<label>2</label>
<title>Discussion</title>
<p>An animal’s survival often depends on its ability to make rapid decisions. Consequently, there will be evolutionary pressure for neural circuits to function at the most rapid timescale possible in some situations. For example, studies of primate visual reaction time estimate each neuron in the synaptic pathway has approximately 10 ms to make a firing decision, a time window allowing 1-2 spikes in each unit on average [<xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c61">61</xref>]. This places the excitatory units in these pathways in an effectively binary regime: either a neuron fires once during the entire computation or it does not. We asked how cortical neurons might exploit dendritic nonlinearities to make such rapid computations feasible in the biologically realistic situation of spike timing jitter and signalling noise.</p>
<p>Traditionally thought to be passive cables, we now know that dendrites possess a zoo of voltage-gated ion channels that generate nonlinear membrane potential dynamics [<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c55">55</xref>, <xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c43">43</xref>]. As with axonal conduction, dendritic excitability provides a means for signals to overcome spatial attenuation so it is perhaps not surprising to find regenerative currents in dendrites, particularly the long, thin dendrites of cortical neurons.</p>
<p>It is far less obvious why dendritic action currents are so much slower than their axonal counterparts. Their temporal dynamics, along with their nonlinear amplitude dependence opens numerous ways for neurons to process time-varying signals. For instance, the dendrites of pyramidal neurons can perform complex tasks such as the discrimination of temporal signals [<xref ref-type="bibr" rid="c7">7</xref>] or the detection of coincident inputs [<xref ref-type="bibr" rid="c36">36</xref>]. In parallel with providing rich signal processing capabilities, dendritic currents also shape activity-dependent synaptic plasticity dynamics, and may thus allow neural circuits to learn temporal patterns [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c23">23</xref>].</p>
<p>We considered a complementary role for dendritic action currents that is not in conflict with any of these ideas, yet it addresses an outlying problem we believe is essential: making rapid cortical computation robust. Conduction delays and noise make asynchrony unavoidable in communication between circuits in the brain [<xref ref-type="bibr" rid="c15">15</xref>]. This poses a fundamental problem for the integration of related inputs: neurons with short membrane time constants can only integrate coincident inputs that arrive simultaneously within ~1 ms of one another. Here, we have shown that slow time constants, which are provided by NMDA depolarization events within dendritic branches, can remedy the situation by widening the integration time window of neurons.</p>
<p>Our hypothesis is consistent with several known experimental findings. It has been shown that the blocking of NMDA receptors impairs precise spike-timing asynchrony and inter-area communication [<xref ref-type="bibr" rid="c67">67</xref>]. This hints at an important role for NMDA in facilitating reliable synchronous communication between neuronal circuits. Recently it was shown that NMDA spikes are a major determinant of neuronal output in vivo, and that these dendritic spikes can be triggered by a handful of synaptic inputs [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c56">56</xref>, <xref ref-type="bibr" rid="c9">9</xref>]. This is in line with the image we have sketched here, where NMDA spikes allow the network to perform computations with sparse spiking patterns.</p>
<p>We have been careful to respect the essence of basic physiological facts while trying to build an abstraction of how elementary spiking computations might occur. One conspicuous omission is to account for temporal variation in inhibition, which plays an important role in determining when and if spikes can fire in a network. We have two motivations for leaving this issue to one side in the present work: First, we wanted to isolate a mechanistic ‘kernel’ for dealing with spiking jitter in excitatory input by assuming that inhibition is present, and, at minimum, not making matters worse. In this setting one may interpret the excitatory inputs to the abstract model in the network (<xref ref-type="fig" rid="fig4">Figure 4</xref>) as a <italic>net</italic> drive in the presence of both inhibition and excitation. We feel this is reasonable because inhibitory signals in many local circuits reflect local population activity and often reliably track excitatory input [<xref ref-type="bibr" rid="c24">24</xref>]. Secondly, overwhelming evidence shows that inhibition itself plays an important role in enhancing synchrony in neural populations [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c64">64</xref>]. We want to return to the question of integrating these features of the physiology in future work, our hypothesis being that integrate-and-hold can serve to improve computational robustness, as we have shown, and furthermore permit information to be preserved throughout the phase of prominent network level oscillations in the brain that are largely orchestrated by inhibition.</p>
<p>An alternative approach to building spiking computations that uses sparse spiking is for post-synaptic targets to become sensitive to specific, predictable, patterns of asynchronous spikes. Several computational studies have shown this is possible in principle using surrogate gradient learning rules that allow networks to perform computations based on relative spike-timings [<xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c66">66</xref>]. However, these solutions are by design sensitive—rather than invariant—to the precise timing and order of inputs. It is therefore not clear that such solutions would work when networks are required to operate robustly on the fastest possible timescale.</p>
<p>Synchrony could potentially be maintained in networks that are organized as feed-forward “synfire chains”, with relatively homogeneous transmission delays between nodes in each “rung” [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c26">26</xref>]. [<xref ref-type="bibr" rid="c33">33</xref>] emphasize a role for refractoriness in maintaining synchrony, nothing that post-spike inhibition “clips” late inputs, thereby maintaining a localized packet in time. [<xref ref-type="bibr" rid="c30">30</xref>] explore further the importance of dendritic nonlinearities in stabilizing packet synchrony.</p>
<p>The significance of our work is to show that sparse yet reliable spiking computations may not require precisely synchronized inputs, and may aid in making computations robust when inputs are only partially synchronised. This perceived necessity has sometimes been raised as an objection to the possibility of spiking computations based on spike times [<xref ref-type="bibr" rid="c39">39</xref>]. Much effort has been devoted to finding out the extent to which neuronal noise can deteriorate the function of neural networks [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c68">68</xref>]. Sometimes out of practical necessity, these studies may assume a point model of a neuron [<xref ref-type="bibr" rid="c19">19</xref>]. Dendritic arbors and their dynamics may obviate some of the apparent fragility of spiking computations.</p>
<p>Other, simpler solutions to the asynchrony problem have been proposed. On possibility is that neural circuits exploit population averaging to overcome spike timing jitter [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c52">52</xref>, <xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c11">11</xref>]. However, this this is energetically costly [<xref ref-type="bibr" rid="c4">4</xref>] and would amount to scaling up the number of cells in a network to perform computations that could, in principle, be performed by more robust single units.</p>
<p>In contrast, we have argued that NMDA currents in distal dendrites can achieve robust, reliable threshold-based computation using relatively few resources. The longer duration of these potentials confers robustness to input timing without additional learning, reducing the number of neurons that must spike to achieve reliable signal transmission. Our key prediction is that neurons in some circuits use these dendritic potentials to make coincidence detection robust, allowing them to fire reliably despite input-timing variability larger than the membrane time constant. We would expect to find these mechanisms in circuits that detect or distinguish specific inputs rapidly, such as in the early stages of perception, or in circuits that coordinate long-range communication across multiple areas of the brain.</p>
<p>Fast action potentials allow rapid, massively parallel communication in the brain. In principle this gives spiking networks the ability to perform complex computations efficiently. However, decades of research has identified obstacles to implementing spiking computations under biologically realistic conditions and in hardware. Our work offers a possible means for rapid spiking computations to function robustly by providing a resettable temporal buffer in the input to each spiking unit. We would be excited to see experimental tests of whether dendrites do indeed operate in this way in the nervous system, and whether this simple principle offers a bio-inspired means to scale up reliable spiking computations in artificial neural networks.</p>
</sec>
<sec id="s4">
<label>3</label>
<title>Methods</title>
<sec id="s4a">
<label>3.1</label>
<title>Biophysical model</title>
<p>The biophysical model used to test the plausibility of the abstract model was taken from [<xref ref-type="bibr" rid="c18">18</xref>], and was implemented in NEURON (version 7.5) [<xref ref-type="bibr" rid="c27">27</xref>]. The model can be found on ModelDB (no. 249705). The model represented a layer 5 pyramidal neuron [<xref ref-type="bibr" rid="c2">2</xref>], and consisted of 85 compartments and 439 segments; 36 compartments for basal dendrites, 45 for apical dendrites, 3 for the soma, and one for the axon. A range of voltage-gated ion channels is included: sodium, A-type potassium, both high-voltage and low-voltage gated calcium, HCN, calcium-activated potassium, and Kv type channels are present.</p>
<p>The glutamate release is simulated at basal dendrites with the indices 14, 15, and 34. These indices were chosen for no particular reason; any collection of numbers would have worked. The glutamate stimuli were all given a fraction of 0.9 away from the soma (where 1 is the total length of the dendrite), and were separated in time from each other with a 50ms delay.</p>
<p>For <xref ref-type="fig" rid="fig2">Figure 2G</xref>, a passive inhibitory current was added to basal dendrite 34 in which an NMDA spike was triggered. The reversal potential of this current was that of GABA<sub>A</sub>, i.e. −80 mV. The maximal conductance of this current was simulated as <italic>g<sub>inhib</sub></italic> = <italic>ḡ</italic><sub>inhib</sub><italic>w</italic><sub>inhib</sub>, with <italic>ḡ</italic><sub>inhib</sub> being the maximal conductance of 0.001 mS / cm<sup>2</sup>, and <italic>w</italic><sub>inhib</sub> the weight that was varied during the simulation, such that <italic>w</italic> = {0.0, 1.0, 2.5, 2.0, 3.0, 3.5, 4.0}. In <xref ref-type="fig" rid="fig2">Figure 2G</xref> we plotted against the dimensionless quantity <italic>g</italic><sub>inhib</sub>/<italic>g</italic><sub>NMDA</sub>, where <italic>g</italic><sub>NMDA</sub> is 0.005 mS / cm<sup>2</sup>.</p>
</sec>
<sec id="s4b">
<label>3.2</label>
<title>Abstract model</title>
<p>The simplified model in <xref ref-type="fig" rid="fig2">Figure 2E,F</xref> is described by two differential equations for each dendritic branch, and two for the soma. The dynamics of the dendritic membrane potential <italic>V<sup>d</sup></italic> and somatic potential <italic>V<sup>s</sup></italic> are given by
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="533815v1_eqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="533815v1_eqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="533815v1_eqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="533815v1_eqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="533815v1_eqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="533815v1_eqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>g<sub>l</sub></italic> is the leak conductance, <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the current triggered by a spike arriving at dendrite <italic>i</italic>, <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the current flowing between dendrite <italic>i</italic> and the soma, with <italic>g<sub>i</sub></italic> the conductance between the two, <italic>τ</italic><sup><italic>x</italic></sup> is the time constant of variable <italic>x, I<sup>r</sup></italic> is a refractory current, and <italic>s</italic> is the postsynaptic conductance of the neuron. When the dendrite reaches threshold Θ<sup>dendrite</sup> the dendrite remains at threshold for <italic>P</italic> ms:
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="533815v1_eqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>When the soma reaches its threshold Θ<sup>soma</sup> a spike is triggered:
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="533815v1_eqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="533815v1_eqn9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="533815v1_eqn10.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="533815v1_eqn11.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
i.e. the membrane potential is reset, a refractory current is activated, and the postsynaptic conductance increases.</p>
<p>Unless mentioned otherwise, the parameter values that were used in simulations are given in <xref ref-type="table" rid="tbl1">Table 1</xref>.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Standard values of parameters used</p></caption>
<graphic xlink:href="533815v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>For <xref ref-type="fig" rid="fig2">Figure 2E,F</xref>, for the case with active dendrites, we used this abstract model, furnished with three dendritic compartments. The dendrites were given boxcar functions, with an amplitude of 50 and a width of 1ms, as input pulses:
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="533815v1_eqn12.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
and <italic>i</italic> ∈ {1, 2, 3}. These input pulses were spaced 10 ms apart; <italic>t</italic><sub>input,<italic>i</italic></sub> = 10<italic>i</italic> ms. Each pulse is strong enough by itself to trigger the plateau in each dendrite, thereby extending its duration. Taken together these three plateaus are strong enough to trigger a spike in the soma. For <xref ref-type="fig" rid="fig2">Figure 2E,F</xref>, for the case without dendrites, these pulses were fed to the soma directly. Due to the lack of plateaus they do not sum and fail to trigger a spike.</p>
</sec>
<sec id="s4c">
<label>3.3</label>
<title>Neuron with asynchronous inputs</title>
<p>For <xref ref-type="fig" rid="fig3">Figure 3</xref> the abstract model was used. The spike times of the incoming spikes were drawn from a normal distribution. The jitter of the spike times was defined as the standard deviation of this distribution. This jitter should always be compared with the membrane time constant <italic>τ</italic> of the neuron, for which we used 1 ms.</p>
<p>We used jitter values of 1<italic>τ</italic> for the synchronous case and 10<italic>τ</italic> for the asynchronous case respectively, i.e. <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline3.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
<p>For all the computed values 500 simulations with a single neuron and randomly initialized spiketimes were performed. During each simulation, the neuron received 10 input spikes. For <xref ref-type="fig" rid="fig3">Figure 3B</xref>, the solid line is the mean voltage over the ensemble of simulations, and the shaded region is the inner 90% of the voltage distribution.</p>
<p>In <xref ref-type="fig" rid="fig3">Figure 3C,D,E</xref> all variables were computed inside the window of spikes arriving. The peak depolarization plotted is the mean of the ensemble of peak depolarizations for each simulation. Similarly, the coefficient of variation <italic>C<sub>v</sub></italic> plotted is the <italic>C<sub>v</sub></italic> for each jitter value, where that particular <italic>C<sub>v</sub></italic> is computed over all 500 simulations for that jitter value.</p>
<p>For <xref ref-type="fig" rid="fig3">Figure 3E</xref> the minimum number of input spikes was computed that would push <italic>C<sub>v</sub></italic> down to 0.1 for a particular value of the jitter value.</p>
</sec>
<sec id="s3d">
<label>3.4</label>
<title>Binary network</title>
<p>The data consisted of 2D points which were assigned to different classes. The three classes were Gaussian clusters, with means <italic>μ<sub>i</sub></italic> = {(4, 5), (−12, 2), (10, −7)} respectively, and isotropic covariance of <italic>σ</italic> = 1.5. 100 points <italic>x<sub>i</sub></italic> per class <italic>i</italic> were generated from <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline4.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
<p>The task of the binary neural network (BNN) was to classify the points correctly. Because we wanted to interpret the continuous 2D points as input spikes to our network, we binarized the data first. To this end the input vectors <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline5.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> were transformed by mapping them onto {0,1}<sup>13</sup>, i.e. every point was mapped onto a 13 dimensional vector of ones and zeros. This was achieved by randomly generating <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline6.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline7.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Then we applied
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>To train our binary network we made use of surrogate gradients [<xref ref-type="bibr" rid="c46">46</xref>]. In short, we defined a function <italic>ϕ</italic> that for the forward pass (i.e. the network unit outputs) acted like a step function
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>But for the purposes of backpropagation the derivative of <italic>ϕ</italic> is defined to be
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
which is the superspike derivative [<xref ref-type="bibr" rid="c65">65</xref>], equivalent to the derivative of a fast sigmoid. Using this derivative allows us to train the network, in spite of the step function having a derivative that is zero almost everywhere.</p>
<p>The network weights were initialized with the distribution:
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline8.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
<p>The biases of the BNN units were set to −1, to enforce a positive firing threshold for the neurons.</p>
<p>Each dendrite receives input from one presynaptic neuron. Let <italic>N<sub>d</sub></italic> be the number of dendrites per neuron for a layer, and <italic>N<sub>o</sub></italic> the number of somas. First an <italic>N<sub>d</sub></italic> × <italic>N<sub>d</sub></italic> diagonal matrix is constructed for each soma in the next layer. Then the total weight matrix will be the vertical concatenation of all these diagonal matrices.</p>
<p>Similarly, each dendrite is coupled with only one soma. This is achieved by constructing an <italic>N<sub>o</sub></italic> × <italic>N<sub>d</sub></italic> matrix for output unit <italic>i</italic> where only the ith row is non-zero. The overall weight matrix is the horizontal concatenation of these matrices.</p>
<p>The weight matrices used by the network alternate between the matrices with ‘dendrites constraints’ (a matrix that projects onto a layer of dendrites), and matrices with ‘soma constraints’ (a matrix projecting onto a layer of somas).</p>
<p>For both weight matrices elements that are initially zero, remain zero during the training procedure, and the elements of the weight matrices were constrained to be nonnegative, by having the activation of a unit in the BNN be
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>We implemented this constraint because we modelled pyramidal neurons, which are excitatory neurons. Therefore, the weights from the connections of these neurons should be positive.</p>
<p>The BNN was trained using stochastic gradient descent and surrogate gradient methods. First the network outputs <italic>ŷ</italic>(<italic>x</italic>) where put through the softmax function
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="533815v1_eqn13.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
which was then parsed through the cross-entropy function
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="533815v1_eqn14.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <bold>ŷ</bold><sub><italic>i</italic></sub> is the output in response to input <bold>x</bold><sub><italic>i</italic></sub> belonging to the batch of size <italic>B</italic> and <italic>y<sub>i,j</sub></italic> the <italic>j</italic>th element of the corresponding target.</p>
<p>The stochastic gradient descent was performed by randomly shuffling the inputs and labels and choosing a batch size (30 in our case). Then in each epoch all batches were iterated over, and the parameters were updated using the Adam algorithm. Training was terminated when the network gave the correct answer for more than 90% of all input points.</p>
</sec>
<sec id="s3e">
<label>3.5</label>
<title>Spiking network</title>
<p>After having a set of weights that gave good performance with the BNN those weights were transplanted to a spiking network with the abstract models from subsection 3.2. This was done through setting the input currents to
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>s<sub>j</sub></italic>(<italic>t</italic>) is the postsynaptic conductance of neuron <italic>j</italic>, which projects on dendrites <italic>i</italic> with weight <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline9.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Here, <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline10.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the nonzero element of the ith row of the weight matrix of this layer, trained with the ‘dendrite constraints’ (see subsection 3.4). This element is unique due to the constraints imposed on the weight matrices during training.</p>
<p>This dendrite is coupled to its soma with weight <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline11.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> to give the current
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
with <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline12.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> the (again unique) nonzero element of the ith row of the next weight matrix, trained with the ‘soma constraints’, and so on.</p>
<p>The 13 dimensional spikes were fed into the network by means of an input layer. This layer consisted of 13 neurons, one for each element in the binary input vectors. If the corresponding element was a 1, this neuron would be made to fire by giving them the same boxcar-shaped input current as described in subsection 3.2.</p>
<p>The degree of synchrony in the input spikes could then be controlled by varying the timing at which these impulses were given to the input neurons. Every input spike packet was centered around an input time <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline13.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Then the degree of asynchrony <italic>τ</italic> was varied by letting each spiketime, for each input neuron <italic>i</italic>, be
<disp-formula>
<alternatives><graphic xlink:href="533815v1_ueqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>To compare the performance of a spiking network without the dendritic plateaus to networks with plateaus, the ‘hold’ on the dynamics of <inline-formula><alternatives><inline-graphic xlink:href="533815v1_inline14.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> was removed. Therefore, the dendrite potential would decay immediately back to rest after reaching threshold. Otherwise, the architecture remained unchanged. For <xref ref-type="fig" rid="fig4">Figure 4D,E</xref> the input volleys were centered at 15ms, 35ms, and 55ms, with an asynchrony measure of <italic>τ</italic> = 10ms.</p>
<p>An answer given by the spiking network was considered correct if neuron <italic>i</italic> in the output layer produced one spike when the input point belonged to class <italic>i</italic>, and the other neurons remained silent.</p>
<p>To compare the accuracies with and without plateaus in <xref ref-type="fig" rid="fig4">Figure 4F</xref>, the spiketimes of the input neurons were produced independently for each data point and each value of <italic>τ</italic>, with the spike packet being centered at 10 ms. Then the same spiketimes were used for both network versions, and the accuracy of the network was measured as the percentage of points classified correctly by the network. In each simulation, each network saw one input vector only, to prevent interference from multiple overlapping inputs for high jitter values.</p>
</sec>
</sec>
</body>
<back>
<ack>
<label>4</label>
<title>Acknowledgements</title>
<p>This work was supported by ERC grant 716643 FLEXNEURO (TO), an Engineering and Physical Sciences Research Council DTP studentship (TJSB) and a Leverhulme and Isaac Newton Trust Fellowship (MER).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="book"><string-name><surname>Abeles</surname>, <given-names>M.</given-names></string-name> <source>Corticonics: Neural Circuits of the Cerebral Cortex</source>. <publisher-name>Cambridge University Press</publisher-name>, <month>Feb</month>. <year>1991</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><surname>Acker</surname>, <given-names>C. D.</given-names></string-name>, and <string-name><surname>Antic</surname>, <given-names>S. D.</given-names></string-name> <article-title>Quantitative Assessment of the Distributions of Membrane Conductances Involved in Action Potential Backpropagation Along Basal Dendrites</article-title>. <source>Journal of Neurophysiology</source> <volume>101</volume>, <issue>3</issue> (<month>Mar</month>. <year>2009</year>), <fpage>1524</fpage>–<lpage>1541</lpage>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><surname>Antic</surname>, <given-names>S. D.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>W.-L.</given-names></string-name>, <string-name><surname>Moore</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Short</surname>, <given-names>S. M.</given-names></string-name>, and <string-name><surname>Ikonomu</surname>, <given-names>K. D.</given-names></string-name> <article-title>The decade of the dendritic NMDA spike</article-title>. <source>Journal of Neuroscience Research</source> <volume>88</volume>, <issue>14</issue> (<year>2010</year>), <fpage>2991</fpage>–<lpage>3001</lpage>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><surname>Attwell</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Laughlin</surname>, <given-names>S. B.</given-names></string-name> <article-title>An Energy Budget for Signaling in the Grey Matter of the Brain</article-title>. <source>Journal of Cerebral Blood Flow &amp; Metabolism</source> <volume>21</volume>, <issue>10</issue> (<month>Oct</month>. <year>2001</year>), <fpage>1133</fpage>–<lpage>1145</lpage>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><surname>Bartolo</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Saunders</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Mitz</surname>, <given-names>A. R.</given-names></string-name>, and <string-name><surname>Averbeck</surname>, <given-names>B. B.</given-names></string-name> <article-title>Information-Limiting Correlations in Large Neural Populations</article-title>. <source>Journal of Neuroscience</source> <volume>40</volume>, <issue>8</issue> (<month>Feb</month>. <year>2020</year>), <fpage>1668</fpage>–<lpage>1678</lpage>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><surname>Bernander</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Douglas</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name>, and <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name> <article-title>Synaptic background activity influences spatiotemporal integration in single pyramidal cells</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>88</volume>, <issue>24</issue> (<month>Dec</month>. <year>1991</year>), <fpage>11569</fpage>–<lpage>11573</lpage>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>B. A.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> <article-title>Dendritic Discrimination of Temporal Input Sequences in Cortical Neurons</article-title>. <source>Science</source> <volume>329</volume>, <issue>5999</issue> (<month>Sept</month>. <year>2010</year>), <fpage>1671</fpage>–<lpage>1675</lpage>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> <article-title>The single dendritic branch as a fundamental functional unit in the nervous system</article-title>. <source>Current opinion in neurobiology</source> <volume>20</volume>, <issue>4</issue> (<year>2010</year>), <fpage>494</fpage>–<lpage>502</lpage>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> <article-title>Synaptic Integration Gradients in Single Cortical Pyramidal Cell Dendrites</article-title>. <source>Neuron</source> <volume>69</volume>, <issue>5</issue> (<month>Mar</month>. <year>2011</year>), <fpage>885</fpage>–<lpage>892</lpage>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><surname>Brodin</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Traven</surname>, <given-names>H. G.</given-names></string-name>, <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Wallen</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Ekeberg</surname>, <given-names>O.</given-names></string-name>, and <string-name><surname>Grillner</surname>, <given-names>S.</given-names></string-name> <article-title>Computer simulations of N-methyl-D-aspartate receptor-induced membrane properties in a neuron model</article-title>. <source>Journal of Neurophysiology</source> <volume>66</volume>, <issue>2</issue> (<month>Aug</month>. <year>1991</year>), <fpage>473</fpage>–<lpage>484</lpage>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><surname>Butts</surname>, <given-names>D. A.</given-names></string-name>, and <string-name><surname>Goldman</surname>, <given-names>M. S.</given-names></string-name> <article-title>Tuning Curves, Neuronal Variability, and Sensory Coding</article-title>. <source>PLOS Biology</source> <volume>4</volume>, <issue>4</issue> (<month>Mar</month>. <year>2006</year>), <fpage>e92</fpage>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><surname>Buzsaki</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Draguhn</surname>, <given-names>A.</given-names></string-name> <article-title>Neuronal oscillations in cortical networks</article-title>. <source>science</source> <volume>304</volume>, <issue>5679</issue> (<year>2004</year>), <fpage>1926</fpage>–<lpage>1929</lpage>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><surname>Destexhe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Rudolph</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Paré</surname>, <given-names>D.</given-names></string-name> <article-title>The high-conductance state of neocortical neurons in vivo</article-title>. <source>Nature reviews neuroscience</source> <volume>4</volume>, <issue>9</issue> (<year>2003</year>), <fpage>739</fpage>–<lpage>751</lpage>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><surname>DeWeese</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Wehr</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Zador</surname>, <given-names>A. M.</given-names></string-name> <article-title>Binary Spiking in Auditory Cortex</article-title>. <source>Journal of Neuro-science</source> <volume>23</volume>, <issue>21</issue> (<month>Aug</month>. <year>2003</year>), <fpage>7940</fpage>–<lpage>7949</lpage>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><surname>Faisal</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Selen</surname>, <given-names>L. P. J.</given-names></string-name>, and <string-name><surname>Wolpert</surname>, <given-names>D. M.</given-names></string-name> <article-title>Noise in the nervous system</article-title>. <source>Nature Reviews Neuroscience</source> <volume>9</volume>, <issue>4</issue> (<month>Apr</month>. <year>2008</year>), <fpage>292</fpage>–<lpage>303</lpage>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="book"><string-name><surname>Földiák</surname>, <given-names>P.</given-names></string-name> <chapter-title>The ‘Ideal Homunculus’: Statistical Inference from Neural Population Responses</chapter-title>. In <source>Computation and Neural Systems</source>, <person-group person-group-type="editor"><string-name><given-names>F. H.</given-names> <surname>Eeckman</surname></string-name> and <string-name><given-names>J. M.</given-names> <surname>Bower</surname></string-name></person-group>, Eds. <publisher-name>Springer US</publisher-name>, <publisher-loc>Boston, MA</publisher-loc>, <year>1993</year>, pp. <fpage>55</fpage>–<lpage>60</lpage>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><surname>Franke</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Fiscella</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sevelev</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Roska</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Hierlemann</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Azeredo da Silveira</surname>, <given-names>R.</given-names></string-name> <article-title>Structures of Neural Correlation and How They Favor Coding</article-title>. <source>Neuron</source> <volume>89</volume>, <issue>2</issue> (<month>Jan</month>. <year>2016</year>), <fpage>409</fpage>–<lpage>422</lpage>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><surname>Gao</surname>, <given-names>P. P.</given-names></string-name>, <string-name><surname>Graham</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>W.-L.</given-names></string-name>, <string-name><surname>Jang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Angulo</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Dura-Bernal</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hines</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lytton</surname>, <given-names>W. W.</given-names></string-name>, and <string-name><surname>Antic</surname>, <given-names>S. D.</given-names></string-name> <article-title>Local glutamate-mediated dendritic plateau potentials change the state of the cortical pyramidal neuron</article-title>. <source>Journal of Neurophysiology</source> <volume>125</volume>, <issue>1</issue> (<month>Jan</month>. <year>2021</year>), <fpage>23</fpage>–<lpage>42</lpage>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="book"><string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Kistler</surname>, <given-names>W. M.</given-names></string-name> <source>Spiking Neuron Models: Single Neurons, Populations, Plasticity</source>. <publisher-name>Cambridge University Press</publisher-name>, <month>Aug</month>. <year>2002</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><surname>Goaillard</surname>, <given-names>J.-M.</given-names></string-name>, <string-name><surname>Moubarak</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Tapia</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Tell</surname>, <given-names>F.</given-names></string-name> <article-title>Diversity of axonal and dendritic contributions to neuronal output</article-title>. <source>Frontiers in cellular neuroscience</source> <volume>13</volume> (<year>2020</year>), <fpage>570</fpage>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><surname>Goetz</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Roth</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> <article-title>Active dendrites enable strong but sparse inputs to determine orientation selectivity</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>118</volume>, <issue>30</issue> (<month>July</month> <year>2021</year>), <fpage>e2017339118</fpage>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><surname>Gómez González</surname>, <given-names>J. F.</given-names></string-name>, <string-name><surname>Mel</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Poirazi</surname>, <given-names>P.</given-names></string-name> <article-title>Distinguishing Linear vs. Non-Linear Integration in CA1 Radial Oblique Dendrites: It’s about Time</article-title>. <source>Frontiers in Computational Neuroscience</source> <volume>5</volume> (<year>2011</year>).</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><surname>Gütig</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Sompolinsky</surname>, <given-names>H.</given-names></string-name> <article-title>The tempotron: A neuron that learns spike timing–based decisions</article-title>. <source>Nature Neuroscience</source> <volume>9</volume>, <issue>3</issue> (<month>Mar</month>. <year>2006</year>), <fpage>420</fpage>–<lpage>428</lpage>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><surname>Haider</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Duque</surname>, <given-names>a.</given-names></string-name>, <string-name><surname>Hasenstaub</surname>, <given-names>A. R.</given-names></string-name>, and <string-name><surname>McCormick</surname>, <given-names>D. A.</given-names></string-name> <article-title>Neocortical network activity in vivo is generated through a dynamic balance of excitation and inhibition</article-title>. <source>Journal of Neuroscience</source> <volume>26</volume>, <issue>17</issue> (<year>2006</year>), <fpage>4535</fpage>–<lpage>4545</lpage>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><surname>Hemberger</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Shein-Idelson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Pammer</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Laurent</surname>, <given-names>G.</given-names></string-name> <article-title>Reliable sequential activation of neural assemblies by single pyramidal cells in a three-layered cortex</article-title>. <source>Neuron</source> <volume>104</volume>, <issue>2</issue> (<year>2019</year>), <fpage>353</fpage>–<lpage>369</lpage>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><surname>Herrmann</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hertz</surname>, <given-names>J. A.</given-names></string-name>, and <string-name><surname>Prügel-Bennett</surname>, <given-names>A.</given-names></string-name> <article-title>Analysis of synfire chains</article-title>. <source>Network: Computation in Neural Systems</source> <volume>6</volume>, <issue>3</issue> (<month>Jan</month>. <year>1995</year>), <fpage>403</fpage>–<lpage>414</lpage>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><surname>Hines</surname>, <given-names>M. L.</given-names></string-name>, and <string-name><surname>Carnevale</surname>, <given-names>N. T.</given-names></string-name> <article-title>The NEURON Simulation Environment</article-title>. <source>Neural Computation</source> <volume>9</volume>, <issue>6</issue> (<month>Aug</month>. <year>1997</year>), <fpage>1179</fpage>–<lpage>1209</lpage>.</mixed-citation></ref>
<ref id="c28"><label>[45]</label><mixed-citation publication-type="journal"><string-name><surname>Histed</surname>, <given-names>M. H.</given-names></string-name>, and <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> <article-title>Cortical neural populations can guide behavior by integrating inputs linearly, independent of synchrony</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>111</volume>,<issue>1</issue> (<year>2014</year>), <fpage>E178</fpage>–<lpage>E187</lpage>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><surname>Jacobs</surname>, <given-names>a. L.</given-names></string-name>, <string-name><surname>Fridman</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Douglas</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Alam</surname>, <given-names>N. M.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name>, <string-name><surname>Prusky</surname>, <given-names>G. T.</given-names></string-name>, and <string-name><surname>Nirenberg</surname>, <given-names>S.</given-names></string-name> <article-title>Ruling out and ruling in neural codes</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>106</volume>, <issue>14</issue> (<year>2009</year>), <fpage>5936</fpage>–<lpage>5941</lpage>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><surname>Jahnke</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Memmesheimer</surname>, <given-names>R.-M.</given-names></string-name>, and <string-name><surname>Timme</surname>, <given-names>M.</given-names></string-name> <article-title>Propagating synchrony in feed-forward networks</article-title>. <source>Frontiers in Computational Neuroscience</source> <volume>7</volume> (<year>2013</year>), <fpage>153</fpage>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><surname>Johnston</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Magee</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Colbert</surname>, <given-names>C. M.</given-names></string-name>, and <string-name><surname>Christie</surname>, <given-names>B. R.</given-names></string-name> <article-title>Active properties of neuronal dendrites</article-title>. <source>Annual review of neuroscience</source> <volume>19</volume>, <issue>1</issue> (<year>1996</year>), <fpage>165</fpage>–<lpage>186</lpage>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>H. G.</given-names></string-name>, and <string-name><surname>Connors</surname>, <given-names>B. W.</given-names></string-name> <article-title>Apical dendrites of the neocortex: Correlation between sodium- and calcium-dependent spiking and pyramidal cell morphology</article-title>. <source>Journal of Neuroscience</source> <volume>13</volume>, <issue>12</issue> (<month>Dec</month>. <year>1993</year>), <fpage>5301</fpage>–<lpage>5311</lpage>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><surname>Kistler</surname>, <given-names>W. M.</given-names></string-name>, and <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name> <article-title>Stable Propagation of Activity Pulses in Populations of Spiking Neurons</article-title>. <source>Neural Computation</source> <volume>14</volume>, <issue>5</issue> (<month>May</month> <year>2002</year>), <fpage>987</fpage>–<lpage>997</lpage>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rapp</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Segev</surname>, <given-names>I.</given-names></string-name> <article-title>A brief history of time (constants)</article-title>. <source>Cerebral cortex</source> <volume>6</volume>, <issue>2</issue> (<year>1996</year>), <fpage>93</fpage>–<lpage>101</lpage>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><surname>Kohn</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Coen-Cagli</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kanitscheider</surname>, <given-names>I.</given-names></string-name>, and <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name> <article-title>Correlations and Neuronal Population Information</article-title>. <source>Annual review of neuroscience</source> <volume>39</volume> (<month>July</month> <year>2016</year>), <fpage>237</fpage>–<lpage>256</lpage>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><surname>Larkum</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>J. J.</given-names></string-name>, and <string-name><surname>Sakmann</surname>, <given-names>B.</given-names></string-name> <article-title>A new cellular mechanism for coupling inputs arriving at different cortical layers</article-title>. <source>Nature</source> <volume>398</volume>, <issue>6725</issue> (<month>Mar</month>. <year>1999</year>), <fpage>338</fpage>–<lpage>341</lpage>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><surname>Loewenstein</surname>, <given-names>Y.</given-names></string-name>, and <string-name><surname>Sompolinsky</surname>, <given-names>H.</given-names></string-name> <article-title>Temporal integration by calcium dynamics in a model neuron</article-title>. <source>Nature neuroscience</source> <volume>6</volume>, <issue>9</issue> (<year>2003</year>), <fpage>961</fpage>–<lpage>967</lpage>.</mixed-citation></ref>
<ref id="c38"><label>[45]</label><mixed-citation publication-type="journal"><string-name><surname>London</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> <article-title>Dendritic Computation</article-title>. <source>Annual Review of Neuroscience</source> <volume>28</volume>, <issue>1</issue> (<year>2005</year>), <fpage>503</fpage>–<lpage>532</lpage>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><surname>London</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Roth</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Beeren</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name> <article-title>Sensitivity to perturbations in vivo implies high noise and suggests rate coding in cortex</article-title>. <source>Nature</source> <volume>466</volume>, <issue>7302</issue> (<month>July</month> <year>2010</year>), <fpage>123</fpage>–<lpage>127</lpage>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><surname>Losonczy</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Magee</surname>, <given-names>J. C.</given-names></string-name> <article-title>Integrative properties of radial oblique dendrites in hippocampal ca1 pyramidal neurons</article-title>. <source>Neuron</source> <volume>50</volume>, <issue>2</issue> (<year>2006</year>), <fpage>291</fpage>–<lpage>307</lpage>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><surname>Lupanov</surname>, <given-names>O. B.</given-names></string-name> <article-title>Circuits using threshold elements</article-title>. <source>Doklady Akademii Nauk</source> <volume>202</volume>, <issue>6</issue> (<year>1972</year>), <fpage>1288</fpage>–<lpage>1291</lpage>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="book"><string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Schnitger</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Sontag</surname>, <given-names>E.</given-names></string-name> <chapter-title>On the computational power of sigmoid versus Boolean threshold circuits</chapter-title>. In <source>[1991] Proceedings 32nd Annual Symposium of Foundations of Computer Science</source> (<publisher-loc>San Juan, Puerto Rico</publisher-loc>, <year>1991</year>), <publisher-name>IEEE Comput. Soc. Press</publisher-name>, pp. <fpage>767</fpage>–<lpage>776</lpage>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><surname>Major</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Larkum</surname>, <given-names>M. E.</given-names></string-name>, and <string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name> <article-title>Active Properties of Neocortical Pyramidal Neuron Dendrites</article-title>. <source>Annual Review of Neuroscience</source> <volume>36</volume>, <issue>1</issue> (<month>July</month> <year>2013</year>), <fpage>1</fpage>–<lpage>24</lpage>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><string-name><surname>Major</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Polsky</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Denk</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name> <article-title>Spatiotemporally Graded NMDA Spike/Plateau Potentials in Basal Dendrites of Neocortical Pyramidal Neurons</article-title>. <source>Journal of Neurophysiology</source> <volume>99</volume>, <issue>5</issue> (<month>May</month> <year>2008</year>), <fpage>2584</fpage>–<lpage>2601</lpage>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><surname>Makara</surname>, <given-names>J. K.</given-names></string-name>, and <string-name><surname>Magee</surname>, <given-names>J. C.</given-names></string-name> <article-title>Variable dendritic integration in hippocampal ca3 pyramidal neurons</article-title>. <source>Neuron</source> <volume>80</volume>, <issue>6</issue> (<year>2013</year>), <fpage>1438</fpage>–<lpage>1450</lpage>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="other"><string-name><surname>Neftci</surname>, <given-names>E. O.</given-names></string-name>, <string-name><surname>Mostafa</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>zenke</surname>, <given-names>F.</given-names></string-name> <article-title>Surrogate Gradient Learning in Spiking Neural Networks</article-title>. <source>arXiv:1901.09948 [cs, q-bio]</source> (<month>May</month> <year>2019</year>).</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="other"><string-name><surname>O’Leary</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Wyllie</surname>, <given-names>D. J.</given-names></string-name> <article-title>Single-channel properties of n-methyl-d-aspartate receptors containing chimaeric glun2a/glun2d subunits</article-title>, <year>2009</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><surname>Poirazi</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brannon</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Mel</surname>, <given-names>B. W.</given-names></string-name> <article-title>Pyramidal neuron as two-layer neural network</article-title>. <source>Neuron</source> <volume>37</volume>, <issue>6</issue> (<year>2003</year>), <fpage>989</fpage>–<lpage>999</lpage>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><string-name><surname>Polack</surname>, <given-names>P.-O.</given-names></string-name>, <string-name><surname>Friedman</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Golshani</surname>, <given-names>P.</given-names></string-name> <article-title>Cellular mechanisms of brain state–dependent gain modulation in visual cortex</article-title>. <source>Nature neuroscience</source> <volume>16</volume>, <month>9</month> (<year>2013</year>), <fpage>1331</fpage>–<lpage>1339</lpage>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><string-name><surname>Poleg-Polsky</surname>, <given-names>A.</given-names></string-name> <article-title>Dendritic Spikes Expand the Range of Well Tolerated Population Noise Structures</article-title>. <source>The Journal of Neuroscience</source> <volume>39</volume>, <issue>46</issue> (<month>Nov</month>. <year>2019</year>), <fpage>9173</fpage>–<lpage>9184</lpage>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><string-name><surname>Polsky</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mel</surname>, <given-names>B. W.</given-names></string-name>, and <string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name> <article-title>Computational subunits in thin dendrites of pyramidal cells</article-title>. <source>Nature neuroscience</source> <volume>7</volume>, <issue>6</issue> (<year>2004</year>), <fpage>621</fpage>–<lpage>627</lpage>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><string-name><surname>Sanger</surname>, <given-names>T. D.</given-names></string-name> <article-title>Probability density estimation for the interpretation of neural population codes</article-title>. <source>Journal of Neurophysiology</source> <volume>76</volume>, <issue>4</issue> (<month>Oct</month>. <year>1996</year>), <fpage>2790</fpage>–<lpage>2793</lpage>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Major</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Koester</surname>, <given-names>H. J.</given-names></string-name>, and <string-name><surname>Schiller</surname>, <given-names>Y.</given-names></string-name> <article-title>NMDA spikes in basal dendrites of cortical pyramidal neurons</article-title>. <source>Nature</source> <volume>404</volume>, <issue>6775</issue> (<month>Mar</month>. <year>2000</year>), <fpage>285</fpage>–<lpage>289</lpage>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Schiller</surname>, <given-names>Y.</given-names></string-name> <article-title>NMDA receptor-mediated dendritic spikes and coincident signal amplification</article-title>. <source>Current Opinion in Neurobiology</source> <volume>11</volume>, <issue>3</issue> (<month>June</month> <year>2001</year>), <fpage>343</fpage>–<lpage>348</lpage>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Schiller</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Stuart</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Sakmann</surname>, <given-names>B.</given-names></string-name> <article-title>Calcium action potentials restricted to distal apical dendrites of rat neocortical pyramidal neurons</article-title>. <source>The Journal of Physiology</source> <volume>505</volume>, <issue>3</issue> (<year>1997</year>), <fpage>605</fpage>–<lpage>616</lpage>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><string-name><surname>Schmidt-Hieber</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Toleikyte</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Aitchison</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Roth</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name> <article-title>Active dendritic integration as a mechanism for robust and precise grid cell firing</article-title>. <source>Nature Neuroscience</source> <volume>20</volume>, <issue>8</issue> (<month>Aug</month>. <year>2017</year>), <fpage>1114</fpage>–<lpage>1121</lpage>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><string-name><surname>Seung</surname>, <given-names>H. S.</given-names></string-name>, and <string-name><surname>Sompolinsky</surname>, <given-names>H.</given-names></string-name> <article-title>Simple models for reading neuronal population codes</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>90</volume>, <issue>22</issue> (<month>Nov</month>. <year>1993</year>), <fpage>10749</fpage>–<lpage>10753</lpage>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><string-name><surname>Šíma</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Orponen</surname>, <given-names>P.</given-names></string-name> <article-title>General-Purpose Computation with Neural Networks: A Survey of Complexity Theoretic Results</article-title>. <source>Neural Computation</source> <volume>15</volume>, <issue>12</issue> (<month>Dec</month>. <year>2003</year>), <fpage>2727</fpage>–<lpage>2778</lpage>.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal"><string-name><surname>Spencer</surname>, <given-names>W. A.</given-names></string-name>, and <string-name><surname>Kandel</surname>, <given-names>E. R.</given-names></string-name> <article-title>Electrophysiology of hippocampal neurons: Iv. fast prepotentials</article-title>. <source>Journal of Neurophysiology</source> <volume>24</volume>, <issue>3</issue> (<month>May</month> <year>1961</year>), <fpage>272</fpage>–<lpage>285</lpage>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><string-name><surname>Takahashi</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Kitamura</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Matsuo</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mayford</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kano</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Matsuki</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Ikegaya</surname>, <given-names>Y.</given-names></string-name> <article-title>Locally Synchronized Synaptic Inputs</article-title>. <source>Science</source> <volume>335</volume>, <issue>6066</issue> (<month>Jan</month>. <year>2012</year>), <fpage>353</fpage>–<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="book"><string-name><surname>Thorpe</surname>, <given-names>S. J.</given-names></string-name>, and <string-name><surname>Imbert</surname>, <given-names>M.</given-names></string-name> <chapter-title>Biological constraints on connectionist modelling</chapter-title>. In <source>Connectionism in Perspective</source> (<year>1989</year>), <publisher-name>Elsevier</publisher-name>, pp. <fpage>63</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><string-name><surname>VanRullen</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Thorpe</surname>, <given-names>S. J.</given-names></string-name> <article-title>Is it a Bird? Is it a Plane? Ultra-Rapid Visual Categorisation of Natural and Artifactual Objects</article-title>. <source>Perception</source> <volume>30</volume>, <issue>6</issue> (<month>June</month> <year>2001</year>), <fpage>655</fpage>–<lpage>668</lpage>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><string-name><surname>Wei</surname>, <given-names>D.-S.</given-names></string-name>, <string-name><surname>Mei</surname>, <given-names>Y.-A.</given-names></string-name>, <string-name><surname>Bagal</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kao</surname>, <given-names>J. P. Y.</given-names></string-name>, <string-name><surname>Thompson</surname>, <given-names>S. M.</given-names></string-name>, and <string-name><surname>Tang</surname>, <given-names>C.-M.</given-names></string-name> <article-title>Compartmentalized and Binary Behavior of Terminal Dendrites in Hippocampal Pyramidal Neurons</article-title>. <source>Science</source> <volume>293</volume>, <issue>5538</issue> (<month>Sept</month>. <year>2001</year>), <fpage>2272</fpage>–<lpage>2275</lpage>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><string-name><surname>White</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Chow</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>Rit</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Soto-Trevióo</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Kopell</surname>, <given-names>N.</given-names></string-name> <article-title>Synchronization and oscillatory dynamics in heterogeneous, mutually inhibited neurons</article-title>. <source>Journal of computational neuroscience</source> <volume>5</volume> (<year>1998</year>), <fpage>5</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, and <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name> <article-title>SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks</article-title>. <source>Neural Computation</source> <volume>30</volume>, <issue>6</issue> (<month>June</month> <year>2018</year>), <fpage>1514</fpage>–<lpage>1541</lpage>.</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="other"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, and <string-name><surname>Vogels</surname>, <given-names>T. P.</given-names></string-name> <article-title>The remarkable robustness of surrogate gradient learning for instilling complex function in spiking neural networks</article-title>. <source>bioRxiv</source> (<month>June</month> <year>2020</year>), 2020.06.29.176925.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><string-name><surname>Zick</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Crowe</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Blackman</surname>, <given-names>R. K.</given-names></string-name>, <string-name><surname>Schultz</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Bergstrand</surname>, <given-names>D. W.</given-names></string-name>, <string-name><surname>denicola</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Carter</surname>, <given-names>R. E.</given-names></string-name>, <string-name><surname>Ebner</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Lanier</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Netoff</surname>, <given-names>T. I.</given-names></string-name>, and <string-name><surname>Chafee</surname>, <given-names>M. V.</given-names></string-name> <article-title>Disparate insults relevant to schizophrenia converge on impaired spike synchrony and weaker synaptic interactions in prefrontal local circuits</article-title>. <source>Current Biology</source> <volume>32</volume>, <issue>1</issue> (<month>Jan</month>. <year>2022</year>), <fpage>14</fpage>–<lpage>25</lpage>.<page-range>e4</page-range>.</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="journal"><string-name><surname>Zylberberg</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name>, and <string-name><surname>Shea-Brown</surname>, <given-names>E.</given-names></string-name> <article-title>Robust information propagation through noisy neural circuits</article-title>. <source>PLOS Computational Biology</source> <volume>13</volume>, <issue>4</issue> (<month>Apr</month>. <year>2017</year>), <fpage>e1005497</fpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89629.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Berman</surname>
<given-names>Gordon J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Emory University</institution>
</institution-wrap>
<city>Atlanta</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
</front-stub>
<body>
<p>This is an <bold>important</bold> study showing how dendritic plateau potentials can enable neurons to perform reliable 'binary' computations in the face of realistic spike time jitter in cortical networks. The authors make a surprising and novel claim that dendritic plateau potentials perform equally well in short integration windows of only 10 ms and detail a biophysical mechanism for how this effect may occur. While the authors make many good arguments, and the general concept underlying the paper is sound, the evidence as of now is <bold>incomplete</bold>, with some unsupported statements that should be more thoroughly defended in the manuscript.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89629.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This is an elegant didactic exposition showing how dendritic plateau potentials can enable neurons to perform reliable 'binary' computations in the face of realistic spike time jitter in cortical networks. The authors make many good arguments, and the general concept underlying the paper is sound. A strength is their systematic progression from biophiysical to simplified models of single neurons, and their parallel investigation of spiking and binary neural networks, with training happening in the binary neural network.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89629.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Artificial intelligence (AI) could be useful in some applications and could help humankind. Some forms of AI work on the platform of artificial neural networks (ANN). ANNs are inspired by real brains and real neurons. Therefore understanding the repertoire and logic of real neurons could potentially improve AANs. Cell bodies of real neurons, and axons of real neurons, fire nerve impulses (nerve impulses are very brief ~2 ms, and very tall ~100 mV). Dendrites, which comprise ~80% of the total neuronal membrane (80% of the total neuronal apparatus) typically generate smaller (~50 mV amplitude) but much longer (~100 ms duration) electrical transients, called glutamate-mediated dendritic plateau potentials. The authors have built artificial neurons capable of generating such dendritic plateau potentials, and through computer simulations the authors concluded that long-lasting dendritic signals (plateau potentials) reduce negative impact of temporal jitter occurring in real brain, or in AANs. The authors showed that in AANs equipped with neurons whose dendrites are capable of generating local dendritic plateau potentials, the sparse, yet reliable spiking computations may not require precisely synchronized inputs. That means, the real world can impose notable fluctuations in the network activity and yet neurons could still recognize and pair the related network events. In the AANs equipped with dendritic plateaus, the computations are very robust even when inputs are only partially synchronized. In summary, dendritic plateau potentials endow neurons with ability to hold information longer and connect two events which did not happen at the same moment of time. Dendritic plateaus circumvent the negative impact, which the short membrane time constants arduously inflict on the action potential generation (in both real neurons and model neurons). Interestingly, one of the indirect conclusions of the current study is that neurons equipped with dendritic plateau potentials may reduce the total number of cells (nodes, units) required to perform robust computations.</p>
<p>Strengths:</p>
<p>
The majority of published studies are descriptive in nature. Researchers report what they see or measure. A smaller number of studies embark on a more difficult task, which is to explain the logic and rationale of a particular natural design. The current study falls into that second category. The authors first recognize that conduction delays and noise make asynchrony unavoidable in communication between circuits in the real brain. This poses a fundamental problem for the integration of related inputs in real (noisy) world. Neurons with short membrane time constants can only integrate coincident inputs that arrive simultaneously within 2-3 ms of one another. Then the authors considered the role for dendritic plateau potentials. Glutamate-mediated depolarization events within individual dendritic branches, can remedy the situation by widening the integration time window of neurons. In summary, the authors recognized that one important feature of neurons, their dendrites, are built-in to solve the major problems of rapid signal processing: [1] temporal jitter, [2] variation, [3] stochasticity, and [4] reliability of computation. In one word, the dendritic plateau potentials have evolved in the central nervous systems to make rapid CNS computations robust.</p>
<p>Weaknesses:</p>
<p>
The authors made some unsupported statements, which should either be deleted, or thoroughly defended in the manuscript. But first of all, the authors failed to bring this study to the readers who are not experts in computational modeling or Artificial Neural Networks. Critical terms (syntax) and ideas have not been explained. For example: [1] binary feature space? [2] 13 dimensions binary vectors? [3] the binary network could still cope with the loss of information due to the binarization of the continuous coordinates? [4] accurate summation?</p>
</body>
</sub-article>
</article>