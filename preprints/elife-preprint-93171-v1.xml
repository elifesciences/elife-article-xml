<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">93171</article-id>
<article-id pub-id-type="doi">10.7554/eLife.93171</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93171.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Mesoscale functional organization and connectivity of color, disparity, and naturalistic texture in human second visual area</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Ai</surname>
<given-names>Hailin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">†</xref></contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Lin</surname>
<given-names>Weiru</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">†</xref></contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Chengwen</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0890-3875</contrib-id>
<name>
<surname>Chen</surname>
<given-names>Nihong</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9603-8454</contrib-id>
<name>
<surname>Zhang</surname>
<given-names>Peng</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a7">7</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychology, School of Social Sciences, Tsinghua University</institution>, Beijing, 100084, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>State Key Laboratory of Brain and Cognitive Science, Institute of Biophysics, Chinese Academy of Sciences</institution>, Beijing, 100101, <country>China</country></aff>
<aff id="a3"><label>3</label><institution>University of Chinese Academy of Sciences</institution>, Beijing, 100049, <country>China</country></aff>
<aff id="a4"><label>4</label><institution>THU-IDG/McGovern Institute for Brain Research, Tsinghua University</institution>, Beijing 100084, <country>China</country></aff>
<aff id="a5"><label>5</label><institution>Department of Psychology and Cognition and Human Behavior Key Laboratory of Hunan Province, Hunan Normal University</institution>, Hunan, 410081, <country>China</country></aff>
<aff id="a6"><label>6</label><institution>Center for Mind &amp; Brain Sciences, Hunan Normal University</institution>, Changsha, Hunan, 410081, <country>China</country></aff>
<aff id="a7"><label>7</label><institution>Institute of Artificial Intelligence, Hefei Comprehensive National Science Center</institution>, Hefei, 230026, <country>China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Krug</surname>
<given-names>Kristine</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Otto-von-Guericke University Magdeburg</institution>
</institution-wrap>
<city>Magdeburg</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Moore</surname>
<given-names>Tirin</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Stanford University, Howard Hughes Medical Institute</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>†</label><p>H.A. and W.L. contributed equally to this work.</p></fn>
<corresp id="cor1"><label>*</label>Address correspondence to Nihong Chen (<email>nihongch@mail.tsinghua.edu.cn</email>) or Peng Zhang (<email>zhangpeng@ibp.ac.cn</email>)</corresp>
<fn id="n2" fn-type="con"><p>Author contributions: N.C. and P.Z. designed the research. H.A., W.L., C.L., and P.Z. conducted the experiments. H.A., W.L., N.C., and P.Z. analyzed the data. H.A., N.C., and P.Z. wrote the manuscript.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-02-02">
<day>02</day>
<month>02</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP93171</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-10-26">
<day>26</day>
<month>10</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-10-30">
<day>30</day>
<month>10</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.10.26.564178"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Ai et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Ai et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-93171-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Although parallel processing has been extensively studied in the low-level geniculostriate pathway and the high-level dorsal and ventral visual streams, much less is known at the intermediate-level visual areas. In this study, we employed high-resolution fMRI at 7 Tesla to investigate the columnar and laminar organizations for color, disparity, and naturalistic texture in the human secondary visual cortex (V2), and its informational connectivity with lower and higher order visual areas. Although fMRI activations in V2 showed clear and reproducible color-selective thin and disparity-selective thick “stripe” columns, we found no evidence for a columnar organization for naturalistic textures. Cortical depth-dependent analyses revealed the strongest color-selectivity in the superficial layers of V2, along with both feedforward and feedback informational connectivity with V1 and V4. Disparity selectivity was similar across different cortical depths of V2, which showed significant feedforward and feedback connectivity with V1 and V3ab. Interestingly, the selectivity for naturalistic texture was strongest in the deep layers of V2, with significant feedback connectivity from V4. Thus, while local circuitry within cortical columns is crucial for processing color and disparity information, feedback modulations from V4 play a dominant role in processing naturalistic statistics in area V2, which lacks a clear columnar organization.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>V2</kwd>
<kwd>Naturalistic texture</kwd>
<kwd>Color</kwd>
<kwd>Disparity</kwd>
<kwd>7T fMRI</kwd>
<kwd>Cortical columns and layers</kwd>
<kwd>Layer-specific informational connectivity</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>A single glance at the world captures a rich amount of visual information. The initial signals hit on the retina are transformed along the visual hierarchy in a way that different aspects of information are processed in parallel streams (<xref ref-type="bibr" rid="c51">Nassi &amp; Callaway, 2009</xref>). The retina-geniculate-striate pathway of the primate visual system is primarily segregated into the magnocellular (M) and parvocellular (P) streams (<xref ref-type="bibr" rid="c28">Kaplan et al., 1990</xref>; <xref ref-type="bibr" rid="c36">Lee, 1996</xref>; <xref ref-type="bibr" rid="c46">Merigan &amp; Maunsell, 1993</xref>), selectively processing different spatiotemporal frequencies of achromatic and chromatic information. After the input layers of the primary visual cortex (V1), the M and P information are transformed into higher-level visual representations, such as motion, disparity, color, orientation, etc. (<xref ref-type="bibr" rid="c67">Tootell &amp; Nasr, 2017</xref>). In area V2 of the primate visual cortex, the processing of motion/disparity, color and orientation information has been found to be organized into “stripe”-shaped interdigitated columns (<xref ref-type="bibr" rid="c23">Hubel &amp; Livingstone, 1985</xref>, <xref ref-type="bibr" rid="c24">1987</xref>; <xref ref-type="bibr" rid="c61">Roe &amp; Ts’o, 1995</xref>; <xref ref-type="bibr" rid="c69">Ts’O et al., 2001</xref>; <xref ref-type="bibr" rid="c72">Xiao et al., 2003</xref>), corresponding to the ‘thick’, ‘thin’, and ‘pale’ stripes in cytochrome oxidase (CO) staining studies (<xref ref-type="bibr" rid="c40">Livingstone &amp; Hubel, 1982</xref>; <xref ref-type="bibr" rid="c68">Tootell et al., 1983</xref>). The interdigitated columnar organizations for color and motion/disparity processing have also been found in human V2 by high-resolution fMRI at 7 Tesla (<xref ref-type="bibr" rid="c31">Kennedy et al., 2023</xref>; <xref ref-type="bibr" rid="c50">Nasr et al., 2016</xref>).</p>
<p>More recently, primate V2 was also found to be sensitive to high-order statistical dependencies embedded in naturalistic textures (<xref ref-type="bibr" rid="c17">Freeman et al., 2013</xref>), a unique type of information critical for surface and material perception. Computationally, these high-order statistical dependencies were composed of correlations across different orientations, spatial scales, and local positions, which can be calculated from the output of orientation filters in V1 (<xref ref-type="bibr" rid="c17">Freeman et al., 2013</xref>; <xref ref-type="bibr" rid="c58">Portilla &amp; Simoncelli, 2000</xref>). Although weakly represented in V1 (<xref ref-type="bibr" rid="c17">Freeman et al., 2013</xref>; <xref ref-type="bibr" rid="c53">Okazawa et al., 2015</xref>; <xref ref-type="bibr" rid="c75">Ziemba et al., 2016</xref>), the neural selectivity to naturalistic statistics was found to be increasingly stronger in the downstream areas V3 (<xref ref-type="bibr" rid="c34">Kohler et al., 2016</xref>) and V4 (<xref ref-type="bibr" rid="c3">Arcizet et al., 2008</xref>; <xref ref-type="bibr" rid="c53">Okazawa et al., 2015</xref>, <xref ref-type="bibr" rid="c54">2017</xref>). Electrophysiological recordings have also identified later and much weaker sensitivity to naturalistic texture in the superficial and deep layers of V1 compared to V2 (<xref ref-type="bibr" rid="c76">Ziemba et al., 2019</xref>), consistent with an effect of corticocortical feedback modulation. However, it remains unclear whether the neural representations of naturalistic textures arise from local processing within V2 or feedback modulation from higher order visual areas, such as V4.</p>
<p>While interdigitated stripe-shaped columnar organizations for color and motion/disparity processing have been found in primate V2, it remains unknown whether a columnar organization also exists for the processing of naturalistic textures. If local circuits in area V2 are essential for processing high-order naturalistic statistics, specialized cortical columns might develop to enhance computational efficiency (<xref ref-type="bibr" rid="c47">Mountcastle, 1997</xref>; Schulte to <xref ref-type="bibr" rid="c62">Brinke et al., 2022</xref>; <xref ref-type="bibr" rid="c64">Stoop et al., 2013</xref>). A likely candidate for such computational units is the pale stripes, known for their preferential responses to orientation information (<xref ref-type="bibr" rid="c24">Hubel &amp; Livingstone, 1987</xref>; <xref ref-type="bibr" rid="c42">Livingstone &amp; Hubel, 1988</xref>; <xref ref-type="bibr" rid="c43">Lu &amp; Roe, 2008</xref>; <xref ref-type="bibr" rid="c44">Malach et al., 1994</xref>). Alternatively, if feedback modulations from higher order visual areas play a prominent role in generating the selectivity in area V2 to high-order statistical dependencies embedded in naturalist textures, a specialized cortical column may not be necessary for such computations. Furthermore, the integration of local elements across various locations, orientations, and spatial scales, which is necessary for processing high-order statistics, might pose a challenge for early visual areas like V2 to develop a specialized computational module.</p>
<p>To better understand the functional organizations and neural circuits of information processing in area V2, the present study investigated laminar and columnar response profiles for color, disparity, and naturalistic texture in human V2 using 7T fMRI at 1-mm isotropic resolution. Cortical depth-dependent fMRI (also called layer fMRI) allows us to non-invasively measure feedforward, local, and feedback activity in human cerebral cortex (<xref ref-type="bibr" rid="c25">Huber et al., 2017</xref>; <xref ref-type="bibr" rid="c39">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="c52">Norris &amp; Polimeni, 2019</xref>; <xref ref-type="bibr" rid="c55">Olman et al., 2012</xref>; <xref ref-type="bibr" rid="c57">Polimeni &amp; Uludağ, 2018</xref>). By combining laminar fMRI with informational connectivity method (<xref ref-type="bibr" rid="c27">Jia et al., 2020</xref>), we further investigated the feedforward and feedback connectivity between V2 and lower/higher order visual cortical areas. Our results revealed interdigitated stripe-shaped columnar organizations in V2 for color and disparity processing, which involved both feedforward and feedback connectivity with other visual areas in the hierarchy. In contrast, feedback modulations from V4 played a prominent role in processing naturalistic statistics in area V2, which did not exhibit a clear columnar organization.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p><xref rid="fig1" ref-type="fig">Figure 1A</xref> shows the stimuli for the color, disparity, and texture experiments. Color-selective activation was defined as the contrast of fMRI responses between chromatic (Chr) and achromatic (Ach) gratings (1<sup>st</sup> column). Disparity-selective activation was the response difference between disparity-defined sinusoidal gratings (3D) by random dot stereograms (RDSs) and their zero-disparity (2D) counterparts (2<sup>nd</sup> column). Texture-selective activation was the response difference between naturalistic textures (T) and spectrally matched noise (N) (3<sup>rd</sup> column).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>A. Visual stimuli for the fMRI experiments. Left: chromatic and achromatic gratings for the color experiment; Middle: disparity-defined grating and zero-disparity disc from random dots for the disparity experiment; Right: naturalistic texture and spectrally matched noise for the texture experiment. B. Parallel information processing pathways in the early visual areas. C. Layer-specific neural circuitry of feedforward, feedback, and horizontal connections in the early visual areas. S: Superficial layers, M: Middle layers, D: Deep layers.</p></caption>
<graphic xlink:href="564178v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig2" ref-type="fig">Figure 2B</xref> illustrates a simple model for the building blocks of parallel processing streams in area V2 and their connections with lower (V1) and higher order visual areas (V3ab and V4). Previous studies in anesthetized macaques found neural selectivity to binocular disparity in the layer 4B of V1, V2 thick stripes, and V3ab in the dorsal stream (<xref ref-type="bibr" rid="c24">Hubel &amp; Livingstone, 1987</xref>; <xref ref-type="bibr" rid="c41">Livingstone &amp; Hubel, 1987</xref>; <xref ref-type="bibr" rid="c68">Tootell et al., 1983</xref>; <xref ref-type="bibr" rid="c69">Ts’O et al., 2001</xref>; <xref ref-type="bibr" rid="c70">Tsao et al., 2003</xref>), color selectivity in the color blobs in the V1 superficial layers, V2 thin stripes, and V4 in the ventral stream (<xref ref-type="bibr" rid="c24">Hubel &amp; Livingstone, 1987</xref>; <xref ref-type="bibr" rid="c41">Livingstone &amp; Hubel, 1987</xref>, <xref ref-type="bibr" rid="c42">1988</xref>; <xref ref-type="bibr" rid="c43">Lu &amp; Roe, 2008</xref>; <xref ref-type="bibr" rid="c74">Zeki, 1973</xref>), and strong orientation selectivity in layer 2/3 of V1, V2 pale stripes, and V4 (<xref ref-type="bibr" rid="c24">Hubel &amp; Livingstone, 1987</xref>; <xref ref-type="bibr" rid="c61">Roe &amp; Ts’o, 1995</xref>; <xref ref-type="bibr" rid="c65">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="c69">Ts’O et al., 2001</xref>). Given a strong dependency on the output of orientation filters (<xref ref-type="bibr" rid="c58">Portilla &amp; Simoncelli, 2000</xref>; <xref ref-type="bibr" rid="c63">Simoncelli &amp; Olshausen, 2001</xref>), naturalistic textures might be selectively processed by orientation-selective neurons in the pale stripes of V2.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>A. Activation maps in a representative subject (S09). The scale bar denotes percent signal change of BOLD response. From left to right: Chr - Ach (color), 3D - 2D (disparity), color - disparity, T – N (texture). The bottom panels show enlarged activations in the black square. The highlighted region in the bottom panels represents area V2.Color-selective and disparity-selective stripe-shaped activations arranged perpendicular to the V1-V2 border. Red arrowheads denote the location of color-selective (thin) stripes and blue arrowheads denote the location of disparity-selective (thick) stripes. The ROIs for pale stripes were defined as vertices in-between adjacent thin and thick stripes (see methods for details). B. Selectivity indices for color, disparity and naturalistic texture in different types of columns. Error bar indicates 1 SEM across subjects. **: <italic>p</italic> &lt; 0.01, ***: <italic>p</italic> &lt; 0.001.n.s.: none significance. C. Inter-session correlations for the color- and disparity-selective functional maps in S09. Each blue dot represents one vertex on V2 surface.</p></caption>
<graphic xlink:href="564178v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig1" ref-type="fig">Figure 1C</xref> illustrates a simplified model for the layer-specific neural circuitry in the early visual cortex (<xref ref-type="bibr" rid="c14">Felleman &amp; Van Essen, 1991</xref>; <xref ref-type="bibr" rid="c51">Nassi &amp; Callaway, 2009</xref>). In addition to feedforward and local horizontal connections, feedback modulations may also play important roles in processing visual information, especially in conscious visual perception (<xref ref-type="bibr" rid="c20">Ge et al., 2020</xref>). Using cortical-depth dependent fMRI, we aim to investigate the feedforward, feedback, and local processing of color, disparity, and texture information in the human visual system.</p>
<sec id="s2a">
<title>Functional organizations on the cortical surface of V2</title>
<p>In a representative subject (<xref rid="fig2" ref-type="fig">Figure 2A</xref>), color-selective (Chr - Ach, 1<sup>st</sup> column, red arrows) and disparity-selective activations (3D - 2D, 2<sup>nd</sup> column, blue arrows) show stripe-shaped organizations in area V2. These interdigitated stripes can be more clearly seen on the differential map between color and disparity activations ((Chr – Ach) – (3D – 2D), 3<sup>rd</sup> column). However, the texture-selective activation map does not exhibit a clear columnar organization (T - N, 4<sup>th</sup> column). Stronger texture-selective activations can be found from the more anterior part of V2, corresponding to the peripheral visual field. Similar functional organizations can be found from other subjects (<xref rid="figs1" ref-type="fig">Supplementary Fig. S1</xref>).</p>
<p>To further demonstrate whether there is a difference in texture selectivity within different functional modules of the parallel processing streams in area V2, we performed an ROI analysis with the thick, thin, and pale stripes. The ROIs for disparity-selective thick and color-selective thin stripes were defined by the differential map between color- and disparity-selective activations (color-disparity, the 3<sup>rd</sup> column in <xref rid="fig2" ref-type="fig">figure 2A</xref>), while the ROIs for the pale stripes were defined as vertices in-between adjacent thin- and thick-stripe ROIs (see methods for details about ROI-definition, and <xref rid="figs2" ref-type="fig">Supplementary Fig. S2</xref> for the ROIs of a representative subject). From the columnar response profile (<xref rid="fig2" ref-type="fig">Figure 2B</xref>), thin- and thick-stripe ROIs show the strongest selectivity to color and disparity information, respectively. This is as expected and validated our ROI definition approach. We further conducted repeated-measures ANOVA and Bayesian ANOVA to examine whether there is difference in texture-selectivity index across three different stripes. The results were statistically non-significant (F(2,9) = 1.88, p = 0.18, BF<sub>10</sub> = 0.65). A non-parametric bootstrap method also revealed no significant difference between the responses to naturalistic texture and spectrally matched noise (see bootstrapped distributions in <xref rid="figs3" ref-type="fig">Supplementary Fig. S3</xref>).</p>
<p>In 5 out of 10 subjects, both color and disparity experiments were conducted in two sessions. To evaluate the test-retest reliability of the interdigitated columnar organizations, we calculated the inter-session pattern correlations for the color- and disparity-selective functional maps. For the representative subject (<xref rid="fig2" ref-type="fig">Figure 2C</xref>), the correlation coefficients for both color- (r = 0.66) and disparity-selective activation maps (r = 0.53) were highly significant (both p &lt; 0.001, FWE corrected). The functional maps from the other four subjects also demonstrate highly significant pattern correlations between sessions (<xref rid="figs4" ref-type="fig">Supplementary Fig. S4</xref>). These findings demonstrate that the interdigitated columnar organizations for color and disparity processing are highly reproducible.</p>
</sec>
<sec id="s2b">
<title>Layer-specific response selectivity</title>
<p>A response selectivity index was calculated for each stimulus contrast (see method for details). Within each ROI, repeated-measures ANOVA was conducted on each type of selectivity index with cortical depth (deep/middle/superficial) as the within-subject factor, followed by post-hoc t-tests between different depths. Color selectivity was significantly stronger in the superficial cortical depth compared to the middle and deep cortical depths in both V1 (F(2,9) = 15.08, p &lt; 0.001, BF<sub>10</sub> = 133.72; S vs. M: t(9) = 4.78, p &lt; 0.01; S vs. D: t(9) = 3.98, p &lt; 0.01) and V2 (F(2,9) = 12.93, p &lt; 0.001, BF<sub>10</sub> = 64.83; S vs. M: t(9) = 3.80, p &lt; 0.01; S vs. D: t(9) = 3.78, p &lt; 0.01). No significant difference was observed across different depths in other visual areas (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). According to the hierarchical model in <xref rid="fig1" ref-type="fig">figure 1B</xref> and 1C, the strongest color selectivity in the superficial cortical depth is consistent with the fact that color blobs mainly locate in the superficial layers of V1 (<xref ref-type="bibr" rid="c14">Felleman &amp; Van Essen, 1991</xref>; <xref ref-type="bibr" rid="c24">Hubel &amp; Livingstone, 1987</xref>; <xref ref-type="bibr" rid="c51">Nassi &amp; Callaway, 2009</xref>), suggesting that both local and feedforward connections are involved in processing color information in area V2.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Layer-specific response selectivity for color (A), disparity (B) and naturalistic texture (C). Error bars indicate 1 SEM across subjects. *: <italic>p</italic> &lt; 0.05, **: <italic>p</italic> &lt; 0.01.</p></caption>
<graphic xlink:href="564178v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Disparity selectivity was significantly higher in the superficial cortical depth compared to the middle and deep cortical depths in V3ab (<xref rid="fig3" ref-type="fig">Figure 3B</xref>) (F(2,9) = 8.3, p &lt; 0.01, BF<sub>10</sub> = 12.43; S vs. M: t(9) = 2.85, p &lt; 0.05; S vs. D: t(9) = 3.68, p &lt; 0.01). No significant difference was found across cortical depths in other ROIs (all F(2,9) &lt; 2.85, p &gt; 0.08). The absence of laminar difference in disparity selectivity may suggest that both feedforward, feedback, and local mechanisms are involved in processing disparity information in area V2.</p>
<p>Response selectivity to naturalistic texture was strongest in the deep cortical depth in both V1 (F(2,9) = 8.6, p &lt; 0.01, BF<sub>10</sub> = 63.57; D vs. M: t(9) = 2.28, p &lt; 0.05; D vs. S: t(9) = 4.76, p &lt; 0.01) and V2 (F(2,9) = 12.91, BF<sub>10</sub> = 14.08, p &lt; 0.001; D vs. M: t(9) = 2.49, p &lt; 0.05; D vs. S: t(9) = 4.29 p &lt; 0.01). Although texture selectivity showed no significant difference across cortical depths in the higher level visual areas V4 (F(2,9) = 0.48, p = 0.63) and V3ab (F(2,9) = 3.53, p = 0.051), which were significantly larger than those in V1 and V2 (all paired comparisons between ROIs, p &lt; 0.001, BF<sub>10</sub> &gt; 1106.79). V1 responses to naturalistic textures were also significantly weaker compared to spectrally matched noise, in line with the top-down feedback hypothesis of predictive coding (<xref ref-type="bibr" rid="c18">Friston, 2005</xref>; <xref ref-type="bibr" rid="c49">Murray et al., 2002</xref>; <xref ref-type="bibr" rid="c60">Rao &amp; Ballard, 1999</xref>). The strongest selectivity in the deep layers of V2 suggests that feedback modulations from higher-level visual areas play a crucial role in processing naturalistic statistical information in this region.</p>
</sec>
<sec id="s2c">
<title>Layer-specific informational connectivity</title>
<p>To further investigate the information flow in the visual hierarchy, we conducted layer-specific informational connectivity analysis among V1, V2, V3ab, and V4 (<xref ref-type="bibr" rid="c1">Aly &amp; Turk-Browne, 2016</xref>; <xref ref-type="bibr" rid="c12">Coutanche &amp; Thompson-Schill, 2014</xref>; <xref ref-type="bibr" rid="c22">Haxby et al., 2001</xref>; <xref ref-type="bibr" rid="c26">Huffman &amp; Stark, 2017</xref>; <xref ref-type="bibr" rid="c27">Jia et al., 2020</xref>; <xref ref-type="bibr" rid="c35">Koster et al., 2018</xref>). For each pair of stimuli, an SVM classifier was trained to decode the stimulus type (e.g., chromatic or achromatic gratings). Block-by-block multi-variate distances to the decision boundary were used to calculate the co-variability of stimulus representations between two brain regions. Feedforward connectivity was defined as the connection between the superficial layer of a lower level area and the middle layer of a higher level area, whereas feedback connectivity was defined as the connection between the deep layers of two brain regions.</p>
<p>As shown in <xref rid="fig4" ref-type="fig">figure 4</xref>, for color-selective processing, significant feedforward (t(9) = 5.64, p &lt; 0.001) and feedback connections (t(9) = 10.39, p &lt; 0.001) were found between V1 and V2, and between V2 and V4 (both t(9) &gt; 4.96, p &lt; 0.01). For disparity-selective processing, significant feedforward (t(9) = 3.77, p &lt; 0.05) and feedback connections (t(9) = 3.06, p &lt; 0.05) were found between V1 and V2, and also between V2 and V3ab (both t(9) &gt; 2.90, p &lt; 0.05). In contrast, for naturalistic texture-selective processing, a significant feedback connection was found from V4 to V2 (t(9) = 4.28, p &lt; 0.05). No significant correlation was found for other connections (all t(9) &lt; 1.7, p &gt; 0.25).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Layer-specific feedforward and feedback informational connectivity of color, disparity, and naturalistic texture. Numbers denote the mean values of connection (Pearson’s r) across all subjects. *: <italic>p</italic> &lt; 0.05, **: <italic>p</italic> &lt; 0.01, ***: <italic>p</italic> &lt; 0.001</p></caption>
<graphic xlink:href="564178v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Utilizing 7T BOLD fMRI at 1-mm isotropic resolution, we investigated laminar and columnar response profiles for color, disparity, and naturalistic textures in human V2 by presenting three stimulus contrasts. Color- and disparity-selective activations revealed clear stripe-shaped columnar organizations in area V2, oriented perpendicular to the V1-V2 border (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). These columnar patterns were reproducible between different scanning sessions (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, <xref rid="figs4" ref-type="fig">Supplementary Fig. S4</xref>), and are consistent with previous findings from intrinsic optical imaging studies in monkeys (<xref ref-type="bibr" rid="c43">Lu &amp; Roe, 2008</xref>; <xref ref-type="bibr" rid="c69">Ts’O et al., 2001</xref>) and 7T fMRI studies in humans (<xref ref-type="bibr" rid="c31">Kennedy et al., 2023</xref>; <xref ref-type="bibr" rid="c50">Nasr et al., 2016</xref>). However, V2 does not exhibit a clear columnar organization for naturalistic textures. Cortical depth-dependent analysis revealed that compared to color and disparity information, the processing of naturalistic statistics in V2 is more dependent on feedback modulation from V4.</p>
<p>The laminar profiles of response selectivity revealed both inter- and intra-areal hierarchical processing of visual information. Color selectivity was strongest in the superficial layers of V1 and V2. This result is consistent with the findings that color blobs are primarily located in the superficial layers of primate V1 (<xref ref-type="bibr" rid="c40">Livingstone &amp; Hubel, 1982</xref>), and that the local processing of color information is most prominent in the superficial layers of the early visual cortex (<xref ref-type="bibr" rid="c24">Hubel &amp; Livingstone, 1987</xref>; <xref ref-type="bibr" rid="c43">Lu &amp; Roe, 2008</xref>). For disparity processing, no significant difference was identified across cortical depths in the early visual cortex. This result suggests that feedforward, feedback, and local mechanisms all contribute to generating disparity-defined 3D perception, as the middle layer is recognized as the primary termination of feedforward inputs, and the superficial and deep layers are considered as the output layers to higher-order areas and the primary recipients of feedback projections, respectively (<xref ref-type="bibr" rid="c10">Callaway, 2004</xref>; <xref ref-type="bibr" rid="c14">Felleman &amp; Van Essen, 1991</xref>). Consistent with the laminar response profiles, layer-specific informational connectivity analyses showed that both feedforward and feedback signals play important roles in color and disparity processing in the ventral (i.e., V2-V4) and dorsal (i.e., V2-V3ab) visual streams, respectively.</p>
<p>A previous electrophysiological study investigated laminar neural activity in V1 and V2 to naturalistic textures in anesthetized macaques (<xref ref-type="bibr" rid="c76">Ziemba et al., 2019</xref>). Their findings suggest that the superficial and deep layers of V1 are subject to top-down modulation from higher-order visual areas during processing of naturalistic textures. Consistent with this study, we found the strongest selectivity to naturalistic textures in the deep layer of V1, suggesting feedback modulation from higher-order visual areas. V1 responses to naturalistic textures were also significantly weaker compared to spectrally matched noise, consistent with the framework of predictive coding: top-down hypotheses from higher level area “explain away” or reduce the prediction error signals in the lower visual area (<xref ref-type="bibr" rid="c18">Friston, 2005</xref>; <xref ref-type="bibr" rid="c49">Murray et al., 2002</xref>; <xref ref-type="bibr" rid="c60">Rao &amp; Ballard, 1999</xref>). This could also explain the strongest signal reduction in the superficial layers in our results, since the error signals should be mainly represented in the output layers according to the model of canonical microcircuits for predictive coding (<xref ref-type="bibr" rid="c5">Bastos et al., 2012</xref>).</p>
<p>In V2, <xref ref-type="bibr" rid="c76">Ziemba and colleagues (2019)</xref> found stronger texture selectivity in the superficial and middle layers, which potentially emerged from local processing within this area. In contrast, our data revealed the highest selectivity to naturalistic textures in the deep layers of V2, along with a significant feedback modulation from V4. The amount of texture selectivity in V4 was also stronger compared to V2. This is consistent with previous macaque studies showing stronger texture selectivity in V4 than in V2 (<xref ref-type="bibr" rid="c54">Okazawa et al., 2017</xref>) and local clustered neurons in V4 that shared preferential image statistics (<xref ref-type="bibr" rid="c21">Hatanaka et al., 2022</xref>; <xref ref-type="bibr" rid="c32">Kim et al., 2022</xref>). Altogether, these findings suggest an important role of feedback modulation from V4 in generating selectivity to naturalistic textures in V2. In the monkey study, it is possible that general anesthesia substantially reduced feedback modulation from high-order brain areas. There is evidence showing that V4 activity is more closely related to conscious visual perception than the early visual areas (<xref ref-type="bibr" rid="c45">Mehta et al., 2000</xref>; <xref ref-type="bibr" rid="c66">Tong, 2003</xref>).</p>
<p>Our fMRI data demonstrate a significant contribution of feedback signals in generating the selectivity for naturalistic textures in area V2. Nonetheless, this does not preclude the possibility that such selectivity might arise from local processing within this area and become progressively stronger along the feedforward pathway. In accordance with the predictive coding hypothesis discussed above, top-down feedback might reduce the neural activity representing prediction errors in the superficial layers of lower-order areas, counteracting the effect of neural response evoked by local processing. Furthermore, recent macaque studies have shown that the cortical processing of naturalistic textures depends on the type of statistical regularities (<xref ref-type="bibr" rid="c32">Kim et al., 2022</xref>; <xref ref-type="bibr" rid="c53">Okazawa et al., 2015</xref>). Compared to previous studies (<xref ref-type="bibr" rid="c17">Freeman et al., 2013</xref>; <xref ref-type="bibr" rid="c53">Okazawa et al., 2015</xref>; <xref ref-type="bibr" rid="c75">Ziemba et al., 2016</xref>), our V2 results showed much weaker selectivity to naturalistic textures. This could be due to different textures used in the current study. As suggested by the previous findings, texture selectivity across neurons in V2 and V4 can be highly diversified (<xref rid="fig2" ref-type="fig">Fig. 2e</xref> in <xref ref-type="bibr" rid="c17">Freeman et al., 2013</xref>; <xref ref-type="bibr" rid="c32">Kim et al., 2022</xref>): some texture families are much more or less effective in driving the neural activity than others, with distinct temporal dynamics.</p>
<p>We found no evidence of a columnar organization for naturalistic texture information within area V2. A cortical column is formed by many mini-columns bound together by short-range horizontal connections (<xref ref-type="bibr" rid="c47">Mountcastle, 1997</xref>), supporting efficient information processing via local circuitry. Thus, the absence of a columnar organization in area V2 is consistent with a dominant role of feedback modulation, rather than local or feedforward processing in generating texture selectivity within this area. Considering the complex computations required for processing naturalistic information, it is likely that V4 neurons are more suitable for this task than those in V2. High-order statistics in naturalistic textures are computed via integrating local elements across different locations, orientations, and spatial scales (<xref ref-type="bibr" rid="c58">Portilla &amp; Simoncelli, 2000</xref>), presenting a challenge for an early visual area such as V2 to develop a specialized computational module. In line with this idea, the neural tunings in V4 are distributed in a way suitable for categorizing textures and predicting texture discrimination abilities (<xref ref-type="bibr" rid="c21">Hatanaka et al., 2022</xref>; <xref ref-type="bibr" rid="c32">Kim et al., 2022</xref>; <xref ref-type="bibr" rid="c53">Okazawa et al., 2015</xref>).</p>
<p>Finally, the critical period for the formation of cortical columns in lower-level visual area might close at an earlier stage during development (<xref ref-type="bibr" rid="c33">Kiorpes, 2015</xref>; <xref ref-type="bibr" rid="c37">Levi, 2005</xref>). It is possible that the emergence of selectivity to naturalistic textures requires extensive visual experience with the ability to actively explore the visual environment. After the closure of critical period in V2 for forming color- and disparity-selective columns, V4 may still be in its critical period with high neural plasticity, allowing it to develop neuronal clusters with strong preference for naturalistic textures (<xref ref-type="bibr" rid="c21">Hatanaka et al., 2022</xref>). Subsequently, feedback modulations from V4 may further increase the selectivity for naturalistic textures in V2.</p>
<p>In summary, the present study demonstrated parallel pathways for color, disparity, and texture processing in human visual cortex. Unlike color and disparity, no evidence of columnar organization or response preference across thick, pale, and thin stripes was found for naturalistic texture in area V2. Consistent with this finding, our results further suggest that feedback processing from V4 plays a dominant role in generating texture selectivity within V2. These results underscore the critical involvement of higher-order visual area in texture processing. Given the diversity of naturalistic textures, different cortical mechanisms may be involved at various processing stages (<xref ref-type="bibr" rid="c32">Kim et al., 2022</xref>; <xref ref-type="bibr" rid="c53">Okazawa et al., 2015</xref>). In the future, it would be important to characterize columnar and laminar fMRI responses using different texture types to obtain a comprehensive picture of naturalistic texture processing along the visual hierarchy.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Ten participants (four females; age range 21-40 years) were recruited for this study. All participants had normal or corrected-to-normal vision and reported no history of neuropsychological or visual disorders. The experimental procedures were approved by the ethical review board of Institute of Biophysics, Chinese Academy of Sciences. Written informed consent was obtained from all participants prior to their participation in the study.</p>
</sec>
<sec id="s4b">
<title>General procedures</title>
<p>Each participant underwent three fMRI experiments in the 7T scanner. Six subjects participated color, disparity, and texture experiments in three daily sessions (five subjects scanned both color and disparity experiments in two sessions, and the texture experiment in a single session; one subject scanned one experimental condition in each session). For each experiment, ten runs of fMRI data were collected. The remaining four participants completed all three experiments in a single session, consisting of twelve runs in total (four runs for each experiment). The order of experimental conditions was counterbalanced across participants. Visual stimuli subtended 46.7° × 35.9° in visual angle, with a fixation point (0.3° in diameter) in the center. During fMRI scans, each run started and ended with 16-s fixation periods. In the remaining periods, visual stimuli were presented in 24-second stimulus blocks. Participants were required to maintain fixation and to detect sparsely and randomly presented color changes of the fixation point.</p>
</sec>
<sec id="s4c">
<title>Stimuli and apparatus</title>
<p>Visual stimuli were presented through an MRI-safe projector (1024 × 768 pixel resolution, 60 Hz refresh rate) onto a rear-projection screen. The experiment was conducted using MATLAB 2016a (MathWorks) based on Psychophysics toolbox extensions Version 3.0 (<xref ref-type="bibr" rid="c9">Brainard, 1997</xref>; <xref ref-type="bibr" rid="c56">Pelli, 1997</xref>). Participants viewed the screen via a mirror mounted inside the head coil.</p>
<sec id="s4c1">
<title>Color experiment</title>
<p>The MRI-safe projector was calibrated using a PR-655 photometer to have a linear luminance output. To account for changes in isoluminance at different eccentricities (<xref ref-type="bibr" rid="c50">Nasr et al., 2016</xref>; <xref ref-type="bibr" rid="c8">Bilodeau &amp; Faubert, 1997</xref>; <xref ref-type="bibr" rid="c41">Livingstone &amp; Hubel, 1987</xref>; <xref ref-type="bibr" rid="c48">Mullen, 1985</xref>), we measured blue-red and blue-gray isoluminance for each participant at three eccentricity ranges (0°-3°, 3°-8°, and 8°-16°). Blue was set as the reference color, because the project has lower light intensity for blue compared with red and gray. A minimal motion procedure was used to match the perceived luminance between blue and red/gray (<xref ref-type="bibr" rid="c2">Anstis &amp; Cavanagh, 1983</xref>). During isoluminance adjustment, achromatic and chromatic gratings were presented in alternating frames, with pi/2 phase difference between adjacent frames. Blue luminance was fixed at the maximum level, participants adjusted the match-color luminance until no consistent apparent motion was seen (i.e., bi-stable motion directions with equal durations). For each eccentricity range, the isoluminance adjustment was repeated four times and the results were averaged. <xref rid="figs5" ref-type="fig">Supplementary Fig. S5A</xref> and <xref rid="figs5" ref-type="fig">S5B</xref> illustrate the blue-matched luminance levels (in RGB index) of gray and red, respectively, at the three eccentricity ranges. Consistent with previous findings (<xref ref-type="bibr" rid="c50">Nasr et al., 2016</xref>; <xref ref-type="bibr" rid="c8">Bilodeau &amp; Faubert, 1997</xref>; <xref ref-type="bibr" rid="c41">Livingstone &amp; Hubel, 1987</xref>; <xref ref-type="bibr" rid="c48">Mullen, 1985</xref>), the isoluminance level varied significantly as eccentricity (blue-gray: F(2,9) = 87.9, p &lt; 0.001, FWE corrected; blue-red: F(2,9) = 35.71, p &lt; 0.001, FWE corrected). During fMRI scans, chromatic and achromatic gratings (0.2 cycles-per-degree concentric rings, 46.7° × 35.9° in size, <xref rid="fig1" ref-type="fig">Fig. 1A</xref>, left panel) moved in either centrifugal or centripetal direction with a speed of 0.8 cycles/s, alternating in 24-s blocks (5 blocks per stimulus condition). A 16-second fixation period with uniform gray background was presented at the beginning and the end of each run. Ten runs of fMRI data were collected for six subjects and four runs for the other four subjects.</p>
</sec>
<sec id="s4c2">
<title>Disparity experiment</title>
<p>The binocular disparity stimulus (46.7°×35.9°) was random red/green dot stereograms (RDSs) presented against a black background. Subjects viewed the stimulus through custom anaglyph spectacles (red and cyan). The RDSs generated a stereoscopic percept, with the depth of each dot sinusoidally modulating between −2.2° ∼ 2.2° in front of and behind the frontoparallel plane of fixation (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>, middle panel). In the zero-disparity 2D control condition, randomly moving dots formed a frontoparallel plane intersecting the fixation point (i.e., zero depth at that point). Each run began and ended with a 16-second fixation period. The disparity-defined grating and zero-disparity disc stimuli were presented in alternation every 24 s. Ten runs of fMRI data were collected for six subjects and four runs for the other four subjects.</p>
</sec>
<sec id="s4c3">
<title>Texture experiment</title>
<p>The naturalistic texture and spectrally matched noise (<xref rid="fig1" ref-type="fig">Figure 1A</xref>, right panel) were synthesized using the Portilla-Simoncelli model (<xref ref-type="bibr" rid="c58">Portilla &amp; Simoncelli, 2000</xref>). Thirty image pairs were generated. The stimuli (46.7° × 35.9°) were presented in the middle of the screen, centered on the fixation point. Each fMRI run consisted of ten 24-s stimulus blocks, starting and ending with 16-s fixation periods. Each stimulus block consisted of thirty pictures in a random order, with a duration of 0.6 s for each picture. Ten runs of fMRI data were collected for six subjects and four runs for the other four subjects.</p>
</sec>
<sec id="s4c4">
<title>MRI Data Acquisition</title>
<p>MRI data were acquired on a 7T MAGNETOM MRI scanner (Siemens Healthineers, Erlangen, Germany) with a 32-channel receive 4-channel transmit open-face surface coil, in the Beijing MRI center for Brain Research (BMCBR). Functional data were collected with a T2*-weighted 2D GE-EPI sequence (1.0 mm isotropic voxels, 39 slices, TR = 2400 ms, TE = 25 ms, image matrix = 128 × 128, FOV = 128 × 128 mm<sup>2</sup>, GRAPPA acceleration factor = 3, nominal flip angle = 80°, partial Fourier factor = 7/8, phase encoding direction from Head to Foot, receiver bandwidth = 1148 Hz/Pix). Slices were oriented perpendicular to the calcarine sulcus. After each fMRI run, five EPI images with reversed phase encoding direction (F to H) were also acquired for EPI distortion correction. High-resolution anatomical volumes were acquired with a T1-weighted MP2RAGE sequence at 0.7 mm isotropic resolution (256 sagittal slices, centric phase encoding, acquisition matrix = 320 × 320, FOV = 224 × 224 mm<sup>2</sup>, GRAPPA = 3, TR = 4000 ms, TE = 3.05 ms, TI1 = 750ms, flip angle = 4°, TI2 = 2500 ms, flip angle = 5°). A bite-bar was settled for each subject to minimize head motion to ensure high data quality.</p>
</sec>
</sec>
<sec id="s4d">
<title>MRI data analysis</title>
<sec id="s4d1">
<title>Preprocessing</title>
<p>The anatomical data were preprocessed using FreeSurfer Version 6.0 (<xref ref-type="bibr" rid="c15">Fischl, 2012</xref>), which involved the segmentation and reconstruction of inflated and flattened cortical surfaces based on high-resolution anatomical data. We inspected visually and edited manually the surface segmentation to eliminate dura matter, sinus, etc., ensuring correct gray matter boundaries. The functional data were preprocessed and analyzed with AFNI (<xref ref-type="bibr" rid="c13">Cox, 1996</xref>), ANTs (<xref ref-type="bibr" rid="c4">Avants et al., 2011</xref>), and the mripy package developed in our lab (<ext-link ext-link-type="uri" xlink:href="https://github.com/herrlich10/mripy">https://github.com/herrlich10/mripy</ext-link>). Preprocessing steps included head motion correction, de-spiking, slice timing correction, EPI distortion correction (non-linear warping with blip-up/down method), and per-run scaling as percent signal change. All spatial transformations were combined and applied in a single interpolation step (sinc interpolation) to minimize the loss of spatial resolution. No spatial smoothing was applied to the main functional imaging data. We aligned the anatomical volume as well as the reconstructed surfaces to the mean of preprocessed EPI images. General linear models (GLMs) were used to estimate the BOLD responses (β values) to visual stimuli with a canonical hemodynamic response function (BLOCK4 in AFNI). Slow baseline drift and motion parameters were included as nuisance regressors in GLMs.</p>
</sec>
<sec id="s4d2">
<title>Cortical depth definition</title>
<p>To perform the cortical depth-dependent analysis, we resampled the functional volumes to 0.5 mm isotropic resolution using cubic interpolation (3dresample in AFNI). The equi-volume method was used to calculate the relative cortical depth of each voxel to the white matter and pial surface (0: white matter surface, 1: pial surface) (<xref rid="figs6" ref-type="fig">Supplementary Figure S6A</xref>). The voxels in each ROI were sorted and divided into three bins: deep depth (0-0.33), middle depth (0.33-0.67), and superficial depth (0.67-1.00) (<xref ref-type="bibr" rid="c20">Ge et al., 2020</xref>; <xref ref-type="bibr" rid="c30">Kemper et al., 2018</xref>).</p>
</sec>
<sec id="s4d3">
<title>ROI definition</title>
<p>ROIs were defined on the inflated cortical surface. Surface ROIs for V1, V2, V3ab, and V4 were defined based on the polar angle atlas from the 7T retinotopic dataset of Human Connectome Project (<xref ref-type="bibr" rid="c6">Benson et al., 2014</xref>, <xref ref-type="bibr" rid="c7">2018</xref>). Moreover, the boundary of V2 was edited manually based on columnar patterns. All ROIs were constrained to regions where mean activation across all stimulus conditions exceeded 0. In V2, ROIs for the thin and thick “stripe”-shaped columns were manually defined in two stages. Firstly, we defined thin stripes by contrast between the chromatic and achromatic stimuli, and thick stripes by contrast between binocular disparity and 2D control stimuli. Secondly, we defined final stripes by contrast between these two, resulting in interdigitated thin and thick stripes distributed without overlap. The pale stripes were defined as the regions located between the thin and thick stripes. We compared the fMRI signal changes elicited by the three stimulus contrasts in each stripe.</p>
</sec>
<sec id="s4d4">
<title>Stimulus-selectivity index</title>
<p>The ROI-averaged BOLD responses were calculated for each stimulus condition. We defined a selectivity index (SI) for color, disparity, and texture processing, respectively:
<disp-formula>
<graphic xlink:href="564178v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here, β<sub>chr</sub>, β<sub>ach,</sub> β<sub>3D,</sub> β<sub>2D</sub>, β<sub>T</sub> and β<sub>N</sub> represent the beta estimates of BOLD responses for the chromatic, achromatic, binocular disparity, 2D control, naturalistic texture, and spectrally matched noise stimuli, respectively.</p>
</sec>
<sec id="s4d5">
<title>Test-retest reliability of columnar organizations</title>
<p>For five subjects who participated in both color and disparity experiments across two daily scan sessions, we generated color (β<sub>chr</sub> – β<sub>ach</sub>) and disparity (β<sub>3D</sub> – β<sub>2D</sub>) selective functional maps on the cortical surface in area V2. Pearson’s correlations were computed to evaluate the test-retest reliability of color- and disparity-selective response patterns between the two scan sessions. Family-wise errors of the pattern correlations were controlled by a null distribution generated from Monte Carlo simulation (<xref ref-type="bibr" rid="c59">Qian et al., 2023</xref>). In this procedure, the first session’s GLM residual volumes were used to estimate the spatial auto-correlation function (3dFWHMx in AFNI), and it was then used to generate a simulated GLM volume for the second session (3dClustSim in AFNI). We then projected the first and second sessions’ GLM volumes onto the cortical surface and calculated the inter-session correlations of color- and disparity-selective response patterns in V2. This process was repeated 10,000 times (<xref rid="figs7" ref-type="fig">Supplementary Figure S7</xref>). Finally, the measured correlation coefficients were compared to the critical value of the null distribution.</p>
</sec>
<sec id="s4d6">
<title>Pial vein removal</title>
<p>To mitigate the strong BOLD effect from large pial veins on layer-specific signals in the gray matter (<xref ref-type="bibr" rid="c11">Cheng et al., 2001</xref>; <xref ref-type="bibr" rid="c19">Gati et al., 1997</xref>; <xref ref-type="bibr" rid="c29">Kay et al., 2019</xref>; <xref ref-type="bibr" rid="c73">Yacoub et al., 2005</xref>), we excluded vertices with extremely large signal changes and their corresponding voxels in the gray matter. Specifically, the top 5% cortical vertices with large signal changes from baseline (all stimulus conditions vs. fixation) and the corresponding voxels across all cortical depths were excluded from analysis in V1, V2, V4, and V3ab (<xref rid="figs6" ref-type="fig">Supplementary Figure S6B</xref>). According to our previous study (<xref ref-type="bibr" rid="c39">Liu et al., 2021</xref>), this large vein removal approach can effectively reduce the superficial bias in laminar response profiles of the visual cortex.</p>
</sec>
<sec id="s4d7">
<title>Layer-specific informational connectivity</title>
<p>To investigate stimulus-specific information flow in the visual processing hierarchy, we calculated informational connectivity between the input and output layers of two brain regions (<xref ref-type="bibr" rid="c1">Aly &amp; Turk-Browne, 2016</xref>; <xref ref-type="bibr" rid="c12">Coutanche &amp; Thompson-Schill, 2014</xref>; <xref ref-type="bibr" rid="c22">Haxby et al., 2001</xref>; <xref ref-type="bibr" rid="c26">Huffman &amp; Stark, 2017</xref>; <xref ref-type="bibr" rid="c27">Jia et al., 2020</xref>; <xref ref-type="bibr" rid="c35">Koster et al., 2018</xref>). This approach is analogous to the functional connectivity method in multivariate pattern analysis (MVPA), where connectivity is inferred from shared changes (covariation) in decoding accuracy between regions over time (i.e., across blocks). The layer-specific neural circuitry was further used to define the direction of informational connectivity (<xref ref-type="bibr" rid="c27">Jia et al., 2020</xref>). Specifically, feedforward connectivity was defined as the connection between the superficial layer of the lower visual area and the middle layer of the higher visual area, whereas feedback connectivity was defined as the connection between two deep layers (<xref rid="fig1" ref-type="fig">Figure 1C</xref>).</p>
<p>In the analysis, a separate GLM regressor was first used to estimate the activation pattern (t scores of voxels) for each stimulus block. For each stimulus condition per cortical layer, 50 activation patterns were obtained for six subjects and 20 activation patterns for the other four subjects. We trained linear support vector machine (SVM) classifiers (<ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm">www.csie.ntu.edu.tw/~cjlin/libsvm</ext-link>) using these patterns and extracted the distance from the hyperplane for each stimulus block, following a leave-one-run-out cross-validation procedure. Before each training, feature selection was performed with K-1 runs of data to select voxels with high visual sensitivity and stimulus selectivity. We first selected the top 20% most visually responsive voxels by the t distribution of activations from baseline for a stimulus condition (e.g., Chromatic + Achromatic - Fixation). Then 200 voxels with strong stimulus selectivity were selected from each side of the t distribution of differential responses (e.g., Chromatic - Achromatic). The activation patterns of these 400 voxels were normalized to have a unitary Euclidean norm (L2-norm). An SVM classifier of stimulus type (e.g., Chromatic vs. Achromatic) was trained from K-1 runs of data, and the distance to the decision boundary was calculated for each stimulus block from the remaining run. Pearson’s correlation between the block-by-block distance timeseries of two brain regions was calculated to estimate the layer-specific informational connectivity. Then we averaged the correlation coefficients across all folds.</p>
<p>The correlation coefficients were Fisher z-transformed before statistical analysis. One-sample t-test against 0 was conducted on each connectivity value, and the results were submitted to FDR (False Discovery Rate) correction. The reported correlations are the original r values to facilitate interpretation and visualization.</p>
</sec>
</sec>
<sec id="s4e">
<title>Statistical analysis</title>
<p>Statistical analyses were performed using MATLAB 2021a, JASP (v0.17.1), and custom Python code. Repeated-measures ANOVA and paired t-tests were used for most of the statistical analyses of ROI data. A family-wise-error (FWE) corrected threshold of p &lt; 0.05 was used for each group of ANOVA analysis. We further performed an FWE correction for paired t-tests only when the corrected p-value from ANOVA analysis exceeded threshold, according to the Fisher’s logic (<xref ref-type="bibr" rid="c16">Fisher, 1936</xref>; <xref ref-type="bibr" rid="c38">Levin et al., 1994</xref>). We conducted Bayesian repeated-measures ANOVA to complement the classical null-hypothesis test with JASP (<xref ref-type="bibr" rid="c71">Wagenmakers et al., 2018</xref>). The calculated Bayes factor (BF<sub>10</sub>) falling into 0.33-1 indicates anecdotal evidence for the null hypothesis (H<sub>0</sub>), whereas a value between 10-30 and &gt;100 refers to strong and extreme evidence for the alternative hypothesis (H<sub>1</sub>) respectively. Moreover, we used the non-parametric permutation test to test if selectivity indices differ across stripes. For each selectivity index, we resampled with replacement and computed the mean value within each type of stripe, and calculated the difference between each pair of stripes. This process was repeated 10,000 times to derive the null distribution. The critical value was set to 0.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Data availability</title>
<p>All data and code used in this study will be made publicly available upon the publication of the paper.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This study was funded by National Science and Technology Innovation 2030 Major Program (2021ZD0203600, 2022ZD0211900, 2021ZD0204200), National Natural Science Foundation of China (31971031, 31871107, 31930053), Strategy Priority Research Program (XDB32020200).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Aly</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N. B</given-names></string-name>. (<year>2016</year>). <article-title>Attention promotes episodic encoding by stabilizing hippocampal representations</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>113</volume>(<issue>4</issue>), <fpage>E420</fpage>–<lpage>E429</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1518931113</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="book"><string-name><surname>Anstis</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Cavanagh</surname>, <given-names>P</given-names></string-name>. (<year>1983</year>). <chapter-title>A minimum Motion Technique for Judging Equiluminance</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>J.</given-names> <surname>Mollon</surname></string-name></person-group> &amp; <person-group person-group-type="editor"><string-name><given-names>L. T.</given-names> <surname>Sharpe</surname></string-name></person-group> (Eds.), <source>Colour vision: Physiology and psychophysics</source> (pp. <fpage>155</fpage>–<lpage>166</lpage>). <publisher-name>Academic Press</publisher-name>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Arcizet</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Jouffrais</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Girard</surname>, <given-names>P</given-names></string-name>. (<year>2008</year>). <article-title>Natural textures classification in area V4 of the macaque monkey</article-title>. <source>Experimental Brain Research</source>, <volume>189</volume>(<issue>1</issue>), <fpage>109</fpage>–<lpage>120</lpage>. <pub-id pub-id-type="doi">10.1007/s00221-008-1406-9</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Avants</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Tustison</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Cook</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gee</surname>, <given-names>J. C</given-names></string-name>. (<year>2011</year>). <article-title>A reproducible evaluation of ANTs similarity metric performance in brain image registration</article-title>. <source>NeuroImage</source>, <volume>54</volume>(<issue>3</issue>), <fpage>2033</fpage>–<lpage>2044</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.09.025</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bastos</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Usrey</surname>, <given-names>W. M.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Mangun</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Fries</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K. J</given-names></string-name>. (<year>2012</year>). <article-title>Canonical Microcircuits for Predictive Coding</article-title>. <source>Neuron</source>, <volume>76</volume>(<issue>4</issue>), <fpage>695</fpage>–<lpage>711</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Benson</surname>, <given-names>N. C.</given-names></string-name>, <string-name><surname>Butt</surname>, <given-names>O. H.</given-names></string-name>, <string-name><surname>Brainard</surname>, <given-names>D. H.</given-names></string-name>, &amp; <string-name><surname>Aguirre</surname>, <given-names>G. K</given-names></string-name>. (<year>2014</year>). <article-title>Correction of Distortion in Flattened Representations of the Cortical Surface Allows Prediction of V1-V3 Functional Organization from Anatomy</article-title>. <source>PLoS Computational Biology</source>, <volume>10</volume>(<fpage>3</fpage>). <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003538</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Benson</surname>, <given-names>N. C.</given-names></string-name>, <string-name><surname>Jamison</surname>, <given-names>K. W.</given-names></string-name>, <string-name><surname>Arcaro</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Vu</surname>, <given-names>A. T.</given-names></string-name>, <string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Coalson</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Winawer</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Kay</surname>, <given-names>K.</given-names></string-name> (<year>2018</year>). <article-title>The Human Connectome Project 7 Tesla retinotopy dataset: Description and population receptive field analysis</article-title>. <source>Journal of Vision</source>, <volume>18</volume>(<issue>13</issue>), <fpage>1</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1167/18.13.23</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Bilodeau</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Faubert</surname>, <given-names>J.</given-names></string-name> (<year>1997</year>). <article-title>Isoluminance and chromatic motion perception throughout the visual field</article-title>. <source>Vision Research</source>, <volume>37</volume>(<issue>15</issue>), <fpage>2073</fpage>–<lpage>2081</lpage>. <pub-id pub-id-type="doi">10.1016/S0042-6989(97)00012-6</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Brainard</surname>, <given-names>D. H</given-names></string-name>. (<year>1997</year>). <article-title>The Psychophysics Toolbox</article-title>. <source>Spatial Vision</source>, <volume>10</volume>, <fpage>433</fpage>–<lpage>436</lpage>. <pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Callaway</surname>, <given-names>E. M</given-names></string-name>. (<year>2004</year>). <article-title>Feedforward, feedback and inhibitory connections in primate visual cortex</article-title>. <source>Neural Networks</source>, <volume>17</volume>(<issue>5–6</issue>), <fpage>625</fpage>–<lpage>632</lpage>. <pub-id pub-id-type="doi">10.1016/j.neunet.2004.04.004</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Cheng</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Waggoner</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Tanaka</surname>, <given-names>K</given-names></string-name>. (<year>2001</year>). <article-title>Human Ocular Dominance Columns as Revealed by High-Field Functional Magnetic Resonance Imaging</article-title>. <source>Neuron</source>, <volume>32</volume>, <fpage>1</fpage>–<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1016/S0896-6273(01)00477-9</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Coutanche</surname>, <given-names>M. N.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name>. (<year>2014</year>). <article-title>Using Informational Connectivity to Measure the Synchronous Emergence of fMRI Multi-voxel Information Across Time</article-title>. <source>Journal of Visualized Experiments</source>, <volume>89</volume>, <fpage>e51226</fpage>. <pub-id pub-id-type="doi">10.3791/51226</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>R. W</given-names></string-name>. (<year>1996</year>). <article-title>AFNI: Software for analysis and visualization of functional magnetic resonance neuroimages</article-title>. <source>Computers and Biomedical Research</source>, <volume>29</volume>(<issue>29</issue>), <fpage>162</fpage>–<lpage>173</lpage>. <pub-id pub-id-type="doi">10.2307/2342435</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Felleman</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name> (<year>1991</year>). <article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title>. <source>Cerebral Cortex</source>, <volume>1</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/1.1.1-a</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Fischl</surname>, <given-names>B</given-names></string-name>. (<year>2012</year>). <article-title>FreeSurfer</article-title>. <source>NeuroImage</source>, <volume>62</volume>(<issue>2</issue>), <fpage>774</fpage>–<lpage>781</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Fisher</surname>, <given-names>R. A</given-names></string-name>. (<year>1936</year>). <article-title>Design of Experiments</article-title>. <source>British Medical Journal</source>, <volume>1</volume>(<issue>3923</issue>), <fpage>554</fpage>. <pub-id pub-id-type="doi">10.1136/bmj.1.3923.554-a</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Freeman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Ziemba</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A</given-names></string-name>. (<year>2013</year>). <article-title>A functional and perceptual signature of the second visual area in primates</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>(<issue>7</issue>), <fpage>974</fpage>–<lpage>981</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3402</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Friston</surname>, <given-names>K</given-names></string-name>. (<year>2005</year>). <article-title>A theory of cortical responses</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>360</volume>(<issue>1456</issue>), <fpage>815</fpage>–<lpage>836</lpage>. <pub-id pub-id-type="doi">10.1098/RSTB.2005.1622</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Gati</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Menon</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Uǧurbil</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Rutt</surname>, <given-names>B. K.</given-names></string-name> (<year>1997</year>). <article-title>Experimental determination of the BOLD field strength dependence in vessels and tissue</article-title>. <source>Magnetic Resonance in Medicine</source>, <volume>38</volume>(<issue>2</issue>), <fpage>296</fpage>–<lpage>302</lpage>. <pub-id pub-id-type="doi">10.1002/mrm.1910380220</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Ge</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Qian</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>He</surname>, <given-names>S</given-names></string-name>. (<year>2020</year>). <article-title>Adaptation to feedback representation of illusory orientation produced from flash grab effect</article-title>. <source>Nature Communications</source>, <volume>11</volume>(<fpage>1</fpage>). <pub-id pub-id-type="doi">10.1038/s41467-020-17786-1</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Hatanaka</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Inagaki</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Takeuchi</surname>, <given-names>R. F.</given-names></string-name>, <string-name><surname>Nishimoto</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ikezoe</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Fujita</surname>, <given-names>I</given-names></string-name>. (<year>2022</year>). <article-title>Processing of visual statistics of naturalistic videos in macaque visual areas V1 and V4</article-title>. <source>Brain Structure and Function</source>, <volume>227</volume>(<issue>4</issue>), <fpage>1385</fpage>–<lpage>1403</lpage>. <pub-id pub-id-type="doi">10.1007/s00429-022-02468-z</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name>, <string-name><surname>Gobbini</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Furey</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Ishai</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schouten</surname>, <given-names>J. L.</given-names></string-name>, &amp; <string-name><surname>Pietrini</surname>, <given-names>P</given-names></string-name>. (<year>2001</year>). <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title>. <source>Science</source>, <volume>293</volume>(<issue>5539</issue>), <fpage>2425</fpage>–<lpage>2430</lpage>. <pub-id pub-id-type="doi">10.1126/science.1063736</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Hubel</surname>, <given-names>D. H.</given-names></string-name>, &amp; <string-name><surname>Livingstone</surname>, <given-names>M. S</given-names></string-name>. (<year>1985</year>). <article-title>Complex-unoriented cells in a subregion of primate area 18</article-title>. <source>Nature</source>, <volume>315</volume>(<issue>6017</issue>), <fpage>325</fpage>–<lpage>327</lpage>. <pub-id pub-id-type="doi">10.1038/315325a0</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Hubel</surname>, <given-names>D. H.</given-names></string-name>, &amp; <string-name><surname>Livingstone</surname>, <given-names>M. S</given-names></string-name>. (<year>1987</year>). <article-title>Segregation of form, color, and stereopsis in primate area 18</article-title>. <source>Journal of Neuroscience</source>, <volume>7</volume>(<issue>11</issue>), <fpage>3378</fpage>–<lpage>3415</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.07-11-03378.1987</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Huber</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Handwerker</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Jangraw</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Hall</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Stüber</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gonzalez-Castillo</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Ivanov</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Marrett</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Guidi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Goense</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Poser</surname>, <given-names>B. A.</given-names></string-name>, &amp; <string-name><surname>Bandettini</surname>, <given-names>P. A</given-names></string-name>. (<year>2017</year>). <article-title>High-Resolution CBV-fMRI Allows Mapping of Laminar Activity and Connectivity of Cortical Input and Output in Human M1</article-title>. <source>Neuron</source>, <volume>96</volume>(<issue>6</issue>), <fpage>1253</fpage>–<lpage>1263</lpage>.e7. <pub-id pub-id-type="doi">10.1016/J.NEURON.2017.11.005</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Huffman</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Stark</surname>, <given-names>C. E. L</given-names></string-name>. (<year>2017</year>). <article-title>The influence of low-level stimulus features on the representation of contexts, items, and their mnemonic associations</article-title>. <source>NeuroImage</source>, <volume>155</volume>, <fpage>513</fpage>–<lpage>529</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2017.04.019</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Jia</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Zamboni</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Kemper</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Rua</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Goncalves</surname>, <given-names>N. R.</given-names></string-name>, <string-name><surname>Ng</surname>, <given-names>A. K. T.</given-names></string-name>, <string-name><surname>Rodgers</surname>, <given-names>C. T.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Goebel</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Kourtzi</surname>, <given-names>Z</given-names></string-name>. (<year>2020</year>). <article-title>Recurrent Processing Drives Perceptual Plasticity</article-title>. <source>Current Biology</source>, <volume>30</volume>(<issue>21</issue>), <fpage>4177</fpage>–<lpage>4187</lpage>.e4. <pub-id pub-id-type="doi">10.1016/j.cub.2020.08.016</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Kaplan</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>B. B.</given-names></string-name>, &amp; <string-name><surname>Shapley</surname>, <given-names>R. M</given-names></string-name>. (<year>1990</year>). <article-title>Chapter 7 New views of primate retinal function</article-title>. <source>Progress in Retinal Research</source>, <volume>9</volume>, <fpage>273</fpage>–<lpage>336</lpage>. <pub-id pub-id-type="doi">10.1016/0278-4327(90)90009-7</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Kay</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Jamison</surname>, <given-names>K. W.</given-names></string-name>, <string-name><surname>Vizioli</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Margalit</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Ugurbil</surname>, <given-names>K</given-names></string-name>. (<year>2019</year>). <article-title>A critical assessment of data quality and venous effects in sub-millimeter fMRI</article-title>. <source>NeuroImage</source>, <volume>189</volume>, <fpage>847</fpage>–<lpage>869</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.02.006</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Kemper</surname>, <given-names>V. G.</given-names></string-name>, <string-name><surname>De Martino</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Emmerling</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Goebel</surname>, <given-names>R.</given-names></string-name> (<year>2018</year>). <article-title>High resolution data analysis strategies for mesoscale human functional MRI at 7 and 9.4 T</article-title>. <source>NeuroImage</source>, <volume>164</volume>, <fpage>48</fpage>–<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.03.058</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kennedy</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Bex</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Hunter</surname>, <given-names>D. G.</given-names></string-name>, &amp; <string-name><surname>Nasr</surname>, <given-names>S</given-names></string-name>. (<year>2023</year>). <article-title>Two fine-scale channels for encoding motion and stereopsis within the human magnocellular stream</article-title>. <source>Progress in Neurobiology</source>, <volume>220</volume>, <fpage>102374</fpage>. <pub-id pub-id-type="doi">10.1016/j.pneurobio.2022.102374</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Bair</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Pasupathy</surname>, <given-names>A</given-names></string-name>. (<year>2022</year>). <article-title>Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4</article-title>. <source>Journal of Neuroscience</source>, <volume>42</volume>(<issue>4</issue>), <fpage>631</fpage>–<lpage>642</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0971-21.2021</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Kiorpes</surname>, <given-names>L</given-names></string-name>. (<year>2015</year>). <article-title>Visual development in primates: Neural mechanisms and critical periods</article-title>. <source>Developmental Neurobiology</source>, <volume>75</volume>(<issue>10</issue>), <fpage>1080</fpage>–<lpage>1090</lpage>. <pub-id pub-id-type="doi">10.1002/dneu.22276</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Kohler</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yakovleva</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Norcia</surname>, <given-names>A. M.</given-names></string-name> (<year>2016</year>). <article-title>Representation of maximally regular textures in human visual cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>36</volume>(<issue>3</issue>), <fpage>714</fpage>–<lpage>729</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2962-15.2016</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Koster</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Chadwick</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Berron</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Banino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Düzel</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Hassabis</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Kumaran</surname>, <given-names>D</given-names></string-name>. (<year>2018</year>). <article-title>Big-Loop Recurrence within the Hippocampal System Supports Integration of Information across Episodes</article-title>. <source>Neuron</source>, <volume>99</volume>(<issue>6</issue>), <fpage>1342</fpage>–<lpage>1354</lpage>.e6. <pub-id pub-id-type="doi">10.1016/J.NEURON.2018.08.009</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>B. B</given-names></string-name>. (<year>1996</year>). <article-title>Receptive field structure in the primate retina</article-title>. <source>Vision Research</source>, <volume>36</volume>(<issue>5</issue>), <fpage>631</fpage>–<lpage>644</lpage>. <pub-id pub-id-type="doi">10.1016/0042-6989(95)00167-0</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Levi</surname>, <given-names>D. M</given-names></string-name>. (<year>2005</year>). <article-title>Perceptual learning in adults with amblyopia: A reevaluation of critical periods in human vision</article-title>. <source>Developmental Psychobiology</source>, <volume>46</volume>(<issue>3</issue>), <fpage>222</fpage>–<lpage>232</lpage>. <pub-id pub-id-type="doi">10.1002/dev.20050</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Levin</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Serlin</surname>, <given-names>R. C.</given-names></string-name>, &amp; <string-name><surname>Seaman</surname>, <given-names>M. A</given-names></string-name>. (<year>1994</year>). <article-title>A controlled, powerful multiple-comparison strategy for several situations</article-title>. <source>Psychological Bulletin</source>, <volume>115</volume>(<issue>1</issue>), <fpage>153</fpage>–<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.115.1.153</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Qian</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Sun</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname>, <given-names>P</given-names></string-name>. (<year>2021</year>). <article-title>Layer-dependent multiplicative effects of spatial attention on contrast responses in human early visual cortex</article-title>. <source>Progress in Neurobiology</source>, <volume>207</volume>, <fpage>101897</fpage>. <pub-id pub-id-type="doi">10.1016/j.pneurobio.2020.101897</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Livingstone</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Hubel</surname>, <given-names>D. H</given-names></string-name>. (<year>1982</year>). <article-title>Thalamic inputs to cytochrome oxidase-rich regions in monkey visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>79</volume>(<issue>19</issue>), <fpage>6098</fpage>–<lpage>6101</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.79.19.6098</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Livingstone</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Hubel</surname>, <given-names>D. H</given-names></string-name>. (<year>1987</year>). <article-title>Psychophysical evidence for separate channels for the perception of form, color, movement, and depth</article-title>. <source>Journal of Neuroscience</source>, <volume>7</volume>(<issue>11</issue>), <fpage>3416</fpage>–<lpage>3468</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.07-11-03416.1987</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Livingstone</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Hubel</surname>, <given-names>D. H</given-names></string-name>. (<year>1988</year>). <article-title>Segregation of Form, Color, Movement, and Depth: Anatomy, Physiology, and Perception</article-title>. <source>Science</source>, <volume>240</volume>(<issue>4853</issue>), <fpage>740</fpage>–<lpage>749</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Lu</surname>, <given-names>H. D.</given-names></string-name>, &amp; <string-name><surname>Roe</surname>, <given-names>A. W</given-names></string-name>. (<year>2008</year>). <article-title>Functional organization of color domains in V1 and V2 of Macaque monkey revealed by optical imaging</article-title>. <source>Cerebral Cortex</source>, <volume>18</volume>(<issue>3</issue>), <fpage>516</fpage>–<lpage>533</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhm081</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Malach</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Tootell</surname>, <given-names>R. B. H.</given-names></string-name>, &amp; <string-name><surname>Malonek</surname>, <given-names>D</given-names></string-name>. (<year>1994</year>). <article-title>Relationship between orientation domains, cytochrome oxidase stripes, and intrinsic horizontal connections in squirrel monkey area V2</article-title>. <source>Cerebral Cortex</source>, <volume>4</volume>(<issue>2</issue>), <fpage>151</fpage>–<lpage>165</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/4.2.151</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Mehta</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Ulbert</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Schroeder</surname>, <given-names>C. E</given-names></string-name>. (<year>2000</year>). <article-title>Intermodal selective attention in monkeys I: Distribution and timing of effects across visual areas</article-title>. <source>Cerebral Cortex</source>, <volume>10</volume>(<issue>4</issue>), <fpage>343</fpage>–<lpage>358</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/10.4.343</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Merigan</surname>, <given-names>W. H.</given-names></string-name>, &amp; <string-name><surname>Maunsell</surname>, <given-names>J. H. R</given-names></string-name>. (<year>1993</year>). <article-title>How parallel are the primate visual pathways?</article-title> <source>Annual Review of Neuroscience</source>, <volume>16</volume>, <fpage>369</fpage>–<lpage>402</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.ne.16.030193.002101</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Mountcastle</surname>, <given-names>V. B</given-names></string-name>. (<year>1997</year>). <article-title>The columnar organization of the neocortex</article-title>. <source>Brain</source>, <volume>120</volume>(<issue>4</issue>), <fpage>701</fpage>– <lpage>722</lpage>. <pub-id pub-id-type="doi">10.1093/BRAIN/120.4.701</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Mullen</surname>, <given-names>K. T</given-names></string-name>. (<year>1985</year>). <article-title>Bornstein changes in brightness matches may have produced artifacts in previous isoluminant</article-title>. <source>The Journal of Physiology</source>, <volume>359</volume>(<issue>1</issue>), <fpage>381</fpage>–<lpage>400</lpage>. <pub-id pub-id-type="doi">10.1113/jphysiol.1985.sp015591</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Murray</surname>, <given-names>S. O.</given-names></string-name>, <string-name><surname>Kersten</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Olshausen</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Schrater</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Woods</surname>, <given-names>D. L</given-names></string-name>. (<year>2002</year>). <article-title>Shape perception reduces activity in human primary visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>99</volume>(<issue>23</issue>), <fpage>15164</fpage>–<lpage>15169</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.192579399</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Nasr</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Polimeni</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Tootell</surname>, <given-names>R. B. H</given-names></string-name>. (<year>2016</year>). <article-title>Interdigitated color- and disparity-selective columns within human visual cortical areas V2 and V3</article-title>. <source>Journal of Neuroscience</source>, <volume>36</volume>(<issue>6</issue>), <fpage>1841</fpage>–<lpage>1857</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3518-15.2016</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Nassi</surname>, <given-names>J. J.</given-names></string-name>, &amp; <string-name><surname>Callaway</surname>, <given-names>E. M</given-names></string-name>. (<year>2009</year>). <article-title>Parallel processing strategies of the primate visual system</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>(<issue>5</issue>), <fpage>360</fpage>–<lpage>372</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2619</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Norris</surname>, <given-names>D. G.</given-names></string-name>, &amp; <string-name><surname>Polimeni</surname>, <given-names>J. R</given-names></string-name>. (<year>2019</year>). <article-title>Laminar (f)MRI: A short history and future prospects</article-title>. <source>NeuroImage</source>, <volume>197</volume>, <fpage>643</fpage>–<lpage>649</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2019.04.082</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Okazawa</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Tajima</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Komatsu</surname>, <given-names>H</given-names></string-name>. (<year>2015</year>). <article-title>Image statistics underlying natural texture selectivity of neurons in macaque V4</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>112</volume>(<issue>4</issue>), <fpage>E351</fpage>–<lpage>E360</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1415146112</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Okazawa</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Tajima</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Komatsu</surname>, <given-names>H</given-names></string-name>. (<year>2017</year>). <article-title>Gradual Development of Visual Texture-Selective Properties between Macaque Areas V2 and V4</article-title>. <source>Cerebral Cortex</source>, <volume>27</volume>(<issue>10</issue>), <fpage>4867</fpage>–<lpage>4880</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhw282</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Olman</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Harel</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Feinberg</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Yacoub</surname>, <given-names>E</given-names></string-name>. (<year>2012</year>). <article-title>Layer-Specific fMRI Reflects Different Neuronal Computations at Different Depths in Human V1</article-title>. <source>PLOS ONE</source>, <volume>7</volume>(<issue>3</issue>), <fpage>e32536</fpage>. <pub-id pub-id-type="doi">10.1371/JOURNAL.PONE.0032536</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Pelli</surname>, <given-names>D. G</given-names></string-name>. (<year>1997</year>). <article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title>. <source>Spatial Vision</source>, <volume>10</volume>(<issue>4</issue>), <fpage>437</fpage>–<lpage>442</lpage>. <pub-id pub-id-type="doi">10.1163/156856897X00366</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Polimeni</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Uludağ</surname>, <given-names>K</given-names></string-name>. (<year>2018</year>). <article-title>Neuroimaging with ultra-high field MRI: Present and future</article-title>. <source>NeuroImage</source>, <volume>168</volume>, <fpage>1</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1016/J.NEUROIMAGE.2018.01.072</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Portilla</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P</given-names></string-name>. (<year>2000</year>). <article-title>Parametric texture model based on joint statistics of complex wavelet coefficients</article-title>. <source>International Journal of Computer Vision</source>, <volume>40</volume>(<issue>1</issue>), <fpage>49</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1023/A:1026553619983</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Qian</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>de Hollander</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Knapen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname>, <given-names>P.</given-names></string-name> (<year>2023</year>). <article-title>Hierarchical and fine-scale mechanisms of binocular rivalry for conscious perception</article-title>. <source>BioRxiv</source>, <fpage>2023.02.11.528110</fpage>. <ext-link ext-link-type="uri" xlink:href="http://biorxiv.org/content/early/2023/03/02/2023.02.11.528110.abstract">http://biorxiv.org/content/early/2023/03/02/2023.02.11.528110.abstract</ext-link></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Rao</surname>, <given-names>R. P. N.</given-names></string-name>, &amp; <string-name><surname>Ballard</surname>, <given-names>D. H</given-names></string-name>. (<year>1999</year>). <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nature Neuroscience1999 2:1</source>, <volume>2</volume>(<issue>1</issue>), <fpage>79</fpage>–<lpage>87</lpage>. <pub-id pub-id-type="doi">10.1038/4580</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Roe</surname>, <given-names>A. W.</given-names></string-name>, &amp; <string-name><surname>Ts’o</surname>, <given-names>D. Y</given-names></string-name>. (<year>1995</year>). <article-title>Visual topography in primate V2: Multiple representation across functional stripes</article-title>. <source>Journal of Neuroscience</source>, <volume>15</volume>(<issue>5</issue>), <fpage>3689</fpage>–<lpage>3715</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.15-05-03689.1995</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><given-names>Schulte to</given-names> <surname>Brinke</surname></string-name>, <string-name><given-names>T.</given-names>, <surname>Duarte</surname></string-name>, <string-name><given-names>R.</given-names>, &amp; <surname>Morrison</surname></string-name>, A. (<year>2022</year>). <article-title>Characteristic columnar connectivity caters to cortical computation: Replication, simulation, and evaluation of a microcircuit model</article-title>. <source>Frontiers in Integrative Neuroscience</source>, <volume>16</volume>. <pub-id pub-id-type="doi">10.3389/fnint.2022.923468</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Olshausen</surname>, <given-names>B. A</given-names></string-name>. (<year>2001</year>). <article-title>Natural Image Statistics And Neural Representation</article-title>. <source>Annual Review of Neuroscience</source>, <volume>24</volume>, <fpage>1193</fpage>–<lpage>1216</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.1193</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Stoop</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Saase</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Wagner</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Stoop</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Stoop</surname>, <given-names>R</given-names></string-name>. (<year>2013</year>). <article-title>Beyond scale-free small-world networks: Cortical columns for quick brains</article-title>. <source>Physical Review Letters</source>, <volume>110</volume>(<issue>10</issue>), <fpage>1</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.110.108105</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Tanigawa</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Lu</surname>, <given-names>H. D.</given-names></string-name>, &amp; <string-name><surname>Roe</surname>, <given-names>A. W</given-names></string-name>. (<year>2010</year>). <article-title>Functional organization for color and orientation in macaque V4</article-title>. <source>Nature Neuroscience</source>, <volume>13</volume>(<issue>12</issue>), <fpage>1542</fpage>–<lpage>1549</lpage>. <pub-id pub-id-type="doi">10.1038/nn.2676</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Tong</surname>, <given-names>F</given-names></string-name>. (<year>2003</year>). <article-title>Cognitive neuroscience: Primary visual cortex and visual awareness</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>4</volume>(<issue>3</issue>), <fpage>219</fpage>–<lpage>229</lpage>. <pub-id pub-id-type="doi">10.1038/nrn1055</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Tootell</surname>, <given-names>R. B. H.</given-names></string-name>, &amp; <string-name><surname>Nasr</surname>, <given-names>S</given-names></string-name>. (<year>2017</year>). <article-title>Columnar segregation of magnocellular and parvocellular streams in human extrastriate cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>37</volume>(<issue>33</issue>), <fpage>8014</fpage>–<lpage>8032</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0690-17.2017</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Tootell</surname>, <given-names>R. B. H.</given-names></string-name>, <string-name><surname>Silverman</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>De Valois</surname>, <given-names>R. L.</given-names></string-name>, &amp; <string-name><surname>Jacobs</surname>, <given-names>G. H.</given-names></string-name> (<year>1983</year>). <article-title>Functional organization of the second cortical visual area in primates</article-title>. <source>Science</source>, <volume>220</volume>(<issue>4598</issue>), <fpage>737</fpage>–<lpage>739</lpage>. <pub-id pub-id-type="doi">10.1126/science.6301017</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Ts’O</surname>, <given-names>D. Y.</given-names></string-name>, <string-name><surname>Roe</surname>, <given-names>A. W.</given-names></string-name>, &amp; <string-name><surname>Gilbert</surname>, <given-names>C. D</given-names></string-name>. (<year>2001</year>). <article-title>A hierarchy of the functional organization for color, form and disparity in primate visual area V2</article-title>. <source>Vision Research</source>, <volume>41</volume>(<issue>10–11</issue>), <fpage>1333</fpage>–<lpage>1349</lpage>. <pub-id pub-id-type="doi">10.1016/S0042-6989(01)00076-1</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Tsao</surname>, <given-names>D. Y.</given-names></string-name>, <string-name><surname>Vanduffel</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Sasaki</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Fize</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Knutsen</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Mandeville</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Wald</surname>, <given-names>L. L.</given-names></string-name>, <string-name><surname>Dale</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Rosen</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Livingstone</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Orban</surname>, <given-names>G. A.</given-names></string-name>, &amp; <string-name><surname>Tootell</surname>, <given-names>R. B. H.</given-names></string-name> (<year>2003</year>). <article-title>Stereopsis activates V3A and caudal intraparietal areas in macaques and humans</article-title>. <source>Neuron</source>, <volume>39</volume>(<issue>3</issue>), <fpage>555</fpage>–<lpage>568</lpage>. <pub-id pub-id-type="doi">10.1016/S0896-6273(03)00459-8</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Wagenmakers</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Love</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Marsman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jamil</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ly</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Verhagen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Selker</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Gronau</surname>, <given-names>Q. F.</given-names></string-name>, <string-name><surname>Dropmann</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Boutin</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Meerhoff</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Knight</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Raj</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>van Kesteren</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>van Doorn</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Šmíra</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Epskamp</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Etz</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Matzke</surname>, <given-names>D.</given-names></string-name>, … <string-name><surname>Morey</surname>, <given-names>R. D.</given-names></string-name> (<year>2018</year>). <article-title>Bayesian inference for psychology</article-title>. <source>Part II: Example applications with JASP. Psychonomic Bulletin and Review</source>, <volume>25</volume>(<issue>1</issue>), <fpage>58</fpage>–<lpage>76</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-017-1323-7</pub-id></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Xiao</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Felleman</surname>, <given-names>D. J</given-names></string-name>. (<year>2003</year>). <article-title>A spatially organized representation of colour in macaque cotical area V2</article-title>. <source>Nature</source>, <volume>421</volume>(<issue>6922</issue>), <fpage>535</fpage>–<lpage>539</lpage>. <pub-id pub-id-type="doi">10.1038/nature01372</pub-id></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Van De Moortele</surname>, <given-names>P. F.</given-names></string-name>, <string-name><surname>Shmuel</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Uǧurbil</surname>, <given-names>K.</given-names></string-name> (<year>2005</year>). <article-title>Signal and noise characteristics of Hahn SE and GE BOLD fMRI at 7 T in humans</article-title>. <source>NeuroImage</source>, <volume>24</volume>(<issue>3</issue>), <fpage>738</fpage>–<lpage>750</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.09.002</pub-id></mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Zeki</surname>, <given-names>S. M</given-names></string-name>. (<year>1973</year>). <article-title>Colour coding in rhesus monkey prestriate cortex</article-title>. <source>Brain Research</source>, <volume>53</volume>(<issue>2</issue>), <fpage>422</fpage>–<lpage>427</lpage>. <pub-id pub-id-type="doi">10.1016/0006-8993(73)90227-8</pub-id></mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>Ziemba</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Freeman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P</given-names></string-name>. (<year>2016</year>). <article-title>Selectivity and tolerance for visual texture in macaque V2</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>113</volume>(<issue>22</issue>), <fpage>3140</fpage>–<lpage>3149</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1510847113</pub-id></mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Ziemba</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Perez</surname>, <given-names>R. K.</given-names></string-name>, <string-name><surname>Pai</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Kelly</surname>, <given-names>J. G.</given-names></string-name>, <string-name><surname>Hallum</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Shooner</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Anthony Movshon</surname>, <given-names>J</given-names></string-name>. (<year>2019</year>). <article-title>Laminar differences in responses to naturalistic texture in macaque V1 and V2</article-title>. <source>Journal of Neuroscience</source>, <volume>39</volume>(<issue>49</issue>), <fpage>9748</fpage>–<lpage>9756</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1743-19.2019</pub-id></mixed-citation></ref>
</ref-list>
<sec id="s6">
<title>Supplementary figures</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><p>The functional maps in V2 for all ten subjects. The scale bar denotes percent signal change of BOLD response. Color-selective thin and disparity-selective thick stripes were denoted by red and blue arrows, respectively. LH: left hemisphere; RH: right hemisphere.</p></caption>
<graphic xlink:href="564178v1_figs1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><p>The manually defined ROIs for disparity-selective thick, color-selective thin stripes, and the pale stripes in-between in a representative subject (S09). The scale bar denotes percent signal change of BOLD response. The stripes are framed with dashed lines. Black: thin and thick stripes (<xref rid="fig2" ref-type="fig">Figure 2A</xref>); purple: pale stripes.</p></caption>
<graphic xlink:href="564178v1_figs2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><p>The bootstrapped distributions of stimulus-selectivity indices in different types of column ROIs. Dashed lines indicate zero selectivity. Color- and disparity-selective indices both show significant difference across three stripes. Texture-selective index shows non-significant difference across different stripes.</p></caption>
<graphic xlink:href="564178v1_figs3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><p>Inter-session correlations for the color- and disparity-selective activation maps in four subjects who scanned both color and disparity experiments in two days. The results for S09 were shown in <xref rid="fig2" ref-type="fig">figure 2</xref>.</p></caption>
<graphic xlink:href="564178v1_figs4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5.</label>
<caption><p>Results of isoluminance adjustment.</p><p>The measured luminance values of gray (A) and red (B) that match the luminance of maximum blue values across three eccentricities.</p></caption>
<graphic xlink:href="564178v1_figs5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Figure S6.</label>
<caption><p>Illustrations of depth map (A) and pial vein removal (B). Red pixels in Figure B represents vertices with extremely large signal changes (top 5%) that were excluded.</p></caption>
<graphic xlink:href="564178v1_figs6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Figure S7.</label>
<caption><p>Null distributions of pattern correlation coefficients from Monto-Carlo simulation.</p></caption>
<graphic xlink:href="564178v1_figs7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93171.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Krug</surname>
<given-names>Kristine</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Otto-von-Guericke University Magdeburg</institution>
</institution-wrap>
<city>Magdeburg</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents <bold>important</bold> findings for understanding cortical processing of color, binocular disparity, and naturalistic textures in the human visual cortex at the spatial scale of cortical layers and columns using state-of-the-art high-resolution fMRI methods at ultra-high magnetic field strength (7 T). <bold>Solid</bold> evidence supports an interesting layer-specific informational connectivity analysis to infer information flow across early visual areas for processing disparity and color signals. While the question of how the modularity of representation relates to cortical hierarchical processing is interesting, the findings that texture does not map onto previously established columnar architecture in V2 are suggestive but would benefit from further controls. The successful application of high-resolution fMRI methods to study the functional organization along cortical columns and layers is relevant to a broad readership interested in general neuroscience.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93171.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This study examines the cortical modular functional organization of visual texture in comparison with that of color and disparity. While color, disparity, and orientation have been shown to exhibit clear functional organizations within the thin, thick, and thick/pale stripes of V2, whether the feature of texture is also organized within V2 is unknown. Using ultrahigh field 7T fMRI in humans viewing color-, disparity-, and texture-specific visual stimuli, the authors find that, unlike color and disparity, texture does not exhibit stripe-specific organization in V2. Moreover, using laminar imaging methods and calculations of informational connectivity, they find V2 color and disparity stripes exhibit the expected feedforward and feedback relationships with V1 &amp; V4, and with V1 &amp; V3ab, respectively. In contrast, texture activation, found predominantly in the deep layers of V2, is driven preferentially by feedback from V4. Based on these findings, the authors suggest that texture is a visual feature computed in higher-order areas and not generated by local intra-V2 computation.</p>
<p>Strengths:</p>
<p>
This study poses an interesting and fundamental question regarding the relationship between functional modularity and the hierarchical origin of computed properties. This question is thus highly significant and deserves study. The methodology is appropriate for the question and the areal and laminar resolution achieved across 10 subjects is commendable. The combination of high-resolution functional imaging and informational connectivity analysis introduces a useful way for examining feedforward and feedback relationships in mesoscale imaging data.</p>
<p>Weaknesses:</p>
<p>
While the data are suggestive, further controls are needed.</p>
<p>To support the finding that texture is not represented in a modular fashion, additional possibilities must be considered. These include the effectiveness and specificity of the texture stimulus and control stimuli, (b) further analysis of possible structure in images that may have been missed, and (c) limitations of imaging resolution.</p>
<p>More in-depth analysis of subject data is needed. The apparent structure in the texture images in peripheral fields of some subjects calls for more detailed analysis. e.g Relationship to eccentricity and the need for a 'modularity index' to quantify the degree of modularity. A possible relationship to eccentricity should also be considered.</p>
<p>Given what is known as a modular organization in V4 and V3 (e.g. for color, orientation, curvature), did images reveal these organizations? If so, connectivity analysis would be improved based on such ROIs. This would further strengthen the hierarchical scheme.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93171.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>High-resolution functional magnetic resonance imaging (fMRI) at ultra-high magnetic field strengths (7 T and above) can potentially study cortical functioning at the mesoscopic scale, i.e., at the spatial scale of cortical columns and layers. The authors of the study entitled &quot;Mesoscale functional organization and connectivity of color, disparity, and naturalistic texture in human second visual area&quot; remarkably show the current possibilities of high-resolution fMRI methods by studying the columnar and laminar organization for the processing of color, binocular disparity, and naturalistic texture in human secondary visual cortex (V2).</p>
<p>The study could robustly show color-selective and disparity-selective stripes in human V2. While this was already demonstrated in several in vivo studies using fMRI (Nasr et al., 2016, J Neurosci, 36, 1841-1857; Dumoulin et al., 2017, Sci Rep, 7, 733; Tootell et al., 2021, Cereb Cortex, 31, 1163-1181; Navarro et al., 2021, NeuroImage, 225, 117520; Kennedy et al., 2023, Prog Neurobiol, 220, 102374; Haenelt et al., 2023, eLife, 12, e78756), the strength, in my opinion, of the current study is three-fold:</p>
<p>1. Previous studies mainly focused on the columnar architecture of the stripe architecture in V2, neglecting any information across cortical depth. This study included a laminar analysis, which showcases the current possibilities of high-resolution fMRI methods that target the cortical local circuitry at the mesoscopic level.</p>
<p>2. The successful mapping of color-selective and disparity-selective stripes in V2 was corroborated by an innovative connectivity analysis, which shows the expected higher connectivity of color-selective clusters in V2 with area V4 and binocular disparity with area V3ab.</p>
<p>3. Furthermore, in addition to color-selective and disparity-selective stripes in V2 that were already shown in several studies at the columnar level (but without a laminar analysis), this study included naturalistic textures and analyzed the mesoscopic processing in V2. As expected, they showed greater sensitivity for texture selectivity in higher-order areas such as V4 and V3ab. In addition, due to the laminar analysis, feedforward and feedback connectivity were shown to be differentiable, demonstrating that feedback processes from higher-order areas rather drive texture processing in V2.</p>
<p>Overall, the study shows interesting results that are valuable for the general neuroscientific community. In addition, the manuscript is understandable and clearly written.</p>
<p>However, a few points might be worth discussing:</p>
<p>1. In lines 162-163, it is stated that no clear columnar organization exists for naturalistic texture processing in V2. In my opinion, this should be rephrased. As far as I understand, Figure 2B refers to the analysis used to support the conclusion. The left and middle bar plots only show a circular analysis since ROIs were based on the color and disparity contrast used to define thin and thick stripes. The interesting graph is the right plot, which shows no statistically significant overlap of texture processing with thin, thick, and pale stripe ROIs. It should be pointed out that this analysis does not dismiss a columnar organization per se but instead only supports the conclusion of no coincidence with the CO-stripe architecture.</p>
<p>2. In Figure 3, cortical depth-dependent analyses are presented for color, disparity, and texture processing. I acknowledge that the authors took care of venous effects by excluding outlier voxels. However, the GE-BOLD signal at high magnetic fields is still biased to extravascular contributions from around larger veins. Therefore, the highest color selectivity in superficial layers might also result from the bias to draining veins and might not be of neuronal origin. Furthermore, it is interesting that cortical profiles with the highest selectivity in superficial layers show overall higher selectivity across cortical depth. Could the missing increase toward the pial surface in other profiles result from the ROI definition or overall smaller signal changes (effect size) of selected voxels? At least, a more careful interpretation and discussion would be helpful for the reader.</p>
<p>3. I was slightly surprised that no retinotopy data was acquired. The ROI definition in the manuscript was based on a retinotopy atlas plus manual stripe segmentation of single columns. Both steps have disadvantages because they neglect individual differences and are based on subjective assessment. A few points might be worth discussing: (1) In lines 467-468, the authors state that V2 was defined based on the extent of stripes. This classical definition of area V2 was questioned by a recent publication (Nasr et al., 2016, J Neurosci, 36, 1841-1857), which showed that stripes might extend into V3. Could this have been a problem in the present analysis, e.g., in the connectivity analysis? (2) The manual segmentation depends on the chosen threshold value, which is inevitably arbitrary. Which value was used?</p>
<p>4. The use of 1-mm isotropic voxels is relatively coarse for cortical depth-dependent analyses, especially in the early visual cortex, which is highly convoluted and has a small cortical thickness. For example, most layer-fMRI studies use a voxel size of around isotropic 0.8 mm, which has half the voxel volume of 1 mm isotropic voxels. With increasing voxel volume, partial volume effects become more pronounced. For example, partial volume with CSF might confound the analysis by introducing pulsatility effects.</p>
<p>5. The SVM analysis included a feature selection step stated in lines 531-533. Although this step is reasonable for the training of a machine learning classifier, it would be interesting to know if the authors think this step could have reintroduced some bias to remaining draining vein contributions.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93171.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
Ai et al. studied texture, color, and disparity selectivity in the human visual cortex at the mesoscale level using high-resolution fMRI. They reproduced earlier monkey and human studies showing interdigitated color-selective and disparity-selective sub-compartments within area V2, likely corresponding to thin and thick stripes, respectively. At least with the stimuli used, no clear evidence for texture-selective mesoscale activations was observed in area V2. The most interesting and novel part of this study focused on cortical-depth-dependent connectivity analyses across areas. The data suggest feedback and feedforward functional connectivity between V1 and V3A for disparity signals and feedback from V4 to the deep layers of V2 for textures.</p>
<p>Strengths:</p>
<p>
High-resolution fMRI and highly interesting layer-specific informational connectivity analyses.</p>
<p>Weaknesses:</p>
<p>
The authors tend to overclaim their results.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93171.1.sa4</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ai</surname>
<given-names>Hailin</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lin</surname>
<given-names>Weiru</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Chengwen</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chen</surname>
<given-names>Nihong</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0890-3875</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Peng</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9603-8454</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>eLife assessment</bold></p>
<p>This study presents important findings for understanding cortical processing of color, binocular disparity, and naturalistic textures in the human visual cortex at the spatial scale of cortical layers and columns using state-of-the-art high-resolution fMRI methods at ultra-high magnetic field strength (7 T). Solid evidence supports an interesting layer-specific informational connectivity analysis to infer information flow across early visual areas for processing disparity and color signals. While the question of how the modularity of representation relates to cortical hierarchical processing is interesting and fundamental, the findings that texture does not map onto previously established columnar architecture in V2 is suggestive but would benefit from further controls. The successful application of high-resolution fMRI methods to study the functional organization along cortical columns and layers is relevant to a broad readership interested in general neuroscience.</p>
</disp-quote>
<p>Thank you for your assessment of our manuscript &quot;Mesoscale functional organization and connectivity of color, disparity, and naturalistic texture in human second visual area &quot;. We have carefully considered the public reviews and have outlined our plans of revision by providing point-by-point responses to the reviewers’ comments.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>To support the finding that texture is not represented in a modular fashion, additional possibilities must be considered. These include the effectiveness and specificity of the texture stimulus and control stimuli, (b) further analysis of possible structure in images that may have been missed, and (c) limitations of imaging resolution.</p>
</disp-quote>
<p>Thank you for your suggestions. We will provide evidence and additional analyses to show that there was indeed a large difference in high-order statistical information between the texture and control stimuli in our study, and thus the contrast between the two stimuli should be effective in localizing the processing of high-order texture information. Compared to the previous studies, another reason for the weaker texture selectivity in the current study could be the smaller number of images used and the slower rate of image presentation. Although our fMRI result at 1-mm isotropic resolution did not show a modular processing of naturalistic texture in CO-stripe columns, this does not exclude the possibility that smaller modules exist beyond the current fMRI resolution. We will discuss these limitations in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>More in-depth analysis of subject data is needed. The apparent structure in the texture images in peripheral fields of some subjects calls for more detailed analysis. e.g. Relationship to eccentricity and the need for a 'modularity index' to quantify the degree of modularity. A possible relationship to eccentricity should also be considered.</p>
</disp-quote>
<p>We will perform further analysis based on your suggestion, especially regarding the relationship between eccentricity and modulation index. We will discuss this possibility in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Given what is known as a modular organization in V4 and V3 (e.g. for color, orientation, curvature), did images reveal these organizations? If so, connectivity analysis would be improved based on such ROIs. This would further strengthen the hierarchical scheme.</p>
</disp-quote>
<p>Thank you for your suggestion. The informational connectivity analyses used highly informative voxels by feature selection, which may already represent information from the modular organizations in these higher visual areas. We will examine the functional maps for possible modular organizations.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>In lines 162-163, it is stated that no clear columnar organization exists for naturalistic texture processing in V2. In my opinion, this should be rephrased. As far as I understand, Figure 2B refers to the analysis used to support the conclusion. The left and middle bar plots only show a circular analysis since ROIs were based on the color and disparity contrast used to define thin and thick stripes. The interesting graph is the right plot, which shows no statistically significant overlap of texture processing with thin, thick, and pale stripe ROIs. It should be pointed out that this analysis does not dismiss a columnar organization per se but instead only supports the conclusion of no coincidence with the CO-stripe architecture.</p>
</disp-quote>
<p>Reviewer #1 also raised a similar concern. We agree that there may be a smaller functional module of textures in area V2 at a finer spatial scale than our fMRI resolution. We will rephrase our conclusions to be more precise.</p>
<disp-quote content-type="editor-comment">
<p>In Figure 3, cortical depth-dependent analyses are presented for color, disparity, and texture processing. I acknowledge that the authors took care of venous effects by excluding outlier voxels. However, the GE-BOLD signal at high magnetic fields is still biased to extravascular contributions from around larger veins. Therefore, the highest color selectivity in superficial layers might also result from the bias to draining veins and might not be of neuronal origin. Furthermore, it is interesting that cortical profiles with the highest selectivity in superficial layers show overall higher selectivity across cortical depth. Could the missing increase toward the pial surface in other profiles result from the ROI definition or overall smaller signal changes (effect size) of selected voxels? At least, a more careful interpretation and discussion would be helpful for the reader.</p>
</disp-quote>
<p>We will discuss the limitations of cortical depth-dependent analysis using GE-BOLD fMRI. All our stimuli produced robust activations in these visual areas, thus the flat laminar profiles of modulatory indices are unlikely to be caused by smaller signal changes. We will show the original BOLD responses in addition to the modulation index.</p>
<disp-quote content-type="editor-comment">
<p>I was slightly surprised that no retinotopy data was acquired. The ROI definition in the manuscript was based on a retinotopy atlas plus manual stripe segmentation of single columns. Both steps have disadvantages because they neglect individual differences and are based on subjective assessment. A few points might be worth discussing: (1) In lines 467-468, the authors state that V2 was defined based on the extent of stripes. This classical definition of area V2 was questioned by a recent publication (Nasr et al., 2016, J Neurosci, 36, 1841-1857), which showed that stripes might extend into V3. Could this have been a problem in the present analysis, e.g., in the connectivity analysis? (2) The manual segmentation depends on the chosen threshold value, which is inevitably arbitrary. Which value was used?</p>
</disp-quote>
<p>The retinotopic atlas on the standard surface is usually quite accurate in defining the boundaries of early visual areas. Although some stripes may extend into V3, these patterns should be more robust in V2. In our analysis, we selected only those with clear organizations within the retinotopic atlas. Thus, the signal contribution from V3 is likely to be small and would not affect the pattern of results. In addition, the results between V3 and V2 could be very different, we will compare the pattern of results from these areas in additional analyses. The threshold for segmentation is abs(T)&gt;2, we will clarify this in the method.</p>
<disp-quote content-type="editor-comment">
<p>The use of 1-mm isotropic voxels is relatively coarse for cortical depth-dependent analyses, especially in the early visual cortex, which is highly convoluted and has a small cortical thickness. For example, most layer-fMRI studies use a voxel size of around isotropic 0.8 mm, which has half the voxel volume of 1 mm isotropic voxels. With increasing voxel volume, partial volume effects become more pronounced. For example, partial volume with CSF might confound the analysis by introducing pulsatility effects.</p>
</disp-quote>
<p>We agree that the 1-mm isotropic voxel is much smaller in volume than the 0.8-mm isotropic voxel, but the resolution along the cortical depth is not a large difference. In addition to our study, there are also other studies showing that fMRI at 1-mm isotropic resolution is capable of resolving cortical depth-dependent signals. Also, our fMRI slices were oriented perpendicular to the calcarine sulcus, the higher in-plane resolution will also benefit in resolving depth-dependent signals. We will discuss these issues about fMRI resolution in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>The SVM analysis included a feature selection step stated in lines 531-533. Although this step is reasonable for the training of a machine learning classifier, it would be interesting to know if the authors think this step could have reintroduced some bias to remaining draining vein contributions.</p>
</disp-quote>
<p>Several precautions have been taken in the ROI definition to reduce the influence of large draining veins. The same number of voxels were selected from each cortical depth for the SVM analysis, thus there was no bias from the superficial layers susceptible to draining veins. Also, since both feedforward and feedback connections involved the superficial voxels, the remaining influence of large draining veins should be comparable between the two connections.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>The authors tend to overclaim their results.</p>
</disp-quote>
<p>Thank you for your comments. We will add more control analyses to strengthen our findings, and have appropriate discussion of results.</p>
</body>
</sub-article>
</article>