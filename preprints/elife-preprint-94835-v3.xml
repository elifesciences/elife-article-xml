<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">94835</article-id>
<article-id pub-id-type="doi">10.7554/eLife.94835</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94835.3</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.4</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Neural coding of multiple motion speeds in visual cortical area MT</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Huang</surname>
<given-names>Xin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>Xin.Huang@wisc.edu</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ghimire</surname>
<given-names>Bikalpa</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chakrala</surname>
<given-names>Anjani Sreeprada</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wiesner</surname>
<given-names>Steven</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01y2jtd41</institution-id><institution>Department of Neuroscience, University of Wisconsin-Madison</institution></institution-wrap>, <city>Madison</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Groh</surname>
<given-names>Jennifer M</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Duke University</institution>
</institution-wrap>, <city>Durham</city>, <country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="supported-by"><p>Grant support: Research reported in this publication was supported by the National Eye Institute of the NIH grant R01EY022443 (XH). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-03-28">
<day>28</day>
<month>03</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-12-01">
<day>01</day>
<month>12</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP94835</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-03">
<day>03</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-11-22">
<day>22</day>
<month>11</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.08.532456"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-03-28">
<day>28</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94835.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa2">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa1">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa0">Reviewer #3 (Public Review):</self-uri>
</event>
<event>
<event-desc>Reviewed preprint v2</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-07-17">
<day>17</day>
<month>07</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94835.2"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.94835.2.sa3">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.2.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.2.sa1">Reviewer #3 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.94835.2.sa0">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Huang et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Huang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-94835-v3.pdf"/>
<abstract>
<p>Motion speed provides a salient cue for visual segmentation, yet how the visual system represents and differentiates multiple speeds remains poorly understood. Here, we investigated the neural coding of multiple speeds. First, we characterized the perceptual capacity of human and macaque subjects to segment overlapping random-dot stimuli moving at different speeds. We then recorded from neurons in the middle temporal (MT) cortex of macaque monkeys to determine how multiple speeds are represented. We made a novel finding that the responses of MT neurons to two speeds showed a robust bias toward the faster speed component when both speeds were slow (≤ 20°/s). This faster-speed bias emerged early in the neuronal response. It occurred regardless of whether the two speed components moved in the same or different directions, and even when attention was directed away from the receptive field. As stimulus speed increased, the faster-speed bias diminished. Our finding can be explained by a modified divisive normalization model, in which the weights for the speed components are proportional to the responses of a population of neurons, referred to as the weighting pool, elicited by the individual speeds. We suggest that the weighting pool include neurons with a broad range of speed preferences. We found that a classifier can differentiate the responses of MT neurons to two speeds versus a corresponding log-mean speed. We further showed that it was possible to decode two speeds from MT population response, supporting the theoretical framework of coding multiplicity of visual features in neuronal populations. The decoded speeds can account for the perceptual performance of segmenting two speeds with a large (×4) but not a small (×2) separation, raising questions for future investigations. Our findings help define the neural coding rule of multiple speeds. The faster-speed bias in MT at slow stimulus speeds could benefit important behavioral tasks such as figure-ground segregation, as figural objects tend to move faster than the background in the natural environment.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>neural encoding</kwd>
<kwd>decoding</kwd>
<kwd>segmentation</kwd>
<kwd>discrimination</kwd>
<kwd>speed tuning</kwd>
<kwd>velocity</kwd>
<kwd>transparent motion</kwd>
<kwd>divisive normalization</kwd>
<kwd>figure-ground segregation</kwd>
<kwd>natural scenes</kwd>
<kwd>efficient coding</kwd>
</kwd-group>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
    <institution-id institution-id-type="ror">https://ror.org/03wkg3b53</institution-id>
<institution>HHS | NIH | National Eye Institute (NEI)</institution>
</institution-wrap>
</funding-source>
<award-id>R01EY022443</award-id>
<principal-award-recipient>
<name>
<surname>Huang</surname>
<given-names>Xin</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Include an additional analysis of the weight for the fast component, using the firing rates in response to the slower component from split trials, and a supplementary Figure (SFig. 1). We also made minor edits to the manuscript.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Neuroscientists have been investigating how neurons in the brain represent sensory information for decades. Previous studies have often focused on the neural coding of a single visual stimulus. However, natural environments are abundant with multiple entities that often co-occupy the receptive fields (RFs) of visual neurons. Segmenting visual objects from one another and their background is a fundamental function of vision (<xref ref-type="bibr" rid="c12">Braddick, 1993</xref>). Yet, the neural mechanisms underlying the representation of multiple stimuli remain poorly understood. As the field moves toward understanding visual processing under more naturalistic conditions, it becomes increasingly important to uncover the principles by which the brain encodes multiple stimuli. Visual motion is a particularly salient cue for scene segmentation. Elements that share common motion are typically grouped into a single perceptual object, while entities moving at different velocities can often be segregated from each other. For instance, an object moving at a speed distinct from its background is more readily segmented. In this study, we investigated how the primate visual system represents multiple motion speeds.</p>
    <p>The extrastriate area MT plays a crucial role in motion processing and motion-based segmentation (<xref ref-type="bibr" rid="c1">Allman et al., 1985</xref>; <xref ref-type="bibr" rid="c15">Britten, 2003</xref>; <xref ref-type="bibr" rid="c10">Born and Bradley, 2005</xref>; <xref ref-type="bibr" rid="c56">Pasternak et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Born et al., 2000</xref>; <xref ref-type="bibr" rid="c31">Huang et al., 2007</xref>, <xref ref-type="bibr" rid="c32">2008</xref>). Segmentation of overlapping stimuli moving in different directions and speeds gives rise to the perception of transparent motion (<xref ref-type="bibr" rid="c13">Braddick, 1997</xref>; <xref ref-type="bibr" rid="c14">Braddick et al., 2002</xref>; <xref ref-type="bibr" rid="c47">Mestre et al., 2001</xref>; <xref ref-type="bibr" rid="c44">Masson et al., 1999</xref>). Previous studies have investigated how neurons in MT represent two directions of transparently moving stimuli (<xref ref-type="bibr" rid="c72">Snowden et al., 1991</xref>; <xref ref-type="bibr" rid="c63">Qian and Andersen, 1994</xref>; <xref ref-type="bibr" rid="c46">McDonald et al., 2014</xref>; <xref ref-type="bibr" rid="c82">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c81">Xiao and Huang, 2015</xref>; <xref ref-type="bibr" rid="c80">Wiesner et al., 2020</xref>; <xref ref-type="bibr" rid="c74">Stoner and Albright, 1992</xref>; <xref ref-type="bibr" rid="c36">Krekelberg and van Wezel, 2013</xref>). Although how cortical neurons represent the speed of a single stimulus has been well-studied (<xref ref-type="bibr" rid="c45">Maunsell and van Essen, 1983</xref>; <xref ref-type="bibr" rid="c40">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c52">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="c55">Pack et al., 2005</xref>; <xref ref-type="bibr" rid="c37">Krekelberg et al., 2006a</xref>; <xref ref-type="bibr" rid="c57">Perrone and Thiele, 2001</xref>; <xref ref-type="bibr" rid="c61">Priebe et al., 2003</xref>, <xref ref-type="bibr" rid="c62">2006</xref>; <xref ref-type="bibr" rid="c41">Liu and Newsome, 2003</xref>), how neurons represent multiple speeds of transparently moving stimuli is largely unknown.</p>
<p>In characterizing how MT neurons represent multiple directions of transparently moving stimuli, we have previously shown that many neurons do not pool two directions equally, but weigh one direction more than the other (<xref ref-type="bibr" rid="c81">Xiao and Huang, 2015</xref>). We have also found that some MT neurons exhibit response nonlinearity when pooling two directions, in a manner that better represents the individual direction components. The heterogeneous response weights and response nonlinearity in representing multiple directions can benefit the neural coding of multiple stimuli (<xref ref-type="bibr" rid="c54">Orhan and Ma, 2015</xref>; <xref ref-type="bibr" rid="c81">Xiao and Huang, 2015</xref>), and may constitute an optimal population representation of visual motion with multiple directions (<xref ref-type="bibr" rid="c29">Huang et al., 2017</xref>). Unlike two motion directions for which the individual directions appear to be balanced in perceptual quality and salience, visual stimuli moving at two speeds appear to be asymmetrical – one slower and one faster. The goal of this study is to determine the neural coding principle for multiple speeds of overlapping stimuli.</p>
    <p>Visual information is encoded in the brain by populations of neurons, and Bayesian inference provides a robust framework for understanding the population neural code (<xref ref-type="bbir" rid="c58">Pouget et al., 2000</xref>; <xref ref-type="bibr" rid="c6">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="c42">Ma et al., 2006</xref>; Fisher et al., 2010). Additionally, the visual system may be optimized to represent information in natural environments and to enhance performance in key behavioral tasks (<xref ref-type="bibr" rid="c8">Barlow, 1961</xref>; <xref ref-type="bibr" rid="c4">Atick and Redlich, 1992</xref>; <xref ref-type="bibr" rid="c71">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="c26">Ganguli and Simoncelli, 2014</xref>; <xref ref-type="bibr" rid="c43">Manning et al., 2024</xref>). Within this framework, we consider several scenarios for how MT neurons might encode two speeds within their RFs. 1) <italic>Response averaging</italic>: MT neurons may average the responses elicited by individual speed components, a phenomenon often observed in neural responses to multiple stimuli (e.g., <xref ref-type="bibr" rid="c64">Recanzone et al., 1997</xref>; <xref ref-type="bibr" rid="c86s">Zoccolan et al., 2005</xref>). When the separation between the two speeds is smaller than the neuron’s tuning width, the population response to two speeds would appear unimodal, peaking at an intermediate speed. While decoding two stimuli from a unimodal response is theoretically possible (<xref ref-type="bibr" rid="c84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c75">Treue et al., 2000</xref>), response averaging may result in poorer segmentation compared to encoding schemes that emphasize individual components, as demonstrated in neural coding of overlapping motion directions (<xref ref-type="bibr" rid="c81">Xiao and Huang, 2015</xref>). 2) <italic>Bias toward the stronger component response</italic>: A neuron may favor the speed component that elicits a stronger response, following a soft-max operation (<xref ref-type="bibr" rid="c65">Riesenhuber and Poggio, 1999</xref>). This scheme allows neurons to preferentially encode stimuli at speeds closer to their preferred speeds and maintain a population code that represents both components. 3) <italic>Bias toward the slower speed component</italic>: Given that slower speeds are more prevalent in natural environments (<xref ref-type="bibr" rid="c79">Weiss et al., 2002</xref>; <xref ref-type="bibr" rid="c73">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="c85">Zhang and Stocker, 2022</xref>), MT neurons may favor slower components. Such encoding would align with the prior probability of natural speed distributions, optimizing for more frequent stimuli. 4) <italic>Bias toward the faster speed component</italic>: Neurons may prioritize faster-moving components. This scheme would enable better segmentation of a faster-moving stimulus from a slower background, facilitating the critical perceptual task of figure-ground segregation. Finally, we investigated whether these encoding rules are dependent on stimulus speeds and the speed preferences of individual neurons.</p>
<p>Regarding neural decoding, previous studies successfully extracted single stimulus speeds from neuronal populations in MT using decoders such as vector-averaging and maximum likelihood estimators (<xref ref-type="bibr" rid="c40">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c23">Churchland and Lisberger, 2001</xref>; <xref ref-type="bibr" rid="c60">Priebe and Lisberger, 2004</xref>; <xref ref-type="bibr" rid="c30">Huang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="c83">Yang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="c37">Krekelberg et al., 2006a</xref>, b; <xref ref-type="bibr" rid="c36">Krekelberg and van Wezel, 2013</xref>). However, it is unclear whether simultaneously presented multiple speeds can be extracted from population neural responses, which would be difficult for decoders that only read out a single value. Zemel and colleagues developed a decoding framework that recovers the probabilistic distribution of a stimulus feature (<xref ref-type="bibr" rid="c84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c59">Pouget et al., 2003</xref>). Decoders of this type remain to be tested with neurophysiological and perceptual data.</p>
<p>We first characterized the perception of overlapping stimuli that moved simultaneously at two speeds. Our results showed that human and monkey subjects can segment overlapping stimuli based only on speed cues. The performance was better when the separation between the two stimulus speeds was larger, and the ability to segment speeds was reduced when stimulus speeds were fast. Next, we recorded neuronal responses from area MT of macaque monkeys. We made a novel finding that MT neurons exhibited a strong faster-speed bias when stimulus speeds were slow. As stimulus speeds increased, the faster-speed bias gradually shifted toward response averaging. We also demonstrated that a classifier could distinguish between a two-speed stimulus and a single-speed stimulus based on MT responses in a manner generally consistent with perception. We proposed a model in which each speed component was weighted by the responses of a population of neurons with a broad range of speed preferences elicited by that speed component. We also found that information about two speeds was carried in the population neural response in MT, and it was possible to extract either a single speed or two speeds in a way largely consistent with perception, with limitations when two stimulus speeds were less separated from each other. This study helps to fill a gap in understanding the neural coding principle of multiple motion speeds. It provides new insight into the mechanism underlying the neural representation of multiple visual stimuli.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Perception of overlapping stimuli moving at different speeds</title>
<sec id="s2a1">
<title>Human psychophysics</title>
<p>To establish the perceptual basis for our study, we first characterized how human subjects perceived overlapping stimuli moving at different speeds. We used similar visual stimuli in our psychophysics experiments as in our neurophysiology experiments. We asked how perceptual segmentation was impacted by the separation between two stimulus speeds and the mean stimulus speed.</p>
<p>The visual stimuli consisted of two overlapping random-dot patches presented within a stationary square aperture, 10° wide, and centered at an eccentricity of 11°. The random dots translated within the aperture in the same direction at two different speeds. It has been suggested that the neural encoding of speed in the visual cortex is on a logarithmic scale (<xref ref-type="bibr" rid="c45">Maunsell and van Essen, 1983</xref>; <xref ref-type="bibr" rid="c40">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c52">Nover et al., 2005</xref>). We used a fixed ratio between two speeds, which resulted in a fixed speed difference on the logarithmic scale. One set of stimuli had a “large speed separation”, and the speed of the faster component was four times that of the slower component. The five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1B1</xref>). Another set of stimuli had a “small speed separation”, and the speed ratio was two. The five speed pairs were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1B2</xref>). Experimental trials of bi-speed stimuli that had large and small speed separations were randomly interleaved.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Psychophysical tasks and performance of human subjects.</title>
<p><bold>A.</bold> Illustration of the 2AFC and 3AFC tasks. <bold>B</bold>. Motion speeds of visual stimuli. The speeds of two stimulus components were plotted versus the log mean speed of each bi-speed stimulus. <bold>C</bold>. Discriminability of four human subjects performing a standard 2AFC task. Letters are coded symbols for individual subjects. <bold>D</bold>. In the 3AFC task, the percentage of trials that human subjects reported “no two-speeds”. <bold>E</bold>. Discriminability of the same subjects performing the 3AFC task. <bold>B1-E1</bold>. X4 speed separation. <bold>B2-E2</bold>. X2 speed separation. Each color represents data from one subject. The solid line shows the subject-averaged result. Error bars and error bands represent ±STE.</p></caption>
<graphic xlink:href="532456v4_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Human subjects first performed a standard two-alternative forced-choice (2AFC) task to discriminate a bi-speed stimulus from the corresponding single-speed stimulus that moved at the log mean speed of the two component speeds. In each trial, the bi-speed and single-speed stimuli were presented in two consecutive time intervals in a random and balanced order (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). At large (x4) speed separation, all four subjects could perform the task well when the component speeds were less than 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). At 20 and 80°/s, the discrimination performance was poor (mean <italic>d’</italic> = 0.74, standard error STE = 0.5), indicating that subjects could not segment the speed components. At the small (x2) speed separation, the discriminability was worse than at the x4 separation. When the component speeds were less than 20 and 40°/s, subjects on average could differentiate the bi-speed stimulus from the single-speed stimulus (<italic>d’</italic> &gt; 1.5), but not when speeds were at 20 and 40°/s (mean <italic>d’</italic> = 0.17, STE = 0.1) (<xref rid="fig1" ref-type="fig">Fig. 1C2</xref>).</p>
<p>In the standard 2AFC task, it is possible that subjects could not segment the bi-speed stimulus into two separate speeds, but were still able to differentiate the bi-speed stimulus from the single-speed stimulus based on their appearance (e.g., the distribution of random dots in the bi-speed stimulus may appear less uniform). To address this concern, we designed a novel 3AFC task to measure discriminability based on perceptual segmentation. In the modified task, subjects still discriminated the bi-speed stimulus from the corresponding single-speed stimulus, but had the option to make a third choice on trials when they thought neither stimulus interval appeared to contain two speeds (“no two-speeds” choice) (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Panels D1 and D2 show the percentage of trials in which subjects made the no two-speeds choice (NTC). At x4 speed separation, the percentage of NTC was low at most speed pairs, except for the highest speeds of 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1D1</xref>). At x2 speed separation, the percentage of NTC showed a U-shape as a function of the stimulus speed and was near 100% at 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1D2</xref>). These results confirmed that human subjects had difficulty segmenting two speeds when stimulus speeds were high. In addition, at low stimulus speeds with a small (x2) speed separation, subjects tended to perceive only one speed (<xref rid="fig1" ref-type="fig">Fig. 1D2</xref>). We incorporated the NTC into the <italic>d’</italic> calculation by evenly splitting the NTC trials into “hit” trials and “false alarm” trials (see Methods). In this way, the NTC trials were accounted for by <italic>d’</italic>, in the sense that they did not contribute to successful discrimination.</p>
<p>The <italic>d’</italic> from the 3AFC task were similar to those of the 2AFC task, with a slight reduction across conditions as the NTC trials reduced discrimination performance (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref> vs. 1C1, 1E2 vs. 1C2). The small performance difference between the 2AFC and 3AFC tasks suggests that human subjects generally relied on speed segmentation to perform the 2AFC task. Based on the results from the 3AFC task, we performed a two-way ANOVA, with the two factors being the mean speed of the stimulus components and the speed separation (x4 or x2). We found that both factors had significant effects. <italic>d’</italic> changed significantly with the mean stimulus speed (F(4,30) = 26.8, p = 1.60×10<sup>-9</sup>) and the <italic>d’</italic> at x4 separation differed significantly from that at x2 separation (F(1,30) = 84.1, p = 3.29×10<sup>-10</sup>). <italic>d’</italic> was higher at x4 than at x2 speed separation except at the fastest speeds of 20 and 80°/s vs. 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref> vs. <xref rid="fig1" ref-type="fig">1E2</xref>). Our results also showed that segmentation was significantly worse at fast speeds – <italic>d’</italic> dropped significantly as the stimulus speeds increased from 10 and 40°/s to 20 and 80°/s for x4 separation (one-way ANOVA, F(1,6) = 38.6, p = 8.1×10<sup>-4</sup>) (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>), and from 10 and 20°/s to 20 and 40°/s for x2 separation (one-way ANOVA, F(1,6) = 32.7, p = 1.24×10<sup>-3</sup>) (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>).</p>
</sec>
<sec id="s2a2">
<title>Monkey psychophysics</title>
<p>We next measured the monkey’s ability to segment overlapping stimuli moving at two speeds. We trained one male macaque monkey to perform a 2AFC task, in which it reported whether a stimulus contained one or two speeds (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>, see Methods). The monkey’s performance at x2 speed separation (<xref rid="fig2" ref-type="fig">Fig. 2B2</xref>) was very similar in shape to that of humans (<xref rid="fig1" ref-type="fig">Fig. 1C2</xref> of the 2AFC task). In addition, the monkey’s performance was generally better at x4 separation than at x2 separation (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref> vs <xref rid="fig2" ref-type="fig">2B2</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Monkey psychophysics.</title>
<p><bold>A.</bold> The behavioral task and visual stimuli. <bold>B</bold>. Discriminability of a monkey subject performing a 2AFC task. <bold>B1</bold>. X4 speed separation. <bold>B2</bold>. X2 speed separation. Error bars and error bands represent ±STE.</p></caption>
<graphic xlink:href="532456v4_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At x4 separation, performance improved as stimulus speeds increased from 1.25 and 5°/s to 5 and 20°/s. As the stimulus speeds increased from 5 and 20°/s to 20 and 80°/s, the performance declined (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), similar to the human results (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). However, the monkey was still able to differentiate the bi-speed and single-speed stimuli at the fastest speeds of 20 and 80°/s (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), whereas the average human performance was poor (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). Note that one human subject (NP) performed better than other subjects at 20 and 80°/s (mean <italic>d’</italic> = 2.12, STE = 0.12) (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). The difference between the monkey and human results may be due to species differences or individual variability. The differences in behavioral tasks may also play a role – the monkey received feedback on the correctness of the choice, whereas human subjects did not.</p>
<p>Another notable difference between the monkey and human results was that, at low stimulus speeds of 1.25 and 5°/s, human subjects could differentiate the bi-speed stimulus from the corresponding single-speed (2.5°/s) stimulus nearly perfectly. In comparison, the ability of the monkey subject to segment 1.25 and 5 °/s was lower (<italic>d’</italic> = 2.8, STE = 0.51), although still good (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref> vs <xref rid="fig1" ref-type="fig">1C1</xref>). This may be explained by how the monkey performed the task. For human subjects, while the motion of the faster component (5°/s) of the bi-speed stimulus appeared to be salient, it required effort to notice the very slow component (1.25°/s) to be moving rather than stationary. In some trials, the monkey might be able to segment the 5°/s component from the bi-speed stimulus but consider the slower component of 1.25°/s as stationary and, therefore, reported that the stimulus contained only one speed. Despite some differences between the human and monkey results, the two general trends – better segmentation performance at larger than smaller speed separation and reduced segmentation ability at very fast speeds were consistent across species.</p>
</sec>
</sec>
<sec id="s2b">
<title>Neuronal responses in MT elicited by bi-speed stimuli and single-speed components</title>
<p>To characterize how neurons in the visual cortex encode overlapping stimuli moving at different speeds, we recorded extracellularly from 100 isolated neurons in area MT of two male macaque monkeys (60 neurons from IM and 40 neurons from MO) while they performed a fixation task. <xref rid="fig3" ref-type="fig">Figure 3</xref> shows the responses from four example neurons. To visualize the relationship between the responses to the bi-speed stimulus (red) and the constituent speed components, the plots of the response tuning curves to the slower (green) and faster (blue) components are shifted horizontally so that the responses elicited by the bi-speed stimulus and its constituent single-speed components are aligned along a vertical line as illustrated in <xref rid="fig3" ref-type="fig">Figure 3A1</xref>.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Speed tuning curves of four example neurons to bi-speed stimuli and constituent single-speed components.</title>
<p><bold>A.</bold> Illustration of the visual stimuli and the response tuning curves of an example neuron. Green and blue dots in the diagram indicate two overlapping achromatic random-dot patterns moving in the same direction at different speeds. Colors are used for illustration purposes only. The abscissas in green and blue show the speeds of the slower and faster components, respectively. The abscissa in black shows the log mean speed of the two speed components. <bold>A-D</bold>. Four example neurons are sorted by their preferred speeds (PS) from slow to fast. Error bars represent ±STE. For some data points, error bars were comparable to the symbol size. <bold>A1-D1</bold>. ×4 speed separation. <bold>A2-D2</bold>. ×2 speed separation.</p></caption>
<graphic xlink:href="532456v4_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We found that the relationship between the responses elicited by the bi-speed stimulus and the constituent components depended on the stimulus speeds. <xref rid="fig3" ref-type="fig">Figure 3A1-D1</xref> shows the neuronal responses when the speed separation was large (×4). The component speeds were the same as the bi-speed stimuli used in the psychophysics experiments. When the two component speeds were slow (1.25 and 5°/s), the response to the bi-speed stimulus nearly followed the response elicited by the faster-speed component (the leftmost data points in <xref rid="fig3" ref-type="fig">Fig. 3A1-D1</xref>). Importantly, the response elicited by the bi-speed stimuli did not simply follow the stronger component response. When the preferred speed of a neuron was sufficiently low such that the response elicited by the faster component was weaker than that elicited by the slower component, the response to the bi-speed stimulus still followed the weaker response elicited by the faster component (<xref rid="fig3" ref-type="fig">Fig. 3A1</xref>). When the speeds of the two stimulus components were at 2.5 and 10°/s, the response elicited by the bi-speed stimulus was also biased toward the faster component, albeit to a lesser degree. As the mean speed of the two stimulus components increased, the bi-speed response became closer to the average of the two component responses (<xref rid="fig3" ref-type="fig">Fig. 3A1-D1</xref>). We found similar results when the speed separation between the two components was small (×2) (<xref rid="fig3" ref-type="fig">Fig. 3A2-D2</xref>).</p>
<p>We found the same trend in the neural responses averaged across 100 neurons (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). At ×4 speed separation, the population-averaged response showed a strong bias toward the faster component when the stimulus speeds were low, and shifted toward the average of the component responses as the speeds increased (<xref rid="fig4" ref-type="fig">Fig. 4A1</xref>). To determine whether this trend held for neurons with different preferred speeds, we divided the neuron population into three groups with “low” (&lt;2.5°/s), “intermediate” (between 2.5 and 25°/s), and “high” (&gt;25°/s) preferred speeds. For 10 neurons that preferred low speeds, the response to the faster component was weaker than that to the slower component. However, the response to the bi-speed stimuli was strongly biased toward the faster component when the stimulus speeds were low (<xref rid="fig4" ref-type="fig">Fig. 4B1</xref>). This finding suggests that the bi-speed response is not biased toward the stimulus component that the neuron prefers when presented alone, but biased toward the faster speed component.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components.</title>
<p>Speed tuning curves averaged across: <bold>A</bold>. 100 neurons in our dataset. <bold>B</bold>. 10 neurons that had preferred speeds (PS) lower than 2.5°/s. <bold>C</bold>. 61 neurons that had PS between 2.5 and 25°/s. <bold>D</bold>. 29 neurons that had PS greater than 25°/s. Error bars represent ±STE. For some data points, error bars were comparable to the symbol size. <bold>A1-D1</bold>. ×4 speed separation. <bold>A2-D2</bold>. ×2 speed separation.</p></caption>
<graphic xlink:href="532456v4_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For 61 neurons that preferred intermediate speeds (<xref rid="fig4" ref-type="fig">Fig. 4C1</xref>) and 29 neurons that preferred high speeds (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>), we also found a strong bias toward the faster speed component when the stimulus speeds were low, and a gradual change toward the average of the component responses as the stimulus speeds increased. At the lowest stimulus speeds of 1.25 and 5°/s, the bi-speed response was nearly identical to that elicited by the faster component, showing “faster-component-take-all”. For neurons that preferred high speeds, faster-component-take-all was also found for the stimulus speeds of 2.5 and 10°/s (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>). At the fastest speeds of 20 and 80°/s, the response to the bi-speed stimuli showed a slight bias toward the slower component (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>). We found similar results at ×2 speed separation (<xref rid="fig4" ref-type="fig">Fig. 4A2-D2</xref>), although the effect is not as pronounced as ×4 speed separation.</p>
</sec>
<sec id="s2c">
<title>Relationship between the responses to bi-speed stimuli and constituent stimulus components</title>
<p>We aimed to quantify the relationship between the response elicited by the bi-speed stimuli and the corresponding component responses. We first assumed that the response <italic>R</italic> of a neuron elicited by two component speeds can be described as a weighted sum of the component responses <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub> elicited by the slower (<italic>v</italic><sub><italic>s</italic></sub>) and faster (<italic>v</italic><sub><italic>f</italic></sub>) component speed, respectively (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>).
<disp-formula id="eqn5">
<graphic xlink:href="532456v4_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which, <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> are the response weights for the slower and faster speed component <italic>v</italic><sub><italic>s</italic></sub> <italic>and v</italic><sub><italic>f</italic></sub>, respectively.</p>
<p>Our goal was to estimate the weights for each speed pair and determine whether the weights change with the stimulus speeds. In our main data set, the two speed components moved in the same direction. To determine the weights of <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> for each neuron at each speed pair, we have three data points <italic>R, R</italic><sub><italic>s</italic></sub>, and <italic>R</italic><sub><italic>f</italic></sub>, which are trial-averaged responses. Since it is not possible to solve for both variables, <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub>, from a single equation (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>) with three data points, we introduced an additional constraint: <italic>w</italic><sub><italic>s</italic></sub> + <italic>w</italic><sub><italic>f</italic></sub> <italic>=</italic>1. With this constraint, the weighted sum becomes a weighted average. While this constraint may not yield the exact weights that would be obtained with a fully determined system, it nevertheless allows us to characterize how the relative weights vary with stimulus speed. As long as <italic>R</italic><sub><italic>f</italic></sub> ≠ <italic>R</italic><sub><italic>s</italic></sub>, <italic>R</italic> can be expressed as:
<disp-formula id="eqn6">
<graphic xlink:href="532456v4_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The response weights are <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="532456v4_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Intuitively, if <italic>R</italic> were closer to one component response, that stimulus component would have a higher weight. Note that <xref ref-type="disp-formula" rid="eqn6">Equation 6</xref> is not intended for fitting the response <italic>R</italic> using <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub>, but rather to use the relationship among <italic>R, R</italic><sub><italic>s</italic></sub>, and <italic>R</italic><sub><italic>f</italic></sub> to determine the weights for the faster and slower components.</p>
<p>Using this approach to estimate response weights for individual neurons can be unreliable, particularly when <italic>R</italic><sub><italic>f</italic></sub> and <italic>Rs</italic> are similar. This situation often arises when the two speeds fall on opposite sides of the neuron’s preferred speed, resulting in a small denominator (<italic>R</italic><sub><italic>f</italic></sub> – <italic>Rs</italic>) and consequently an artificially inflated weight estimate. We, therefore, used the neuronal responses across the population to determine the response weights (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). For each pair of stimulus speeds, we plotted (<italic>R - R</italic><sub><italic>s</italic></sub>) in the ordinate versus (<italic>R</italic><sub><italic>f</italic></sub> - <italic>R</italic><sub><italic>s</italic></sub>) in the abscissa. <xref rid="fig5" ref-type="fig">Figure 5A1-E1</xref> shows the results obtained at ×4 speed separation. Across the neuronal population, the relationship between (<italic>R - R</italic><sub><italic>s</italic></sub>) and (<italic>R</italic><sub><italic>f</italic></sub> - <italic>R</italic><sub><italic>s</italic></sub>) can be described by a linear equation (<xref ref-type="disp-formula" rid="eqn7">Eq. 7</xref>) (see <italic>R</italic><sup><italic>2</italic></sup> in <xref rid="tbl1" ref-type="table">Table 1</xref>). This linearity suggests that the response weights for each speed pair are roughly consistent across the neuronal population.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
    <caption><title>Response weight for faster component based on linear regression (N = 100)</title>
    </caption>
<graphic xlink:href="532456v4_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Relationship between the responses to the bi-speed stimuli and the constituent stimulus components.</title>
<p><bold>A-E.</bold> Each panel shows the responses from 100 neurons. Each dot represents the responses from one neuron. <italic>R, R</italic><sub><italic>f</italic></sub>, and <italic>R</italic><sub><italic>s</italic></sub> were firing rates averaged across all recorded trials for each neuron. The ordinate shows the difference between the responses to a bi-speed stimulus and the slower component (<italic>R - R</italic><sub><italic>s</italic></sub>). The abscissa shows the difference between the responses to the faster and slower components (<italic>R</italic><sub><italic>f</italic></sub> <italic>-R</italic><sub><italic>s</italic></sub>). The regression line is shown in red. <bold>F</bold>. Response weights for the faster stimulus component obtained from the slope of the linear regression based on the recorded responses of 100 neurons (black symbols), and based on simulated responses to the bi-speed stimuli (gray symbols). Error bars represent 95% confidence intervals. <bold>A1-F1</bold>. ×4 speed separation. <bold>A2-F2</bold>. ×2 speed separation.</p></caption>
<graphic xlink:href="532456v4_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>
<disp-formula id="eqn7">
<graphic xlink:href="532456v4_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Because all the regression lines in <xref rid="fig5" ref-type="fig">Figure 5</xref> nearly go through the origin (i.e. intercept <italic>b</italic> ≈ 0, <xref rid="tbl1" ref-type="table">Table 1</xref>), the slope <italic>k</italic> obtained from the linear regression approximates <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="532456v4_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which is the response weight <italic>w</italic><sub><italic>f</italic></sub> for the faster component (<xref ref-type="disp-formula" rid="eqn6">Eq. 6</xref>). Hence, for each pair of stimulus speeds, we can estimate the response weight for the faster component using the slope of the linear regression of the responses from the neuronal population.</p>
<p>Our results showed that the bi-speed response showed a strong bias toward the faster component when the speeds were slow, and changed progressively from a scheme of “faster-component-take-all” to “response-averaging” as the speeds of the two stimulus components increased (<xref rid="fig5" ref-type="fig">Fig. 5F1</xref>). We found similar results when the speed separation between the stimulus components was small (×2), although the bias toward the faster component at low stimulus speeds was not as strong as x4 speed separation (<xref rid="fig5" ref-type="fig">Fig. 5A2-F2</xref> and <xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
<p>In the regression between (<italic>R</italic> − <italic>R</italic><sub><italic>s</italic></sub>) and (<italic>R</italic><sub><italic>f</italic></sub> – <italic>R</italic><sub><italic>s</italic></sub>), <italic>R</italic><sub><italic>s</italic></sub> (i.e., the firing rate to the slow component averaged across all trials for each neuron) was a common term and therefore could artificially introduce correlations. We wanted to determine whether our estimates of the regression slope (<italic>w</italic><sub><italic>f</italic></sub>) were confounded by this factor. We performed two additional analyses.</p>
<p>First, at each speed pair and for each of the 100 neurons in the data sample shown in <xref rid="fig5" ref-type="fig">Figure 5</xref>, we simulated the response to the bi-speed stimuli (<italic>R</italic><sub><italic>e</italic></sub>) as a randomly weighted average of <italic>R</italic><sub><italic>f</italic></sub> and <italic>R</italic><sub><italic>s</italic></sub> of the same neuron.
<disp-formula id="ueqn1">
<graphic xlink:href="532456v4_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which <italic>a</italic> was a randomly generated weight (between 0 and 1) for <italic>R</italic><sub><italic>f</italic></sub>, and the weights for <italic>R</italic><sub><italic>f</italic></sub> and <italic>R</italic><sub><italic>s</italic></sub> summed to one. We then calculated the regression slope and the correlation coefficient between the simulated <italic>R</italic><sub><italic>e</italic></sub>-<italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub>-<italic>R</italic><sub><italic>s</italic></sub> across the 100 neurons. We repeated the process 1000 times and obtained the mean and 95% confidence interval (CI) of the regression slope and the <italic>R</italic><sup><italic>2</italic></sup>. The mean slope based on the simulated responses was 0.5 across all speed pairs. The estimated slope (<italic>w</italic><sub><italic>f</italic></sub>) from the data was significantly greater than the simulated slope at slow speeds of 1.25/5, 2.5/10 (<xref rid="fig5" ref-type="fig">Fig. 5F1</xref>), and 1.25/2.5, 2.5/5, and 5/10 °/s (<xref rid="fig5" ref-type="fig">Fig. 5F2</xref>) (bootstrap test, see p-values in <xref rid="tbl1" ref-type="table">Table 1</xref>). The estimated <italic>R</italic><sup><italic>2</italic></sup> based on the data was also significantly higher than the simulated <italic>R</italic><sup><italic>2</italic></sup> for most of the speed pairs (<xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
<p>Second, we calculated <italic>R</italic><sub><italic>s</italic></sub> in the ordinate and abscissa of <xref rid="fig5" ref-type="fig">Figure 5A-E</xref> using responses averaged across different subsets of trials, such that <italic>R</italic><sub><italic>s</italic></sub> was no longer a common term in the ordinate and abscissa. For each neuron, we determined <italic>R</italic><sub><italic>sl</italic></sub> by averaging the firing rates of <italic>R</italic><sub><italic>s</italic></sub> across half of the recorded trials, selected randomly. We also determined <italic>R</italic><sub><italic>s2</italic></sub> by averaging the firing rates of <italic>R</italic><sub><italic>s</italic></sub> across the rest of the trials. We regressed (<italic>R</italic> − <italic>R</italic><sub><italic>sl</italic></sub>) on (<italic>R</italic><sub><italic>f</italic></sub> − <italic>R</italic><sub><italic>s2</italic></sub>), as well as (<italic>R</italic> − <italic>R</italic><sub><italic>s2</italic></sub>) on (<italic>R</italic><sub><italic>f</italic></sub> − <italic>R</italic><sub><italic>sl</italic></sub>), and repeated the procedure 50 times. The averaged slopes obtained with <italic>R</italic><sub><italic>s</italic></sub> from the split trials showed the same pattern as those using <italic>R</italic><sub><italic>s</italic></sub> from all trials (<xref rid="tbl1" ref-type="table">Table 1</xref> and <xref rid="figS1" ref-type="fig">Supplementary Fig. 1</xref>), although the coefficient of determination was slightly reduced (<xref rid="tbl1" ref-type="table">Table 1</xref>). For ×4 speed separation, the slopes were nearly identical to those shown in <xref rid="fig5" ref-type="fig">Figure 5F1</xref>. For ×2 speed separation, the slopes were slightly smaller than those in <xref rid="fig5" ref-type="fig">Figure 5F2</xref>, but followed the same pattern (<xref rid="figS1" ref-type="fig">Supplementary Fig. 1</xref>). Together, these analysis results confirmed the faster-speed bias at the slow stimulus speeds, and the change of the response weights as stimulus speeds increased.</p>
</sec>
<sec id="s2d">
<title>Timecourse of MT responses to bi-speed stimuli</title>
<p>The temporal dynamics of the response bias toward the faster component may provide a useful constraint on the neural model that accounts for this phenomenon. We therefore examined the timecourse of MT response to the bi-speed stimuli. We asked whether the faster-speed bias occurred early in the neuronal response or developed gradually.</p>
<p><xref rid="fig6" ref-type="fig">Figure 6</xref> shows the timecourse of the normalized responses averaged across 100 neurons in the population. The bias toward the faster speed component occurred at the very beginning of the neuronal response when the stimulus speeds were less than 20º/s (<xref rid="fig6" ref-type="fig">Fig. 6A-C</xref>). The first 20-30 ms of the neuronal response elicited by the bi-speed stimulus was nearly identical to the response elicited by the faster component alone, as if the slower component were not present. The early dominance of the faster component on the bi-speed response cannot be explained by the difference in the response latencies of the faster and slower components. Faster stimuli elicit a shorter response latency (<xref ref-type="bibr" rid="c40">Lisberger and Movshon, 1999</xref>), which can be seen in <xref rid="fig6" ref-type="fig">Figure 6A-C</xref>. However, the bi-speed response still closely followed the faster component for some time after the response to the slower component began to rise. The effect of the slower component on the bi-speed response was delayed for about 25 ms, as indicated by the arrows in <xref rid="fig6" ref-type="fig">Figure 6A-C</xref>. During the rest of the response period, the bias toward the faster component was persistent. As the stimulus speeds increased, the bi-speed response gradually changed to follow the average of the component responses (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>). We found similar results when the speed separation between the two stimulus components was ×4 (<xref rid="fig6" ref-type="fig">Fig. 6A1-E1</xref>) and ×2 (<xref rid="fig6" ref-type="fig">Fig. 6A2-E2</xref>). At slow speeds, the very early faster-speed bias suggests a likely role of feedforward inputs to MT in the faster-speed bias. The slightly delayed reduction (normalization) in the bi-speed response relative to the stronger component response also helps constrain the circuit model for divisive normalization.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Timecourse of MT responses averaged across neurons to bi-speed stimuli.</title>
<p>Peristimulus time histograms (PSTHs) were averaged across 100 neurons. The bin width of PSTH was 10 ms. <bold>A1-E1</bold>. ×4 speed separation. <bold>A2-E2</bold>. ×2 speed separation. In A-C, the left dashed line indicates the latency of the response to a bi-speed stimulus, and the right dashed line and the arrow indicate when the response to a bi-speed stimulus started to diverge from the response to the faster component.</p></caption>
<graphic xlink:href="532456v4_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2e">
<title>Faster-speed bias still present when attention was directed away from the RFs</title>
<p>One possible explanation for the faster-speed bias is that bottom-up attention is drawn toward the faster stimulus component, enhancing the response to it. To address this question, we asked whether the faster-speed bias was still present if attention was directed away from the RFs. We trained one monkey (RG) to perform a demanding direction-discrimination task in the visual hemifield opposite to the RFs. The monkey performed the task well with an average correct rate of 86.7 ± 7.3% (mean ± std) (see Methods and Supplementary Material <xref rid="fig2" ref-type="fig">Fig. 2</xref>).</p>
<p>We recorded the responses from an additional 48 MT neurons in 23 experimental sessions while the monkey performed the task. Thirty-two out of the 48 neurons were recorded using both the attention-away paradigm and a fixation paradigm. The results obtained using the attention-away paradigm and the fixation paradigm were similar (<xref rid="figS2" ref-type="fig">Supplementary Fig. 2</xref>). The faster-speed bias was more evident at ×4 speed separation than at ×2 speed separation. Based on the neuronal responses across the population, we calculated the weight for the faster stimulus component at each of the five speed pairs using linear regression (<xref ref-type="disp-formula" rid="eqn6">Eqs. 6</xref>, <xref ref-type="disp-formula" rid="eqn7">7</xref>), as we did in <xref rid="fig5" ref-type="fig">Figure 5</xref>. When attention was directed away from the RFs, the response weight for the faster component decreased from a strong faster-speed bias to response averaging as the stimulus speeds increased, similar to the results from the fixation paradigm (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). These results suggest that the faster-speed bias at low speeds cannot be explained by attention drawn to the faster-speed component.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Comparison of response weights between attention-away and fixation paradigms.</title>
<p>The red and blue curves indicate the response weights for the faster speed component in an attention-away paradigm and a fixation paradigm, respectively, obtained from the same population of 32 neurons. The black curves are the replot of the data in Figure 5F, obtained from 100 neurons in a fixation paradigm. <bold>A</bold>. ×4 speed separation. <bold>B</bold>. ×2 speed separation.</p></caption>
<graphic xlink:href="532456v4_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2f">
<title>Faster speed bias also occurs when stimulus components move in different directions</title>
<p>We showed that at low speeds, MT response to the bi-speed stimulus was biased toward the faster stimulus component when two overlapping components moved in the same direction (at the preferred direction of the neuron). We asked whether this faster-speed bias also occurred when visual stimuli moved in different directions. We presented overlapping random-dot stimuli within the RF, moving in two directions separated by 90°. The two stimulus components moved at speeds of 2.5 and 10°/s. The faster speed component moved on the clockwise side of the two directions. We varied the vector-average (VA) direction of the two component directions across 360° to characterize the direction tuning curves. Each neuron’s direction tuning curve was fitted with a spline and circularly shifted such that the VA direction 0° was aligned with the neuron’s preferred direction before averaging across neurons.</p>
<p><xref rid="fig8" ref-type="fig">Figure 8A</xref> shows the results averaged across 21 neurons (13 from monkey RG, 8 from monkey GE). The peak response to the faster component (<xref rid="fig8" ref-type="fig">Fig. 8A</xref>, blue curve) was stronger than that to the slower component (green curve), consistent with the overall speed preference of a large MT neuron population (<xref ref-type="bibr" rid="c52">Nover et al., 2005</xref>). MT responses elicited by the bi-directional stimuli (red curve) showed a strong bias toward the faster component, more than expected by the average of the two component responses (gray curve). The bi-speed response was biased toward the faster component regardless of whether the response to the faster component was stronger (in positive VA directions) or weaker (in negative VA directions) than that to the slower component (<xref rid="fig8" ref-type="fig">Fig. 8A</xref>). The result from an example neuron further demonstrated that, even when the peak firing rates of the faster and slower component responses were similar, the response elicited by the bi-speed stimuli was still biased toward the faster component (<xref rid="fig8" ref-type="fig">Fig. 8B</xref>). These results suggest that the bias was not toward the stronger component response of the individual neuron, but to the faster component.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>MT responses to bi-speed stimuli moving in different directions and the linear weighted sum (LWS) and normalization model fits.</title>
<p><bold>A.</bold> Population-averaged direction tuning curves of 21 neurons in response to stimuli moving at two speeds and in two directions separated by 90° (red). The component direction Dir. 1 (blue) moved at 10°/s, and the component direction Dir. 2 (green) moved at 2.5°/s. The faster component Dir. 1 was always on the clockwise side of Dir. 2. The abscissas in blue and green show the directions of stimulus components Dir. 1 and Dir. 2, respectively. The blue and green axes are shifted by 90° relative to each other. The abscissa in black shows the corresponding VA direction of the two direction components. Error bands represent ±STE. The gray curve represents the average of the component responses. The orange and black curves are the LWS and normalization model fits, respectively, of the population-averaged direction-tuning curve to the bi-speed stimuli. <bold>B</bold>. The direction-tuning curves of an example neuron show similar peak responses to the slower and faster components. The orange and black curves are the LWS and normalization model fits of the bi-speed responses and are nearly identical. The weights of <italic>w</italic><sub><italic>f</italic></sub>, <italic>w</italic><sub><italic>s</italic></sub> are from the normalization model fit. <bold>C</bold>. Response weights for the stimulus components obtained using the LWS model fit. Each circle represents one neuron. <bold>D</bold>. Response weights obtained using the normalization model fit. The dashed lines in C, D indicate where <italic>w</italic><sub><italic>s</italic></sub> <italic>and w</italic><sub><italic>f</italic></sub> sum to one. Although <italic>w</italic><sub><italic>s</italic></sub> <italic>and w</italic><sub><italic>f</italic></sub> are not constrained to sum to one in the model fits, the fitted weights are roughly aligned with the dashed lines. <bold>E</bold>. Population-averaged speed tuning curves of MT neurons recorded in our data sample in response to single speeds. The red circles indicate responses to 2.5 and 10º/s. Error bars represent ±STE.</p></caption>
<graphic xlink:href="532456v4_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To quantify the response weights, for each neuron, we fitted the MT raw firing rates of the direction tuning curve to bi-speed/bi-directional stimuli as a linear weighted sum (LWS) of the direction tuning curves to the individual stimulus components moving at different speeds:
<disp-formula id="eqn8">
<graphic xlink:href="532456v4_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<italic>R</italic><sub><italic>bi</italic></sub> is the model-fitted direction-tuning curves to the bi-speed and bi-direction stimuli. <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub> are the measured direction tuning curves to the slower and faster stimulus components, respectively. <italic>θ</italic><sub><italic>l</italic></sub> <italic>and θ</italic><sub><italic>2</italic></sub> are the motion directions of the two components; <italic>w</italic><sub><italic>s</italic></sub>, <italic>w</italic><sub><italic>f</italic></sub>, and <italic>c</italic> are model parameters, which represent the response weights for the slower and faster components and an offset constant, respectively. <italic>c</italic> was constrained to be between 0 and 100 spikes/s. Because the model can be well constrained by the measured direction-tuning curves, it is not necessary to require <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> to sum to one, which is more general. An implicit assumption of the model is that, at a given pair of stimulus speeds, the response weights for the slower and faster components are fixed across motion directions. The model fitted MT responses very well, accounting for an average of 91.8% of the response variance (std = 7.2%, N = 21) (see Methods), which supports the assumption that the response weights are fixed across motion directions. The median response weights for the faster and slower components were 0.74 and 0.26, respectively, and were significantly different (Wilcoxon signed-rank test, p = 8.0 ×10<sup>-5</sup>). For most neurons (20 out of 21), the response weight for the faster component was larger than that for the slower component (<xref rid="fig8" ref-type="fig">Fig. 8C</xref>). This result suggests that at low speeds, the faster-speed bias is a general phenomenon that applies to overlapping stimuli moving either in the same direction or different directions.</p>
</sec>
<sec id="s2g">
<title>Normalization model fit of the direction-tuning curves to bi-speed stimuli</title>
<p>We showed that the neuronal response in MT to a bi-speed stimulus can be described by a weighted sum of the neuron’s responses to the individual speed components. However, what determines the response weights? The divisive normalization model (<xref ref-type="bibr" rid="c19">Carandini and Heeger, 2012</xref>) has been used to explain a wide array of phenomena, including neuronal responses elicited by multiple visual stimuli (e.g. <xref ref-type="bibr" rid="c16">Britten and Heuer 1999</xref>; <xref ref-type="bibr" rid="c28">Heuer and Britten 2002</xref>; <xref ref-type="bibr" rid="c18">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="c82">Xiao et al. 2014</xref>; <xref ref-type="bibr" rid="c81">Xiao and Huang, 2015</xref>; <xref ref-type="bibr" rid="c7">Bao and Tsao 2018</xref>). In the normalization model, while the division by the activity of a population of neurons in the denominator (the normalization pool) is well accepted, the nature of the numerator is less understood. We have previously proposed that the weight of a stimulus component is proportional to the activity of a population of neurons elicited by the stimulus component (<xref ref-type="bibr" rid="c82">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c80">Wiesner et al., 2020</xref>). We refer to this neuronal population as the “weighting pool”. Here, we assumed that the weighting pool was composed of neurons with a broad range of speed preferences in response to multiple speed components. So, the summed response of the weighting pool reflects the speed preference of the neuronal population rather than the speed preference of individual neurons. We used the following equation (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>) to fit the direction-tuning curves of each neuron in response to two speed components moving in different directions:
<disp-formula id="eqn9">
<graphic xlink:href="532456v4_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<italic>R</italic><sub><italic>bi</italic></sub>, <italic>R</italic><sub><italic>s</italic></sub>, <italic>R</italic><sub><italic>f</italic></sub>, <italic>θ</italic><sub><italic>l</italic></sub>, <italic>and θ</italic><sub><italic>2</italic></sub> are the same as in <xref ref-type="disp-formula" rid="eqn8">Equation 8</xref>. <italic>S</italic><sub><italic>s</italic></sub> and <italic>S</italic><sub><italic>f</italic></sub> are the population neural responses of the weighting pools to the slower and faster component speeds, respectively. <italic>n, σ</italic>, α, and <italic>c</italic> are model parameters and have the following constraints: 0.01 ≤ n ≤ 100, 0 ≤ σ ≤ 500, 0.01 ≤ α ≤ 100, 0 ≤ c ≤ 100. α is a parameter that controls for the tuned normalization (<xref ref-type="bibr" rid="c51">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="c68">Rust et al., 2006</xref>; <xref ref-type="bibr" rid="c20">Carandini et al., 1997</xref>). We approximated <italic>S</italic><sub><italic>s</italic></sub> and <italic>S</italic><sub><italic>f</italic></sub> based on the population-averaged responses of our recorded MT neurons (N = 100) in response to single speeds moving in the preferred direction of each neuron (<xref rid="fig8" ref-type="fig">Fig. 8E</xref>). For the speeds of 2.5 and 10°/s, <italic>S</italic><sub><italic>s</italic></sub> = 36.7 and <italic>S</italic><sub><italic>f</italic></sub> = 62.5 spikes/s (red circles in <xref rid="fig8" ref-type="fig">Fig. 8E</xref>). The normalization model fitted the data well, accounting for an average of 90.5% of the response variance (std = 7.1%, N = 21), slightly smaller but comparable to the fit by the LWS model. The median response weights obtained from the normalization model for the faster and slower components were 0.78 and 0.15, respectively, and were significantly different (Wilcoxon signed-rank test, p = 6.0 ×10<sup>-5</sup>) (<xref rid="fig8" ref-type="fig">Fig. 8D</xref>). The median values of the fitted parameters across 21 neurons are n = 4.13, σ = 123, α = 1.57, c = 0.03.</p>
<p>So far, we have described the neural encoding of multiple speeds in area MT. We will next examine the decoding of speed(s) from population neural responses in MT and compare the performance of decoding with perceptual performance.</p>
</sec>
<sec id="s2h">
<title>Discriminate bi-speed and single-speed stimuli based on neuronal responses in area MT</title>
<p>We asked whether the responses of MT neurons contained information about bi-speed and single-speed stimuli suitable for supporting the perceptual discrimination of these stimuli. To address this question, we first examined the responses elicited by the bi-speed and single-speed stimuli from a population of MT neurons with different preferred speeds. Next, we used a classifier to discriminate the bi-speed stimuli from the single, log-mean speed stimuli based on MT responses.</p>
<p>In different experimental sessions, we centered visual stimuli on neurons’ RFs. The visual stimuli were identical across experimental sessions except for the spatial location of the RF. This allowed us to pool the trial-averaged responses recorded from different neurons to form a pseudo-population (see Methods). One can interpret the responses as from a population of neurons elicited by the same visual stimulus. <xref rid="fig9" ref-type="fig">Figure 9</xref> shows the pseudo-population neural response (referred to in brief as the population response) plotted as a function of neurons’ preferred speed, constructed from 100 neurons that we recorded using a fixation paradigm (see Methods). To capture the population response evenly across a full range of preferred speeds, we spline-fitted the recorded response elicited by the bi-speed stimulus (the red curves) and by the single, log-mean speed (the black curves) (<xref rid="fig9" ref-type="fig">Fig. 9A-E</xref>). At ×4 and ×2 speed separations, the population responses elicited by two speeds did not show two separate peaks. Instead, they had a single hump that shifted from low to high preferred speed as the stimulus speeds increased. At ×4 speed separation across all five speed pairs, the population response elicited by two speeds was broader and flatter than that elicited by the single log-mean speed (<xref rid="fig9" ref-type="fig">Fig. 9A1-E1</xref>).</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><title>Population neural responses elicited by the bi-speed and single-speed stimuli and the performance of a linear classifier.</title>
<p>A population response of 100 recorded neurons was reconstructed by pooling across recordings in different experimental sessions. Each neuron’s response was averaged across experimental trials and normalized by the maximum response of the spline-fitted speed tuning curve to single speeds. Each dot represents the response from one neuron plotted as the neuron’s PS in the natural logarithm scale. The curves represent the spline-fitted population neural responses. Red: response to the bi-speed stimulus; Black: the response to the corresponding single, log-mean speed. <bold>A1-F1</bold>. ×4 speed separation. The speeds of the bi-speed stimuli are 1.25 and 5°/s (A1), 2.5 and 10°/s (B1), 5 and 20°/s (C1), 10 and 40°/s (D1), 20 and 80°/s (E1). <bold>A2-F2</bold>. ×2 speed separation. The speeds of the bi-speed stimuli are 1.25 and 2.5°/s (A2), 2.5 and 5°/s (B2), 5 and 10°/s (C2), 10 and 20°/s (D2), 20 and 40°/s (E2). Two red dots on the X-axis indicate two component speeds; the black dot indicates the log-mean speed. <bold>F1, F2</bold>. Performance of a linear classifier to discriminate the population neural responses to the bi-speed stimulus and the corresponding single log-mean speed. Error bars represent STE.</p></caption>
<graphic xlink:href="532456v4_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In our experiments, we directly measured the neuronal responses elicited by the log-mean speed of ×4 but not ×2 speed separation. Because we had characterized each neuron’s tuning curve to single speeds, we could infer the responses elicited by the log-mean speed of ×2 separation by interpolating the speed tuning curve using a spline fit. At ×2 speed separation, the population response elicited by two speeds was similar to that elicited by the single log-mean speed, with the two-speed population response slightly broader (<xref rid="fig9" ref-type="fig">Fig. 9A2-E2</xref>).</p>
<p>We used a linear classifier to perform a discrimination task to evaluate the discriminability between MT population responses elicited by the bi-speed stimulus and the corresponding log-mean speed. Trial-by-trial population responses were generated randomly according to a Poisson process, and the mean response of each neuron was set to the trial-averaged neuronal response. The classifier was trained and tested using k-fold cross-validation. The classifier determined whether a population response from the recorded 100 neurons in our data set was elicited by two speeds or a single speed (see Methods). Discriminability of the classifier was measured in <italic>d’</italic> as in our psychophysics study.</p>
<p>Consistent with perceptual discrimination (<xref rid="fig1" ref-type="fig">Figs. 1E</xref>, <xref ref-type="fig" rid="fig2">2B</xref>), the classifier’s performance at ×4 speed separation (<xref rid="fig9" ref-type="fig">Fig. 9F1</xref>) was better than that at ×2 speed separation (<xref rid="fig9" ref-type="fig">Fig. 9F2</xref>). This provides a neural correlate with better perceptual speed segmentation at larger speed separation. At ×4 speed separation, the discriminability of the classifier was slightly decreased as the stimulus speed increased (<xref rid="fig9" ref-type="fig">Fig. 9F1</xref>), which was generally consistent with the human psychophysics results (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>). However, one difference was that at 20 and 80°/s, the classifier’s performance did not drop to a low level as human performance (compare <xref rid="fig9" ref-type="fig">Fig. 9F1</xref> with <xref rid="fig1" ref-type="fig">Fig. 1E1</xref>), but was more comparable to that of the monkey subject (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>). At ×2 speed separation, the classifier’s performance (<xref rid="fig9" ref-type="fig">Fig. 9F2</xref>) had a similar shape as that of the human (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>) and monkey (<xref rid="fig2" ref-type="fig">Fig. 2B2</xref>) subjects, but the performance was not as good as the perceptual performance at intermediate speeds.</p>
<p>When the stimulus speeds were 20 and 80°/s, the population responses elicited by the bi-speed stimulus and the single log-mean speed stimulus were noticeably different (<xref rid="fig9" ref-type="fig">Fig. 9E1</xref>), which explains the good performance of the classifier in differentiating the two stimuli. However, the differences in population neural responses may contribute to perceptual differences in quality other than motion speeds, and the monkey subject might be able to detect these perceptual cues at high speeds to aid task performance. To directly evaluate whether the population neural responses elicited by the bi-speed stimulus carry information about two speeds, it is important to conduct a decoding analysis to extract speed(s) from MT population responses.</p>
</sec>
<sec id="s2i">
<title>Decoding either a single speed or two speeds from trial-averaged population neural response</title>
<p>Since the population responses elicited by the ×4 and ×2 speed separations only had a single peak centered between the two component speeds (<xref rid="fig9" ref-type="fig">Fig. 9A-E</xref>), this raised the question of how neuronal populations represent multiple speeds of the motion components. To address this question, we used a decoding approach motivated by the theoretical framework of coding multiplicity and probability distribution of visual features in neuronal populations proposed by Zemel et al. (<xref ref-type="bibr" rid="c84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c59">Pouget et al., 2003</xref>; also see <xref ref-type="bibr" rid="c75">Treue et al., 2000</xref>). Our decoder extracted speeds that minimized the difference (sum squared error) between the estimated population response elicited by the extracted speeds, and the reconstructed population neural response based on the neural recording (<xref ref-type="disp-formula" rid="eqn10">Eqs. 10</xref>-<xref ref-type="disp-formula" rid="eqn13">13</xref>, see Methods). Rather than searching for a probability distribution of speed, we constrained the search to either a single speed or two speeds. We also constrained the weights for the extracted speeds to sum to one, consistent with a probability distribution.</p>
<p>Our approach is akin to the forward encoding model for decoding that is often used in brain imaging studies (e.g., <xref ref-type="bibr" rid="c35">Kay et al., 2008</xref>; <xref ref-type="bibr" rid="c17">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="c50">Naselaris et al., 2011</xref>; <xref ref-type="bibr" rid="c78">Vintch and Gardner, 2014</xref>; van <xref ref-type="bibr" rid="c9">Bergen et al., 2015</xref>). We applied an encoding rule and found that the visual stimuli generating a population response best matched the recorded neural response. Our assumed encoding rule in the decoder is that a neuron’s response to multiple speeds is the linear sum of the neuron’s responses to individual speed components presented alone, based on the neuron’s speed tuning curve and weighted by the strength (or probability) of each speed component. The decision to use this encoding model for decoding, rather than the encoding rule characterized in this study, was made primarily for practical reasons. Our experimental data only covered two speed separations (×4 and ×2) and 5 log mean speeds. We do not yet know a general encoding rule for two speeds across all different speed separations and log mean speeds. However, if the linear encoding of the two speeds, as characterized in this study, generalizes across a broader range of speed combinations – such that only the weights of the speed components vary within the general encoding rule – then our choice of encoding model for decoding would not alter the decoded speeds themselves, but would merely affect the estimated weights associated with those speeds (<xref ref-type="disp-formula" rid="eqn10">Eq. 10</xref>).</p>
<p><xref rid="fig10" ref-type="fig">Figure 10</xref> shows the decoding procedure and the results of extracting speed(s) from the population neural responses reconstructed based on the trial-averaged responses of the recorded neurons to the bi-speed stimuli. To capture the population neural response across a full range of preferred speeds, we spline-fitted the recorded (red dots) and estimated (blue dots) population responses. The estimated population responses (<xref rid="fig10" ref-type="fig">Fig. 10</xref>, blue curves) matched the recorded neural responses well (<xref rid="fig10" ref-type="fig">Fig. 10</xref>, red curves) (for five speed pairs, R<sup>2</sup> &gt; 0.96 at ×4 speed separation; R<sup>2</sup> &gt; 0.99 at ×2 speed separation). At ×4 speed separation, the decoder extracted two speeds for all speed combinations (<xref rid="fig10" ref-type="fig">Fig. 10A-E</xref>). The readout speeds were generally close to the veridical stimulus speeds. At low stimulus speeds of 1.25 and 5°/s (<xref rid="fig10" ref-type="fig">Fig. 10A</xref>) and 2.5 and 10°/s (<xref rid="fig10" ref-type="fig">Fig. 10B</xref>), the decoded faster speed component had a higher weight than the slower component. At the highest speeds of 20 and 80°/s, the decoder extracted two speeds (<xref rid="fig10" ref-type="fig">Fig. 10E</xref>), whereas human subjects could not perceive two speeds (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>) (see <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref>). At ×2 speed separation, the decoder extracted two speeds only at low stimulus speeds of 1.25 and 2.5°/s (<xref rid="fig10" ref-type="fig">Fig. 10F</xref>). At higher stimulus speeds, the decoder extracted a dominant speed that was between the two component speeds, with or without a second nearby speed that had a very low weight (<xref rid="fig10" ref-type="fig">Fig. 10G-J</xref>). In contrast, human subjects could perceive two speeds when stimulus speeds were below 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>) (see below and Discussion).</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10.</label>
    <caption><title>Illustration of the decoding procedure and extraction of speed(s) from population responses reconstructed based on the trial-averaged neuronal responses to the bi-speed stimuli.</title>
    <p>A-E. ×4 speed separation. F-J. ×2 speed separation. The neural population contains 100 recorded neurons, as shown in Figure 9. Each red dot represents the trial-averaged response from one neuron plotted versus the PS of the neuron in the natural logarithm scale. The red curve represents the spline-fitted population neural response. The decoder found either one speed or two speeds with different weights (vertical green bars on the X-axis), giving rise to the estimated and spline-fitted population response (blue curve) that best fitted the recorded and spline-fitted population neural response (red curve). Each blue dot represents the estimated response from one neuron, and the blue curve represents the spline-fitted estimated population response. Two red dots on the X-axis indicate the stimulus speeds. The Y-axis on the right side shows the weight of the readout speed (A, F).</p></caption>
<graphic xlink:href="532456v4_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2j">
<title>Decoding speeds from trial-by-trial population neural responses</title>
<p>To determine the distribution of the readout speed across trials, we randomly generated 200 trials based on the trial-averaged responses of 100 recorded neurons in our data sample. In each simulated trial, a given neuron’s response was determined by a Poisson process, with the mean set to the spike count averaged across the recorded trials. The trial-by-trial response of each neuron was normalized to construct the population response and then spline-fitted for decoding. The speeds extracted from the recorded neural responses to single stimulus speeds (<xref ref-type="fig" rid="figS3">Suppl. Fig. 3A-G</xref>) and from the inferred responses to the log-mean speed of ×2 speed separation (<xref ref-type="fig" rid="figS3">Suppl. Fig. 3H-L</xref>) generally matched the single stimulus speed well (<xref ref-type="fig" rid="figS3">Suppl. Fig. 3M</xref>).</p>
<p><xref rid="fig11" ref-type="fig">Figure 11</xref> shows the speeds extracted from the neural response to the bi-speed stimuli. The decoder often extracted two speeds across trials. In some trials, the readout of one speed component had a minimal weight. We considered a trial having a “single” readout speed if the weight difference between the two readout speeds was greater than 0.7 (i.e., the weaker weight &lt; 0.15). This usually happened when the readout speed having a minimal weight was either at one of the boundaries of the speed range (i.e., 1.25°/s or 80°/s) or separated from the other readout speed by a large speed separation (×27.86, which was the largest speed separation searched by the algorithm) (see Methods). These small weights were likely artifacts due to the boundaries of the stimulus speeds used in our experiments or the range of speed separation searched by the decoder.</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11.</label>
<caption><title>Trial-by-trial readout speeds decoded from population neural responses to the bi-speed stimuli.</title>
    <p>The neural population contains 100 recorded neurons, and the trial-by-trial responses are randomly generated based on a Poisson process. The convention is the same as in <xref ref-type="fig" rid="fig10">Figure 10</xref>. <bold>A-E.</bold> Speeds decoded from population responses to ×4 speed separation. The vertical red lines indicate two component speeds, which are 1.25 and 5°/s (A), 2.5 and 10°/s (B), 5 and 20°/s (C), 10 and 40°/s (D), 20 and 80°/s (E). <bold>F-J.</bold> Speeds decoded from population responses to ×2 speed separation. The red vertical line indicates two component speeds, and the black vertical line indicates the log mean speed. The component speeds are 1.25 and 2.5°/s (F), 2.5 and 5°/s (G), 5 and 10°/s (H), 10 and 20°/s (I), 20 and 40°/s (J).</p></caption>
<graphic xlink:href="532456v4_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At ×4 speed separation, the decoder was able to extract the speeds of the stimulus components (<xref rid="fig11" ref-type="fig">Fig. 11A-D</xref>), except at the fastest speeds of 20 and 80°/s. At low stimulus speeds of 1.25 and 5°/s, and 2.5 and 10°/s, the readout speed around the faster stimulus component usually had a higher weight than that around the slower stimulus component (<xref rid="fig11" ref-type="fig">Fig. 11A, B</xref>). At stimulus speeds of 1.25 and 5°/s, in trials with two readout speeds (<xref rid="fig11" ref-type="fig">Fig. 11A</xref>, on the white background), the faster readout speeds were close to the faster stimulus speed of 5°/s. The slower readout speeds were closely aligned with the slower stimulus speed of 1.25°/s, which was also the lower boundary of the speed range. In trials considered to have a single readout speed, the readout was very close to the faster stimulus speed of 5°/s (<xref rid="fig11" ref-type="fig">Fig. 11A</xref>, on the grey background). For some of these trials (at the top of <xref rid="fig11" ref-type="fig">Fig. 11A</xref>), the faster readout speed was near the upper-speed boundary of 80°/s and had a minimal weight (&lt; 0.15). Those faster readout speeds were considered boundary artifacts.</p>
<p>At stimulus speeds of 2.5 and 10°/s, the decoder extracted two speeds that had a separation close to the veridical separation (<xref rid="fig11" ref-type="fig">Figs. 11B</xref>, <xref ref-type="fig" rid="fig12">12B</xref>). In trials considered to have a single-speed readout, the readout speed was close to the faster stimulus speed of 10°/s. In some single- and two-readout speed trials, the slower readout speeds aligned with the 1.25°/s boundary and had a small weight, suggesting they were boundary artifacts.</p>
<p>At stimulus speeds of 5 and 20°/s, nearly all trials had two readout speeds with a separation well aligned with the veridical speed separation (<xref rid="fig11" ref-type="fig">Figs. 11C</xref>, <xref ref-type="fig" rid="fig12">12C</xref>). At stimulus speeds of 10 and 40°/s, the decoder was able to extract two speeds for most of the trials (<xref rid="fig11" ref-type="fig">Fig. 11D</xref>). A small percentage of the trials (∼10%) were considered to have a single readout speed, which was close to the log mean speed of the two stimulus speeds (20°/s) (blue dots at the top of <xref rid="fig11" ref-type="fig">Fig. 11D</xref> on the grey background).</p>
    <p>At the fastest stimulus speeds of 20 and 80°/s, about 40% of the total trials were considered to have only a single readout speed, which was near the log mean speed of the stimulus components (40°/s) (<xref rid="fig11" ref-type="fig">Fig. 11E</xref>). In other trials, the decoder extracted two speeds – the slower readout speeds were generally higher than the slower stimulus speed (20°/s), and the faster readout speeds aligned with the faster stimulus speed (80°/s), which was also the upper boundary speed. However, an examination of the objective function as the decoder searched for the best-fit population response across speed separations revealed that the trial-averaged objective function was flat within a big range of speed separations (<xref rid="figS4" ref-type="fig">Suppl. Fig. 4A</xref>). Further analysis showed that the decoder was uncertain about how many speeds were in the visual stimuli and therefore had difficulty segmenting the visual stimuli at these fast stimulus speeds of 20 and 80°/s (<xref ref-type="fig" rid="figS4">Suppl. Fig. 4</xref>).</p>
<p>At ×2 speed separation, the decoder was not able to extract two speeds of the stimulus components, except at the slowest speeds of 1.25 and 2.5°/s (<xref rid="fig11" ref-type="fig">Fig. 11F-J</xref>). At stimulus speeds of 1.25 and 2.5°/s (<xref rid="fig11" ref-type="fig">Fig. 11F</xref>), in 38% of total trials considered to have a single readout speed, the readout speed was close to the faster stimulus speed of 2.5°/s (mean = 1.97°/s, STD = 1.08). In trials that had two readout speeds, the slower readout speeds roughly followed the slower stimulus speed (1.25°/s), which was also the lower boundary of the speed range (<xref rid="fig11" ref-type="fig">Fig. 11F</xref>). At stimulus speeds higher than 1.25 and 2.5°/s, most trials were considered to have a single readout speed (<xref rid="fig11" ref-type="fig">Fig. 11G-J</xref>). The mean speeds of the single readout-speed trials were 3.9°/s (STD = 1.07), 7.3°/s (STD = 1.99), 13.5°/s (STD = 1.06), and 31°/s (STD = 1.07), respectively, for stimulus speeds of 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s. These mean readout speeds were close to the log mean speeds of the two stimulus speeds (3.54°/s, 7.07°/s, 14.14°/s, and 28.28°/s, respectively).</p>
</sec>
<sec id="s2k">
<title>Discrimination between single- and bi-speed stimuli based on decoded speeds</title>
<p>To compare the perceptual discrimination between bi-speed stimuli and the log-mean speed, we used the decoding results to perform a discrimination task similar to that used in our psychophysical experiments. <xref rid="fig12" ref-type="fig">Figure 12</xref> shows the distributions of the speed separation between two readout speeds extracted from the reconstructed population neural responses to the bi-speed stimuli, and the corresponding single log-mean speed. As stated above, when the difference between the weights of two readout speeds in a trial was greater than 0.7, the trial was considered to have a single readout speed, and the speed separation was set to zero.</p>
<fig id="fig12" position="float" fig-type="figure">
<label>Figure 12.</label>
<caption><title>Discrimination between single- and bi-speed stimuli based on decoded speeds.</title>
<p><bold>A-J.</bold> The distributions of the speed separation between two readout speeds in each trial in response to either the bi-speed stimuli (yellow) or the corresponding single, log-mean speed (blue). The abscissa is shown on a natural logarithm scale. The bin width is 0.05. The red dotted line indicates veridical speed separation. <bold>A-E.</bold> ×4 speed separation. The speeds of the bi-speed stimuli are 1.25 and 5°/s (A), 2.5 and 10°/s (B), 5 and 20°/s (C), 10 and 40°/s (D), 20 and 80°/s (E). <bold>F-J.</bold> ×2 speed separation. The speeds of the bi-speed stimuli are 1.25 and 2.5°/s (F), 2.5 and 5°/s (G), 5 and 10°/s (H), 10 and 20°/s (I), 20 and 40°/s (J). <bold>K-L</bold>. The performance of discriminating a bi-speed stimulus from the corresponding log-mean speed is based on the speed separation of the decoded speeds. <bold>K</bold>. ×4 speed separation; <bold>L</bold>. ×2 speed separation. The black triangles in A-J indicate the speed separation threshold of x1.3 (0.26 on the log scale) used for discriminating bi-speed and single-speed stimuli.</p></caption>
<graphic xlink:href="532456v4_fig12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At ×4 speed separation, the separations between the readout speeds extracted from the response to the bi-speed stimuli generally matched the veridical speed separation. They were larger than those extracted from the response to single log-mean speed (<xref rid="fig12" ref-type="fig">Fig. 12A-E</xref>). Based on the distributions of the decoded speeds, we used a speed separation threshold of x1.3 (i.e., 0.26 on the log scale, marked by a black triangle in <xref rid="fig12" ref-type="fig">Fig. 12</xref>) to distinguish single- and bi-peed stimuli and to evaluate the hit rate and false alarm rate. The choice of the threshold within a range from x1.1 to x1.7 did not change the results qualitatively. We calculated <italic>d’</italic> to measure the ability to discriminate the bi-speed stimuli from the corresponding single log-mean speed. The <italic>d’</italic> (<xref rid="fig12" ref-type="fig">Fig. 12K</xref>) was similar to the psychophysical performance of the monkey subject (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), reaching its peak at 5 and 20°/s. Although <italic>d’s</italic> at stimulus speeds of 1.25 and 5°/s and 2.5 and 10°/s were smaller than those of human subjects (<xref rid="fig1" ref-type="fig">Fig. 1C1, E1</xref>), the fact that in many trials, the readout speeds matched the faster stimulus speeds (<xref rid="fig11" ref-type="fig">Fig. 11A, B</xref>) indicated that the decoder was able to segment the visual stimuli when stimulus speeds were low.</p>
<p>At ×2 speed separation, except at 1.25 and 2.5°/s, the distribution of the speed separation extracted from the response to the bi-speed stimuli was similar to that extracted from the inferred response to single log-mean speed (see Methods) (i.e., orange and blue bars overlapping) (<xref rid="fig12" ref-type="fig">Fig. 12F-J</xref>). The <italic>d’</italic> calculated based on the decoded speed separation (<xref rid="fig12" ref-type="fig">Fig. 12L</xref>) was smaller than the psychophysical performance of human and monkey subjects (<xref rid="fig1" ref-type="fig">Fig. 1C2, E2</xref>; Fig. B2), suggesting that the decoder was not able to segment the visual stimuli at ×2 speed separation, with a potential exception at the lowest speeds of 1.5 and 2.5°/s.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>Perceptual segmentation of multiple motion speeds</title>
<p>Our human psychophysical study employed a novel 3AFC task. The task combined an identification task (to report whether a stimulus had one or two speeds) with a discrimination task (to compare a two-speed stimulus with a single-speed stimulus) (<xref rid="fig1" ref-type="fig">Fig. 1A, E1, E2</xref>). This approach allowed us to characterize discriminability based on perceptual segmentation, rather than other perceptual appearances of the stimuli. We made two findings. First and intuitively, the performance of speed segmentation was better when the separation between two stimulus speeds was larger. Second, at a fixed speed separation, speed segmentation became harder at fast speeds. Our results are consistent with previous studies. <xref ref-type="bibr" rid="c44">Masson et al. (1999)</xref> showed that the speed segmentation threshold increased sharply when the mean stimulus speed increased from 8°/s to 16°/s. By varying the width of a speed notch, <xref ref-type="bibr" rid="c66">Rocchi et al. (2018)</xref> showed that transparent motion perception was stronger with a wider notch width, and that transparent motion was well perceived at slow speeds (mean speed = 4.6°/s) but not at faster speeds (mean speed = 20.6°/s) at a range of notch widths from 1 to 6°/s. Our study tested a larger range of speeds and showed that the segmentation performance dropped sharply at speeds of 20 and 80°/s (×4), and 20 and 40°/s (×2), faster than those shown in the previous studies. This discrepancy is likely due to the larger speed separations used in our study and the difference in stimuli. The visual stimuli used in our study had either one or two speeds, whereas those used by <xref ref-type="bibr" rid="c66">Rocchi et al. (2018)</xref> were sampled from a distribution of motion speeds and had multiple elements.</p>
</sec>
<sec id="s3b">
<title>Neural encoding of multiple speeds and implications for efficient coding</title>
<p>We found that, at low stimulus speeds, MT neurons showed a faster-speed bias in representing two speeds of overlapping stimuli. We also showed that faster-speed bias in MT is a robust phenomenon regardless of whether the stimulus components move in the same or different directions. A faster-speed bias in representing two motion speeds is a novel finding. It adds to a growing body of studies demonstrating that visual neurons do not necessarily average the responses elicited by individual stimulus components in response to multiple stimuli (e.g., <xref ref-type="bibr" rid="c51">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="c7">Bao and Tsao, 2018</xref>). Our laboratory has previously reported that the responses of MT neurons to multiple moving stimuli can show a bias toward the stimulus component with a higher signal strength such as motion coherence or luminance contrast (<xref ref-type="bibr" rid="c82">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c80">Wiesner et al., 2020</xref>), a directional side bias toward one of two motion directions, even when the stimulus components have the same signal strength (<xref ref-type="bibr" rid="c81">Xiao and Huang, 2015</xref>), and a disparity bias toward one of two surfaces moving at different stereoscopic depths (<xref ref-type="bibr" rid="c22">Chakrala et al., 2024</xref>). These different response biases enhance the representation of individual stimulus components and can help to facilitate the segmentation of multiple moving stimuli (<xref ref-type="bibr" rid="c54">Orhan and Ma, 2015</xref>).</p>
<p>While the faster-speed bias reported in this study may facilitate the segregation of faster-moving stimuli, it may come at the cost of reduced ability to segregate slower speeds. Why does the primate visual system encode multiple speeds in this way? An efficient way to represent sensory information is to devote limited resources to better represent signals that occur more frequently in the natural environment (<xref ref-type="bibr" rid="c5">Attneave 1954</xref>; <xref ref-type="bibr" rid="c8">Barlow 1961</xref>; <xref ref-type="bibr" rid="c71">Simoncelli and Olshausen 2001</xref>). Previous studies have suggested that slow speeds are more likely to occur than fast speeds in natural scenes (<xref ref-type="bibr" rid="c79">Weiss et al., 2002</xref>; <xref ref-type="bibr" rid="c73">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="c85">Zhang and Stocker, 2022</xref>). If neurons in the primate visual cortex are optimized to efficiently represent speeds that are more likely to occur in natural scenes, one may expect to find neurons showing a slower-speed bias rather than a faster-speed bias. However, besides maximizing information about the environment, neural representation in the sensory cortices may be optimized for other goals, such as maximizing the performance of certain behavioral tasks (<xref ref-type="bibr" rid="c71">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="c43">Manning et al., 2024</xref>). Since a figural object tends to move faster than its background in natural scenes (<xref ref-type="bibr" rid="c33">Huang et al., 2019</xref>; <xref ref-type="bibr" rid="c25">Friedman et al., 2025</xref>), a neural representation of multiple motions with a faster-speed bias would help to identify the figure and, therefore, benefit the performance of an essential behavioral task – figure/ground segregation. Our finding of a faster-speed bias at slow stimulus speeds underscores the possibility that, when choosing between efficiently representing the most commonly occurring features in natural scenes (e.g., slow speeds) and enhancing behavioral performance in critical tasks (e.g., figure-ground segregation), some brain areas in the visual system may prioritize enhancing the behavioral performance.</p>
</sec>
<sec id="s3c">
<title>Potential mechanisms underlying the neural encoding of multiple speeds</title>
<p>We found that the faster-speed bias was still present when attention was directed away from the RFs, suggesting that the faster-speed bias cannot be explained by an attentional modulation. The faster-speed bias cannot be explained by the apparent contrast of the stimulus component either – the random dots of the faster-speed component had shorter dwell time on the video display and appeared dimmer than the slower component. We suggest a modified normalization model that may explain why the faster-speed bias in MT occurs at low stimulus speeds and diminishes at high speeds.</p>
<p>Previous studies that characterize the neural representation of multiple stimuli have used stimulus strength to weigh the component responses in the divisive normalization model (e.g., <xref ref-type="bibr" rid="c18">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="c51">Ni et al, 2012</xref>; <xref ref-type="bibr" rid="c82">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c28">Heuer and Britten, 2002</xref>). In comparison to the standard normalization model, we suggest that the response of a population of neurons (i.e., the weighting pool) defines the numerator of the normalization equation (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>). The weighting pool may or may not be the same as the normalization pool that defines the response in the denominator. We suggest that the weighting pool contains a population of neurons with a broad range of speed preferences. In this way, the summed (or averaged) response of the weighting pool depends mainly on the stimulus speed, and therefore, the weighting is less sensitive to the individual neuron’s speed preference. In this study, we used MT population-averaged responses to single speeds to approximate the responses of the weighting pool. MT population-averaged speed tuning in our data peaked around 20°/s (<xref rid="fig8" ref-type="fig">Fig. 8E</xref>), consistent with previous studies (<xref ref-type="bibr" rid="c45">Maunsell and Van Essen 1983</xref>; <xref ref-type="bibr" rid="c40">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c52">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="c30">Huang and Lisberger, 2009</xref>). At stimulus speeds less than 20°/s, the population speed tuning has a positive slope, and a faster component would elicit a stronger population response than a slower component. This insight explains the faster-speed bias at low stimulus speeds and why it tends to be stronger at ×4 than at ×2 speed separation. Conceptually, this model can also explain why faster-speed bias diminishes at higher speeds. When two stimulus speeds are at opposite sides of the population’s preferred speed, they elicit similar population responses in the weighting pool. This model also predicts that when both stimulus speeds exceed the preferred speed of the weighting pool, the response weight for the slower component should be greater than that for the faster component.</p>
<p>This modified normalization model well described our data on MT responses to two stimuli moving in different directions at 2.5 and 10°/s (<xref rid="fig8" ref-type="fig">Fig. 8</xref>). However, our current data set has limitations to validate this model fully. This normalization model (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>) can reasonably describe our data on MT responses to bi-speed stimuli moving in the same direction across five speed pairs (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) (results not shown). However, since the responses of each neuron to the bi-speed stimuli only have five data points (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>) and our model has four free parameters (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>), the model is underconstrained. In future work, it will be important to extend the experiment to include pairs of stimuli moving in different directions at varying combinations of speeds across a broader range. By incorporating full direction tuning curves to better constrain the model (as shown in <xref rid="fig8" ref-type="fig">Fig. 8</xref>) and systematically varying speed combinations, future studies could test the model’s prediction that the response bias shifts from a faster-speed bias to response averaging and eventually to a slower-speed bias, as the stimulus speeds increase.</p>
    <p>Although in our model, we used the responses of a population of MT neurons to estimate the responses of the weighting pool, the weighting pool may be composed of neurons that feed signals into MT and have similar population-averaged speed tuning as MT neurons. MT neurons receive feedforward motion-selective input mainly from V1, and also from V2 and V3 (<xref ref-type="bibr" rid="c76">Ungerleider and Desimone, 1986</xref>; <xref ref-type="bibr" rid="c49">Movshon and Newsome, 1996</xref>; <xref ref-type="bibr" rid="c3">Anderson et al., 1998</xref>; <xref ref-type="bibr" rid="c2">Anderson and Martin, 2002</xref>; <xref ref-type="bibr" rid="c67">Rockland, 2002</xref>). Speed-selective complex cells in V1 have preferred speeds in a range similar to that of MT neurons, but the mean preferred speed is slower than MT (<xref ref-type="bibr" rid="c48">Mikami et al., 1986</xref>; <xref ref-type="bibr" rid="c53">Orban et al., 1986</xref>; <xref ref-type="bibr" rid="c62">Priebe et al., 2006</xref>). Future studies examining the transition speeds at which faster-speed bias changes to response averaging and slower-speed bias may help to differentiate whether the weighting pool consists of neurons in MT or early visual areas such as V1.</p>
</sec>
<sec id="s3d">
<title>Decoding multiple speeds from population neural responses</title>
    <p>Theoretical studies have proposed neural coding of probability distribution and multiplicity of a visual attribute (<xref ref-type="bbir" rid="c58">Pouget et al., 2000</xref>). The key idea of this framework is that neurons do not code a single stimulus value but instead code the distribution of the stimulus (<xref ref-type="bibr" rid="c84">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c59">Pouget et al., 2003</xref>). However, neurophysiological evidence supporting this framework on coding multiplicity is limited. Previous studies have not demonstrated the ability to extract multiple speeds from population neural responses. Our results provide support for this framework of coding multiplicity. Our decoding analysis reveals that the population neural response in MT carries information about multiple speeds of overlapping stimuli, and it is possible to extract multiple speeds and their weights even when the population neural response has a unimodal distribution.</p>
<p>At large (x4) speed separation, our decoding results captured several key features of humans’ and monkeys’ perception of multiple speeds – the decoded speeds support perceptual segmentation at low to intermediate speeds (<xref rid="fig11" ref-type="fig">Figs. 11A-E</xref>, <xref ref-type="fig" rid="fig12">12A-K</xref>). At 20 and 80°/s, the decoder was uncertain about whether a single speed or two speeds were present in the visual stimuli and, therefore, had difficulty segmenting the visual stimuli at these fast speeds (<xref rid="figS4" ref-type="fig">Suppl. Fig. 4</xref>). However, at small (×2) speed separation, the decoding results showed very little segmentation (<xref rid="fig11" ref-type="fig">Figs. 11G-J</xref>, <xref ref-type="fig" rid="fig12">12L</xref>), except at very low speeds. This result differs from the perception at stimulus speeds less than 20 and 40°/s (<xref rid="fig1" ref-type="fig">Figs. 1C2, E2</xref>, <xref ref-type="fig" rid="fig2">2B2</xref>). What are the potential reasons for the decoder’s inadequacy in segmenting small speed separations? The best-fit population response predicted by the encoding rule of the decoder matched the neural responses remarkably well (<italic>R</italic><sup><italic>2</italic></sup> &gt; 0.99 for all five speed pairs of ×2 separation, <xref rid="fig10" ref-type="fig">Fig. 10F-J</xref>). So, the encoding model for decoding effectively described the population neural responses to the bi-speed stimuli. Because we found the same results when performing decoding based on neural responses averaged across experimental trials (<xref rid="fig10" ref-type="fig">Fig. 10G-J</xref>), this inadequacy was unlikely due to our assumption of the trial-by-trial response variability following a Poisson process. We consider several factors that may contribute to this discrepancy.</p>
<p>First, this may be attributed to the limited sample size of our dataset. If we had a much larger MT neuron population, potential differences in neuronal responses to bi-speed stimuli and the single log mean speed might be captured by the data, which may lead to better decoding. Second, it may be due to the choice of the “objective function”. Our decoder minimized the sum of squared error between the predicted population response and the recorded neural response. In contrast, <xref ref-type="bibr" rid="c84">Zemel et al. (1998)</xref> found motion directions that maximized the posterior probability <italic>P</italic>(<bold><italic>s</italic></bold>|<bold><italic>r</italic></bold>) using a maximum a posteriori (MAP) estimate. It remains to be determined whether maximizing the posterior probability can improve the resolution of segmenting multiple speeds. Third, in different sensory areas, neuronal responses to two stimuli can fluctuate from trial to trial, representing one stimulus component over the other (<xref ref-type="bibr" rid="c39">Li et al., 2016</xref>; <xref ref-type="bibr" rid="c21">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="c34">Jun et al., 2022</xref>; <xref ref-type="bibr" rid="c69">Schmehl et al., 2024</xref>; <xref ref-type="bibr" rid="c27">Groh et al., 2024</xref>). If this trial-varying stimulus multiplexing also occurred for representing two speeds with a small separation, information about individual speed components would be lost in the trial-averaged responses (with added variability based on a Poisson process), as in our decoding procedure. Future studies with a large number of repeated experimental trials would be needed to test this possibility. Finally, while area MT is clearly important for motion-based segmentation, other motion-sensitive brain areas may be important for segmenting speeds with a small difference.</p>
</sec>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<p>We conducted psychophysical experiments using human subjects, and psychophysical and neurophysiological experiments using macaque monkeys.</p>
<sec id="s4a">
<title>Human psychophysics</title>
<sec id="s4a1">
<title>Subjects</title>
<p>Four adult human subjects (<italic>CN, CO, IN, NP</italic>), two men and two women, with normal or corrected-to-normal visual acuity, participated in the psychophysics experiments. Subject <italic>CN</italic> was naive about the purposes of the experiments. Subjects CO and IN had a general idea about this study but did not know the specific design of the experiments. Informed consent was obtained from the subjects. All aspects of the study were in accordance with the principles of the Declaration of Helsinki and were approved by the Institutional Review Board at the University of Wisconsin-Madison.</p>
</sec>
<sec id="s4a2">
<title>Apparatus</title>
<p>Visual stimuli were generated by a Linux workstation using an OpenGL application and displayed on a 19-inch CRT monitor. The monitor had a resolution of 1,024 x 768 pixels and a refresh rate of 100 Hz. The output of the video monitor was measured with a photometer (LS-110, Minolta) and was gamma-corrected. Stimulus presentation was controlled by a real-time data acquisition and stimulus control program “Maestro” (<ext-link ext-link-type="uri" xlink:href="https://sites.google.com/a/srscicomp.com/maestro/">https://sites.google.com/a/srscicomp.com/maestro/</ext-link>) as in the animal behavior and neurophysiology experiments. Subjects viewed the visual stimuli in a dark room with dim background illumination. The viewing distance was 58 cm. A chin rest and forehead support were used to restrict the head movements of the observers. During experimental trials, human subjects maintained fixation on a small spot within a 2 x 2<sup>o</sup> window. Eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1kHz.</p>
</sec>
<sec id="s4a3">
<title>Visual stimuli</title>
<p>Visual stimuli were two spatially overlapping random-dot patches presented within a square aperture 10° wide. Each square stimulus was centered 11° to the right of the fixation spot, therefore covering 6° to 16° eccentricity. This range roughly matched the RF eccentricity of the recorded MT neurons in our neurophysiological experiments. The random dots were achromatic. Each random dot was 3 pixels and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was 0.03 cd/m<sup>2</sup>. The dot density of each random dot patch was 2 dots/degree<sup>2</sup>. The two random-dot patches translated horizontally in the same direction. To reduce adaptation, the motion direction was either leftward or rightward in half of the trials, and stimulus trials were randomly interleaved. In one set of trials, two overlapping random-dot patches had a “large speed separation” and the speed of the faster component was always four times (x4) that of the slower component. In another set of trials, visual stimuli had a “small speed separation” and the speed of the faster component was always twice (x2) that of the slower component (see <xref rid="fig1" ref-type="fig">Fig. 1B1</xref>, B2). For each bi-speed stimulus, there was a corresponding single-speed stimulus composed of two overlapping random-dot patches moving in the same direction at the same speed. The single speed was the natural logarithmic (log) mean speed of the bi-speed stimulus: <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="532456v4_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, in which <italic>Spd</italic><sub><italic>1</italic></sub> and <italic>Spd</italic><sub><italic>2</italic></sub> were the two component speeds. The motion coherence of each random-dot patch was always 100%.</p>
</sec>
<sec id="s4a4">
<title>Procedure</title>
<p>In a standard two-alternative-forced-choice (2AFC) task, subjects discriminated a bi-speed stimulus from the corresponding single log-mean speed stimulus. The bi-speed and single-speed stimuli were presented in two consecutive time intervals with a 500 ms gap in between, in random, balanced order. In each time interval, the visual stimulus appeared, remained stationary for 250 ms, and then moved for 500 ms. At the end of each trial, subjects reported which time interval contained a bi-speed stimulus by pressing one of two buttons (left or right) within a 1500-ms window. After the button press, the inter-trial interval was 1300 ms. Each block of trials contained 40 trials, i.e. 5 speed pairs × 2 speed separations × 2 temporal orders (the bi-speed stimulus appeared in the first or second time-interval) × 2 motion directions (visual stimuli moved either to the left or right). Each experimental session typically contained 5 blocks, i.e. 200 trials.</p>
<p>Subjects also performed a 3AFC task. As in the 2AFC task, subjects discriminated a bi-speed stimulus from the corresponding single log-mean speed stimulus but had the option to make a third choice by pressing the middle button on trials when they thought neither stimulus interval appeared to contain two speeds (“no two-speeds” choice). When subjects thought one of the two stimulus intervals contained two speeds, subjects then pressed either the left or the right button to indicate which interval had two speeds.</p>
</sec>
<sec id="s4a5">
<title>Data analysis</title>
<p>The hit rate was calculated as the percentage of trials in which a subject correctly picked the bi-speed stimulus as having two speeds. The false alarm rate was calculated as the percentage of trials in which a subject incorrectly identified the single-speed stimulus as having two speeds. As a measure of discriminability between the bi-speed and the corresponding single-speed stimuli, we calculated the discriminability index <italic>d′</italic> = <italic>norminv</italic>(hit rate) – <italic>norminv</italic>(false alarm rate). <italic>norminv</italic> is a MATLAB function that calculates the inverse of the normal cumulative distribution function, with the mean and standard deviation set to 0 and 1, respectively. When the hit or false alarm rate was occasionally close to 1, to avoid infinite d’ values, d’ was calculated using a modified formula: <italic>d’</italic> = norminv{[(100 x hit rate)+1]/102} - norminv{[(100 x false alarm rate) +1]/102}. In analyzing the results of the 3AFC task, we incorporated the NTC trials into the <italic>d’</italic> calculation by evenly splitting the NTC trials into “hit” trials and “false alarm” trials. In this way, the NTC trials were still accounted for by the hit rate and false alarm rate, in the sense that they did not contribute to the discrimination. We also examined the percentage of trials in which subjects made the NTC choice at different stimulus speeds.</p>
</sec>
</sec>
<sec id="s4b">
<title>Neurophysiological and psychophysical experiments</title>
<sec id="s4b1">
<title>Subjects</title>
<p>Five male adult rhesus monkeys (<italic>Macaca mulatta</italic>) were used in the experiments. Four monkeys were used in the neurophysiological experiments, and one was used in the psychophysical experiment. Experimental protocols were approved by the local Institutional Animal Care and Use Committee and were in strict compliance with U.S. Department of Agriculture regulations and the National Institutes of Health <italic>Guide for the Care and Use of Laboratory Animals</italic>.</p>
</sec>
<sec id="s4b2">
<title>Apparatus and electrophysiological recording</title>
<p>Procedures for surgical preparation and electrophysiological recording were routine and similar to those described previously (<xref ref-type="bibr" rid="c30">Huang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="c82">Xiao et al., 2014</xref>). For subjects IM and MO, horizontal and vertical eye positions were monitored using the search coil method at a sampling rate of 1kHz on each channel. For subjects RG, GE, and BJ, eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1kHz. For electrophysiological recordings, we lowered single-contact tungsten microelectrodes (Thomas Recording or FHC) either using the MiniMatrix microdrive (Thomas Recording) or the NAN drive (NAN Instruments) into the posterior bank of the superior temporal sulcus. The impedances of the electrodes were 1∼3 MΩ. We identified area MT by its characteristically large proportion of directionally selective neurons, small classical RFs relative to those in the neighboring medial superior temporal area, and location on the posterior bank of the superior temporal sulcus. Electrical signals were filtered, amplified, and digitized conventionally. Single units were identified with a real-time template-matching system (Plexon). Spikes were carefully sorted using Plexon offline sorter.</p>
<p>Stimulus presentation and the behavioral paradigm were controlled by a real-time data acquisition program Maestro as described in the human psychophysics experiment. For neurophysiological recordings from IM and MO, visual stimuli were presented on a 20-inch CRT monitor at a viewing distance of 38 cm. Monitor resolution was 1,280 × 1,024 pixels and the refresh rate was 85 Hz. For RG, GE, and BJ, visual stimuli were presented on a 25-inch CRT monitor at a viewing distance of 63 cm. Monitor resolution was 1,024 × 768 pixels and the refresh rate was 100 Hz. Visual stimuli were generated by a Linux workstation using an OpenGL application that communicated with the main experimental-control computer over a dedicated Ethernet link. The output of the video monitor was gamma-corrected.</p>
</sec>
<sec id="s4b3">
<title>Visual stimuli and experimental procedure of the main experiment</title>
<p>All visual stimuli were presented in individual trials while monkeys maintained fixation. Monkeys were required to maintain fixation within a 1.5 × 1.5° window centered around a fixation spot during each trial to receive juice rewards, although actual fixation was typically more accurate. In a trial, visual stimuli were illuminated after the animal had acquired fixation for 200 ms. To assist the isolation of directional-selective neurons in area MT, we used circular translation of a large random-dot patch (30 × 30°) as a search stimulus (<xref ref-type="bibr" rid="c70">Schoppmann and Hoffmann, 1976</xref>). After an MT neuron was isolated, we characterized the direction tuning using randomly interleaved trials of 30 × 30° random-dot patches moving at 10°/s in eight different directions, ranging from 0 to 315° in 45° steps. Next, we mapped the RF by recording responses to a series of 5 × 5° patches of random dots that moved in the preferred direction of the neuron at 10°/s. The location of the patch was varied randomly to tile the screen in 5° steps without overlap, covering an area of either 40 × 30° or 35 × 25°. The raw map of the RF was interpolated using the Matlab function <italic>interp2</italic> at an interval of 0.5°, and the location giving rise to the highest firing rate was taken as the center of the RF. In the following experiments, testing stimuli were centered on the RF.</p>
<p>Monkeys IM and MO were tested with the main visual stimuli used in our experiments, which were two spatially overlapping random-dot patches presented within a square aperture 10° wide. The random dots were achromatic. The dot density of each random-dot patch was 2 dots/deg<sup>2</sup>. Each random dot was 3 pixels at a side and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was &lt; 0.2 cd/m<sup>2</sup>. In each trial, the random dots moved within the aperture. The two random-dot patches were translated at two different speeds, both at 100% motion coherence, in the same direction (the preferred direction of the recorded neuron). The ratio between the two component speeds was fixed either at 4 (i.e., the large speed separation) or 2 (i.e., the small speed separation) (see Methods for human psychophysics above). At x4 speed separation, the five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1B1</xref>). At x2 speed separation, the speed pairs used were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1B2</xref>). Experimental trials of bi-speed stimuli that had x4 or x2 speed separations were randomly interleaved. Also randomly interleaved were trials that showed only a single random-dot patch moving at a speed of 1.25, 2.5, 5, 10, 20, 40, or 80°/s, which were the individual stimulus components of the bi-speed stimuli.</p>
<p>Monkeys RG and GE were tested with a variation of the main visual stimuli, where two overlapping random-dot stimulus components moved at fixed speeds of 2.5 and 10°/s, respectively, in two different directions separated by 90°. The diameter of the stimulus aperture was 3°. The faster component moved at the clockwise side of the two component directions (illustrated in <xref rid="fig8" ref-type="fig">Fig. 8</xref>). We varied the vector average direction of the two stimulus components across 360° in a step of 15° to characterize the direction-tuning curves of MT neurons. We also measured the direction-tuning curves to a single stimulus moving at the individual component speeds.</p>
</sec>
<sec id="s4b4">
<title>Behavioral paradigm and visual stimuli of attention control</title>
<p>Monkey RG was also tested in a control experiment in which the attention of the animal was directed away from the RFs of MT neurons. The attended stimulus was a random-dot patch moving in a single direction at 100% motion coherence within a stationary circular aperture that had a diameter of 5°. The stimulus patch was centered 10° to the left of the fixation spot, in the visual hemifield contralateral to the hemifield of the recorded MT neurons’ RFs. The monkey performed a direction discrimination task to report whether the motion direction of the attended stimulus moved at the clockwise or counter-clockwise side relative to the vertical direction. While the animal fixated on a point at the center of the monitor, both the attended stimulus and the RF stimulus were turned on and remained stationary for 250 ms before they moved for 500 ms. The attended stimulus translated at a speed of 10°/s and in a direction either clockwise or counter-clockwise from an invisible vertical (upward) direction by an offset of 10°, 15°, or 20°. The RF stimuli were the same as our main visual stimuli, with either a single-speed or bi-speed stimulus moving in the same direction. All trials were randomly interleaved. After the motion period, all the visual stimuli were turned off, and two reporting targets appeared 10° eccentric on the left and right sides of the fixation point. To receive a juice reward, the animal was required to make a saccadic eye movement within 400 ms after the fixation spot was turned off, either to the left or right target, depending on whether the motion direction of the attended stimulus was counter-clockwise or clockwise to the vertical direction, respectively.</p>
</sec>
<sec id="s4b5">
<title>Monkey psychophysics</title>
<p>Monkey BJ was trained to perform a 2AFC discrimination task. The visual stimuli were the same as our main visual stimuli in the neurophysiological experiments, except that the stimulus moving at a single speed was also composed of two overlapping random-dot patches moving in the same direction at the same speed, the same as in the human psychophysics experiments. In this way, the single-speed stimulus and the bi-speed stimuli had the same dot density. Visual stimuli were random-dot patches moving within a square aperture of 10°x10°, centered 10° to the right of the fixation spot. The motion direction of the visual stimuli was always rightward. Experimental trials of bi-speed stimuli that had x4 or x2 speed separations, as well as the single-speed stimulus that moved at the log mean speed of the bi-speed stimuli, were randomly interleaved. Visual stimuli were turned on, remained stationary for 250 ms, and then moved for 500 ms. Following the stimulus offset, two reporting targets (dots) were presented 5.7° away from the fixation spot, at upper right (4°, 4°) and lower left (-4°, -4°) positions relative to the fixation spot. To receive a juice reward, the animal was required to make a saccadic eye movement to one of the two targets within 300 ms after the fixation spot was turned off. In most of the experiment trials, the animal received juice rewards for selecting the upper-right target when visual stimuli moved at two different speeds, and for selecting the lower-left target when visual stimuli moved at a single speed. Guided by our human psychophysics results, we made an exception to always reward the animal when the bi-speed stimuli moved at 20 and 80°/s or at 20 and 40°/s, regardless of which target was selected to avoid biasing the monkey’s choice by veridically rewarding the animal. This was because, at these fast speeds, human subjects could not segment the bi-speed stimuli. During training, the animal was never presented with the bi-speed stimuli of 20 and 80°/s, and 20 and 40°/s. During testing, the trials of 20 and 80°/s, and 20 and 40°/s were randomly interleaved with bi-speed and single-speed trials that were rewarded veridically to anchor the task rule. Among all testing trials, only 10% of the trials were rewarded with a 100% rate. We collected 50 trials of data for x4 speed separation across 5 experimental sessions, and 90 trials for x2 speed separation across 9 sessions during the testing phase. The hit rate, false alarm rate, and the <italic>d’</italic> were calculated in the same way as in the human psychophysics experiments.</p>
</sec>
<sec id="s4b6">
<title>Model fit of the tuning curves to bi-speed stimuli</title>
<p>We used a linear weighted summation model (<xref ref-type="disp-formula" rid="eqn8">Eq. 8</xref>) to fit the direction-tuning curves to overlapping stimuli moving in different directions and at different speeds. We also fitted the direction-tuning curves to the bi-speed/bi-directional stimuli using a modified divisive normalization model (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>). These model fits were obtained using the constrained minimization tool “fmincon” (MATLAB) to minimize the sum of squared error. To evaluate the goodness of fit of models for the response tuning curves, we calculated the percentage of variance (PV) accounted for by the model as follows: <inline-formula id="inline-eqn-4"><inline-graphic xlink:href="532456v4_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where SSE is the sum of squared errors between the model fit and the neuronal data, and SST is the sum of squared differences between the data and the mean of the data (Morgan et al., 2008).</p>
</sec>
<sec id="s4b7">
<title>Construction of population neural response</title>
<p>For each recorded MT neuron, we plotted the trial-averaged speed tuning curve in response to the single speed and spline-fitted the tuning curve using the Matlab function <italic>csaps</italic> with the smoothing parameter <italic>p</italic> set to 0.93. We found <italic>p</italic> = 0.93 best captured the trend of the speed tuning, without obvious overfitting. We then found the preferred speed of the neuron, defined as the speed at which the maximum firing rate was reached in the spline-fitted tuning curve. The neuron’s responses to all single-speed and bi-speed stimuli were normalized by the maximum firing rate at the preferred speed. To construct the population neural response to a given stimulus, we took the normalized firing rate of each neuron elicited by that stimulus and plotted it against the preferred speed of the neuron. Because the preferred speeds of the neurons in our data sample did not cover the full speed range evenly, we spline-fitted (with a smoothing parameter of 0.93) the population neural response to capture it evenly across the full range of preferred speed.</p>
</sec>
<sec id="s4b8">
<title>Discrimination of population neural responses using a classifier</title>
<p>We trained a linear classifier to discriminate between the constructed population neural responses to a bi-speed stimulus and those to the corresponding single-speed stimulus moving at the log mean speed. Constructed trial-by-trial population responses were generated randomly according to a Poisson process with the mean set to the recorded neuronal response averaged across experimental trials. For each speed combination, we generated 200 trials of responses to both the bi-speed stimulus and the corresponding single-speed stimulus. Constructed population responses were partitioned into training and testing sets using k-fold cross-validation (k = 40). The 200 generated trials were randomly divided into 40 folds. The classifier was trained on 39 data folds and tested on the remaining fold, and the process was repeated 40 times to ensure that each fold was used for testing exactly once. The Matlab <italic>fitclinear</italic> function was used to fit a linear classifier to the training data. The logistic learner and lasso regularization techniques were specified during the model training. The Stochastic Gradient Descent solver was used to optimize the objective function during the training of the classifier. The performance of the classifier was evaluated by <italic>d’</italic>, calculated using the hit rate and false alarm rate as described in human psychophysics.</p>
</sec>
<sec id="s4b9">
<title>Population Decoding</title>
<p>We define a given probability distribution of stimulus speed as: ∅<sub><italic>m</italic></sub> = {<italic>P</italic><sub><italic>m,j</italic></sub>}, in which <italic>P</italic><sub><italic>m,j</italic></sub> is the probability of speed <italic>S</italic><sub><italic>j</italic></sub>, <italic>j</italic> = 1, 2, 3, …, 121, and <italic>j</italic> evenly samples speeds from 1.25°/s to 80°/s (referred to as the “full speed range”) on a natural logarithm scale and at a “<italic>speed interval</italic>” of 0.0347. Because ∅<sub><italic>m</italic></sub> is a probability distribution, Σ<sub><italic>j</italic></sub> <italic>P</italic><sub><italic>m,j</italic></sub> <italic>= 1</italic>. <italic>m</italic> is an index for different distributions.</p>
<p>The estimated response (<italic>ES</italic>) of neuron <italic>i</italic> to the stimulus speeds with a probability distribution ∅<sub><italic>m</italic></sub> is a linear sum of the responses of neuron <italic>i</italic> to each single speed <italic>S</italic><sub><italic>j</italic></sub> within the full speed range, weighted by the probability of each speed in ∅<sub><italic>m</italic></sub>. The probability can also be considered as the weight (signal strength) of the speed.
<disp-formula id="eqn10">
<graphic xlink:href="532456v4_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>f</italic><sub><italic>i</italic></sub> is the spline-fitted speed tuning curve of neuron <italic>i</italic> in response to single speeds. The estimated population response (<italic>EP</italic>) of <italic>N</italic> neurons to ∅<sub><italic>m</italic></sub> is:
<disp-formula id="eqn11">
<graphic xlink:href="532456v4_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>PS</italic><sub><italic>i</italic></sub> is the preferred speed of neuron <italic>i, i</italic> = 1, 2, 3, …, N. N = 100 in our neural data.</p>
<p>We then spline-fitted the estimated population response <italic>EP</italic><sub><italic>m</italic></sub>(<italic>ln</italic> (<italic>PS</italic><sub><italic>i</italic></sub>)) using a smoothing parameter of 0.93, interpolating the PS within the full speed range from 1.25°/s to 80°/s in natural logarithm with 121 evenly spaced values. The spline-fitted estimated population response is represented as <italic>spEP</italic><sub><italic>m</italic></sub>(<italic>ln</italic> (<italic>PS</italic><sub><italic>j</italic></sub>)), <italic>j</italic> = 1, 2, 3, …, 121.</p>
<p>Similarly, we spline-fitted the recorded and normalized population neural response <italic>RP</italic><sub><italic>m</italic></sub>(<italic>ln</italic> (<italic>PS</italic><sub><italic>i</italic></sub>)), <italic>i</italic> = 1, 2, 3, …, 100, and interpolated the PS to the same 121-speed values on a logarithm scale within the full speed range as above. The spline-fitted, recorded population neural response is represented as <italic>spRP</italic><sub><italic>m</italic></sub>(<italic>ln</italic> (<italic>PS</italic><sub><italic>j</italic></sub>)), <italic>j</italic> = 1, 2, 3, …, 121.</p>
<p>The decoded probability distribution of the stimulus speed ∅<sub><italic>e</italic></sub> is the ∅<sub><italic>m</italic></sub> that maximizes the objective function (OF), which is defined as the negative value of the SSE (sum squared error) between the spline-fitted estimated population response and the recorded neural response:
<disp-formula id="eqn12">
<graphic xlink:href="532456v4_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn13">
<graphic xlink:href="532456v4_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Rather than finding an arbitrary distribution, we constrained ∅<sub><italic>e</italic></sub> to contain either a single speed with a probability (referred to as the “weight”) of 1 or two speeds with the same or different weights that sum to 1.</p>
</sec>
<sec id="s4b10">
<title>An algorithm to search for the probability distribution of stimulus speed</title>
<p>We first searched for the best-fit distribution ∅<sub><italic>el</italic></sub> that contained a single speed <italic>SP</italic> with non-zero probability (P=1) and gave rise to the maximum OF across the full speed range (<italic>OF</italic><sub><italic>max</italic></sub>). We next searched for the best-fit distribution ∅<sub><italic>e2</italic></sub> that contained two speeds <italic>SP</italic><sub><italic>l</italic></sub> and <italic>SP</italic><sub><italic>2</italic></sub> with non-zero probability and gave rise to the maximum OF for two speeds (<italic>OF</italic><sub><italic>max2</italic></sub>). We varied the speed separation, the center position (i.e., the log mean speed), and the probabilities of the two speeds. For each speed separation and center position, the probabilities of <italic>SP</italic><sub><italic>l</italic></sub> and <italic>SP</italic><sub><italic>2</italic></sub> were varied from 0 to 1 at a step of 0.01, with the constraint that they summed to <italic>1</italic>. We searched through the speed separation, ln(<italic>SP</italic><sub><italic>2</italic></sub>)-ln(<italic>SP</italic><sub><italic>l</italic></sub>), from 0.0693 (i.e., 2 <italic>speed intervals</italic>) to 3.3271 (i.e., 96 <italic>speed intervals</italic>), in a step of 0.0693. The search range covered the speed ratio <italic>SP</italic><sub><italic>2</italic></sub>/<italic>SP</italic><sub><italic>l</italic></sub> from x1.07 to x27.86, sufficiently broader than x2 and x4 used in our visual stimuli. For each speed separation, we started the search where the center position of the two speeds [ln(<italic>SP</italic><sub><italic>l</italic></sub>)+ln(<italic>SP</italic><sub><italic>2</italic></sub>)<italic>]/2</italic> was in the middle of the 121 possible speed values, referred to as the “speed axis”. We then moved the center position toward the left border of ln(1.25) at a step of 0.0347 to find the maximum OF value (<italic>OF</italic><sub><italic>leftmax</italic></sub>) along the left half of the speed axis. If the OF value at the center position next to the current position was higher, the search moved to the next position. Otherwise, the current position was considered a local maximum. After we found a local maximum, the search continued in the same direction for up to another 30 <italic>speed intervals</italic>. This continued until one of the component speeds hit a border, 30 intervals were reached, or an OF value greater than the previous local maximum was found. If a larger OF was found, the local maximum was updated and the search jumped to that position, and the procedure was repeated until <italic>OF</italic><sub><italic>leftmax</italic></sub> was found. We then returned to the middle of the speed axis and searched through speed pairs toward the right border ln(80) to find the maximum <italic>OF</italic><sub><italic>rightmax</italic></sub>. The larger one of <italic>OF</italic><sub><italic>leftmax</italic></sub> and <italic>OF</italic><sub><italic>right</italic></sub> was the maximum OF for two speeds (<italic>OF</italic><sub><italic>max2</italic></sub>). The ∅<sub><italic>e</italic></sub> was either ∅<sub><italic>el</italic></sub> or ∅<sub><italic>e2</italic></sub>, whichever gave rise to the larger value of <italic>OF</italic><sub><italic>maxl</italic></sub> and <italic>OF</italic><sub><italic>ma</italic></sub>.</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Supplementary Materials and Figures</title>
<sec id="s5a">
<label>1.</label>
<title>Additional analysis of the weight for the fast component, using the firing rates in response to the slower component from split trials</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Weights for the faster stimulus component obtained from the slope of the linear regression, based on the recorded responses of 100 neurons.</title>
<p>The black curves are a replot of those in <xref rid="fig5" ref-type="fig">Figure 5F1</xref> and F2, with the <italic>Rs</italic> (the response to the slower component) calculated based on the average firing rate across all trials for each neuron at each speed pair. The red curves were calculated the same way as the black curves, except that the <italic>Rs</italic> used for the linear regression between (<italic>R – Rs</italic>) and (<italic>Rf – Rs</italic>) was averaged across different subsets of trials. For each neuron and at each speed pair, we determined <italic>R</italic><sub><italic>sl</italic></sub> by averaging the firing rates of <italic>R</italic><sub><italic>s</italic></sub> across half of the recorded trials, selected randomly. If the number of trials (<italic>n</italic>) was odd, we selected (<italic>n</italic> + 1)/2 trials. We also determined <italic>R</italic><sub><italic>s2</italic></sub> by averaging the firing rates of <italic>R</italic><sub><italic>s</italic></sub> across the rest of the trials. We regressed (<italic>R</italic> − <italic>R</italic><sub><italic>sl</italic></sub>) on (<italic>R</italic><sub><italic>f</italic></sub> − <italic>R</italic><sub><italic>s2</italic></sub>), as well as (<italic>R</italic> − <italic>R</italic><sub><italic>s2</italic></sub>) on (<italic>R</italic><sub><italic>f</italic></sub> − <italic>R</italic><sub><italic>sl</italic></sub>), and repeated the procedure 50 times. We then averaged the slope for each speed pair across a total of 100 regressions. Red error bars represent the standard deviation (N = 100 regressions). <bold>A</bold>. ×4 speed separation. <bold>B</bold>. ×2 speed separation.</p></caption>
<graphic xlink:href="532456v4_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5b">
<label>2.</label>
<title>Behavioral performance of the fine-direction discrimination task and MT response properties when the attention was directed away from MT neurons’ RFs</title>
<p>The monkey RG performed a direction discrimination task with an average correct rate of 86.7 ± 7.3% (mean ± std) across 23 sessions and over 5000 trials. The correct rates for 10°, 15°, and 20° direction offsets of the direction discrimination task were 78.8 ± 9.7%, 87.5 ± 8.3%, and 93.9 ± 5.8%, respectively (see Methods).</p>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components recorded in an attention-away and a fixation paradigm.</title>
<p>Speed tuning curves from one monkey (RG) averaged across: <bold>A1-D1</bold>. 5 neurons that had PS ≤ 2.5°/s, <bold>A2-D2</bold>. 6 neurons that had PS between 2.5 and 25°/s, <bold>A3-D3</bold>. 21 neurons that had PS &gt; 25°/s. Error bars represent ±STE. <bold>A1-A3</bold> and <bold>B1-B3</bold>. ×4 speed separation; <bold>C1-C3</bold> and <bold>D1-D3</bold>. ×2 speed separation. <bold>A1-A3</bold> and <bold>C1-C3</bold>. Attention directed away from the RFs; <bold>B1-B3</bold> and <bold>D1-D3</bold>. Fixation paradigm.</p></caption>
<graphic xlink:href="532456v4_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5c">
<label>3.</label>
<title>Trial-by-trial readouts from population neural responses to single speeds</title>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><title>Trial-by-trial readout speeds decoded from population neural responses to single speeds.</title>
<p>The neural population contained 100 recorded neurons, as shown in <xref rid="fig9" ref-type="fig">Figure 9</xref>. The trial-by-trial responses were randomly generated based on a Poisson process, with the mean set to the spike count averaged across the recorded trials. Each row in A-L shows the readout speed(s) from one trial, and each dot’s size is proportional to the weight of the readout speed. If only one speed is decoded in a trial, that readout speed is shown in red. In trials with two readout speeds, the slower and faster readout speeds are shown in green and blue, respectively. The white background indicates trials with a weight difference between two readout speeds of less than 0.7, which are considered to have two readout speeds. The gray background indicates trials with a weight difference greater than 0.7, which are considered to have only one readout speed. The vertical black line and the speed marked in each panel indicate the stimulus speed. <bold>A-G</bold>. Speeds decoded from recorded population neural responses to single speeds from 1.25 to 80°/s. Note that, at the stimulus speed of 80°/s (G), in addition to picking up the veridical speed of 80°/s (log speed of 4.382), the decoder often picked up a slower speed at 2.872°/s (log speed of 1.055), which was at the largest speed separation from 80°/s used in our searching algorithm (x27.86, log value 3.327). This border effect can also be seen at the stimulus speed of 1.25°/s (A), where a weaker and faster speed was sometimes picked up around 34.8°/s (log speed of 3.55). <bold>H-L</bold>. Speeds decoded from inferred population neural response to single speeds, which are the log-mean speeds of the bi-speed stimuli with x2 speed separation. The responses of these log mean speeds of x2 speed separation were obtained from the splined-fitted, trial-averaged speed-tuning curve of each neuron. <bold>M</bold>. Comparison of the readout speeds and the stimulus speeds. The diagonal line is the unity line. The ordinate represents the speed at the peak of the readout speed distribution pooled across simulated trials (not shown). At the stimulus speed of 1.77°/s (H), the distribution of the readout speed has two peaks, indicated by a solid circle (at 1.77°/s) and an open circle (at 1.25°/s). At the stimulus speed of 80°/s (G), the distribution of the readout speed also has two peaks; only the readout speed for the higher peak is shown in M.</p></caption>
<graphic xlink:href="532456v4_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
    <sec id="s5c1">
        <label>4.</label>
        <title>Analysis of decoded speeds of the bi-speed stimulus with the speeds of 20 and 80°/s</title>
        <p>At the fastest stimulus speeds of 20 and 80°/s, across all trials, the mean objective function value peaked at speed separation of x3.25 (mean OF = -0.17, std = 0.14) (purple vertical line in <xref rid="figS4" ref-type="fig">Suppl. Fig. 4A</xref>). However, the peak value is not significantly different from the mean objective function value at the largest speed separation (x27.86, 3.3 on the log scale) searched (mean OF = -0.19, std = 0.14) (paired t-test, p=0.31) (orange vertical line in <xref rid="figS4" ref-type="fig">Suppl. Fig. 4A</xref>). The flat objective function suggests high uncertainty of the extracted speed separation at this speed pair.</p>
        <p>We divided the trials into two subgroups, based on whether they had one or two readout speeds, and calculated the objective function for each subgroup.</p>
        <p>For trials considered to have two readout speeds, the objective function peaked at the speed separation of x3.25 (1.18 on the log scale) (purple vertical line in <xref rid="figS4" ref-type="fig">Suppl. Fig. 4B</xref>), corresponding to two readout speeds of 17.8 and 58.0°/s (the intersection points between the purple vertical line with the thick navy blue and thick green curves) (<xref rid="figS4" ref-type="fig">Suppl. Fig. 4C</xref>).</p>
        <p>For trials considered to have one readout speed, the mean objective function showed a peak at the speed separation of x27.86 (3.3 on the log scale), which was the largest speed separation searched (orange vertical line in <xref rid="figS4" ref-type="fig">Suppl. Fig. 4E</xref>). As shown in <xref rid="figS4" ref-type="fig">Supplementary Figure 4F</xref>, the dominate faster readout speed approached the log mean speed (40°/s, 3.7 on log scale) (thick navy blue curve) and the mean weight increased to 0.94 (cyan curve), as the searched speed separation increased. In contrast, as the searched speed separation increased, the slower readout speed approached the lower boundary speed (1.25°/s) (thick green curve) with the weight diminishing to negligible 0.06 (thin green curve) (<xref rid="figS4" ref-type="fig">Suppl. Fig. 4F</xref>), likely a border artifact.</p>
        <p>Furthermore, we compared the population neural responses averaged across the one-readout-speed trials and the two-readout-speed trials. The spline-fitted population responses of the two subgroups were highly correlated (R<sup>2</sup> = 0.99) and statistically indistinguishable (paired t-test, p=0.30) (<xref rid="figS4" ref-type="fig">Suppl. Fig. 4D</xref>). This indicates that a tiny change in the population response (e.g., a slightly higher peak near log preferred speed of 3.7) would lead the decoder to exact one speed rather than two speeds (<xref rid="figS4" ref-type="fig">Suppl. Fig. 4D</xref>). In other words, the decoder was uncertain about how many speeds were in the visual stimuli and therefore had difficulty segmenting the visual stimuli at these fast stimulus speeds of 20 and 80°/s.</p>
        <fig id="figS4" position="float" fig-type="figure">
            <label>Supplementary Figure 4.</label>
            <caption><title>Analysis of decoding the bi-speed stimulus with the speeds of 20 and 80°/s.</title>
                <p><bold>A</bold>. Values of the objective function averaged across all 200 trials as the decoder searched through different speed separations. The red dot on the X-axis indicates the ground-truth speed separation of the stimulus speeds. <bold>B, E</bold>. Values of the objective functions averaged across trials considered to have two (B) and one (E) readout speed(s). In A, B, and E, the error bands indicate ±STE. The black arrow indicates the speed separation where the objective function reaches its peak. The horizontal dotted line indicates the peak value of the objective function. <bold>C, F</bold>. Values of the readout speeds (darker and thick lines in green and blue) and their weights (lighter and thin lines in green and cyan) as the decoder searched through different speed separations in trials considered to have two (C) and one (F) readout speed(s). <bold>D</bold>. Population neural responses averaged across trials that are considered to have two readout speeds (purple) and one readout speed (orange). Each dot represents the trial-averaged response of one neuron. The curves represent the spline-fitted population neural responses. The two red dots on the X-axis indicate stimulus speeds of 20 and 80°/s.</p></caption>
            <graphic xlink:href="532456v4_figS4.tif" mimetype="image" mime-subtype="tiff"/>
        </fig>
    </sec>
</sec>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>All behavioral and neuronal data analyses were conducted using Matlab. Behavioral and electrophysiological data, as well as the Matlab code for neural decoding will be deposited and available at <ext-link ext-link-type="uri" xlink:href="https://github.com/XinHuangLab">https://github.com/XinHuangLab</ext-link> upon publication of the Version of Record.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Dr. Steven Lisberger for his support in the early phase of this project, Emily Ausloos and Jianbo Xiao for data collection in early human psychophysics experiments, Bryce Arseneau for animal training, and Ying Cao for collecting additional neural data. We also thank Drs. Jennifer Coonen and Kevin Brunner at the Wisconsin National Primate Research Center for excellent veterinary care and surgical assistance, Kechen Zhang for helpful suggestions on the study, Emily Cooper and Greg DeAngelis for their valuable comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Miezin</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>McGuinness</surname>, <given-names>E.</given-names></string-name></person-group> (<year>1985</year>). <article-title>Direction- and velocity-specific responses from beyond the classical receptive field in the middle temporal visual area (MT)</article-title>. <source>Perception</source>, <volume>14</volume>(<issue>2</issue>), <fpage>105</fpage>–<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anderson</surname>, <given-names>J. C.</given-names></string-name>, &amp; <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Connection from cortical area V2 to MT in macaque monkey</article-title>. <source>J Comp Neurol</source>, <volume>443</volume>(<issue>1</issue>), <fpage>56</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anderson</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Binzegger</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Rockland</surname>, <given-names>K. S.</given-names></string-name></person-group> (<year>1998</year>). <article-title>The connection from cortical area V1 to V5: a light and electron microscopic study</article-title>. <source>J Neurosci</source>, <volume>18</volume>(<issue>24</issue>), <fpage>10525</fpage>–<lpage>10540</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Atick</surname>, <given-names>J. J.</given-names></string-name> &amp; <string-name><surname>Redlich</surname>, <given-names>A. N.</given-names></string-name></person-group> (<year>1992</year>). <article-title>What Does the Retina Know about Natural Scenes?</article-title> <source>Neural Computation</source>, <volume>4</volume>(<issue>2</issue>), <fpage>196</fpage>–<lpage>210</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Attneave</surname>, <given-names>F.</given-names></string-name></person-group> (<year>1954</year>). <article-title>Some informational aspects of visual perception</article-title>. <source>Psychol Rev</source>, <volume>61</volume>(<issue>3</issue>), <fpage>183</fpage>–<lpage>193</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Averbeck</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name> &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Neural correlations, population coding and computation</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>7</volume>(<issue>5</issue>), <fpage>358</fpage>–<lpage>366</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bao</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Tsao</surname>, <given-names>D. Y.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Representation of multiple objects in macaque category-selective areas</article-title>. <source>Nat Commun</source>, <volume>9</volume>(<issue>1</issue>), <fpage>1774</fpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Barlow</surname> <given-names>H. B.</given-names></string-name></person-group> (<year>1961</year>). <chapter-title>Possible principles underlying the transformations of sensory messages. Chapter 13</chapter-title>. In: <person-group person-group-type="editor"><string-name><given-names>W.</given-names> <surname>Rosenblith</surname></string-name></person-group> (Ed.), <source>Sensory communication</source> (pp. <fpage>217</fpage>–<lpage>234</lpage>). <publisher-name>M.I.T. Press</publisher-name>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bergen</surname>, <given-names>R. S. van</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Pratte</surname>, <given-names>M. S.</given-names></string-name> &amp; <string-name><surname>Jehee</surname>, <given-names>J. F. M.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Sensory uncertainty decoded from visual cortex predicts behavior</article-title>. <source>Nature Neuroscience</source>, <volume>18</volume>(<issue>12</issue>), <fpage>1728</fpage>–<lpage>1730</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name>, &amp; <string-name><surname>Bradley</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Structure and function of visual area MT</article-title>. <source>Annu Rev Neurosci</source>, <volume>28</volume>, <fpage>157</fpage>–<lpage>189</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name>, <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Lukasewycz</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Segregation segregation of object and background motion in visual area MT: effects of microstimulation on eye movements</article-title>. <source>Neuron</source>, <volume>26</volume>(<issue>3</issue>), <fpage>725</fpage>–<lpage>734</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braddick</surname>, <given-names>O.</given-names></string-name></person-group> (<year>1993</year>). <article-title>Segmentation versus integration in visual motion processing</article-title>. <source>Trends Neurosci</source>, <volume>16</volume>(<issue>7</issue>), <fpage>263</fpage>–<lpage>268</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braddick</surname>, <given-names>O.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Local and global representations of velocity: transparency, opponency, and global direction perception</article-title>. <source>Perception</source>, <volume>26</volume>(<issue>8</issue>), <fpage>995</fpage>–<lpage>1010</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braddick</surname>, <given-names>O. J.</given-names></string-name>, <string-name><surname>Wishart</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Curran</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Directional performance in motion transparency</article-title>. <source>Vision Res</source>, <volume>42</volume>(<issue>10</issue>), <fpage>1237</fpage>–<lpage>1248</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name></person-group> (<year>2003</year>). <chapter-title>The middle temporal area: motion processing and the link to perception</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>J.W. LM</given-names> <surname>Chalupa</surname></string-name></person-group> (Ed.), <source>The visual neurosciences</source> (pp. <fpage>1203</fpage>–<lpage>1216</lpage>). <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name>, &amp; <string-name><surname>Heuer</surname>, <given-names>H. W.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Spatial summation in the receptive fields of MT neurons</article-title>. <source>J Neurosci</source>. <volume>19</volume>, <fpage>5074</fpage>–<lpage>5084</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name> &amp; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Decoding and Reconstructing Color from Responses in Human Visual Cortex</article-title>. <source>The Journal of Neuroscience</source>, <volume>29</volume>(<issue>44</issue>), <fpage>13992</fpage>–<lpage>14003</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Busse</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wade</surname>, <given-names>A. R.</given-names></string-name>, &amp; <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title>. <source>Neuron</source>, <volume>64</volume>(<issue>6</issue>), <fpage>931</fpage>–<lpage>942</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Normalization as a canonical neural computation</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>13</volume>(<issue>1</issue>), <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carandini</surname> <given-names>M.</given-names></string-name>, <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title>. <source>J Neurosci</source>. <volume>17</volume>, <fpage>8621</fpage>–<lpage>8644</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Caruso</surname>, <given-names>V. C.</given-names></string-name>, <string-name><surname>Mohl</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Glynn</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Willett</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Zaman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ebihara</surname>, <given-names>A. F.</given-names></string-name>, <string-name><surname>Estrada</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Freiwald</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name> &amp; <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Single neurons may encode simultaneous stimuli by switching between activity patterns</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>), <fpage>2715</fpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Chakrala</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2024</year>). <article-title>The role of binocular disparity and attention in the neural representation of multiple moving stimuli in the visual cortex</article-title>. <source>BioRxiv</source>, 2023.06.25.546480.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Churchland</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Shifts in the population response in the middle temporal visual area parallel perceptual and motor illusions produced by apparent motion</article-title>. <source>J Neurosci</source>, <volume>21</volume>(<issue>23</issue>), <fpage>9387</fpage>–<lpage>9402</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Berkes</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Orbán</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>14</volume>(<issue>3</issue>), <fpage>119</fpage>–<lpage>130</lpage>.</mixed-citation></ref>
    <ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedman</surname>, <given-names>C.T.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Yerxa</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Arseneau</surname>, <given-names>B.A.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Cooper</surname>, <given-names>E.A.</given-names></string-name></person-group> (<year>2025</year>). <article-title>Statistical regularities in natural scenes that support figure-ground segregation by neural populations</article-title>. <source>PLOS Computational Biology</source>. <volume>17</volume> <elocation-id>e1013573</elocation-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ganguli</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Efficient Sensory Encoding and Bayesian Inference with Heterogeneous Neural Populations</article-title>. <source>Neural Computation</source>, <volume>26</volume>(<issue>10</issue>), <fpage>2103</fpage>–<lpage>2134</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Schmehl</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Caruso</surname>, <given-names>V. C.</given-names></string-name> &amp; <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Signal switching may enhance processing power of the brain</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>28</volume>(<issue>7</issue>), <fpage>600</fpage>–<lpage>613</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heuer</surname>, <given-names>H. W.</given-names></string-name>, &amp; <string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Contrast dependence of response normalization in area MT of the rhesus macaque</article-title>. <source>J Neurophysiol</source>, <volume>88</volume>(<issue>6</issue>), <fpage>3398</fpage>–<lpage>3408</lpage>.</mixed-citation></ref>
    <ref id="c29"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Huang</surname> <given-names>W.</given-names></string-name>, <string-name><surname>Huang</surname> <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname> <given-names>K.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Information-theoretic interpretation of tuning curves for multiple motion directions</article-title>. <conf-name>51st Annual Conference on Information Sciences and Systems (CISS)</conf-name>, <conf-loc>Baltimore, United States</conf-loc> pp. <fpage>1</fpage>–<lpage>4</lpage>, doi: <pub-id pub-id-type="doi">10.1109/CISS.2017.7926142</pub-id>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Noise correlations in cortical area MT and their potential impact on trial-by-trial variation in the direction and speed of smooth-pursuit eye movements</article-title>. <source>J Neurophysiol</source>, <volume>101</volume>(<issue>6</issue>), <fpage>3012</fpage>–<lpage>3030</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Adaptive surround modulation in cortical area MT</article-title>. <source>Neuron</source>, <volume>53</volume>(<issue>5</issue>), <fpage>761</fpage>–<lpage>770</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Stimulus dependency and mechanisms of surround modulation in cortical area MT</article-title>. <source>J Neurosci</source>, <volume>28</volume>(<issue>51</issue>), <fpage>13889</fpage>–<lpage>13906</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Arseneau</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Yerxa</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Cooper</surname>, <given-names>E. A.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Natural scene statistics of depth and motion pertinent to figure-ground segregation</article-title>. <source>Society for Neuroscience (SfN) Abstract. 2019-S-7048-SfN</source>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jun</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Ruff</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Kramer</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Bowes</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>M. R.</given-names></string-name> &amp; <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Coordinated multiplexing of information about separate objects in visual cortex</article-title>. <source>eLife</source>, <volume>11</volume>, <elocation-id>e76452</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.76452</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kay</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Prenger</surname>, <given-names>R. J.</given-names></string-name> &amp; <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Identifying natural images from human brain activity</article-title>. <source>Nature</source>, <volume>452</volume>(<issue>7185</issue>), <fpage>352</fpage>–<lpage>355</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Neural mechanisms of speed perception: transparent motion</article-title>. <source>J Neurophysiol</source>, <volume>110</volume>(<issue>9</issue>), <fpage>2007</fpage>–<lpage>2018</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name></person-group> (<year>2006a</year>). <article-title>Adaptation in macaque MT reduces perceived speed and improves speed discrimination</article-title>. <source>J Neurophysiol</source>, <volume>95</volume>(<issue>1</issue>), <fpage>255</fpage>–<lpage>270</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name></person-group> (<year>2006b</year>). <article-title>Interactions between speed and contrast tuning in the middle temporal area: implications for the neural code for speed</article-title>. <source>J Neurosci</source>, <volume>26</volume>(<issue>35</issue>), <fpage>8988</fpage>–<lpage>8998</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kozyrev</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Kyllingsbæk</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ditlevsen</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Bundesen</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Neurons in Primate Visual Cortex Alternate between Responses to Multiple Stimuli in Their Receptive Field</article-title>. <source>Frontiers in Computational Neuroscience</source>, <volume>10</volume>, <fpage>141</fpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Visual motion analysis for pursuit eye movements in area MT of macaque monkeys</article-title>. <source>J Neurosci</source>, <volume>19</volume>(<issue>6</issue>), <fpage>2224</fpage>–<lpage>2246</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Functional organization of speed tuned neurons in visual area MT</article-title>. <source>J Neurophysiol</source>, <volume>89</volume>(<issue>1</issue>), <fpage>246</fpage>–<lpage>256</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Beck</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name> &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>(<issue>11</issue>), <fpage>1432</fpage>–<lpage>1438</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manning</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Alexander</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name>, <string-name><surname>DeAngelis</surname>, <given-names>G. C.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name> &amp; <string-name><surname>Cooper</surname>, <given-names>E. A.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Transformations of sensory information in the brain suggest changing criteria for optimality</article-title>. <source>PLOS Computational Biology</source>, <volume>20</volume>(<issue>1</issue>), <fpage>e1011783</fpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masson</surname>, <given-names>G. S.</given-names></string-name>, <string-name><surname>Mestre</surname>, <given-names>D. R.</given-names></string-name>, &amp; <string-name><surname>Stone</surname>, <given-names>L. S.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Speed tuning of motion segmentation and discrimination</article-title>. <source>Vision Res</source>, <volume>39</volume>(<issue>26</issue>), <fpage>4297</fpage>–<lpage>4308</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name>, &amp; <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>1983</year>). <article-title>Functional properties of neurons in middle temporal visual area of the macaque monkey. I. Selectivity for stimulus direction, speed, and orientation</article-title>. <source>J Neurophysiol</source>, <volume>49</volume>(<issue>5</issue>), <fpage>1127</fpage>–<lpage>1147</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McDonald</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Clifford</surname>, <given-names>C. W.</given-names></string-name>, <string-name><surname>Solomon</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>S. C.</given-names></string-name>, &amp; <string-name><surname>Solomon</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Integration and segregation of multiple motion signals by neurons in area MT of primate</article-title>. <source>J Neurophysiol</source>, <volume>111</volume>(<issue>2</issue>), <fpage>369</fpage>–<lpage>378</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mestre</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>Masson</surname>, <given-names>G. S.</given-names></string-name>, &amp; <string-name><surname>Stone</surname>, <given-names>L. S.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Spatial scale of motion segmentation from speed cues</article-title>. <source>Vision Res</source>, <volume>41</volume>(<issue>21</issue>), <fpage>2697</fpage>–<lpage>2713</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mikami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name>, &amp; <string-name><surname>Wurtz</surname>, <given-names>R. H.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Motion selectivity in macaque visual cortex. I. Mechanisms of direction and speed selectivity in extrastriate area MT</article-title>. <source>J Neurophysiol</source>, <volume>55</volume>(<issue>6</issue>), <fpage>1308</fpage>–<lpage>1327</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> (<year>1996</year>). <article-title>Visual response properties of striate cortical neurons projecting to area MT in macaque monkeys</article-title>. <source>J Neurosci</source>, <volume>16</volume>(<issue>23</issue>), <fpage>7733</fpage>–<lpage>7741</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kay</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Nishimoto</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Encoding and decoding in fMRI</article-title>. <source>NeuroImage</source>, <volume>56</volume>(<issue>2</issue>), <fpage>400</fpage>–<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ni</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Ray</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Tuned normalization explains the size of attention modulations</article-title>. <source>Neuron</source>, <volume>73</volume>(<issue>4</issue>), <fpage>803</fpage>–<lpage>813</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nover</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>C. H.</given-names></string-name>, &amp; <string-name><surname>DeAngelis</surname>, <given-names>G. C.</given-names></string-name></person-group> (<year>2005</year>). <article-title>A logarithmic, scale-invariant representation of speed in macaque middle temporal area accounts for speed discrimination performance</article-title>. <source>J Neurosci</source>, <volume>25</volume>(<issue>43</issue>), <fpage>10049</fpage>–<lpage>10060</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orban</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Kennedy</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Bullier</surname>, <given-names>J.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Velocity sensitivity and direction selectivity of neurons in areas V1 and V2 of the monkey: influence of eccentricity</article-title>. <source>J Neurophysiol</source>, <volume>56</volume>(<issue>2</issue>), <fpage>462</fpage>–<lpage>480</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orhan</surname>, <given-names>A. E.</given-names></string-name>, &amp; <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Neural population coding of multiple stimuli</article-title>. <source>J Neurosci</source>. <volume>35</volume>, <fpage>3825</fpage>–<lpage>3841</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pack</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>Hunter</surname>, <given-names>J. N.</given-names></string-name>, &amp; <string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Contrast dependence of suppressive influences in cortical area MT of alert macaque</article-title>. <source>J Neurophysiol</source>, <volume>93</volume>(<issue>3</issue>), <fpage>1809</fpage>–<lpage>1815</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pasternak</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Tadin</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Linking Neuronal Direction Selectivity to Perceptual Decisions About Visual Motion</article-title>. <source>Annu Rev Vis Sci</source>, <volume>6</volume>, <fpage>335</fpage>–<lpage>362</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Perrone</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Thiele</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Speed skills: measuring the visual speed analyzing properties of primate MT neurons</article-title>. <source>Nat Neurosci</source>, <volume>4</volume>(<issue>5</issue>), <fpage>526</fpage>–<lpage>532</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Snyder</surname>, <given-names>L. H.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Computational approaches to sensorimotor transformations</article-title>. <source>Nat Neurosci</source>, <volume>3</volume> <issue>Suppl</issue>, <fpage>1192</fpage>–<lpage>1198</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Zemel</surname>, <given-names>R. S.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Inference and computation with population codes</article-title>. <source>Annu Rev Neurosci</source>, <volume>26</volume>, <fpage>381</fpage>–<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Estimating target speed from the population response in visual area MT</article-title>. <source>J Neurosci</source>, <volume>24</volume>(<issue>8</issue>), <fpage>1907</fpage>–<lpage>1916</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Cassanello</surname>, <given-names>C. R.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2003</year>). <article-title>The neural representation of speed in macaque area MT/V5</article-title>. <source>J Neurosci</source>, <volume>23</volume>(<issue>13</issue>), <fpage>5650</fpage>–<lpage>5661</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Tuning for spatiotemporal frequency and speed in directionally selective neurons of macaque striate cortex</article-title>. <source>J Neurosci</source>, <volume>26</volume>(<issue>11</issue>), <fpage>2941</fpage>–<lpage>2950</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qian</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name></person-group> (<year>1994</year>). <article-title>Transparent motion perception as detection of unbalanced motion signals. II. Physiology</article-title>. <source>J Neurosci</source>, <volume>14</volume>(<issue>12</issue>), <fpage>7367</fpage>–<lpage>7380</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Recanzone</surname>, <given-names>G. H.</given-names></string-name>, <string-name><surname>Wurtz</surname>, <given-names>R. H.</given-names></string-name> &amp; <string-name><surname>Schwarz</surname>, <given-names>U.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Responses of MT and MST Neurons to One and Two Moving Objects in the Receptive Field</article-title>. <source>Journal of Neurophysiology</source>, <volume>78</volume>(<issue>6</issue>), <fpage>2904</fpage>–<lpage>2915</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Hierarchical models of object recognition in cortex</article-title>. <source>Nat Neurosci</source>, <volume>2</volume>(<issue>11</issue>), <fpage>1019</fpage>–<lpage>1025</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rocchi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Ledgeway</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Webb</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Criterion-free measurement of motion transparency perception at different speeds</article-title>. <source>Journal of Vision</source>, <volume>18</volume>(<issue>4</issue>).</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rockland</surname>, <given-names>K. S.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Visual cortical organization at the single axon level: a beginning</article-title>. <source>Neurosci Res</source>, <volume>42</volume>(<issue>3</issue>), <fpage>155</fpage>–<lpage>166</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rust</surname>, <given-names>N. C.</given-names></string-name>, <string-name><surname>Mante</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>How MT cells analyze the motion of visual patterns</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>(<issue>11</issue>), <fpage>1421</fpage>–<lpage>1431</lpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schmehl</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Caruso</surname>, <given-names>V. C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Jun</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Willett</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Mohl</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Ruff</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ebihara</surname>, <given-names>A. F.</given-names></string-name>, <string-name><surname>Freiwald</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name> &amp; <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Multiple objects evoke fluctuating responses in several regions of the visual pathway</article-title>. <source>eLife</source>, <volume>13</volume>, <elocation-id>e91129</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.91129</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schoppmann</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Hoffmann</surname>, <given-names>K. P.</given-names></string-name></person-group> (<year>1976</year>). <article-title>Continuous mapping of direction selectivity in the cat’s visual cortex</article-title>. <source>Neurosci Lett</source>, <volume>2</volume>(<issue>4</issue>), <fpage>177</fpage>–<lpage>181</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Olshausen</surname>, <given-names>B. A.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Natural image statistics and neural representation</article-title>. <source>Annu Rev Neurosci</source>, <volume>24</volume>, <fpage>1193</fpage>–<lpage>1216</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Snowden</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Erickson</surname>, <given-names>R. G.</given-names></string-name>, &amp; <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name></person-group> (<year>1991</year>). <article-title>The response of area MT and V1 neurons to transparent motion</article-title>. <source>J Neurosci</source>, <volume>11</volume>(<issue>9</issue>), <fpage>2768</fpage>–<lpage>2785</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name>, &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Noise characteristics and prior expectations in human visual speed perception</article-title>. <source>Nat Neurosci</source>, <volume>9</volume>(<issue>4</issue>), <fpage>578</fpage>–<lpage>585</lpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name></person-group> (<year>1992</year>). <article-title>Neural correlates of perceptual motion coherence</article-title>. <source>Nature</source>, <volume>358</volume>(<issue>6385</issue>), <fpage>412</fpage>–<lpage>414</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hol</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Rauber</surname>, <given-names>H.-J.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Seeing multiple directions of motion—physiology and psychophysics</article-title>. <source>Nature Neuroscience</source>, <volume>3</volume>(<issue>3</issue>), <fpage>270</fpage>–<lpage>276</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ungerleider</surname>, <given-names>L. G.</given-names></string-name>, &amp; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Cortical connections of visual area MT in the macaque</article-title>. <source>J Comp Neurol</source>, <volume>248</volume>(<issue>2</issue>), <fpage>190</fpage>–<lpage>222</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ungerleider</surname>, <given-names>L. G.</given-names></string-name>, &amp; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Cortical connections of visual area MT in the macaque</article-title>. <source>J Comp Neurol</source>, <volume>248</volume>(<issue>2</issue>), <fpage>190</fpage>–<lpage>222</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vintch</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Gardner</surname>, <given-names>J. L.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Cortical Correlates of Human Motion Perception Biases</article-title>. <source>The Journal of Neuroscience</source>, <volume>34</volume>(<issue>7</issue>), <fpage>2592</fpage>–<lpage>2604</lpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weiss</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Adelson</surname>, <given-names>E. H.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Motion illusions as optimal percepts</article-title>. <source>Nat Neurosci</source>, <volume>5</volume>(<issue>6</issue>), <fpage>598</fpage>–<lpage>604</lpage>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wiesner</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baumgart</surname>, <given-names>I. W.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Spatial Arrangement Drastically Changes the Neural Representation of Multiple Visual Stimuli That Compete in More Than One Feature Domain</article-title>. <source>J Neurosci</source>, <volume>40</volume>(<issue>9</issue>), <fpage>1834</fpage>–<lpage>1848</lpage>.</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Distributed and Dynamic Neural Encoding of Multiple Motion Directions of Transparently Moving Stimuli in Cortical Area MT</article-title>. <source>J Neurosci</source>, <volume>35</volume>(<issue>49</issue>), <fpage>16180</fpage>–<lpage>16198</lpage>.</mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Niu</surname>, <given-names>Y. Q.</given-names></string-name>, <string-name><surname>Wiesner</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Normalization of neuronal responses in cortical area MT across signal strengths and motion directions</article-title>. <source>J Neurophysiol</source>, <volume>112</volume>(<issue>6</issue>), <fpage>1291</fpage>–<lpage>1306</lpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Relationship between adapted neural population responses in MT and motion adaptation in speed and direction of smooth-pursuit eye movements</article-title>. <source>J Neurophysiol</source>, <volume>101</volume>(<issue>5</issue>), <fpage>2693</fpage>–<lpage>2707</lpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zemel</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Probabilistic interpretation of population codes</article-title>. <source>Neural Comput</source>, <volume>10</volume>(<issue>2</issue>), <fpage>403</fpage>–<lpage>430</lpage>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>L. Q.</given-names></string-name>, &amp; <string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Prior Expectations in Visual Speed Perception Predict Encoding Characteristics of Neurons in Area MT</article-title>. <source>J Neurosci</source>, <volume>42</volume>(<issue>14</issue>), <fpage>2951</fpage>–<lpage>2962</lpage>.</mixed-citation></ref>
<ref id="c86s"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zoccolan</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cox</surname>, <given-names>D. D.</given-names></string-name> &amp; <string-name><surname>DiCarlo</surname>, <given-names>J. J.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Multiple Object Response Normalization in Monkey Inferotemporal Cortex</article-title>. <source>The Journal of Neuroscience</source>, <volume>25</volume>(<issue>36</issue>), <fpage>8150</fpage>–<lpage>8164</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.3.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Groh</surname>
<given-names>Jennifer M</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Duke University</institution>
</institution-wrap>, <city>Durham</city>, <country country="US">United States</country></aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion. The study is <bold>valuable</bold> because little is known about how the visual pathway segments and preserves information about multiple stimuli, and the study involves perceptual reports from both humans and one monkey regarding whether there are one or two speeds in the stimulus. The study presents <bold>compelling</bold> evidence that (on average) MT neurons shift from faster-speed-takes-all at low speeds to representing the average of the two speeds at higher speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information could potentially be lost in an average response as described here, depending on assumptions about how MT activity is evaluated by other visual areas.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.3.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Most studies in sensory neuroscience investigate how individual sensory stimuli are represented in the brain (e.g., the motion or color of a single object). This study starts tackling the more difficult question of how the brain represents multiple stimuli simultaneously and how these representations help to segregate objects from cluttered scenes with overlapping objects.</p>
<p>Strengths:</p>
<p>The authors first document the ability of humans to segregate two motion patterns based on differences in speed. Then they show that a monkey's performance is largely similar; thus establishing the monkey as a good model to study the underlying neural representations.</p>
<p>Careful quantification of the neural responses in the middle temporal area during the simultaneous presentation of fast and slow speeds leads to the surprising finding that, at low average speeds, many neurons respond as if the slowest speed is not present, while they show averaged responses at high speeds. This unexpected complexity of the integration of multiple stimuli is key to the model developed in this paper.</p>
<p>One experiment in which attention is drawn away from the receptive field supports the claim that this is not due to the involuntary capture of attention by fast speeds.</p>
<p>A classifier using the neuronal response and trained to distinguish single speed from bi-speed stimuli shows a similar overall performance and dependence on the mean speed as the monkey. This supports the claim that these neurons may indeed underlie the animal's decision process.</p>
<p>The authors expand the well-established divisive normalization model to capture the responses to bi-speed stimuli. The incremental modeling (eq 9 and 10) clarifies which aspects of the tuning curves are captured by the parameters.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.3.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion.</p>
<p>Strengths:</p>
<p>The study is valuable because little is known about how the visual pathway segments and preserves information about multiple stimuli. The study presents compelling evidence that (on average) MT neurons shift from faster-speed-takes-all at low speeds to representing the average of the two speeds at higher speeds. An additional strength of the study is the inclusion of perceptual reports from both humans and one monkey participant performing a task in which they judged whether the stimuli involved one vs two different speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information is potentially lost in an average response as described here.</p>
<p>Reviewing Editor comment on revised version:</p>
<p>The remaining concern was resolved.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.3.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Huang</surname>
<given-names>Xin</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ghimire</surname>
<given-names>Bikalpa</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chakrala</surname>
<given-names>Anjani Sreeprada</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wiesner</surname>
<given-names>Steven</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the previous reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations for the authors):</bold></p>
<p>The authors have done an excellent job of addressing most comments, but my concerns about Figure 5 remain. I appreciate the authors' efforts to address the problem involving Rs being part of the computation on both the x and y axes of Figure 5, but addressing this via simulation addresses statistical significance but overlooks effect size. I think the authors may have misunderstood my original suggestion, so I will attempt to explain it better here. Since &quot;Rs&quot; is an average across all trials, the trials could be subdivided in two halves to compute two separate averages - for example, an average of the even numbered trials and an average of the odd numbered trials. Then you would use the &quot;Rs&quot; from the even numbered trials for one axis and the &quot;Rs&quot; from the odd numbered trials for the other. You would then plot R-Rs_even vs Rf-Rs_odd. This would remove the confound from this figure, and allow the text/interpretation to be largely unchanged (assuming the results continue to look as they do).</p>
</disp-quote>
<p>We have added a description and the result of the new analysis (line #321 to #332), and a supplementary figure (Suppl. Fig. 1) (line #1464 to #1477).</p>
<p>“We calculated 𝑅<sub>𝑠</sub> in the ordinate and abscissa of Figure 5A-E using responses averaged across different subsets of trials, such that 𝑅<sub>𝑠</sub> was no longer a common term in the ordinate and abscissa. For each neuron, we determined 𝑅<sub>𝑠1</sub> by averaging the firing rates of 𝑅<sub>𝑠</sub> across half of the recorded trials, selected randomly. We also determined 𝑅<sub>𝑠2</sub> by averaging the firing rates of 𝑅<sub>𝑠</sub> across the rest of the trials.  We regressed (𝑅 − 𝑅<sub>𝑠1</sub> )  on (𝑅<sub>𝑓</sub> − 𝑅<sub>𝑠2</sub>) , as well as (𝑅<sub>𝑠</sub> - 𝑅<sub>𝑠2</sub>)  on (𝑅<sub>𝑓</sub> − 𝑅<sub>𝑠1</sub>), and repeated the procedure 50 times. The averaged slopes obtained with 𝑅<sub>𝑠</sub> from the split trials showed the same pattern as those using 𝑅<sub>𝑠</sub> from all trials (Table 1 and Supplementary Fig. 1), although the coefficient of determination was slightly reduced (Table 1). For ×4 speed separation, the slopes were nearly identical to those shown in Figure 5F1. For ×2 speed separation, the slopes were slightly smaller than those in Figure 5F2, but followed the same pattern (Supplementary Fig. 1). Together, these analysis results confirmed the faster-speed bias at the slow stimulus speeds, and the change of the response weights as stimulus speeds increased.”</p>
<disp-quote content-type="editor-comment">
<p>An additional remaining item concerns the terminology weighted sum, in the context of the constraint that wf and ws must sum to one. My opinion is that it is non-standard to use weighted sum when the computation is a weighted average, but as long as the authors make their meaning clear, the reader will be able to follow. I suggest adding some phrasing to explain to the reader the shift in interpretation from the more general weighted sum to the more constrained weighted average. Specifically, &quot;weighted sum&quot; first appears on line 268, and then the additional constraint of ws + wf =1 is introduced on line 278. Somewhere around line 278, it would be useful to include a sentence stating that this constraint means the weighted sum is constrained to be a weighted average.</p>
</disp-quote>
<p>Thanks for the suggestion. We have modified the text as follows. Since we made other modifications in the text, the line numbers are slightly different from the last version.</p>
<p>Line #274 to 275:</p>
<p>“Since it is not possible to solve for both variables, 𝑤<sub>𝑠</sub> and 𝑤<sub>𝑓</sub>, from a single equation (Eq. 5) with three data points, we introduced an additional constraint: 𝑤<sub>𝑠</sub> + 𝑤<sub>𝑓</sub> =1. With this constraint, the weighted sum becomes a weighted average.”</p>
<p>Also on line #309:</p>
<p>“First, at each speed pair and for each of the 100 neurons in the data sample shown in Figure 5, we simulated the response to the bi-speed stimuli (𝑅<sub>𝑒</sub>) as a randomly weighted average of 𝑅<sub>𝑓</sub> and 𝑅<sub>𝑠</sub> of the same neuron.</p>
<disp-formula id="sa3equ1">
<graphic mime-subtype="jpg" xlink:href="elife-94835-sa3-equ1.jpg" mimetype="image"/>
</disp-formula>
<p>in which 𝑎 was a randomly generated weight (between 0 and 1) for 𝑅<sub>𝑓</sub>, and the weights for 𝑅<sub>𝑓</sub> and 𝑅<sub>𝑠</sub> summed to one.”</p>
</body>
</sub-article>
</article>