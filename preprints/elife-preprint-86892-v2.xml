<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">86892</article-id>
<article-id pub-id-type="doi">10.7554/eLife.86892</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.86892.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Judging the difficulty of perceptual decisions</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Löffler</surname>
<given-names>Anne</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2572-4748</contrib-id>
<name>
<surname>Zylberberg</surname>
<given-names>Ariel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shadlen</surname>
<given-names>Michael N.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2011-2790</contrib-id>
<name>
<surname>Wolpert</surname>
<given-names>Daniel M.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Zuckerman Mind Brain Behavior Institute, Columbia University</institution>, New York, NY 10027, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Department of Neuroscience, Columbia University</institution>, New York, NY 10027, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Kavli Institute for Brain Science, Columbia University</institution>, NY 10027, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Howard Hughes Medical Institute, Columbia University</institution>, NY 10027, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Wyart</surname>
<given-names>Valentin</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Inserm</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>For correspondence: <email>wolpert@columbia.edu</email> (DMW)</corresp>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-05-05">
<day>05</day>
<month>05</month>
<year>2023</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2023-09-12">
<day>12</day>
<month>09</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP86892</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-02-13">
<day>13</day>
<month>02</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-02-14">
<day>14</day>
<month>02</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.13.528254"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2023-05-05">
<day>05</day>
<month>05</month>
<year>2023</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.86892.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.86892.1.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.86892.1.sa2">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.86892.1.sa1">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.86892.1.sa0">Reviewer #3 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Löffler et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Löffler et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-86892-v2.pdf"/>
<abstract>
<title>Abstract</title><p>Deciding how difficult it is going to be to perform a task allows us to choose between tasks, allocate appropriate resources, and predict future performance. To be useful for planning, difficulty judgments should not require completion of the task. Here we examine the processes underlying difficulty judgments in a perceptual decision making task. Participants viewed two patches of dynamic random dots, which were colored blue or yellow stochastically on each appearance. Stimulus coherence (the probability, <italic>p</italic><sub>blue</sub>, of a dot being blue) varied across trials and patches thus establishing difficulty, |<italic>p</italic><sub>blue</sub> − 0.5|. Participants were asked to indicate for which patch it would be easier to decide the dominant color. Accuracy in difficulty decisions improved with the difference in the stimulus difficulties, whereas the reaction times were not determined solely by this quantity. For example, when the patches shared the same difficulty, reaction times were shorter for easier stimuli. A comparison of several models of difficulty judgment suggested that participants compare the absolute accumulated evidence from each stimulus and terminate their decision when they differed by a set amount. The model predicts that when the dominant color of each stimulus is known, reaction times should depend only on the difference in difficulty, which we confirm empirically. We also show that this model is preferred to one that compares the confidence one would have in making each decision. The results extend evidence accumulation models, used to explain choice, reaction time and confidence to prospective judgments of difficulty.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>D.M.W is a consultant to CTRL-Labs Inc., in the Reality Labs Division of Meta. This entity did not support or influence this work. The authors declare no other competing interests.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Revised based on eLife reviewers comments</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Estimating the difficulty of different tasks we might perform allows us to decide which task to engage in (<bold><italic><xref ref-type="bibr" rid="c4">Bennett-Pierre et al., 2018</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c47">Wisniewski et al., 2015</xref></italic></bold>), allocate the necessary amount of effort or cognitive control (<bold><italic><xref ref-type="bibr" rid="c39">Shenhav et al., 2013</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c13">Dunn et al., 2019</xref></italic></bold>), and predict our ability to perform the task successfully (<bold><italic><xref ref-type="bibr" rid="c30">Morgan et al., 2014</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c40">Siedlecka et al., 2016</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c16">Fleming et al., 2016</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c31">Moskowitz et al., 2020</xref></italic></bold>). The need for difficulty estimation arises in a wide variety of human endeavors, from attempting different recipes and hiking routes to learning different languages. For example, consider a musician who is deciding which piece to learn to improve her skills. If the piece is too easy, she is likely to be bored, while if the piece is too difficult she may be frustrated, learning very little in either case. To make the correct choice, she must accurately estimate the difficulty of each potential piece given her current abilities. Attempting to learn each piece would lead to accurate estimates of their difficulty, yet this defies the purpose, since the difficulty estimation was sought to decide if the piece was worth learning in the first place. Alternatively, she could allocate a fixed period of time or learn the first few bars of each piece, or use cues like the length, key or tempo of each piece to estimate their difficulty.</p>
<p>Past studies of difficulty judgments have mainly relied on complex tasks, like 5<sup>th</sup> grade students judging the difficulty of remembering a sentence (<bold><italic><xref ref-type="bibr" rid="c42">Stein et al., 1982</xref></italic></bold>) or physics teachers evaluating the difficulty of different exam questions (<bold><italic><xref ref-type="bibr" rid="c14">Fakcharoenphol et al., 2015</xref></italic></bold>). This line of research highlights the important role that cues and heuristics play in estimating task difficulty (<bold><italic><xref ref-type="bibr" rid="c46">Vangsness and Young, 2019</xref></italic></bold>). While the use of complex naturalistic tasks ensures that difficulty estimates are realistic, their complexity precludes quantitative modeling and thus the identification of the inference process underlying the formation of difficulty judgments.</p>
<p>Tasks that require consideration of multiple samples of evidence presented sequentially over time have advanced our understanding of the computational and neurophysiological underpinnings of decision making. In such tasks, the signal-to-noise ratio of the samples is varied across trials, and on each trial we can obtain the objective measures of choice (correct vs. incorrect) and reaction time. However, metacognitive judgments about the decision process itself, such as confidence and difficulty are also of interest. Decision confidence is often defined as the probability that a choice, just made, is correct or appropriate (<bold><italic><xref ref-type="bibr" rid="c34">Peirce and Jastrow, 1884</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c24">Kiani and Shadlen, 2009</xref></italic></bold>). Similarly, difficulty can be considered a metacognitive judgment, like confidence. In fact, confidence in a decision one has made can be converted to difficulty (the signal-to-noise ratio) if one knows how long it took to reach the decision (<bold><italic><xref ref-type="bibr" rid="c25">Kiani et al., 2014</xref></italic></bold>). In this case confidence and difficulty are retrospective metacognitive judgments that emphasize, respectively, the probability of having chosen correctly and the effort that was required.</p>
<p>Difficulty estimation, can be prospective or retrospective, and can even be independent of task performance (<bold><italic><xref ref-type="bibr" rid="c11">Desender et al., 2017</xref></italic></bold>). For example, the musician may learn a piece and then judge its difficulty (a retrospective estimate), use her prior knowledge about the composer (a prospective estimate), or learn the first few bars and extrapolate its difficulty to the rest of the piece (both prospective and retrospective). Our interest is in prospective judgments of difficulty, for which confidence in the outcome of the decision can be viewed only as a prediction, governed by an assessment of difficulty and introspection about one’s own acumen.</p>
<p>Here we address how a subjective sense of difficulty is constructed from a sequence of evidence samples obtained from the environment, and how this difficulty decision is terminated. In our main experiment, human participants were presented with two visual stimuli (two flickering blue and yellow patches of dots) and had to report for which one it would be less difficult to make a decision about the dominant color. Our results show that judgments of difficulty obey a sequential sampling process similar to one that would be used to make a single decision about perceptual category. However, rather than accumulating evidence for color, difficulty judgments rely on tracking the difference in the absolute accumulated evidence for color judgments for the two stimuli.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>Participants performed variants of a perceptual task that required binary decisions about either one or two patches of dynamic random dot displays. In some blocks they reported the dominant color of one patch (Color judgment) or which of the two patches it would be easier to make a color judgment about (Difficulty judgment). The task was performed as a response time version (Experiment 1). We then evaluate models that explain the difficulty judgements and RTs. The best model makes a prediction, that we test in a second experiment.</p>
<sec id="s2a">
<title>Color judgments in a reaction time task (Experiment 1a)</title>
<p>Participants were first exposed to a color judgment task in which they were asked to decide whether the dominant color of a patch of dynamic random dots was yellow or blue (<xref rid="fig1" ref-type="fig">Figure 1a</xref>) over a range of difficulties (<bold><italic><xref ref-type="bibr" rid="c28">Mante et al., 2013</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c3">Bakkour et al., 2019</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c23">Kang et al., 2021</xref></italic></bold>). The difficulty of the color choice was conferred by the probability that a dot would be colored blue (<italic>p</italic><sub>blue</sub>) or yellow (1 − <italic>p</italic><sub>blue</sub>) on each frame. Therefore, the signed quantity <italic>C</italic><sup>±</sup> = 2<sub>(</sub><italic>p</italic><sub>blue</sub> − 0.5<sub>)</sub>, termed the color coherence, takes on positive values for blue dominant stimuli. We refer to the unsigned quantity <italic>C</italic> = |<italic>C</italic><sup>±</sup>| as color strength and this took on 6 different levels {0, 0.128, 0.256, 0.384, 0.512, 0.64}. The color strength determines the difficulty of the task with smaller strengths being more difficult. This task served to familiarize the participant with the task and instill the intuition that some decisions are more difficult than others. Only participants who performed above a set criterion (see Methods) were invited to perform the main experiment. We refer to this task as a color judgment.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Reaction time color and difficulty judgment tasks (Experiment 1). <bold>(a)</bold> Schematic of the color judgment task. Participants judged the dominant color of a single random-dot stimulus consisting of blue and yellow dots. <bold>(b)</bold> Proportion of correct choices (<italic>top</italic>) and reaction time (<italic>bottom</italic>) as a function of color strength. Solid lines show the average of fits of a standard drift diffusion model to each participant’s choices and RTs. Values of the fit parameters are shown in <xref rid="tbls1" ref-type="table">Table S1</xref>. Data points show mean ± 1 SEM from 20 participants. <bold>(c)</bold> Schematic of the difficulty judgment task. Participants decided for which of the two stimuli it was easier to judge the dominant color, regardless of whether that stimulus was blue or yellow dominant. <bold>(d)</bold> Proportion of trials in which stimulus 1 (S1) was chosen as the easier stimulus (top) and reaction times (bottom) as a function of the strength of S1 (abscissa) and S2 (colors). Open circles identify conditions where both patches have the same color strength (also plotted in inset). Data points show mean ± 1 SEM from 20 participants.</p></caption>
<graphic xlink:href="528254v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig1" ref-type="fig">Figure 1b</xref> shows choice accuracy and reaction times (RTs) averaged across (<italic>N</italic> = 20) participants for color judgments. Participants’ choices and RTs varied according to color strength. As expected, participants chose the correct color more often, and they responded faster, when the strength increased. The data are well described by a standard drift-diffusion model (black lines) that explains the choice and RT by applying a stopping bound to the accumulation of the noisy color evidence (see Methods). We refer to the accumulation of color evidence (blue minus yellow) as the color decision-variable, <italic>DV</italic>.</p>
</sec>
<sec id="s2b">
<title>Difficulty judgments in a reaction time task (Experiment 1b)</title>
<p>The main experiment required participants to make difficulty judgments (<xref rid="fig1" ref-type="fig">Figure 1c</xref>) of two stimuli simultaneously presented to the left and right of a central fixation cross. Participants had to select the stimulus for which they thought it would be easier to decide what the dominant color would be, regardless of whether the patch was yellow or blue dominant. Importantly, in the difficulty judgment task, participants were never asked to report color decisions for either stimulus. In this task all 12 × 12 coherence combinations of the two stimuli were presented in a randomized order (see Methods). We refer to this task as a difficulty judgment.</p>
<p>In the difficulty task, choice and RTs were affected by both the left (S1) and right (S2) stimulus strengths (<xref rid="fig1" ref-type="fig">Figure 1d</xref>). Participants chose S1 more often with increasing strength of S1 (<xref rid="fig1" ref-type="fig">Figure 1d</xref> top, abscissa) and decreasing strength of S2, and <italic>vice versa</italic>. The RTs exhibit a more complex pattern. For a given S1 strength (<xref rid="fig1" ref-type="fig">Figure 1d</xref> bottom, abscissa), RTs tend to be slowest when the strength of both stimuli are the same (open symbols), and the RTs accompanying these same matched difficulties are shorter for higher strength (<xref rid="fig1" ref-type="fig">Figure 1d</xref> bottom, inset). Therefore, the RTs are not simply a function of the difference between the two strengths. For example, RTs were significantly longer in the hard-hard (0:0, leftmost point in inset) combination (mean = 1.99 s, sd = 0.6) compared to easy-easy (0.64:0.64, rightmost point in inset) conditions (mean 1.30 s, sd = 0.36, difference in RT <italic>t</italic>(19) = 8.63, <italic>p</italic> &lt; 0.001, <italic>CI</italic>[0.52 − 0.85]). These tendencies lead to a criss-cross pattern in the RTs. For example, when S1 is difficult the shortest RT occurs when S2 is easy, whereas when S1 is easy, the longest RT occurs when S2 is easy. This leads to an inversion in the order of colors in the leftmost and rightmost stacks of points.</p>
<p>We developed four models (<xref rid="fig2" ref-type="fig">Fig. 2</xref>) of difficulty decisions and examined whether they could account for the choice and RT data. The models we consider assume that sensory evidence accumulates over time. This is a reasonable assumption because these models have been very successful in explaining choice, RT, and even confidence in many perceptual and mnemonic decision tasks, including color discrimination (<bold><italic><xref ref-type="bibr" rid="c3">Bakkour et al., 2019</xref></italic></bold>; Gold et al., (2007)). All models assume that for each stimulus (S1 and S2), momentary color evidence (MCE) for blue vs. yellow (positive for blue) is extracted at each point in time. The models differ in how they use this MCE to determine which stimulus is easier.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Models of difficulty judgments. In each model, momentary color evidence (MCE) is obtained simultaneously from each of the two stimuli as the difference in proportion of blue vs. yellow dots on each frame. The models differ in i) how this momentary evidence is accumulated into a decision variable (second row) and ii) how the bounds are set for the decision (third row). For each model, an example of a simulation of a single-trial (fourth row) is illustrated in the 2D space of the decision variables <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub> for the left (S1) and right (S2) stimuli.Each simulation shows a biased random walk that starts at the origin and terminates when it reaches one of the decision bounds. Decision bounds in green and blue correspond to S1 and S2 being judged the easier decision, respectively. For clarity, all bounds are illustrated as time-independent (although in the model they are allowed to collapse over time). The models predict different patterns of reaction times (RTs; bottom row) for different difficulty combinations of S1 (abscissa) and S2 (magenta = easy, yellow = hard). <bold>(a)</bold> The Race model, <bold>(b)</bold> the Difference model, <bold>(c)</bold> the Two-step model and <bold>(d)</bold> the Absolute momentary evidence model (gray area is not reachable as all accumulation is positive). See main text for model details.</p></caption>
<graphic xlink:href="528254v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Race model</title>
<p>In the <italic>Race model</italic>, the difficulty decision is determined by which of two color decisions terminates first, motivated by the regularity that more difficult stimuli typically require more samples of evidence.</p>
<p>In this model, MCE is accumulated into two independent decision variables, <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>, which represent the accumulated color evidence for the left and right stimulus, respectively. The single-trial example in <xref rid="fig2" ref-type="fig">Fig. 2a</xref> shows a schematic of the decision process, plotted as <italic>DV</italic><sub><italic>S</italic>2</sub> against <italic>DV</italic><sub><italic>S</italic>1</sub>. In this space the bounds form a square at ±<italic>B</italic> in each dimension. The decision variables both start at zero so that the trajectory starts at the origin and evolves as a function of time. The time dimension is not shown, so the displayed trajectory is the path of the decision variables up until the decision is made. The trajectory is confined to a space bounded by the green and blue termination bounds. The bounds are actually collapsing as a function of time but form a square at any point in time. Trajectories that reach the green or blue bound lead to S1 or S2 being judged as easier, respectively. In the example shown, S1 is judged as easier.</p>
<p>The bottom row of <xref rid="fig2" ref-type="fig">Fig. 2a</xref> shows the predicted pattern of RTs. When both color decisions are hard, difficulty choices are slow (long RT) since they depend on the winner of two slow processes. RTs decrease as either of the two color decisions becomes easier. When both color decisions are the easiest (0.64:0.64), RTs should be fastest since they reflect the minimum of two fast processes. This model, therefore, predicts that the shortest RTs occur when both stimuli are easiest, which is clearly contradicted by the data (e.g., the rightmost stack of points in <xref rid="fig1" ref-type="fig">Figure 1d</xref>, bottom).</p>
</sec>
<sec id="s2d">
<title>Difference model</title>
<p>In the <italic>Difference model</italic> (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>), difficulty is determined by the difference between the absolute values of the decision variables, motivated by the intuition that the accumulation of weaker evidence is unlikely to traverse far from the origin compared to the accumulation of stronger evidence.</p>
<p>In this model the difficulty decision is made by computing |<italic>DV</italic><sub><italic>S</italic>1</sub>|−|<italic>DV</italic><sub><italic>S</italic>2</sub>|. When this difference value reaches an upper/lower bound, then S1/S2 is chosen as the easier one. Thus, in contrast to the Race model, the decision boundary is applied to |<italic>DV</italic><sub><italic>S</italic>1</sub>| − |<italic>DV</italic><sub><italic>S</italic>2</sub>|, instead of the individual <italic>DV</italic> s. This gives rise to bounds that parallel the positive and negative diagonals on which |<italic>DV</italic><sub><italic>S</italic>1</sub>|−|<italic>DV</italic><sub><italic>S</italic>2</sub>| = 0. This leads to bounds that form channels emanating from the origin. Note that the four apices on the bounds are at (0, ±<italic>B</italic>) and (±<italic>B</italic>, 0), which correspond to where a decision would be made, that is |<italic>DV</italic><sub><italic>S</italic>1</sub>|−|<italic>DV</italic><sub><italic>S</italic>2</sub>| = ±<italic>B</italic>. Similarly, all other points on the bounds correspond to this difference being equal to ±<italic>B</italic>. Again, trajectories that reach the green or blue bound lead to S1 or S2 being judged as easier, respectively. In this example S2 is judged as easier.</p>
<p>The Difference model predicts a criss-cross pattern of RTs that is qualitatively similar to the data. In the Difference model the RT is related to the difference in the absolute coherences of each stimulus. In general, the larger the unsigned difference the shorter the RT. Therefore on the left of the RT graph, where one of the stimuli (abscissa) is hard, RT will be longer when the other stimulus is also hard (yellow, same coherence) compared to when it is easy (purple, large coherence difference). In contrast on the right hand side of the RT graph where one stimulus is easy (abscissa) the RT will now be longer when the other stimulus is also easy (purple, no coherence difference) and shorter when the other coherence is harder (yellow). This leads to the criss-cross observed in the simulation. The model also predicts that the easy-easy comparison takes less time than the hard-hard comparison (right end of purple compared to left end of gold). We will supply an intuition for this prediction under Experiment 2, which is designed to test it.</p>
</sec>
<sec id="s2e">
<title>Two-step model</title>
<p>The <italic>Two-step model</italic> combines elements of the first two models and involves a two-step process. The motivation here is that if the dominant color of each stimulus were known, the difficulty decision would be simpler to compute and more accurate. Therefore, this model operates in two steps, the first of which estimates the dominant color of each stimulus and the second judges difficulty based on these estimates.</p>
<p>The Two-step model (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>) first estimates the signs of the two strengths with a mini color decision (made at time <italic>t</italic><sub>mini</sub>). Similar to the Race model, the mini decision terminates as soon as one of the DVs has reached a bound. In the second step, further evidence is accumulated and a difficulty decision is made when
<disp-formula>
<alternatives><graphic xlink:href="528254v2_ueqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
For example, if S1 is estimated to have a positive coherence and S2 a negative coherence the decision should be made when <italic>DV</italic><sub><italic>S</italic>1</sub> +<italic>DV</italic><sub><italic>S</italic>2</sub> = ±<italic>B</italic>, whereas if both coherences are estimated to be positive the decision should be made when <italic>DV</italic><sub><italic>S</italic>1</sub> − <italic>DV</italic><sub><italic>S</italic>2</sub> = ±<italic>B</italic>. Note that if no further information is accumulated after the mini-decision, then the Two-step model becomes identical to the Race model. Differences in predictions between the Difference and Two-step arise from trials in which there is a mismatch between the inferred dominant colors from the Two-step model and the color associated with the final DVs in the Difference model.</p>
<p>This model predicts a similar RT pattern to the Difference model, but it requires one additional parameter: a decision bound for the initial color choice <italic>B</italic><sub><italic>mini</italic></sub>. The higher the bound, the longer the initial color decision will take, but the more accurate the estimate of the sign of each coherence will be. When both stimuli are hard, the initial color choice will be slow, thus causing overall longer RTs for hard-hard compared to easy-easy conditions. Additionally, similar to the Difference model, the duration of the second step depends on the difference in difficulty. When both stimuli are equally hard (or easy), the difference in DVs will take longer to reach a bound compared to conditions where the difference in difficulty is large. Thus, similar to the Difference model, this model predicts a crossing in the pattern of RTs where decisions about easy-easy stimuli take longer than decisions about easy-hard stimuli.</p>
</sec>
<sec id="s2f">
<title>Absolute momentary evidence model</title>
<p>In the <italic>Absolute momentary evidence model</italic>, each decision variable represents the accumulated <italic>absolute</italic> momentary color evidence, as opposed to the signed evidence used in the first three models. The motivation here is the simplicity of accumulating momentary evidence bearing directly on difficulty. The obvious shortcoming is that this intuition is only valid if the samples have the same sign as the color coherence; in other words it ignores the contribution of noise.</p>
<p>In the model (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>), on each frame absolute color strength is derived from each stimulus (independent of the color dominance of each frame) and the difference between these absolute color strength is accumulated over frames. A difficulty decision is made when the difference between the DVs reaches a bound.</p>
<p>Compared to the Difference model, the Absolute momentary evidence model generally predicts faster RTs for hard-hard conditions. In the Difference model weak evidence for blue followed by weak evidence for yellow for one stimulus cancel each other out in terms of the DV for that stimulus. In contrast, in the Absolute momentary evidence model as the evidence is summed unsigned such weak evidence for each color causes an increase in DV and in general contributes to the accumulated differences between the two stimuli.</p>
</sec>
<sec id="s2g">
<title>Model fitting</title>
<p>In each model, there are two separate streams of sensory evidence—one for each stimulus. For simplicity, we illustrate the models in <xref rid="fig2" ref-type="fig">Fig. 2</xref> as if the two streams of evidence were accumulated in parallel. However, in a previous study, we showed that decisions about two perceptual features (or two stimuli) are based on serial, time-multiplexed integration of decision evidence, causing longer reaction times for double-decisions compared to decisions about a single stimulus (<bold><italic><xref ref-type="bibr" rid="c23">Kang et al., 2021</xref></italic></bold>). We include this feature in our model, but its only consequence is to expand the decision times, without affecting distinguishing features of the models (see Methods for additional explanation).</p>
<p>We fit all four models to each participant’s difficulty choices and RTs (see Methods and Model Recovery). For each model, five parameters were optimized: a drift rate <italic>k</italic> that relates coherence to the mean rate of accumulation of color evidence, three parameters controlling how each decision bound collapses over time, and a non-decision time <italic>T</italic><sub><italic>nd</italic></sub> reflecting sensory and motor processing time that add to the decision time to yield the measured reaction time. For the Two-step model, one additional parameter <italic>B</italic><sub><italic>mini</italic></sub> was required for the bound height of the initial color choice. We fit the model by maximum likelihood to each participant’s data individually.</p>
<p><xref rid="fig3" ref-type="fig">Figure 3</xref> shows model fits, averaged across participants (for parameters, see <xref rid="tbls2" ref-type="table">Tables S2</xref> to <xref rid="tbls4" ref-type="table">S4</xref> and <xref rid="tbls1" ref-type="table">Table 1</xref>). To compare the models we computed the Bayesian Information Criterion (BIC) for each model. This showed that the Difference model provided the best fit overall (group-level ΔBIC = 148.7 compared to the Two-step model, which was the second best). Compared to all other models, the Difference model was the preferred model for 12 out of 20 participants (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, bottom row). We also calculated the exceedance probability (<bold><italic><xref ref-type="bibr" rid="c43">Stephan et al., 2009</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c36">Rigoux et al., 2014</xref></italic></bold>), which measures how likely it is that any given model is more frequent than all other models in the comparison set, which across the four models gave [0, 0.97, 0.03, 0], showing that the Difference model has a probability of 0.97 of being the most frequent model, compared to 0.03 for the Two-step model.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label><caption><p>Fit parameter values for Difference model (Exp. 1).</p></caption>
<graphic xlink:href="528254v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Reaction time difficulty judgment results (Experiment 1). Difficulty choices (top row) are shown as the proportion of trials in which participants chose S1 (left stimulus) as the easier stimulus. Reaction times are shown in the middle row. Data points are averages across participants (mean ± 1 SEM; <italic>N</italic> = 20). Lines represent model fits. Bottom row: ΔBIC values for each model, relative to BIC value of the winning model for each participant (hatched bars represent values &gt; 100).</p></caption>
<graphic xlink:href="528254v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The Race model fails to capture the crossing of RTs for easy-easy vs. easy-hard stimuli since it predicts that decisions are fastest when both stimuli are easy. This model also fails systematically to explain the choice behavior (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>, top). Overall, the Race model provides the poorest fit to participants’ data (group-level ΔBIC = 930.2 from Difference model).</p>
<p>The Absolute momentary evidence model provides a better fit to participants’ choices and correctly predicts the crossing of RTs. However, it underestimates RTs when both stimuli are hard. This is because in this model, any momentary evidence (regardless of sign) contributes to the difficulty decision. Consequently, this model also did not provide a good fit to the data overall (group-level ΔBIC = 509.0 from best model).</p>
<p>Finally, the fits obtained with the Difference model and Two-step model were very similar, and both provided a good fit to participants’ data. However, the Two-step model requires an extra parameter for the initial color bound. Consequently, compared to the Two-step model, the Difference model was the preferred model for 14 out of 20 participants. Because of the similarity of these models, we verified that model recovery could distinguish between these models. We generated 200 synthetic datasets using each model and then fit them with both models. The fitting procedure correctly classified (ΔBIC| &gt; 10) the correct model with 100 and 77% accuracy for the data generated by the difference and the two-step models, respectively (see Methods).</p>
<p>In summary, we found support for a model in which difficulty is based on a moment-by-moment comparison of the absolute accumulated evidence from two stimuli.</p>
<p>Difficulty judgments with unknown vs. known color dominance (Experiment 2)</p>
<p>The Difference model predicts that behavior should change if the color dominance of each patch is known. <xref rid="fig4" ref-type="fig">Figure 4a</xref> contrast the Difference model for an easy-easy vs. a hard-hard trial. When the drift component is small (hard-hard) the density of DVs across trials (orange circle) remains near the origin. When the drift component is large (easy-easy) the density moves into one of the channels (purple circle). Therefore, more density will cross the bound in the high drift case (grey hatched area for purple vs. orange circle), leading to RTs being shorter for the easy-easy condition compared to hard-hard condition (as in <xref rid="fig3" ref-type="fig">Fig. 3</xref>). However, if the color dominance of both stimuli is known then this changes the bounds as shown in <xref rid="fig4" ref-type="fig">Fig. 4b</xref>. In this example, both patches are known to be blue (positive) dominant. In this case the DVs can be compared in a signed manner where positive evidence corresponds to information in support of the known color, leading to a bound <italic>DV</italic><sub><italic>S</italic>1</sub> − <italic>DV</italic><sub><italic>S</italic>2</sub> = ±<italic>B</italic>, that is a simple channel (as in the Two-step model). In this case both hard-hard and easy-easy trials will on average cross the bound at the same rate and faster in general than in the unknown color condition. When the dominant colors are known, (<italic>i</italic>) reaction times should be faster overall, and (<italic>ii</italic>) reaction times should only depend on the difference in strengths between the stimuli, that is on ΔC = <sub>|</sub>C<sub><italic>S</italic></sub> − C<sub><italic>S</italic>2</sub> (i.e., reaction times for 0:0 and 0.64:0.64 strengths should be the same). Note that the Two-step model becomes identical to the Difference model if the color dominance of each patch is know, obviating the need for the first step of the model.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Reaction time task for unknown vs. known color dominance. (a &amp; b)</title>
<p>Schematic illustration of the unknownvs. known-color tasks. For each condition, the dispersion of DVs is represented in the 2D space of <italic>DV</italic><sub><italic>S</italic>1</sub> (abscissa) and <italic>DV</italic><sub><italic>S</italic>2</sub> (ordinate), assuming a constant noise in the drift diffusion process independent of strength. To provide intuition colored circles show the dispersion expected without absorption at the bounds and represent contours of equal density of the decision variable. Green and blue lines represent decision boundaries (B) for S1 and S2 being easier. <bold>(a)</bold> In the unknown-color condition, the Difference model computes the difference between the two absolute DVs. <bold>(b)</bold> In the known-color condition (example shown is for both stimuli blue dominant), the model compares the signed DVs, resulting in a larger region where the DV dispersion crosses the bounds (shaded areas). Thus, when both stimuli are blue-dominant, yellow (negative) evidence for S1 contributes to the decision that S2 is the easier stimulus.</p></caption>
<graphic xlink:href="528254v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We test both of these predictions in an additional experiment on three participants, with the same basic paradigm as Experiment 1. However, in some blocks of trials, participants were informed that both stimuli would be blue dominant or both yellow dominant (‘known color’ condition). In the other blocks they did not receive any instructions about the stimulus color so that, as in Experiment 1, each stimulus could either be blue or yellow dominant (‘unknown color’ condition). For the unknown color condition, only trials in which both patches had the same color dominance were included in the analyses. This ensured better comparability with performance in the known-color blocks (where both stimuli by definition always had the same color).</p>
<p>We first replicate the findings from Experiment 1, as shown in the left column of <xref rid="fig5" ref-type="fig">Fig. 5a</xref>. To evaluate the predictions, we also plot the data as a function of the difference in strength (<xref rid="fig5" ref-type="fig">Fig. 5a</xref>, right column). This way of plotting the RT highlights the fact that the RTs depend on more than the difference in strengths (i.e., also the strengths of S2, colors). The curves are fits of the Difference model.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Reaction time task for unknown vs. known color dominance (Experiment 2a). <bold>(a)</bold> Unknown color condition. Proportion of S1 choices (top row) and reaction times (bottom row) plotted as a function of strength of S1 (left column) and difference of strengths of the two stimuli (right column). Lines show the fit of the Difference model. <bold>(b)</bold> as <bold>a</bold> for the known color condition. Lines show the predictions of behavior when the color dominance is known (correct sign applied as in <xref rid="fig7" ref-type="fig">Fig. 7b</xref>) based on the parameters obtained in the fit to <bold>a</bold>. <bold>(c)</bold> Comparison of overall choice performance and RTs in the known vs. unknown-color condition as a function of the absolute difference in strength levels (data mean ± 1 SEM across 3 participants).</p></caption>
<graphic xlink:href="528254v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref rid="fig5" ref-type="fig">Figure 5b</xref> shows the results for the same participants when the color dominance was known. The choice behavior (top row) is only subtly different from the unknown condition (<xref rid="fig5" ref-type="fig">Figure 5a</xref>) for reasons explained below. However there is a striking, qualitative difference in the pattern of RTs. Consistent with prediction, the RTs appear to depend only on the difference in strengths (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>, bottom right), and they are faster when the color dominance is known (<xref rid="fig5" ref-type="fig">Fig. 5c</xref>). Note that all solid curves accompanying the <italic>known color</italic> data in panels <xref rid="fig5" ref-type="fig">Figure 5b</xref> &amp; c are not fits but predictions of the best fitting model to the <italic>unknown color</italic> condition.</p>
<p>To quantify the extent to which the difference in strengths (ΔC) explains RTs in the known vs. unknown conditions, we compared the variance explained by the six unique ΔC levels for the two conditions. The increase in variance explained under the known color dominance is highly significant for all participants (<italic>F</italic><sub>176,1290</sub> = 1.31, 1.41, 1.39 all p&lt; 10<sup>−6</sup>). Further, in the known color condition only one of the three participants showed a significant explanatory effect of C<sub><italic>S</italic>2</sub> on RT beyond its contribution to ΔC (p=0.002, 0.15 and 0.68 for the three participants; ANOVA of RT as additive in ΔC and C<sub><italic>S</italic>2</sub>, 6 levels each).</p>
<p>Examining choice as a function of the difference in strengths (<xref rid="fig5" ref-type="fig">Fig. 5c</xref>) shows that accuracy of difficulty choices was similar in the two conditions (mean <italic>P</italic> (Correct) = 0.87, sd = 0.014 for known and 0.86, sd = 0.018 for unknown condition; Fisher exact test, p&gt;0.12 for each participant). However, RTs were significantly faster in known vs. unknown condition (mean = 1.08 s, sd = 0.19 vs. 1.15 s, sd = 0.31). A two-way ANOVA of RT by condition (2 levels: known vs. unknown)× ΔC (6 levels) gave a main effect of condition <italic>p</italic> &lt; 10<sup>−8</sup> for all participants. Taken together, this suggests that similar bounds are used in the unknown and known color conditions as accuracy is similar. However, in the unknown color condition it takes longer, on average, to reach the bound (as in <xref rid="fig4" ref-type="fig">Fig. 4a</xref> vs. b) leading to longer RTs.</p>
</sec>
<sec id="s2h">
<title>Difference in confidence model</title>
<p>Up to now we have considered models that base difficulty on the color evidence, without requiring a decision about color dominance. We next consider the possibility that the difficulty comparison is actually a confidence judgment in disguise—that is the confidence one would assign to the two color dominance decisions were they made at each moment in time. Confidence is a mapping from DV and time into the log-odd of being correct if one were to choose the color (<bold><italic><xref ref-type="bibr" rid="c24">Kiani and Shadlen, 2009</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c25">Kiani et al., 2014</xref></italic></bold>). Our known color condition makes this seem unlikely as participants have no uncertainty about the color of each patch and, therefore, should have full confidence in both color estimates (so that the difference in confidence should be zero). It is not inconceivable, however, that participants evaluate a <italic>counterfactual</italic> form of confidence even in the known color condition—something to the effect of, “How confident would I be in the color choice if I did not know the color?”</p>
<p>We fit difficulty judgments to the unknown color condition by calculating the confidence for each decision, that is the probability (log-odds) of being correct if one were to choose the color dominance based on the sign of the DV. In the confidence model, the difficulty decision is made when the difference in absolute confidence for each stimulus reaches a bound. The fits of the confidence model are very poor (ΔBIC = 38, 56, 47 for participants 1 to 3, in favor of the Difference model; fit parameters: <xref rid="tbls7" ref-type="table">Table S7</xref>), and the model fails to explain the known color condition (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). The reason for this failure may be understood as follows. In the Difference model the decision only depends on the difference in the two DVs and not on the level of either DV. In contrast, the difference in confidence depends on the difference in DVs as well as the actual level of each DV. Indeed, confidence increases supra-linearly with DV such that a 0.64:0.64 coherence trial will tend to have a bigger difference in confidence than a 0:0 trial, which would lead to much shorter RTs for the former. This leads to the confidence model failing to explain the range of RTs apparent in the data (<xref rid="fig6" ref-type="fig">Fig. 6</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Same as <xref rid="fig5" ref-type="fig">Fig. 5</xref> but with lines showing the fit of the Confidence model to the unknown color condition and predictions for the known color condition.</p></caption>
<graphic xlink:href="528254v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2i">
<title>Controlled duration task</title>
<p>In addition to the RT version of the task, the participants performed a version of the task in which viewing duration was controlled by the experimenter. Stimulus duration was sampled from a truncated exponential distribution leading to an equal probability of 6 discrete durations: {0.1, 0.15, 0.25, 0.45, 0.85, 1.65} s (which leads to roughly equal changes in accuracy between consecutive duration).</p>
<p>We focus on short duration stimuli as the model predicts that differences in performance between the known and unknown color dominance conditions are largest for short durations. Participants had to wait for the stimuli to disappear before indicating their response. Again there were blocks with unknown color dominance and blocks with known color dominance. The Difference model predicts that accuracy should be better in the known color dominance condition.</p>
<p><xref rid="fig7" ref-type="fig">Fig. 7</xref> shows the decision accuracy as a function of stimulus duration for the difficulty tasks, for both known (solid red) and unknown (hollow red) color. As expected, accuracy improved with longer stimulus durations. More importantly, choice accuracy was generally higher in blocks with known color (accuracy across durations: mean <italic>P</italic> (Correct) = 0.82, sd = 0.01) compared to blocks with unknown color (mean <italic>P</italic> (Correct) = 0.76, sd = 0.01; Fisher exact test, <italic>p</italic> &lt; 0.001 for each participants).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Controlled duration task for unknown vs. known color dominance.</title>
<p>Performance in the controlled-duration task for difficulty judgments in the known(solid-red) and unknown-color condition (open-red). Participants’ accuracy (mean ± 1 SEM) is shown for each stimulus duration. Here, we exclude trials which had no objective correct answer (i.e. trials in the difficulty task where S1 and S2 had the same strength). Lines illustrate model fits for the 6 stimulus times used in the experiment. Results are shown for individual participants.</p></caption>
<graphic xlink:href="528254v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We fit a single DDM model simultaneously to each participant’s choices for both difficulty tasks (solid and dashed lines in <xref rid="fig7" ref-type="fig">Fig. 7</xref>). For the unknown-color task we used the Difference model as in Experiment 1 (i.e. using the equation shown in <xref rid="fig4" ref-type="fig">Fig. 4a</xref>). For the known-color task, we set the signs of the DVs according to the true color dominance (as in <xref rid="fig4" ref-type="fig">Fig. 4b</xref>).</p>
<p>The model has four parameters (fit parameters <xref rid="tbls6" ref-type="table">Table S6</xref>): a drift rate coefficient (<italic>k</italic>) and three parameters controlling how each decision bound collapses over time (as in the RT experiments). Previous work has shown that although evidence integration is serial, there is a buffer that can store a limited amount sensory information from both streams of evidence (<bold><italic><xref ref-type="bibr" rid="c33">Pashler, 1994</xref></italic></bold>). This means information can be acquired in parallel until the buffer is full and then the accumulation happens in a multiplexed manner (<bold><italic><xref ref-type="bibr" rid="c23">Kang et al., 2021</xref></italic></bold>). We included a 80 ms buffer in the model, that represents the duration of the two stimulus streams that can be held in short-term memory. The buffer simply accommodates the observation that decision makers use all the information from both stimuli when they are presented for very short durations. Indeed, we found that the model with buffer was superior to a model without a buffer for all three participants (log<sub>10</sub> BF = 2.1, 2.1, 1.3 in favor of the model that includes the buffer).</p>
<p>An alternative explanation for the accuracy improvements is that the difficulty judgment is always based on the absolute DVs (as in <xref rid="fig4" ref-type="fig">Fig. 4a</xref>) but that the drift rate might be higher when participants know the correct color. For example, integration might be more efficient when focusing on evidence that is consistent with the instructed color. We therefore compared our model with an alternative model in which we allowed two different <italic>k</italic> parameters—one for the known-color and one for the unknown-color condition. Model comparison reveals that the more parsimonious model with a single <italic>k</italic>, across both conditions was preferred overall and strongly for two of the participants: log<sub>10</sub> BF = 8.7 (group level) and 4.77, 4.74, −0.85 (participants) in favor of the single <italic>k</italic> model.</p>
<p>In summary, Experiment 2 provides evidence that knowing the correct color improves the accuracy and speed of difficulty judgments despite the fact that color identity is not relevant for the final difficulty choice. This effect is explained by the Difference model: when the correct color is known, difficulty judgments are based on a comparison of appropriately signed DVs, which provide more information than the unsigned absolute strength of evidence, as explained above.</p>
</sec>
<sec id="s2j">
<title>Optimal model</title>
<p>We model the decision process on of Experiment 1 (RT) as a partially observable Markovian decision process (POMDP), and transform it into a fully observable Markov decision process (MDP) over the decision maker’s belief states. The belief states are uniquely defined by the tuple ⟨<italic>t</italic><sub><italic>S</italic>1</sub>, <italic>t</italic><sub><italic>S</italic>2</sub>, <italic>DV</italic><sub><italic>S</italic>1</sub>, <italic>DV</italic><sub><italic>S</italic>2</sub>⟩ where <italic>t</italic><sub><italic>x</italic></sub> is the time elapsed sampling stimulus <italic>x</italic> and <italic>DV</italic><sub><italic>x</italic></sub> is the accumulated evidence for stimulus <italic>x</italic>. Three actions are available in each belief state: choose the option <italic>S</italic>1, option <italic>S</italic>2, or continue gathering evidence (with evidence time shared equally between <italic>S</italic>1 and <italic>S</italic>2). The assignment of policies to belief states is deterministic: only one action is chosen in each state. Transitions between states, however, are stochastic, and depend on the coherences of the stimuli and noise, which is assumed Gaussian.</p>
<p>For the unknown color-dominance condition (Experiment 1) behavior derived from the optimal decision policy (see Methods) is qualitatively similar to that of the participants (<xref rid="fig8" ref-type="fig">Fig. 8a</xref>). Optimal performance shows a clear modulation by the strength of each stimulus. The proportion of correct responses and the decision speed are higher when strength is higher. The optimal model also captures the crossing of RTs for easy-easy vs. easy-hard stimuli that we observed in the data.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Optimal policy for difficulty decisions. (a) Choices and response times obtained from simulations of the model that maximizes the rate of correct choices, derived for the reaction time version of the task with unknown color dominance (as in Experiment 1; N=200,000 simulated trials). (b) The optimal decision policy is a deterministic mapping from a belief state to an action. The figure identifies the values of the decision variables for stimuli S1 and S2, for which it is optimal to continue sampling sensory information (shown in white) or commit to a choice (shown in grey). Each panel represents different time within a trial (where the time spent sampling each stimulus is t/2). (c &amp; d) Same as panels a &amp; b, but for the version of the reaction time task in which the color dominance is known (as in Experiment 2).</p></caption>
<graphic xlink:href="528254v2_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To determine which of the four models presented above is most similar to the optimal model, we performed simulations of the optimal model and fit the four models to the simulated data.</p>
<p>The model that best accounted for the simulated data was the Difference model, followed by the Absolute momentary evidence model (Δ<italic>BIC</italic> = 2, 847 relative to the Difference model), and the Two-step and Race models (Δ<italic>BIC</italic> = 6, 949 and 15, 465 respectively).</p>
<p>An analysis of the decision space of the optimal model allows us to identify similarities with the four models. In <xref rid="fig8" ref-type="fig">Fig. 8B</xref> we show the decision space of the optimal model for four different times (<italic>t</italic><sub><italic>S</italic>1</sub> + <italic>t</italic><sub><italic>S</italic>2</sub>). At early times, the decision space resembles that of the Difference model, in that the decision variable can diffuse along four paths defined by the possible signs of the color coherences. However, later in a trial, the regions where it is optimal to continue sampling evidence become disjoint. That is, the center of the graph is no longer a region where it is optimal to keep sampling information. This is because, if after prolonged deliberation the decision variable is still in the central region of the decision space, then it is reasonable to infer that the sensory evidence is weak, in which case it may be optimal to hasten the decision and move to the next trial rather than continue deliberating on a decision that has a high probability of being wrong. The logic is the same as why it is optimal to collapse decision boundaries over time in binary decisions (<bold><italic><xref ref-type="bibr" rid="c17">Frazier and Yu, 2007</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c12">Drugowitsch et al., 2012</xref></italic></bold>). Interestingly, such a disjoint decision space approximates an internal commitment to a decision about the sign of the color coherence, as in the Two-step model.</p>
<p>We also derived the optimal model for the known-color reaction-time condition of Experiment 2. To do this we limited the distribution of coherences so that both were positive. The optimal model was in qualitative agreement with the experimental data (<xref rid="fig8" ref-type="fig">Fig. 8c</xref>) and its bounds (<xref rid="fig8" ref-type="fig">Fig. 8d</xref>) are similar to the difference model. Response times were largely determined by the difference between the coherences, such that RTs were faster when the absolute value of difference was higher. However, there is a notable exception. In contrast to what we observed in the experimental data, the RTs of the optimal model also depended on the absolute value of the coherences, such that coherences closer to the extremes of the range led to faster RTs. This can be understood as follows. Near the range limit of coherences, the decision maker can obtain evidence samples that are very informative about the coherence of a patch. For example, if a very negative sample is obtained for one of the stimuli, then, since the decisions maker knows that all coherences are positive, then this evidence value is most likely due to a very low coherence, from which one could conclude that the other stimulus is likely to be of higher coherence. In contrast, for coherences that are in the middle of the range, there is no single sample that can be as informative. The optimal model—but not the participants—seem to exploit the knowledge of the distribution over coherences to make better decisions.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Tasks that require consideration of multiple samples of evidence serve to elucidate the cognitive and neurophysiological mechanisms of decision making (Gold et al., (2007); <bold><italic><xref ref-type="bibr" rid="c6">Brody and Hanks, 2016</xref></italic></bold>). They promote the framework of sequential sampling with optional stopping, which unifies accounts of choice accuracy, response time, and confidence (<bold><italic><xref ref-type="bibr" rid="c25">Kiani et al., 2014</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c45">Van Den Berg et al., 2016</xref></italic></bold>). In this paper we build on this sequential sampling framework to understand how people construct a subjective estimate of the difficulty of a decision. In many circumstances, one might judge the relative difficulty of two tasks by performing them and comparing accuracy, confidence and decision time—in a word, experience. We were intrigued by the possibility that relative difficulty of two decisions could be determined directly by accumulating a transformed version of the evidence used to make the perceptual decisions. We show that this is possible and, moreover, the process is distinct from the perceptual decisions. In some cases, the difficulty decision is made faster than at least one of the perceptual decisions (e.g., the difficult perceptual decision when the other stimulus is very easy). This is true despite the difficulty decision requiring monitoring of two patches (which might be expected to be slower than monitoring one patch). For example, making a color choice for 0% color strength takes longer than a difficulty choice for 0:0.52 color strengths. Thus, the difficulty judgment does not require completion of the color decisions. However, in other cases, the two perceptual decisions are almost certainly completed before the difficulty decision (e.g., when color decisions are both very easy).</p>
<p>Studies of subjective beliefs, such as difficulty and confidence, often rely on numerical scales or discrete categorizations (e.g., <bold><italic><xref ref-type="bibr" rid="c48">Yildirim et al., 2019</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c2">Ais et al., 2016</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c45">Van Den Berg et al., 2016</xref></italic></bold>). This is in some ways more intuitive and more germane, perhaps, to real world judgments, which do not always warrant a comparison (but see <bold><italic><xref ref-type="bibr" rid="c21">Gweon et al., 2017</xref></italic></bold>). We pursued the comparison as it allowed us to relate the difficulty decision to quantities that are known to govern the simple decision. Moreover, comparative judgments of difficulty allow us to ignore participant-specific attributes of the estimation (e.g., a task may be more difficult for one participant than for another one), and the idiosyncrasies involved in mapping a subjective quantity to a numeric scale (<bold><italic><xref ref-type="bibr" rid="c27">Mamassian, 2020</xref></italic></bold>). Measuring the time it took our participants to form their judgments of difficulty allowed us to test between different mechanisms. The model that best explained the difficulty choices and reaction times (Difference model) was one in which participants accumulate information about the predominant color—which would be used to resolve each low-level decision—and the decision about difficulty is based on the comparison of the accumulated evidence for the two color decisions. The decision about difficulty terminates when the difference between the absolute values of the evidence accumulated by the low-level decisions crosses a threshold. The model makes concrete the idea of difficulty estimation as a metacognitive process, as the evidence for the difficulty judgment is given by the output of lower-level decisions, thus instantiating a processing hierarchy.</p>
<p>The difficulty decision relies on a difference in the absolute values of the DVs that would be formed to make the individual decisions. This quantity might be computed using a simple <italic>max</italic> operation. Neural implementation of simple drift diffusion, associated with a single binary decision, is organized as a race between two drift-diffusion processes: (<italic>i</italic>) the accumulation of the difference in momentary evidence for blue minus yellow (or more generally, colors that are not blue) and (<italic>ii</italic>) yellow minus blue (or not yellow). These racing accumulations are anticorrelated, albeit imperfectly. The absolute value of the DV can be approximated by the greater of the competing accumulations. The same computation is also applied to the other stimulus and the difference between the absolute DVs for the two stimuli is then computed. Such a process could be extended to difficulty decisions over more than two stimuli.</p>
<sec id="s3a">
<title>Difficulty judgments and the magnitude effect</title>
<p>The reaction time for difficulty judgments did not just depend on the difference in difficulty between the two color decisions. Specifically, responses were faster, when the sum of the color strengths was larger (i.e., a ‘magnitude’ effect) even if the difference in difficulty was the same. This effect has a parallel in value-based decision making. For instance, when people choose between two highly desirable items, the decision is faster than when the items are both less desirable, even if the decisions are difficult because the pairs comprise items of approximately equal value (<bold><italic><xref ref-type="bibr" rid="c41">Smith and Krajbich, 2019</xref></italic></bold>). This effect can be explained by arguing that attention fluctuates between both items under comparison and that attention has a multiplicative effect on the subjective value of the unattended item (<bold><italic><xref ref-type="bibr" rid="c41">Smith and Krajbich, 2019</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c37">Sepulveda et al., 2020</xref></italic></bold>). Because of this multiplicative effect, the greater the value of the items under comparison, the greater the discount of the unattended item, leading to faster decisions (i.e., the magnitude effect).</p>
<p>This explanation does not apply in our case, since we could largely abolish the magnitude effect by informing the participants about the dominant color in each stimulus patch. In our task, the magnitude effect occurs, because DVs on hard-hard trials (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>, orange circle) cross the bounds later than on easy-easy trials (purple circle). This arises because the DVs for easy-easy trials move into one of the channels, whereas weak-weak DVs linger near the origin making them less likely to cross a bound. When the color dominance is known (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>), the bounds change so that the DV can reach a bound when lingering near the origin. Therefore, the reaction times now only depend on difference in difficulty and not the magnitude.</p>
</sec>
<sec id="s3b">
<title>Optimal model of difficulty judgments</title>
<p>The model that maximizes reward rate in our unknown color dominance task (Experiment 1) qualitatively reproduces the behavior of the participants. In particular, the optimal model shows a similar “magnitude effect” to that observed in the data and the same criss-cross pattern in response times. Therefore, these features of the data do not signify suboptimal decision-making. We fit the four models (<xref rid="fig2" ref-type="fig">Fig. 2</xref>) to simulations of the optimal model and found that the Difference model best accounts for the data from the optimal model. That is, the model that most closely resembles the optimal model is also the one that best explains the participants’ data. The decision space derived from the optimal policy was similar to that of the Difference model, with one notable exception. The optimal model predicts that the speed at which the bounds collapse depend both on elapsed time and the magnitude of the decision variables (<xref rid="fig8" ref-type="fig">Fig. 8b</xref>). The same was observed in the optimal model (<xref rid="fig8" ref-type="fig">Fig. 8d</xref>) derived for the known color dominance task (Experiment 2). In contrast, in the Difference model the speed at which the bounds collapse depends only on elapsed time. It remains to be determined the extent to which this difference has a meaningful impact on behavior. Conducting a variant of our experiment in which participants are incentivized to maximize reward rate could be informative.</p>
</sec>
<sec id="s3c">
<title>Parallel vs. serial processing of the two stimuli</title>
<p>In our models we assume that participants sample the two stimuli in difficulty judgment sequentially through alternation. However, our results are not affected by whether participants sample the stimulus sequentially through alternation (which we assume is fast and has equal times for both stimulus) or in a parallel manner (cf., <bold><italic><xref ref-type="bibr" rid="c23">Kang et al., 2021</xref></italic></bold>). What does change is the parameters of the model (but not their predictions/fits). In the parallel model information is acquired at twice the rate of the serial model. We can, therefore, obtain the parameters of parallel models (that had identical predictions to the serial model) directly from the parameters of the current sequential models simply by adjusting the parameters that depend on the time scale (subscripts <italic>s</italic> and <italic>p</italic> for serial and parallel models): <inline-formula><alternatives><inline-graphic xlink:href="528254v2_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> (<xref rid="eqn2" ref-type="disp-formula">Eq. 2</xref>).</p>
</sec>
<sec id="s3d">
<title>Potential limitations</title>
<p>We acknowledge several limitation to our study. First, we only consider accumulation models as these have been very successful in explaining choice, RT, and even confidence in many perceptual and mnemonic decision tasks, including color discrimination (<bold><italic><xref ref-type="bibr" rid="c3">Bakkour et al., 2019</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c20">Gold et al., 2007</xref></italic></bold>). Using such a model we were able to account for difficulty judgment in both reaction time and controlled-duration tasks in which the color dominance was either unknown or known. Given that simple perceptual decision of the type we study have been shown to involve accumulation, we chose not to consider non-accumulation models (<bold><italic><xref ref-type="bibr" rid="c44">Stine et al., 2020</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c9">Cisek et al., 2009</xref></italic></bold>). Second, for Experiment 2 we required considerable data from each participant to be able to test our hypothesis. Therefore we ran 3 participants over 18 sessions each. While this provided a large dataset we accept that the number of participants is small. Third, it is an open question whether the results we obtain from our simple perceptual decision task would generalize to more naturalistic real world tasks (e.g., choosing an instrument to learn or a recipe to cook). We chose to study judgments of difficulty in simple tasks amenable to quantitative modeling and, eventually, neurophysiological investigations in nonhuman animals. Moreover, the feedback we provided on each trial – which of the two tasks was actually easier – is likely to differ in the real world, where difficulty is rarely directly indicated. Importantly, accumulation models have been extended to more complex tasks such as decision making in a game of chess (<bold><italic><xref ref-type="bibr" rid="c15">Fernandez Slezak et al., 2018</xref></italic></bold>) and therefore in principle the same types of algorithm could operate for more complex difficulty judgment tasks.</p>
</sec>
<sec id="s3e">
<title>Confidence does not underlie difficulty judgments</title>
<p>It has been proposed that confidence judgments about the accuracy of a decision require having learned a mapping between (<italic>i</italic>) the state of a decision variable (<italic>DV</italic>) and elapsed time (<italic>t</italic>) and (<italic>ii</italic>) the probability that the decision is correct (<bold><italic><xref ref-type="bibr" rid="c24">Kiani and Shadlen, 2009</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c25">Kiani et al., 2014</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c45">Van Den Berg et al., 2016</xref></italic></bold>). This mapping is used to define a policy; for instance, respond with high confidence if the estimated probability of being correct is greater than a criterion. An explicit calculation of confidence in the color decisions is not necessary in our task, because the difficulty decision is based on quantity derived directly from the two color decision variables. Indeed a model that compares confidence to make the difficulty judgement provides a poor fit to the data (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). That said, there may be situations where the difficulty determinations involve calculation of confidence as an intermediate step. For example, in a difficulty-comparison of a color dominance in one patch and motion direction in another patch, the decision variables may not be directly comparable and may therefore require a conversion to confidence (cf. <bold><italic><xref ref-type="bibr" rid="c18">de Gardelle et al., 2016</xref></italic></bold>).</p>
<p>In summary, we have shown that a Difference model can explain difficulty judgments in both a reaction time and controlled-duration task and when the dominant color of both patches is either unknown or known. The results extend decision making models, which have been used to explain choice, reaction time and confidence to judgments of difficulty.</p>
</sec>
<sec id="s3f">
<title>Methods and Materials</title>
</sec>
<sec id="s3g">
<title>Participants</title>
<p>For Experiment 1 (Difficulty judgments in a reaction time task), 51 participants were recruited on Amazon Mechanical Turk. Only participants who completed the entire study and met performancebased inclusion criteria (see below) were included in the final sample of 20 participants (12 male and 8 female; 19 right-handed; age 20–-51, mean = 33.6, sd = 9.1). Participants completed two one hour sessions each. They received $1 for each session, plus a performance-based bonus of up to $5. Participants who successfully completed both sessions of the task within 48 hours received an additional bonus of $1. These experiments were an early foray into using Mechanical Turk and we simply matched payment with the typical payment for similar online experiments. We have since become aware, and agree with, advocates who feel the pay is too low and have since moved to using the Prolific platform and ensure we pay $8/hour minimum.</p>
<p>For Experiment 2 (Difficulty judgments with unknown vs. known color dominance), 4 participants were recruited via a Sona Systems participant pool. After initial training, 3 participants (1 male and 2 female; all right-handed; age 20-–24, mean = 21.7, sd = 2.1) were selected for the main experiment based on their performance (see below). Participants completed a total of 18 one hour sessions and received $17/h and an additional performance-based bonus.</p>
<p>All participants had normal or corrected-to-normal vision and were naïve about the hypotheses of the experiment. Participants provided written informed consent prior to the study. The study was approved by the local ethics committee (Institutional Review Board of Columbia University Medical Center).</p>
</sec>
<sec id="s3h">
<title>Apparatus and stimuli</title>
<p>Both experiments were conducted remotely during the SARS-CoV-2 pandemic (summer 2021). Participants completed the task online using a Google Chrome browser. The task was programmed in JavaScript and jsPsych (<bold><italic><xref ref-type="bibr" rid="c10">De Leeuw, 2015</xref></italic></bold>). During the task, two dynamic random dot patches with yellow and blue dots were presented in rectangular apertures (3 × 5<sup>∘</sup>, horizontal × vertical) to the left and right of a red fixation cross, separated by a central gray bar (2 × 5<sup>∘</sup>; <xref rid="fig1" ref-type="fig">Figure 1a</xref>). Visual stimuli were presented with a screen refresh rate of 60 Hz and stimulus density of 16 dots deg<sup>−2</sup> s<sup>−1</sup> (i.e. 4 dots displayed in each aperture on each frame). On each video frame, each dot was displayed in a location chosen from a uniform distribution over the aperture. The color of each dot was determined independent of its location, according to one of 6 color strength levels (see below).</p>
<p>Prior to the experiment, participants completed a virtual chin-rest procedure in order to estimate viewing distance and calibrate the screen pixels per degree (<bold><italic><xref ref-type="bibr" rid="c26">Li et al., 2020</xref></italic></bold>). This procedure involves first adjusting objects of known size displayed on the screen to match their physical size and then measuring the horizontal distance from fixation to the blind spot on the screen (taken as 13.5<sup>∘</sup>).</p>
</sec>
<sec id="s3i">
<title>Overview of experimental tasks</title>
<p>On each trial, two patches of random dots were presented after an onset delay of 400–800 ms. Participants were asked to decide for which one of two patches of dots it is easier to decide what the dominant color is (yellow/blue). The instructions given the participants was “Your task is to judge which patch has a stronger majority of yellow or blue dots. In other words: For which patch do you find it easier to decide what the dominant color is? It does not matter what the dominant color of the easier patch is (i.e., whether it is yellow or blue). All that matters is whether the left or right patch is easier to decide.”</p>
<p>Participants were instructed to press the F or J key with their left/right index finger to indicate whether the left or right stimulus was the easier one, respectively. Participants did not have to report the individual color decision (yellow or blue) for either stimulus. Instead, they were required to indicate which patch (left or right) was the easier one, regardless of whether the majority of dots in that patch was yellow or blue.</p>
<p>The difficulty of the color choice was conferred by the probability that a dot would be colored blue or yellow on each frame. We refer to the signed quantity, <italic>C</italic><sup>±</sup> = 2<sub>(</sub><italic>p</italic><sub>blue</sub> − 0.5<sub>)</sub>, as the color coherence where positive coherences refer to blue dominant stimuli. The dominant color of each stimulus (yellow/blue) and its difficulty (color strength <italic>C</italic> = |<italic>C</italic><sup>±</sup>|) was fixed during a trial but randomized independently across trials. We used 6 different coherence levels ±{0, 0.128, 0.256, 0.384, 0.512, 0.64}, resulting in 12 signed coherence levels for the 2 colors. All 12 × 12 color-coherence combinations for the 2 patches were presented in a pseudo-random, counter-balanced manner during the task. Visual feedback was provided at the end of each trial. For correct responses, participants won 1 point. After errors and miss trials (too early/late), participants lost 1 point. For trials in which both stimuli were equally difficult (i.e., same coherence level), half of the trials were randomly designated ‘correct’. Miss trials were repeated later during the same block. Participants were instructed to try and gain as many points as possible and at the end of the experiment they received an extra bonus of one cent for every point they accumulated. Their point score was shown in the corner of the screen throughout the task and additional feedback about percent accuracy was provided at the end of every block.</p>
<p>Prior to completing the task with difficulty judgments, all participants were first trained on a task in which they had to make color judgments (blue/yellow) about a single patch of dots presented to the left or right of the central fixation cross. Participants used the M and K keys with their right index/middle finger to indicate their response. Throughout the task, the response mapping (M = yellow, K = blue) was shown on the screen. The ± sign of the 0 coherence level determined which response would be rewarded.</p>
<p>Participants were instructed to keep their eyes fixated on the central fixation cross throughout the task.</p>
</sec>
<sec id="s3j">
<title>Experiment 1: Difficulty judgments in a reaction time task</title>
<p>Participants performed two separate sessions with a total of 432 trials of the color judgment task and 1,152 trials of the difficulty task. In session 1, participants were first trained on the color judgment task (see above). They performed 6 blocks of 72 trials each, in which all 12 signed coherence levels were presented in random order. They then completed 3 blocks of the difficulty judgment task (96 trials/block), in which all 12 × 12 coherence combinations for the two patches were presented in random order. In a second session there were 9 blocks (96 trials/block) of the difficulty task.</p>
<p>In both sessions, participants performed a reaction time task in which they were instructed to respond as soon as they had made their decision. The stimuli disappeared as soon as participants made a response. Participants were instructed to try to be both as fast and as accurate as possible in order to maximize their score. Warning messages were presented if participants initiated a response before stimulus onset or within 200 ms of stimulus onset (“too early”) or when RTs exceeded 5 sec (“too slow!”).</p>
</sec>
<sec id="s3k">
<title>Exclusion criteria</title>
<p>Online experiments pose challenges concerning quality control (<bold><italic><xref ref-type="bibr" rid="c8">Chmielewski and Kucker, 2020</xref></italic></bold>). Therefore, we excluded participants who could not perform the task sufficiently well. After session 1, we fit a logistic of color choices against coherence and difficulty choices against the difference in strength of S1 and S2. In order to ensure high data quality, participants with low choice accuracy were excluded from the experiment and were not invited to participate in session 2 of the experiment. Specifically, participants whose sensitivity (slope parameter of logistic) of color choices was less than 4 (n = 4), or whose sensitivity of difficulty choices was less than 3 (n = 21) a lower threshold used here as we found difficulty choices were harder than color choices) were not invited to participate in session 2 and were excluded from all analyses. In addition participants (n = 6) were excluded from all analyses because they did not complete session 2 despite meeting the performance criteria. Importantly, exclusion criteria were not based on reaction time (our main analysis in the study), and instead, were strictly based on accuracy to ensure that participants followed the task instructions correctly. In the final sample, mean sensitivity of color choices was 9.67 (sd = 2.66) and mean sensitivity of difficulty choices was 5.24 (sd = 1.03).</p>
</sec>
<sec id="s3l">
<title>Experiment 2: Difficulty judgments with unknown vs. known color dominance</title>
<p>Participants completed a total of 18 sessions on separate days. The first 4 sessions were regarded as training (see below) and were not included in the analysis. During sessions 5–17, participants performed different versions of the difficulty judgment task that alternated every 3–4 blocks of 96 trials each (order counterbalanced across participants): i) controlled duration task with unknown color (total of 3,888 trials per participant), ii) controlled duration task with known color (1,944 trials, half of which were blocks with blue stimuli while the other half of blocks had yellow stimuli), iii) reaction time task with unknown color (2,592 trials), iv) reaction time task with known color (1,296 trials, half of which were blocks with blue stimuli while the other half of blocks had yellow stimuli). In the final session, participants completed 600 trials of a controlled duration task in which they had to judge the dominant color of a single stimulus. In all versions of the controlled duration task, stimuli were presented with one of 6 stimulus durations {0.1, 0.15, 0.25, 0.45, 0.85, 1.65}s, which were randomized within blocks. This gives a discrete sample from a truncate exponential distribution. Participants were instructed to wait for the stimuli to disappear before indicating their response. Warning messages were presented if participants initiated a response before stimulus offset (“too early”) or later than 5 s after stimulus offset (“too slow!”).</p>
<p>In the difficulty task with unknown color, all 12 × 12 signed coherence combinations for the two patches were presented in random order. Participants were instructed that each color patch could be either yellow or blue and that the two patches would not necessarily be of the same color. In the blocks with known color, only coherence combinations with the same sign (6 × 6 combinations) were presented. Participants received instructions that all patches in the following blocks would be dominantly blue (or yellow). Throughout the task, participants were shown a brief instruction in the corner of the screen reminding them of the condition of the current block.</p>
<p>In all versions of the task, coherence combinations where both stimuli had the same difficulty (i.e., same strength) were presented with one third the frequency compared to other coherence combinations in order to reduce overall trial numbers. The rationale behind this was that choice accuracy was determined randomly in this condition, and thus, it is not informative with regard to participants’ actual choice performance. Consequently, for analyses of choice accuracy in the controlled Duration task, all trials with equal coherence combinations were excluded. All other coherence combinations were presented with equal frequency and in a randomized order.</p>
<p>Although all possible 12 × 12 coherence combinations were presented in the unknown color condition, only trials in which both patches had the same color were included in the analyses.This ensured better comparability with performance in the known-color blocks (where both stimuli by definition always had the same color). The task was designed with this in mind due to the fact that previous pilot studies from our lab revealed that performance tends to be worse when the 2 patches are of different color compared to when they are of the same color. Thus, participants performed twice the number of total trials with the unknown color condition, but only trials with equal color combinations were included in the main analyses, resulting in the same trial numbers for the known vs. unknown condition (1,944 trials each for controlled duration and 1,296 trials each for reaction time).</p>
</sec>
<sec id="s3m">
<title>Training sessions</title>
<p>Prior to the experimental sessions, participants completed 4 training sessions. During session 1, participants were trained on a controlled duration task with single color judgments in which stimulus durations were drawn randomly from an exponential distribution with <italic>μ</italic> = 800 ms, truncated at 400–1800 ms. In session 2, participants performed a reaction time version of the color judgments task. Finally, in sessions 3 and 4, participants performed the difficulty judgments task with half the blocks of each session being a reaction time version of the task while the remaining blocks were a controlled duration version in which stimulus durations were drawn randomly from an exponential distribution (Session 3: <italic>μ</italic> = 900 ms, truncated at 400–2000 ms; Session 4: <italic>μ</italic> = 800 ms, truncated at 200–1800 ms). After training, all 4 participants met the performance criteria (slope of logistic function &gt; 4 for color choices and &gt; 3 for difficulty choices). However, one participant was excluded from the remaining sessions of the experiment due to failing to complete the training sessions in a timely manner.</p>
</sec>
<sec id="s3n">
<title>Drift diffusion model of color judgments</title>
<p>We fit a standard drift diffusion model to participants’ color choices and RTs. The model assumes that momentary color evidence is accumulated into a decision variable (DV). The process terminates when the DV reaches an upper or lower bound (±<italic>B</italic>), which corresponds to making a blue vs. yellow choice, respectively. The DV is determined by a Wiener process with drift, which starts at 0 and then evolves according to the sum of a deterministic and a stochastic component (with discrete updates every Δ<italic>t</italic>):
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="528254v2_eqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The deterministic term depends on the drift <italic>μ</italic> = <italic>k</italic>(<italic>C</italic><sup>±</sup> + <italic>C</italic><sub>0</sub>) where <italic>C</italic><sup>±</sup> is the signed color coherence (positive for blue; negative for yellow), <italic>k</italic> converts coherence to drift rate and <italic>C</italic><sub>0</sub> allows for a color bias. Here, the bias term is modeled as an offset in the coherence, rather than a shift in the starting point of the accumulation process. This approximates the optimal way of implementing a bias when coherence levels vary across trials (<bold><italic><xref ref-type="bibr" rid="c22">Hanks et al., 2011</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c49">Zylberberg et al., 2018</xref></italic></bold>).</p>
<p>The second term of <xref rid="eqn1" ref-type="disp-formula">Eq. 1</xref> describes the stochastic component, which captures the variability introduced by the noise in the stimulus and in the neural response. This variability is modeled as independent samples from a Normal distribution with mean 0 and standard deviation √Δ<italic>t</italic>, which results in the variance of the DV being equal to 1 after accumulating evidence for 1 s. This was done by convention, since for any other scaling of the variance, it would be possible to define an equivalent model in which the variance is 1 and the other parameters are a scaled version of the original ones (<bold><italic><xref ref-type="bibr" rid="c32">Palmer et al., 2005</xref></italic></bold>).</p>
<p>The accumulation process terminates when the DV crosses one of two bounds (±<italic>B</italic>), resulting in a blue or yellow choice. The decision time <italic>T</italic><sub><italic>d</italic></sub> is the time it takes for the DV to reach a bound. To account for the observation that RTs tend to be slower in erroneous, compared to correct choices, for a given coherence level (data not shown here), we implemented bounds that collapse over time</p>
<p>(<bold><italic><xref ref-type="bibr" rid="c35">Rapoport and Burkheimer, 1971</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c12">Drugowitsch et al., 2012</xref></italic></bold>; <bold><italic><xref ref-type="bibr" rid="c38">Shadlen and Kiani, 2013</xref></italic></bold>). Collapsing bounds result in an increased probability that the <italic>DV</italic> will reach the wrong bound the longer the accumulation process takes. We parameterized the upper collapsing bound as a logistic function:
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="528254v2_eqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
with three parameters <italic>a</italic>, <italic>u</italic>, <italic>d</italic>. Therefore the bound collapse (slope related to <italic>a</italic>) and reaches a value of <italic>u</italic>/2 at <italic>t</italic> = <italic>d</italic> and approaches 0 as <italic>t</italic> → ∞. The lower bound is simply the negative of the upper bound (<italic>u</italic> → −<italic>u</italic>).</p>
<p>Given a set of parameters (Φ = [<italic>k</italic>, <italic>C</italic><sub>0</sub>, <italic>u</italic>, <italic>a</italic>, <italic>d</italic>]), we can estimate the joint probability density function for choices and decision times <italic>T</italic><sub><italic>d</italic></sub> as a function of the signed color coherence <italic>coh</italic>. We used a Δ<italic>t</italic> of 0.5 ms and obtained the probability density function by numerically solving the FokkerPlanck equation associated with a Wiener process with drift (<bold><italic><xref ref-type="bibr" rid="c24">Kiani and Shadlen, 2009</xref></italic></bold>), using the finite difference method of <bold><italic><xref ref-type="bibr" rid="c7">Chang &amp; Cooper 1970</xref></italic></bold>. Finally, the RT is determined by the sum of the decision time <italic>T</italic><sub><italic>d</italic></sub> and a non-decision time, which is assumed to be Gaussian with mean <italic>T</italic><sub><italic>nd</italic></sub> and a standard deviation that was fixed to σ<sub><italic>Tnd</italic></sub> = 0.05 s.</p>
<p>We fit the model parameters to the mean choice-RT data of individual participants by maximizing the likelihood of observing the data given the model parameters (Φ = [<italic>k</italic>, <italic>C</italic><sub>0</sub>, <italic>u</italic>, <italic>a</italic>, <italic>d</italic>, <italic>T</italic><sub><italic>nd</italic></sub>]) and the signed color coherence <italic>coh</italic>. We used Bayesian adaptive direct search (BADS; Acerbi and Ma, (2017)) to optimize the model parameters. All model fits were obtained by performing several iterations of the optimization procedure with 10 different sets of starting parameters.</p>
</sec>
<sec id="s3o">
<title>Drift diffusion models of difficulty judgments</title>
<p>We developed four alternative models of difficulty judgments. All models assume that momentary color evidence is integrated into a DV, as in the drift diffusion model for color judgments. However, for difficulty judgments, there are two DVs: <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>, representing the accumulated momentary evidence from the left and right stimulus, respectively. In all models, we assumed that accumulation proceeds in a serial, time-multiplexed manner where evidence integration switches back and forth between the two stimuli (<bold><italic><xref ref-type="bibr" rid="c23">Kang et al., 2021</xref></italic></bold>). We assumed perfect time sharing between <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>, resulting in decision times that are twice as long compared to parallel integration.</p>
<p>The models differ in a) how momentary color evidence is accumulated into a decision variable and b) the decision criterion that is used to make the difficulty choice (<xref rid="fig2" ref-type="fig">Fig. 2</xref>).</p>
<sec id="s3o1">
<title>(i)#Race model</title>
<p>In the Race model, difficulty choice depends on a race between <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>. The DV for each stimulus is calculated in the same way as if participants made two independent color choices (<xref rid="eqn1" ref-type="disp-formula">Eq. 1</xref>) and the first decision to cross the bound is regarded as the easier decision. For difficulty choices, we did not include a color bias (<italic>C</italic><sub>0</sub>). Thus, the drift part of <italic>DV</italic><sub><italic>S</italic>1</sub> is simply <italic>μ</italic><sub><italic>S</italic>1</sub> = <italic>k</italic> ⋅ <italic>C</italic><sup>±</sup> (and similarly for S2).</p>
<p>The difficulty choice in the Race model is determined by which DV crosses its bound first and the stimulus associated with this DV is chosen as the easier one. The decision time is determined by the time that the first DV crosses a bound. In the model the decision bounds collapse in the same way for both stimuli.</p>
</sec>
<sec id="s3o2">
<title>(ii)#Difference model</title>
<p>In the Difference model, <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub> are calculated in the same way as in the Race model. However, the decision bound for the difficulty choice is not applied to the individual color DVs, but instead to the difference in absolute DVs, i.e. |<italic>DV</italic><sub><italic>S</italic>1</sub>| − |<italic>DV</italic><sub><italic>S</italic>2</sub>|. A difficulty choice is made when this difference value reaches an upper (lower) bound, indicating that S1 (S2) is the easier stimulus. The bounds collapse symmetrically, according to <xref rid="eqn2" ref-type="disp-formula">Eq. 2</xref>.</p>
</sec>
<sec id="s3o3">
<title>(iii)#Two-step model</title>
<p>The Two-step model is similar to the Difference model, however, the bounds for difficulty choice depend on the sign of each DV, according to an initial mini decision. The mini decision depends on a low-threshold bound <italic>B</italic><sub><italic>mini</italic></sub>. In order to minimize the number of additional parameters in this model, we modeled <italic>B</italic><sub><italic>mini</italic></sub> as time-independent for 2 s, followed by a sharp collapse. The DVs were calculated in the same way as in the Race and Difference models. Thus, choices and decision time (<italic>t</italic><sub><italic>mini</italic></sub>) for the mini decision only depend on the signed color coherence, <italic>C</italic><sub>0</sub> and the parameters <italic>k</italic> and <italic>B</italic><sub><italic>mini</italic></sub>.</p>
<p>The model uses the mini decision to determine the color dominance of each stimulus and then only performs difficulty judgments assuming this color dominance. Therefore, once a mini decision has been made for either of the two DVs, a difficulty judgment is made when sign(<italic>DV</italic><sub><italic>S</italic>1</sub>(<italic>t</italic><sub><italic>mini</italic></sub>)) ⋅ <italic>DV</italic><sub><italic>S</italic>1</sub> − sign(<italic>DV</italic><sub><italic>S</italic>2</sub>(<italic>t</italic><sub><italic>mini</italic></sub>)) ⋅ <italic>DV</italic><sub><italic>S</italic>2</sub> reaches one of the bounds, that is ±<italic>B</italic>(<italic>t</italic>). We also tested a version of the Two-step model in which both DVs need to reach <italic>B</italic><sub><italic>mini</italic></sub> before the difficulty choice can be made. However, this model was inferior compared to the model presented here, in which only one mini decision is required, and the sign of the other DV is fixed according to its value at time <italic>t</italic><sub>1</sub>(group-level log<sub>10</sub> BF = 49.11 in favor of single mini-decision model).</p>
<p>As in the Difference model, the bounds for the difficulty choice collapse over time, starting from the beginning of the accumulation process (i.e., before a mini decision has been made). We constrained the model such that a difficulty choice could only be made at time <italic>t</italic><sub><italic>mini</italic></sub> at earliest, that is, once a mini decision has been made.</p>
</sec>
<sec id="s3o4">
<title>(iv)#Absolute momentary evidence model</title>
<p>In the Absolute momentary evidence model, DVs represent the accumulated absolute momentary color evidence at each time step.
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="528254v2_eqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The model is, therefore, color agnostic in that it accumulates evidence in favor of strong color independent of whether the dominant color is blue or yellow on each frame. Thus, both DVs are always positive. Similar to the previous two models, a difficulty choice is made when the difference in DVs, <italic>DV</italic><sub><italic>S</italic>1</sub> − <italic>DV</italic><sub><italic>S</italic>2</sub> exceeds an upper/lower bound, which again collapses over time.</p>
</sec>
</sec>
<sec id="s3p">
<title>Model fitting</title>
<p>To fit each model we simulated 1000 trials for each unique combination of signed coherence for S1 × S2 (using a Δ<italic>t</italic> of 5 ms). An Epanechnikov kernel smoothed probability distribution was then fit to the simulated RT data for each choice (S1 or S2) and combination of signed coherences. This was used to calculate the log likelihood of the data given the model parameters <italic>k</italic>, <italic>u</italic>, <italic>a</italic>, <italic>d</italic>, <italic>T</italic><sub><italic>nd</italic></sub>, and in case of the Two-step model, <italic>B</italic><sub><italic>mini</italic></sub>. We used Bayesian adaptive direct search (BADS; <bold><italic><xref ref-type="bibr" rid="c1">Acerbi and Ma, 2017</xref></italic></bold>) to optimize the model parameters. Model fits were obtained by performing several iterations of the optimization procedure with 10 different sets of starting parameters. The Bayesian information criterion (BIC) was computed for each model and participant in order to compare the models while controlling for their number of free parameters. Group-level model comparison was performed by summing BICs across individual participants.</p>
</sec>
<sec id="s3q">
<title>Model recovery</title>
<p>We used the parameters from the fits of the race, difference, two-step and absolute momentary evidence models to the data for each participant in Experiment 1 to generate 10 synthetic data sets for each participant. We then fit each synthetic data set with each of the four models as we did with the real data. For model recovery, we examined the proportion of times the BIC was lowest for the fit to the model that was used to generate the data. Classification accuracy was 93.5, 97.0, 53.5 and 95.5% for data generated by the race, difference, two-step and absolute momentary evidence models, respectively. For data generated by the two-step model the BIC was lowest for the difference model in 36% of fits.</p>
</sec>
<sec id="s3r">
<title>Model for Experiment 2: Difficulty judgments with unknown vs. known color dominance</title>
<p>In order to model choice accuracy in the unknown and known color condition, we used a Difference model in which difficulty choice was based on either the difference in absolute DVs (unknown color) or appropriately signed DVs (known color). To fit choices in difficulty judgments, we excluded trials in unknown condition in which both stimuli had the same strength (i.e. ΔC = 0), and trials in which the two stimuli had different dominant colors (so as to make comparable to the known color condition).</p>
<p>For the reaction time task in Exp. 2, we fit the Difference model as in Exp. 1 to the data from the unknown color condition. We then used the optimized parameters to predict choices and RTs in the known color condition using the same model, but with appropriately signed DVs instead of absolute DVs.</p>
<p>To fit the choices in the controlled duration task we simulated 2000 trials for each unique combination of signed coherence for S1 × S2 (using a Δ<italic>t</italic> of 5 ms) with a collapsing bound as in the RT task. Choice was based on crossing a bound or on the the sign of the difference in DVs at the end of evidence accumulation if no bound had been crossed. We fit both the known and unknown color conditions simultaneously using the appropriate decision rules for each (difference model with absolute DVs for the unknown and appropriately signed DVs instead of absolute DVs for the known color condition).</p>
<p>We included a buffer <italic>T</italic><sub>buf</sub> in the model that controls the duration of the stimulus streams that can be stored while the accumulation process alternates between the two stimuli and this was set to 80 ms based on our previous work (<bold><italic><xref ref-type="bibr" rid="c23">Kang et al., 2021</xref></italic></bold>). If the stimulus duration is shorter than the buffer, the amount of time that each stimulus is sampled, <italic>T</italic><sub>dur</sub>, equals the stimulus duration (i.e. all the information can be stored in the buffer and can be integrated into the DV). If the stimulus duration is longer than the buffer, <italic>T</italic><sub>dur</sub> equals the buffer plus the remaining stimulus duration, time-shared between the two stimuli:
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="528254v2_eqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s3s">
<title>Difference in confidence model</title>
<p>For the reaction time data of Experiment 2 we fit a difference in confidence model. Rather than comparing the two DVs (as in the Difference model), we compare measures of confidence. Confidence is a mapping from DV and time into the probability of being correct if one were to choose color based on the sign of the DV. We followed the method in Kiani and Shadlen ((2009)) to calculate confidence. We placed bounds on the difference in confidence (measured as the log-odds of being correct). All other elements of the model were the same as for the Difference model (e.g. collapsing bounds). We fit the unknown color condition and use the fits to predict the known color condition. In the unknown color condition, we compared the difference in the absolute log-odds. In the known color condition we calculated the difference in the appropriately signed log-odds (i.e., the log-odds for choosing the known color). We chose to represent confidence as log-odds because using raw probabilities led to very poor fits. This is because for high:high coherences the difference in confidence (when both are close to 1) can be very small when represented in raw probabilities.</p>
</sec>
<sec id="s3t">
<title>Optimal reaction time model</title>
<p>We derived the decision strategy that maximizes the number of correct choices per unit time, for the RT tasks with known and unknown color dominances. To this end, we formalize the difficultyjudgment task as a partially observable Markov decision process (POMDP). Following well-established procedures, we find the solution to the POMDP by transforming it into a fully observable Markov decision process (MDP) over belief states. The MDP comprises (<bold><italic><xref ref-type="bibr" rid="c19">Geffner and Bonet, 2013</xref></italic></bold>):
<list list-type="bullet">
<list-item><p>a space <italic>S</italic>,</p></list-item>
<list-item><p>an initial state <italic>s</italic><sub>0</sub> ∈ <italic>S</italic>,</p></list-item>
<list-item><p>goal states <italic>S</italic><sub><italic>G</italic></sub> ∈ <italic>S</italic>,</p></list-item>
<list-item><p>a set of actions <italic>A</italic>(<italic>s</italic>) applicable in each state <italic>s</italic> ∈ <italic>S</italic>,</p></list-item>
<list-item><p>transition probabilities <italic>P</italic><sub><italic>a</italic></sub>(<italic>s</italic><sup>′</sup>|<italic>s</italic>) that specify the probability of transitioning to state <italic>s</italic><sup>′</sup> after selecting action <italic>a</italic> in state <italic>s</italic>, and</p></list-item>
<list-item><p>rewards and costs, <italic>r</italic>(<italic>a</italic>, <italic>s</italic>), for selecting action <italic>a</italic> in state <italic>s</italic>.</p></list-item>
</list>
In our task, the state space is defined by the tuple ⟨<italic>t</italic><sub><italic>S</italic>1</sub>, <italic>t</italic><sub><italic>S</italic>2</sub>, <italic>DV</italic><sub><italic>S</italic>1</sub>, <italic>DV</italic><sub><italic>S</italic>2</sub>⟩ where <italic>t</italic><sub><italic>x</italic></sub> is the time spent sampling stimulus <italic>x</italic> and <italic>DV</italic><sub><italic>x</italic></sub> is the accumulated evidence for stimulus <italic>x</italic>. We discretize time and accumulated evidence in bins of Δ<italic>t</italic> and Δ<italic>DV</italic> . The initial state is the one for which no evidence has been accrued, <italic>s</italic><sub>0</sub> = ⟨0, 0, 0, 0⟩.</p>
<p>The actions available to the decision maker are: gather more evidence, choose the option <italic>S</italic>1 (as the least-difficult random dot color patch), or choose the option <italic>S</italic>2. The last two actions terminate the trial and lead to a ‘dummy’ cost-free and absorbing goal state.</p>
<p>As with the models that we fit to the data, the two stimuli are sampled serially in rapid alternation so that we alternate between sampling <italic>S</italic>1 and <italic>S</italic>2 in sequential time steps (Δ<italic>t</italic>).</p>
<p>When stimulus <italic>Sx</italic> is sampled while in state <italic>s</italic>, the agent obtains an evidence sample which is used to update the state to <inline-formula><alternatives><inline-graphic xlink:href="528254v2_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Because one stimulus is sampled at a time, only two of the four variables that define a state can change per new observation. For example, if the stimulus <italic>S</italic>1 is sampled, then <italic>t</italic><sub><italic>S</italic>2</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub> do not change. In turn, since time evolves in steps of Δ<italic>t</italic>, then <italic>t</italic><sup>′</sup> = <italic>t</italic><sub><italic>S</italic>1</sub> + Δ<italic>t</italic>.</p>
<p>To complete the definition of the transition probabilities, it remains only to specify how the probability of <italic>DV</italic><sub><italic>x</italic></sub> changes after sampling stimulus <italic>x</italic>, <italic>P</italic><sub><italic>sample</italic><sub><italic>x</italic></sub></sub> (<italic>DV</italic><sub><italic>x</italic></sub><sup>′</sup>|<italic>s</italic>). As in the models we fit to the data, we assume that the sensory observations follow a normal distribution with mean equal to <italic>k</italic> ⋅ <italic>C</italic><sub><italic>x</italic></sub><sup>±</sup> ⋅ Δ<italic>t</italic> and variance equal to Δ<italic>t</italic>, where <italic>k</italic> is a drift rate coefficient and <italic>C</italic><sub><italic>x</italic></sub><sup>±</sup> is the signed color strength of the sampled patch. If <italic>C</italic><sub><italic>x</italic></sub><sup>±</sup> were known, the values of <italic>DV</italic><sub><italic>x</italic></sub> would follow a normal distribution:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="528254v2_eqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>DV</italic><sub><italic>x</italic></sub> is the state of the decision variable in state <italic>s</italic>, and 𝒩 (·<italic>μ</italic>, Ã<sup>2</sup>) is the normal p.d.f. with mean <italic>μ</italic> and variance Ã<sup>2</sup>.</p>
<p>Since we do not know the color coherence <italic>C</italic><sub><italic>x</italic></sub><sup>±</sup>, we must marginalize over its possible values:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="528254v2_eqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
For clarity of notation we omitted the associated action, <italic>sample</italic><sub><italic>x</italic></sub>. We assume that the decision maker knows the possible values that <italic>C</italic><sub><italic>x</italic></sub><sup>±</sup> can take. The probability distribution over the color coherence values given that one is in state <italic>s</italic>, <italic>P</italic> (<italic>C</italic><sub><italic>x</italic></sub><sup>±</sup>|<italic>s</italic>), can be calculated as (<bold><italic><xref ref-type="bibr" rid="c29">Moreno-Bote, 2010</xref></italic></bold>):
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="528254v2_eqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where the constant of proportionality is such that the sum of <italic>P</italic> (<italic>C</italic><sub><italic>x</italic></sub><sup>±</sup>|<italic>s</italic>) over the possible values of <italic>C</italic><sub><italic>x</italic></sub><sup>±</sup> is equal to 1. The prior <italic>P</italic> (<italic>C</italic><sub><italic>x</italic></sub><sup>±</sup>) is uniformly distributed over the discrete set of unsigned color coherences, as in the experiment.</p>
<p>We find the optimal policy by solving the Bellman equations (as in Drugowitsch et al. ((2012))). Each state <italic>s</italic> has associated with it a value, <italic>V</italic> (<italic>s</italic>), given by the maximum value over the actions applicable in state <italic>s</italic> (in this case we have just sampled <italic>S</italic>2), so that
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="528254v2_eqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>b</italic>(<italic>s</italic>, <italic>Sx</italic>) is the probability that choosing <italic>Sx</italic> is correct in state <italic>s</italic>, <italic>R</italic><sub><italic>c</italic></sub> is the reward obtained for a correct choice, <italic>R</italic><sub><italic>n</italic></sub> is the reward obtained after an incorrect choice, <italic>t</italic><sub><italic>p</italic></sub> is the time penalty after an error, <italic>t</italic><sub><italic>nd</italic></sub> is the average non-decision time, <italic>t</italic><sub><italic>w</italic></sub> is the inter trial interval (from the time a choice is registered to onset of the random dot stimuli for the next trial) and ρ is the expected reward per unit of time.</p>
<p>The probability that choice <italic>Sx</italic> is correct in state <italic>s</italic>, <italic>b</italic>(<italic>s</italic>, choose <italic>Sx</italic>), is the probability that the color strength at stimulus <italic>Sx</italic> is higher than that of the other stimulus, so that:
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="528254v2_eqn9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where the summations are over all possible signed color coherence values, and
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="528254v2_eqn10.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
constrains the summation in <xref rid="eqn9" ref-type="disp-formula">equation 9</xref> to the coherence pairs for which <italic>S</italic>1 is the objectively easier, plus half of the ties. Note that <italic>b</italic>(<italic>s</italic>, choose <italic>S</italic>2) = 1 − <italic>b</italic>(<italic>s</italic>, choose <italic>S</italic>1).</p>
<p>In <xref rid="eqn8" ref-type="disp-formula">equation 8</xref>, if <italic>ρ</italic> (the reward per unit of time) were known, the Bellman equations could be solved in a single backwards pass, assuming that for sufficiently long times the best action is to select one of two terminal actions, and then propagating the value function <italic>V</italic> (<italic>s</italic>) backwards in time. However, <italic>ρ</italic> is not known since it depends on the decision policy itself. Following a usual procedure (<bold><italic><xref ref-type="bibr" rid="c5">Bertsekas et al., 2011</xref></italic></bold>), we find the value of <italic>ρ</italic> by root finding. We solve the Bellman equations by backwards induction for two extreme values of <italic>ρ</italic>, such that the actual value lies between them. Then we divide the range into two halves, keeping the half for which the value of the initial state <italic>V</italic> (<italic>s</italic><sub>0</sub>) has different signs for the extreme values of the range. We repeat this procedure multiple times, gradually bracketing the value of <italic>ρ</italic> in diminishing intervals, until the difference between the value we assume and the one resulting from solving Bellman’s equations is negligible.</p>
<p>Once the value of each state converges to its optimal value, <italic>V</italic> <sup>∗</sup>(<italic>s</italic>), the best action in each state is the one for which the value of the state-action pair, <italic>Q</italic>(<italic>s</italic>, <italic>a</italic>) is equal to <italic>V</italic> <sup>∗</sup>(<italic>s</italic>) (<xref rid="eqn8" ref-type="disp-formula">Eq. 8</xref>). For the analysis shown in <xref rid="fig8" ref-type="fig">Fig. 8</xref>, we simulated 200,000 trials following the optimal policy. The parameters used to make these simulations were: <italic>k</italic> = 13, <italic>R</italic><sub><italic>c</italic></sub> = 1, <italic>R</italic><sub><italic>n</italic></sub> = 0, <italic>t</italic><sub><italic>p</italic></sub> = 1<italic>s</italic>, <italic>t</italic><sub><italic>nd</italic></sub> = 0.4<italic>s</italic>, <italic>t</italic><sub><italic>w</italic></sub> = 0.5<italic>s</italic>, Δ<italic>t</italic> = 0.05<italic>s</italic> and Δ<italic>DV</italic> = 0.1.</p>
<p>The derivation of the optimal policy for the known-color RT task follows the same procedure to the one described above for the case of unknown color, with the only exception that the signed coherences, <italic>C</italic><sup>±</sup>, is replaced by the unsigned coherences, <italic>C</italic><sup>+</sup>.</p>
<p>We did not fit the parameters of the optimal model to the data as the experiment was not designed to incentivize maximization of the reward rate and fitting would have been computationally laborious.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by the National Institutes of Health (R01NS117699 to D.M.W; R01NS113113 to M.N.S.), and the Air Force Office of Scientific Research under award (FA9550-22-1-0337 to D.M.W and M.N.S) the Howard Hughes Medical Institute (M.N.S.), and Kavli Institute for Brain Science (A.L).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="book"><string-name><surname>Acerbi</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>WJ.</given-names></string-name> <chapter-title>Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</chapter-title>. In: <string-name><surname>Guyon</surname> <given-names>I</given-names></string-name>, <string-name><surname>Luxburg</surname> <given-names>UV</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>S</given-names></string-name>, <string-name><surname>Wallach</surname> <given-names>H</given-names></string-name>, <string-name><surname>Fergus</surname> <given-names>R</given-names></string-name>, <string-name><surname>Vishwanathan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Garnett</surname> <given-names>R</given-names></string-name>, editors. <source>Advances in Neural Information Processing Systems</source>, vol. <volume>30</volume> <publisher-name>Curran Associates, Inc.</publisher-name>; <year>2017</year>. p. 1836–1846. <ext-link ext-link-type="uri" xlink:href="https://proceedings.neuripscc/paper/2017/file/df0aab058ce179e4f7ab135ed4e641a9-Paper.pdf">https://proceedings.neuripscc/paper/2017/file/df0aab058ce179e4f7ab135ed4e641a9-Paper.pdf</ext-link>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Ais</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Barttfeld</surname> <given-names>P</given-names></string-name>, <string-name><surname>Sigman</surname> <given-names>M</given-names></string-name>. <article-title>Individual consistency in the accuracy and distribution of confidence judgments</article-title>. <source>Cognition</source>. <year>2016</year>; <volume>146</volume>:<fpage>377</fpage>–<lpage>386</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Bakkour</surname> <given-names>A</given-names></string-name>, <string-name><surname>Palombo</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kang</surname> <given-names>YH</given-names></string-name>, <string-name><surname>Reid</surname> <given-names>A</given-names></string-name>, <string-name><surname>Verfaellie</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Shohamy</surname> <given-names>D</given-names></string-name>. <article-title>The hippocampus supports deliberation during value-based decisions</article-title>. <source>eLife</source>. <year>2019</year>; <volume>8</volume>:<issue>e46080</issue>. doi: <pub-id pub-id-type="doi">10.7554/eLife.46080</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="book"><string-name><surname>Bennett-Pierre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Asaba</surname> <given-names>M</given-names></string-name>, <source>Gweon H. Preschoolers consider expected task difficulty to decide what to do and whom to help</source>. <publisher-loc>In</publisher-loc>: <publisher-name><italic>CogSci</italic></publisher-name>; <year>2018</year>. p. <fpage>1359</fpage>–<lpage>1374</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="book"><string-name><surname>Bertsekas</surname> <given-names>DP</given-names></string-name>, et al. <chapter-title>Dynamic programming and optimal control</chapter-title> <edition>3rd edition</edition>, volume ii. <publisher-loc>Belmont, MA</publisher-loc>: <publisher-name>Athena Scientific</publisher-name>. <year>2011</year>; .</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Brody</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Hanks</surname> <given-names>TD</given-names></string-name>. <article-title>Neural underpinnings of the evidence accumulator</article-title>. <source>Current opinion in neurobiology</source>. <year>2016</year>; <volume>37</volume>:<fpage>149</fpage>–<lpage>157</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Chang</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Cooper</surname> <given-names>G</given-names></string-name>. <article-title>A practical difference scheme for Fokker-Planck equations</article-title>. <source>Journal of Computational Physics</source>. <year>1970</year>; <volume>6</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>16</lpage>. doi: <pub-id pub-id-type="doi">10.1016/0021-9991(70)90001-X</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Chmielewski</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kucker</surname> <given-names>SC</given-names></string-name>. <article-title>An MTurk Crisis? Shifts in Data Quality and the Impact on Study Results</article-title>. <source>Social Psychological and Personality Science</source>. <year>2020</year>; <volume>11</volume>(<issue>4</issue>):<fpage>464</fpage>–<lpage>473</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Cisek</surname> <given-names>P</given-names></string-name>, <string-name><surname>Puskas</surname> <given-names>GA</given-names></string-name>, <string-name><surname>El-Murr</surname> <given-names>S</given-names></string-name>. <article-title>Decisions in changing conditions: the urgency-gating model</article-title>. <source>Journal of Neuroscience</source>. <year>2009</year>; <volume>29</volume>(<issue>37</issue>):<fpage>11560</fpage>–<lpage>11571</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>De Leeuw</surname> <given-names>JR</given-names></string-name>. <article-title>jsPsych: A JavaScript library for creating behavioral experiments in a Web browser</article-title>. <source>Behavior research methods</source>. <year>2015</year>; <volume>47</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>. doi: <pub-id pub-id-type="doi">10.3758/s13428-014-0458-y</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Desender</surname> <given-names>K</given-names></string-name>, <string-name><surname>Van Opstal</surname> <given-names>F</given-names></string-name>, Van den Bussche E. <article-title>Subjective experience of difficulty depends on multiple cues</article-title>. <source>Scientific reports</source>. <year>2017</year>; <volume>7</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Drugowitsch</surname> <given-names>J</given-names></string-name>, <string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>. <article-title>The cost of accumulating evidence in perceptual decision making</article-title>. <source>Journal of Neuroscience</source>. <year>2012</year>; <volume>32</volume>(<issue>11</issue>):<fpage>3612</fpage>–<lpage>3628</lpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Dunn</surname> <given-names>T</given-names></string-name>, <string-name><surname>Inzlicht</surname> <given-names>M</given-names></string-name>, <string-name><surname>Risko</surname> <given-names>E</given-names></string-name>. <article-title>Anticipating cognitive effort: roles of perceived error-likelihood and time demands</article-title>. <source>Psychol Res</source>. <year>2019</year>; <volume>83</volume>(<issue>5</issue>):<fpage>1033</fpage>–<lpage>1056</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Fakcharoenphol</surname> <given-names>W</given-names></string-name>, <string-name><surname>Morphew</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Mestre</surname> <given-names>JP</given-names></string-name>. <article-title>Judgments of physics problem difficulty among experts and novices</article-title>. <source>Physical review special topics-physics education research</source>. <year>2015</year>; <volume>11</volume>(<issue>2</issue>):<fpage>020128</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><given-names>Fernandez</given-names> <surname>Slezak D</surname></string-name>, <string-name><surname>Sigman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Cecchi</surname> <given-names>GA</given-names></string-name>. <article-title>An entropic barriers diffusion theory of decision-making in multiple alternative tasks</article-title>. <source>PLOS Computational Biology</source>. <year>2018</year>; <volume>14</volume>(<issue>3</issue>):<fpage>e1005961</fpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Fleming</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Massoni</surname> <given-names>S</given-names></string-name>, <string-name><surname>Gajdos</surname> <given-names>T</given-names></string-name>, <string-name><surname>Vergnaud</surname> <given-names>JC</given-names></string-name>. <article-title>Metacognition about the past and future: quantifying common and distinct influences on prospective and retrospective judgments of self-performance</article-title>. <source>Neuroscience of Consciousness</source>. 2016; <year>2016</year>(<volume>1</volume>):niw018.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Frazier</surname> <given-names>P</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>AJ</given-names></string-name>. <article-title>Sequential hypothesis testing under stochastic deadlines</article-title>. <source>Advances in neural information processing systems</source>. <year>2007</year>; <volume>20</volume>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>de Gardelle</surname> <given-names>V</given-names></string-name>, <string-name><surname>Le Corre</surname> <given-names>F</given-names></string-name>, <string-name><surname>Mamassian</surname> <given-names>P</given-names></string-name>. <article-title>Confidence as a common currency between vision and audition</article-title>. <source>Plos one</source>. <year>2016</year>; <volume>11</volume>(<issue>1</issue>):<fpage>e0147901</fpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Geffner</surname> <given-names>H</given-names></string-name>, <string-name><surname>Bonet</surname> <given-names>B</given-names></string-name>. <article-title>A concise introduction to models and methods for automated planning</article-title>. <source>Synthesis Lectures on Artificial Intelligence and Machine Learning</source>. <year>2013</year>; <volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>141</lpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Gold</surname> <given-names>JI</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <etal>et al.</etal> <article-title>The neural basis of decision making</article-title>. <source>Annual review of neuroscience</source>. <year>2007</year>; <volume>30</volume>(<issue>1</issue>):<fpage>535</fpage>– <lpage>574</lpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="book"><string-name><surname>Gweon</surname> <given-names>H</given-names></string-name>, <string-name><surname>Asaba</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bennett-Pierre</surname> <given-names>G</given-names></string-name>. <chapter-title>Reverse-engineering the process: Adults’ and preschoolers’ ability to infer the difficulty of novel tasks</chapter-title>. In: <source>Reverse-engineering the process: Adults’ and preschoolers’ ability to infer the difficulty of novel tasks</source>., vol. <publisher-name>CogSci</publisher-name>; <year>2017</year>. p. <fpage>458</fpage>–<lpage>463</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Hanks</surname> <given-names>TD</given-names></string-name>, <string-name><surname>Mazurek</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Hopp</surname> <given-names>E</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Elapsed decision time affects the weighting of prior probability in a perceptual decision task</article-title>. <source>J Neurosci</source>. <year>2011</year>; <volume>31</volume>(<issue>17</issue>):<fpage>6339</fpage>–<lpage>6352</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5613-10.2011</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Kang</surname> <given-names>YH</given-names></string-name>, <string-name><surname>Löffler</surname> <given-names>A</given-names></string-name>, <string-name><surname>Jeurissen</surname> <given-names>D</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Multiple decisions about one object involve parallel sensory acquisition but time-multiplexed evidence incorporation</article-title>. <source>Elife</source>. <year>2021</year>; <volume>10</volume>:<issue>e63721</issue>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>. <source>Science</source>. <year>2009</year>; <volume>324</volume>(<issue>5928</issue>):<fpage>759</fpage>–<lpage>764</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1169405</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Corthell</surname> <given-names>L</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Choice certainty is informed by both evidence and decision time</article-title>. <source>Neuron</source>. <year>2014</year>; <volume>84</volume>(<issue>6</issue>):<fpage>1329</fpage>–<lpage>1342</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Li</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Joo</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Yeatman</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Reinecke</surname> <given-names>K</given-names></string-name>. <article-title>Controlling for participants’ viewing distance in large-scale, psychophysical online experiments using a virtual chinrest</article-title>. <source>Sci Rep</source>. <year>2020</year>; <volume>10</volume>:<issue>904</issue>. doi: <pub-id pub-id-type="doi">10.1038/s41598-019-57204-1</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Mamassian</surname> <given-names>P</given-names></string-name>. <article-title>Confidence forced-choice and other metaperceptual tasks</article-title>. <source>Perception</source>. <year>2020</year>; <volume>49</volume>(<issue>6</issue>):<fpage>616</fpage>–<lpage>635</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Mante</surname> <given-names>V</given-names></string-name>, <string-name><surname>Sussillo</surname> <given-names>D</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title>. <source>Nature</source>. <year>2013</year>; <volume>503</volume>:<fpage>78</fpage>–<lpage>84</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nature12742</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>. <article-title>Decision confidence and uncertainty in diffusion models with partially correlated neuronal integrators</article-title>. <source>Neural computation</source>. <year>2010</year>; <volume>22</volume>(<issue>7</issue>):<fpage>1786</fpage>–<lpage>1811</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Morgan</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kornell</surname> <given-names>N</given-names></string-name>, <string-name><surname>Kornblum</surname> <given-names>T</given-names></string-name>, <string-name><surname>Terrace</surname> <given-names>HS</given-names></string-name>. <article-title>Retrospective and prospective metacognitive judgments in rhesus macaques (Macaca mulatta)</article-title>. <source>Animal cognition</source>. <year>2014</year>; <volume>17</volume>(<issue>2</issue>):<fpage>249</fpage>–<lpage>257</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Moskowitz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Gale</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Gallivan</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Flanagan</surname> <given-names>JR</given-names></string-name>. <article-title>Human decision making anticipates future performance in motor learning</article-title>. <source>PLoS Computational Biology</source>. <year>2020</year>; <volume>16</volume>(<issue>2</issue>):<fpage>e1007632</fpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Palmer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Huk</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>The effect of stimulus strength on the speed and accuracy of a perceptual decision</article-title>. <source>J Vis</source>. <year>2005</year>; <volume>5</volume>(<issue>5</issue>):<fpage>376</fpage>–<lpage>404</lpage>. doi: <pub-id pub-id-type="doi">10.1167/5.5.1</pub-id>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Pashler</surname> <given-names>H</given-names></string-name>. <article-title>Dual-task interference in simple tasks: data and theory</article-title>. <source>Psychological bulletin</source>. <year>1994</year>; <volume>116</volume>(<issue>2</issue>):<fpage>220</fpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Peirce</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Jastrow</surname> <given-names>J</given-names></string-name>. <article-title>On small differences in sensation</article-title>. <source>Memoirs of the National Academy of Sciences</source>. <year>1884</year>; <volume>3</volume>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Rapoport</surname> <given-names>A</given-names></string-name>, <string-name><surname>Burkheimer</surname> <given-names>GJ</given-names></string-name>. <article-title>Models for deferred decision making</article-title>. <source>Journal of Mathematical Psychology</source>. <year>1971</year>; <volume>8</volume>(<issue>4</issue>):<fpage>508</fpage>–<lpage>538</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Rigoux</surname> <given-names>L</given-names></string-name>, <string-name><surname>Stephan</surname> <given-names>KE</given-names></string-name>, <string-name><surname>Friston</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Daunizeau</surname> <given-names>J</given-names></string-name>. <article-title>Bayesian model selection for group studies—revisited</article-title>. <source>Neuroimage</source>. <year>2014</year>; <volume>84</volume>:<fpage>971</fpage>–<lpage>985</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Sepulveda</surname> <given-names>P</given-names></string-name>, <string-name><surname>Usher</surname> <given-names>M</given-names></string-name>, <string-name><surname>Davies</surname> <given-names>N</given-names></string-name>, <string-name><surname>Benson</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Ortoleva</surname> <given-names>P</given-names></string-name>, <string-name><surname>De Martino</surname> <given-names>B</given-names></string-name>. <article-title>Visual attention modulates the integration of goal-relevant evidence and not value</article-title>. <source>Elife</source>. <year>2020</year>; <volume>9</volume>:<issue>e60705</issue>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>. <article-title>Decision making as a window on cognition</article-title>. <source>Neuron</source>. <year>2013</year>; <volume>80</volume>(<issue>3</issue>):<fpage>791</fpage>–<lpage>806</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Shenhav</surname> <given-names>A</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <article-title>The expected value of control: an integrative theory of anterior cingulate cortex function</article-title>. <source>Neuron</source>. <year>2013</year>; <volume>79</volume>(<issue>2</issue>):<fpage>217</fpage>–<lpage>240</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Siedlecka</surname> <given-names>M</given-names></string-name>, <string-name><surname>Paulewicz</surname> <given-names>B</given-names></string-name>, <string-name><surname>Wierzchoń</surname> <given-names>M</given-names></string-name>. <article-title>But I was so sure! Metacognitive judgments are less accurate given prospectively than retrospectively</article-title>. <source>Frontiers in psychology</source>. <year>2016</year>; <volume>7</volume>:<issue>218</issue>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Smith</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Krajbich</surname> <given-names>I</given-names></string-name>. <article-title>Gaze amplifies value in decision making</article-title>. <source>Psychological science</source>. <year>2019</year>; <volume>30</volume>(<issue>1</issue>):<fpage>116</fpage>–<lpage>128</lpage>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Stein</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Bransford</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Franks</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Vye</surname> <given-names>NJ</given-names></string-name>, <string-name><surname>Perfetto</surname> <given-names>GA</given-names></string-name>. <article-title>Differences in judgments of learning difficulty</article-title>. <source>Journal of Experimental Psychology: General</source>. <year>1982</year>; <volume>111</volume>(<issue>4</issue>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Stephan</surname> <given-names>KE</given-names></string-name>, <string-name><surname>Penny</surname> <given-names>WD</given-names></string-name>, <string-name><surname>Daunizeau</surname> <given-names>J</given-names></string-name>, <string-name><surname>Moran</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Friston</surname> <given-names>KJ</given-names></string-name>. <article-title>Bayesian model selection for group studies</article-title>. <source>Neuroimage</source>. <year>2009</year>; <volume>46</volume>(<issue>4</issue>):<fpage>1004</fpage>–<lpage>1017</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Stine</surname> <given-names>GM</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ditterich</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Differentiating between integration and non-integration strategies in perceptual decision making</article-title>. <source>Elife</source>. <year>2020</year>; <volume>9</volume>:<issue>e55365</issue>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><given-names>Van Den</given-names> <surname>Berg R</surname></string-name>, <string-name><surname>Anandalingam</surname> <given-names>K</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>. <article-title>A common mechanism underlies changes of mind about decisions and confidence</article-title>. <source>Elife</source>. <year>2016</year>; <volume>5</volume>:<issue>e12192</issue>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Vangsness</surname> <given-names>L</given-names></string-name>, <string-name><surname>Young</surname> <given-names>M</given-names></string-name>. <article-title>Central and Peripheral Cues to Difficulty in a Dynamic Task</article-title>. <source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source>. <year>2019</year>; <volume>61</volume>(<issue>5</issue>):<fpage>749</fpage>–<lpage>762</lpage>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Wisniewski</surname> <given-names>D</given-names></string-name>, <string-name><surname>Reverberi</surname> <given-names>C</given-names></string-name>, <string-name><surname>Tusche</surname> <given-names>A</given-names></string-name>, <string-name><surname>Haynes</surname> <given-names>JD</given-names></string-name>. <article-title>The neural representation of voluntary task-set selection in dynamic environments</article-title>. <source>Cerebral Cortex</source>. <year>2015</year>; <volume>25</volume>(<issue>12</issue>):<fpage>4715</fpage>–<lpage>4726</lpage>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="other"><string-name><surname>Yildirim</surname> <given-names>I</given-names></string-name>, <string-name><surname>Saeed</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bennett-Pierre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Gerstenberg</surname> <given-names>T</given-names></string-name>, <string-name><surname>Tenenbaum</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gweon</surname> <given-names>H.</given-names></string-name> <article-title>Explaining intuitive difficulty judgments by modeling physical effort and risk</article-title>. arXiv preprint arXiv:190504445. 2019; .</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <article-title>Counterfactual reasoning underlies the learning of priors in decision making</article-title>. <source>Neuron</source>. <year>2018</year>; <volume>99</volume>(<issue>5</issue>):<fpage>1083</fpage>–<lpage>1097</lpage>.e6. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.035</pub-id>.</mixed-citation></ref>
</ref-list>
<sec id="s4">
<title>Supporting Information</title>
<table-wrap id="tbls1" orientation="portrait" position="float">
<label>Table S1.</label><caption><p>Fit parameter values for drift diffusion model of color judgments (Exp. 1a).</p></caption>
<graphic xlink:href="528254v2_tbls1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbls2" orientation="portrait" position="float">
<label>Table S2.</label><caption><p>Fit parameter values for Race model (Exp. 1).</p></caption>
<graphic xlink:href="528254v2_tbls2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbls3" orientation="portrait" position="float">
<label>Table S3.</label><caption><p>Fit parameter values for Two-step model (Exp. 1).</p></caption>
<graphic xlink:href="528254v2_tbls3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbls4" orientation="portrait" position="float">
<label>Table S4.</label><caption><p>Fit parameter values for Absolute momentary evidence model (Exp. 1).</p></caption>
<graphic xlink:href="528254v2_tbls4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbls5" orientation="portrait" position="float">
<label>Table S5.</label><caption><p>Fit parameter values for Difference model in reaction time task (Exp. 2).</p></caption>
<graphic xlink:href="528254v2_tbls5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbls6" orientation="portrait" position="float">
<label>Table S6.</label><caption><p>Fit parameter values for Difference model in controlled duration task (Exp. 2). The high <italic>u</italic> parameter for subject 2 implies that the decision process was not bounded.</p></caption>
<graphic xlink:href="528254v2_tbls6.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbls7" orientation="portrait" position="float">
<label>Table S7.</label><caption><p>Fit parameter values for Confidence model in reaction time task (Exp. 2).</p></caption>
<graphic xlink:href="528254v2_tbls7.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wyart</surname>
<given-names>Valentin</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Inserm</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This behavioral modeling study investigates how humans make decisions on the difficulty of perceptual categorization tasks. The study finds that such judgments are best described by an evidence-accumulation model that includes a dynamic comparison of difficulty-related evidence, which terminates when the difference in evidence between two tasks reaches a predetermined bound – a <bold>valuable</bold> finding for research in perceptual decision-making. The paper provides <bold>compelling</bold> behavioral evidence for the proposed model through: 1) quantitative model selection/validation procedures, and 2) qualitative analyses of the relation between the optimal model of the task and the human data (and the proposed model).</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Meta-cognition, and difficulty judgments specifically, is an important part of daily decision-making. When facing two competing tasks, individuals often need to make quick judgments on which task they should approach (whether their goal is to complete an easy or a difficult task).</p>
<p>In the study, subjects face two perceptual tasks on the same screen. Each task is a cloud of dots with a dominating color (yellow or blue), with a varying degree of domination - so each cloud (as a representation of a task where the subject has to judge which color is dominant) can be seen an easy or a difficult task. Observing both, the subject has to decide which one is easier.</p>
<p>It is well-known that choices and response times in each separate task can be described by a drift-diffusion model, where the decision maker accumulates evidence toward one of the decisions (&quot;blue&quot; or &quot;yellow&quot;) over time, making a choice when the accumulated evidence reaches a predetermined bound. However, we do not know what happens when an individual has to make two such judgments at the same time, without actually making a choice, but simply deciding which task would have stronger evidence toward one of the options (so would be easier to solve).</p>
<p>It is clear that the degree of color dominance (&quot;color strength&quot; in the study's terms) of both clouds should affect the decision on which task is easier, as well as the total decision time. Experiment 1 clearly shows that color strength has a simple cumulative effect on choice: cloud 1 is more likely to be chosen if it is easier and cloud 2 is harder. Response times, however, show a more complex interactive pattern: when cloud 2 is hard, easier cloud 1 produces faster decisions. When cloud 2 is easy, easier cloud 1 produces slower decisions.</p>
<p>The study explores several models that explain this effect. The best-fitting model (the Difference model is the paper's terminology) assumes that the decision-maker accumulates evidence in both clouds simultaneously and makes a difficulty judgment as soon as the difference between the values of these decision variables reaches a certain threshold. Another potential model that provides a slightly worse fit to the data is a two-step model. First, the decision maker evaluates the dominant color of each cloud, then judges the difficulty based on this information.</p>
<p>Importantly, the study explores an optimal model based on the Markov decision processes approach. This model shows a very similar qualitative pattern in RT predictions but is too complex to fit to the real data. Possibly, the fact that simple approaches such as the Difference model fit the data best could suggest the existence of some cognitive constraints that play a role in difficulty judgments and could be explored in future research.</p>
<p>The Difference model produces a well-defined qualitative prediction: if the dominant color of both clouds is known to the decision maker, the overall RT effect (hard-hard trials are slower than easy-easy trials) should disappear. Essentially, that turns the model into the second stage of the two-stage model, where the decision maker learns the dominant colors first. The data from Experiment 2 impressively confirms that prediction and provides a good demonstration of how the model can explain the data out-of-sample with a predicted change in context.</p>
<p>Overall, the study provides a very coherent and clean set of predictions and analyses that advance our understanding of meta-cognition. The field would benefit from further exploration of differences between the models presented and new competing predictions (for instance, exploring how the sequential presentation of stimuli or attentional behavior can impact such judgments). Finally, the study provides a solid foundation for future neuroimaging investigations.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Starting from the observation that difficulty estimation lies at the core of human cognition, the authors acknowledge that despite extensive work focusing on the computational mechanisms of decision-making, little is known about how subjective judgments of task difficulty are made. Instantiating the question with a perceptual decision-making task, the authors found that how humans pick the easiest of two stimuli, and how quickly these difficulty judgments are made, are best described by a simple evidence accumulation model. In this model, perceptual evidence of concurrent stimuli is accumulated and difficulty is determined by the difference between the absolute values of decision variables corresponding to each stimulus, combined with a threshold crossing mechanism. Altogether, these results strengthen the success of evidence accumulation models in describing human decision-making, now extending it to judgments of difficulty.</p>
<p>The manuscript addresses a timely question and is very well written, with its goals, methods and findings clearly explained and directly relating to each other. The authors are specialists of evidence accumulation tasks and models. Their modelling of human behaviour within this framework is state-of-the-art. In particular, their model comparison is guided by qualitative signatures which are diagnostic to tease apart different models (e.g., the RT criss-cross pattern). Human behaviour is then inspected for these signatures, instead of relying exclusively on quantitative comparison of goodness-of-fit metrics.</p>
<p>The study has potential limitations well flagged by the authors after the revision process. The main limitation pertains to the (dis)similarity between the behavioural task used in the study and difficulty judgments people actually do in real world (and which are well illustrated in the introduction). First, difficulty judgments made in the task never impact the participant (a new trial simply follows) while difficulty judgments in the wild often determine whether to pursue or quit the corresponding task, which can have consequences years after the difficulty estimation (e.g., deciding to engage in a particular academic path as a function of the estimated difficulty). Second, while trial-by-trial feedback is delivered in the task, difficulty estimation in the wild has to be made with partial information and feedback is either absent or delayed. How much these differences are key in providing an accurate computational description of human difficulty judgments will likely require further research.</p>
<p>Another limitation is the absence of models based on computational principles other than evidence accumulation. Although there are good reasons to favour evidence accumulation models in these settings (as mentioned by the authors in their manuscript), showing that evidence accumulation models would have won against competitors would have further strengthened the authors' claim that difficulty judgment about perceptual information are firmly anchored in the principles of evidence accumulation.</p>
<p>These limitations should not distract the reader from the impact of the present work, which will likely be wide, spanning the whole field of decision-making, and this across species. It will echo in particular with the many other seminal studies that have relied on a similar theoretical account of behaviour and brain activity (evidence accumulation). In addition, this study will hopefully inspire novel task designs aiming at addressing difficulty judgment estimations in controlled lab experiments, possibly with features closer to real world difficulty estimation (e.g., long-term consequences of difficulty estimation and absence of feedback).</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.2.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The manuscript presents novel findings regarding the judgment of difficulty of perceptual decisions. In the main task (Experiment 1), participants accumulated evidence over time about two tasks, patches of random dot motion, and were asked to report for which patch it would be easier to make a decision about its dominant color, while not explicitly making such decision(s). By fitting several alternative models, authors demonstrated that while accuracy changes as a function of the difference between stimulus strengths, reaction times of such decisions are not solely governed by the difference in stimulus strength, but (also) by the difference in absolute accumulated evidence for color judgment of the two stimuli ('Difference model'). Predictions from the best fitted model were then tested with a new set of conditions and participants (Experiment 2). Here, authors eliminated part of the uncertainty by informing participants about the dominant color of the two stimuli ('known color' condition) and showing that reaction times were faster compared to the 'unknown color' task, and only depended on the difference between stimulus strengths.</p>
<p>The paper deals with a valuable question about a metacognitive aspect of perceptual decision making, which was only sparsely addressed before. The paper is very well written, figures and illustrations clearly accompanied the text, and methods and modeling are rigor. The authors also address the concern that a difficulty judgment might be a confidence estimation, another metacognitive judgment of perceptual decisions, by fitting a Confidence model to the 'known color' condition in Experiment 2 and showing that this model performs worse compared to the Difference model. This is an important control analysis, given the possibility that humans might make an implicit decision about the dominant color of each patch, and then report their level of confidence.</p>
<p>This work is likely to be of great interest in the field of behavioral modeling of perceptual decision making, and might encourage further investigations of how judging the difficulty of a task affects subsequent decisions about the same task.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.2.sa4</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Löffler</surname>
<given-names>Anne</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zylberberg</surname>
<given-names>Ariel</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2572-4748</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Shadlen</surname>
<given-names>Michael N.</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wolpert</surname>
<given-names>Daniel M.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2011-2790</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Meta-cognition, and difficulty judgments specifically, is an important part of daily decision-making. When facing two competing tasks, individuals often need to make quick judgments on which task they should approach (whether their goal is to complete an easy or a difficult task).</p>
<p>In the study, subjects face two perceptual tasks on the same screen. Each task is a cloud of dots with a dominating color (yellow or blue), with a varying degree of domination - so each cloud (as a representation of a task where the subject has to judge which color is dominant) can be seen an easy or a difficult task. Observing both, the subject has to decide which one is easier.</p>
<p>It is well-known that choices and response times in each separate task can be described by a driftdiffusion model, where the decision maker accumulates evidence toward one of the decisions (”blue” or ”yellow”) over time, making a choice when the accumulated evidence reaches a predetermined bound. However, we do not know what happens when an individual has to make two such judgments at the same time, without actually making a choice, but simply deciding which task would have stronger evidence toward one of the options (so would be easier to solve).</p>
<p>It is clear that the degree of color dominance (”color strength” in the study’s terms) of both clouds should affect the decision on which task is easier, as well as the total decision time. Experiment 1 clearly shows that color strength has a simple cumulative effect on choice: cloud 1 is more likely to be chosen if it is easier and cloud 2 is harder. Response times, however, show a more complex interactive pattern: when cloud 2 is hard, easier cloud 1 produces faster decisions. When cloud 2
is easy, easier cloud 1 produces slower decisions.</p>
<p>The study explores several models that explain this effect. The best-fitting model (the Difference model is the paper’s terminology) assumes that the decision-maker accumulates evidence in both clouds simultaneously and makes a difficulty judgment as soon as the difference between the values of these decision variables reaches a certain threshold. Another potential model that provides a slightly worse fit to the data is a two-step model. First, the decision maker evaluates the dominant color of each cloud, then judges the difficulty based on this information.</p>
</disp-quote>
<p>Thank you for a very good summary of our work.</p>
<disp-quote content-type="editor-comment">
<p>Importantly, the study explores an optimal model based on the Markov decision processes approach. This model shows a very similar qualitative pattern in RT predictions but is too complex to fit to the real data. It is hard to judge from the results of the study how the models identified above are specifically related to the optimal model - possibly, the fact that simple approaches such as the Difference model fit the data best could suggest the existence of some cognitive constraints that play a role in difficulty judgments.</p>
</disp-quote>
<p>The reviewer asks “how the models identified above are specifically related to the optimal model”. We did fit the four models to simulations of the optimal model and found that the Difference model was the closest. However, we did not fit the parameters of the optimal model to the data (no easy feat given the complexity of the model) as the experiment was not designed to incentivize maximization of the reward rate and fitting would have been computationally laborious. We therefore focused on the qualitative features of the optimal model and how they compare to our models. We now also include the optimal model for the known color dominance RT experiment (line 420). We have also added a new paragraph in the Discussion on the optimal model at line 503 comparing it qualitatively to the Difference model.</p>
<disp-quote content-type="editor-comment">
<p>The Difference model produces a well-defined qualitative prediction: if the dominant color of both clouds is known to the decision maker, the overall RT effect (hard-hard trials are slower than easyeasy trials) should disappear. Essentially, that turns the model into the second stage of the twostage model, where the decision maker learns the dominant colors first. The data from Experiment 2 impressively confirms that prediction and provides a good demonstration of how the model can explain the data out-of-sample with a predicted change in context.</p>
<p>Overall, the study provides a very coherent and clean set of predictions and analyses that advance our understanding of meta-cognition. The field would benefit from further exploration of differences between the models presented and new competing predictions (for instance, exploring how the sequential presentation of stimuli or attentional behavior can impact such judgments). Finally, the study provides a solid foundation for future neuroimaging investigations.</p>
</disp-quote>
<p>Thank you for your positive comments and suggestions.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Starting from the observation that difficulty estimation lies at the core of human cognition, the authors acknowledge that despite extensive work focusing on the computational mechanisms of decision-making, little is known about how subjective judgments of task difficulty are made. Instantiating the question with a perceptual decision-making task, the authors found that how humans pick the easiest of two stimuli, and how quickly these difficulty judgments are made, are best described by a simple evidence accumulation model. In this model, perceptual evidence of concurrent stimuli is accumulated and difficulty is determined by the difference between the absolute values of decision variables corresponding to each stimulus, combined with a threshold crossing mechanism. Altogether, these results strengthen the success of evidence accumulation models, and more broadly sequential sampling models, in describing human decision-making, now extending it to judgments of difficulty.</p>
<p>The manuscript addresses a timely question and is very well written, with its goals, methods and findings clearly explained and directly relating to each other. The authors are specialists in evidence accumulation tasks and models. Their modelling of human behaviour within this framework is state-of-the-art. In particular, their model comparison is guided by qualitative signatures which are diagnostic to tease apart the different models (e.g., the RT criss-cross pattern). Human behaviour is then inspected for these signatures, instead of relying exclusively on quantitative comparison of goodness-of-fit metrics. This work will likely have a wide impact in the field of decisionmaking, and this across species. It will echo in particular with many other studies relying on the similar theoretical account of behaviour (evidence accumulation).</p>
</disp-quote>
<p>Thank you for these generous comments.</p>
<disp-quote content-type="editor-comment">
<p>A few points nevertheless came to my attention while reading the manuscript, which the authors might find useful to answer or address in a new version of their manuscript.</p>
<p>1. The authors acknowledge that difficulty estimation occurs notably before exploration (e.g., attempting a new recipe) or learning (e.g., learning a new musical piece) situations. Motivated by the fact that naturalistic tasks make difficult the identification of the inference process underlying difficulty judgments, the authors instead chose a simple perceptual decision-making task to address their question. While I generally agree with the authors’s general diagnostic, I am nevertheless concerned so as to whether the task really captures the cognitive process of interest as described in the introduction. As coined by the authors themselves, the main function of prospective difficulty judgment is to select a task which will then ultimately be performed, or reject one which won’t. However, in the task presented here, participants are asked to produce difficulty judgments without those judgements actually impacting the future in the task. A feature thus key to difficulty judgments thus seems lacking from the task. Furthermore, the trial-by-trial feedback provided to participants also likely differ from difficulty judgments made in real world. This comment is probably difficult to address but it might generally be useful to discuss the limitations of the task, in particular in probing the desired cognitive process as described in introduction. Currently, no limitations are discussed.</p>
</disp-quote>
<p>We have added a Limitations paragraph to the Discussion and one item we deal with is the generalization of the model to more complex tasks (line 539).</p>
<disp-quote content-type="editor-comment">
<p>1. The authors take their findings as the general indication that humans rely on accumulation evidence mechanisms to probe the difficulty of perceptual decisions. I would probably have been slightly more cautious in excluding alternative explanations. First, only accumulation models are compared. It is thus simply not possible to reach a different conclusion. Second, even though it is particularly compelling to see untested predictions from the winning model in experiment #1 to be directly tested, and validated in a second experiment, that second experiment presents data from only 3 participants (1 of which has slightly different behaviour than the 2 others), thereby limiting the generality of the findings. Third, the winning model in experiment #1 (difference model) is the preferred model on 12 participants, out of the 20 tested ones. Fourth, the raw BIC values are compared against each other in absolute terms without relying on significance testing of the differences in model frequency within the sample of participants (e.g., using exceedance probabilities; see Stephan et al., 2009 and Rigoux et al., 2014). Based on these different observations, I would thus have interpreted the results of the study with a bit more caution and avoided concluding too widely about the generality of the findings.</p>
</disp-quote>
<p>Thank you for these suggestions.</p>
<p>i)  We have now make it clear in the Results (line 126) that all four models we examine are accumu-lation models. In addition, we have added a paragraph on Limitations (line 530) in the Discussion where we explain why we only consider accumulation models and acknowledge that there are other non-accumulation models.</p>
<p>ii) Each of three participants in Experiment 2 performed 18 sessions making it a large and valuabledataset necessary to test our hypothesis. We have now included a mention of the the small number of participants in Experiment 2 in a Limitations paragraph in the Discussion (line 539).</p>
<p>iii) As suggested, we have now calculated exceedance probabilities for the 4 models which gives[0,0.97,0.03,0]. This shows that there is a 0.97 probability of the Difference model being the most frequent and only a 0.03 probability of the two-step model. We have included this in the results on line 237.</p>
<disp-quote content-type="editor-comment">
<p>1. Deriving and describing the optimal model of the task was particularly appreciated. It was however a bit disappointing not to see how well the optimal model explains participants behaviour and whether it does so better than the other considered models. Also, it would have been helpful to see how close each of the 4 models compared in Figures 2 &amp; 3 get to the optimal solution. Note however that neither of these comments are needed to support the authors’ claims.</p>
</disp-quote>
<p>The reviewer asks how close each of the four models is to the optimal solution. We did fit the four models to simulations of the optimal model and found that the Difference model was the closest. However, we did not fit the parameters of the optimal model to the data (no easy feat given the complexity of the model) as the experiment was not designed to incentivize maximization of the reward rate and fitting would have been computationally laborious. We therefore focused on the qualitative features of the optimal model and how they compare to our models. We now also include the optimal model for the known color dominance RT experiment (line 420). We have also added a new paragraph in the Discussion on the optimal model at line 503 comparing it qualitatively to the Difference model.</p>
<disp-quote content-type="editor-comment">
<p>1. The authors compared the difficulty vs. color judgment conditions to conclude that the accumulation process subtending difficulty judgements is partly distinct from the accumulation process leading to perceptual decisions themselves. To do so, they directly compared reaction times obtained in these two conditions (e.g. ”in other cases, the two perceptual decisions are almost certainly completed before the difficulty decision”). However, I find it difficult to directly compare the ’color’ and ’difficulty’ conditions as the latter entails a single stimulus while the former comprises two stimuli. Any reaction-time difference between conditions could thus I believe only follow from asymmetric perceptual/cognitive load between conditions (at least in the sense RT-color &lt; RT-difficulty). One alternative could have been to present two stimuli in the ’color’ condition as well, and asking participants to judge both (or probe which to judge later in the trial). Implementing this now would however require to run a whole new experiment which is likely too demanding. Perhaps the authors could instead also acknowledge that this a critical difference between their conditions, which makes direct comparison difficult.</p>
</disp-quote>
<p>We feel we can rule out that participants make color decisions (as in the color task) to make difficulty decisions. For example, making a color choice for 0% color strength takes longer than a difficulty choice for 0:52% color strengths. Thus, the difficulty judgment does not require completion of the color decisions. Therefore, average reaction time for a single color patch (C𝑆1) can be longer than the reaction time for the difficulty task which contains the same coherence (C𝑆1) for one of the patches. This is true despite the difficulty decision requiring monitoring of two patches
(which might be expected to be slower than monitoring one patch). We have added this in to the Discussion at line 449.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>The manuscript presents novel findings regarding the metacognitive judgment of difficulty of perceptual decisions. In the main task, subjects accumulated evidence over time about two patches of random dot motion, and were asked to report for which patch it would be easier to make a decision about its dominant color, while not explicitly making such decision(s). Using 4 models of difficulty decisions, the authors demonstrate that the reaction time of these decisions are not solely governed by the difference in difficulties between patches (i.e., difference in stimulus strength), but (also) by the difference in absolute accumulated evidence for color judgment of the two stimuli. In an additional experiment, the authors eliminated part of the uncertainty by informing participants about the dominant color of the two stimuli. In this case, reaction times were faster compared to the original task, and only depended on the difference between stimulus strength.</p>
<p>Overall, the paper is very well written, figures and illustrations clearly and adequately accompanied the text, and the method and modeling are rigor.</p>
<p>The weakness of the paper is that it does not provide sufficient evidence to rule out the possibility that judging the difficulty of a decision may actually be comparing between levels of confidence about the dominant color of each stimulus. One may claim that an observer makes an implicit color decision about each stimulus, and then compares the confidence levels about the correctness of the decisions. This concern is reflected in the paper in several ways:</p>
</disp-quote>
<p>We tested a Difference in confidence model (line 315) in the orginal paper and showed it was inferior to the Difference model. We did this for experiment 2, RT task so that we could fit the unknown color condition and try to predict the known color condition. To emphasize this model (which we think the reviewer may have missed) we have moved the supplementary figure to the main results (now Fig. 6) as we think it is very cool that we were able to discard the confidence model.</p>
<p>When comparing the confidence model to the Difference we found the difference model was pre-Δ ferred with BIC of 38, 56, 47. We are unsure why the reviewer feels this “does not provide sufficient evidence to rule out the possibility that judging the difficulty of a decision may actually be comparing between levels of confidence about the dominant color of each stimulus.” We regard this as strong evidence.</p>
<disp-quote content-type="editor-comment">
<p>1. It is not clear what were the actual instructors to the participants, as two different phrasings appear in the methods: one instructs participants to indicate which stimulus is the easier one and the other instructs them to indicate the patch with the stronger color dominance. If both instructions are the same, it can be assumed that knowing the dominant color of each patch is in fact solving the task, and no judgment of difficulty needs to be made (perhaps a confidence estimation). Since this is not a classical perceptual task where subjects need to address a certain feature of the stimuli, but rather to judge their difficulties, it is important to make it clear.</p>
</disp-quote>
<p>We now include the precise words used to instruct the participant (line 604): “Your task is to judge which patch has a stronger majority of yellow or blue dots. In other words: For which patch do you find it easier to decide what the dominant color is? It does not matter what the dominant color of the easier patch is (i.e., whether it is yellow or blue). All that matters is whether the left or right patch is easier to decide”.</p>
<p>Knowing both colors or the dominant color is not sufficient to solve the task. Knowing both are yellow does not tell you which has more yellow which is what you need to estimate to solve the task. Again, we tested a confidence model in the original version of the paper and showed it was a poor model compared to the Difference model.</p>
<disp-quote content-type="editor-comment">
<p>1. Two step model: two issues are a bit puzzling in this model. First, if an observer reaches a decision about the dominant color of each patch, does it mean one has made a color decision about the patches? If so, why should more evidence be accumulated? This may also support the possibility that this is a ”post decision” confidence judgment rather than a ”pre decision” difficulty judgment. Second, the authors assume the time it takes to reach a decision about the dominant color for both patches are equal, i.e., the boundaries for the ”mini decision” are symmetrical. However, it would make sense to assume that patches with lower strength would require a longer time to reach the boundaries.</p>
</disp-quote>
<p>In the Two-step model we assume a mini decision is made for the color of each stimulus. However, the assumption is that this is made with a low bound so it is not a full decision as in a typical color decision. Again estimating the colors from the mini decision does not tell you which is easier so you need to accumulate more evidence to make this judgment. In fact the Race model is a version of the two step in which no further accumulation is made after the initial decision and this model fits poorly (we now explain this on line 185). We assume for simplicity that the first stimulus to cross a bound triggers both mini color decisions. So although the bounds are equal the one with stronger color dominance is more likely to hit the bound first.</p>
<p>We have already addressed this concern about the comparison with confidence above.</p>
<disp-quote content-type="editor-comment">
<p>1. Experiment 2: the modification of the Difference model to fit the known condition (Figure 5b),can also be conceptualized as the two-step model, excluding the ”mini” color decision time. These two models (Difference model with known color; two-step model) only differ from each other in a way that in the former the color is known in advance, and in the second, the subject has to infer it. One may wonder if the difference in patterns between the two (Figure 3C vs. Figure 6B) is only due to the inaccuracies of inferring the dominant color in the two-step model.</p>
</disp-quote>
<p>In Experiment 2 the participant is explicitly informed as to the color dominance of both stimuli. Therefore, assuming the two-step model skips the first step and uses this explicit information in the second step, the difference and two-step model are identical for modeling Experiment 2. We explain this now on line 277.</p>
<p>As the reviewer suggests, differences in predictions between the Difference and Two-step arise from trials in which there is a mismatch between the inferred dominant colors from the two-step model and the color associated with the final DVs in the Difference model. We now explain this on line 187. We do not see this as a problem of any sort but just defines the difference between the models. Note that the new exceedance analysis now strongly supports the Difference model as the most common model among the participants.</p>
<disp-quote content-type="editor-comment">
<p>An additional concern is about the controlled duration task: Why were these specific durations chosen (0.1-1.65 sec; only a single duration was larger than 1sec), given the much longer reaction times in the main task (Experiment 1), which were all larger on average than 1sec? This seems a bit like an odd choice. Additionally, difficulty decision accuracies in this version of the task differ between known and unknown conditions (Figure 7), while in the reaction time version of the same task there were no detectable differences in performance between known and unknown conditions (Figure 6C), just in the reaction times. This discrepancy is not sufficiently explained in the manuscript. Could this be explained by the short trial durations?</p>
</disp-quote>
<p>The reviewer asks about the choice of stimulus durations in Experiment 2. First, RTs in Experiment 1 do not only reflect the time needed to make decisions but also contain non-decision times (0.23-0.47 s). So to compare decision time in RT and controlled duration experiment one must subtract the non-decision time from the RTs (the non-decision time is not relevant to the controlled duration experiment). Second, the model specifically predicts that differences in performance between the known and unknown color dominance conditions are largest for short duration stimulus presentation trials (see Fig. 7). We explain this on line 346. For long durations, performance pretty much plateaus, and many decisions have already terminated (Kiani 2008). We sample stimulus durations from a discrete truncated exponential distribution to get roughly equal changes in accuracy between consecutive durations (which we now explain at line 345).</p>
<disp-quote content-type="editor-comment">
<p>Group consensus review</p>
<p>The reviewers have discussed with each other, and they have discussed a series of revisions which, if carried out, would make their evaluation of your paper even more positive. I outline them below in case you would be interested in revising your paper based on these reviews. You will see below that the reviewers share overall a quite positive evaluation of your study. All three limitations described in the Public Reviews could be addressed explicitly in the discussion which for the moment is limited to description and generalization of findings.</p>
<p>1. The model selection procedure should be amended and strengthened to provide clearer results. As noted by one of the reviewers during the consultation session, ”the Difference model just barely wins over the two-step model, and the two-step model might produce the same prediction for the next experiment.” You will also see below that Reviewer #2 provides guidance to improve the model selection process: ”[...] the second experiment presents data from only 3 participants (1 of which has slightly different behaviour than the 2 others), thereby limiting the generality of the findings. Third, the winning model in experiment #1 (difference model) is the preferred model on 12 participants, out of the 20 tested ones. Fourth, the raw BIC values are compared against each other in absolute terms without relying on significance testing of the differences in model frequency within the sample of participants (e.g., using exceedance probabilities; see Stephan et al., 2009 and Rigoux et al., 2014).” Altogether, model selection appears currently to be the ’weakest’ part of the paper (Difference model vs. Two-step model, model comparison, how to better incorporate the optional model with the other parts). It would be great if you would improve this section of the Results.</p>
</disp-quote>
<p>Thank you for these suggestions.</p>
<p>i)  We have now make it clear in the Results (line 126) that all four models we examine are accumu-lation models. In addition, we have added a paragraph on Limitations (line 530) in the Discussion where we explain why we only consider accumulation models and acknowledge that there are other non-accumulation models.</p>
<p>ii) Each of three participants in Experiment 2 performed 18 session making it a large and valuabledataset necessary to test our hypothesis. We have now included a mention of the the small number of participants in Experiment 2 in a Limitations paragraph in the Discussion (line 539).</p>
<p>iii) We have now calculated exceedance probabilities for the 4 models which gave [0,0.97,0.03,0].
This shows that there is a 0.97 probability of the Difference model being the most frequent and only a 0.03 probability of the two-step model. We have included this in the results on line 237.</p>
<disp-quote content-type="editor-comment">
<p>1. All reviewers have noted that the relation of the optimal model with the human data and theother models should be clarified and discussed in a revised version of the manuscript. You will find their specific comments in their individual reviews, appended below.</p>
</disp-quote>
<p>We now include the optimal model for the known color dominance RT experiment (line 420). We have also added a new paragraph in the Discussion on the optimal model at line 503 comparing it to the Difference model.</p>
<disp-quote content-type="editor-comment">
<p>1. Finally, the exclusion strategy is also unclear at the moment and should be clarified and discussed explicitly somewhere in a revised version of the manuscript. Reviewers were wondering why so many participants were excluded from Experiment 1, and only 3 participants were included in Experiment 2. This should also be clarified better in the manuscript.</p>
</disp-quote>
<p>We have clarified the exclusion criteria in the Methods at line 651 as a new subsection.</p>
<p>The data quality problem with MTurk is well documented (Chmielewski, M &amp; Kucker SC. 2020. An MTurk Crisis? Shifts in Data Quality and the Impact on Study Results. Social Psychological and Personality Science, 11, 464-473). Given that this was an online experiment on MTurk, it is hard to know exactly why some participants showed low accuracy, but it’s likely that some may have misunderstood the instructions in the difficulty task or they may have been unmotivated to do well in this highly repetitive task. Either reason would be problematic for our model comparisons that are based on choice-RT patterns. Note that the cut-offs we chose for inclusion were purely based on accuracy, whereas the modeling approach considered RTs, which importantly were not used as a inclusion criterion (see revised methods). Moreover, accuracy cut-offs were fairly lenient and mainly aimed to exclude participants who appeared to be guessing/misunderstood instructions (for reference: mean sensitivity of participants who were included was 2x higher than the cut-offs we used).</p>
<p>Each of three participants in Experiment 2 performed 18 session making it a large and valuable dataset necessary to test our hypothesis. We have now included a mention of the the small number of participants in Experiment 2 in a Limitations paragraph in the Discussion (line 539).</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>Thank you for an excellent paper, I enjoyed reading it a lot. I have a few questions that could potentially clarify some aspects for the reader.</p>
<p>(1)    It seems from the model fit plots (Figure 3) that the RT predictions of the model tend to overshoot in cases where one of the clouds is very easy. Could you include potential interpretations of this effect?</p>
</disp-quote>
<p>We assume the reviewer is examining the Difference Model (i.e. the preferred model) panel when commenting on the overshoot. It is true the predictions for the highest coherence (bottom purple line) for RT is above the data but it is barely outside the data errorbars of 1 s.e. To be honest we regard this as a pretty good fit and would not want to over-interpret this small mismatch.</p>
<disp-quote content-type="editor-comment">
<p>(2)    On page 4, around line 121, the study discusses the ”criss-crossing” effect in the RT data. You mention that the fact that RTs are long in hard-hard trials compared to easy-easy trials could be important here: ”These tendencies lead to a criss-cross pattern..”. It is confusing since, for instance, the race model does not have a criss-cross, but still exhibits the overall effect. I was intrigued bythe criss-crossing, and after some quick simulations, I found that the equation RT2 ∗   = 2 − 2 ∗ Cs12 −
Cs22 + 6 ∗ (Cs1 ∗ Cs2)2 can (very roughly) replicate Figure 1d (bottom panel), so it seems that the criss-crossing effect must be produced by some interactive effect of color strengths on RTs. I wonder if you could provide a better explanation of how this interactive effect is generated by the model, given that it is the main interesting finding in the data. I believe at this point the intuition is not well-outlined.</p>
</disp-quote>
<p>The criss cross arises through an interaction of the coherences as the reviewer suspects. That is, for the Difference model the RT related to abs(|Coh1|- |Coh2|). If we replace the first abs with a square we get</p>
<p>|coh1|2 + |coh2|2 − 2|coh1||coh2|</p>
<p>The larger this is, the smaller the RT so</p>
<p>RT = constant − coh12 − coh22 + 2|coh1||coh2|</p>
<p>which is very similar to the formula the reviewer mentions.</p>
<p>We now supply an intuition as to why the criss-cross arises in the Difference model (line 167). We do not get a criss-cross in the race model, because there the RT is determined by the Race that that reaches a bound first. Because the races are independent, RTs will be fastest when coherence is high for either stimuli.</p>
<disp-quote content-type="editor-comment">
<p>(3)    Am I wrong in my intuition that the two-step model would produce very similar predictions as the Difference model for Experiment 2? It would be great to discuss that either way since the twostep model seems to produce very close quantitative and pretty much the same qualitative fit to the data of Experiment 1.</p>
</disp-quote>
<p>In Experiment 2 the participant is explicitly informed about the color dominance of both stimuli. Therefore, assuming the two-step model skips the first step and uses this explicit information in the second step, the difference and two-step model are identical for modeling Experiment 2. We explain this now on line 277.</p>
<disp-quote content-type="editor-comment">
<p>(4)    The inclusion of the optimal model is great. It would be beneficial to provide some more connections to the rest of the paper here. Would this model produce similar predictions for Experiment 2, for instance?</p>
</disp-quote>
<p>We now include the optimal model for the known color dominance RT experiment (line 420). We have also added a new paragraph in the Discussion on the optimal model at line 503 comparing it to the Difference model.</p>
<disp-quote content-type="editor-comment">
<p>(5)    In the Methods, it is quite striking that out of 51 original participants, most were excluded and only 20 were studied. It is not easy to trace through this section why and how and who was excluded, so it would be great if this information was organized and presented more clearly.</p>
</disp-quote>
<p>We have clarified this in the Methods at line 651 as a new subsection in the Methods. We also explain that exclusion was not made on RT data which is our main focus in the models.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<list list-type="bullet">
<list-item><p>As detailed in the ’public review’, a more cautious discussion, notably delineating the limitations of the study would be appreciated.</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>In their models, the authors assume that participants sequentially allocate attention between the two stimuli, alternating between them. Did the authors test this assumption and did they consider the possibility that participants could sample from both stimuli in parallel? In particular, does the conclusion of the model comparison also holds under this parallel processing assumption?</p>
</list-item></list>
</disp-quote>
<p>Our results are not affected by whether participants sample the stimulus sequentially through alternation or in a parallel manner (Kang et al., 2021). What does change is the parameters of the model (but not their predictions/fits). In the parallel model, information is acquired at twice the rate of the serial model. We can, therefore, obtain the parameters of parallel models (that has serial and parallel models): 𝜅𝑝 = 𝜅𝑠/√2, 𝑢𝑝 = 𝑢𝑠√2, 𝑎𝑝 = 𝑎𝑠/2 and 𝑑𝑝 = 2𝑑𝑠 (Eq. 2). We now explain𝑠 𝑝 identical predictions to the serial model) directly from the parameters of the current sequential models simply by adjusting the parameters that depend on the time scale (subscripts and for this on line 518.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>I found the small paragraph corresponding to lines 193-196 particularly difficult to understand. If the authors could think of a better way to phrase their claim, it would probably help.</p>
</list-item></list>
</disp-quote>
<p>We have rewritten this paragraph at line 211</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>I found a type on line 122: ”wheres” instead of ”whereas”.</p>
</list-item></list>
</disp-quote>
<p>Corrected</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>I found a type on line 181: ”or” instead of ”of”.</p>
</list-item></list>
</disp-quote>
<p>Yes corrected</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>Figure #2 is extremely useful in understanding the models and their differences, make sure it remains after addressing the reviews!</p>
</list-item></list>
</disp-quote>
<p>Thank you, this figure is retained.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p>
<p>All comments are detailed in the public review, with some clarifications here:</p>
<p>1. The confusing instructions to the participants are detailed here: under ”overview of experimental tasks” in the methods it says: ”They were instructed... to indicate whether the left or right stimulus was the easier one” (line 520), and below it ”they were required to indicate which patch had the stronger color dominance...” (line 524).</p>
</disp-quote>
<p>We have clarified the instructions by providing the actual text displayed to participants in the methods and have ensured consistency in the method to talk about judging the easier stimulus
(line 604).</p>
<p>The instructions were “Your task is to judge which patch has a stronger majority of yellow or blue dots. In other words: For which patch do you find it easier to decide what the dominant color is?
It does not matter what the dominant color of the easier patch is (i.e., whether it is yellow or blue). All that matters is whether the left or right patch is easier to decide”.</p>
<disp-quote content-type="editor-comment">
<p>1. Minor comments: Line 76: ”that” should be ”than”.</p>
</disp-quote>
<p>Thanks, corrected</p>
<disp-quote content-type="editor-comment">
<p>Line 574: ”variable duration task” means ”controlled duration task”?</p>
</disp-quote>
<p>Yes, corrected</p>
<disp-quote content-type="editor-comment">
<p>Line 151: ”or” should be ”of”.</p>
</disp-quote>
<p>Corrected</p>
</body>
</sub-article>
</article>