<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">101413</article-id>
<article-id pub-id-type="doi">10.7554/eLife.101413</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.101413.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Methamphetamine-induced adaptation of learning rate dynamics depend on baseline performance</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9747-1746</contrib-id>
<name>
<surname>Kirschner</surname>
<given-names>Hans</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>hans.kirschner@ovgu.de</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Molla</surname>
<given-names>Hanna M</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Nassar</surname>
<given-names>Matthew R</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>de Wit</surname>
<given-names>Harriet</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Ullsperger</surname>
<given-names>Markus</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Institute of Psychology, Otto-von-Guericke University</institution>, <city>Magdeburg</city>, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Department of Psychiatry and Behavioral Neuroscience, University of Chicago</institution>, <city>Chicago</city>, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Robert J. and Nancy D. Carney Institute for Brain Science, Brown University</institution>, <city>Providence</city>, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Department of Neuroscience, Brown University</institution>, <city>Providence</city>, <country>USA</country></aff>
<aff id="a5"><label>5</label><institution>Center for Behavioral Brain Sciences</institution>, <city>Magdeburg</city>, <country>Germany</country></aff>
<aff id="a6"><label>6</label><institution>German Center for Mental Health (DZPG), Center for Intervention and Research on Adaptive and Maladaptive Brain Circuits Underlying Mental Health (C-I-R-C)</institution>, <city>Magdeburg</city>, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Cools</surname>
<given-names>Roshan</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Roiser</surname>
<given-names>Jonathan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes><fn id="n1" fn-type="equal"><label>*</label><p>shared senior authorship</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-10-02">
<day>02</day>
<month>10</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP101413</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-07-18">
<day>18</day>
<month>07</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-07-08">
<day>08</day>
<month>07</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.07.04.602054"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Kirschner et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Kirschner et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-101413-v1.pdf"/>
<abstract>
<title>Abstract</title><p>The ability to calibrate learning according to new information is a fundamental component of an organism’s ability to adapt to changing conditions. Yet, the exact neural mechanisms guiding dynamic learning rate adjustments remain unclear. Catecholamines appear to play a critical role in adjusting the degree to which we use new information over time, but individuals vary widely in the manner in which they adjust to changes. Here, we studied the effects of a low dose of methamphetamine (MA), and individual differences in these effects, on probabilistic reversal learning dynamics in a within-subject, double-blind, randomized design. Participants first completed a reversal learning task during a drug-free baseline session to provide a measure of baseline performance. Then they completed the task during two sessions, one with MA (20 mg oral) and one with placebo (PL). First, we showed that, relative to PL, MA modulates the ability to dynamically adjust learning from prediction errors. Second, this effect was more pronounced in participants who performed poorly at baseline. These results present novel evidence for the involvement of catecholaminergic transmission on learning flexibility and highlights that baseline performance modulates the effect of the drug.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>HdW is on the Board of Directors of PharmAla Biotech, and on scientific advisory committees of Gilgamesh Pharmaceuticals and MIND Foundation. These activities are unrelated to the present study. The other authors report no competing interests.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Goal-directed behavior requires organisms to continually update predictions about the world to select actions in the light of new information. In environments that include discontinuities (changepoints) and noise (probabilistic errors), optimal learning requires increased weighting of surprising information during periods of change and ignoring surprising events during periods of stability. A burgeoning literature suggests that humans are able to calibrate learning rates according to the statistical content of new information (<xref ref-type="bibr" rid="c6">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c13">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c16">Diederen et al., 2016</xref>; <xref ref-type="bibr" rid="c47">Nassar et al., 2019</xref>; <xref ref-type="bibr" rid="c51">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="c57">Razmi &amp; Nassar, 2022</xref>), albeit to varying degrees (<xref ref-type="bibr" rid="c36">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="c37">Kirschner et al., 2023</xref>; <xref ref-type="bibr" rid="c48">Nassar et al., 2016</xref>; <xref ref-type="bibr" rid="c49">Nassar et al., 2012</xref>; <xref ref-type="bibr" rid="c50">Nassar et al., 2021</xref>).</p>
<p>Although the exact neural mechanisms guiding dynamic learning adjustments are unclear, several neuro-computational models have been put forward to characterize adaptive learning. While these models differ in their precise computational mechanisms, they share the hypothesis that catecholamines play a critical role in adjusting the degree to which we use new information over time. For example, a class of models assumes that striatal dopaminergic prediction errors act as a teaching signal in cortico–striatal circuits to learn task structure and rules (<xref ref-type="bibr" rid="c3">Badre &amp; Frank, 2012</xref>; <xref ref-type="bibr" rid="c9">Collins &amp; Frank, 2013</xref>; <xref ref-type="bibr" rid="c11">Collins &amp; Frank, 2016</xref>; <xref ref-type="bibr" rid="c41">Lieder et al., 2018</xref>; <xref ref-type="bibr" rid="c53">Pasupathy &amp; Miller, 2005</xref>; <xref ref-type="bibr" rid="c61">Schultz et al., 1997</xref>). Another line of research highlights the role of dopamine in tracking the reward history with multiple learning rates (<xref ref-type="bibr" rid="c18">Doya, 2002</xref>; <xref ref-type="bibr" rid="c38">Kolling et al., 2016</xref>; <xref ref-type="bibr" rid="c44">Meder et al., 2017</xref>; <xref ref-type="bibr" rid="c63">Schweighofer &amp; Doya, 2003</xref>). This integration of reward history over multiple time scales enables people to estimate trends in the environment through past and recent experiences and adjust actions accordingly (<xref ref-type="bibr" rid="c76">Wilson et al., 2013</xref>). Within the broader literature of cognitive control, it has been suggested that dopamine in the prefrontal cortex and basal ganglia is involved in modulating computational tradeoffs such as cognitive stability–flexibility balance (<xref ref-type="bibr" rid="c14">Cools, 2008</xref>; <xref ref-type="bibr" rid="c19">Dreisbach et al., 2005</xref>; <xref ref-type="bibr" rid="c25">Floresco, 2013</xref>; <xref ref-type="bibr" rid="c27">Goschke, 2013</xref>; <xref ref-type="bibr" rid="c28">Goschke &amp; Bolte, 2014</xref>; <xref ref-type="bibr" rid="c29">Goschke &amp; Bolte, 2018</xref>). In particular, it has been proposed that dopamine plays a crucial role in the regulation of meta-control parameters that facilitate dynamic switching between complementary control modes (i.e., shielding goals from distracting information vs. switching goals in response to significant changes in the environment) (<xref ref-type="bibr" rid="c27">Goschke, 2013</xref>; <xref ref-type="bibr" rid="c28">Goschke &amp; Bolte, 2014</xref>; <xref ref-type="bibr" rid="c29">Goschke &amp; Bolte, 2018</xref>). Finally, other theories highlight the importance of the locus coeruleus/norepinephrine system in facilitating adaptive learning and structure learning (<xref ref-type="bibr" rid="c57">Razmi &amp; Nassar, 2022</xref>; <xref ref-type="bibr" rid="c66">Silvetti et al., 2018</xref>; <xref ref-type="bibr" rid="c78">Yu et al., 2021</xref>). Consistent with these neuro-computational models catecholaminergic drugs are known to affect cognitive performance including probabilistic reversal learning (<xref ref-type="bibr" rid="c13">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c17">Dodds et al., 2008</xref>; <xref ref-type="bibr" rid="c58">Repantis et al., 2010</xref>; <xref ref-type="bibr" rid="c60">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="c70">van den Bosch et al., 2022</xref>; <xref ref-type="bibr" rid="c74">Westbrook et al., 2020</xref>). Indeed, psychostimulants, such as methamphetamine, that increase extracellular catecholamine availability, can enhance cognition (<xref ref-type="bibr" rid="c2">Arria et al., 2017</xref>; <xref ref-type="bibr" rid="c31">Husain &amp; Mehta, 2011</xref>; <xref ref-type="bibr" rid="c67">Smith &amp; Farah, 2011</xref>) and are used to remediate cognitive deficits in attention deficit hyperactivity disorder (ADHD) (<xref ref-type="bibr" rid="c1">Arnsten &amp; Pliszka, 2011</xref>; <xref ref-type="bibr" rid="c56">Prince, 2008</xref>). However, the cognitive enhancements vary across tasks and across individuals (<xref ref-type="bibr" rid="c7">Bowman et al., 2023</xref>; <xref ref-type="bibr" rid="c13">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c15">Cools &amp; D’Esposito, 2011</xref>; <xref ref-type="bibr" rid="c26">Garrett et al., 2015</xref>; <xref ref-type="bibr" rid="c60">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="c70">van den Bosch et al., 2022</xref>; <xref ref-type="bibr" rid="c71">van der Schaaf et al., 2013</xref>) and the mechanisms underlying this variability remain poorly understood.</p>
<p>There is evidence that the effects of catecholaminergic drugs depend on an individual’s baseline dopamine levels in the prefrontal cortex (PFC) and striatum (<xref ref-type="bibr" rid="c8">Cohen &amp; Servan-Schreiber, 1992</xref>; <xref ref-type="bibr" rid="c15">Cools &amp; D’Esposito, 2011</xref>; <xref ref-type="bibr" rid="c17">Dodds et al., 2008</xref>; <xref ref-type="bibr" rid="c20">Durstewitz &amp; Seamans, 2008</xref>; <xref ref-type="bibr" rid="c60">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="c70">van den Bosch et al., 2022</xref>). Depending on individual baseline dopamine levels the administration of catecholaminergic drugs can promote states of cognitive flexibility or stability. For example, pushing dopamine from low to optimal (medium) levels may increase update thresholds in the light of new information (i.e., facilitating shielding/stability), whereas if a drug pushes dopamine either too high or too low may decrease update thresholds (i.e., facilitating shifting/flexibility) (<xref ref-type="bibr" rid="c20">Durstewitz &amp; Seamans, 2008</xref>; <xref ref-type="bibr" rid="c29">Goschke &amp; Bolte, 2018</xref>).</p>
<p>Here, we argue that baseline performance should be considered when studying the behavioral effects of catecholaminergic drugs effects. To investigate the role of baseline performance in drug challenge studies, it is important to control for several factors. First, the order of drug and placebo sessions must be balanced to control for practice effects (<xref ref-type="bibr" rid="c5">Bartels et al., 2010</xref>; <xref ref-type="bibr" rid="c26">Garrett et al., 2015</xref>; <xref ref-type="bibr" rid="c42">MacRae et al., 1988</xref>; <xref ref-type="bibr" rid="c64">Servan-Schreiber et al., 1998</xref>). Second, it is desirable to obtain an independent measure of baseline performance that is not confounded with the drug vs placebo comparison. Thus, participants may be stratified based on their performance on an independent session.</p>
<p>In the present study, we studied the effects of methamphetamine, a stimulant that increases monoaminergic transmission, on probabilistic reversal learning dynamics in a within-subject, double-blind, randomized design. The effects of the drug on a reversal learning task were examined in relation to participants’ baseline level of performance. Baseline performance was determined during an initial drug-free session. Then, participants completed the task during two sessions after receiving placebo (PL) and 20 mg of methamphetamine (MA; order counterbalanced).</p>
<p>The task used to study adaptive learning dynamics was a reversal variant of an established probabilistic learning task (<xref ref-type="bibr" rid="c24">Fischer &amp; Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="c34">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="c36">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="c37">Kirschner et al., 2023</xref>). On each trial, subjects made a choice to either gamble or avoid gambling on a probabilistic outcome, in response to a stimulus presented in the middle of the screen (see <xref rid="fig2" ref-type="fig">Figure 2A</xref>). A gamble could result in a gain or loss of 10 points, depending on the reward contingency associated with that stimulus. In choosing not to gamble, subjects avoided losing or winning points, but they were informed what would have happened if they had chosen to gamble. The reward contingency changed every 30-35 trials. By learning which symbols to choose and which to avoid, participants could maximize total points. A novel feature of this modified version of the task is that we introduced different levels of noise (probability) to the reward contingencies. Here, reward probabilities could be less predictable (30% or 70%) or more certain (20% or 80%). This manipulation allowed us to study the effect of MA on the dynamic balancing of updating and shielding beliefs about reward contingencies within different levels of noise in the task environment. To estimate learning rate adjustments, we fit a nested set of reinforcement learning models, that allowed for trial-by-trial learning rate adjustments.</p>
<p>We found that MA improved participants’ performance in the task, but this effect was driven mainly by a greater improvement in performance in those participants who performed poorly during the baseline session. Modeling results suggested that MA helps performance by adaptively shifting the relative weighting of surprising outcomes based on their statistical context. Specifically, MA facilitates down-weighting of probabilistic errors in stages of less predictable reward contingencies. Together, these results reveal novel insights into the role of catecholamines in adaptive learning behavior and highlights the importance to consider individual difference at baseline.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>97 healthy young adults completed the probabilistic learning task (<xref rid="fig2" ref-type="fig">Figure 2</xref>) (<xref ref-type="bibr" rid="c24">Fischer &amp; Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="c34">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="c36">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="c37">Kirschner et al., 2023</xref>) on three separate sessions, an initial drug-free session, and after PL and MA. The study followed a double-blinded cross-over design, whereby 50% of participants received MA first, and 50% of participants PL first. <xref rid="tbl1" ref-type="table">Table 1</xref> shows the demographic characteristics of the participants grouped by their task performance during the baseline session. The groups did not differ significantly on any of the variables measured. In a first analysis, we checked for general practice effects across the three task completions based on the total points earned in the task. We found a strong practice effect (<italic>F</italic>(2,186) = 14.53, p &lt; .001) with better performance on session two and three compared to session one (baseline). There was no difference in the total scores between session two and three (see <xref rid="fig2" ref-type="fig">Figure 2B</xref>). These results suggest that the baseline session may have minimized order effects between MA and PL sessions (see also results and discussion below). The key findings detailed below are summarized in a schematic figure presented in the discussion section (<xref rid="fig7" ref-type="fig">Figure 7</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Demographics and drug use characteristics of study participants (n = 94)</title></caption>
<graphic xlink:href="602054v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
<graphic xlink:href="602054v1_tbl1a.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<sec id="s2a">
<title>Subjective drug effects</title>
<p>MA administration significantly increased ‘feel drug effect’ ratings compared to PL, at 30, 50, 135, 180, and 210 min post-capsule administration (see <xref rid="fig1" ref-type="fig">Figure 1</xref>; Drug x Time interaction <italic>F</italic>(5,555) = 38.46, <italic>p</italic> &lt; 0.001).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Subjective drug effects post-capsule administration.</title><p>MA administration significantly increased ‘feel drug effect’ ratings compared to placebo. The scale for the ratings of Feeling a drug effect range from 0 to 100. The vertical black line indicates the time at which the task was completed. The asterisks refer to a significant on-/ off-drug difference.</p></caption>
<graphic xlink:href="602054v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Methamphetamine improved performance in a modified probabilistic reversal learning task only in participants who performed the task poorly at baseline.</title><p>(<bold>A</bold>) Schematic of the learning task. Each trial began with the presentation of a random jitter between 300 ms and 500 ms. Hereafter, a fixation cross was presented together with two response options (choose – green tick mark; or avoid – red no-parking sign). After the fixation cross, the stimulus was shown centrally until the participant responded or for a maximum duration of 2000 ms. Thereafter, participants’ choices were confirmed by a white rectangle surrounding the chosen option for 500 ms. Finally, the outcome was presented for 750 ms. If subjects chose to gamble on the presented stimuli, they received either a green smiling face and a reward of 10 points or a red frowning face and a loss of 10 points. When subjects avoided a symbol, they received the same feedback but with a slightly paler color and the points that could have been received were crossed out to indicate that the feedback was fictive and had no effect on the total score. A novel feature of this modified version of the task is that we introduced different levels of noise (probability) to the reward contingencies. Here, reward probabilities could be less predictable (30% or 70%), more certain (20% or 80%), or random (50%). <bold>(B)</bold> Total points earned in the task split up in sessions (baseline, drug session 1 and 2) and drug condition (PL vs. MA). Results show practice effects but no differences between the two drug sessions (baseline vs. drug session 1: 595.85 (39.81) vs. 708.62 (36.93); <italic>t</italic>(93) = –4.21, <italic>p</italic> = 5.95<sup>-05</sup>, d = 0.30; baseline vs. drug session 2: 595.85 (39.81) vs. 730.00 (38.53); <italic>t</italic>(93) = –4.77, <italic>p</italic> = 6.66<sup>-06</sup>, d = 0.35; session 1 vs. session 2: <italic>t</italic>(93) = –0.85, <italic>p</italic> = 0.399, d = 0.05). Dashed gray indicates no significant difference on/off drug (Δ∼35 points) <bold>(C)</bold> Interestingly, when we stratified drug effects by baseline performance (using median split on total points at baseline), we found that there was a trend towards better performance under MA in the low baseline performance group (n=47, p = .07). <bold>(D)</bold> Overall performance in drug session 1 and 2 stratified by baseline performance. Here, baseline performance appears not to affect performance in drug session 1 or 2. <italic>Note.</italic> IQR = inter quartile range; PL = Placebo; MA = methamphetamine.</p></caption>
<graphic xlink:href="602054v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2b">
<title>Drug effects on overall performance and RT</title>
<p>In general, participants learned the task well, based on the observation that their choice behavior largely followed the underlying reward probabilities of the stimuli across the sessions (see <xref rid="fig4" ref-type="fig">Figure 4D-F</xref>). When all subjects were considered together, we did not find a performance benefit under MA quantified by the total points scored in the task (MA: 736.59 (37.11) vs. PL: 702.02 (38.305); <italic>t</italic>(93) = 1.38, <italic>p</italic> = 0.17, d = 0.10). When participants were stratified by their baseline performance (median spilt on total points at baseline), we found a marginally significant Drug x Baseline Performance Group interaction (Drug x Baseline Performance Group interaction: <italic>F</italic>(1,92) = 3.20, <italic>p</italic> = 0.07; see <xref rid="fig2" ref-type="fig">Figure 2C</xref> and <xref rid="fig7" ref-type="fig">Figure 7A</xref>). Post hoc t tests revealed that compared to PL, MA improved performance marginally in participants with poor baseline performance (total points MA: 522.55 (53.79) vs. PL: 443.61 (47.81); <italic>t</italic>(46) = 1.85, <italic>p</italic> = 0.071, d = 0.23). MA did not, however, improve performance in the high baseline performance group (total points MA: 950.63 (26.15) vs. PL: 960.42 (27.26); <italic>t</italic>(46) = –0.38, <italic>p</italic> = 0.698, d = 0.05). In control analyses we ensured that these effects are not driven by session-order effects (see also section on session control analyses below). Results showed no effect of Session (<italic>F</italic>(1,92) = 0.71, <italic>p</italic> = 0.40) and no Session x Baseline Performance Group interaction (<italic>F</italic>(1,92) = 0.59, <italic>p</italic> = 0.44 ; see <xref rid="fig1" ref-type="fig">Figure 1C</xref>). There was a trend for slightly faster RTs under MA (PL: 544.67ms (9.87) vs. MA: 533.84ms (11.51); <italic>t</italic>(93) = 1.75, <italic>p</italic> = 0.08, d = 0.10). This speed effect appeared to be independent of baseline performance (Drug x Baseline Performance Group interaction: <italic>F</italic>(1,92) = 0.45, <italic>p</italic> = 0.50). Moreover, MA was associated with reduced RT variability (average individual SD of RTs: PL: 193.74 (6.44) vs. MA: 178.98 (5.47); <italic>t</italic>(93) = 2.54, <italic>p</italic> = 0.012, d = 0.25). Reduced RT variability has previously been associated with increased attention and performance (<xref ref-type="bibr" rid="c21">Esterman et al., 2012</xref>; <xref ref-type="bibr" rid="c35">Karamacoska et al., 2018</xref>). Two-way ANOVA on RT variability revealed an effect of baseline performance (<italic>F</italic>(1,92) = 4.52, <italic>p</italic> = 0.03), with increased RT variability in low baseline performers across the drug sessions (low baseline performance: 197.27 (6.48) vs. high baseline performance: 175.45 (5.29)). Moreover, there was an effect of Drug (<italic>F</italic>(1,92) = 6.87, <italic>p</italic> = 0.01), and a Drug x Baseline Performance Group interaction (<italic>F</italic>(1,92) = 6.97, <italic>p</italic> = 0.009). Post hoc t tests indicated that the MA-related reduction in RT variability was specific to low baseline performers (PL: 212.07 (9.84) vs. MA: 182.46 (7.98); <italic>t</italic>(46) = 3.04, p = 0.003, d = 0.48), whereas MA did not affect high baseline performers RT variability (PL: 175.40 (7.51) vs. MA: 175.50 (7.55); <italic>t</italic>(46) = –0.02, <italic>p</italic> = 0.98, d &lt; 0.01).</p>
</sec>
<sec id="s2c">
<title>Methamphetamine improves learning performance when reward contingencies are less predictable</title>
<p>Next, to get a better understanding of how MA affects learning dynamics, we investigated the probability of correct choice (i.e., choosing the advantageous stimuli and avoiding disadvantageous stimuli) across successive reversals. As shown in <xref rid="fig3" ref-type="fig">Figure 3</xref> the drug did not affect initial learning. However, the drug improved performance later in learning, particularly for stimuli with less predictable reward probabilities (see <xref rid="fig3" ref-type="fig">Figure 3B</xref>) and in subjects with low baseline performance. To quantify this observation, we first applied the Bai-Perron multiple break point test (see Methods) to find systematic breaks in the learning curves allowing us to divide learning into early and late stages. We applied the test to the reversal learning data across subjects. One break point was identified at 10 trials after a reversal (indexed by the vertical lines in <xref rid="fig3" ref-type="fig">Figure 3</xref>). We did not find drug differences when considering all reversals (PL: 0.84 (0.01) vs. MA 0.85 (0.01); t(93) = –1.14, p = 0.25, d = 0.07) and reversals to stimuli with high reward probability certainty (PL 0.86 (0.01) vs. MA 0.87 (0.01); t(93) = –0.25, p = 0.80, d = 0.02). Interestingly, we found a trend for increased learning under MA for stimuli with less predictable rewards (PL 0.80 (0.01) vs. 0.82 (0.01); <italic>t</italic>(93) = –1.80, <italic>p</italic> = 0.07, d = 0.14). Two-way ANOVA on the averaged probability of correct choice during the late stage of learning revealed a Drug x Baseline Performance Group interaction (<italic>F</italic>(1,92) = 4.85, <italic>p</italic> = 0.03; see <xref rid="fig7" ref-type="fig">Figure 7B</xref>). Post hoc <italic>t</italic> tests revealed that subjects performing lower at baseline appeared to benefit from MA (average accuracy late learning PL: 0.69 (0.02) vs. MA 0.74 (0.02); <italic>t</italic>(46) = –2.59, <italic>p</italic> = 0.01, d = 0.32), whereas there was no difference between MA and PL in the high baseline performance group (PL: 0.91 (0.01) vs. MA: 0.91 (0.01); <italic>t</italic>(46) = 0.29, <italic>p</italic> = 0.77, d = 0.04). We did not find other differences in reversal learning (all p &gt; 0.1). In control analyses we split the learning curves into other possible learning situations in the task (i.e., acquisition, first reversal learning etc.). Here no drug related effects emerged (see Supplementary Figure1).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Learning curves after reversals suggest that methamphetamine improves learning performance in phases of less predictable reward contingencies in low baseline performer.</title><p>Top panel of the Figure shows learning curves after all reversals <bold>(A)</bold>, reversals to stimuli with less predictable reward contingencies <bold>(B)</bold>, and reversals to stimuli with high reward probability certainty <bold>(C)</bold>. Bottom panel displays the learning curves stratified by baseline performance for all reversals <bold>(D)</bold>, reversals to stimuli with less predictable reward probabilities <bold>(E)</bold>, and reversals to stimuli with high reward probability certainty <bold>(F)</bold>. Vertical black lines divide learning into early and late stages as suggested by the Bai-Perron multiple break point test. Results suggest no clear differences in the initial learning between MA and PL. However, learning curves diverged later in the learning, particular for stimuli with less predictable rewards <bold>(B)</bold> and in subjects with low baseline performance <bold>(E)</bold>. <italic>Note</italic>. PL = Placebo; MA = methamphetamine; Mean/SEM = line/shading.</p></caption>
<graphic xlink:href="602054v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Computational modeling results reveal that methamphetamine affects the model parameter controlling dynamic adjustments of learning rate.</title><p><bold>(A)</bold> Model comparison. Bayesian model selection was performed using –0.5*BIC as a proxy for model evidence (<xref ref-type="bibr" rid="c68">Stephan et al., 2009</xref>). The best fitting mixture model assigned proportions to each model based on the frequency with which they provided the “best” fit to the observed participant data (Mixture proportion; blue bars) and estimated the probability with which the true population mixture proportion for a given model exceeded that of all others (Exceedance probability; black bars). The hybrid model plus learning rate modulation by feedback confirmatory (model 3) provided the best fit to the majority of participants and had an exceedance probability near one in our model set. <bold>(B-C)</bold> Comparison of parameter estimates from the winning model on-/ off drug. Stars indicate significant difference for the respective parameter. Results suggest that only the parameter controlling dynamic adjustments of learning rate according to recent prediction errors, eta, was affected by our pharmacological manipulation. <bold>(D-F)</bold> Modelled and choice behavior of the participants in the task, stretched out for all stimuli. Note that in the task the different animal stimuli were presented in an intermixed and randomized fashion, but this visualization allows to see that participants’ choices followed the reward probabilities of the stimuli. Data plots are smoothed with a running average (+/− 2 trials). Ground truth corresponds to the reward probability of the respective stimuli (good: 70/80%; neutral: 50%; bad: 20/30%). Dashed black lines represent 95% confidence intervals derived from 1000 simulated agents with parameters that were best fit to participants in each group. Model predictions appear to capture the transitions in choice behavior well. Mean/SEM = line/shading. <italic>Note.</italic> IQR = inter quartile range; PL = Placebo; MA = methamphetamine;</p></caption>
<graphic xlink:href="602054v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2d">
<title>Computational modeling results</title>
<p>To gain a better mechanistical understanding of the trial-to-trial learning dynamics we constructed a nested model set built from RL models (see methods) that included the following features: (1) a temperature parameter of the softmax function used to convert trial expected values to action probabilities (β), (2) a play bias term that indicates a tendency to attribute higher value to gambling behavior, and (3) an intercept term for the effect of learning rate on choice behavior. Additional parameters controlled trial-by-trial modulations of the learning rate including feedback confirmation (confirmatory feedback was defined as factual wins and counterfactual losses, disconfirmatory feedback was defined as factual losses and counterfactual wins), feedback modality (factual vs. counterfactual) and weighting of the learning rate as a function of the absolute value of previous prediction error (parameter Eta, determining the influence of surprise about the outcome on learning; <xref ref-type="bibr" rid="c40">Li et al., 2011</xref>). The winning model (as measured by lowest BIC and achieving protected exceedance probabilities of 100%) was one that allowed the learning rate to vary based on whether the feedback was confirmatory or not and the level of surprise of the outcome (see <xref rid="fig4" ref-type="fig">Figure 4A</xref>). Sufficiency of the model was evaluated through posterior predictive checks that matched behavioral choice data (see <xref rid="fig4" ref-type="fig">Figure 4D-F</xref>) and model validation analyses (see Supplementary Figure 2). We did not find evidence for differences in model fit between the groups (avg. BIC PL: 596.77 (21.63) vs. MA: 599.66 (19.85); <italic>t</italic>(93) = –0.25, p = 0.80, d = 0.01).</p>
<p>Next, we compared MAs effect on best-fitting parameters of the winning model (see <xref rid="fig4" ref-type="fig">Figure 4B-C</xref>). We found that eta (the parameter controlling dynamic adjustments of learning rate according to recent absolute prediction errors) was reduced under MA (eta MA: 0.24 (0.01) vs. PL 0.30 (0.01); <italic>t</italic>(93) = –3.005, p = 0.003, d = 0.43). When we stratified drug effects by baseline performance, we found a marginally significant Drug x Baseline Performance Group interaction (<italic>F</italic>(1,92) = 3.09, <italic>p</italic> = 0.08; see <xref rid="fig7" ref-type="fig">Figure 7C</xref>)). Post hoc t tests revealed that compared to PL, MA affected eta depending on baseline performance in the task. Here, subjects performing less well at baseline showed smaller eta’s (eta MA: 0.24 (0.01) vs. 0.33 (0.02); <italic>t</italic>(46) = –3.06, <italic>p</italic> = 0.003, d = 0.67), whereas there was no difference between MA and PL in the high baseline performance group MA: 0.23 (0.01) vs. 0.26 (0.01); <italic>t</italic>(46) = –1.03, <italic>p</italic> = 0.31, d = 0.18). We did not find drug related differences in any model parameters (all p &gt; 0.1).</p>
</sec>
<sec id="s2e">
<title>Methamphetamine affects learning rate dynamics</title>
<p>Next, we investigated how the model parameters fit with trial-by-trial modulations of the learning rate. Learning rates in our best fitting model were dynamic and affected by both model parameters and their interaction with feedback. Learning rate trajectories after reversals are depicted in <xref rid="fig5" ref-type="fig">Figure 5</xref>. As suggested by lower eta scores, MA appears to be associated with reduced learning rate dynamics in low-baseline performers. In contrast, low-baseline-performers in the PL condition exhibited greater variability in learning rate (and average LR throughout) rendering their choices more erratic. Consistent with this, on many trials their choices were driven by the most recent feedback, as their learning rates on a large subset of trials in later learning stages (on average 9 out of 11; <xref rid="fig5" ref-type="fig">Figure 5H</xref>) were greater than 0.5. Specifically, variability in learning rate (average individual SD of learning rate) was reduced in both early and late stages of learning across all reversals (early PL: 0.20 (0.01) vs. MA: 0.17 (0.01); <italic>t</italic>(93) = 2.72, p = 0.007, d = 0.36; late PL: 0.18 (0.01) vs. MA: 0.15 (0.01); t(93) = 2.51, p = 0.01, d = 0.33), as were reversals to stimuli with less predictable rewards (early PL: 0.19 (0.01) vs. 0.16 (0.01); t(93) = 2.98, p = 0.003, d = 0.39; late PL: 0.18 (0.01) vs. MA: 0.16 (0.01); t(93) = 2.66, p = 0.009, d = 0.35). Reversals to stimuli with high outcome certainty were also associated with decreased learning rate variability after MA administration (early PL: 0.18 (0.01) vs. MA: 0.15 (0.01); t(93) = 2.57, p = 0.01, d = 0.34; late PL: 0.18 (0.01) vs. MA: 0.15 (0.01); t(93) = 2.63, p = 0.009, d = 0.35). Two-way ANOVA revealed that this effect depended on baseline performance across all reversals (Drug x Baseline performance: <italic>F</italic>(1,92) = 3.47, <italic>p</italic> = 0.06), reversals to stimuli with less predictable rewards (Drug x Baseline performance: <italic>F</italic>(1,92) = 4.97, <italic>p</italic> = 0.02), and stimuli with high outcome certainty (Drug x Baseline performance: <italic>F</italic>(1,92) = 5.26, <italic>p</italic> = 0.03). Here, reduced variability under MA was observed in low baseline performers (all p &lt; .006, all d &gt; .51) but not in high baseline performers (all p &gt;.1). Together, these patterns of results suggest that people with high baseline performance show a large difference in learning rates after true reversals and during the rest of the task including misleading feedback. Specifically, they show a peak in learning after reversals and reduced learning rates in later periods of a learning block, when choice preferences should ideally be stabilized (see <xref rid="fig5" ref-type="fig">Figure 5C</xref>). This results in a better signal-to-noise ratio (SNR) between real reversals and misleading feedback (i.e., surprising outcomes in the late learning stage). In low baseline performers the SNR is improved after the administration of MA. This effect was particularly visible in stages of the task where rewards were less predictable. To quantify the SNR for less predictable reward contingencies for low baseline performers, we computed the difference between learning rate peaks on true reversals (signal) vs. learning rate peaks after probabilistic feedback later in learning (noise; SNR = signal –noise). The results of this analysis revealed that MA significantly increased the SNR for low baseline performers (PL: 0.01 (0.01) vs. MA: 0.04 (0.01); t(46) = –2.81, p = 0.007, d = 0.49). Moreover, learning rates were generally higher in later stages of learning, when choice preferences should ideally have stabilized (avg. learning rate during late learning for less predictable rewards: PL: 0.48 (0.01) vs. MA: 0.42 (0.01); t(46) = 3.36, p = 0.001, d = 0.56).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Methamphetamine boosts signal-to-noise ratio between real reversals and misleading feedback in late learning stages.</title><p>Learning rate trajectories after reversal derived from the computational model. First column depicts learning rates across all subjects for all reversals <bold>(A)</bold>, reversal to stimuli with high reward probability certainty <bold>(D)</bold>, and reversal to stimuli with noisy outcomes <bold>(G)</bold>. Middle and right column shows learning rate trajectories for subjects stratified by baseline performance (<bold>B, E, H</bold> – low baseline performance; <bold>C, F, I</bold> – high baseline performance). Results suggest that people with high baseline performance show a large difference in learning rates after true reversals and during the rest of the task including misleading feedback. Specifically, they show a peak in learning after reversals and reduced learning rates in later periods of a learning block, when choice preferences should ideally be stabilized <bold>(C)</bold>. This results in a better signal-to-noise ratio (SNR) between real reversals and misleading feedback (i.e., surprising outcomes in the late learning stage). In low baseline performers the SNR is improved after the administration of MA. This effect was particularly visible in stages of the task where rewards were less predictable (<bold>H</bold>). Bottom row <bold>(J)</bold> shows the association between receiving misleading feedback later in learning (i.e., reward or losses that do not align with a stimulus’ underlying reward probability) and the probability of making the correct choice during the next encounter of the same stimulus. Results indicate a negative correlation between the probability of a correct choice after double-misleading feedback and eta (scatter plot on the right). Here, the probability of a correct choice after double-misleading feedback decreases with increasing eta. There was a trend (p = .06) that subjects under MA were more likely to make the correct choice after two misleading feedback as compared to PL (plot in the middle). This effect appeared to be dependent on baseline performance, whereby only subjects with low baseline performance seem to benefit from MA (p = 0.02; plot on the right). <italic>Note.</italic> IQR = inter quartile range; PL = Placebo; MA = methamphetamine; MFB = misleading feedback.</p></caption>
<graphic xlink:href="602054v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Thus far, our results suggest that (1) MA improved performance in subjects who performed poorly at baseline, and (2) that MA reduced learning rate variability in subjects with low baseline performance (driven by significantly lower eta parameter estimates, which improved the SNR between true reversals and misleading feedback particularly for less predictable rewards). Next, we aimed to test how these differences relate to each other. Given that eta causes increased learning after surprising feedback and that we found the biggest drug differences in later stages of learning for stimuli that have less predictable rewards, we tested the association between the probability of making the correct choice after two consecutive probabilistic errors (wins for bad stimuli and losses for good stimuli; in total this happened 8 times in the late learning stage for stimuli with 30/70% reward probability) and eta. We found a significant correlation across participants (see <xref rid="fig5" ref-type="fig">Figure 5J</xref>), whereby higher etas scores were associated with fewer correct choices (r = .29, <italic>p</italic> = &lt; .001). There was a trend toward a drug effect, with subjects in MA condition being more likely to make the correct choice after two misleading feedbacks (PL: 0.82 (0.02) vs. 0.84 (0.01); <italic>t</italic>(93) = –1.92, p = 0.06, d = 0.13). Two-way ANOVA revealed, that this effect depended on baseline performance (Drug x Baseline performance: <italic>F</italic>(1,92) = 4.27, <italic>p</italic> = 0.04). Post-hoc t tests indicated higher correct choice probabilities under MA in low baseline performers (PL: 0.70 (0.02) vs. MA: 0.75 (0.02); t(46) = –2.41, p = 0.02, d = 0.30) but not in high baseline performers (PL: 0.92 (0.01234) vs. MA: 0.92 (0.01); t(46) = 0.11, p = 0.91, d = 0.01).</p>
</sec>
<sec id="s2f">
<title>Methamphetamine shifts learning rate dynamics closer to the optimum for low baseline performers</title>
<p>To better understand the computational mechanism through which MA improved performance in low baseline performers, we first examined how performance in the task related to model parameters from our fits. To do so, we regressed task performance onto an explanatory matrix containing model parameter estimates across all conditions (see <xref rid="fig6" ref-type="fig">Figure 6A</xref>). The results of this analysis revealed that variability in several of the parameters was related to overall task performance, with the overall learning rate, feedback confirmation LR adjustments, and inverse temperature all positively predicting performance and eta and the play bias term negatively predicting it.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Changes in learning rate adjustment explain drug induced performance benefits in low baseline performers.</title><p>(<bold>A</bold>) Regression coefficients and 95% confidence intervals (points and lines; sorted by value) stipulating the contribution of each model parameter estimate to overall participants task performance (i.e., scored points in the task). Play bias and eta (the parameter governing the influence of surprise on learning rate) both made a significant negative contribution to overall task performance, whereas inverse temperature and learning rates were positively related to performance. <bold>(B)</bold> Differences in parameter values for on– and off-drug sessions as quantified by regression coefficients and 95% confidence intervals are plotted separately for high (red) and low (yellow) baseline performers. Note that the drug predominately affected the eta parameter and did so to a greater extent in low baseline performers. <bold>(C)</bold> eta estimates on-drug (y-axis) are plotted against eta estimates off-drug (x-axis) for high baseline performer (yellow points) and low baseline performer (red points). Note that a majority of subjects showed a reduction in eta on-drug vs. off-drug (67.02%). This effect was more pronounced in low baseline performers (low baseline performers: 74.47%; (low baseline performers: 59.57%). <bold>(D)</bold> To better understand how changes in eta might have affected overall performance we conducted a set of simulations using the parameters best fit to human subjects, except that we equipped the model with a range of randomly chosen eta values to examine how altering that parameter might affect performance (n=1000 agents). The results revealed that simulated agents with low to intermediate levels of eta achieved the best task performance, with models equipped with the highest etas performing particularly poorly. To illustrate how this relationship between eta and performance could have driven improved performance for some participants under the methamphetamine condition, we highlight four participants with low-moderate eta values under methamphetamine, but who differ dramatically in their eta values in the placebo condition (<bold>D</bold>, inset). <bold>(E)</bold> To test whether simulations correspond to actual performance differences across conditions we calculated the predicted improvement for each participant based on their eta in each condition using a polynomial function that best described the relationship between simulated eta values and scored points (red line in <bold>D</bold>; fitted with matlab’s ployfit.m function; f(x) = –– 2.35e+03*x<sup>4</sup> + 5.64e+03*x<sup>3</sup> +––4.71e+03*x<sup>2</sup> + 1.29e+03*x + 692.08). We found that actual performance differences were positively correlated with the predicted ones (high baseline performer: Pearson’s Rho (47) = .31, p = .03; low baseline performer: Spearman’s Rho(47) = .0.34, p = .02). These results indicate that the individuals who showed the greatest task benefit from methamphetamine were those who underwent the most advantageous adjustments of eta in response to it. Note that we used rank order statistics for low baseline performers based on the fact that the distribution is skewed due to an outlier (upper left corner). PL = Placebo; MA = methamphetamine.</p></caption>
<graphic xlink:href="602054v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>While each of these parameters explained unique variance in overall performance levels, only the parameter controlling dynamic adjustments of learning rate according to recent prediction errors, eta, was affected by our pharmacological manipulation (<xref rid="fig6" ref-type="fig">Figure 6B</xref>). In particular, eta was reduced in the MA condition, specifically in the low baseline group, albeit to an extent that differed across individuals (<xref rid="fig6" ref-type="fig">Figure 6C</xref>). To better understand how changes in eta might have affected overall performance we conducted a set of simulations using the parameters best fit to human subjects, except that we implemented equipped the model with a range of randomly chosen eta values, to examine how altering that parameter might affect performance. The results revealed that simulated agents with low to intermediate levels of eta achieved the best task performance, with models equipped with the highest etas performing particularly poorly (<xref rid="fig6" ref-type="fig">Figure 6D</xref>). To illustrate how this relationship between eta and performance could have driven improved performance for some participants under the methamphetamine condition, we highlight four participants with low-moderate eta values under methamphetamine, but who differ dramatically in their eta values in the placebo condition (<xref rid="fig6" ref-type="fig">Figure 6D</xref>, inset). Note that the participants who have the largest decreases in eta under the methamphetamines, resulting from the highest placebo levels of eta, would be expected to have the largest improvements in performance. To test whether these simulations correspond to actual performance differences across conditions we calculated the predicted improvement for each participant based on their eta in each condition using the function in <xref rid="fig6" ref-type="fig">Figure 6D</xref>. We found that actual performance differences were positively correlated with the predicted ones (<xref rid="fig6" ref-type="fig">Figure 6E</xref>), indicating that the individuals who showed the greatest task benefit from methamphetamine were those who underwent the most advantageous adjustments of eta in response to it. This result was specific to eta, and taking a similar approach to explain conditional performance differences in terms of the other model parameters, including those that were quite strongly related to performance (<xref rid="fig6" ref-type="fig">Figure 6A</xref>), yielded negative results (all <italic>p</italic> &gt; .1; see Supplementary Figure S3). It is noteworthy that low-baseline performers tended to have particularly high values of eta under the baseline condition (low-baseline performers: 0.33 (0.02) vs. high-baseline performers: 0.25 (0.01); t(46) = 2.59, p = 0.01 d = 0.53), explaining why these individuals saw the largest improvements under the methamphetamine condition. Taken together, these results suggest that MA alters performance by changing the degree to which learning rates are adjusted according to recent prediction errors (eta), in particular by reducing the strength of such adjustments in low-baseline performers to push them closer to task-specific optimal values.</p>
<p>While eta seemed to account for the differences in the effects of MA on performance in our low and high performance groups, it did not fully account for performance differences across the two groups (see <xref rid="fig1" ref-type="fig">Figure 1C</xref> and <xref rid="fig7" ref-type="fig">Figure 7A</xref>/B). When comparing other model parameters between low and high baseline performer across drug sessions, we found that high baseline performer displayed higher overall inverse temperatures (2.97(0.05) vs. 2.11 (0.08); <italic>t</italic>(93) = 7.94, <italic>p</italic> &lt; .001, d = 1.33). This suggests that high baseline performers displayed higher transfer of stimulus values to actions leading to better performance (as also indicated by the positive contribution of this parameter to overall performance in the GLM). Moreover, they tended to show a reduced play bias (–0.01 (0.01) vs. 0.04 (0.03); <italic>t</italic>(93) = –1.77, <italic>p</italic> = 0.08, d = 0.26) and increased intercepts in their learning rate term (–2.38 (0.364) vs. –6.48 (0.70); t(93) = 5.03, <italic>p</italic> &lt; .001, d = 0.76). Both of these parameters have been associated with overall performance (see <xref rid="fig6" ref-type="fig">Figure 6A</xref>). Thus, overall performance difference between high and low baseline performed can be attributed to differences in model parameters other than eta. However, as described in the previous paragraph, differential effects of MA on performance on the two groups were driven by eta.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Summary of key findings.</title><p>Mean (SEM) scores on three measures of task performance after PL and MA, in participants stratified on low or high baseline performance<bold>. (A)</bold> There was a trend toward a drug effect, with boosted task performance (total points scored in the task) in low baseline performers (subjects were stratified via median split on baseline performance) after methamphetamine (20mg) administration. <bold>(B)</bold> Follow-up analyses revealed that on-drug performance benefits were mainly driven by significantly better choices (i.e., choosing the advantageous stimuli and avoiding disadvantageous stimuli) at later stages after reversals for less predictable reward contingencies (30/70% reward probability). <bold>(C)</bold> To understand the computational mechanism through which methamphetamine improved performance in low baseline performers we investigated how performance in the task related to model parameters from our fits. Our results suggest that methamphetamine alters performance by changing the degree to which learning rates are adjusted according to recent prediction errors (eta), in particular by reducing the strength of such adjustments in low-baseline performers to push them closer to task-specific optimal values.</p></caption>
<graphic xlink:href="602054v1_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2g">
<title>Control analyses</title>
<p>To control for the potentially confounding factor session order (i.e., PL first vs. MA first), we repeated the two-way mixed ANOVAs with significant Drug x Baseline Session interactions with session order as a between subject factor. Including session order did not alter the significance of the observed effects and did not interact with the effects of interest (all p &gt; .24).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>To study learning dynamics participants completed a reversal variant of an established probabilistic learning task (<xref ref-type="bibr" rid="c24">Fischer &amp; Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="c34">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="c36">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="c37">Kirschner et al., 2023</xref>). Participants completed the task three times: in a baseline session without drug, and after PL and after oral MA (20 mg) administration. We observed a trend towards a drug effect on overall performance, with improved task performance (total points scored in the task) selectively in low baseline performers. Follow-up analyses revealed that MA performance benefits were mainly driven by significantly better choices (i.e., choosing the advantageous stimuli and avoiding disadvantageous stimuli) at later stages after reversals for less predictable reward contingencies. Modeling results suggest that MA is helping performance by adaptively shifting the relative weighting of surprising outcomes based on their statistical context. Specifically, MA facilitated down-weighting of probabilistic errors in phases of less predictable reward contingencies. In other words, in low baseline-performers the SNR between true reversals and misleading feedback is improved after the administration of MA. Our results advance the existing literature that, to date, overlooked baseline performance effects. Moreover, although existing literature has linked catecholamines to volatility-based learning rate adjustments (<xref ref-type="bibr" rid="c13">Cook et al., 2019</xref>), we show that these adjustments also relate to other context-dependent adjustments like levels of probabilistic noise. The key findings of this study are summarized in <xref rid="fig7" ref-type="fig">Figure 7</xref>.</p>
<sec id="s3a">
<title>Methamphetamine affects the relative weighting of reward prediction errors</title>
<p>A key finding of the current study is that MA affected the relative weighting of reward prediction errors. In our model, adjustments in learning rate are afforded by weighting the learning rate as a function of the absolute value of the previous prediction error (<xref ref-type="bibr" rid="c40">Li et al., 2011</xref>). This associability-gated learning mechanism is empirically well supported (<xref ref-type="bibr" rid="c39">Le Pelley, 2004</xref>) and facilitates decreasing learning rates in periods of stability and increasing learning rates in periods of change. MA was associated with lower weighting of prediction errors (quantified by lower eta parameters under MA). Our results comprise an important next step in understanding the neurochemical underpinnings of learning rate adjustments.</p>
<p>Neuro-computational models suggest that catecholamines play a critical role in adjusting the degree to which we use new information. One class of models highlights the role of striatal dopaminergic prediction errors as a teaching signal in cortico–striatal circuits to learn task structure and rules (<xref ref-type="bibr" rid="c3">Badre &amp; Frank, 2012</xref>; <xref ref-type="bibr" rid="c9">Collins &amp; Frank, 2013</xref>; <xref ref-type="bibr" rid="c11">Collins &amp; Frank, 2016</xref>; <xref ref-type="bibr" rid="c41">Lieder et al., 2018</xref>; <xref ref-type="bibr" rid="c53">Pasupathy &amp; Miller, 2005</xref>; <xref ref-type="bibr" rid="c61">Schultz et al., 1997</xref>). The implication of such models is that learning the structure of a task results in appropriate adjustments in learning rates. Optimal learning in our task with high level of noise in reward probabilities in combination with changing reward contingencies required increased learning from surprising events during periods of change (reversals) and reduced learning from probabilistic errors. Thus, neither too low learning adjustments after surprising outcomes (low eta), nor too high learning adjustments after surprising outcomes (high eta) are beneficial in our task structure. Interestingly, MA appears to shift eta closer to the optimum. In terms of the neurobiological implementation of this effect, MA may prolong the impact of phasic dopamine signals, which in turn facilitates better learning of the task structure and learning rate adjustments (<xref ref-type="bibr" rid="c13">Cook et al., 2019</xref>; <xref ref-type="bibr" rid="c43">Marshall et al., 2016</xref>; <xref ref-type="bibr" rid="c73">Volkow et al., 2002</xref>). Our data, in broad strokes, are consistent with the idea that dopamine in the prefrontal cortex and basal ganglia is involved in modulating meta-control parameters that facilitated dynamic switching between complementary control modes (i.e., shielding goals from distracting information vs. shifting goals in response to significant changes in the environment) (<xref ref-type="bibr" rid="c14">Cools, 2008</xref>; <xref ref-type="bibr" rid="c19">Dreisbach et al., 2005</xref>; <xref ref-type="bibr" rid="c25">Floresco, 2013</xref>; <xref ref-type="bibr" rid="c27">Goschke, 2013</xref>; <xref ref-type="bibr" rid="c28">Goschke &amp; Bolte, 2014</xref>; <xref ref-type="bibr" rid="c29">Goschke &amp; Bolte, 2018</xref>). A key challenge in our task is differentiating real reward reversals from probabilistic misleading feedback which is a clear shielding/shifting dilemma described in the meta-control literature. Our data suggest that MA might improve meta-control of when to shield and when to shift beliefs in low baseline performers.</p>
<p>Moreover, it is possible that MA’s effect on learning rate adjustments is driven by its influence on the noradrenaline system. Indeed, a line of research is highlighting the importance of the locus coeruleus/norepinephrine system in facilitating adaptive learning and structure learning (<xref ref-type="bibr" rid="c57">Razmi &amp; Nassar, 2022</xref>; <xref ref-type="bibr" rid="c66">Silvetti et al., 2018</xref>; <xref ref-type="bibr" rid="c78">Yu et al., 2021</xref>). In particular, evidence from experimental studies, together with pharmacological manipulations and lesion studies of the noradrenergic system suggest that noradrenaline is important for change detection (<xref ref-type="bibr" rid="c46">Muller et al., 2019</xref>; <xref ref-type="bibr" rid="c49">Nassar et al., 2012</xref>; Preuschoff et al., 2011; <xref ref-type="bibr" rid="c65">Set et al., 2014</xref>). Thus, the administration of MA may have increased participants’ synaptic noradrenaline levels and, therefore, increased the sensitivity to salient events indicating true change points in the task.</p>
<p>It should be noted that other neuromodulators, such as acetylcholine (<xref ref-type="bibr" rid="c43">Marshall et al., 2016</xref>; <xref ref-type="bibr" rid="c77">Yu &amp; Dayan, 2005</xref>), and serotonin (<xref ref-type="bibr" rid="c30">Grossman et al., 2022</xref>; <xref ref-type="bibr" rid="c32">Iigaya et al., 2018</xref>), have also been associated with dynamic learning rate adjustment. Future studies should compare the effects of neuromodulator-specific drugs for example a dopaminergic modulator, a noradrenergic modulator, a cholinergic modulator, and a serotonin modulator to make neuromodulator-specific claims (for example see <xref ref-type="bibr" rid="c43">Marshall et al., 2016</xref>). Taken together, it is likely that in our study MA effects on learning rate adjustments are driven by multiple processes that perhaps also work in concert. Moreover, because we only administered a single pharmacological agent, our results could reflect general effects of neuromodulation.</p>
<p>Our results are in line with recent studies that show improved performance under methylphenidate (MPH) by making learning more robust against misleading information. For example, Fallon et al. (2017) showed that (MPH) helped participants to ignore irrelevant information but impaired the ability to flexibly update items held in working memory. Another study showed that (MPH) improved performance by adaptively reducing the effective learning rate in participants with higher working memory capacity (<xref ref-type="bibr" rid="c60">Rostami Kandroodi et al., 2021</xref>). These studies highlight the complex effects of MPH on working memory and the role of working memory in reinforcement learning (<xref ref-type="bibr" rid="c10">Collins &amp; Frank, 2012</xref>; <xref ref-type="bibr" rid="c12">Collins &amp; Frank, 2018</xref>). It could be that the effect of MA on learning rate dynamics reflect a modulation of interactions between working memory and reinforcement learning strategies. However, it should be acknowledged that our task was not designed to parse out specific contributions of the reinforcement learning system and working memory to performance.</p>
</sec>
<sec id="s3b">
<title>Methamphetamine selectively boosts performance in participants with poor initial task performance</title>
<p>Another key finding of the current study is that the benefits of MA on performance depend on the baseline task performance. Specifically, we found that MA selectively improved performance in participants that performed poorly in the baseline session. It is important to note, that MA did not bring performance of low baseline performers to the level of performance of high baseline performers. We speculate that high performers gained a good representation of the task structure during the orientation practice session, taking specific features of the task into account (change point probabilities, noise in the reward probabilities). This is reflected in a large signal to noise ratio between real reversals and misleading feedback. Because the high performers already perform the task at a near-optimal level, MA may not further enhance performance.</p>
<p>These results have several interesting implications. First, a novel aspect of our design is that, in contrast to most pharmacological studies, participants completed the task during a baseline session before they took part in the two drug sessions. Drug order and practice effects are typical nuisance regressors in pharmacological imaging research. Yet, although practice effects are well acknowledged in the broader neuromodulator and cognitive literature (<xref ref-type="bibr" rid="c5">Bartels et al., 2010</xref>; <xref ref-type="bibr" rid="c42">MacRae et al., 1988</xref>; <xref ref-type="bibr" rid="c64">Servan-Schreiber et al., 1998</xref>), our understanding of these effects is limited. One of the few studies that report on drug administration effects, showed that d-amphetamine (AMPH) driven increases in functional-MRI–based blood oxygen level-dependent (BOLD) signal variability (SD<sub>BOLD</sub>) and performance depended greatly on drug administration order (<xref ref-type="bibr" rid="c26">Garrett et al., 2015</xref>). In this study, only older subjects who received AMPH first improved in performance and SD<sub>BOLD</sub>. Based on research in rats, demonstrating that dopamine release increases linearly with reward-based lever press practice (<xref ref-type="bibr" rid="c52">Owesson-White et al., 2008</xref>), the authors speculate that practice may have shifted participants along an inverted-U-shaped dopamine performance curve (<xref ref-type="bibr" rid="c15">Cools &amp; D’Esposito, 2011</xref>) by increasing baseline dopamine release (<xref ref-type="bibr" rid="c26">Garrett et al., 2015</xref>). Interestingly, we did not see a modulation of the MA effects by drug session order (PL first vs. MA first). Thus, the inclusion of an orientation session might be a good strategy to control for practice and drug order effects.</p>
<p>Our results also illustrate the large interindividual variability of MA effects. Recently a large pharmacological fMRI/PET study (n=100) presented strong evidence that interindividual differences in striatal dopamine synthesis capacity explain variability in effects of methylphenidate on reversal learning (<xref ref-type="bibr" rid="c70">van den Bosch et al., 2022</xref>). They demonstrated that methylphenidate improved reversal learning performance to a greater degree in participants with higher dopamine synthesis capacity, thus establishing the baseline-dependency principle for methylphenidate. These results are in line with previous research showing that methylphenidate improved reversal learning to a greater degree in participants with higher baseline working memory capacity, an index that is commonly used as an indirect proxy of dopamine synthesis capacity (<xref ref-type="bibr" rid="c60">Rostami Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="c71">van der Schaaf et al., 2013</xref>; <xref ref-type="bibr" rid="c72">van der Schaaf et al., 2014</xref>). In the current study, we did not collect working memory capacity related information. However, our result that initial task performance strongly affected the effect of MA is in line with the pattern of results showing that individual baseline differences strongly influence drug effects and thus should be considered in pharmacological studies (<xref ref-type="bibr" rid="c15">Cools &amp; D’Esposito, 2011</xref>; <xref ref-type="bibr" rid="c20">Durstewitz &amp; Seamans, 2008</xref>; <xref ref-type="bibr" rid="c70">van den Bosch et al., 2022</xref>). Indeed, there is evidence from the broader literature on the effects of psychostimulants on cognitive performance, that suggest that stimulants improve performance only in low performers (<xref ref-type="bibr" rid="c33">Ilieva et al., 2013</xref>). Consistent with this, there is evidence in rats, that poor baseline performance was associated with greater response to amphetamine and increased performance in signal detection task (<xref ref-type="bibr" rid="c69">Turner et al., 2017</xref>).</p>
</sec>
</sec>
<sec id="s4">
<title>Conclusion</title>
<p>The current data provide evidence that relative to placebo, methamphetamine facilitates the ability to dynamically adjust learning from prediction errors. This observation was seen to a greater degree in those participants who performed poorly at baseline. These results advance existing literature by presenting evidence for a causal link between catecholaminergic modulation and learning flexibility and further highlights a baseline-dependency principle for catecholaminergic modulation.</p>
</sec>
<sec id="s5">
<title>Materials and methods</title>
<sec id="s5a">
<title>Design</title>
<p>The results presented here were obtained from the first two sessions of a larger four-session study (clinicaltrials.gov ID number NCT04642820). During the two 4-h laboratory sessions, healthy adults ingested capsules containing methamphetamine (20 mg; MA) or placebo (PL), in mixed order under double-blind conditions. One hour after ingesting the capsule they completed the 30-min reinforcement reversal learning task. The primary comparisons were on acquisition and reversal learning parameters of reinforcement learning after MA vs PL. Secondary measures included subjective and cardiovascular responses to the drug.</p>
</sec>
<sec id="s5b">
<title>Subjects</title>
<p>Healthy men and women aged 18-35 years were recruited with flyers and on-line advertisements. Initial eligibility was ascertained in a telephone interview (age, current drug use, medical conditions), and appropriate candidates attended an in-person interview with a physical examination, EKG and a structured clinical psychiatric interview (<xref ref-type="bibr" rid="c23">First et al., 2015</xref>). Inclusion criteria were a high school education, fluency in English, body mass index between 19 and 26, and good physical and mental health. Exclusion criteria were serious psychiatric disorders (e.g., psychosis, severe PTSD, depression, history of Substance Use Disorder), any regular prescription medication, history of cardiac disease, high blood pressure, consuming &gt;4 alcoholic or caffeinated beverages a day, or working night shifts. A total of 113 healthy young adults took part in the study. We excluded four subjects because of excessive misses on at least one session. Grubbs’ test for outlier detection with a one-sided alpha of 0.001 identified a cut-off of &gt; 40 missed trials.</p>
</sec>
<sec id="s5c">
<title>Orientation session</title>
<p>Participants attended an initial orientation session to provide informed consent, and to complete personality questionnaires. They were told that the purpose of the study was to investigate the effects of psychoactive drugs on mood, brain, and behavior. To reduce expectancies, they were told that they might receive a placebo, stimulant, or sedative/tranquilizer. They agreed not to use any drugs except for their normal amounts of caffeine for 24 hours before and 6 hours following each session. Women who were not on oral contraceptives were tested only during the follicular phase (1-12 days from menstruation) because responses to stimulant drugs are dampened during the luteal phase of the cycle (<xref ref-type="bibr" rid="c75">White et al., 2002</xref>). Most participants (N=97 out of 113) completed the reinforcement learning task during the orientation session as a baseline measurement. This measure was added after the study began. Participants who did not complete the baseline measurement were omitted from the analyses presented in the main text. We run the key analyses on the full sample (n=109). This sample included participants who completed the task only on the drug sessions. When controlling for session order and number (two vs. three sessions) effects, we see no drug effect on overall performance and learning. Yet, we found that eta was also reduced under MA in the full sample, which also resulted in reduced variability in the learning rate (see supplementary results for more details).</p>
</sec>
<sec id="s5d">
<title>Drug sessions</title>
<p>The two drug sessions were conducted in a comfortable laboratory environment, from 9 am to 1 pm, at least 72 hours apart. Upon arrival, participants provided breath and urine samples to test for recent alcohol or drug use and pregnancy (CLIAwaived Inc,Carlsbad, CAAlcosensor III, Intoximeters; AimStickPBD, hCG professional, Craig Medical Distribution). Positive tests lead to rescheduling or dismissal from the study. After drug testing, subjects completed baseline mood measures, and heart rate and blood pressure were measured. At 9:30 am they ingested capsules (PL or MA 20 mg, in color-coded capsules) under double-blind conditions. Oral MA (Desoxyn, 5 mg per tablet) was placed in opaque size 00 capsules with dextrose filler. PL capsules contained only dextrose. Subjects completed the reinforcement learning task 60 minutes after capsule ingestion. Drug effects questionnaires were obtained at multiple intervals during the session. They completed four other cognitive tasks not reported here. Participants were tested <bold>i</bold>ndividually and were permitted to relax, read or watch neutral movies when they were not completing study measures.</p>
</sec>
<sec id="s5e">
<title>Dependent measures</title>
<sec id="s5e1">
<title>Reinforcement Learning Task</title>
<p>Participants performed a reversal variant of an established probabilistic learning task (<xref ref-type="bibr" rid="c24">Fischer &amp; Ullsperger, 2013</xref>; <xref ref-type="bibr" rid="c34">Jocham et al., 2014</xref>; <xref ref-type="bibr" rid="c36">Kirschner et al., 2022</xref>; <xref ref-type="bibr" rid="c37">Kirschner et al., 2023</xref>). On each trial participants were presented one of three different stimuli and decided to either gamble or avoid gambling with that stimulus with the goal to maximize the final reward (see <xref rid="fig1" ref-type="fig">Figure 1A</xref>). A gamble resulted in winning or losing points, depending on reward contingencies associated with the particular stimulus. If participants decided not to gamble, they avoided any consequences, but were still able to observe what would have happened if they had gambled by receiving counterfactual feedback. The three stimuli – white line drawings of animals on black background – were presented in a pseudo random series that was the same for all participants. Reward contingencies for every stimulus could be 20%, 30%, 50%, 70%, or 80% and stayed constant within one block of 30-35 trials. After every block, reward contingency changed without notice. The experiment consisted of 7 blocks per stimulus, leading to 18 reversals and 714 trials in total. Presentation 22.0 (Neurobehavioral Systems) was used for task presentation. Every trial of the task began with a central fixation cross, presented for a variable time between 300 and 500 ms. After fixation, the stimulus was presented together with the two choice alternatives (a green checkmark for choosing and a red no-go sign for avoiding, sides counterbalanced across subjects) for a maximum of 2000 ms or until a response was given. If participants failed to respond in time, a question mark was shown and the trial was repeated at the end of the block. When a response was made, the stimulus stayed on screen and feedback was given after 500 ms. The outcome was then presented for 750 ms depending on the subject’s choice. Choosing to gamble led to either a green smiley face and a reward of 10 points or a red frowning face and a loss of 10 points according to the reward probability of the stimulus. An avoided gamble had no monetary consequences: the outcome was always 0. Counterfactual/fictive outcomes, indicating what would have happened had the participant chosen to gamble, were shown on screen using the same smileys in a paler color, but the reward or punishment was crossed out to indicate that the outcome was fictive.</p>
</sec>
<sec id="s5e2">
<title>Drug Effects Questionnaire (DEQ)</title>
<p>(<xref ref-type="bibr" rid="c45">Morean et al., 2013</xref>) The DEQ consists of 5 questions in total. In this paper we only reported the ratings of the “Do you feel any drug effect?” question which was rated on a 100 mm visual analog scale. Participants completed this at regular intervals throughout the session.</p>
</sec>
</sec>
<sec id="s5f">
<title>Reinforcement learning model fitting</title>
<p>We fit variants of reinforcement learning models to participants’ choice behavior using a constrained search algorithm (fmincon in MATLAB 2021b), which computed a set of parameters that maximized the total log posterior probability of choice behavior. The base model (M1) was a standard Q-learning model with three parameters: (1) a temperature parameter of the softmax function used to convert trial expected values to action probabilities, (2) a play bias term that indicates a tendency to attribute higher value to gambling behavior, and (3) an intercept term for the effect of learning rate on choice behavior. On each trial the expected value (<italic>Q</italic><sub><italic>t</italic></sub>) of a stimulus (<italic>X</italic><sub><italic>t</italic></sub>) was calculated according to the following formula:
<disp-formula>
<graphic xlink:href="602054v1_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Q values represent the expected value of an action at trial t. α reflects the learning rate. δ<sub><italic>t</italic></sub> represents the prediction error with R<sub><italic>t</italic></sub> being the reward magnitude of that trial. On each trial, this value term was transferred into a “biased” value term (<italic>V</italic><sub><italic>B</italic></sub>(<italic>X</italic><sub><italic>t</italic></sub>) = <italic>B</italic><sub><italic>play</italic></sub> + <italic>Q</italic><sub><italic>t</italic></sub>(<italic>X</italic><sub><italic>t</italic></sub>), where <italic>B</italic><sub><italic>play</italic></sub> is the play bias term) and converted into action probabilities (P(play|<italic>V</italic><sub><italic>B</italic></sub>(<italic>t</italic>)(<italic>X</italic><sub><italic>t</italic></sub>); P(pass|<italic>V</italic><sub><italic>B</italic></sub>(<italic>t</italic>)(<italic>X</italic><sub><italic>t</italic></sub>)) using a softmax function. This was our base model (M1).</p>
<p>Next, we fit further reinforcement models by complementing the base model with additional parameters. These additional parameters controlled trial-by-trial modulations of the learning rate. Note that our base model treats the learning rate for value updates as a constant. However, previous studies have been shown that people are able to adjust their learning rate according to the volatility of the environment (<xref ref-type="bibr" rid="c6">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c51">Nassar et al., 2010</xref>). In the Pearce-Hall hybrid model, adjustments in learning rate are afforded by weighting the learning rate as a function of the absolute value of previous prediction error (<xref ref-type="bibr" rid="c40">Li et al., 2011</xref>). This associability-gated learning mechanism is empirically well supported (<xref ref-type="bibr" rid="c39">Le Pelley, 2004</xref>) and facilitates decreasing learning rates in periods of stability and increasing learning rates in periods of change. Previous work has shown that the hybrid model can approximate normative learning rate adjustments (<xref ref-type="bibr" rid="c40">Li et al., 2011</xref>; <xref ref-type="bibr" rid="c54">Piray et al., 2019</xref>). In this hybrid model, the learning rate is updated as follows:
<disp-formula>
<graphic xlink:href="602054v1_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here, κ is scale of learning rate (α<sub><italic>t</italic></sub>) and η determines the step size for updating associability (<italic>A</italic><sub><italic>t</italic></sub>) as a function of the absolute RPE (|δ<sub><italic>t</italic></sub>|). On each trial, the learning rate (α<sub><italic>t</italic></sub>) depends on the absolute RPE from past trial. Note that the initial learning rate is defined by κ, whereby κ is determined by a logistic function of a weighted predictor matrix that could include an intercept term (Pearce-Hall hybrid model (M2)) and task variables that may additionally affected trial-by-trial learning rate adjustments. In the Pearce-Hall hybrid feedback confirmatory model (M3) the predictor matrix included an intercept term and feedback confirmatory information (i.e., was the feedback on a given trial confirmatory (factual wins and counterfactual losses) or disconfirmatory (factual losses and counterfactual wins)). Finally, in the Pearce-Hall hybrid feedback confirmatory and modality model (M4) the predictor matrix included an intercept term, feedback confirmatory information and feedback modality (factual vs. counterfactual feedback) information. The best-fitting model was determined by computing the Bayesian Information Criterion (BIC) for each model (<xref ref-type="bibr" rid="c62">Schwarz, 1978</xref>). Moreover, we computed protected exceedance probabilities, which gives the probability that one model was more likely than any other model of the model space (<xref ref-type="bibr" rid="c59">Rigoux et al., 2014</xref>). To compare participant behavior to model-predicted behavior, we simulated choice behavior using the best fitting model (Pearce-Hall hybrid feedback confirmatory model; see <xref rid="fig3" ref-type="fig">Figure 3A</xref>). For each trial, we used the expected trial value (<italic>Q</italic><sub><italic>t</italic></sub>(<italic>X</italic><sub><italic>t</italic></sub>)) computed above, and the parameter estimates of the temperature variable as inputs to a softmax function to generate choices. Validation of model selection and parameter recovery is reported in the supplementary materials (Figure S1).</p>
</sec>
<sec id="s6">
<title>Data analysis</title>
<p>We analyzed drug effects on behavioral performance, and model parameters using paired <italic>t</italic> tests. Given the effects of initial performance and practice in pharmacological imaging research (<xref ref-type="bibr" rid="c26">Garrett et al., 2015</xref>), we additionally stratified MA effects by task performance in the orientation using median split. These data were analyzed using a two-way repeated-measures ANOVA with the factors Drug (two levels) and Baseline Performance (two levels). Paired <italic>t</italic> tests were used as post hoc tests. Moreover, we investigated reversal learning by calculating learning curves. Post hoc, we observed that drug effects on learning became only apparent in the second phase of learning. We therefore used the Bai-Perrin multiple break point test (<xref ref-type="bibr" rid="c4">Bai &amp; Perron, 2003</xref>) to identify the number and location of structural breaks in the learning curves. In broad strokes, the test detects whether breaks in a curve exists, and if so, how many there are, based on the regression slope in predefined segments (here, we set the segment length to 5 trials). In our case, the test could reveal between 0 and 5 breaks (number of trials / segment length – 1). We run this test using data from all subjects and all sessions. The test detected one break that cut the learning curves into two segments (see results). We then calculated an index of learning performance after reversals by averaging the number of correct choices over the second learning phase. The index was then subjected to a two-way repeated ANOVA with the factors Drug (two levels) and Baseline Performance (two levels).</p>
</sec>
</sec>
<sec id="s7" sec-type="data-availability">
<title>Data Availability Statement</title>
<p>All raw data and analysis scripts can be accessed at the Open Science Framework data repository: [insert after acceptance].</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank all our participants who took part in this research for the generosity of their time and commitment. This research was supported by the National Institute on Drug Abuse DA02812. HM was supported by the National Institutes of Health T32 GM07019. MU was supported by the Deutsche Forschungsgemeinschaft, Grant/Award Number: SFB 1436; and the European Research Council, Grant/Award Number: 101018805”.</p>
</ack>
<sec id="s8">
<title>Competing interests</title>
<p>HdW is on the Board of Directors of PharmAla Biotech, and on scientific advisory committees of Gilgamesh Pharmaceuticals and MIND Foundation. These activities are unrelated to the present study. The other authors report no competing interests.</p>
</sec>
<sec id="s9">
<title>Supplementary Information</title>
<p>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure S1.</label>
<caption><title>Learning curves</title><p>Top part shows learning curves quantified as the probability to select the correct choice (choosing the advantageous stimuli and avoiding disadvantageous stimuli) stratified by orientation performance. Two-way ANOVAs with the factors Drug (two levels) and Baseline Performance (two levels) on the averaged probability of correct choice during the early and late stage of learning were used to investigate drug effects. <bold>(A)</bold> No differences in the learning curves between MA and PL became evident when considering all reversals (all p &gt; .1). <bold>(B)</bold> There was no drug related difference in the acquisition phase of the task between (all p &gt; .05) or <bold>(C)</bold> in the first reversal learning (all p &gt; .1). In the bottom part of the figure, learning curves are defined as the probability to select a stimulus. <bold>(D)</bold> No drug effect emerged for reversal learning from a bad stimulus to a good stimulus (all p &gt; .09) or <bold>(E)</bold> good to bad stimuli (all p &gt; .09). Moreover, there was no difference in reversal learning to neutral stimuli <bold>(F and G)</bold>. Note. PL = Placebo; MA = methamphetamine.</p></caption>
<graphic xlink:href="602054v1_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure S2.</label>
<caption><title>Validation of model selection and parameter recovery.</title><p>After model-fitting, each model was used to simulate data for each participant using the best-fitting parameters for that participant. Each model was fit to each synthetic dataset and BIC was used to determine which model provided best fit to synthetic data. <bold>(A)</bold> Inverse confusion matrix. The frequency with which a recovered model (abscissa, determined by lowest BIC) corresponded to a given simulation model (ordinate) is depicted in color. Recovered models correspond to the same models labeled on the ordinate, with recovered model 1 corresponding to the base model, and so on. The results of the model recover analyses suggest that the recovered model typically corresponded to a synthetic dataset produced by that model. <bold>(B)</bold> Parameter values that were used to simulate data from the hybrid model with additional modulation of the learning rate by feedback confirmatory (ordinate) tended to correlate (color) with the parameter values best fit to those synthetic datasets (abscissa). Recovered parameter values correspond to the labels on the ordinate, with parameter 1 reflecting temperature parameter of the softmax function, and so on.</p></caption>
<graphic xlink:href="602054v1_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure S3.</label>
<caption><title>Relationships between model parameters not affected by the drug and task performance (measured by total scored points in the task).</title><p>To better understand how changes in model parameters not affected by methamphetamine might have affected overall performance we conducted a set of simulations using the parameters best fit to human subjects, except that we equipped the model with a range of randomly chosen temperature parameters of the softmax function <bold>(A)</bold>, paly bias term <bold>(B)</bold>, intercept term of the learning rate <bold>(C)</bold>, and feedback confirmation term of the learning rate <bold>(D)</bold>, to examine how altering these parameters might affect performance. For each model we draw 1000 values of the respective parameter from a uniform distribution spanning the fitted parameter space. The results revealed that simulated agents with higher temperature parameters achieved the best task performance <bold>(A)</bold>. Moreover, agents with a play bias around zero <bold>(B)</bold>, and intercept term of the learning rate <bold>(C)</bold>, and feedback confirmation term of the learning rate <bold>(D)</bold> centered around zero achieved the best task performance. To test whether simulations correspond to actual performance differences across conditions we calculated the predicted performance difference for each participant based on their on– / off-drug parameter difference using a polynomial function that best described the relationship between simulated parameter values and scored points (red lines fitted with matlab’s ployfit.m function). Results are shown next to the simulation and suggest that predicted performance differences were unrelated to actual performance differences for changes in the temperature parameters of the softmax function (<bold>A</bold>; r(188) = 0.16, p = 0.10), play bias term (<bold>B</bold>; r(188) = 0.12, p = 0.22), intercept term of the learning rate (<bold>C</bold>; r(188) = 0.09, p = 0.34), and feedback confirmation term of the learning rate (<bold>D</bold>; r(188) = 0.08, p = 0.39).</p></caption>
<graphic xlink:href="602054v1_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure S4.</label>
<caption><title>Overall points full sample.</title><p>When comparing overall point in the whole sample (n = 109), we do not see a difference between MPH vs. PLA (705.68 (36.27) vs. 685.77 (35.78); <italic>t</italic>(108) = 0.81, <italic>p</italic> = 0.42, d = 0.05). Repeated mixed ANOVAs suggested, that drug effects did not depend on session order (MPH first vs. PLA first), or whether subjects performed the orientation session. Yet, participants who completed the orientation tended to performed better during the dug sessions (<italic>F</italic>(1,107) = 3.09, <italic>p</italic> = 0.08; 719.31 (26.6264) vs. 548.00 (75.09)). Note. PL = Placebo; MA = methamphetamine.</p></caption>
<graphic xlink:href="602054v1_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure S5.</label>
<caption><title>Learning curves after reversals full sample.</title><p>Figure shows learning curves after all reversals <bold>(A)</bold>, reversals to high reward probability uncertainty <bold>(B)</bold>, and reversals to low reward probability uncertainty <bold>(C)</bold> for the whole sample. Vertical black lines divide learning into early and late stages as suggested by the Bai-Perron multiple break point test. Paired-sample t-test revealed no drug related difference for all reversals during early learning (0.72 (0.01) vs. 0.72 (0.01); t(108) = –0.02, p = 0.98, d &lt; 0.01) and late learning (0.83 (0.01) vs. 0.84 (0.01); t(108) = –0.80, p = 0.42, d = 0.04). Similarly, there was no significant differences in both learning stages for reversals to low reward probability certainty stimuli (early learning PLA vs MPH: 0.68 (0.01) vs. 0.69 (0.01); t(108) = –0.92, p = 0.35, d = 0.08; late learning PLA vs MPH: 0.80 (0.01) vs. 0.81 (0.01); t(108) = –1.48, p = 0.14, d = 0.10) or to low reward probability certainty stimuli (early learning PLA vs MPH: 0.74 (0.01) vs. 0.73 (0.01); t(108) = 0.87, p = 0.38, d = 0.06; late learning PLA vs MPH: 0.85 (0.01) vs. 0.85 (0.01); t(108) = –0.02, p = 0.97, d &lt; 0.01). Mixed effect ANOVAs that controlled for session order effects and whether participants performed the orientation session revealed no significant effects (all p &gt; .06). Note. PL = Placebo; MA = methamphetamine.</p></caption>
<graphic xlink:href="602054v1_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure S6.</label>
<caption><title>Learning curves after reversals full sample.</title><p>(<bold>A</bold>) Here we compare MPHs effect on best-fitting parameters of the winning model in the full sample (n = 109). We found that eta (i.e., the weighting of the effect of the abs. reward prediction error on learning) was reduced under MPHs (eta MPH: 0.23 (0.01) vs. PLA 0.29 (0.01); t(108) = –3.05, <italic>p</italic> = 0.002, d = 0.40). Mixed effect ANOVAs that controlled for session order effects and whether participants performed the orientation session revealed this effect did not depend on these cofounds. No other condition differences emerged. <bold>(B)</bold> Learning rate trajectories after reversal derived from the computational model. As in the reduced sample MPH appears to be associated reduced learning rate dynamics in the full sample too. Specifically, variability in learning rate (average individual SD of learning rate) tended to be reduced in the MPH condition both during early and late stages of learning across all reversals (early PLA: 0.19 (0.01) vs. 0.18 (0.01); t(108) = 1.89, p = 0.06, d = 0.24; late PLA: 0.17 (0.01) vs. MPH: 0.16 (0.01); t(108) = 1.77, p = 0.08, d = 0.23) and reversals to high reward probability uncertainty (early PLA: 0.18 (0.01) vs. 0.16 (0.01); t(108) = 1.74, p = 0.08, d = 0.22; late PLA: 0.18 (0.01) vs. MPH: 0.16 (0.01); t(108) = 1.82, p = 0.07, d = 0.24). Condition differences became most evident in reversals to low reward probability uncertainty (early PLA: 0.19 (0.01) vs. MPH: 0.16 (0.01); t(108) = 2.18, p = 0.03, d = 0.28; late PLA: 0.18 (0.01) vs. MPH: 0.16 (0.01); t(108) = 1.93, p = 0.05, d = 0.24). Control analyses revealed that these effects were independent of session order and orientation session. Note. PL = Placebo; MA = methamphetamine.</p></caption>
<graphic xlink:href="602054v1_figs6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arnsten</surname>, <given-names>A. F.</given-names></string-name>, &amp; <string-name><surname>Pliszka</surname>, <given-names>S. R</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Catecholamine influences on prefrontal cortical function: relevance to treatment of attention deficit/hyperactivity disorder and related disorders</article-title>. <source>Pharmacol Biochem Behav</source>, <volume>99</volume>(<issue>2</issue>), <fpage>211</fpage>–<lpage>216</lpage>. <pub-id pub-id-type="doi">10.1016/j.pbb.2011.01.020</pub-id></mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arria</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Caldeira</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Vincent</surname>, <given-names>K. B.</given-names></string-name>, <string-name><surname>O’Grady</surname>, <given-names>K. E.</given-names></string-name>, <string-name><surname>Cimini</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Geisner</surname>, <given-names>I. M.</given-names></string-name>, <string-name><surname>Fossos-Wong</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Kilmer</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Larimer</surname>, <given-names>M. E</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Do college students improve their grades by using prescription stimulants nonmedically?</article-title> <source>Addict Behav</source>, <volume>65</volume>, <fpage>245</fpage>–<lpage>249</lpage>. <pub-id pub-id-type="doi">10.1016/j.addbeh.2016.07.016</pub-id></mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Mechanisms of hierarchical reinforcement learning in cortico-striatal circuits 2: evidence from fMRI</article-title>. <source>Cereb Cortex</source>, <volume>22</volume>(<issue>3</issue>), <fpage>527</fpage>–<lpage>536</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhr117</pub-id></mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bai</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Perron</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Computation and analysis of multiple structural change models</article-title>. <source>Journal of Applied Econometrics</source>, <volume>18</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1002/jae.659</pub-id></mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bartels</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wegrzyn</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wiedl</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ackermann</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Ehrenreich</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Practice effects in healthy adults: a longitudinal study on frequent repetitive cognitive testing</article-title>. <source>BMC Neurosci</source>, <volume>11</volume>, <fpage>118</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2202-11-118</pub-id></mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Walton</surname>, <given-names>M. E.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>, <volume>10</volume>(<issue>9</issue>), <fpage>1214</fpage>–<lpage>1221</lpage>. <pub-id pub-id-type="doi">10.1038/nn1954</pub-id></mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bowman</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Coghill</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Murawski</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Bossaerts</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Not so smart? “Smart” drugs increase the level but decrease the quality of cognitive effort</article-title>. <source>Sci Adv</source>, <volume>9</volume>(<issue>24</issue>), <fpage>eadd4165</fpage>. <pub-id pub-id-type="doi">10.1126/sciadv.add4165</pub-id></mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name>, &amp; <string-name><surname>Servan-Schreiber</surname>, <given-names>D</given-names></string-name></person-group>. (<year>1992</year>). <article-title>Context, cortex, and dopamine: a connectionist approach to behavior and biology in schizophrenia</article-title>. <source>Psychol Rev</source>, <volume>99</volume>(<issue>1</issue>), <fpage>45</fpage>–<lpage>77</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295x.99.1.45</pub-id></mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title>. <source>Psychol Rev</source>, <volume>120</volume>(<issue>1</issue>), <fpage>190</fpage>–<lpage>229</lpage>. <pub-id pub-id-type="doi">10.1037/a0030852</pub-id></mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2012</year>). <article-title>How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis</article-title>. <source>European Journal of Neuroscience</source>, <volume>35</volume>(<issue>7</issue>), <fpage>1024</fpage>–<lpage>1035</lpage>. <pub-id pub-id-type="doi">10.1111/j.1460-9568.2011.07980.x</pub-id></mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Neural signature of hierarchically structured expectations predicts clustering and transfer of rule sets in reinforcement learning</article-title>. <source>Cognition</source>, <volume>152</volume>, <fpage>160</fpage>–<lpage>169</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2016.04.002</pub-id></mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Within– and across-trial dynamics of human EEG reveal cooperative interplay between reinforcement learning and working memory</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>115</volume>(<issue>10</issue>), <fpage>2502</fpage>–<lpage>2507</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1720963115</pub-id></mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cook</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Swart</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Froböse</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Diaconescu</surname>, <given-names>A. O.</given-names></string-name>, <string-name><surname>Geurts</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>den Ouden</surname>, <given-names>H. E.</given-names></string-name>, &amp; <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Catecholaminergic modulation of meta-learning</article-title>. <source>Elife</source>, <volume>8</volume>. <pub-id pub-id-type="doi">10.7554/eLife.51439</pub-id></mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cools</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Role of Dopamine in the Motivational and Cognitive Control of Behavior</article-title>. <source>The Neuroscientist</source>, <volume>14</volume>(<issue>4</issue>), <fpage>381</fpage>–<lpage>395</lpage>. <pub-id pub-id-type="doi">10.1177/1073858408317009</pub-id></mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>D’Esposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Inverted-U-shaped dopamine actions on human working memory and cognitive control</article-title>. <source>Biol Psychiatry</source>, <volume>69</volume>(<issue>12</issue>), <fpage>e113</fpage>–<lpage>125</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2011.03.028</pub-id></mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diederen</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Spencer</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Vestergaard</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Fletcher</surname>, <given-names>P. C.</given-names></string-name>, &amp; <string-name><surname>Schultz</surname>, <given-names>W</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Adaptive Prediction Error Coding in the Human Midbrain and Striatum Facilitates Behavioral Adaptation and Learning Efficiency</article-title>. <source>Neuron</source>, <volume>90</volume>(<issue>5</issue>), <fpage>1127</fpage>–<lpage>1138</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.019</pub-id></mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dodds</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Müller</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>van Loon</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Robbins</surname>, <given-names>T. W.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Methylphenidate has differential effects on blood oxygenation level-dependent signal related to cognitive subprocesses of reversal learning</article-title>. <source>J Neurosci</source>, <volume>28</volume>(<issue>23</issue>), <fpage>5976</fpage>–<lpage>5982</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.1153-08.2008</pub-id></mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doya</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Metalearning and neuromodulation</article-title>. <source>Neural Netw</source>, <volume>15</volume>(<issue>4-6</issue>), <fpage>495</fpage>–<lpage>506</lpage>. <pub-id pub-id-type="doi">10.1016/s0893-6080(02)00044-8</pub-id></mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dreisbach</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Müller</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Goschke</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Strobel</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schulze</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Lesch</surname>, <given-names>K.-P.</given-names></string-name>, &amp; <string-name><surname>Brocke</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2005</year>). <article-title>Dopamine and Cognitive Control: The Influence of Spontaneous Eyeblink Rate and Dopamine Gene Polymorphisms on Perseveration and Distractibility</article-title>. <source>Behavioral Neuroscience</source>, <volume>119</volume>(<issue>2</issue>), <fpage>483</fpage>–<lpage>490</lpage>. <pub-id pub-id-type="doi">10.1037/0735-7044.119.2.483</pub-id></mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Durstewitz</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Seamans</surname>, <given-names>J. K</given-names></string-name></person-group>. (<year>2008</year>). <article-title>The dual-state theory of prefrontal cortex dopamine function with relevance to catechol-o-methyltransferase genotypes and schizophrenia</article-title>. <source>Biol Psychiatry</source>, <volume>64</volume>(<issue>9</issue>), <fpage>739</fpage>–<lpage>749</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2008.05.015</pub-id></mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esterman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Noonan</surname>, <given-names>S. K.</given-names></string-name>, <string-name><surname>Rosenberg</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>DeGutis</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2012</year>). <article-title>In the Zone or Zoning Out? Tracking Behavioral and Neural Fluctuations During Sustained Attention</article-title>. <source>Cerebral Cortex</source>, <volume>23</volume>(<issue>11</issue>), <fpage>2712</fpage>–<lpage>2723</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhs261</pub-id></mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fallon</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>van der Schaaf</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>ter Huurne</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name></person-group>. (<year>2017</year>). <article-title>The Neurocognitive Cost of Enhancing Cognition with Methylphenidate: Improved Distractor Resistance but Impaired Updating</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>29</volume>(<issue>4</issue>), <fpage>652</fpage>–<lpage>663</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_01065</pub-id></mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>First</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Karg</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Spitzer</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2015</year>). <source>Structured clinical interview for DSM-5 Research version (SCID-5 for DSM-5, research version; SCID-5-RV).</source> <publisher-loc>Arlington, VA</publisher-loc>: <publisher-name><italic>American Psychiatric Association</italic></publisher-name>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fischer</surname>, <given-names>A. G.</given-names></string-name>, &amp; <string-name><surname>Ullsperger</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Real and fictive outcomes are processed differently but converge on a common adaptive mechanism</article-title>. <source>Neuron</source>, <volume>79</volume>(<issue>6</issue>), <fpage>1243</fpage>–<lpage>1255</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.006</pub-id></mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Floresco</surname>, <given-names>S. B</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Prefrontal dopamine and behavioral flexibility: shifting from an “inverted-U” toward a family of functions [Review]</article-title>. <source>Frontiers in Neuroscience</source>, <volume>7</volume>. <pub-id pub-id-type="doi">10.3389/fnins.2013.00062</pub-id></mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garrett</surname>, <given-names>D. D.</given-names></string-name>, <string-name><surname>Nagel</surname>, <given-names>I. E.</given-names></string-name>, <string-name><surname>Preuschhof</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Burzynska</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Marchner</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wiegert</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jungehülsing</surname>, <given-names>G. J.</given-names></string-name>, <string-name><surname>Nyberg</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Villringer</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>S. C.</given-names></string-name>, <string-name><surname>Heekeren</surname>, <given-names>H. R.</given-names></string-name>, <string-name><surname>Bäckman</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Lindenberger</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Amphetamine modulates brain signal variability and working memory in younger and older adults</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>112</volume>(<issue>24</issue>), <fpage>7593</fpage>–<lpage>7598</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1504090112</pub-id></mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Goschke</surname>, <given-names>T.</given-names></string-name> (). . In , <string-name><given-names>M.</given-names> <surname>Beisert</surname></string-name>, &amp; <string-name><given-names>A.</given-names> <surname>Herwig</surname></string-name></person-group><year>2013</year>). <chapter-title>Volition in Action: Intentions, Control Dilemmas, and the Dynamic Regulation of Cognitive Control</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>W.</given-names> <surname>Prinz</surname></string-name></person-group>, , &amp;  (Eds.), <source>Action Science: Foundations of an Emerging Discipline</source> (pp. 0). <publisher-name>The MIT Press</publisher-name>. <pub-id pub-id-type="doi">10.7551/mitpress/9780262018555.003.0024</pub-id></mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goschke</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Bolte</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Emotional modulation of control dilemmas: the role of positive affect, reward, and dopamine in cognitive stability and flexibility</article-title>. <source>Neuropsychologia</source>, <volume>62</volume>, <fpage>403</fpage>–<lpage>423</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.07.015</pub-id></mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Goschke</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Bolte</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2018</year>). <chapter-title>A dynamic perspective on intention, conflict, and volition: Adaptive regulation and emotional modulation of cognitive control dilemmas</chapter-title>. In <source>Why people do the things they do: Building on Julius Kuhl’s contributions to the psychology of motivation and volition</source>. (pp. <fpage>111</fpage>–<lpage>129</lpage>). <publisher-loc>Hogrefe</publisher-loc>. <pub-id pub-id-type="doi">10.1027/00540-000</pub-id></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grossman</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Bari</surname>, <given-names>B. A.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. Y</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Serotonin neurons modulate learning rate through uncertainty</article-title>. <source>Current Biology</source>, <volume>32</volume>(<issue>3</issue>), <fpage>586</fpage>–<lpage>599.e587.</lpage> <pub-id pub-id-type="doi">10.1016/j.cub.2021.12.006</pub-id></mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Husain</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Mehta</surname>, <given-names>M. A</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Cognitive enhancement by drugs in health and disease</article-title>. <source>Trends Cogn Sci</source>, <volume>15</volume>(<issue>1</issue>), <fpage>28</fpage>–<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2010.11.002</pub-id></mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Iigaya</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Fonseca</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Murakami</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mainen</surname>, <given-names>Z. F.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2018</year>). <article-title>An effect of serotonergic stimulation on learning rates for rewards apparent after long intertrial intervals</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>), <fpage>2477</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-018-04840-2</pub-id></mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ilieva</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Boland</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Farah</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Objective and subjective cognitive enhancing effects of mixed amphetamine salts in healthy people</article-title>. <source>Neuropharmacology</source>, <volume>64</volume>, <fpage>496</fpage>–<lpage>505</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropharm.2012.07.021</pub-id></mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jocham</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>T. A.</given-names></string-name>, &amp; <string-name><surname>Ullsperger</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Differential modulation of reinforcement learning by D2 dopamine and NMDA glutamate receptor antagonism</article-title>. <source>J Neurosci</source>, <volume>34</volume>(<issue>39</issue>), <fpage>13151</fpage>–<lpage>13162</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.0757-14.2014</pub-id></mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karamacoska</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Barry</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Steiner</surname>, <given-names>G. Z</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Electrophysiological underpinnings of response variability in the Go/NoGo task</article-title>. <source>International Journal of Psychophysiology</source>, <volume>134</volume>, <fpage>159</fpage>–<lpage>167</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2018.09.008</pub-id></mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kirschner</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Fischer</surname>, <given-names>A. G.</given-names></string-name>, &amp; <string-name><surname>Ullsperger</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Feedback-related EEG dynamics separately reflect decision parameters, biases, and future choices</article-title>. <source>Neuroimage</source>, <volume>259</volume>, <fpage>119437</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119437</pub-id></mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kirschner</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Fischer</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>Frodl</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Meyer-Lotz</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Froböse</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Seidenbecher</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>T. A.</given-names></string-name>, &amp; <string-name><surname>Ullsperger</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Transdiagnostic inflexible learning dynamics explain deficits in depression and schizophrenia</article-title>. <source>Brain</source>, <volume>147</volume>(<issue>1</issue>), <fpage>201</fpage>–<lpage>214</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awad362</pub-id></mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kolling</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Wittmann</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Boorman</surname>, <given-names>E. D.</given-names></string-name>, <string-name><surname>Mars</surname>, <given-names>R. B.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Value, search, persistence and model updating in anterior cingulate cortex</article-title>. <source>Nat Neurosci</source>, <volume>19</volume>(<issue>10</issue>), <fpage>1280</fpage>–<lpage>1285</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4382</pub-id></mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Le Pelley</surname>, <given-names>M. E.</given-names></string-name></person-group> (<year>2004</year>). <article-title>The Role of Associative History in Models of Associative Learning: A Selective Review and a Hybrid Model</article-title>. <source>The Quarterly Journal of Experimental Psychology Section B</source>, <volume>57</volume>(<issue>3b</issue>), <fpage>193</fpage>–<lpage>243</lpage>. <pub-id pub-id-type="doi">10.1080/02724990344000141</pub-id></mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Schiller</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Schoenbaum</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Phelps</surname>, <given-names>E. A.</given-names></string-name>, &amp; <string-name><surname>Daw</surname>, <given-names>N. D</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Differential roles of human striatum and amygdala in associative learning</article-title>. <source>Nat Neurosci</source>, <volume>14</volume>(<issue>10</issue>), <fpage>1250</fpage>–<lpage>1252</lpage>. <pub-id pub-id-type="doi">10.1038/nn.2904</pub-id></mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lieder</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Shenhav</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Musslick</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Griffiths</surname>, <given-names>T. L</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Rational metareasoning and the plasticity of cognitive control</article-title>. <source>PLoS Comput Biol</source>, <volume>14</volume>(<issue>4</issue>), <fpage>e1006043</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006043</pub-id></mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MacRae</surname>, <given-names>P. G.</given-names></string-name>, <string-name><surname>Spirduso</surname>, <given-names>W. W.</given-names></string-name>, &amp; <string-name><surname>Wilcox</surname>, <given-names>R. E</given-names></string-name></person-group>. (<year>1988</year>). <article-title>Reaction time and nigrostriatal dopamine function: the effects of age and practice</article-title>. <source>Brain Res</source>, <volume>451</volume>(<issue>1-2</issue>), <fpage>139</fpage>–<lpage>146</lpage>. <pub-id pub-id-type="doi">10.1016/0006-8993(88)90758-5</pub-id></mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marshall</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Mathys</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ruge</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>de Berker</surname>, <given-names>A. O.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name>, &amp; <string-name><surname>Bestmann</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Pharmacological Fingerprints of Contextual Uncertainty</article-title>. <source>PLoS Biol</source>, <volume>14</volume>(<issue>11</issue>), <fpage>e1002575</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pbio.1002575</pub-id></mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meder</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kolling</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Verhagen</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wittmann</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Scholl</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Madsen</surname>, <given-names>K. H.</given-names></string-name>, <string-name><surname>Hulme</surname>, <given-names>O. J.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F. S</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Simultaneous representation of a spectrum of dynamically changing value estimates during decision making</article-title>. <source>Nature Communications</source>, <volume>8</volume>(<issue>1</issue>), <fpage>1942</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-017-02169-w</pub-id></mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morean</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>de Wit</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>King</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Sofuoglu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rueger</surname>, <given-names>S. Y.</given-names></string-name>, &amp; <string-name><surname>O’Malley</surname>, <given-names>S. S.</given-names></string-name></person-group> (<year>2013</year>). <article-title>The drug effects questionnaire: psychometric support across three drug types</article-title>. <source>Psychopharmacology (Berl</source><italic>)</italic>, <volume>227</volume>(<issue>1</issue>), <fpage>177</fpage>–<lpage>192</lpage>. <pub-id pub-id-type="doi">10.1007/s00213-012-2954-z</pub-id></mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Muller</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Mars</surname>, <given-names>R. B.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, &amp; <string-name><surname>O’Reilly</surname>, <given-names>J. X</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Control of entropy in neural models of environmental state</article-title>. <source>Elife</source>, <volume>8</volume>. <pub-id pub-id-type="doi">10.7554/eLife.39404</pub-id></mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Statistical context dictates the relationship between feedback-related EEG signals and learning</article-title>. <source>Elife</source>, <volume>8</volume>. <pub-id pub-id-type="doi">10.7554/eLife.46975</pub-id></mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>S. C.</given-names></string-name>, <string-name><surname>Heekeren</surname>, <given-names>H. R.</given-names></string-name>, &amp; <string-name><surname>Eppinger</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Age differences in learning emerge from an insufficient representation of uncertainty in older adults</article-title>. <source>Nat Commun</source>, <volume>7</volume>, <fpage>11609</fpage>. <pub-id pub-id-type="doi">10.1038/ncomms11609</pub-id></mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Rumsey</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Parikh</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nat Neurosci</source>, <volume>15</volume>(<issue>7</issue>), <fpage>1040</fpage>–<lpage>1046</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Waltz</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Albrecht</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Gold</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>All or nothing belief updating in patients with schizophrenia reduces precision and flexibility of beliefs</article-title>. <source>Brain</source>, <volume>144</volume>(<issue>3</issue>), <fpage>1013</fpage>–<lpage>1029</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awaa453</pub-id></mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I</given-names></string-name></person-group>. (<year>2010</year>). <article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title>. <source>J Neurosci</source>, <volume>30</volume>(<issue>37</issue>), <fpage>12366</fpage>–<lpage>12378</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0822-10.2010</pub-id></mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Owesson-White</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Cheer</surname>, <given-names>J. F.</given-names></string-name>, <string-name><surname>Beyene</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Carelli</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Wightman</surname>, <given-names>R. M</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Dynamic changes in accumbens dopamine correlate with learning during intracranial self-stimulation</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>105</volume>(<issue>33</issue>), <fpage>11957</fpage>–<lpage>11962</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0803896105</pub-id></mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pasupathy</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Miller</surname>, <given-names>E. K</given-names></string-name></person-group>. (<year>2005</year>). <article-title>Different time courses of learning-related activity in the prefrontal cortex and striatum</article-title>. <source>Nature</source>, <volume>433</volume>(<issue>7028</issue>), <fpage>873</fpage>–<lpage>876</lpage>. <pub-id pub-id-type="doi">10.1038/nature03287</pub-id></mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piray</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Ly</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Roelofs</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Toni</surname>, <given-names>I</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Emotionally Aversive Cues Suppress Neural Systems Underlying Optimal Learning in Socially Anxious Individuals</article-title>. <source>J Neurosci</source>, <volume>39</volume>(<issue>8</issue>), <fpage>1445</fpage>–<lpage>1456</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.1394-18.2018</pub-id></mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Preuschoff</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>t Hart</surname>, <given-names>B. M.</given-names></string-name>, &amp; <string-name><surname>Einhäuser</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Pupil Dilation Signals Surprise: Evidence for Noradrenaline’s Role in Decision Making</article-title>. <source>Front Neurosci</source>, <volume>5</volume>, <fpage>115</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2011.00115</pub-id></mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prince</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Catecholamine dysfunction in attention-deficit/hyperactivity disorder: an update</article-title>. <source>J Clin Psychopharmacol</source>, <volume>28</volume>(<issue>3 Suppl 2</issue>), <fpage>S39</fpage>-<lpage>45</lpage>. <pub-id pub-id-type="doi">10.1097/JCP.0b013e318174f92a</pub-id></mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Razmi</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Nassar</surname>, <given-names>M. R</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Adaptive Learning through Temporal Dynamics of State Representation</article-title>. <source>J Neurosci</source>, <volume>42</volume>(<issue>12</issue>), <fpage>2524</fpage>–<lpage>2538</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.0387-21.2022</pub-id></mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Repantis</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Schlattmann</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Laisney</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Heuser</surname>, <given-names>I</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Modafinil and methylphenidate for neuroenhancement in healthy individuals: A systematic review</article-title>. <source>Pharmacol Res</source>, <volume>62</volume>(<issue>3</issue>), <fpage>187</fpage>–<lpage>206</lpage>. <pub-id pub-id-type="doi">10.1016/j.phrs.2010.04.002</pub-id></mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rigoux</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, &amp; <string-name><surname>Daunizeau</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Bayesian model selection for group studies – revisited</article-title>. <source>Neuroimage</source>, <volume>84</volume>, <fpage>971</fpage>–<lpage>985</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.065</pub-id></mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rostami Kandroodi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cook</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Swart</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Froböse</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Geurts</surname>, <given-names>D. E. M.</given-names></string-name>, <string-name><surname>Vahabie</surname>, <given-names>A. H.</given-names></string-name>, <string-name><surname>Nili Ahmadabadi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>den Ouden</surname>, <given-names>H. E. M.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Effects of methylphenidate on reinforcement learning depend on working memory capacity</article-title>. <source>Psychopharmacology (Berl</source><italic>)</italic>, <volume>238</volume>(<issue>12</issue>), <fpage>3569</fpage>–<lpage>3584</lpage>. <pub-id pub-id-type="doi">10.1007/s00213-021-05974-w</pub-id></mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schultz</surname>, <given-names>W</given-names></string-name>., <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Montague</surname>, <given-names>P. R.</given-names></string-name></person-group> (<year>1997</year>). <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>, <volume>275</volume>(<issue>5306</issue>), <fpage>1593</fpage>–<lpage>1599</lpage>. <pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id></mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwarz</surname>, <given-names>G</given-names></string-name></person-group>. (<year>1978</year>). <article-title>Estimating the Dimension of a Model</article-title>. <source>The Annals of Statistics</source>, <volume>6</volume>(<issue>2</issue>), <fpage>461</fpage>–<lpage>464</lpage>. <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2958889">http://www.jstor.org/stable/2958889</ext-link></mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schweighofer</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Doya</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Meta-learning in reinforcement learning</article-title>. <source>Neural Netw</source>, <volume>16</volume>(<issue>1</issue>), <fpage>5</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1016/s0893-6080(02)00228-9</pub-id></mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Servan-Schreiber</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Carter</surname>, <given-names>C. S.</given-names></string-name>, <string-name><surname>Bruno</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>1998</year>). <article-title>Dopamine and the mechanisms of cognition: Part II. D-amphetamine effects in human subjects performing a selective attention task</article-title>. <source>Biol Psychiatry</source>, <volume>43</volume>(<issue>10</issue>), <fpage>723</fpage>–<lpage>729</lpage>. <pub-id pub-id-type="doi">10.1016/s0006-3223(97)00449-6</pub-id></mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Set</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Saez</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Houser</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Myung</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Zhong</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ebstein</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>Chew</surname>, <given-names>S. H.</given-names></string-name>, &amp; <string-name><surname>Hsu</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Dissociable contribution of prefrontal and striatal dopaminergic genes to learning in economic games</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>111</volume>(<issue>26</issue>), <fpage>9615</fpage>–<lpage>9620</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1316259111</pub-id></mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Silvetti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Vassena</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Abrahamse</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Verguts</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Dorsal anterior cingulate-brainstem ensemble as a reinforcement meta-learner</article-title>. <source>PLoS Comput Biol</source>, <volume>14</volume>(<issue>8</issue>), <fpage>e1006370</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006370</pub-id></mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname>, <given-names>M. E.</given-names></string-name>, &amp; <string-name><surname>Farah</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Are prescription stimulants “smart pills”? The epidemiology and cognitive neuroscience of prescription stimulant use by normal healthy individuals</article-title>. <source>Psychol Bull</source>, <volume>137</volume>(<issue>5</issue>), <fpage>717</fpage>–<lpage>741</lpage>. <pub-id pub-id-type="doi">10.1037/a0023825</pub-id></mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name>, <string-name><surname>Penny</surname>, <given-names>W. D.</given-names></string-name>, <string-name><surname>Daunizeau</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Moran</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K. J</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Bayesian model selection for group studies</article-title>. <source>Neuroimage</source>, <volume>46</volume>(<issue>4</issue>), <fpage>1004</fpage>–<lpage>1017</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.025</pub-id></mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Turner</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Peak</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Burne</surname>, <given-names>T. H</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Baseline-dependent effects of amphetamine on attention are associated with striatal dopamine metabolism</article-title>. <source>Sci Rep</source>, <volume>7</volume>(<issue>1</issue>), <fpage>297</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-017-00437-9</pub-id></mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Bosch</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Lambregts</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Määttä</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hofmans</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Papadopetraki</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Westbrook</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Verkes</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Booij</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Striatal dopamine dissociates methylphenidate effects on value-based versus surprise-based reversal learning</article-title>. <source>Nat Commun</source>, <volume>13</volume>(<issue>1</issue>), <fpage>4962</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-022-32679-1</pub-id></mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Schaaf</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Fallon</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Ter Huurne</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Buitelaar</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Working memory capacity predicts effects of methylphenidate on reversal learning</article-title>. <source>Neuropsychopharmacology</source>, <volume>38</volume>(<issue>10</issue>), <fpage>2011</fpage>–<lpage>2018</lpage>. <pub-id pub-id-type="doi">10.1038/npp.2013.100</pub-id></mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van der Schaaf</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>van Schouwenburg</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Geurts</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Schellekens</surname>, <given-names>A. F.</given-names></string-name>, <string-name><surname>Buitelaar</surname>, <given-names>J. K.</given-names></string-name>, <string-name><surname>Verkes</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Establishing the dopamine dependency of human striatal signals during reward and punishment reversal learning</article-title>. <source>Cereb Cortex</source>, <volume>24</volume>(<issue>3</issue>), <fpage>633</fpage>–<lpage>642</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhs344</pub-id></mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Volkow</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>G. J.</given-names></string-name>, <string-name><surname>Fowler</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Logan</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Franceschi</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Maynard</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ding</surname>, <given-names>Y. S.</given-names></string-name>, <string-name><surname>Gatley</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Gifford</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Swanson</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Relationship between blockade of dopamine transporters by oral methylphenidate and the increases in extracellular dopamine: therapeutic implications</article-title>. <source>Synapse</source>, <volume>43</volume>(<issue>3</issue>), <fpage>181</fpage>–<lpage>187</lpage>. <pub-id pub-id-type="doi">10.1002/syn.10038</pub-id></mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Westbrook</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>van den Bosch</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Määttä</surname>, <given-names>J. I.</given-names></string-name>, <string-name><surname>Hofmans</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Papadopetraki</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Dopamine promotes cognitive effort by biasing the benefits versus costs of cognitive work</article-title>. <source>Science</source>, <volume>367</volume>(<issue>6484</issue>), <fpage>1362</fpage>–<lpage>1366</lpage>. <pub-id pub-id-type="doi">10.1126/science.aaz5891</pub-id></mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>White</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Justice</surname>, <given-names>A. J.</given-names></string-name>, &amp; <string-name><surname>de Wit</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Differential subjective effects of D-amphetamine by gender, hormone levels and menstrual cycle phase</article-title>. <source>Pharmacol Biochem Behav</source>, <volume>73</volume>(<issue>4</issue>), <fpage>729</fpage>–<lpage>741</lpage>.</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I</given-names></string-name></person-group>. (<year>2013</year>). <article-title>A mixture of delta-rules approximation to bayesian inference in change-point problems</article-title>. <source>PLoS Comput Biol</source>, <volume>9</volume>(<issue>7</issue>), <fpage>e1003150</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003150</pub-id></mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>A. J.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2005</year>). <article-title>Uncertainty, neuromodulation, and attention</article-title>. <source>Neuron</source>, <volume>46</volume>(<issue>4</issue>), <fpage>681</fpage>–<lpage>692</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id></mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>L. Q.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, &amp; <string-name><surname>Nassar</surname>, <given-names>M. R</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Adaptive learning is structure learning in time</article-title>. <source>Neurosci Biobehav Rev</source>, <volume>128</volume>, <fpage>270</fpage>–<lpage>281</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2021.06.024</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101413.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Cools</surname>
<given-names>Roshan</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This manuscript reports on the effects of a single dose of methamphetamine vs placebo on a probabilistic reversal learning task with different levels of noise, in a large group of young healthy volunteers. The paper is well written and the methods are rigorous. The findings are <bold>valuable</bold> and have theoretical or practical implications for a subfield. The strength of the evidence is <bold>solid</bold>, with the methods, data, and analyses broadly supporting the claims with only minor weaknesses.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101413.1.sa0</article-id>
<title-group>
<article-title>Reviewing Editor (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this well-written paper, a pharmacological experiment is described in which a large group of volunteers is tested on a novel probabilistic reversal learning task with different levels of noise, once after intake of methamphetamine and once after intake of placebo. The design includes a separate baseline session, during which performance is measured. The key result is that drug effects on learning rate variability depend on performance in this separate baseline session.</p>
<p>The approach and research question are important, the results will have an impact, and the study is executed according to current standards in the field. Strengths include the interventional pharmacological design, the large sample size, the computational modeling, and the use of a reversal-learning task with different levels of noise.</p>
<p>(i) One novel and valuable feature of the task is the variation of noise (having 70-30 and 80-20 conditions). This nice feature is currently not fully exploited in the modeling of the task and the data. For example, recently reported new modeling approaches for disentangling two types of uncertainty (stochasticity vs volatility) could be usefully leveraged here (by Piray and Daw, 2021, Nat Comm). The current 'signal to noise ratio' analysis that is targeting this issue relies on separately assessing learning rates on true reversals and learning rates after misleading feedback, in a way that is experimenter-driven. As a result, this analysis cannot capture a latent characteristic of the subject's computational capacity.</p>
<p>(ii) An important caveat is that all the drug x baseline performance interactions, including for the key computational eta parameter did not reach the statistical threshold, and only tended towards significance.</p>
<p>(iii) Both the overlap and the differences between the current study and previous relevant work (that is, how this goes beyond prior studies in particular Rostami Kandroodi et al, which also assessed effects of catecholaminergic drug administration as a function of baseline task performance using a probabilistic reversal learning task) are not made explicit, particularly in the introduction.</p>
<p>(iv) In the discussion, it is stated that the existing literature has, to date, overlooked baseline performance effects, but this is not true in the general sense, given that an accumulating number of studies have shown that the effects of drugs like MA depend on baseline performance on working memory tasks, which often but certainly not always correlates positively with performance on the task under study.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101413.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The authors examine how probabilistic reversal learning is affected by dopamine by studying the effects of methamphetamine (MA) administration. Based on prior evidence that the effects of pharmacological manipulation depend on baseline neurotransmitter levels, they hypothesized that MA would improve learning in people with low baseline performance. They found this effect, and specifically found that MA administration improved learning in noisy blocks, by reducing learning from misleading performance, in participants with lower baseline performance. The authors then fit participants' behavior to a computational learning model and found that an eta parameter, responsible for scaling learning rate based on previously surprising outcomes, differed in participants with low baseline performance on and off MA.</p>
<p>Questions:</p>
<p>(1) It would be helpful to confirm that the observed effect of MA on the eta parameter is responsible for better performance in low baseline performers. If performance on the task is simulated for parameters estimated for high and low baseline performers on and off MA, does the simulated behavior capture the main behavioral differences shown in Figure 3?</p>
<p>(2) In Figure 4C, it appears that the main parameter difference between low and high baseline performance is inverse temperature, not eta. If MA is effective in people with lower baseline DA, why is the effect of MA on eta and not IT?</p>
<p>Also, this parameter is noted as temperature but appears to be inverse temperature as higher values are related to better performance. The exact model for the choice function is not described in the methods.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101413.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Kirschner and colleagues test whether methamphetamine (MA) alters learning rate dynamics in a validated reversal learning task. They find evidence that MA can enhance performance for low-performers and that the enhancement reflects a reduction in the degree to which these low-performers dynamically up-regulate their learning rates when they encounter unexpected outcomes. The net effect is that poor performers show more volatile learning rates (e.g. jumping up when they receive misleading feedback), when the environment is actually stable, undermining their performance over trials.</p>
<p>Strengths:</p>
<p>The study has multiple strengths including large sample size, placebo control, double-blind randomized design, and rigorous computational modeling of a validated task.</p>
<p>Weaknesses:</p>
<p>The limitations, which are acknowledged, include that the drug they use, methamphetamine, can influence multiple neuromodulatory systems including catecholamines and acetylcholine, all of which have been implicated in learning rate dynamics. They also do not have any independent measures of any of these systems, so it is impossible to know which is having an effect.</p>
<p>Another limitation that the authors should acknowledge is that the fact that participants were aware of having different experiences in the drug sessions means that their blinding was effectively single-blind (to the experimenters) and not double-blind. Relatedly, it is difficult to know whether subjective effects of drugs (e.g. arousal, mood, etc.) might have driven differences in attention, causing performance enhancements in the low-performing group. Do the authors have measures of these subjective effects that they could include as covariates of no interest in their analyses?</p>
</body>
</sub-article>
</article>