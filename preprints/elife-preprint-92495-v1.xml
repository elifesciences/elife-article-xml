<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">92495</article-id>
<article-id pub-id-type="doi">10.7554/eLife.92495</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.92495.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Multi-day Neuron Tracking in High Density Electrophysiology Recordings using EMD</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Yuan</surname>
<given-names>Augustine(Xiaoran)</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Colonell</surname>
<given-names>Jennifer</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lebedeva</surname>
<given-names>Anna</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Okun</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Charles</surname>
<given-names>Adam</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6289-4439</contrib-id>
<name>
<surname>Harris</surname>
<given-names>Timothy</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Janelia Research Campus, Howard Hughes Medical Institute</institution>, Ashburn, VA, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Department of Biomedical Engineering, Center for Imaging Science, Kavli Neuroscience Discovery Institute, Johns Hopkins University</institution>, Baltimore, MD, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Sainsbury Wellcome Centre, University College London</institution>, London, <country>UK</country></aff>
<aff id="a4"><label>4</label><institution>Department of Psychology and Neuroscience Institute, University of Sheffield</institution>, Sheffield, <country>UK</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Peyrache</surname>
<given-names>Adrien</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>McGill University</institution>
</institution-wrap>
<city>Montreal</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding author(s). E-mail(s): <email>adamsc@jhu.edu</email>; <email>harrist@janelia.hhmi.org</email>;</corresp>
<fn fn-type="con"><p>Contributing authors: <email>yuanx@janelia.hhmi.org</email>; <email>colonellj@janelia.hhmi.org</email>; <email>anna.lebedeva.17@ucl.ac.uk</email>; <email>m.okun@sheffield.ac.uk</email>;</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-12-12">
<day>12</day>
<month>12</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP92495</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-09-18">
<day>18</day>
<month>09</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-09-03">
<day>03</day>
<month>09</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.08.03.551724"/>
</event>
</pub-history>
<permissions>
<copyright-statement>Â© 2023, Yuan et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Yuan et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-92495-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Accurate tracking of the same neurons across multiple days is crucial for studying changes in neuronal activity during learning and adaptation. Advances in high density extracellular electrophysiology recording probes, such as Neuropixels, provide a promising avenue to accomplish this goal. Identifying the same neurons in multiple recordings is, however, complicated by non-rigid movement of the tissue relative to the recording sites (drift) and loss of signal from some neurons. Here we propose a neuron tracking method that can identify the same cells independent of firing statistics, which a reused by most existing methods. Our method is based on between-day non-rigid alignment of spike sorted clusters. We verified the same cell identify using measured visual receptive fields. This method succeeds on datasets separated from one to 47 days, with an 84% average recovery rate.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Neuron tracking</kwd>
<kwd>Neuropixels</kwd>
<kwd>visual cortex</kwd>
<kwd>chronic recording</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>We have added an author, correct typo's and posted the software archive</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/AugustineY07/Neuron_Tracking">https://github.com/AugustineY07/Neuron_Tracking</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>The ability to longitudinally track neural activity is crucial to understanding central capabilities and changes of neural circuits that operate on long time-scales, such as learning and plasticity[<xref ref-type="bibr" rid="c1">1</xref>][<xref ref-type="bibr" rid="c2">2</xref>][<xref ref-type="bibr" rid="c3">3</xref>][<xref ref-type="bibr" rid="c4">4</xref>] and motor stability[<xref ref-type="bibr" rid="c5">5</xref>][<xref ref-type="bibr" rid="c1">1</xref>][<xref ref-type="bibr" rid="c6">6</xref>]. We seek to develop a method capable of tracking single units regardless of changes in functional responses for the duration of an experiment spanning one to two months.</p>
<p>High-density multi-channel extracellular electrophysiology (ephys) recording devices enable chronic recordings over large areas for days-to-months[<xref ref-type="bibr" rid="c7">7</xref>]. Such chronic recordings make possible experiments targeted at improving our understanding of neural computation and underlying mechanisms. Examples include perceptual decision making, exploration and navigation[<xref ref-type="bibr" rid="c8">8</xref>][<xref ref-type="bibr" rid="c9">9</xref>][<xref ref-type="bibr" rid="c10">10</xref>][<xref ref-type="bibr" rid="c11">11</xref>][<xref ref-type="bibr" rid="c12">12</xref>][<xref ref-type="bibr" rid="c13">13</xref>]. Electrode arrays with hundreds to thousands of sites, for example Neuropixels, are now used extensively to record the neural activity of large populations stably and with high spatio-temporal resolution, capturing hundreds of neurons with single neuron resolution[<xref ref-type="bibr" rid="c9">9</xref>][<xref ref-type="bibr" rid="c10">10</xref>]. Moreover, ephys retains the higher time resolution needed for single spike identification, as compared with calcium imaging that provides more spatial cues with which to track neurons over days.</p>
<p>The first step in analyzing ephys data is to extract single neuron signals from the recorded voltage traces, i.e. spike sorting. Spike sorting identifies individual neurons by grouping detected action potentials using waveform profiles and amplitudes. Specific algorithms include principal components based methods, for example,[<xref ref-type="bibr" rid="c14">14</xref>] and [<xref ref-type="bibr" rid="c15">15</xref>], and template matching methods, for example, Kilosort[<xref ref-type="bibr" rid="c16">16</xref>][<xref ref-type="bibr" rid="c9">9</xref>][<xref ref-type="bibr" rid="c11">11</xref>][<xref ref-type="bibr" rid="c17">17</xref>]. Due to the high dimensional nature of the data, spike sorting is often computationally intensive on large data sets (10âs to 100âs of GB) and optimized to run on single sessions. Thus processing multiple sessions has received minimal attention, and the challenges therein remain largely unaddressed.</p>
<p>One major challenge in reliably tracking neurons is the potential for changes in the neuron population recorded (<xref rid="fig1" ref-type="fig">Fig. 1a</xref> and <xref rid="fig1" ref-type="fig">1b</xref>). In particular, since the probe is attached to the skull, brain tissue can move relative to the probe, e.g. during licking, and drift can accumulate over time[<xref ref-type="bibr" rid="c18">18</xref>]. Kilosort 2.5 corrects drift within a single recording by inferring tissue motion from continuous changes in spiking activity and interpolating the data to account for that motion[<xref ref-type="bibr" rid="c7">7</xref>]. Larger between-recording drift occurs for sessions on different days, and can 1) change the size and location of spike waveforms along the probe[<xref ref-type="bibr" rid="c19">19</xref>], 2) lose neurons that move out of range, and 3) gain new neurons that move into recording range. Thus clusters can change firing pattern characteristics or completely appear/disappear. As a result the specific firing patterns classified a s unit lusters may appear and disappear in different recordings[<xref ref-type="bibr" rid="c9">9</xref>][<xref ref-type="bibr" rid="c20">20</xref>][<xref ref-type="bibr" rid="c21">21</xref>][<xref ref-type="bibr" rid="c22">22</xref>]. Another challenge is that popular template-matching-based spike sorting methods usually involve some randomness in template initialization[<xref ref-type="bibr" rid="c16">16</xref>][<xref ref-type="bibr" rid="c23">23</xref>][<xref ref-type="bibr" rid="c24">24</xref>]. As a result, action potentials can be assigned to clusters differently, and clusters can be merged or separated differently across runs.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1:</label>
<caption><p>Schematic depiction of drift: a. Mice were implanted with a 4-shank Neuropixels 2.0 probe in visual cortex area V1. b. Each colored star represents the location of a unit recorded on the probe. In this hypothetical case, the same color indicates unit correspondence across days. The black unit is missing on day 48, while the turquoise star is an example of a new unit. Tracking aims to correctly match the red and blue unit across all datasets and detect that the black units on day 48 is likely undetected. c. Two example spatial-temporal waveforms of units recorded in two datasets that likely represent the same neuron, based on similar visual responses. Each trace is the average waveform on one channel across 2.7 millisecond. The blue traces are waveforms on a peak channel and 9 nearby channels (two rows above, two rows below, and one in the same row) from the first dataset (Day 1). The red traces, similarly selected, are from the second dataset. Waveforms are aligned at the electrodes with peak amplitude, different on the two days.</p></caption>
<graphic xlink:href="551724v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Previous neuron tracking methods are frequently based on waveform and firing statistics, e.g., firing rate similarity[<xref ref-type="bibr" rid="c25">25</xref>], action potential shape correlation and inter-spike interval histogram(ISI) shape[<xref ref-type="bibr" rid="c26">26</xref>]. When neuronal representations change, e.g., during learning [<xref ref-type="bibr" rid="c1">1</xref>][<xref ref-type="bibr" rid="c2">2</xref>][<xref ref-type="bibr" rid="c3">3</xref>] or representational drift [<xref ref-type="bibr" rid="c27">27</xref>], neural activity statistics became less reliable. In this work, we take advantage of the rich spatial-temporal information in the multi-channel recordings, matching units based on the estimated neuron locations and unit waveforms[<xref ref-type="bibr" rid="c28">28</xref>], instead of firing patterns.</p>
<p>As an alternative method, Steinmetz et al.[<xref ref-type="bibr" rid="c7">7</xref>] concatenated pairs of datasets after low resolution alignment, awkward for more than 2 datasets. We report here a more flexible, ex p andable a n d ro b ust tr a cking me t hod th a t ca n track neurons effectively a nd e fficiently acr oss any num ber of sessions.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<sec id="s2a">
<label>2.1</label>
<title>Procedure</title>
<p>Our datasets consist of multiple recordings taken from three mice over 2 months. The time gap between two recordings ranges from two to 25 days. Each dataset is spike-sorted individually with a standard Kilosort 2.5 pipeline. The sorting results, including unit assignment, spike times, are used as input for our method (post-processed using [<xref ref-type="bibr" rid="c29">29</xref>]) (<xref ref-type="sec" rid="s4b">Sec. 4.2</xref>). To ensure the sorting results are unbiased, we performed no manual curation. As the clusters returned by Kilosort can vary in quality, we only considered the subset of units labeled as âgoodâ by Kilosort, here referred to as KSgood units(<xref ref-type="sec" rid="s4c">Sec. 4.3</xref>). KSgood units are mainly determined by the fraction of inter-spike-interval violations and are believed to represent a single unit[<xref ref-type="bibr" rid="c16">16</xref>].</p>
<p>Our overall strategy is to run spike-sorting once per session, and then to generate a unit-by-unit assignment between pairs of datasets. When tracking units across more than two sessions, two strategies are possible: matching of all ensuing sessions to a single session (e.g., the first s ession) (<xref ref-type="sec" rid="s2b">Sec. 2.2</xref> and <xref ref-type="sec" rid="s2c">Sec. 2.3</xref>), or match consecutive pairs of sessions and then tracing matched units through all sessions (<xref ref-type="sec" rid="s2d">Sec. 2.4</xref>).</p>
<p>We refer to the subset of KSgood units with strong and distinguishable visual responses in both compared datasets as reference units (See <xref ref-type="sec" rid="s4c">Sec. 4.3</xref> for details). Similar to Steinmetz et al.[<xref ref-type="bibr" rid="c7">7</xref>]. we validated our unit matchings of those reference units using visual receptive field similarity. Finally, we showed that trackable units with strong visual response are qualitatively similar to those without (<xref rid="figS1" ref-type="fig">Supplement Fig. S1</xref> to <xref rid="figS5" ref-type="fig">S5</xref>).</p>
<p>To provide registration between pairs of recordings, we used the Earth Moverâs Distance (EMD)[<xref ref-type="bibr" rid="c30">30</xref>][<xref ref-type="bibr" rid="c31">31</xref>]. We use a feature space consisting of a geometric distance space and a waveform similarity space, to address both rigid and non-rigid neuron motion. The EMD finds matches between objects in the two distributions by minimizing the overall distances between the established matches (<xref ref-type="sec" rid="s4a1">Sec. 4.1.1</xref>).</p>
<p>We use EMD in two stages: rigid drift correction and unit assignment. Importantly, the EMD distance incorporates two parameters crucial for matching units: location-based physical distance and a waveform distance metric that characterizes similarity of waveforms (<xref ref-type="sec" rid="s4a2">Sec. 4.1.2</xref>). The EMD distance matrix is constructed with a weighted combination of the two (details in <xref ref-type="sec" rid="s4">Sec. 4</xref>), i.e. a distance between two units <italic>d</italic><sub><italic>ik</italic></sub> is given by <italic>d</italic><sub><italic>ik</italic></sub> = <italic>d</italic><sub><italic>location</italic></sub><italic>ik</italic> + <italic>d</italic><sub><italic>waveform</italic></sub><italic>ik</italic> (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>). The first EMD stage estimates the homogeneous vertical movement of the entire population of KSgood units (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>). This movement estimate is used to correct the between-session rigid drift in unit locations. The rigid drift estimation procedure is illustrated in <xref rid="fig2" ref-type="fig">figure 2b</xref>. Post drift correction, a unitâs true match will be close in both physical distance and waveform distance. Drift-corrected units were then matched at the second EMD stage. The EMD distance between assigned units can be thought of as the local non-rigid drift combined with the waveform distortion resulting from drift. We test the accuracy of the matching by comparing with reference unit assignments based on visual receptive fields (<xref ref-type="sec" rid="s4c">Sec. 4.3</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2:</label>
<caption><p>The EMD can detect the displacement of single units: a. Schematic of EMD unit matching. Each blue unit in day 1 is matched to a red unit in day 2. Dashed lines indicate the matches to be found by minimizing the weighted sum of physical and waveform distances. b. Open and filled circles show positions of units on days 1 and 2, respectively. Arrows indicate matching using EMD. The arrow color represents the match direction; upward matches found with the EMD are in red and downward in black. Solid lines indicate a z-match distance within 15<italic>Âµm</italic>, while a dashed line indicates a z distance <italic>&gt;</italic> 15<italic>Âµm</italic>. An expand segment is shown for the probe section from 3120 to 3220<italic>Âµm</italic>. c. The match distance histogram (black and red bars) and kernel fit (light blue solid curve). The light blue dashed line shows the mode (<italic>d</italic><sub><italic>m</italic></sub> = 15.65<italic>Âµm</italic>). The dark blue dashed line shows the imposed drift (<italic>d</italic><sub><italic>i</italic></sub> = 12<italic>Âµm</italic>). The red region shows the matches within 15<italic>Âµm</italic> of the mode. The EMD needs to detect the homogeneous movement against the background, i.e. units in the black region that are unlikely to be the real match due to biological constraints.</p></caption>
<graphic xlink:href="551724v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For each unit, the location is determined by fitting the peak to peak amplitudes on the 10 sites nearest the site with peak signal, based on the tri-angulation method in [<xref ref-type="bibr" rid="c32">32</xref>] (<xref ref-type="sec" rid="s4a2">Sec. 4.1.2</xref>). The waveform distance is an L2 norm between two spatial-temporal waveforms that spans 22 channels and 2.7 msec (<xref ref-type="sec" rid="s4a2">Sec. 4.1.2</xref>). Physical unit distances provide a way to maintain the internal structure and relations between units in the EMD. Waveform similarity metrics will distinguish units in the local neighborhood and likely reduce the effect of new and missing units (<xref rid="figS6" ref-type="fig">Fig. S6</xref>).</p>
<p>We analyzed the match assignment results in two ways. First, we compared all subsequent datatsets to dataset 1 using recovery rate and accuracy. We define recovery rate <italic>R</italic><sub><italic>rec</italic></sub> as the fraction of unit assignments by our method that are the same as reference units assignments established using visual response (<xref ref-type="sec" rid="s4c">Sec. 4.3</xref>).
<disp-formula id="eqn1">
<graphic xlink:href="551724v3_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Since the EMD forces all units from the dataset with fewer neurons to have an assigned match, we use vertical z-distance to threshold out the biologically-impossible unit assignments. We then calculated the accuracy <italic>R</italic><sub><italic>acc</italic></sub>, i.e. the number of unit assignments within the z-distance threshold by our method the same as assignments of reference units.
<disp-formula id="eqn2">
<graphic xlink:href="551724v3_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We retrieved non-reference units, i.e. matched units without receptive field information but whose z-distance is smaller than the threshold.</p>
<p>Second, we tracked units between consecutive datasets and summarized and analyzed the waveforms, unit locations, firing rate, visual responses (see <xref rid="figS1" ref-type="fig">Supplement Fig. S1</xref> to <xref rid="figS5" ref-type="fig">S5</xref> for details) of all tracked chains, i.e. units that can be tracked across at least three consecutive datasets.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Measuring rigid drift using the EMD</title>
<p>Drift happens mostly along the direction of probe insertion (vertical or z direction). We want to estimate the amount of vertical drift under the assumption that part of the drift is rigid, this is likely a good assumption given the small (720 <italic>Âµm</italic>) z-range of these recordings. The EMD allows us to extract the homogeneous (rigid) movement of matched units. For datasets with a few units consistently detected across days, this problem is relatively simple (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>). In these datasets, we find that only â60% of units are detected on both days, so the rigid motion of the real pairs must be detected against a background of units with no true match. These units with no real match will have z-shifts far from the consensus z-shift of the paired units (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>).</p>
<p>The EMD match of units from the first dataset (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>, open circles) and from the dataset recorded the next day (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>, closed circles) is indicated by the arrow between them. We added a 12 micron upward drift to the z-coordinate of the units from the second day and use the first stage of the EMD to find the matches using combined distances as described in <xref ref-type="sec" rid="s4a2">sections 4.1.2</xref> and <xref ref-type="sec" rid="s4a2">4.1.2</xref>. We used the z-distance mode (Mode = 16 <italic>Âµm</italic>) of a kernel fit of all the matched units to find the rigid d rift (<xref rid="fig2" ref-type="fig">Fig. 2 c</xref>). T he resulting mode is close to the actual imposed drift (<italic>d</italic><sub><italic>i</italic></sub> = 12<italic>Âµm</italic>).</p>
<p>As the EMD is an optimization algorithm with no biological constraints, it assigns matches to all units in the smaller dataset regardless of biophysical plausibility. As a result, some of the assigned matches may have unrealistically long distances. We thus select only the pairs with separation below a threshold. Here we use <italic>Î»</italic> = 15<italic>Âµm</italic>, which is chosen to be larger than most of the z-shift in experimental data, and will be refined later by distribution fitting (<xref rid="figS2" ref-type="fig">Fig. S2</xref>). All of the sub-threshold (short) distances belong to upward pairs (<xref rid="fig2" ref-type="fig">Fig. 2b</xref> and <xref rid="fig2" ref-type="fig">2c</xref>, red solid arrows), showing that the EMD can detect the homogeneous movement direction and the amount of imposed drift.</p>
<p>When determining matched reference units from visual response data, we require that units be spatially nearby (within 30 <italic>Âµm</italic>) as well as having similar visual responses. After correcting for drift, we find that we recover more reference units (<xref rid="figS7" ref-type="fig">Figure S7</xref>), indicating improved spatial match of the two ensembles. This improved recovery provides further evidence of the success of the drift correction.</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>A vertical distance threshold is necessary for accurate tracking</title>
<p>To detect the homogeneous z-shift of correct matches against the background of units without true matches, it is necessary to apply a threshold on the z-shift. When tracking units after shift correction, a vertical distance threshold is again required to determine which matches are reasonable in consideration of biological plausibility. The ROC curve in <xref rid="fig3" ref-type="fig">figure 3</xref> shows the percentage of reference units recovered and the number of KSgood preserved as a function of z-distance threshold. We want to determine the best threshold that maximizes the overall accuracy in the reference units (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, blue curve) while including as many KSgood units as possible (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, red curve).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3:</label>
<caption><p>The ROC curve of matching accuracy vs. distance. The blue curve indicates the recovery rate of reference units. The red line indicates the number of reference units included. The solid vertical line indicates the average z distance across all reference pairs in all animals (<italic>z</italic> = 6.96<italic>Âµm</italic>). The dashed vertical black line indicates a z-distance threshold at z = 10<italic>Âµm</italic>.</p></caption>
<graphic xlink:href="551724v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Since reference units only account for 29% of KSgood units (units with few inter-spike-interval violations that are believed to represent a single unit), and the majority of KSgood units did not show a distinguishable visual response, we need to understand how representative the reference units are of all KSgood units.</p>
<p>We found the distribution of z-distances of reference pairs is different from the distribution of all KSgood units (Fig.4a, top and middle panel). While both distributions may be fit t o e xponentials, t he b est fi t de cay co nstant is significantly different (Kolmogorov-Smirnov test, reject H0, p = 5.5 Ã 10<sup><italic>â</italic>31</sup>). Therefore, the accuracy predicted by the ROC of reference pairs in <xref rid="fig3" ref-type="fig">Figure 3</xref> will not apply to the set of all KSgood pairs. The difference in distribution is likely due to the reference units being a special subset of KSgood units in which units are guaranteed to be found in both datasets, whereas the remaining units may not have a real match in the second dataset. To estimate the ROC curve for the set of all KSgood units, we must estimate the distribution of KSgood correct and incorrect pairs vs. z-distance of the matched units.</p>
<p>We assume that the distribution of z-distances <italic>P</italic> (â) for reference units is the conditional probability <italic>P</italic> (â|<italic>H</italic>); that is, we assume all reference units are true hits. The distribution of z-distances for all KSgood units <italic>P</italic> (â) includes both hits and false positives. The distance distribution of false positives is the difference b etween the two (<xref ref-type="sec" rid="s7d">Sec. 8.4</xref>, <xref ref-type="disp-formula" rid="eqn5">Eqn. 5</xref>).</p>
<p>A Monte Carlo simulation determined that the best model for fitting the z-distance distribution of reference units <italic>P</italic> (â|<italic>H</italic>) is a folded gaussian distribution (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>, middle panel) and an exponential distribution for false positive units. The KSgood distribution is a weighted combination of the folded Gaussian and an exponential. (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>, top panel, see <xref ref-type="sec" rid="s7d">Sec. 8.4</xref> for details).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Fig. 4:</label>
<caption><p>Recovery rate, accuracy and putative pairs: a. The histogram distribution fit for all KSgood units (top) and reference units alone (middle). False positives for reference units are defined as units matched by EMD but not matched when using receptive fields. The false positive fraction for the set of all KSgood units is obtained by integration. z = 10<italic>Âµm</italic> threshold has a false positive rate = 27% for KSgood units. b. Light blue bars represent the number of reference units successfully recovered using only unit location and waveform. The numbers on the bars are the recovery rate of each datatset, and the red portion indicates incorrect matches. Incorrect matches are those matches using receptive field data that were not recovered using EMD without receptive field information. Similarly, the green bars show matching accuracy with distance under threshold z at 10<italic>Âµm</italic>. The orange portion indicates incorrect matches after thresholding. The false positives are mostly eliminated by adding the threshold. Purple bars are the number of putative units (unit with no reference information) inferred with z-threshold = 10<italic>Âµm</italic>.</p></caption>
<graphic xlink:href="551724v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Based on the the estimated false positive rate (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>, bottom panel), we used the threshold of 10<italic>Âµm</italic> (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, black dotted line) to obtain at least 70% accuracy in the KSgood units. We used the same threshold to calculate the number of matched reference units and the corresponding reference unit accuracy (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>, green bars).</p>
<p>Note that this threshold eliminates most of the known false positive matches of reference pairs (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>, red fraction) at the cost of recovering fewer correct pairs (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>, green bars). The recovery rate varies from day to day; datasets separated by longer times tend to have higher tracking uncertainty (<xref rid="figS9" ref-type="fig">Fig. S9</xref>).</p>
<p>In addition to the units with visual response data, we can track units which have no significant visual response (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>, purple bars). All comparisons are between subsequent datasets and the day 1 dataset.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Units can be tracked in discontinuous recordings for 48 days</title>
<p>To assess long-term tracking capabilities, we tracked neurons across all datasets for each mouse. <xref rid="fig5" ref-type="fig">Figure 5</xref> shows a survival plot of the number of unit chains successfully tracked over all durations. All units in the plot can be tracked across at least three consecutive datasets, a chain as the term is used here. We categorized all trackable unit chains into three types: reference chains, mixed chains and putative chains. Reference chains have receptive field information in all datasets. Putative chains have no reference information in any of the datasets. Mixed units have at least one dataset with no receptive field information. There are 133 reference chains, 135 mixed chains and 84 putative chains across all the subjects. Among them, 46 reference, 51 mixed, and 9 putative units can be followed across all datasets. We refer to them as fully trackable units. One example trackable unit in each group is shown in <xref rid="fig6" ref-type="fig">figure 6</xref>, <xref rid="figS11" ref-type="fig">figure S11</xref>, and <xref rid="figS10" ref-type="fig">figure S10</xref>, respectively.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Fig. 5:</label>
<caption><p>Number of reference units (deep blue, dark orange and green for different subjects), putative (medium green, medium orange and blue) units, and mixed units (light green, yellow, and light blue) tracked for different duration of days. The decrease rate is similar for different chain types in the same subject.</p></caption>
<graphic xlink:href="551724v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig6" position="float" fig-type="figure">
<label>Fig. 6:</label>
<caption><p>Example mixed chain: a. Above: Firing rates for this neuron on each day (Day 1, 2, 13, 23, 48). Below: Firing rate percent change compared to the previous day. b. Visual response similarity (yellow line), PSTH similarity correlation (orange line), and visual fingerprint similarity correlation (blue line). The similarity score is the sum of vfp and PSTH. The dashed black line represent the threshold to be considered a reference unit. c. Spatial-temporal waveform of a trackable unit. Each pair of traces represent the waveform on a single channel. d. Estimated location of this unit on different days. Each colored dot represent a unit in a day. The orange squares represent the electrodes. e. The pairwise vfp and PSTH traces of this unit.</p></caption>
<graphic xlink:href="551724v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We hypothesize that the three groups of units are not qualitatively different from each other, that is, all units are equally trackable. In order to check for differences among the three groups, we analyzed the locations, firing rates, waveforms, and receptive fields of the fully trackable units in the three groups, reference, putative, and mixed, respectively.</p>
<p>The spatial-temporal waveform similarity is measured by the L2 distances between waveforms (<xref ref-type="sec" rid="s4a2">Sec. 4.1.2</xref>). A Kruskal Wallis test is performed on the amount of L2 change between two matched waveforms among the three groups. There is no statistical difference in the waveform similarity in reference, putative, and mixed units (H = 0.59, p = 0.75) (<xref rid="figS1" ref-type="fig">Fig. S1</xref>). There is no significant difference in the physical distances of units per dataset (H = 1.31, p = 0.52) (<xref rid="figS2" ref-type="fig">Fig.S2</xref>, bottom panel), and in the location change per units (H = 0.23, p = 0.89) (<xref rid="figS2" ref-type="fig">Fig.S2</xref>, top panel).</p>
<p>Firing rate is characterized as the average firing rate fold change of each unit chain, with firing rate of each unit in each dataset normalized by the average firing rate of that dataset. There is no difference in the firing rate fold change in the three groups of units (H = 1, p = 0.6) (<xref rid="figS3" ref-type="fig">Fig.S3</xref>).</p>
<p>The receptive field similarity between units in different datasets is described by visual fingerprint (vfp) correlation and Peristimulus Time Histogram (PSTH) correlation between units, and similarity score, the sum of the two correlations (<xref ref-type="sec" rid="s4c">Sec. 4.3</xref>). Vfp change between matched units is similar among the three groups (H = 2.23, p = 0.33). Similarly, PSTH change is not different among the three groups (H = 1.61, p = 0.45) (<xref rid="figS4" ref-type="fig">Fig. S4</xref>).</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Discussion</title>
<p>We present here an EMD-based neuron tracking algorithm that provides a new, automated way to track neurons over long-term experiments to enable the study of learning and adaptation with state-of-the-art high density electrophysiology probes. We demonstrate our method by tracking neurons up to 48 days without using receptive fields information. Our method achieves 90% recovery rate on average for neurons separated up to one week apart and 78% on average for neurons five to seven weeks apart (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>, blue bars). We also achieved 97% accuracy up to one week apart and 95% five to seven weeks apart, when applying a threshold of 10 <italic>Âµm</italic> (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>, green bars). It also retrieved a total of 552 tracked neurons with partial or no receptive field information, 12 per pair of datasets on average. All the fully trackable unit chains were evaluated by waveforms and estimated locations. Our method is simple and robust; it only requires spike sorting be performed once, independently, per dataset. In order to be more compatible and generalizable with existing sorting methods, we chose Kilosort, one of the most widely used spike sorting methods (e.g., [<xref ref-type="bibr" rid="c33">33</xref>][34]). We show the capability of our method to track neurons with no specific tuning preference (<xref rid="figS10" ref-type="fig">Fig. S10</xref>).</p>
<p>The method includes means to identify dataset pairs with very large drift. In our data, we can detect large drift because such datasets have very few reference units, and significantly different EMD cost (<xref ref-type="sec" rid="s7g">Sec. 8.7</xref>). For example, dataset 1 and 2 in animal AL036 have very few reference units compared to other datasets (see <xref rid="figS12" ref-type="fig">Fig. S12</xref>, AL036). This observation is consistent with the overall relationship between the EMD cost and recovery rate (<xref rid="figS13" ref-type="fig">Fig. S13</xref>). Datasets with higher cost tend to have lower unit recovery rate and higher variation in recovery rates. Therefore, these two datasets were excluded in the tracking analysis.</p>
<p>Our validation relies on identifying reference units. The reference unit definition has limitations. The similarity score is largely driven by PSTHs (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, S12), the timing of stimulus triggered response, rather than vfp, the response selectivity. As a result, a single neuron can be highly correlated, i.e. similarity score greater than 1, with more than 20 other neurons. For example, in subject AL032 shank 2, one neuron on day 1 has 22 highly correlated neurons on day 2, 4 of which are also within the distance of 30<italic>Âµm</italic>. This contributed to inaccurate assignment of reference units and irregularity in trackable unit analysis. In summary, 33 (5 putative neurons and 28 mixed neurons) out of 106 trackable neurons have a similarity score greater than 1 even for days with no reference unit assignment. To account for the possibility that the most similar unit within the neighborhood might not be the real match, we redefined the reference units as any neuron in the neighborhood with a similarity score â¥ 1, rather than the one with the highest similarity score. This reassignment results in the loss of 162 out of 934 (17%) reference units across all comparisons, while the overall recovery rate decreases by only 0.14%.</p>
<p>We note that the ratio of reference units over KSgood units decreases as recordings are further separated in time (<xref rid="figS14" ref-type="fig">Fig. S14</xref>). This reduction in KSgood units might due in part to representational drift as well as the fact that the set of active neurons are slightly different in each recording. The visual fingerprint similarity of matched neurons decreased to 60% after 40 days ([<xref ref-type="bibr" rid="c7">7</xref>] supplement).</p>
<p>As suggested in Dhawale et al.[<xref ref-type="bibr" rid="c5">5</xref>], the false positive rate is not ideal for discontinuous recordings. Improving spike sorting and restricting the analysis to reliably sorted units will help to decrease the false positive rate. Current spike sorting methods involves fitting of many parameters. The stochastic nature of template initialization makes only around 60% to 70% of the same units for two independently executed analysis passes. Additionally, the existence of unpaired units in the neighborhood will deteriorate the matching accuracy. Future users may consider limiting their analysis to the most reliably detected units for tracking. Finally, more frequent data acquisition during experiments will provide more intermediate stages for tracking and involves smaller drift between consecutive recordings.</p>
</sec>
<sec id="s4">
<label>4</label>
<title>Methods</title>
<p>Our neuron tracking algorithm uses the Earth Moverâs Distance (EMD) optimization algorithm. The minimized distance is a weighted combination of physical distance and âwaveform distanceâ without receptive field information: the algorithm seeks to form pairs that are closest in space and have the most similar waveforms. We test the performance of the algorithm by comparing EMD matches to reference pairs determined from visual receptive fields (<xref ref-type="sec" rid="s4c">Sec. 4.3</xref>). We calculate two performance metrics. The ârecovery rateâ is the percentage of reference units that are correctly matched by the EMD procedure. The âaccuracyâ is the percentage of correctly matched reference units that pass the z-distance threshold (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). âPutative unitsâ are units matched by the procedure which do not have reference receptive field i nformation. âChainsâ are units that can be tracked across at least three consecutive datasets. The full procedure is summarized in Algorithm 1.</p>
<statement id="alg1">
<label>Algorithm 1</label>
<title>Neuron Matching Procedure</title>
<p><fig id="alg1a" position="float" fig-type="figure">
<graphic xlink:href="551724v3_alg1.tif" mimetype="image" mime-subtype="tiff"/>
</fig></p>
</statement>
<sec id="s4a">
<label>4.1</label>
<title>Algorithm</title>
<sec id="s4a1">
<label>4.1.1</label>
<title>Earth Moverâs Distance</title>
<p>The EMD is an optimization-based metric developed in the context of optimal transport and measuring distances between probability distributions. It frames the question as moving dirt, in our case, units from the first dataset, into holes, which here are the neural units in the second dataset. The distance between the âdirtâ and the âholesâ determines how the optimization program will prioritize a given match. Specifically, the EMD seeks to minimize the total work needed to move the dirt to the holes, i.e., neurons in day one to day 2, by solving a minimum overall effort, the total distances required for the movement[<xref ref-type="bibr" rid="c30">30</xref>][<xref ref-type="bibr" rid="c31">31</xref>].
<disp-formula id="eqn3">
<graphic xlink:href="551724v3_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which <italic>d</italic><sub><italic>loc</italic></sub> <italic>â ð</italic><sup>3</sup> is the three-dimensional physical distance between a unit from the first d ataset <italic>x</italic> <sub><italic>i</italic></sub>, a nd a u nit f rom t he s econd d ataset <italic>y</italic> <sub><italic>k</italic></sub>. <italic>d</italic> <sub><italic>wf</italic></sub> <italic>â ð</italic><sup>1</sup> is a scalar representing the similarity between waveforms of units <italic>x</italic><sub><italic>i</italic></sub> and <italic>y</italic><sub><italic>k</italic></sub>. <italic>Ï</italic> is a weight parameter that was tuned to maximize the recovery rate of correctly matched reference units. f indicates the matched objects between the two datasets (See <xref rid="figS15" ref-type="fig">Fig.S15</xref> for details about selecting weight).</p>
<p>The EMD has three benefits:</p>
<list list-type="bullet">
<list-item><p>It allows combing different information into âdistance matrixâ to characterize the features of units.</p></list-item>
<list-item><p>The EMD can detect homogeneous movement of units (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>), thus providing means for rigid drift correction, as described in <xref ref-type="sec" rid="s4a4">section 4.1.3</xref>.</p></list-item>
<list-item><p>By minimizing overall distances, the EMD has tolerance for imperfect drift correction, error in the determination of unit positions, and possible non-rigid motion of the units.</p></list-item>
</list>
<p>However, since the EMD is an optimization method with no assumptions about the biological property of the data, it can make matches to the lower number of the two sets. We thus added a threshold over the permissible z-distance to select physical plausible matches. Supplement <xref rid="figS15" ref-type="fig">Fig. S15</xref> shows the recovery rate change for using different weight parameters to combine neuron location and waveform metrics into a distance matrix.</p>
</sec>
<sec id="s4a2">
<label>4.1.2</label>
<title>Distance 1: Unit Location Estimation</title>
<p>The unit locations are estimated by fitting 10 peak-to-peak (PTP) amplitudes from adjacent electrodes and the corresponding channel positions with a 1/R distance model [<xref ref-type="bibr" rid="c32">32</xref>]. Unlike [<xref ref-type="bibr" rid="c32">32</xref>], we operate on the mean waveforms for each unit rather than individual spikes. We found using the mean waveform yields comparable results and saves significant computation time. Unit locations are three-dimensional coordinates estimated relative to the probe, where the location of the first electrode on the left column at the tip is considered the origin. The mean waveform is computed by averaging all the spike snippets assigned to the cluster by KS 2.5.</p>
<p>For 10 channels <inline-formula><inline-graphic xlink:href="551724v3_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, find the location coordinates <inline-formula><inline-graphic xlink:href="551724v3_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> that minimizes the difference between measured amplitudes <italic>V</italic><sub><italic>P T P</italic></sub> and amplitudes estimated with locations<inline-formula><inline-graphic xlink:href="551724v3_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>:
<disp-formula id="eqn4">
<graphic xlink:href="551724v3_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The locations are used to calculate the physical distance portion of the EMD distance.</p>
</sec>
<sec id="s4a3">
<label>4.1.2</label>
<title>Distance 2: Waveform Similarity Metrics</title>
<p>We want to describe the wave-form characteristics of each unit with its spatial-temporal waveform at the channels capturing the greatest differentiability. The waveform similarity metric between any two waveforms <italic>u</italic><sub><italic>n</italic>1</sub> and <italic>u</italic><sub><italic>n</italic>2</sub> in the two datasets is a scalar calculated as a normalized L2 metric (see Alg.1 Step 2) on the peak channels, namely the channel row with the highest amplitude and 5 rows above and below (a total of 22 channels). The resulting scalar reflects the âdistanceâ between the two units in the waveform space and is used to provide information about the waveform similarity of the units. It is used for between-session drift correction and neuron matching. <xref rid="fig1" ref-type="fig">Figure 1c</xref> shows an example waveform of a reference unit.</p>
</sec>
<sec id="s4a4">
<label>4.1.3</label>
<title>Between-session Drift Correction</title>
<p>Based on previous understanding of the drift in chronic implants, we assumed that the majority of drift occurs along the direction of the probe insertion, i.e. vertical z-direction. This rigid drift amount is estimated by the mode of the z-distance distribution of the EMD assigned units using a normal kernel density estimation implemented in Matlab. We only included KSgood units [<xref ref-type="bibr" rid="c16">16</xref>]. The estimated drift is then applied back to correct both the reference units and the EMD distance matrix by adjusting the z coordinates of the units. A post-correction reference set is compared with the post-correction matching results for validation.</p>
</sec>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Dataset</title>
<p>The data used in this work are two chronically implanted NP 2.0 four-shank probes and one chronically implanted one-shank NP 2.0 probe recordings collected in the visual cortex of three head fixed mice (<xref rid="fig7" ref-type="fig">Fig. 7b</xref>, see [<xref ref-type="bibr" rid="c7">7</xref>] for experiment details). The recordings were taken while 112 visual stimuli were shown from three surrounding screens (data from [<xref ref-type="bibr" rid="c7">7</xref>] Supplement Section 1.2). The same bank of stimuli was presented five times, with order shuffled. The 4-shank probes had the 384 recording channels mapped to 96 sites on each shank.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Fig. 7:</label>
<caption><p>Summary of dataset: a. The recording intervals for each animal. A black dash indicates one recording on that day. b. All animals were recorded from visual cortex V1 with a 720 <italic>Âµm</italic> section of the probe containing 96 recording sites. The blue arrow indicate main drift direction. c. Examples of visual fingerprint(vfp) and peri-stimulus time histogram(PSTH) from a high correlation (left column) and a just-above-threshold (right column) correlation unit. Both vfp and PSTH values vary from [0,1]. d. Kilosort-good and reference unit counts for animal AL032, including units from all four shanks.</p></caption>
<graphic xlink:href="551724v3_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We analyzed 65 recordings, each from one shank, collected on 17 sessions (5 sessions for animal AL031, 5 sessions for animal AL032, and 7 sessions for animal AL036). The time gap between recordings ranges from one day to 47 days (<xref rid="fig7" ref-type="fig">Fig. 7a</xref>), with recording durations ranging from 1917 to 2522 seconds. The sample rate is 30kHz for all recordings. There are a total of 2958 KSgood units analyzed across all animals and shanks, with an average of 56 units per dataset (<xref rid="fig7" ref-type="fig">Fig. 7d</xref> and S16).</p>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Reference set</title>
<p>To track clusters across days, Steinmetz et al.[<xref ref-type="bibr" rid="c7">7</xref>] concatenated two recording sessions and took advantage of the within-recording drift correction feature of Kilosort 2.0 to extract spikes from the two days with a common set of templates. They first estimated the between session drift of each recording from the pattern of firing rate and amplitude on the probe and applied a position correction of an integer number of probe rows (15 <italic>Âµm</italic> for the probes used). Then two corrected recordings were concatenated and sorted as a single recording. This procedure ensured that the same templates are used to extract spikes across both recordings, so that putative matches are extracted with the same template. A unit from the first half of the recording is counted as the same neuron if its visual response is more similar to that from the same cluster in the second half of the recording than to the visual response of the physically nearest neighbor unit. Using this procedure and matching criteria, 93% of the matches were correct for recordings <italic>&lt;</italic> 16 days apart, and 85% were correct for recordings from 3-9 weeks ([<xref ref-type="bibr" rid="c7">7</xref>], <xref rid="fig4" ref-type="fig">Fig. 4</xref>). In addition, even though mean fingerprint similarity decreases for recordings separated by more than 16 days, there is roughly 60% of mean fingerprint similarity for the same unit recorded from 40 days apart (see [<xref ref-type="bibr" rid="c7">7</xref>] Supplement S3). This procedure, while successful in their setting, was limited to the use of integral row adjustments of the data for between-session drift correction and relied on a customized version of Kilosort 2.0. Although up to three recordings can be sorted together, they must come from recording sessions close in time. In addition, a separate spike sorting session needs to be performed for every pair of recordings to be matched, which is time consuming and introduces extra sorting uncertainty.</p>
<p>To find units with matched visual responses, we examine the visual response similarity across all possible pairs. The visual response similarity score follows [<xref ref-type="bibr" rid="c7">7</xref>], and consists of two measurements. 1) The peristimulus time histogram (PSTH), which is the histogram of the firing of a neuron across all presentations of all images, in a 1800 msec time window starting 400 msec before and 400 msec after the stimulus presentation. The PSTH is calculated by histrogramming spike times relative to stimulus on time for all stimuli, using 1 ms bins. This histogram is then smoothed with a gaussian filter. 2) The visual fingerprint(vfp) is the average response of the neuron to each of the 112 images. The vfp is calculated by averaging the spike counts in response to each natural image from the stimulus onset to 1 second afterwards across 5 shuffled trials.</p>
<p>Following Steinmetz et al.[<xref ref-type="bibr" rid="c7">7</xref>], the similarity score between two neurons is the sum of the correlation of the PSTH across the 2 sessions (0-1) and the correlation of the vfp across those same sessions (0-1), ranging from 0 to 2.</p>
<p>The pool of reference units is established with three criteria: 1) The visual response similarity score of the pair, as described above, is greater than 1 and their physical distance, both before and after drift correction, is smaller than 30 <italic>Âµ</italic>m. We chose 30 <italic>Âµ</italic>m on both pre- and post-correction data because the drift is relatively small in our case, and we can reduce false positives by constrain the reference units to be in a smaller region without losing units.</p>
<p>In general, one could apply the threshold only on corrected data (after drift correction), similar to the case of putative units in our case, which do not have reference visual information. 2) A Kruskal-Wallis test is applied on all trials of the vfps to make sure the response firing pattern triggered by the stimulus is significantly distinguishable from a flat line. 3) Select units from each recording that meet the good criteria in Kilosort. Kilosort assigns a label of either single-unit (good) or multi-unit (MUA) to all the sorted clusters based on ISI violation [<xref ref-type="bibr" rid="c16">16</xref>]. This step attempts to ensure the units are well separated. If there are multiple potential partners for a unit, the pair with the highest similarity score is selected as the reference unit. The reference units capture two representations from different sessions of the neuronsâ visual response to the stimulus. The portion of units with qualified visual response ranges from 5% to 61%, depending on the time gap between datatets (<xref rid="figS14" ref-type="fig">Fig.S14</xref>). Overall, these reference units made up 29% of all KSgood units (<xref rid="figS16" ref-type="fig">Fig. S16</xref>) across all three animals in our dataset. <xref rid="fig7" ref-type="fig">Figure 7c</xref> shows examples of visual responses from a high similarity and a just-above-threshold similarity reference units</p>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Code sharing</title>
<p>All code used can be accessed at: <ext-link ext-link-type="uri" xlink:href="https://github.com/AugustineY07/Neuron_Tracking">https://github.com/AugustineY07/Neuron_Tracking</ext-link>.</p>
</sec>
</body>
<back>
<ack>
<label>6</label>
<title>Acknowledgments</title>
<p>We thank M. Okun from University College London for his assistance in data pre-processing. This work was supported supported in part by NIH grant U01 NS115587.</p>
</ack>
<sec id="s6">
<label>7</label>
<title>Declaration of interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec id="s7">
<label>8</label>
<title>Supplements</title>
<sec id="s7a">
<label>8.1</label>
<title>Trackable units statistics</title>
<p>In order to make sure trackable reference, putative, and mixed units are qualitatively similar, We summarized the median, maximum and minimum amount of change on firing rate, visual receptive field, and location in the box plots below. Kruskal Wallis test performed in each feature suggested no difference among the three groups (see Sec. 2.4 for details).</p>
<fig id="figS1" position="float" fig-type="figure">
<label>Fig. S1:</label>
<caption><p>The waveform L2 similarity change distribution per dataset by neuron groups and across all neurons. Box plots indicate 25% percentile, medians, and 75% percentile. Whiskers at the ends of the box plot show maximum and minimum values. n and N represents the number of unit comparisons, i.e. number of units times (number of datatset â1).</p></caption>
<graphic xlink:href="551724v3_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Fig. S2:</label>
<caption><p>The plots show location change distribution per units and the bottom plot show the change per dataset by neuron groups and across all neurons. Box plots indicate 25% percentile, medians, and 75% percentile. Whiskers at the ends of the box plot show maximum and minimum values. n and N represents the number of units (above plot), and the number of unit comparisons, i.e. number of units times (number of datatset â1) (lower plot).</p></caption>
<graphic xlink:href="551724v3_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Fig. S3:</label>
<caption><p>The average firing rate fold change per dataset by neuron groups and across all neurons. Box plots indicate 25% percentile, medians, and 75% percentile. Whiskers at the ends of the box plot show maximum and minimum values. n and N represents the number of units.</p></caption>
<graphic xlink:href="551724v3_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Fig. S4:</label>
<caption><p>The visual fingerprint and PSTH change distribution per dataset by neuron groups and across all neurons. Box plots indicate 25% percentile, medians, and 75% percentile. Whiskers at the ends of the box plot show maximum and minimum values. n and N represents the number of unit comparisons, i.e. number of units times (number of datatset â1).</p></caption>
<graphic xlink:href="551724v3_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Fig. S5:</label>
<caption><p>The similarity score distribution per dataset by neuron groups and across all neurons.Box plots indicate 25% percentile, medians, and 75% percentile. Whiskers at the ends of the box plot show maximum and minimum values. n and N represents the number of occurrence of units, i.e. number of units times number of datasets this unit have.</p></caption>
<graphic xlink:href="551724v3_figS5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7b">
<label>8.2</label>
<title>Similarity score heatmap</title>
<p>We identify reference pairs as units that are close in space (peak channels separated by <italic>&lt;</italic> 30<italic>Âµm</italic>) and high similarity score (<italic>&gt;</italic>1). Multiple partners can meet these criteria due to oversplitting â these correspond to blocks of high scores in the heatmap. We only include a unit as a reference if its highest similarity score counterpart in the other dataset is within the 30<italic>Âµm</italic> distance threshold.</p>
<fig id="figS6" position="float" fig-type="figure">
<label>Fig. S6:</label>
<caption><p>An example similarity score (vfp + PSTH) heatmap from animal AL032 shank 2 Kilosort-good units between day 1 and 2. Each small square represents the similarity score (value range from [0,2]) between one unit from day 1 and one unit from day 2. A warm colored square indicates a higher score. All clusters are sequenced by their physical locations on the probe. There is a diagonal line with brightest color blocks, indicating that units with more similar firing responses across days tend to be physically close. This confirms our assumption that neurons are physically stable overtime. Also notice that, on each column, there might be more than one bright blocks in the more distance clusters. We minimizes the effect of the distant units by constraining the feasible region during reference units selection. There are also columns without bright yellow blocks. This happens because some units do not respond to the stimulus and those units are not included in the reference set.</p></caption>
<graphic xlink:href="551724v3_figS6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7c">
<label>8.3</label>
<title>Pre- and post-drift correction Unit counts</title>
<p>We showed that between-session drift correction retrieved more reference units.</p>
<fig id="figS7" position="float" fig-type="figure">
<label>Fig. S7:</label>
<caption><p>The effect of drift correction in finding reference units for all three animals. Note that drift correction improves the recovery rate for most cases; the degree of improvement is a function of the magnitude of the drift.</p></caption>
<graphic xlink:href="551724v3_figS7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7d">
<label>8.4</label>
<title>ref and KSgood distribution</title>
<p>As shown in <xref rid="fig4" ref-type="fig">Fig. 4a</xref>, the z distance distribution of reference differs significantly from that of all pairs. To estimate the false positive rate (False positives are defined as units matched by EMD but not matched by using receptive fields) for all pairs, we need to account for this difference; we cannot simply extrapolate from the measured false positive rate of the reference units. The difference arises from a selection bias in the reference units, which must be easily detectable units in both datasets to meet the requirements of similar visual fingerprint. We created a simple model to determine an appropriate functional form to fit the z distribution of all units and estimate the false positive.</p>
<p>Assume the following distributions:</p>
<list list-type="order">
<list-item><p>The distance distribution of matched neurons, i.e. KSgood unit distribution, (â <italic>&gt;</italic> 0) is
<disp-formula id="ueqn1">
<graphic xlink:href="551724v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p></list-item>
<list-item><p>The distance distribution of matched neurons that are true hits, i.e. the correctly-matched reference unit distribution (<italic>H</italic>: correct match/hits) is
<disp-formula id="ueqn2">
<graphic xlink:href="551724v3_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p></list-item>
<list-item><p>The distance distribution of false positive matched neurons, i.e. false positive distribution, is
<disp-formula id="ueqn3">
<graphic xlink:href="551724v3_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p></list-item></list>
<p>Let f be the fraction of units with true hits, then the z distance distribution for all units is:
<disp-formula id="eqn5">
<graphic xlink:href="551724v3_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
To estimate the distribution of <italic>P</italic> (â|<italic>H</italic>), we assume that drift correction works properly. The z shift between the two units of a reference pair is due to the error in measuring the position of the unit. The distribution of â<italic>z</italic>, which is the absolute value of the z shift, is expected to be a Folded Gaussian with mean = 0, and sigma = 2*(error in measured z position).</p>
<p>To estimate the distribution of <italic>P</italic> (â |<italic>â¼ H</italic>), we perform a Monte Carlo model of simulated units. We chose the number of units to be 150, the average density of subject AL036. A fraction f will have real partners in the second dataset. The unit positions in each dataset have normally distributed errors with sigma = 5<italic>Âµm</italic>. This error is set to match observed distribution of z-distance in the reference units.</p>
<p>To determine a range f (fraction of true hits) that matches the real data, we can estimate probability of a hit in terms of probability of being a reference neuron <italic>P</italic> (<italic>R</italic>) using Bayes rule
<disp-formula id="ueqn4">
<graphic xlink:href="551724v3_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<italic>P</italic> (<italic>H</italic> | <italic>R</italic>) can be estimated from the reference units recovery rate 0.86, and <italic>P</italic> (<italic>R</italic>) can be estimated from the ratio of reference units, which is 0.29. <italic>P</italic> (<italic>â¼ R</italic>) = 1 <italic>â P</italic> (<italic>R</italic>) = 0.73. Then
<disp-formula id="eqn6">
<graphic xlink:href="551724v3_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn7">
<graphic xlink:href="551724v3_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We estimated the conditions with 25% to 96% of hits, which includes units with or without reference information.
<disp-formula id="eqn8">
<graphic xlink:href="551724v3_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We modeled the distribution at values of f = 0.23, 0.5, 0.6, 0.7 and 0.96. For each value of f, we generate 500 datasets, and compile the z-distance distributions for H and â¼ <italic>H</italic>, both from the EMD solution that âmispairâ some of the true hits due to unit crowding.</p>
<fig id="figS8" position="float" fig-type="figure">
<label>Fig. S8:</label>
<caption><p>The distribution fitting for KSgood and correct reference units with simulated data at f = 0.23, 0.5, 0.6, 0.7, 0.96, respectively.</p></caption>
<graphic xlink:href="551724v3_figS8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We fit the distance distribution of the reference units to obtain sigma, the width of the folded gaussian in the first term of Eqn.8. With sigma fixed, we then fit the distance distribution of all KSGood units to Eqn.8 to obtain the width of the exponential and f. Then we can estimate the false positive rate by integrating <italic>P</italic> (â|<italic>H</italic>) and <italic>P</italic> (â |<italic>â¼H</italic>) up to the z distance threshold. The fraction of false positivies as a function of z distance threshold is shown in <xref rid="fig4" ref-type="fig">Fig.4a</xref>, in the bottom panel.</p>
</sec>
<sec id="s7e">
<label>8.5</label>
<title>Recovery rate vs. time between recordings</title>
<fig id="figS9" position="float" fig-type="figure">
<label>Fig. S9:</label>
<caption><p>The reference units recovery rate for spike sorted recordings spanning different days. Each triangle represents the matching results of two datasets. Animal AL031 has 6 sets of matching, with one outlier removed. Animal AL032 has 24 sets of matching. Animal AL036 has 60 sets of matching. The recovery quality becomes lower as datasets spans longer time.</p></caption>
<graphic xlink:href="551724v3_figS9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7f">
<label>8.6</label>
<title>Example reference and putative chains</title>
<fig id="figS10" position="float" fig-type="figure">
<label>Fig. S10:</label>
<caption><p>An example of reference chain. a. Above: Firing rates of this neuron on each day. Below: Firing rate percent change compared to the previous day. b. Visual response similarity (yellow line), PSTH similarity correlation (orange line), and visual fingerprint similarity correlation (blue line). The similarity score is the sum of vfp and PSTH. The dashed black line represent the threshold to be considered a reference unit. c. Spatial-temporal waveform of a trackable unit. Each pair of traces represent the waveform on a single channel. d. Estimated location of this unit on different days. Each colored dot represent a unit in a day. The orange squares represent the electrodes. e. The pairwise vfp and PSTH traces of this unit.</p></caption>
<graphic xlink:href="551724v3_figS10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS11" position="float" fig-type="figure">
<label>Fig. S11:</label>
<caption><p>An example of putative chain. Order is the same as above.</p></caption>
<graphic xlink:href="551724v3_figS11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7g">
<label>8.7</label>
<title>Reference unit counts and the EMD cost matrix</title>
<p>In animal AL036, there is a large decrease in the number of reference units after the second dataset, likely due to a large physical shift of the probe relative to the tissue. It is important to be able to detect such discontinuities to eliminate datasets from consideration. We find that the discontinuity can be detected in the EMD mean cost, location mean cost and waveform mean cost. The pairwise values for the costs are show in <xref rid="figS12" ref-type="fig">Fig.S12</xref>.</p>
<p>To show that days 1-2 (first two rows) are significantly different from days 3-9, we use Mann Whitney U Test. All three cost values show significant differences between the groups (EMD mean cost, reject H0, p = 6 <italic>Ã</italic> 10<sup><italic>â</italic>7</sup>; location mean cost, reject H0, p = 6 <italic>Ã</italic> 10<sup><italic>â</italic>5</sup>; waveform mean cost, reject H0, p = 5 <italic>Ã</italic> 10<sup><italic>â</italic>7</sup>)). To show that days 3-9 come from the same distribution, we compare odd and and even rows using the same test. All three cost values show no significant difference between odd and even days (accept H0, p = 0.92).</p>
<p>Because days 1-2 are significantly different from 3-9, we eliminated them from our analysis.</p>
<fig id="figS12" position="float" fig-type="figure">
<label>Fig. S12:</label>
<caption><p>Reference unit counts and normalized EMD cost for each pair of datasets recorded by the same shank. For animal AL036 (left), we excluded the first two datasets and all of their matching results (first two rows of each matrix on the left) based on the reference unit counts. Following analysis on their matching EMD cost, location-only cost and waveform-only cost suggest a big difference compared to the following days (datasets in the red rectangles). We infer that the first two datatsets have recorded from a different population from the later days. The other matrices show the similar information for animal AL032 for reference. To show the relative size of EMD cost in related datasets versus unrelated datasets, we calculated the cost between unrelated datasets with similar number of units (AL032 shank 1 and AL036 shank 1, EMD cost = 78, location cost = 67, and waveform cost = 32). The EMD cost is between 70-80, much larger than those between related datasets (between 20-30).</p></caption>
<graphic xlink:href="551724v3_figS12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7h">
<label>8.8</label>
<title>Recovery rate vs. the EMD cost</title>
<fig id="figS13" position="float" fig-type="figure">
<label>Fig. S13:</label>
<caption><p>The normalized EMD cost (unitless), z distance (<italic>Âµm</italic>), physical distance (<italic>Âµm</italic>), and waveform distance (unitless) and the corresponding recovery rate in pairwise match of all recording to all other recordings, shank by shank. Each triangle represents the recovery rate of two datasets. Animal AL031 has 6 sets of matching, with one outlier removed. Animal AL032 has 24 sets of matching. Animal AL036 has 60 sets of matching. Overall, most of the datat-set with high recovery rate has per-unit EMD cost around 50. Note that the EMD cost is not predictive of recovery rate.</p></caption>
<graphic xlink:href="551724v3_figS13.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7i">
<label>8.9</label>
<title>Reference unit ratio</title>
<fig id="figS14" position="float" fig-type="figure">
<label>Fig. S14:</label>
<caption><p>The reference units to KSgood units ratio decreases for datasets with larger time interval. But the variability of the number of reference units is generally large for datasets with the same time interval.</p></caption>
<graphic xlink:href="551724v3_figS14.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7j">
<label>8.10</label>
<title>Parameter tuning: L2-weight vs. Recovery rate</title>
<fig id="figS15" position="float" fig-type="figure">
<label>Fig. S15:</label>
<caption><p>We varied weight <italic>Ï</italic> in <xref ref-type="disp-formula" rid="eqn3">equation 3</xref> used to combine physical and waveform distances at an increment of 500. The vertical line indicate weight = 1500, where the overall recovery rate = 86.29%. The maximum recovery rate = 87.68% occurs at weight = 3000. We chose weight = 1500 for all subsequent analysis.</p></caption>
<graphic xlink:href="551724v3_figS15.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s7k">
<label>8.11</label>
<title>Reference unit counts</title>
<p>The number of KSgood units in each datatset and number of reference units between a later dataset and the first dataset in animal AL021 and AL032 is shown here.</p>
<fig id="figS16" position="float" fig-type="figure">
<label>Fig. S16:</label>
<caption><p>The Kilosort-good and reference unit counts for the animals. AL031 and AL036 as shown for animal AL032 in <xref rid="fig5" ref-type="fig">Figure 5</xref>.</p></caption>
<graphic xlink:href="551724v3_figS16.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>J. M.</given-names> <surname>Carmena</surname></string-name>, <string-name><given-names>C. S. H. M. A.</given-names> <surname>Lebedev</surname></string-name> &amp; <string-name><surname>Nicolelis</surname>, <given-names>M. A. L.</given-names></string-name> <article-title>Stable ensemble performance with single-neuron variability during reaching movements in primates</article-title>. <source>J. Neurosci</source>. <volume>25</volume>, <fpage>10712</fpage>â<lpage>10716</lpage> (<year>2005</year>). <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2772-05.2005</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>Huber</surname></string-name>, <collab>S. P. D. H. O. J. S. W. L. T. T. G. O. L. L. L.. K. S., D. A</collab>. <article-title>Gutnisky. Multiple dynamic representations in the motor cortex during sensorimotor learning</article-title>. <source>Nature</source> <volume>484</volume>, <fpage>473</fpage>â<lpage>478</lpage> (<year>2012</year>). <pub-id pub-id-type="doi">10.1038/nature11039</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>William A</given-names> <surname>Liberti</surname> <suffix>III</suffix></string-name>, <collab>L. N. P. D. C. L. D. P. L. G. G. T. V. D. N. K. C. L.. T. J. G</collab>., <string-name><given-names>Jeffrey E</given-names> <surname>Markowitz</surname></string-name>. <article-title>Unstable neurons underlie a stable learned behavior</article-title>. <source>Nat Neurosci</source> <volume>19</volume>, <fpage>1665</fpage>â<lpage>1671</lpage> (<year>2016</year>). <pub-id pub-id-type="doi">10.1038/nn.4405</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Clopath</surname></string-name>, <string-name><given-names>M. H. T.</given-names> <surname>Bonhoeffer</surname></string-name> &amp; <string-name><surname>Rose</surname>, <given-names>T.</given-names></string-name> <article-title>Variance and invariance of neuronal long-term representations</article-title>. <source>Phil. Trans. R. Soc</source>. <volume>372</volume> (<year>2017</year>). <pub-id pub-id-type="doi">10.1098/rstb.2016.0161</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>A. K.</given-names> <surname>Dhawale</surname></string-name>, <collab>S. B. W. V. A. N. E. K</collab>., <string-name><given-names>R.</given-names> <surname>Poddar</surname></string-name> &amp; <string-name><surname>Ãlveczky</surname>, <given-names>B. P.</given-names></string-name> <article-title>Automated long-term recording and analysis of neural activity in behaving animals</article-title>. <source>eLife</source> <volume>6</volume>, <fpage>e27702</fpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.7554/eLife.27702</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>K. T.</given-names> <surname>Jensen</surname></string-name>, <collab>A. K. D. S. B. E. W</collab>., <string-name><given-names>N. Kadmon</given-names> <surname>Harpaz</surname></string-name> &amp; <string-name><surname>Ãlveczky</surname>, <given-names>B. P.</given-names></string-name> <article-title>Long-term stability of single neuron activity in the motor system</article-title>. <source>Nat Neurosci</source> <volume>25</volume>, <fpage>1664</fpage>â<lpage>1674</lpage> (<year>2022</year>). <pub-id pub-id-type="doi">10.1038/s41593-022-01194-3</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><surname>Steinmetz</surname>, <given-names>N. A.</given-names></string-name> <etal>et al.</etal> <article-title>Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings</article-title>. <source>Science</source> <volume>372</volume>, <fpage>eabf4588</fpage> (<year>2021</year>). <pub-id pub-id-type="doi">10.1126/science.abf4588</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><surname>Luo</surname>, <given-names>T. Z.</given-names></string-name> <etal>et al.</etal> <article-title>An approach for long-term, multi-probe neuropixels recordings in unrestrained rats</article-title>. <source>eLife</source> <volume>9</volume> (<year>2020</year>). <pub-id pub-id-type="doi">10.7554/eLife.59716</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name>, <string-name><surname>Quiroga</surname>, <given-names>R. Q.</given-names></string-name>, <string-name><surname>Freeman</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Smith</surname>, <given-names>S. L.</given-names></string-name> <article-title>Improving data quality in neuronal population recordings</article-title>. <source>Nature Neuroscience</source> <volume>19</volume>, <fpage>1165</fpage>â<lpage>1174</lpage> (<year>2016</year>). <pub-id pub-id-type="doi">10.1038/nn.4365</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><surname>BuzsÃ¡ki</surname>, <given-names>G.</given-names></string-name> <article-title>Large-scale recording of neuronal ensembles</article-title>. <source>Nature Neuroscience</source> <volume>7</volume>, <fpage>446</fpage>â<lpage>451</lpage> (<year>2004</year>). <pub-id pub-id-type="doi">10.1038/nn1233</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name>, <string-name><surname>Kass</surname>, <given-names>R. E.</given-names></string-name> &amp; <string-name><surname>Mitra</surname>, <given-names>P. P.</given-names></string-name> <article-title>Multiple neural spike train data analysis: state-of-the-art and future challenges</article-title>. <source>Nature Neuroscience</source> <volume>7</volume>, <fpage>456</fpage>â<lpage>461</lpage> (<year>2004</year>). <pub-id pub-id-type="doi">10.1038/nn1228</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><surname>Quian Quiroga</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Panzeri</surname>, <given-names>S.</given-names></string-name> <article-title>Extracting information from neuronal populations: information theory and decoding approaches</article-title>. <source>Nature Reviews Neuroscience</source> <volume>10</volume>, <fpage>173</fpage>â<lpage>185</lpage> (<year>2009</year>). <pub-id pub-id-type="doi">10.1038/nrn2578</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name> <article-title>Neural signatures of cell assembly organization</article-title>. <source>Nature Reviews Neuroscience</source> <volume>6</volume>, <fpage>399</fpage>â<lpage>407</lpage> (<year>2005</year>). <pub-id pub-id-type="doi">10.1038/nrn1669</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><surname>R. Q. Quiroga</surname>, <given-names>Z. N.</given-names></string-name> &amp; <string-name><surname>Ben-Shaul</surname>, <given-names>Y.</given-names></string-name> <article-title>Unsupervised spike detection and sorting with wavelets and superparamagnetic clustering</article-title>. <source>Neural Computation</source> <volume>16</volume>, <fpage>1661</fpage>â<lpage>1687</lpage> (<year>2004</year>). <pub-id pub-id-type="doi">10.1162/089976604774201631</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Chah</surname></string-name>, <collab>A. D.-C. J. J. H. M. S. M. O</collab>., <string-name><given-names>V.</given-names> <surname>Hok</surname></string-name> &amp; <string-name><surname>Reilly</surname>, <given-names>R. B.</given-names></string-name> <article-title>Automated spike sorting algorithmbased on laplacian eigenmaps and k -means clustering</article-title>. <source>J. Neural Eng</source>. <volume>8</volume>, <fpage>016006</fpage> (<year>2011</year>). <pub-id pub-id-type="doi">10.1088/1741-2560/8/1/016006</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="other"><string-name><surname>Pachitariu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Steinmetz</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Kadir</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Kenneth D</surname>., <given-names>H.</given-names></string-name> <source>Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels</source> (<year>2016</year>).</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><surname>Carlson</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Carin</surname>, <given-names>L.</given-names></string-name> <article-title>Continuing progress of spike sorting in the era of big data</article-title>. <source>Current Opinion in Neurobiology</source> <volume>55</volume>, <fpage>90</fpage>â<lpage>96</lpage> (<year>2019</year>). <pub-id pub-id-type="doi">10.1016/j.conb.2019.02.007</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><surname>Jun</surname>, <given-names>J. J.</given-names></string-name> <etal>et al.</etal> <article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title>. <source>Nature</source> <volume>551</volume>, <fpage>232</fpage>â<lpage>236</lpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.1038/nature24636</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><surname>Hall</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Herzfeld</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name> <article-title>Evaluation and resolution of many challenges of neural spike sorting: a new sorter</article-title>. <source>Journal of Neurophysiology</source> <volume>126</volume>, <fpage>2065</fpage>â<lpage>2090</lpage> (<year>2021</year>). <pub-id pub-id-type="doi">10.1152/jn.00047.2021</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><surname>Tolias</surname>, <given-names>A. S.</given-names></string-name> <etal>et al.</etal> <article-title>Recording chronically from the same neurons in awake, behaving primates</article-title>. <source>Journal of Neurophysiology</source> <volume>98</volume>, <fpage>3780</fpage>â<lpage>3790</lpage> (<year>2007</year>). <pub-id pub-id-type="doi">10.1152/jn.00260.2007</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><surname>Swindale</surname>, <given-names>N. V.</given-names></string-name> &amp; <string-name><surname>Spacek</surname>, <given-names>M. A.</given-names></string-name> <article-title>Spike sorting for polytrodes: a divide and conquer approach</article-title>. <source>Frontiers in Systems Neuroscience</source> <volume>8</volume> (<year>2014</year>). <pub-id pub-id-type="doi">10.3389/fnsys.2014.00006</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><surname>Bar-Hillel</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Spiro</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Stark</surname>, <given-names>E.</given-names></string-name> <article-title>Spike sorting: Bayesian clustering of non-stationary data</article-title>. <source>Journal of Neuroscience Methods</source> <volume>157</volume>, <fpage>303</fpage>â<lpage>316</lpage> (<year>2006</year>). <pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.04.023</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="other"><collab>JinHyung Lee, H. S.-I. K. N. D. S. W. K. L. E. B. R. D. T. E. B. Y. J. K. N. B. A. K. G. G. E. C. D. C. L. P</collab>., <string-name><given-names>Catalin</given-names> <surname>Mitelut</surname></string-name>. <source>Yass: Yet another spike sorter applied to large-scale multi-electrode array recordings in primate retina</source> <fpage>10712</fpage>â<lpage>10716</lpage> (<year>2020</year>). <pub-id pub-id-type="doi">10.1101/2020.03.18.997924</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>Jason E</given-names> <surname>Chung</surname></string-name>, <collab>A. H. B. V. M. T. A. C. T. K. Y. L. K. G. S. S. H. F. L. M. F. L. F. G</collab>., <string-name><given-names>Jeremy F</given-names> <surname>Magland</surname></string-name>. <article-title>A fully automated approach to spike sorting</article-title>. <source>Neuron</source> <volume>95</volume>, <fpage>1381</fpage>â<lpage>1394</lpage>.e6 (<year>2017</year>). <pub-id pub-id-type="doi">10.1016/j.neuron.2017.08.030</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><surname>Chung</surname>, <given-names>J. E.</given-names></string-name> <etal>et al.</etal> <article-title>High-density, long-lasting, and multi-region electrophysiological recordings using polymer electrode arrays</article-title>. <source>Neuron</source> <volume>101</volume>, <fpage>21</fpage>â<lpage>31</lpage>.e5 (<year>2019</year>). <pub-id pub-id-type="doi">10.1016/j.neuron.2018.11.002</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><surname>Vasilâeva</surname>, <given-names>L. N.</given-names></string-name> <etal>et al.</etal> <article-title>Long-term recording of single neurons and criteria for assessment</article-title>. <source>Neuroscience and Behavioral Physiology</source> <volume>46</volume>, <fpage>264</fpage>â<lpage>269</lpage> (<year>2016</year>). <pub-id pub-id-type="doi">10.1007/s11055-016-0227-8</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><surname>U. Rokni</surname>, <given-names>E. B.</given-names></string-name>, <string-name><given-names>A. G.</given-names> <surname>Richardson</surname></string-name> &amp; <string-name><surname>Seung</surname>, <given-names>H. S.</given-names></string-name> <article-title>Motor learning with unstable neural representations</article-title>. <source>Neuron</source> <volume>54</volume>, <fpage>653</fpage>â<lpage>666</lpage> (<year>2007</year>). <pub-id pub-id-type="doi">10.1016/j.neuron.2007.04.030</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><collab>MS, L</collab>. <article-title>A review of methods for spike sorting: the detection and classification of neural action potentials michael s lewicki</article-title>. <source>Network</source> <volume>9</volume>, <fpage>R53</fpage>â<lpage>78</lpage> (<year>1998</year>). <pub-id pub-id-type="doi">10.1088/0954-898X/9/4/001</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="web"><string-name><surname>Colonell</surname>, <given-names>J.</given-names></string-name> <source>ecephys spike sorting</source>. <ext-link ext-link-type="uri" xlink:href="https://github.com/jenniferColonell/ecephys_spike_sorting">https://github.com/jenniferColonell/ecephys_spike_sorting</ext-link> (<year>2018</year>).</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="book"><string-name><surname>Cohen</surname>, <given-names>S.</given-names></string-name> <source>Finding color and shape patterns in images</source> (<publisher-name>stanford university, palo alto</publisher-name>, 1999) (<year>1999</year>) .</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><given-names>N. P.</given-names> <surname>Bertrand</surname></string-name>, <collab>J. L. P. B. D</collab>., <string-name><given-names>A. S.</given-names> <surname>Charles</surname></string-name> &amp; <string-name><surname>Rozell</surname>, <given-names>C. J.</given-names></string-name> <article-title>Efficient tracking of sparse signals via an earth moverâs distance dynamics regularizer</article-title>. <source>IEEE</source> <volume>27</volume>, <fpage>1120</fpage>â<lpage>1124</lpage> (<year>2020</year>). <pub-id pub-id-type="doi">10.1109/LSP.2020.3001760</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="other"><string-name><surname>Boussard</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Varol</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>H. D.</given-names></string-name>, <string-name><surname>Dethe</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name> <article-title>Three-dimensional spike localization and improved motion correction for neuropixels recordings</article-title>. <source>NeurIPS Proceedings</source> (<year>2021</year>) .</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><given-names>Britton A.</given-names> <surname>Sauerbrei</surname></string-name>, <collab>J. D. C. M. M. W. G. M. K. N. V. B. M. K. B.. A. W. H</collab>., <string-name><given-names>Jian-Zhong</given-names> <surname>Guo</surname></string-name>. <article-title>Cortical pattern generation during dexterous movement is input-driven</article-title>. <source>Nature</source> <volume>577</volume>, <fpage>386</fpage>â<lpage>391</lpage> (<year>2020</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92495.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Peyrache</surname>
<given-names>Adrien</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>McGill University</institution>
</institution-wrap>
<city>Montreal</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study proposes a new method for tracking neurons recorded with Neuropixel electrodes across days. The methods and the strength of the evidence are <bold>convincing</bold>, but the authors do not adequately address whether their approach can be generalized to other brain areas, species, behaviors, or tools. Overall, this method will be potentially of interest to many neuroscientists who want to study long-term activity changes of individual neurons in the brain.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92495.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The brain's code is not static. Neuronal activity patterns change as a result of learning, aging, and disease. Reliable tracking of activity from individual neurons across long time periods would enable detailed studies of these important dynamics. For this reason, the authors' efforts to track electrophysiological activity across days without relying on matching neural receptive fields (which can change due to learning, aging, and disease) are very important.</p>
<p>By utilizing the tightly-spaced electrodes on Neuropixels probes, they are able to measure the physical distance and the waveform shape 'distance' between sorted units recorded on different days. To tune the matching algorithm and validate the results, they used the visual receptive fields of neurons in the mouse visual cortex (which tend to change little over time) as ground truth. Their approach performs quite well, with a high proportion of neurons accurately matched across multiple weeks. This suggests that the method may be useable in other cases where the receptive fields can't be used as ground truth to validate the tracking. This potential extendibility to tougher applications is where this approach holds the most promise.</p>
<p>The main caveat (and disappointment) is that this paper does not address generalizability to other experimental conditions. Because it only looks at one brain area (visual cortex), in one species (mouse), using one type of spike sorter (Kilosort), and one type of behavioral prep (head-fixed), it is not clear if this approach is overfit to those conditions or if it will perform equally well in other conditions. Most importantly, in brain areas where neuronal receptive fields are more dynamic and can't be used as a ground truth diagnostic, it isn't clear how to apply the technique outlined in this study, since many of the parameters are tuned to a very specific set of conditions using visual receptive fields as ground truth.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92495.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The manuscript presents a method for tracking neurons recorded with neuropixels across days, based on the matching of cells' spatial layouts and spike waveforms at the population level. The method is tested on neuropixel recordings of the visual cortex carried over 47 days, with the similarity in visual receptive fields used to verify the matches in cell identity.</p>
<p>This is an important tool as electrophysiological recordings have been notoriously limited in terms of tracking individual neuron's fate over time, unlike imaging approaches. The method is generally sound and properly tested but I think some clarifications would be helpful regarding the implementation of the method and some of the results.</p>
<p>1. Page 6: I am not sure I understand the point of the imposed drift and how the value of 12Âµm is chosen.</p>
<p>2. The EMD is based on the linear sum, with identical weight, of cell distance and waveform similarity measures. How performance is affected by using a different weighting of the 2 measures (for instance, using only cell distance and no waveform similarity)? It is common that spike waveforms associated with a given neuron appear differently on different channels of silicon probes (i.e. the spike waveform changes depending on the position of recording sites relative to the neuron), so I wonder if that feature is helping or potentially impeding the tracking.</p>
<p>3. Fig.5: I assume the dots represent time gaps for which cell tracking is estimated. The 3 different groups of colors correspond to the 3 mice used. For a given mouse, I would expect to always see 3 dots (for ref, putative, and mixed) for a given tracking gap. However, for mouse AL036 for instance, at a tracking duration of 8 days, a dot is visible for mixed but not for ref and putative. How come this is happening?</p>
<p>4. Matched visual responses are measured by the sum of the correlation of visual fingerprints, which are vectors of cells' average firing rate across visual stimuli, and the correlation of PSTHs, which are implemented over all visual stimuli combined. I believe that some information is lost from combining all stimuli in the implementation of PSTHs (assuming that PSTHs show specificity to individual visual stimuli). The authors might consider, as an alternative measure of matched visual responses, a correlation of the vector concatenations of all stimulus PSTHs. Such a simpler measure would contain both visual fingerprint and PSTH information, and would not lose the information of PSTH specificity across visual stimuli.</p>
</body>
</sub-article>
</article>